{
    "chinese": {
        "gemini-2.5-pro": {
            "rating": 1514.4351156053401,
            "rating_q975": 1526.683138137866,
            "rating_q025": 1502.1870930728142
        },
        "glm-4.6": {
            "rating": 1509.8915203571282,
            "rating_q975": 1545.8989634895781,
            "rating_q025": 1473.8840772246783
        },
        "qwen3-max-preview": {
            "rating": 1490.4237318374276,
            "rating_q975": 1508.0265929384523,
            "rating_q025": 1472.8208707364029
        },
        "gemini-2.5-flash-preview-09-2025": {
            "rating": 1473.6651266882639,
            "rating_q975": 1502.4658907867897,
            "rating_q025": 1444.864362589738
        },
        "qwen3-next-80b-a3b-instruct": {
            "rating": 1471.9136349818627,
            "rating_q975": 1491.7339253640955,
            "rating_q025": 1452.09334459963
        },
        "deepseek-v3.1-thinking": {
            "rating": 1469.6686971072784,
            "rating_q975": 1490.6399775772327,
            "rating_q025": 1448.697416637324
        },
        "qwen3-235b-a22b-thinking-2507": {
            "rating": 1467.4861448468896,
            "rating_q975": 1496.2307256270403,
            "rating_q025": 1438.7415640667389
        },
        "grok-4-fast": {
            "rating": 1466.5097729308734,
            "rating_q975": 1498.4718989983755,
            "rating_q025": 1434.5476468633713
        },
        "qwen3-vl-235b-a22b-instruct": {
            "rating": 1465.99338127526,
            "rating_q975": 1497.0962877551763,
            "rating_q025": 1434.8904747953436
        },
        "glm-4.5": {
            "rating": 1465.7195197550218,
            "rating_q975": 1482.8023104379065,
            "rating_q025": 1448.636729072137
        },
        "qwen3-vl-235b-a22b-thinking": {
            "rating": 1461.9451550406097,
            "rating_q975": 1497.3363834909374,
            "rating_q025": 1426.5539265902821
        },
        "deepseek-v3.1": {
            "rating": 1459.6752822819883,
            "rating_q975": 1478.0505617380832,
            "rating_q025": 1441.3000028258934
        },
        "deepseek-r1-0528": {
            "rating": 1456.6953185050545,
            "rating_q975": 1476.0935192342965,
            "rating_q025": 1437.2971177758125
        },
        "qwen3-235b-a22b-instruct-2507": {
            "rating": 1452.4726169765295,
            "rating_q975": 1466.9587608301815,
            "rating_q025": 1437.9864731228774
        },
        "gemini-2.5-flash": {
            "rating": 1451.7145936098652,
            "rating_q975": 1463.4843162986765,
            "rating_q025": 1439.944870921054
        },
        "chatgpt-4o-latest-20250326": {
            "rating": 1450.953473649308,
            "rating_q975": 1463.7544413581472,
            "rating_q025": 1438.152505940469
        },
        "claude-sonnet-4-5-20250929": {
            "rating": 1450.621142193106,
            "rating_q975": 1493.5186432544936,
            "rating_q025": 1407.7236411317183
        },
        "deepseek-v3.2-exp-thinking": {
            "rating": 1450.0200199625542,
            "rating_q975": 1485.0541110587299,
            "rating_q025": 1414.9859288663786
        },
        "mistral-medium-2508": {
            "rating": 1443.8900944151555,
            "rating_q975": 1459.6409039118569,
            "rating_q025": 1428.1392849184542
        },
        "grok-3-preview-02-24": {
            "rating": 1442.449973207167,
            "rating_q975": 1456.6740329662548,
            "rating_q025": 1428.2259134480792
        },
        "o3-2025-04-16": {
            "rating": 1435.5444945397585,
            "rating_q975": 1447.6651299450007,
            "rating_q025": 1423.4238591345163
        },
        "qwen3-max-2025-09-23": {
            "rating": 1432.9845040223397,
            "rating_q975": 1464.0385444336712,
            "rating_q025": 1401.9304636110082
        },
        "qwen3-30b-a3b-instruct-2507": {
            "rating": 1431.8701125053565,
            "rating_q975": 1448.7416007277193,
            "rating_q025": 1414.9986242829937
        },
        "grok-4-0709": {
            "rating": 1429.029669101273,
            "rating_q975": 1444.4863161395222,
            "rating_q025": 1413.5730220630237
        },
        "longcat-flash-chat": {
            "rating": 1425.9924976682673,
            "rating_q975": 1449.7396301159235,
            "rating_q025": 1402.2453652206111
        },
        "glm-4.5-air": {
            "rating": 1425.9791272149705,
            "rating_q975": 1442.2483126790914,
            "rating_q025": 1409.7099417508496
        },
        "hunyuan-t1-20250711": {
            "rating": 1425.7918306834258,
            "rating_q975": 1463.4107631722943,
            "rating_q025": 1388.1728981945573
        },
        "qwen3-235b-a22b-no-thinking": {
            "rating": 1424.9684286873471,
            "rating_q975": 1438.7691066549405,
            "rating_q025": 1411.1677507197537
        },
        "claude-sonnet-4-5-20250929-thinking-32k": {
            "rating": 1423.5196300964185,
            "rating_q975": 1453.7517399451797,
            "rating_q025": 1393.2875202476573
        },
        "gpt-5-high": {
            "rating": 1422.695892446626,
            "rating_q975": 1439.5447606880045,
            "rating_q025": 1405.8470242052474
        },
        "claude-opus-4-1-20250805": {
            "rating": 1417.720518075202,
            "rating_q975": 1431.6260849237403,
            "rating_q025": 1403.8149512266639
        },
        "gpt-4.5-preview-2025-02-27": {
            "rating": 1416.657203892116,
            "rating_q975": 1435.8151681869663,
            "rating_q025": 1397.4992395972658
        },
        "claude-haiku-4-5-20251001": {
            "rating": 1415.3741584902477,
            "rating_q975": 1446.5985802596217,
            "rating_q025": 1384.1497367208738
        },
        "gpt-5-chat": {
            "rating": 1412.3744740746313,
            "rating_q975": 1428.6373063956185,
            "rating_q025": 1396.111641753644
        },
        "hunyuan-turbos-20250416": {
            "rating": 1412.2970249130042,
            "rating_q975": 1439.080540069316,
            "rating_q025": 1385.5135097566924
        },
        "claude-opus-4-1-20250805-thinking-16k": {
            "rating": 1409.4341439769514,
            "rating_q975": 1425.9386647516421,
            "rating_q025": 1392.9296232022607
        },
        "qwen3-next-80b-a3b-thinking": {
            "rating": 1408.5956638367068,
            "rating_q975": 1430.5642120470534,
            "rating_q025": 1386.6271156263601
        },
        "ling-flash-2.0": {
            "rating": 1407.8181617643663,
            "rating_q975": 1440.908417109427,
            "rating_q025": 1374.7279064193056
        },
        "gemini-2.5-flash-lite-preview-09-2025-no-thinking": {
            "rating": 1400.8857442370731,
            "rating_q975": 1428.244067884385,
            "rating_q025": 1373.5274205897613
        },
        "kimi-k2-0905-preview": {
            "rating": 1400.4771780226222,
            "rating_q975": 1423.501105758325,
            "rating_q025": 1377.4532502869195
        },
        "kimi-k2-0711-preview": {
            "rating": 1399.427981289876,
            "rating_q975": 1415.170703065491,
            "rating_q025": 1383.6852595142611
        },
        "ring-flash-2.0": {
            "rating": 1399.3614936509596,
            "rating_q975": 1430.8807443027315,
            "rating_q025": 1367.8422429991876
        },
        "gemini-2.5-flash-lite-preview-06-17-thinking": {
            "rating": 1395.8014021923098,
            "rating_q975": 1410.459701915078,
            "rating_q025": 1381.1431024695414
        },
        "deepseek-r1": {
            "rating": 1395.7740763583,
            "rating_q975": 1413.3629266396474,
            "rating_q025": 1378.1852260769524
        },
        "mai-1-preview": {
            "rating": 1393.1142028399402,
            "rating_q975": 1411.862839782591,
            "rating_q025": 1374.3655658972893
        },
        "o1-2024-12-17": {
            "rating": 1392.606349395722,
            "rating_q975": 1406.5591882878273,
            "rating_q025": 1378.6535105036166
        },
        "step-3": {
            "rating": 1391.5438181160712,
            "rating_q975": 1429.3944166130118,
            "rating_q025": 1353.6932196191306
        },
        "gpt-5-mini-high": {
            "rating": 1391.0977336164244,
            "rating_q975": 1409.0502923246618,
            "rating_q025": 1373.145174908187
        },
        "grok-3-mini-high": {
            "rating": 1388.0868704759396,
            "rating_q975": 1410.413175889182,
            "rating_q025": 1365.7605650626972
        },
        "glm-4-plus-0111": {
            "rating": 1386.5242130788013,
            "rating_q975": 1416.2859860555257,
            "rating_q025": 1356.7624401020769
        },
        "deepseek-v3-0324": {
            "rating": 1385.4492747088284,
            "rating_q975": 1397.7619730906868,
            "rating_q025": 1373.13657632697
        },
        "claude-opus-4-20250514-thinking-16k": {
            "rating": 1383.775919129246,
            "rating_q975": 1398.0958396009712,
            "rating_q025": 1369.4559986575207
        },
        "claude-opus-4-20250514": {
            "rating": 1382.7808180424852,
            "rating_q975": 1395.546340216652,
            "rating_q025": 1370.0152958683184
        },
        "qwen3-235b-a22b": {
            "rating": 1377.838545821795,
            "rating_q975": 1394.4588526765956,
            "rating_q025": 1361.2182389669942
        },
        "amazon-nova-experimental-chat-10-09": {
            "rating": 1377.2856290512275,
            "rating_q975": 1414.303377731314,
            "rating_q025": 1340.267880371141
        },
        "qwen2.5-max": {
            "rating": 1375.844189042004,
            "rating_q975": 1388.6155786861575,
            "rating_q025": 1363.0727993978505
        },
        "o3-mini-high": {
            "rating": 1374.9794638721814,
            "rating_q975": 1391.9358800650969,
            "rating_q025": 1358.023047679266
        },
        "grok-3-mini-beta": {
            "rating": 1374.707797219935,
            "rating_q975": 1392.7128526257497,
            "rating_q025": 1356.7027418141201
        },
        "mistral-medium-2505": {
            "rating": 1373.7659911229748,
            "rating_q975": 1388.2870625747003,
            "rating_q025": 1359.2449196712494
        },
        "qwq-32b": {
            "rating": 1373.416710735476,
            "rating_q975": 1389.162928553216,
            "rating_q025": 1357.670492917736
        },
        "gpt-4.1-2025-04-14": {
            "rating": 1373.313098056216,
            "rating_q975": 1386.196320183045,
            "rating_q025": 1360.429875929387
        },
        "step-1o-turbo-202506": {
            "rating": 1365.9453613414428,
            "rating_q975": 1392.237731921292,
            "rating_q025": 1339.6529907615936
        },
        "gpt-oss-120b": {
            "rating": 1364.5299571990386,
            "rating_q975": 1380.8159766969527,
            "rating_q025": 1348.2439377011244
        },
        "minimax-m1": {
            "rating": 1357.5619714749344,
            "rating_q975": 1371.8761310138468,
            "rating_q025": 1343.247811936022
        },
        "qwen3-30b-a3b": {
            "rating": 1354.844653723556,
            "rating_q975": 1371.465333992664,
            "rating_q025": 1338.2239734544478
        },
        "qwen3-32b": {
            "rating": 1352.8141089974647,
            "rating_q975": 1390.6370193554749,
            "rating_q025": 1314.9911986394545
        },
        "gpt-5-nano-high": {
            "rating": 1352.3595246140076,
            "rating_q975": 1382.0115925993032,
            "rating_q025": 1322.707456628712
        },
        "hunyuan-turbo-0110": {
            "rating": 1352.1416895681316,
            "rating_q975": 1391.7534943826793,
            "rating_q025": 1312.529884753584
        },
        "qwen3-coder-480b-a35b-instruct": {
            "rating": 1351.8986776637776,
            "rating_q975": 1369.608094718305,
            "rating_q025": 1334.1892606092501
        },
        "claude-sonnet-4-20250514-thinking-32k": {
            "rating": 1349.7526986953771,
            "rating_q975": 1364.222036954063,
            "rating_q025": 1335.2833604366913
        },
        "o4-mini-2025-04-16": {
            "rating": 1347.5472605574512,
            "rating_q975": 1360.4799962033876,
            "rating_q025": 1334.6145249115148
        },
        "qwen-plus-0125": {
            "rating": 1344.6205424363484,
            "rating_q975": 1371.9672335337234,
            "rating_q025": 1317.2738513389734
        },
        "hunyuan-large-2025-02-10": {
            "rating": 1341.450248913911,
            "rating_q975": 1373.9647000426348,
            "rating_q025": 1308.9357977851873
        },
        "gemma-3-27b-it": {
            "rating": 1340.834315383929,
            "rating_q975": 1353.4839872902387,
            "rating_q025": 1328.1846434776191
        },
        "claude-sonnet-4-20250514": {
            "rating": 1336.6319214277469,
            "rating_q975": 1350.0340049996405,
            "rating_q025": 1323.2298378558532
        },
        "deepseek-v3": {
            "rating": 1335.5578622382861,
            "rating_q975": 1350.447799876106,
            "rating_q025": 1320.6679246004662
        },
        "gemini-2.0-flash-lite-preview-02-05": {
            "rating": 1335.5412083783028,
            "rating_q975": 1350.0648012683826,
            "rating_q025": 1321.017615488223
        },
        "mistral-small-2506": {
            "rating": 1334.33833022841,
            "rating_q975": 1353.9415374220182,
            "rating_q025": 1314.735123034802
        },
        "gpt-4.1-mini-2025-04-14": {
            "rating": 1329.8645185852208,
            "rating_q975": 1343.5121452719657,
            "rating_q025": 1316.216891898476
        },
        "gemini-1.5-pro-002": {
            "rating": 1328.1092194967832,
            "rating_q975": 1337.110208255737,
            "rating_q025": 1319.1082307378294
        },
        "step-2-16k-exp-202412": {
            "rating": 1326.5681995920127,
            "rating_q975": 1358.8525229752513,
            "rating_q025": 1294.283876208774
        },
        "glm-4.5v": {
            "rating": 1325.4098572031264,
            "rating_q975": 1368.402799499604,
            "rating_q025": 1282.4169149066488
        },
        "o3-mini": {
            "rating": 1325.233253706546,
            "rating_q975": 1335.6410597788242,
            "rating_q025": 1314.825447634268
        },
        "hunyuan-turbos-20250226": {
            "rating": 1323.7898964096385,
            "rating_q975": 1363.2203967620712,
            "rating_q025": 1284.3593960572057
        },
        "o1-preview": {
            "rating": 1322.904992470029,
            "rating_q975": 1334.6491453527476,
            "rating_q025": 1311.1608395873102
        },
        "command-a-03-2025": {
            "rating": 1319.9353146779642,
            "rating_q975": 1331.7665335204897,
            "rating_q025": 1308.1040958354388
        },
        "hunyuan-standard-2025-02-10": {
            "rating": 1316.7886487496173,
            "rating_q975": 1347.7765801756973,
            "rating_q025": 1285.8007173235374
        },
        "yi-lightning": {
            "rating": 1314.8409470090062,
            "rating_q975": 1326.355322670268,
            "rating_q025": 1303.3265713477444
        },
        "deepseek-v2.5-1210": {
            "rating": 1314.6477964602043,
            "rating_q975": 1340.3558127619237,
            "rating_q025": 1288.9397801584848
        },
        "gpt-oss-20b": {
            "rating": 1313.289701142698,
            "rating_q975": 1339.9648631407035,
            "rating_q025": 1286.6145391446926
        },
        "o1-mini": {
            "rating": 1311.0920212242406,
            "rating_q975": 1320.381679276922,
            "rating_q025": 1301.8023631715594
        },
        "qwen2.5-plus-1127": {
            "rating": 1308.9076384635528,
            "rating_q975": 1331.1087538085521,
            "rating_q025": 1286.7065231185534
        },
        "claude-3-7-sonnet-20250219-thinking-32k": {
            "rating": 1306.1193610586513,
            "rating_q975": 1319.849476293149,
            "rating_q025": 1292.3892458241535
        },
        "gemma-3n-e4b-it": {
            "rating": 1300.5828940835045,
            "rating_q975": 1318.2944587349994,
            "rating_q025": 1282.8713294320096
        },
        "athene-v2-chat": {
            "rating": 1299.6241009309067,
            "rating_q975": 1312.9606783579902,
            "rating_q025": 1286.2875235038232
        },
        "glm-4-plus": {
            "rating": 1291.5685508264428,
            "rating_q975": 1303.7450792760321,
            "rating_q025": 1279.3920223768534
        },
        "gemini-1.5-flash-002": {
            "rating": 1291.5603467775975,
            "rating_q975": 1302.2056245389997,
            "rating_q025": 1280.9150690161953
        },
        "grok-2-2024-08-13": {
            "rating": 1286.408387781235,
            "rating_q975": 1294.9256789936303,
            "rating_q025": 1277.8910965688397
        },
        "deepseek-v2.5": {
            "rating": 1279.0091100086443,
            "rating_q975": 1291.3039966341048,
            "rating_q025": 1266.7142233831837
        },
        "llama-3.3-nemotron-49b-super-v1": {
            "rating": 1277.157428091518,
            "rating_q975": 1316.3283134572462,
            "rating_q025": 1237.98654272579
        },
        "gpt-4o-2024-05-13": {
            "rating": 1274.446219574254,
            "rating_q975": 1281.9664070755548,
            "rating_q025": 1266.9260320729531
        },
        "llama-4-maverick-17b-128e-instruct": {
            "rating": 1273.0773142990183,
            "rating_q975": 1286.6061421575498,
            "rating_q025": 1259.5484864404868
        },
        "gemini-1.5-pro-001": {
            "rating": 1271.912023154248,
            "rating_q975": 1280.786682999998,
            "rating_q025": 1263.0373633084978
        },
        "gemini-advanced-0514": {
            "rating": 1271.890647110174,
            "rating_q975": 1282.2411946297839,
            "rating_q025": 1261.5400995905643
        },
        "qwen2.5-72b-instruct": {
            "rating": 1269.5273847921958,
            "rating_q975": 1279.6790765726141,
            "rating_q025": 1259.3756930117775
        },
        "claude-3-5-sonnet-20241022": {
            "rating": 1268.8168407181997,
            "rating_q975": 1276.3651060535517,
            "rating_q025": 1261.2685753828478
        },
        "hunyuan-large-vision": {
            "rating": 1268.3576968863172,
            "rating_q975": 1306.723790000588,
            "rating_q025": 1229.9916037720463
        },
        "gpt-4.1-nano-2025-04-14": {
            "rating": 1265.094554716798,
            "rating_q975": 1301.4337114247141,
            "rating_q025": 1228.755398008882
        },
        "claude-3-5-sonnet-20240620": {
            "rating": 1261.8966429644468,
            "rating_q975": 1270.140555672149,
            "rating_q025": 1253.6527302567445
        },
        "gpt-4o-mini-2024-07-18": {
            "rating": 1261.2545120534674,
            "rating_q975": 1269.392494534525,
            "rating_q025": 1253.1165295724097
        },
        "llama-3.1-nemotron-70b-instruct": {
            "rating": 1260.378988218174,
            "rating_q975": 1281.2147325586757,
            "rating_q025": 1239.5432438776725
        },
        "grok-2-mini-2024-08-13": {
            "rating": 1259.437593654547,
            "rating_q975": 1268.487665376608,
            "rating_q025": 1250.3875219324862
        },
        "gpt-4o-2024-08-06": {
            "rating": 1251.4592495432194,
            "rating_q975": 1261.266935102733,
            "rating_q025": 1241.6515639837057
        },
        "qwen-max-0919": {
            "rating": 1250.7484376240704,
            "rating_q975": 1265.7552749982087,
            "rating_q025": 1235.7416002499322
        },
        "llama-4-scout-17b-16e-instruct": {
            "rating": 1248.0296842050966,
            "rating_q975": 1263.9243026081729,
            "rating_q025": 1232.1350658020203
        },
        "mistral-small-3.1-24b-instruct-2503": {
            "rating": 1247.5751099147271,
            "rating_q975": 1263.2034680388324,
            "rating_q025": 1231.9467517906219
        },
        "llama-3.1-tulu-3-70b": {
            "rating": 1246.138970280428,
            "rating_q975": 1281.9710763316923,
            "rating_q025": 1210.306864229164
        },
        "claude-3-opus-20240229": {
            "rating": 1245.1400200063358,
            "rating_q975": 1251.8532016623196,
            "rating_q025": 1238.426838350352
        },
        "amazon-nova-pro-v1.0": {
            "rating": 1241.3196187687427,
            "rating_q975": 1255.0763633017966,
            "rating_q025": 1227.5628742356887
        },
        "llama-3.1-405b-instruct-bf16": {
            "rating": 1239.9368788785184,
            "rating_q975": 1250.204524644514,
            "rating_q025": 1229.6692331125228
        },
        "gpt-4-turbo-2024-04-09": {
            "rating": 1239.5677353564088,
            "rating_q975": 1247.9396861832467,
            "rating_q025": 1231.1957845295708
        },
        "gpt-4-1106-preview": {
            "rating": 1239.1978708153738,
            "rating_q975": 1248.1530841820027,
            "rating_q025": 1230.242657448745
        },
        "reka-core-20240904": {
            "rating": 1239.1057040329993,
            "rating_q975": 1261.735794163513,
            "rating_q025": 1216.4756139024855
        },
        "mistral-large-2411": {
            "rating": 1237.7178920379572,
            "rating_q975": 1250.592695908874,
            "rating_q025": 1224.8430881670404
        },
        "hunyuan-standard-256k": {
            "rating": 1237.6862525166098,
            "rating_q975": 1271.439731599039,
            "rating_q025": 1203.9327734341805
        },
        "mistral-large-2407": {
            "rating": 1237.5022344635408,
            "rating_q975": 1247.2327367371124,
            "rating_q025": 1227.7717321899693
        },
        "qwen2-72b-instruct": {
            "rating": 1235.9533691899767,
            "rating_q975": 1246.6491984700103,
            "rating_q025": 1225.257539909943
        },
        "gpt-4-0125-preview": {
            "rating": 1234.0268386778203,
            "rating_q975": 1242.771926302027,
            "rating_q025": 1225.2817510536136
        },
        "athene-70b-0725": {
            "rating": 1233.9800493150751,
            "rating_q975": 1247.958637147916,
            "rating_q025": 1220.0014614822342
        },
        "llama-3.1-405b-instruct-fp8": {
            "rating": 1231.562836923045,
            "rating_q975": 1240.2693534251578,
            "rating_q025": 1222.8563204209324
        },
        "gemini-1.5-flash-001": {
            "rating": 1231.0416420954434,
            "rating_q975": 1240.2350675747136,
            "rating_q025": 1221.8482166161732
        },
        "gemini-1.5-flash-8b-001": {
            "rating": 1228.4785834154395,
            "rating_q975": 1239.3316759985141,
            "rating_q025": 1217.625490832365
        },
        "glm-4-0520": {
            "rating": 1226.6520709145816,
            "rating_q975": 1242.9885908842211,
            "rating_q025": 1210.315550944942
        },
        "command-r-plus-08-2024": {
            "rating": 1223.851439043999,
            "rating_q975": 1242.9950704231144,
            "rating_q025": 1204.7078076648838
        },
        "gemma-2-9b-it-simpo": {
            "rating": 1222.939570539951,
            "rating_q975": 1243.4395776921488,
            "rating_q025": 1202.4395633877534
        },
        "amazon-nova-lite-v1.0": {
            "rating": 1222.9111777411117,
            "rating_q975": 1238.4124804805697,
            "rating_q025": 1207.4098750016537
        },
        "claude-3-5-haiku-20241022": {
            "rating": 1222.531625246601,
            "rating_q975": 1232.046397593746,
            "rating_q025": 1213.016852899456
        },
        "magistral-medium-2506": {
            "rating": 1220.6686944978817,
            "rating_q975": 1248.4389931004039,
            "rating_q025": 1192.8983958953595
        },
        "gemma-2-27b-it": {
            "rating": 1218.4565352750694,
            "rating_q975": 1226.168889923118,
            "rating_q025": 1210.7441806270208
        },
        "qwen2.5-coder-32b-instruct": {
            "rating": 1217.9930977403048,
            "rating_q975": 1242.0757773703522,
            "rating_q025": 1193.9104181102575
        },
        "reka-flash-20240904": {
            "rating": 1217.446456965688,
            "rating_q975": 1240.2775374850094,
            "rating_q025": 1194.6153764463666
        },
        "qwq-32b-preview": {
            "rating": 1215.6330841099125,
            "rating_q975": 1256.2515925178168,
            "rating_q025": 1175.0145757020082
        },
        "llama-3.3-70b-instruct": {
            "rating": 1214.5374869155587,
            "rating_q975": 1224.9181176923817,
            "rating_q025": 1204.1568561387357
        },
        "llama-3.1-70b-instruct": {
            "rating": 1212.510001717229,
            "rating_q975": 1221.3763102938726,
            "rating_q025": 1203.6436931405854
        },
        "phi-4": {
            "rating": 1210.5061404631015,
            "rating_q975": 1225.5418689150683,
            "rating_q025": 1195.4704120111346
        },
        "yi-1.5-34b-chat": {
            "rating": 1209.6695786152059,
            "rating_q975": 1221.735302696778,
            "rating_q025": 1197.6038545336337
        },
        "nemotron-4-340b-instruct": {
            "rating": 1209.3534182621988,
            "rating_q975": 1221.8477857070914,
            "rating_q025": 1196.8590508173063
        },
        "amazon-nova-micro-v1.0": {
            "rating": 1209.1645256973006,
            "rating_q975": 1224.8334708271352,
            "rating_q025": 1193.495580567466
        },
        "c4ai-aya-expanse-32b": {
            "rating": 1207.683613388467,
            "rating_q975": 1219.4213836376155,
            "rating_q025": 1195.9458431393184
        },
        "qwen1.5-110b-chat": {
            "rating": 1201.9313456708303,
            "rating_q975": 1214.4423932153472,
            "rating_q025": 1189.4202981263134
        },
        "mistral-small-24b-instruct-2501": {
            "rating": 1201.6030877665157,
            "rating_q975": 1218.9057758592955,
            "rating_q025": 1184.300399673736
        },
        "jamba-1.5-large": {
            "rating": 1199.5120830175147,
            "rating_q975": 1220.9540122484018,
            "rating_q025": 1178.0701537866275
        },
        "internlm2_5-20b-chat": {
            "rating": 1198.680226439531,
            "rating_q975": 1216.8094446997782,
            "rating_q025": 1180.5510081792838
        },
        "deepseek-coder-v2": {
            "rating": 1198.5004178897166,
            "rating_q975": 1212.9575526721283,
            "rating_q025": 1184.043283107305
        },
        "olmo-2-0325-32b-instruct": {
            "rating": 1191.7709279229189,
            "rating_q975": 1227.4600996856325,
            "rating_q025": 1156.0817561602053
        },
        "ministral-8b-2410": {
            "rating": 1190.9643555399873,
            "rating_q975": 1215.8998822489134,
            "rating_q025": 1166.0288288310612
        },
        "command-r-plus": {
            "rating": 1189.8404440948307,
            "rating_q975": 1198.6212557887259,
            "rating_q025": 1181.0596324009355
        },
        "claude-3-sonnet-20240229": {
            "rating": 1186.3782887815296,
            "rating_q975": 1194.570746938366,
            "rating_q025": 1178.1858306246932
        },
        "qwen1.5-72b-chat": {
            "rating": 1183.790107926314,
            "rating_q975": 1195.253943268504,
            "rating_q025": 1172.3262725841241
        },
        "gemma-2-9b-it": {
            "rating": 1182.3319290213753,
            "rating_q975": 1191.099410197549,
            "rating_q025": 1173.5644478452016
        },
        "gpt-4-0314": {
            "rating": 1181.5922233310075,
            "rating_q975": 1192.5093646141283,
            "rating_q025": 1170.6750820478867
        },
        "command-r-08-2024": {
            "rating": 1180.2716608038486,
            "rating_q975": 1199.7220653004256,
            "rating_q025": 1160.8212563072716
        },
        "c4ai-aya-expanse-8b": {
            "rating": 1178.5409317442727,
            "rating_q975": 1201.4362803654906,
            "rating_q025": 1155.6455831230548
        },
        "llama-3.1-nemotron-51b-instruct": {
            "rating": 1177.556893943376,
            "rating_q975": 1205.1330338305036,
            "rating_q025": 1149.9807540562485
        },
        "qwen1.5-32b-chat": {
            "rating": 1175.0170443200977,
            "rating_q975": 1187.5598553663351,
            "rating_q025": 1162.4742332738604
        },
        "yi-34b-chat": {
            "rating": 1173.9160601247027,
            "rating_q975": 1191.4912631786997,
            "rating_q025": 1156.3408570707056
        },
        "llama-3.1-tulu-3-8b": {
            "rating": 1172.9944905882642,
            "rating_q975": 1209.2913846248325,
            "rating_q025": 1136.6975965516958
        },
        "claude-3-haiku-20240307": {
            "rating": 1152.997560068261,
            "rating_q975": 1160.768542251018,
            "rating_q025": 1145.226577885504
        },
        "llama-3.1-8b-instruct": {
            "rating": 1148.7516487477837,
            "rating_q975": 1158.299239525006,
            "rating_q025": 1139.2040579705615
        },
        "qwen1.5-14b-chat": {
            "rating": 1147.1123313089802,
            "rating_q975": 1160.3045508708876,
            "rating_q025": 1133.9201117470727
        },
        "command-r": {
            "rating": 1145.3720799816654,
            "rating_q975": 1155.1779508404788,
            "rating_q025": 1135.566209122852
        },
        "granite-3.1-8b-instruct": {
            "rating": 1142.274630053059,
            "rating_q975": 1181.2616818743438,
            "rating_q025": 1103.287578231774
        },
        "reka-flash-21b-20240226-online": {
            "rating": 1140.805626947023,
            "rating_q975": 1155.3846505973154,
            "rating_q025": 1126.2266032967307
        },
        "qwen1.5-7b-chat": {
            "rating": 1136.417158822665,
            "rating_q975": 1164.4834422245365,
            "rating_q025": 1108.3508754207935
        },
        "granite-3.1-2b-instruct": {
            "rating": 1136.218346389519,
            "rating_q975": 1174.1122278817847,
            "rating_q025": 1098.3244648972532
        },
        "jamba-1.5-mini": {
            "rating": 1133.7022730899303,
            "rating_q975": 1154.7224642153592,
            "rating_q025": 1112.6820819645013
        },
        "gpt-4-0613": {
            "rating": 1133.2303117322936,
            "rating_q975": 1142.6806549821517,
            "rating_q025": 1123.7799684824354
        },
        "reka-flash-21b-20240226": {
            "rating": 1132.841393588559,
            "rating_q975": 1145.6213195846444,
            "rating_q025": 1120.0614675924735
        },
        "gemma-2-2b-it": {
            "rating": 1130.2513935833645,
            "rating_q975": 1140.2633961803924,
            "rating_q025": 1120.2393909863365
        },
        "deepseek-llm-67b-chat": {
            "rating": 1128.1766068926931,
            "rating_q975": 1168.0441101665851,
            "rating_q025": 1088.3091036188011
        },
        "gemini-pro-dev-api": {
            "rating": 1120.970824269917,
            "rating_q975": 1137.7365291486421,
            "rating_q025": 1104.205119391192
        },
        "mistral-large-2402": {
            "rating": 1117.7967223422359,
            "rating_q975": 1127.547599887932,
            "rating_q025": 1108.0458447965398
        },
        "mixtral-8x22b-instruct-v0.1": {
            "rating": 1114.7260083258634,
            "rating_q975": 1124.9251072939521,
            "rating_q025": 1104.5269093577747
        },
        "llama-3-70b-instruct": {
            "rating": 1113.5204056533235,
            "rating_q975": 1121.549413484811,
            "rating_q025": 1105.4913978218358
        },
        "starling-lm-7b-beta": {
            "rating": 1112.6776104053306,
            "rating_q975": 1126.8274379980433,
            "rating_q025": 1098.527782812618
        },
        "mistral-medium": {
            "rating": 1108.7763612087547,
            "rating_q975": 1121.5585963401952,
            "rating_q025": 1095.9941260773141
        },
        "phi-3-medium-4k-instruct": {
            "rating": 1105.919734791343,
            "rating_q975": 1117.9875313501614,
            "rating_q025": 1093.8519382325246
        },
        "gemini-pro": {
            "rating": 1095.4644454460326,
            "rating_q975": 1132.9536154782236,
            "rating_q025": 1057.9752754138417
        },
        "zephyr-orpo-141b-A35b-v0.1": {
            "rating": 1081.7543474428903,
            "rating_q975": 1104.3606444272202,
            "rating_q025": 1059.1480504585604
        },
        "openchat-3.5-0106": {
            "rating": 1081.4309112160229,
            "rating_q975": 1098.3013742433711,
            "rating_q025": 1064.5604481886746
        },
        "gpt-3.5-turbo-0125": {
            "rating": 1074.6261693430715,
            "rating_q975": 1084.0125143769792,
            "rating_q025": 1065.2398243091639
        },
        "llama-3-8b-instruct": {
            "rating": 1074.5506220437833,
            "rating_q975": 1083.3001425093792,
            "rating_q025": 1065.8011015781874
        },
        "qwen-14b-chat": {
            "rating": 1073.5132181647705,
            "rating_q975": 1117.1501565383242,
            "rating_q025": 1029.8762797912168
        },
        "chatglm-6b": {
            "rating": 1072.2887595849575,
            "rating_q975": 1111.5933029656453,
            "rating_q025": 1032.9842162042696
        },
        "openchat-3.5": {
            "rating": 1070.729928727317,
            "rating_q975": 1102.6113257978748,
            "rating_q025": 1038.8485316567592
        },
        "dbrx-instruct-preview": {
            "rating": 1067.7196421564875,
            "rating_q975": 1080.0349530979497,
            "rating_q025": 1055.4043312150252
        },
        "granite-3.0-8b-instruct": {
            "rating": 1066.6954782339426,
            "rating_q975": 1089.4109599036663,
            "rating_q025": 1043.979996564219
        },
        "snowflake-arctic-instruct": {
            "rating": 1066.2694135537054,
            "rating_q975": 1079.2330601904366,
            "rating_q025": 1053.305766916974
        },
        "granite-3.0-2b-instruct": {
            "rating": 1066.0422840344986,
            "rating_q975": 1088.443612389693,
            "rating_q025": 1043.6409556793042
        },
        "chatglm3-6b": {
            "rating": 1061.9892771908696,
            "rating_q975": 1104.978769838244,
            "rating_q025": 1018.9997845434953
        },
        "gemma-1.1-7b-it": {
            "rating": 1059.4582148191448,
            "rating_q975": 1071.1640998721537,
            "rating_q025": 1047.752329766136
        },
        "phi-3-small-8k-instruct": {
            "rating": 1059.3295807743527,
            "rating_q975": 1072.585294648331,
            "rating_q025": 1046.0738669003745
        },
        "wizardlm-70b": {
            "rating": 1057.6524840129166,
            "rating_q975": 1089.7112983593759,
            "rating_q025": 1025.5936696664573
        },
        "mixtral-8x7b-instruct-v0.1": {
            "rating": 1054.3984280133811,
            "rating_q975": 1063.9244010097677,
            "rating_q025": 1044.8724550169945
        },
        "starling-lm-7b-alpha": {
            "rating": 1043.4626419303518,
            "rating_q975": 1064.7183116912515,
            "rating_q025": 1022.2069721694521
        },
        "vicuna-13b": {
            "rating": 1037.168524669161,
            "rating_q975": 1056.0091302970754,
            "rating_q025": 1018.3279190412464
        },
        "gemma-7b-it": {
            "rating": 1035.8628577232075,
            "rating_q975": 1055.053033615821,
            "rating_q025": 1016.6726818305939
        },
        "vicuna-33b": {
            "rating": 1035.5459743611978,
            "rating_q975": 1052.1512632545014,
            "rating_q025": 1018.9406854678942
        },
        "phi-3-mini-4k-instruct-june-2024": {
            "rating": 1032.2970370351695,
            "rating_q975": 1049.5610356053658,
            "rating_q025": 1015.0330384649733
        },
        "qwen1.5-4b-chat": {
            "rating": 1022.2831789945786,
            "rating_q975": 1041.6462238639942,
            "rating_q025": 1002.920134125163
        },
        "wizardlm-13b": {
            "rating": 1021.830695258936,
            "rating_q975": 1054.6890721942586,
            "rating_q025": 988.9723183236134
        },
        "phi-3-mini-4k-instruct": {
            "rating": 1021.1915014671417,
            "rating_q975": 1034.8598057770014,
            "rating_q025": 1007.523197157282
        },
        "llama-3.2-3b-instruct": {
            "rating": 1018.671551586822,
            "rating_q975": 1042.4780097282578,
            "rating_q025": 994.8650934453864
        },
        "phi-3-mini-128k-instruct": {
            "rating": 1017.6083084550794,
            "rating_q975": 1032.7642575233965,
            "rating_q025": 1002.4523593867623
        },
        "gpt-3.5-turbo-1106": {
            "rating": 1014.2900088568688,
            "rating_q975": 1038.6397597168104,
            "rating_q025": 989.9402579969272
        },
        "olmo-7b-instruct": {
            "rating": 1012.2116872530148,
            "rating_q975": 1034.9584280891652,
            "rating_q025": 989.4649464168644
        },
        "gemma-1.1-2b-it": {
            "rating": 1012.1301821677314,
            "rating_q975": 1029.432151239455,
            "rating_q025": 994.8282130960079
        },
        "openhermes-2.5-mistral-7b": {
            "rating": 1011.10110319089,
            "rating_q975": 1053.5590973586268,
            "rating_q025": 968.643109023153
        },
        "mistral-7b-instruct-v0.2": {
            "rating": 1008.5530240723774,
            "rating_q975": 1023.0159557429876,
            "rating_q025": 994.0900924017673
        },
        "tulu-2-dpo-70b": {
            "rating": 1006.9848861137647,
            "rating_q975": 1042.5002005027454,
            "rating_q025": 971.4695717247838
        },
        "llama-2-13b-chat": {
            "rating": 998.6552501134238,
            "rating_q975": 1016.9238597240236,
            "rating_q025": 980.386640502824
        },
        "llama-2-70b-chat": {
            "rating": 993.5893452431033,
            "rating_q975": 1006.2442201454271,
            "rating_q025": 980.9344703407794
        },
        "gemma-2b-it": {
            "rating": 986.3235802543688,
            "rating_q975": 1011.235598991353,
            "rating_q025": 961.4115615173847
        },
        "vicuna-7b": {
            "rating": 977.3148636827639,
            "rating_q975": 1010.1893634390748,
            "rating_q025": 944.440363926453
        },
        "codellama-34b-instruct": {
            "rating": 973.6036925269452,
            "rating_q975": 1011.2704139599703,
            "rating_q025": 935.9369710939202
        },
        "llama-2-7b-chat": {
            "rating": 973.2859406981702,
            "rating_q975": 992.4628399961485,
            "rating_q025": 954.1090414001918
        },
        "zephyr-7b-beta": {
            "rating": 962.1970060251394,
            "rating_q975": 992.492228655508,
            "rating_q025": 931.9017833947709
        },
        "mpt-7b-chat": {
            "rating": 958.6830674958429,
            "rating_q975": 1000.1213678738035,
            "rating_q025": 917.2447671178824
        },
        "llama-3.2-1b-instruct": {
            "rating": 957.8775214840621,
            "rating_q975": 983.8288140081942,
            "rating_q025": 931.92622895993
        },
        "mistral-7b-instruct": {
            "rating": 936.388104001907,
            "rating_q975": 969.2036168494714,
            "rating_q025": 903.5725911543426
        },
        "RWKV-4-Raven-14B": {
            "rating": 901.0498086681005,
            "rating_q975": 940.0317560183081,
            "rating_q025": 862.0678613178928
        },
        "palm-2": {
            "rating": 886.7243534238835,
            "rating_q975": 923.3680092491738,
            "rating_q025": 850.0806975985931
        },
        "koala-13b": {
            "rating": 873.8598985667413,
            "rating_q975": 905.5570984244993,
            "rating_q025": 842.1626987089834
        },
        "dolly-v2-12b": {
            "rating": 828.6350671535163,
            "rating_q975": 873.2783870334837,
            "rating_q025": 783.9917472735489
        },
        "oasst-pythia-12b": {
            "rating": 798.0737363805747,
            "rating_q975": 831.6050897258524,
            "rating_q025": 764.542383035297
        },
        "alpaca-13b": {
            "rating": 778.8806999164633,
            "rating_q975": 817.8785621049508,
            "rating_q025": 739.8828377279758
        },
        "fastchat-t5-3b": {
            "rating": 705.3788930369797,
            "rating_q975": 744.3923227102403,
            "rating_q025": 666.3654633637191
        }
    },
    "coding": {
        "claude-sonnet-4-5-20250929-thinking-32k": {
            "rating": 1497.060418364636,
            "rating_q975": 1508.9610633498023,
            "rating_q025": 1485.1597733794697
        },
        "claude-opus-4-1-20250805-thinking-16k": {
            "rating": 1485.8248140954274,
            "rating_q975": 1494.5967732926524,
            "rating_q025": 1477.0528548982024
        },
        "claude-opus-4-1-20250805": {
            "rating": 1472.0096521669507,
            "rating_q975": 1479.7787961289166,
            "rating_q025": 1464.2405082049847
        },
        "longcat-flash-chat": {
            "rating": 1468.1178621768129,
            "rating_q975": 1480.8044195313214,
            "rating_q025": 1455.4313048223044
        },
        "glm-4.6": {
            "rating": 1465.4333635420564,
            "rating_q975": 1478.4109367629449,
            "rating_q025": 1452.455790321168
        },
        "gemini-2.5-pro": {
            "rating": 1459.899856476776,
            "rating_q975": 1466.684225304016,
            "rating_q025": 1453.115487649536
        },
        "qwen3-max-preview": {
            "rating": 1459.7787121887393,
            "rating_q975": 1468.9392032027163,
            "rating_q025": 1450.6182211747623
        },
        "claude-haiku-4-5-20251001": {
            "rating": 1458.1874688715359,
            "rating_q975": 1470.8529724692555,
            "rating_q025": 1445.5219652738162
        },
        "claude-sonnet-4-5-20250929": {
            "rating": 1453.3511448311056,
            "rating_q975": 1469.5493667838793,
            "rating_q025": 1437.1529228783318
        },
        "qwen3-next-80b-a3b-instruct": {
            "rating": 1447.9734271444818,
            "rating_q975": 1457.5706411922652,
            "rating_q025": 1438.3762130966984
        },
        "qwen3-vl-235b-a22b-instruct": {
            "rating": 1441.7094583894848,
            "rating_q975": 1455.4219403118036,
            "rating_q025": 1427.996976467166
        },
        "qwen3-235b-a22b-instruct-2507": {
            "rating": 1441.704643654977,
            "rating_q975": 1449.4817024273793,
            "rating_q025": 1433.9275848825746
        },
        "claude-opus-4-20250514-thinking-16k": {
            "rating": 1441.226373389351,
            "rating_q975": 1449.2426784415409,
            "rating_q025": 1433.2100683371611
        },
        "qwen3-max-2025-09-23": {
            "rating": 1440.7062619337232,
            "rating_q975": 1453.705152510014,
            "rating_q025": 1427.7073713574325
        },
        "gpt-5-high": {
            "rating": 1440.4555141014998,
            "rating_q975": 1448.9843251800035,
            "rating_q025": 1431.9267030229962
        },
        "deepseek-v3.2-exp-thinking": {
            "rating": 1436.825431126701,
            "rating_q975": 1450.2639314319322,
            "rating_q025": 1423.3869308214698
        },
        "glm-4.5": {
            "rating": 1434.8677485242335,
            "rating_q975": 1443.806145451783,
            "rating_q025": 1425.929351596684
        },
        "mistral-medium-2508": {
            "rating": 1431.9147594787967,
            "rating_q975": 1440.125937788662,
            "rating_q025": 1423.7035811689314
        },
        "grok-3-preview-02-24": {
            "rating": 1431.6387255523425,
            "rating_q975": 1439.9140171995655,
            "rating_q025": 1423.3634339051196
        },
        "qwen3-vl-235b-a22b-thinking": {
            "rating": 1427.8449621362122,
            "rating_q975": 1442.268043589857,
            "rating_q025": 1413.4218806825675
        },
        "grok-4-fast": {
            "rating": 1426.792886595251,
            "rating_q975": 1443.2114145178534,
            "rating_q025": 1410.3743586726487
        },
        "deepseek-r1-0528": {
            "rating": 1425.940032513718,
            "rating_q975": 1437.3010286709248,
            "rating_q025": 1414.5790363565113
        },
        "deepseek-v3.1-terminus-thinking": {
            "rating": 1425.353936021665,
            "rating_q975": 1448.9836110403817,
            "rating_q025": 1401.7242610029484
        },
        "qwen3-235b-a22b-thinking-2507": {
            "rating": 1423.5905183065768,
            "rating_q975": 1438.3106336763876,
            "rating_q025": 1408.870402936766
        },
        "deepseek-v3.1-thinking": {
            "rating": 1418.9306596704705,
            "rating_q975": 1432.5179882826737,
            "rating_q025": 1405.3433310582673
        },
        "qwen3-30b-a3b-instruct-2507": {
            "rating": 1417.5771964379353,
            "rating_q975": 1426.562656348113,
            "rating_q025": 1408.5917365277576
        },
        "gemini-2.5-flash": {
            "rating": 1415.6380459342054,
            "rating_q975": 1422.3830509732345,
            "rating_q025": 1408.8930408951762
        },
        "deepseek-v3.1": {
            "rating": 1415.5095728593794,
            "rating_q975": 1427.1121354743505,
            "rating_q025": 1403.9070102444084
        },
        "claude-sonnet-4-20250514-thinking-32k": {
            "rating": 1411.8809502142137,
            "rating_q975": 1419.923704524252,
            "rating_q025": 1403.8381959041756
        },
        "qwen3-coder-480b-a35b-instruct": {
            "rating": 1410.7977055657639,
            "rating_q975": 1420.080489055871,
            "rating_q025": 1401.5149220756566
        },
        "grok-4-0709": {
            "rating": 1410.0483614386358,
            "rating_q975": 1417.6988885144472,
            "rating_q025": 1402.3978343628244
        },
        "o3-2025-04-16": {
            "rating": 1409.6639516598354,
            "rating_q975": 1416.2376672885187,
            "rating_q025": 1403.0902360311522
        },
        "chatgpt-4o-latest-20250326": {
            "rating": 1408.4102794575622,
            "rating_q975": 1415.3596282038845,
            "rating_q025": 1401.4609307112398
        },
        "deepseek-v3.1-terminus": {
            "rating": 1407.4839279838684,
            "rating_q975": 1428.3807860391066,
            "rating_q025": 1386.5870699286302
        },
        "gpt-5-mini-high": {
            "rating": 1406.6465122511477,
            "rating_q975": 1415.6793623400815,
            "rating_q025": 1397.6136621622138
        },
        "gemini-2.5-flash-preview-09-2025": {
            "rating": 1401.4259611066045,
            "rating_q975": 1412.525841144222,
            "rating_q025": 1390.326081068987
        },
        "claude-opus-4-20250514": {
            "rating": 1401.0778954348339,
            "rating_q975": 1408.4806779699293,
            "rating_q025": 1393.6751128997385
        },
        "kimi-k2-0905-preview": {
            "rating": 1400.0993995707822,
            "rating_q975": 1413.2931639969315,
            "rating_q025": 1386.905635144633
        },
        "gpt-5-chat": {
            "rating": 1397.314652599572,
            "rating_q975": 1405.884147985984,
            "rating_q025": 1388.7451572131597
        },
        "glm-4.5-air": {
            "rating": 1397.2051111767428,
            "rating_q975": 1405.5295597803952,
            "rating_q025": 1388.8806625730904
        },
        "qwen3-235b-a22b-no-thinking": {
            "rating": 1397.1581108301627,
            "rating_q975": 1404.8124900075345,
            "rating_q025": 1389.503731652791
        },
        "mai-1-preview": {
            "rating": 1396.9718523730505,
            "rating_q975": 1408.0946758912487,
            "rating_q025": 1385.8490288548523
        },
        "gpt-4.5-preview-2025-02-27": {
            "rating": 1395.8933244373281,
            "rating_q975": 1408.7898490316811,
            "rating_q025": 1382.9967998429752
        },
        "qwen3-next-80b-a3b-thinking": {
            "rating": 1394.2716444416733,
            "rating_q975": 1405.8724763312532,
            "rating_q025": 1382.6708125520934
        },
        "ling-flash-2.0": {
            "rating": 1391.9657822311258,
            "rating_q975": 1406.6155330135189,
            "rating_q025": 1377.3160314487327
        },
        "gpt-4.1-2025-04-14": {
            "rating": 1391.7223059974285,
            "rating_q975": 1398.7579199840777,
            "rating_q025": 1384.6866920107793
        },
        "hunyuan-t1-20250711": {
            "rating": 1385.1593891267805,
            "rating_q975": 1405.0512144333964,
            "rating_q025": 1365.2675638201647
        },
        "qwen3-235b-a22b": {
            "rating": 1384.7008921143747,
            "rating_q975": 1393.771409338076,
            "rating_q025": 1375.6303748906735
        },
        "mistral-medium-2505": {
            "rating": 1384.3139638170348,
            "rating_q975": 1392.416650204679,
            "rating_q025": 1376.2112774293907
        },
        "claude-sonnet-4-20250514": {
            "rating": 1379.5472882895385,
            "rating_q975": 1387.0838994921958,
            "rating_q025": 1372.0106770868813
        },
        "o3-mini-high": {
            "rating": 1377.2005381822264,
            "rating_q975": 1388.7197032862307,
            "rating_q025": 1365.6813730782221
        },
        "kimi-k2-0711-preview": {
            "rating": 1376.9889803816009,
            "rating_q975": 1385.6267420518898,
            "rating_q025": 1368.351218711312
        },
        "amazon-nova-experimental-chat-10-09": {
            "rating": 1375.5898630012475,
            "rating_q975": 1391.4071280987819,
            "rating_q025": 1359.7725979037132
        },
        "gemini-2.5-flash-lite-preview-06-17-thinking": {
            "rating": 1374.9667261278416,
            "rating_q975": 1382.9719085938452,
            "rating_q025": 1366.961543661838
        },
        "gpt-oss-120b": {
            "rating": 1374.05216499796,
            "rating_q975": 1382.3793924023742,
            "rating_q025": 1365.724937593546
        },
        "grok-3-mini-high": {
            "rating": 1373.9564433854318,
            "rating_q975": 1384.2121665307086,
            "rating_q025": 1363.700720240155
        },
        "deepseek-r1": {
            "rating": 1371.363610491244,
            "rating_q975": 1382.9990196608512,
            "rating_q025": 1359.7282013216366
        },
        "gemini-2.5-flash-lite-preview-09-2025-no-thinking": {
            "rating": 1369.4764915312155,
            "rating_q975": 1380.4647376077992,
            "rating_q025": 1358.4882454546319
        },
        "gpt-4.1-mini-2025-04-14": {
            "rating": 1368.3929634397734,
            "rating_q975": 1375.9715500417756,
            "rating_q025": 1360.8143768377713
        },
        "ring-flash-2.0": {
            "rating": 1367.9539422987336,
            "rating_q975": 1382.737306891164,
            "rating_q025": 1353.1705777063032
        },
        "o4-mini-2025-04-16": {
            "rating": 1367.916842876912,
            "rating_q975": 1374.9339211306608,
            "rating_q025": 1360.899764623163
        },
        "deepseek-v3-0324": {
            "rating": 1366.890242520612,
            "rating_q975": 1373.8080783835717,
            "rating_q025": 1359.9724066576523
        },
        "o1-2024-12-17": {
            "rating": 1365.9457776829681,
            "rating_q975": 1375.3264520698092,
            "rating_q025": 1356.565103296127
        },
        "o1-preview": {
            "rating": 1365.5689481055542,
            "rating_q975": 1374.6604664526956,
            "rating_q025": 1356.4774297584129
        },
        "grok-3-mini-beta": {
            "rating": 1364.9658265848389,
            "rating_q975": 1374.080575245859,
            "rating_q025": 1355.8510779238186
        },
        "mistral-small-2506": {
            "rating": 1363.462465206694,
            "rating_q975": 1373.6264918186114,
            "rating_q025": 1353.2984385947768
        },
        "step-3": {
            "rating": 1362.6709079814027,
            "rating_q975": 1379.2787765406379,
            "rating_q025": 1346.0630394221675
        },
        "claude-3-7-sonnet-20250219-thinking-32k": {
            "rating": 1361.5714504664045,
            "rating_q975": 1369.5603075820418,
            "rating_q025": 1353.5825933507672
        },
        "o3-mini": {
            "rating": 1361.3953706457323,
            "rating_q975": 1367.8252308832032,
            "rating_q025": 1354.9655104082615
        },
        "o1-mini": {
            "rating": 1361.3404069293006,
            "rating_q975": 1368.3941900916827,
            "rating_q025": 1354.2866237669184
        },
        "hunyuan-turbos-20250416": {
            "rating": 1361.1718465730592,
            "rating_q975": 1374.7733725193298,
            "rating_q025": 1347.5703206267885
        },
        "minimax-m1": {
            "rating": 1360.4471299279885,
            "rating_q975": 1368.1794396350094,
            "rating_q025": 1352.7148202209676
        },
        "qwen2.5-max": {
            "rating": 1357.8845713062826,
            "rating_q975": 1365.902916538622,
            "rating_q025": 1349.8662260739432
        },
        "qwen3-32b": {
            "rating": 1356.8150577572774,
            "rating_q975": 1381.4528947695514,
            "rating_q025": 1332.1772207450033
        },
        "gpt-5-nano-high": {
            "rating": 1350.6034275125653,
            "rating_q975": 1365.3237077771,
            "rating_q025": 1335.8831472480306
        },
        "glm-4.5v": {
            "rating": 1348.991474920149,
            "rating_q975": 1367.6917042046423,
            "rating_q025": 1330.2912456356555
        },
        "nvidia-llama-3.3-nemotron-super-49b-v1.5": {
            "rating": 1347.0317736225704,
            "rating_q975": 1368.820968533593,
            "rating_q025": 1325.2425787115478
        },
        "step-1o-turbo-202506": {
            "rating": 1342.4177092653097,
            "rating_q975": 1357.0206269624432,
            "rating_q025": 1327.8147915681761
        },
        "hunyuan-turbos-20250226": {
            "rating": 1341.7821815927075,
            "rating_q975": 1373.042563597704,
            "rating_q025": 1310.521799587711
        },
        "claude-3-5-sonnet-20241022": {
            "rating": 1341.2124453583704,
            "rating_q975": 1346.3638271531734,
            "rating_q025": 1336.0610635635674
        },
        "qwen3-30b-a3b": {
            "rating": 1336.1260177873698,
            "rating_q975": 1345.0072168565794,
            "rating_q025": 1327.2448187181603
        },
        "qwq-32b": {
            "rating": 1334.5752517345945,
            "rating_q975": 1343.590000099659,
            "rating_q025": 1325.5605033695301
        },
        "command-a-03-2025": {
            "rating": 1329.8398579281634,
            "rating_q975": 1336.4011092717822,
            "rating_q025": 1323.2786065845446
        },
        "qwen-plus-0125": {
            "rating": 1327.2025009497952,
            "rating_q975": 1345.486396558294,
            "rating_q025": 1308.9186053412964
        },
        "deepseek-v3": {
            "rating": 1324.639498537377,
            "rating_q975": 1334.517157333105,
            "rating_q025": 1314.761839741649
        },
        "gemma-3-27b-it": {
            "rating": 1323.452599217925,
            "rating_q975": 1330.3373483210428,
            "rating_q025": 1316.567850114807
        },
        "gemini-2.0-flash-lite-preview-02-05": {
            "rating": 1321.3739874352852,
            "rating_q975": 1330.9625433577528,
            "rating_q025": 1311.7854315128177
        },
        "magistral-medium-2506": {
            "rating": 1319.903640135151,
            "rating_q975": 1332.3053794571576,
            "rating_q025": 1307.5019008131442
        },
        "hunyuan-turbo-0110": {
            "rating": 1318.1493146122625,
            "rating_q975": 1348.13567207946,
            "rating_q025": 1288.162957145065
        },
        "step-2-16k-exp-202412": {
            "rating": 1314.7328579699292,
            "rating_q975": 1334.4343549394016,
            "rating_q025": 1295.0313610004569
        },
        "qwen2.5-plus-1127": {
            "rating": 1313.7165445309652,
            "rating_q975": 1327.4586805292024,
            "rating_q025": 1299.974408532728
        },
        "llama-3.1-nemotron-ultra-253b-v1": {
            "rating": 1311.7359388903478,
            "rating_q975": 1342.032820711767,
            "rating_q025": 1281.4390570689286
        },
        "yi-lightning": {
            "rating": 1311.579712490035,
            "rating_q975": 1320.9937499698322,
            "rating_q025": 1302.165675010238
        },
        "athene-v2-chat": {
            "rating": 1311.1039560034872,
            "rating_q975": 1319.9323910959415,
            "rating_q025": 1302.2755209110328
        },
        "gpt-oss-20b": {
            "rating": 1310.8489994509234,
            "rating_q975": 1324.142884785803,
            "rating_q025": 1297.5551141160438
        },
        "hunyuan-large-vision": {
            "rating": 1309.2132438131162,
            "rating_q975": 1328.1800618716286,
            "rating_q025": 1290.2464257546037
        },
        "deepseek-v2.5-1210": {
            "rating": 1309.0264444453355,
            "rating_q975": 1325.7421129641777,
            "rating_q025": 1292.3107759264933
        },
        "mistral-small-3.1-24b-instruct-2503": {
            "rating": 1308.4916866050003,
            "rating_q975": 1316.5233660521435,
            "rating_q025": 1300.460007157857
        },
        "hunyuan-large-2025-02-10": {
            "rating": 1305.9271626714717,
            "rating_q975": 1330.506778710161,
            "rating_q025": 1281.3475466327825
        },
        "gpt-4.1-nano-2025-04-14": {
            "rating": 1305.800607814288,
            "rating_q975": 1325.280846873104,
            "rating_q025": 1286.320368755472
        },
        "claude-3-5-sonnet-20240620": {
            "rating": 1305.5299146934908,
            "rating_q975": 1312.2347114358442,
            "rating_q025": 1298.8251179511374
        },
        "llama-4-maverick-17b-128e-instruct": {
            "rating": 1303.0845703450887,
            "rating_q975": 1310.6539720883393,
            "rating_q025": 1295.515168601838
        },
        "deepseek-v2.5": {
            "rating": 1300.4083545701237,
            "rating_q975": 1309.5028999899318,
            "rating_q025": 1291.3138091503156
        },
        "gpt-4o-2024-05-13": {
            "rating": 1296.376842920927,
            "rating_q975": 1302.458856813914,
            "rating_q025": 1290.2948290279398
        },
        "llama-3.3-nemotron-49b-super-v1": {
            "rating": 1296.0579036990002,
            "rating_q975": 1327.5652760018656,
            "rating_q025": 1264.5505313961348
        },
        "gemini-1.5-pro-002": {
            "rating": 1293.5963913437065,
            "rating_q975": 1300.0782796053243,
            "rating_q025": 1287.1145030820887
        },
        "qwen2.5-72b-instruct": {
            "rating": 1291.867224075463,
            "rating_q975": 1299.18657619357,
            "rating_q025": 1284.5478719573557
        },
        "llama-3.1-405b-instruct-bf16": {
            "rating": 1290.9270760966197,
            "rating_q975": 1298.112350217293,
            "rating_q025": 1283.7418019759464
        },
        "glm-4-plus": {
            "rating": 1289.8520938225038,
            "rating_q975": 1298.9321544261002,
            "rating_q025": 1280.7720332189074
        },
        "gpt-4o-mini-2024-07-18": {
            "rating": 1289.0824854839668,
            "rating_q975": 1295.2328151630645,
            "rating_q025": 1282.9321558048691
        },
        "qwen-max-0919": {
            "rating": 1287.436457588703,
            "rating_q975": 1298.4063827756943,
            "rating_q025": 1276.4665324017117
        },
        "grok-2-2024-08-13": {
            "rating": 1286.9561251854138,
            "rating_q975": 1293.5215784242964,
            "rating_q025": 1280.3906719465313
        },
        "llama-4-scout-17b-16e-instruct": {
            "rating": 1286.6446512416985,
            "rating_q975": 1295.2974314770488,
            "rating_q025": 1277.9918710063482
        },
        "claude-3-5-haiku-20241022": {
            "rating": 1285.88096065303,
            "rating_q975": 1291.7330802088727,
            "rating_q025": 1280.028841097187
        },
        "glm-4-plus-0111": {
            "rating": 1285.6258464029672,
            "rating_q975": 1303.67381537422,
            "rating_q025": 1267.5778774317143
        },
        "llama-3.1-405b-instruct-fp8": {
            "rating": 1283.3007187784228,
            "rating_q975": 1290.087270307295,
            "rating_q025": 1276.5141672495506
        },
        "gpt-4o-2024-08-06": {
            "rating": 1283.0722025493214,
            "rating_q975": 1290.6703238058137,
            "rating_q025": 1275.4740812928292
        },
        "gemma-3-12b-it": {
            "rating": 1281.7883630552183,
            "rating_q975": 1304.9091617603235,
            "rating_q025": 1258.667564350113
        },
        "qwen2.5-coder-32b-instruct": {
            "rating": 1275.863986040296,
            "rating_q975": 1294.101138088874,
            "rating_q025": 1257.6268339917178
        },
        "mistral-large-2407": {
            "rating": 1275.5288472003713,
            "rating_q975": 1283.0635425977555,
            "rating_q025": 1267.994151802987
        },
        "mistral-large-2411": {
            "rating": 1274.7943566701365,
            "rating_q975": 1283.3787493563095,
            "rating_q025": 1266.2099639839635
        },
        "gemma-3n-e4b-it": {
            "rating": 1272.2999635637375,
            "rating_q975": 1282.496520447669,
            "rating_q025": 1262.103406679806
        },
        "llama-3.1-nemotron-70b-instruct": {
            "rating": 1271.0034824948852,
            "rating_q975": 1286.201385631129,
            "rating_q025": 1255.8055793586416
        },
        "amazon-nova-pro-v1.0": {
            "rating": 1269.1808770075631,
            "rating_q975": 1278.0095860652582,
            "rating_q025": 1260.352167949868
        },
        "llama-3.3-70b-instruct": {
            "rating": 1268.2082620457238,
            "rating_q975": 1274.5273390038383,
            "rating_q025": 1261.8891850876093
        },
        "hunyuan-standard-2025-02-10": {
            "rating": 1268.2008440165273,
            "rating_q975": 1292.0430102448058,
            "rating_q025": 1244.3586777882488
        },
        "grok-2-mini-2024-08-13": {
            "rating": 1267.6587186548622,
            "rating_q975": 1274.5045370810935,
            "rating_q025": 1260.812900228631
        },
        "gpt-4-turbo-2024-04-09": {
            "rating": 1267.5586017202886,
            "rating_q975": 1274.3909765887681,
            "rating_q025": 1260.726226851809
        },
        "athene-70b-0725": {
            "rating": 1265.8598979942585,
            "rating_q975": 1276.4852854177957,
            "rating_q025": 1255.2345105707213
        },
        "gemini-1.5-pro-001": {
            "rating": 1265.5668470708433,
            "rating_q975": 1272.776546058226,
            "rating_q025": 1258.3571480834607
        },
        "claude-3-opus-20240229": {
            "rating": 1263.1475912499018,
            "rating_q975": 1268.6248959172558,
            "rating_q025": 1257.6702865825478
        },
        "gemini-1.5-flash-002": {
            "rating": 1260.6628059345717,
            "rating_q975": 1268.3772328790392,
            "rating_q025": 1252.9483789901042
        },
        "llama-3.1-70b-instruct": {
            "rating": 1259.133712165929,
            "rating_q975": 1265.9254943030412,
            "rating_q025": 1252.3419300288167
        },
        "gemini-advanced-0514": {
            "rating": 1254.5311355159633,
            "rating_q975": 1263.2648487569918,
            "rating_q025": 1245.797422274935
        },
        "gpt-4-1106-preview": {
            "rating": 1253.5634622006323,
            "rating_q975": 1260.6893059126876,
            "rating_q025": 1246.437618488577
        },
        "deepseek-coder-v2": {
            "rating": 1250.0617767308208,
            "rating_q975": 1261.8339565262966,
            "rating_q025": 1238.2895969353451
        },
        "gpt-4-0125-preview": {
            "rating": 1248.2061133778739,
            "rating_q975": 1255.527581847544,
            "rating_q025": 1240.8846449082037
        },
        "mistral-small-24b-instruct-2501": {
            "rating": 1245.6717095854465,
            "rating_q975": 1258.0458623778543,
            "rating_q025": 1233.2975567930387
        },
        "amazon-nova-lite-v1.0": {
            "rating": 1238.1634657968657,
            "rating_q975": 1248.1716751425072,
            "rating_q025": 1228.1552564512242
        },
        "llama-3.1-tulu-3-70b": {
            "rating": 1234.9236941063568,
            "rating_q975": 1258.9062390733145,
            "rating_q025": 1210.9411491393992
        },
        "gemini-1.5-flash-001": {
            "rating": 1234.8953475168748,
            "rating_q975": 1242.2467291066155,
            "rating_q025": 1227.5439659271342
        },
        "phi-4": {
            "rating": 1230.773229562896,
            "rating_q975": 1240.4676378433514,
            "rating_q025": 1221.0788212824405
        },
        "gemma-3-4b-it": {
            "rating": 1230.27738417331,
            "rating_q975": 1253.9666670582913,
            "rating_q025": 1206.588101288329
        },
        "hunyuan-standard-256k": {
            "rating": 1229.3117254698213,
            "rating_q975": 1253.9351790393973,
            "rating_q025": 1204.6882719002454
        },
        "reka-core-20240904": {
            "rating": 1229.2051288526968,
            "rating_q975": 1244.5717559538557,
            "rating_q025": 1213.838501751538
        },
        "jamba-1.5-large": {
            "rating": 1226.9825725570654,
            "rating_q975": 1241.3166048412118,
            "rating_q025": 1212.648540272919
        },
        "glm-4-0520": {
            "rating": 1226.57778433445,
            "rating_q975": 1240.4045299845204,
            "rating_q025": 1212.7510386843794
        },
        "llama-3.1-nemotron-51b-instruct": {
            "rating": 1222.213532515113,
            "rating_q975": 1243.62223461995,
            "rating_q025": 1200.804830410276
        },
        "claude-3-sonnet-20240229": {
            "rating": 1221.8350109240557,
            "rating_q975": 1228.9300388616819,
            "rating_q025": 1214.7399829864296
        },
        "amazon-nova-micro-v1.0": {
            "rating": 1216.8544341664851,
            "rating_q975": 1226.9618703100527,
            "rating_q025": 1206.7469980229175
        },
        "gemini-1.5-flash-8b-001": {
            "rating": 1216.7756514694788,
            "rating_q975": 1224.5353107396666,
            "rating_q025": 1209.015992199291
        },
        "gemma-2-27b-it": {
            "rating": 1210.3328858729274,
            "rating_q975": 1216.3239209967164,
            "rating_q025": 1204.3418507491383
        },
        "olmo-2-0325-32b-instruct": {
            "rating": 1209.6914354762823,
            "rating_q975": 1237.468260703103,
            "rating_q025": 1181.9146102494617
        },
        "nemotron-4-340b-instruct": {
            "rating": 1208.0476461448175,
            "rating_q975": 1219.1788941143748,
            "rating_q025": 1196.9163981752602
        },
        "gpt-4-0314": {
            "rating": 1207.5594805630417,
            "rating_q975": 1216.7717385864066,
            "rating_q025": 1198.3472225396767
        },
        "llama-3-70b-instruct": {
            "rating": 1205.8838176820916,
            "rating_q975": 1212.5688159889405,
            "rating_q025": 1199.1988193752427
        },
        "ministral-8b-2410": {
            "rating": 1200.9208086252793,
            "rating_q975": 1219.5446182894796,
            "rating_q025": 1182.296998961079
        },
        "claude-3-haiku-20240307": {
            "rating": 1198.3586861888562,
            "rating_q975": 1204.928907905521,
            "rating_q025": 1191.7884644721912
        },
        "c4ai-aya-expanse-32b": {
            "rating": 1195.8551737689006,
            "rating_q975": 1204.704392972919,
            "rating_q025": 1187.0059545648821
        },
        "qwen2-72b-instruct": {
            "rating": 1194.7966633049182,
            "rating_q975": 1203.5054008294535,
            "rating_q025": 1186.0879257803829
        },
        "llama-3.1-8b-instruct": {
            "rating": 1194.4814861999705,
            "rating_q975": 1201.6101364422084,
            "rating_q025": 1187.3528359577326
        },
        "gemma-2-9b-it-simpo": {
            "rating": 1191.0782966003649,
            "rating_q975": 1205.7817738255892,
            "rating_q025": 1176.3748193751405
        },
        "reka-flash-20240904": {
            "rating": 1189.820869107444,
            "rating_q975": 1204.9774491694227,
            "rating_q025": 1174.6642890454652
        },
        "command-r-plus-08-2024": {
            "rating": 1186.6526355235092,
            "rating_q975": 1200.3079597113801,
            "rating_q025": 1172.9973113356382
        },
        "granite-3.1-8b-instruct": {
            "rating": 1186.6013076380473,
            "rating_q975": 1212.1597553094036,
            "rating_q025": 1161.042859966691
        },
        "gpt-4-0613": {
            "rating": 1186.4049535348172,
            "rating_q975": 1194.1824041092898,
            "rating_q025": 1178.6275029603446
        },
        "qwen1.5-110b-chat": {
            "rating": 1183.1060020851432,
            "rating_q975": 1193.2131793318624,
            "rating_q025": 1172.998824838424
        },
        "llama-3.1-tulu-3-8b": {
            "rating": 1182.773227327456,
            "rating_q975": 1207.3746462011632,
            "rating_q025": 1158.1718084537488
        },
        "mistral-large-2402": {
            "rating": 1182.257253266303,
            "rating_q975": 1190.5607348752612,
            "rating_q025": 1173.9537716573448
        },
        "jamba-1.5-mini": {
            "rating": 1177.5418380670333,
            "rating_q975": 1192.6994560225658,
            "rating_q025": 1162.3842201115008
        },
        "gemma-2-9b-it": {
            "rating": 1172.6741056795418,
            "rating_q975": 1179.553725114934,
            "rating_q025": 1165.7944862441495
        },
        "command-r-plus": {
            "rating": 1171.2853734375278,
            "rating_q975": 1178.7519147612904,
            "rating_q025": 1163.8188321137652
        },
        "command-r-08-2024": {
            "rating": 1168.644519503236,
            "rating_q975": 1181.8985318157854,
            "rating_q025": 1155.3905071906868
        },
        "yi-1.5-34b-chat": {
            "rating": 1168.2091049820333,
            "rating_q975": 1178.4809017750244,
            "rating_q025": 1157.9373081890421
        },
        "mixtral-8x22b-instruct-v0.1": {
            "rating": 1164.9325724289968,
            "rating_q975": 1173.2891319492837,
            "rating_q025": 1156.5760129087098
        },
        "qwen1.5-72b-chat": {
            "rating": 1164.3002389230987,
            "rating_q975": 1173.729983507824,
            "rating_q025": 1154.8704943383734
        },
        "reka-flash-21b-20240226-online": {
            "rating": 1164.0609580383814,
            "rating_q975": 1176.6717757088843,
            "rating_q025": 1151.4501403678785
        },
        "mistral-medium": {
            "rating": 1161.0580785891998,
            "rating_q975": 1171.334429419681,
            "rating_q025": 1150.7817277587185
        },
        "c4ai-aya-expanse-8b": {
            "rating": 1160.405736201179,
            "rating_q975": 1174.7532676061517,
            "rating_q025": 1146.0582047962064
        },
        "internlm2_5-20b-chat": {
            "rating": 1159.521254056833,
            "rating_q975": 1173.4975712435814,
            "rating_q025": 1145.5449368700845
        },
        "qwq-32b-preview": {
            "rating": 1155.2148592794204,
            "rating_q975": 1179.353738438812,
            "rating_q025": 1131.0759801200288
        },
        "qwen1.5-32b-chat": {
            "rating": 1153.6342303920069,
            "rating_q975": 1164.4089117685187,
            "rating_q025": 1142.859549015495
        },
        "reka-flash-21b-20240226": {
            "rating": 1152.7528046666303,
            "rating_q975": 1163.242840920632,
            "rating_q025": 1142.2627684126285
        },
        "llama-3-8b-instruct": {
            "rating": 1151.1325423469557,
            "rating_q975": 1158.4345295249104,
            "rating_q025": 1143.830555169001
        },
        "granite-3.1-2b-instruct": {
            "rating": 1150.8422131342131,
            "rating_q975": 1175.3490183542854,
            "rating_q025": 1126.335407914141
        },
        "starling-lm-7b-beta": {
            "rating": 1142.1356566924205,
            "rating_q975": 1154.753687413462,
            "rating_q025": 1129.517625971379
        },
        "qwen1.5-14b-chat": {
            "rating": 1137.0484040610395,
            "rating_q975": 1149.742825928442,
            "rating_q025": 1124.353982193637
        },
        "gpt-3.5-turbo-0125": {
            "rating": 1135.699782092649,
            "rating_q975": 1143.5962755297865,
            "rating_q025": 1127.8032886555116
        },
        "dbrx-instruct-preview": {
            "rating": 1131.2240898955188,
            "rating_q975": 1141.9801382640205,
            "rating_q025": 1120.468041527017
        },
        "phi-3-medium-4k-instruct": {
            "rating": 1129.5979772563667,
            "rating_q975": 1139.6130395237356,
            "rating_q025": 1119.5829149889978
        },
        "zephyr-orpo-141b-A35b-v0.1": {
            "rating": 1128.5677243493033,
            "rating_q975": 1149.1639229547832,
            "rating_q025": 1107.9715257438233
        },
        "command-r": {
            "rating": 1127.216751100887,
            "rating_q975": 1135.683339871878,
            "rating_q025": 1118.750162329896
        },
        "mixtral-8x7b-instruct-v0.1": {
            "rating": 1125.8419097005797,
            "rating_q975": 1133.731139416665,
            "rating_q025": 1117.9526799844944
        },
        "tulu-2-dpo-70b": {
            "rating": 1115.1484743874444,
            "rating_q975": 1136.3898461228234,
            "rating_q025": 1093.9071026520653
        },
        "gpt-3.5-turbo-1106": {
            "rating": 1114.8524205568883,
            "rating_q975": 1130.5106827533543,
            "rating_q025": 1099.1941583604223
        },
        "gemma-2-2b-it": {
            "rating": 1112.1122375240288,
            "rating_q975": 1119.727447538165,
            "rating_q025": 1104.4970275098926
        },
        "openchat-3.5-0106": {
            "rating": 1111.9725647187931,
            "rating_q975": 1125.8857377467998,
            "rating_q025": 1098.0593916907865
        },
        "granite-3.0-8b-instruct": {
            "rating": 1111.347812765613,
            "rating_q975": 1129.2554246281495,
            "rating_q025": 1093.4402009030766
        },
        "yi-34b-chat": {
            "rating": 1110.7595555861308,
            "rating_q975": 1123.6940153052362,
            "rating_q025": 1097.8250958670253
        },
        "gemini-pro": {
            "rating": 1106.954065815486,
            "rating_q975": 1130.4630105362162,
            "rating_q025": 1083.445121094756
        },
        "qwen1.5-7b-chat": {
            "rating": 1106.5985009337037,
            "rating_q975": 1127.1058181685632,
            "rating_q025": 1086.0911836988441
        },
        "gemini-pro-dev-api": {
            "rating": 1103.4850272255621,
            "rating_q975": 1117.2347811534387,
            "rating_q025": 1089.7352732976856
        },
        "phi-3-small-8k-instruct": {
            "rating": 1100.8683626487698,
            "rating_q975": 1112.2715131409689,
            "rating_q025": 1089.4652121565707
        },
        "starling-lm-7b-alpha": {
            "rating": 1096.850791194826,
            "rating_q975": 1113.1341159307733,
            "rating_q025": 1080.5674664588785
        },
        "llama-3.2-3b-instruct": {
            "rating": 1096.807898448152,
            "rating_q975": 1112.6213965194995,
            "rating_q025": 1080.9944003768044
        },
        "deepseek-llm-67b-chat": {
            "rating": 1095.0569958111168,
            "rating_q975": 1118.9579265057437,
            "rating_q025": 1071.15606511649
        },
        "phi-3-mini-4k-instruct-june-2024": {
            "rating": 1093.3969512684512,
            "rating_q975": 1107.010644234995,
            "rating_q025": 1079.7832583019074
        },
        "phi-3-mini-4k-instruct": {
            "rating": 1092.4216095146237,
            "rating_q975": 1103.9501723863825,
            "rating_q025": 1080.8930466428649
        },
        "granite-3.0-2b-instruct": {
            "rating": 1089.4595793373167,
            "rating_q975": 1106.7806183168814,
            "rating_q025": 1072.138540357752
        },
        "snowflake-arctic-instruct": {
            "rating": 1088.8135789711282,
            "rating_q975": 1099.894185817237,
            "rating_q025": 1077.7329721250194
        },
        "gemma-1.1-7b-it": {
            "rating": 1083.1251020377258,
            "rating_q975": 1093.290025485945,
            "rating_q025": 1072.9601785895065
        },
        "mistral-7b-instruct-v0.2": {
            "rating": 1081.1940629386863,
            "rating_q975": 1092.75639166086,
            "rating_q025": 1069.6317342165128
        },
        "wizardlm-70b": {
            "rating": 1078.9277518404128,
            "rating_q975": 1098.7325501679704,
            "rating_q025": 1059.1229535128552
        },
        "nous-hermes-2-mixtral-8x7b-dpo": {
            "rating": 1078.5359039056611,
            "rating_q975": 1102.00164978484,
            "rating_q025": 1055.0701580264822
        },
        "llama-2-70b-chat": {
            "rating": 1077.9071092201546,
            "rating_q975": 1087.6531917598181,
            "rating_q025": 1068.161026680491
        },
        "vicuna-33b": {
            "rating": 1077.180200843205,
            "rating_q975": 1089.7810059569856,
            "rating_q025": 1064.5793957294245
        },
        "openchat-3.5": {
            "rating": 1073.4977071142412,
            "rating_q975": 1093.1242860182954,
            "rating_q025": 1053.871128210187
        },
        "llama-3.2-1b-instruct": {
            "rating": 1070.3899744088067,
            "rating_q975": 1086.1782804285926,
            "rating_q025": 1054.6016683890207
        },
        "qwen-14b-chat": {
            "rating": 1069.9784809136877,
            "rating_q975": 1094.0896802225207,
            "rating_q025": 1045.8672816048547
        },
        "solar-10.7b-instruct-v1.0": {
            "rating": 1065.9579498011885,
            "rating_q975": 1093.0899578809865,
            "rating_q025": 1038.8259417213906
        },
        "openhermes-2.5-mistral-7b": {
            "rating": 1063.592331720972,
            "rating_q975": 1087.1788972657098,
            "rating_q025": 1040.0057661762341
        },
        "llama-2-13b-chat": {
            "rating": 1061.3838455168375,
            "rating_q975": 1074.1426612456546,
            "rating_q025": 1048.6250297880204
        },
        "zephyr-7b-alpha": {
            "rating": 1053.8216229744894,
            "rating_q975": 1094.729368040632,
            "rating_q025": 1012.9138779083469
        },
        "gemma-7b-it": {
            "rating": 1047.7490612774714,
            "rating_q975": 1064.2363070493298,
            "rating_q025": 1031.261815505613
        },
        "smollm2-1.7b-instruct": {
            "rating": 1047.043330418982,
            "rating_q975": 1079.946157142146,
            "rating_q025": 1014.140503695818
        },
        "codellama-34b-instruct": {
            "rating": 1044.9637031684015,
            "rating_q975": 1065.318477197315,
            "rating_q025": 1024.608929139488
        },
        "zephyr-7b-beta": {
            "rating": 1043.0650318729622,
            "rating_q975": 1061.3034559248872,
            "rating_q025": 1024.8266078210372
        },
        "vicuna-13b": {
            "rating": 1039.6470208327016,
            "rating_q975": 1053.422856216336,
            "rating_q025": 1025.8711854490673
        },
        "phi-3-mini-128k-instruct": {
            "rating": 1039.4464035326096,
            "rating_q975": 1052.2172824245054,
            "rating_q025": 1026.6755246407138
        },
        "mpt-30b-chat": {
            "rating": 1037.3986462688606,
            "rating_q975": 1073.346501351413,
            "rating_q025": 1001.4507911863083
        },
        "wizardlm-13b": {
            "rating": 1033.4189737327222,
            "rating_q975": 1055.6023098870135,
            "rating_q025": 1011.2356375784309
        },
        "gemma-1.1-2b-it": {
            "rating": 1033.2406456828824,
            "rating_q975": 1047.1036026945408,
            "rating_q025": 1019.3776886712241
        },
        "llama2-70b-steerlm-chat": {
            "rating": 1023.8639444585662,
            "rating_q975": 1052.536703158573,
            "rating_q025": 995.1911857585593
        },
        "mistral-7b-instruct": {
            "rating": 1018.1621102673855,
            "rating_q975": 1037.9116060317715,
            "rating_q025": 998.4126145029994
        },
        "olmo-7b-instruct": {
            "rating": 1015.2428668842233,
            "rating_q975": 1037.169061338908,
            "rating_q025": 993.3166724295386
        },
        "vicuna-7b": {
            "rating": 1008.4672852779419,
            "rating_q975": 1031.322230830233,
            "rating_q025": 985.6123397256509
        },
        "gemma-2b-it": {
            "rating": 1008.230778388181,
            "rating_q975": 1030.2719979316978,
            "rating_q025": 986.1895588446641
        },
        "llama-2-7b-chat": {
            "rating": 1001.3109886761124,
            "rating_q975": 1015.3227385646668,
            "rating_q025": 987.299238787558
        },
        "stripedhyena-nous-7b": {
            "rating": 998.608400081203,
            "rating_q975": 1020.9816450932178,
            "rating_q025": 976.2351550691881
        },
        "qwen1.5-4b-chat": {
            "rating": 996.9829372609836,
            "rating_q975": 1014.2816241073311,
            "rating_q025": 979.684250414636
        },
        "guanaco-33b": {
            "rating": 995.1123596282367,
            "rating_q975": 1030.9929694045536,
            "rating_q025": 959.23174985192
        },
        "palm-2": {
            "rating": 993.1130205119218,
            "rating_q975": 1014.132440174001,
            "rating_q025": 972.0936008498427
        },
        "chatglm3-6b": {
            "rating": 962.4110559016449,
            "rating_q975": 989.093873580783,
            "rating_q025": 935.7282382225068
        },
        "koala-13b": {
            "rating": 942.996685427808,
            "rating_q975": 967.4758469109028,
            "rating_q025": 918.5175239447132
        },
        "RWKV-4-Raven-14B": {
            "rating": 926.0072365841822,
            "rating_q975": 953.5941365788614,
            "rating_q025": 898.4203365895031
        },
        "chatglm-6b": {
            "rating": 917.2642709009303,
            "rating_q975": 944.5146157836659,
            "rating_q025": 890.0139260181948
        },
        "mpt-7b-chat": {
            "rating": 911.6997082468856,
            "rating_q975": 943.9739728621246,
            "rating_q025": 879.4254436316467
        },
        "chatglm2-6b": {
            "rating": 900.7779176521583,
            "rating_q975": 936.4927174248525,
            "rating_q025": 865.0631178794641
        },
        "oasst-pythia-12b": {
            "rating": 898.724606089886,
            "rating_q975": 924.2890544750609,
            "rating_q025": 873.1601577047112
        },
        "stablelm-tuned-alpha-7b": {
            "rating": 884.1712141044861,
            "rating_q975": 917.7610052580617,
            "rating_q025": 850.5814229509106
        },
        "alpaca-13b": {
            "rating": 796.8618742380486,
            "rating_q975": 824.7839817426484,
            "rating_q025": 768.9397667334488
        },
        "dolly-v2-12b": {
            "rating": 774.884166441131,
            "rating_q975": 809.0801685565505,
            "rating_q025": 740.6881643257116
        },
        "fastchat-t5-3b": {
            "rating": 762.2514082165787,
            "rating_q975": 793.2883947137581,
            "rating_q025": 731.2144217193994
        },
        "llama-13b": {
            "rating": 679.4070299306536,
            "rating_q975": 719.9562285322926,
            "rating_q025": 638.8578313290146
        }
    },
    "creative_writing": {
        "gemini-2.5-pro": {
            "rating": 1462.3029868011047,
            "rating_q975": 1470.1962410549515,
            "rating_q025": 1454.4097325472578
        },
        "claude-sonnet-4-5-20250929": {
            "rating": 1423.3327889911848,
            "rating_q975": 1443.5495840567937,
            "rating_q025": 1403.1159939255758
        },
        "glm-4.6": {
            "rating": 1423.237110487107,
            "rating_q975": 1440.2604272986866,
            "rating_q025": 1406.2137936755273
        },
        "grok-3-preview-02-24": {
            "rating": 1413.181466370828,
            "rating_q975": 1421.9763716071504,
            "rating_q025": 1404.3865611345057
        },
        "claude-sonnet-4-5-20250929-thinking-32k": {
            "rating": 1409.1463738193888,
            "rating_q975": 1424.4075942311715,
            "rating_q025": 1393.8851534076061
        },
        "claude-opus-4-1-20250805-thinking-16k": {
            "rating": 1406.9091664607602,
            "rating_q975": 1417.4578725546485,
            "rating_q025": 1396.3604603668718
        },
        "chatgpt-4o-latest-20250326": {
            "rating": 1405.3690399210948,
            "rating_q975": 1413.3006326808231,
            "rating_q025": 1397.4374471613664
        },
        "deepseek-r1-0528": {
            "rating": 1404.8841475607671,
            "rating_q975": 1416.9295223525419,
            "rating_q025": 1392.8387727689924
        },
        "deepseek-v3.1-terminus": {
            "rating": 1404.7217565790586,
            "rating_q975": 1432.031161908098,
            "rating_q025": 1377.4123512500191
        },
        "gemini-2.5-flash": {
            "rating": 1403.853657364172,
            "rating_q975": 1411.5058476353818,
            "rating_q025": 1396.2014670929623
        },
        "deepseek-v3.1-thinking": {
            "rating": 1402.8061142794563,
            "rating_q975": 1417.281108164351,
            "rating_q025": 1388.3311203945616
        },
        "qwen3-max-preview": {
            "rating": 1400.507942883731,
            "rating_q975": 1411.2465272404693,
            "rating_q025": 1389.7693585269926
        },
        "claude-opus-4-1-20250805": {
            "rating": 1399.3561767383515,
            "rating_q975": 1408.3471571033524,
            "rating_q025": 1390.3651963733505
        },
        "grok-4-0709": {
            "rating": 1398.1679343972946,
            "rating_q975": 1407.3024366707405,
            "rating_q025": 1389.0334321238488
        },
        "glm-4.5": {
            "rating": 1395.5450816651605,
            "rating_q975": 1406.284337796497,
            "rating_q025": 1384.805825533824
        },
        "deepseek-v3.2-exp-thinking": {
            "rating": 1394.3862903659651,
            "rating_q975": 1411.5807511025228,
            "rating_q025": 1377.1918296294075
        },
        "gpt-4.5-preview-2025-02-27": {
            "rating": 1393.9888036014459,
            "rating_q975": 1405.7624355376659,
            "rating_q025": 1382.2151716652259
        },
        "gemini-2.5-flash-preview-09-2025": {
            "rating": 1393.0177947263267,
            "rating_q975": 1407.2873963064812,
            "rating_q025": 1378.748193146172
        },
        "deepseek-v3.1": {
            "rating": 1392.9504278453287,
            "rating_q975": 1406.2009492861794,
            "rating_q025": 1379.699906404478
        },
        "hunyuan-t1-20250711": {
            "rating": 1392.8938000996097,
            "rating_q975": 1416.7945285006483,
            "rating_q025": 1368.9930716985712
        },
        "mistral-medium-2508": {
            "rating": 1389.8555104644608,
            "rating_q975": 1399.657571431111,
            "rating_q025": 1380.0534494978108
        },
        "grok-4-fast": {
            "rating": 1387.343040989091,
            "rating_q975": 1406.340013977551,
            "rating_q025": 1368.3460680006308
        },
        "qwen3-max-2025-09-23": {
            "rating": 1386.481124561448,
            "rating_q975": 1403.561608016986,
            "rating_q025": 1369.4006411059102
        },
        "qwen3-235b-a22b-thinking-2507": {
            "rating": 1385.9653732934887,
            "rating_q975": 1403.2641137603741,
            "rating_q025": 1368.6666328266033
        },
        "deepseek-v3.1-terminus-thinking": {
            "rating": 1381.8005355077614,
            "rating_q975": 1409.9827298825824,
            "rating_q025": 1353.6183411329405
        },
        "claude-opus-4-20250514-thinking-16k": {
            "rating": 1378.2511268206601,
            "rating_q975": 1387.48852644194,
            "rating_q025": 1369.0137271993804
        },
        "qwen3-235b-a22b-instruct-2507": {
            "rating": 1376.7379199205245,
            "rating_q975": 1385.86487665602,
            "rating_q025": 1367.610963185029
        },
        "gpt-5-high": {
            "rating": 1372.8047684790622,
            "rating_q975": 1382.7590219448784,
            "rating_q025": 1362.850515013246
        },
        "claude-haiku-4-5-20251001": {
            "rating": 1372.7503813713406,
            "rating_q975": 1389.5062283476216,
            "rating_q025": 1355.9945343950596
        },
        "claude-opus-4-20250514": {
            "rating": 1371.2253893958198,
            "rating_q975": 1379.77321758794,
            "rating_q025": 1362.6775612036995
        },
        "gpt-5-chat": {
            "rating": 1368.5194671587344,
            "rating_q975": 1378.694958364634,
            "rating_q025": 1358.3439759528349
        },
        "qwen3-vl-235b-a22b-instruct": {
            "rating": 1367.7521868267136,
            "rating_q975": 1385.2893408845625,
            "rating_q025": 1350.2150327688646
        },
        "gemini-2.5-flash-lite-preview-09-2025-no-thinking": {
            "rating": 1365.3260383607774,
            "rating_q975": 1379.4544164929707,
            "rating_q025": 1351.197660228584
        },
        "deepseek-v3-0324": {
            "rating": 1365.2654089543878,
            "rating_q975": 1373.19020734359,
            "rating_q025": 1357.3406105651857
        },
        "gemini-2.5-flash-lite-preview-06-17-thinking": {
            "rating": 1364.6493606996241,
            "rating_q975": 1373.8618553356432,
            "rating_q025": 1355.436866063605
        },
        "o3-2025-04-16": {
            "rating": 1363.393871602468,
            "rating_q975": 1370.9325235103402,
            "rating_q025": 1355.8552196945957
        },
        "gpt-4.1-2025-04-14": {
            "rating": 1361.070160254966,
            "rating_q975": 1369.0060298590768,
            "rating_q025": 1353.134290650855
        },
        "hunyuan-turbos-20250416": {
            "rating": 1359.9938627360457,
            "rating_q975": 1374.882490367571,
            "rating_q025": 1345.1052351045203
        },
        "mai-1-preview": {
            "rating": 1357.7389710402933,
            "rating_q975": 1370.4439802269005,
            "rating_q025": 1345.0339618536862
        },
        "qwen3-235b-a22b-no-thinking": {
            "rating": 1357.0743070393767,
            "rating_q975": 1366.0366585722354,
            "rating_q025": 1348.111955506518
        },
        "deepseek-r1": {
            "rating": 1354.4359012341167,
            "rating_q975": 1364.4912752825096,
            "rating_q025": 1344.3805271857238
        },
        "kimi-k2-0905-preview": {
            "rating": 1349.801623250478,
            "rating_q975": 1365.900845430954,
            "rating_q025": 1333.7024010700022
        },
        "qwen3-vl-235b-a22b-thinking": {
            "rating": 1348.807882455364,
            "rating_q975": 1367.2142024294994,
            "rating_q025": 1330.4015624812287
        },
        "o1-2024-12-17": {
            "rating": 1347.6690423311927,
            "rating_q975": 1356.430735035182,
            "rating_q025": 1338.9073496272035
        },
        "longcat-flash-chat": {
            "rating": 1346.1895297680494,
            "rating_q975": 1361.8735815004243,
            "rating_q025": 1330.5054780356745
        },
        "claude-sonnet-4-20250514-thinking-32k": {
            "rating": 1345.209291014434,
            "rating_q975": 1354.5400484340337,
            "rating_q025": 1335.8785335948344
        },
        "gemma-3-27b-it": {
            "rating": 1344.445023368969,
            "rating_q975": 1351.9203145370354,
            "rating_q025": 1336.9697322009026
        },
        "glm-4.5-air": {
            "rating": 1343.2667580010154,
            "rating_q975": 1353.2694116093528,
            "rating_q025": 1333.264104392678
        },
        "mistral-medium-2505": {
            "rating": 1341.701519738016,
            "rating_q975": 1350.9485732383448,
            "rating_q025": 1332.4544662376873
        },
        "grok-3-mini-beta": {
            "rating": 1340.2409279425085,
            "rating_q975": 1351.1085583731021,
            "rating_q025": 1329.3732975119149
        },
        "qwen2.5-max": {
            "rating": 1338.8098186861696,
            "rating_q975": 1347.072918388956,
            "rating_q025": 1330.5467189833832
        },
        "claude-sonnet-4-20250514": {
            "rating": 1337.2848307790416,
            "rating_q975": 1346.0792496571698,
            "rating_q025": 1328.4904119009134
        },
        "gemini-1.5-pro-002": {
            "rating": 1333.544833922305,
            "rating_q975": 1340.4730509164374,
            "rating_q025": 1326.6166169281728
        },
        "qwen3-coder-480b-a35b-instruct": {
            "rating": 1333.3121076820744,
            "rating_q975": 1343.9394482812145,
            "rating_q025": 1322.6847670829343
        },
        "grok-3-mini-high": {
            "rating": 1333.1451462880918,
            "rating_q975": 1345.9871722865862,
            "rating_q025": 1320.3031202895975
        },
        "qwen3-next-80b-a3b-instruct": {
            "rating": 1332.710566349171,
            "rating_q975": 1344.7136663965111,
            "rating_q025": 1320.7074663018307
        },
        "gemma-3-12b-it": {
            "rating": 1330.0727156574403,
            "rating_q975": 1353.0354978794903,
            "rating_q025": 1307.1099334353903
        },
        "gpt-5-mini-high": {
            "rating": 1329.8726770913993,
            "rating_q975": 1340.7806657774356,
            "rating_q025": 1318.964688405363
        },
        "claude-3-7-sonnet-20250219-thinking-32k": {
            "rating": 1329.7923841891993,
            "rating_q975": 1338.2484542089926,
            "rating_q025": 1321.336314169406
        },
        "deepseek-v3": {
            "rating": 1329.766001921438,
            "rating_q975": 1339.5158931039798,
            "rating_q025": 1320.016110738896
        },
        "kimi-k2-0711-preview": {
            "rating": 1327.4816171631846,
            "rating_q975": 1337.6068372362772,
            "rating_q025": 1317.356397090092
        },
        "step-2-16k-exp-202412": {
            "rating": 1327.3777492412687,
            "rating_q975": 1347.9833747231185,
            "rating_q025": 1306.772123759419
        },
        "amazon-nova-experimental-chat-10-09": {
            "rating": 1324.351571742527,
            "rating_q975": 1344.731591509483,
            "rating_q025": 1303.9715519755712
        },
        "qwen3-30b-a3b-instruct-2507": {
            "rating": 1323.0651813962272,
            "rating_q975": 1333.9403839324193,
            "rating_q025": 1312.1899788600351
        },
        "qwen3-235b-a22b": {
            "rating": 1321.2335816626558,
            "rating_q975": 1331.1488050861803,
            "rating_q025": 1311.3183582391312
        },
        "gemini-2.0-flash-lite-preview-02-05": {
            "rating": 1320.0537865469075,
            "rating_q975": 1328.981557605264,
            "rating_q025": 1311.126015488551
        },
        "o1-preview": {
            "rating": 1319.3458672888994,
            "rating_q975": 1328.9683860361877,
            "rating_q025": 1309.7233485416111
        },
        "command-a-03-2025": {
            "rating": 1317.743901563534,
            "rating_q975": 1325.0840193876165,
            "rating_q025": 1310.4037837394517
        },
        "llama-3.1-nemotron-ultra-253b-v1": {
            "rating": 1316.048683620631,
            "rating_q975": 1342.5157464386787,
            "rating_q025": 1289.5816208025833
        },
        "step-3": {
            "rating": 1315.5906852537269,
            "rating_q975": 1336.0604641149691,
            "rating_q025": 1295.1209063924846
        },
        "glm-4-plus-0111": {
            "rating": 1312.0172733944628,
            "rating_q975": 1330.8939570426462,
            "rating_q025": 1293.1405897462794
        },
        "qwen3-next-80b-a3b-thinking": {
            "rating": 1309.8677857472055,
            "rating_q975": 1324.0537513937763,
            "rating_q025": 1295.6818201006347
        },
        "nvidia-llama-3.3-nemotron-super-49b-v1.5": {
            "rating": 1306.681170916635,
            "rating_q975": 1334.773828925694,
            "rating_q025": 1278.588512907576
        },
        "mistral-small-2506": {
            "rating": 1306.510697987774,
            "rating_q975": 1318.7023115290801,
            "rating_q025": 1294.3190844464677
        },
        "minimax-m1": {
            "rating": 1304.5329296352845,
            "rating_q975": 1313.44172418925,
            "rating_q025": 1295.624135081319
        },
        "step-1o-turbo-202506": {
            "rating": 1301.5833874445646,
            "rating_q975": 1319.4956474746664,
            "rating_q025": 1283.6711274144627
        },
        "o4-mini-2025-04-16": {
            "rating": 1300.580967750428,
            "rating_q975": 1308.6893980990458,
            "rating_q025": 1292.4725374018103
        },
        "gpt-4.1-mini-2025-04-14": {
            "rating": 1299.4938917044053,
            "rating_q975": 1308.1132068189368,
            "rating_q025": 1290.8745765898739
        },
        "qwen3-32b": {
            "rating": 1298.3356149690214,
            "rating_q975": 1320.8233645350006,
            "rating_q025": 1275.8478654030423
        },
        "glm-4.5v": {
            "rating": 1295.793842122724,
            "rating_q975": 1318.6809630909243,
            "rating_q025": 1272.906721154524
        },
        "claude-3-5-sonnet-20241022": {
            "rating": 1293.515278935667,
            "rating_q975": 1299.342500913199,
            "rating_q025": 1287.6880569581351
        },
        "qwen-plus-0125": {
            "rating": 1292.7025212911562,
            "rating_q975": 1310.9228031681046,
            "rating_q025": 1274.482239414208
        },
        "gpt-4o-2024-05-13": {
            "rating": 1292.3330289392788,
            "rating_q975": 1299.0059704970752,
            "rating_q025": 1285.6600873814825
        },
        "qwq-32b": {
            "rating": 1289.2481878427611,
            "rating_q975": 1298.7989721939593,
            "rating_q025": 1279.697403491563
        },
        "ling-flash-2.0": {
            "rating": 1288.2457554267385,
            "rating_q975": 1308.5277743378697,
            "rating_q025": 1267.9637365156073
        },
        "gemma-3n-e4b-it": {
            "rating": 1286.9776144542325,
            "rating_q975": 1297.8556069141393,
            "rating_q025": 1276.0996219943256
        },
        "llama-3.3-nemotron-49b-super-v1": {
            "rating": 1286.4165673489344,
            "rating_q975": 1313.4349993670755,
            "rating_q025": 1259.3981353307934
        },
        "gemini-1.5-flash-002": {
            "rating": 1286.2882917792833,
            "rating_q975": 1294.8022834105125,
            "rating_q025": 1277.7743001480542
        },
        "o3-mini-high": {
            "rating": 1285.9629898537319,
            "rating_q975": 1296.4937590314892,
            "rating_q025": 1275.4322206759746
        },
        "grok-2-2024-08-13": {
            "rating": 1285.4678367553147,
            "rating_q975": 1292.4494396404882,
            "rating_q025": 1278.4862338701412
        },
        "gemini-advanced-0514": {
            "rating": 1285.2057630584297,
            "rating_q975": 1294.7378264901051,
            "rating_q025": 1275.6736996267543
        },
        "deepseek-v2.5-1210": {
            "rating": 1284.6979847649072,
            "rating_q975": 1301.8027492901422,
            "rating_q025": 1267.5932202396723
        },
        "yi-lightning": {
            "rating": 1281.4982717507635,
            "rating_q975": 1291.5963123764066,
            "rating_q025": 1271.4002311251204
        },
        "gpt-oss-120b": {
            "rating": 1277.537817380918,
            "rating_q975": 1287.8909049384554,
            "rating_q025": 1267.1847298233808
        },
        "gpt-4o-2024-08-06": {
            "rating": 1274.7749806399179,
            "rating_q975": 1282.861157770084,
            "rating_q025": 1266.6888035097518
        },
        "o3-mini": {
            "rating": 1274.6685654124803,
            "rating_q975": 1281.4237340929958,
            "rating_q025": 1267.913396731965
        },
        "qwen3-30b-a3b": {
            "rating": 1274.5992826771171,
            "rating_q975": 1284.6999453641006,
            "rating_q025": 1264.4986199901336
        },
        "gemini-1.5-pro-001": {
            "rating": 1273.4539392320958,
            "rating_q975": 1281.1979656452,
            "rating_q025": 1265.7099128189916
        },
        "ring-flash-2.0": {
            "rating": 1272.9942663616926,
            "rating_q975": 1292.7237379482724,
            "rating_q025": 1253.2647947751127
        },
        "gemma-3-4b-it": {
            "rating": 1272.2075310748621,
            "rating_q975": 1293.8948967709234,
            "rating_q025": 1250.5201653788008
        },
        "hunyuan-turbos-20250226": {
            "rating": 1270.8860110790108,
            "rating_q975": 1296.799478497008,
            "rating_q025": 1244.9725436610136
        },
        "gpt-4-turbo-2024-04-09": {
            "rating": 1270.0880563123524,
            "rating_q975": 1277.4405386139329,
            "rating_q025": 1262.7355740107719
        },
        "llama-3.1-nemotron-70b-instruct": {
            "rating": 1269.4620918215335,
            "rating_q975": 1288.0472337524398,
            "rating_q025": 1250.8769498906272
        },
        "gpt-4o-mini-2024-07-18": {
            "rating": 1268.9172658714758,
            "rating_q975": 1275.3731968268658,
            "rating_q025": 1262.461334916086
        },
        "hunyuan-turbo-0110": {
            "rating": 1268.3765003765452,
            "rating_q975": 1293.4268162658032,
            "rating_q025": 1243.3261844872873
        },
        "llama-4-maverick-17b-128e-instruct": {
            "rating": 1268.3309001028074,
            "rating_q975": 1276.7895833560885,
            "rating_q025": 1259.8722168495262
        },
        "glm-4-plus": {
            "rating": 1264.0321533342417,
            "rating_q975": 1273.947706565098,
            "rating_q025": 1254.1166001033853
        },
        "hunyuan-large-2025-02-10": {
            "rating": 1263.8914666463734,
            "rating_q975": 1287.6811451321569,
            "rating_q025": 1240.1017881605899
        },
        "llama-3.1-405b-instruct-fp8": {
            "rating": 1263.187201787026,
            "rating_q975": 1270.433512763172,
            "rating_q025": 1255.9408908108799
        },
        "qwen2.5-plus-1127": {
            "rating": 1262.5180060771586,
            "rating_q975": 1276.7112519908962,
            "rating_q025": 1248.324760163421
        },
        "gpt-4.1-nano-2025-04-14": {
            "rating": 1262.006193322841,
            "rating_q975": 1280.235097670056,
            "rating_q025": 1243.777288975626
        },
        "llama-3.1-405b-instruct-bf16": {
            "rating": 1260.9076059569488,
            "rating_q975": 1268.1587789971798,
            "rating_q025": 1253.656432916718
        },
        "hunyuan-large-vision": {
            "rating": 1257.8652162222338,
            "rating_q975": 1281.4472572052634,
            "rating_q025": 1234.2831752392042
        },
        "mistral-small-3.1-24b-instruct-2503": {
            "rating": 1254.9398296638628,
            "rating_q975": 1264.3031517829475,
            "rating_q025": 1245.5765075447782
        },
        "gpt-5-nano-high": {
            "rating": 1254.4473595663098,
            "rating_q975": 1274.3150576618075,
            "rating_q025": 1234.5796614708122
        },
        "magistral-medium-2506": {
            "rating": 1254.271940167714,
            "rating_q975": 1270.1867550724814,
            "rating_q025": 1238.3571252629467
        },
        "llama-4-scout-17b-16e-instruct": {
            "rating": 1252.564682352297,
            "rating_q975": 1262.4631245492749,
            "rating_q025": 1242.6662401553192
        },
        "llama-3.3-70b-instruct": {
            "rating": 1252.4265136031536,
            "rating_q975": 1259.0585710525547,
            "rating_q025": 1245.7944561537524
        },
        "qwen-max-0919": {
            "rating": 1249.6134954853733,
            "rating_q975": 1261.3798217188526,
            "rating_q025": 1237.847169251894
        },
        "o1-mini": {
            "rating": 1245.515615353063,
            "rating_q975": 1252.7161331220557,
            "rating_q025": 1238.3150975840701
        },
        "gpt-4-1106-preview": {
            "rating": 1245.2643858774522,
            "rating_q975": 1252.8375980232886,
            "rating_q025": 1237.691173731616
        },
        "mistral-large-2407": {
            "rating": 1244.0864949082484,
            "rating_q975": 1252.2711193892335,
            "rating_q025": 1235.9018704272632
        },
        "grok-2-mini-2024-08-13": {
            "rating": 1243.153097503128,
            "rating_q975": 1250.4341610325619,
            "rating_q025": 1235.8720339736942
        },
        "gemma-2-27b-it": {
            "rating": 1242.2234592333107,
            "rating_q975": 1248.5830388314403,
            "rating_q025": 1235.863879635181
        },
        "mistral-large-2411": {
            "rating": 1242.1121999604657,
            "rating_q975": 1250.7909986440636,
            "rating_q025": 1233.4334012768677
        },
        "hunyuan-standard-2025-02-10": {
            "rating": 1241.5843042924312,
            "rating_q975": 1265.1271978184384,
            "rating_q025": 1218.041410766424
        },
        "gemma-2-9b-it-simpo": {
            "rating": 1240.5285232924407,
            "rating_q975": 1254.9403016116805,
            "rating_q025": 1226.1167449732009
        },
        "claude-3-5-sonnet-20240620": {
            "rating": 1239.0726747875337,
            "rating_q975": 1246.30586956839,
            "rating_q025": 1231.8394800066774
        },
        "athene-70b-0725": {
            "rating": 1238.7211438782963,
            "rating_q975": 1249.720611002624,
            "rating_q025": 1227.7216767539685
        },
        "deepseek-v2.5": {
            "rating": 1238.210544290829,
            "rating_q975": 1248.408138141197,
            "rating_q025": 1228.0129504404608
        },
        "reka-core-20240904": {
            "rating": 1236.0106467180774,
            "rating_q975": 1253.9078975873422,
            "rating_q025": 1218.1133958488126
        },
        "command-r-plus-08-2024": {
            "rating": 1235.9859472610103,
            "rating_q975": 1250.8196172155274,
            "rating_q025": 1221.1522773064933
        },
        "claude-3-opus-20240229": {
            "rating": 1235.9799317629959,
            "rating_q975": 1241.98716540374,
            "rating_q025": 1229.9726981222518
        },
        "athene-v2-chat": {
            "rating": 1234.228450899582,
            "rating_q975": 1243.6534057010822,
            "rating_q025": 1224.8034960980817
        },
        "llama-3.1-70b-instruct": {
            "rating": 1233.8470132673672,
            "rating_q975": 1241.1984093844064,
            "rating_q025": 1226.495617150328
        },
        "gpt-4-0125-preview": {
            "rating": 1233.6161776319816,
            "rating_q975": 1241.3719531013166,
            "rating_q025": 1225.8604021626466
        },
        "llama-3.1-tulu-3-70b": {
            "rating": 1233.1478170238795,
            "rating_q975": 1257.7040785579752,
            "rating_q025": 1208.5915554897838
        },
        "claude-3-5-haiku-20241022": {
            "rating": 1231.752905055201,
            "rating_q975": 1237.9461652047116,
            "rating_q025": 1225.5596449056902
        },
        "gemini-1.5-flash-001": {
            "rating": 1224.143772577842,
            "rating_q975": 1232.1682618676764,
            "rating_q025": 1216.1192832880074
        },
        "qwen2.5-72b-instruct": {
            "rating": 1222.3053672960423,
            "rating_q975": 1230.34339245612,
            "rating_q025": 1214.2673421359646
        },
        "gemini-1.5-flash-8b-001": {
            "rating": 1218.9830953539836,
            "rating_q975": 1227.4395594885889,
            "rating_q025": 1210.5266312193783
        },
        "llama-3.1-nemotron-51b-instruct": {
            "rating": 1213.8541094314328,
            "rating_q975": 1239.383262298284,
            "rating_q025": 1188.3249565645815
        },
        "jamba-1.5-large": {
            "rating": 1213.1139196658373,
            "rating_q975": 1228.942485480347,
            "rating_q025": 1197.2853538513277
        },
        "amazon-nova-pro-v1.0": {
            "rating": 1212.639977494547,
            "rating_q975": 1221.8151697298429,
            "rating_q025": 1203.4647852592514
        },
        "llama-3-70b-instruct": {
            "rating": 1211.7296103109288,
            "rating_q975": 1218.9181934011613,
            "rating_q025": 1204.5410272206964
        },
        "gemma-2-9b-it": {
            "rating": 1206.9296601889585,
            "rating_q975": 1213.958628946462,
            "rating_q025": 1199.9006914314548
        },
        "nemotron-4-340b-instruct": {
            "rating": 1203.776024565058,
            "rating_q975": 1215.1371843968054,
            "rating_q025": 1192.4148647333104
        },
        "reka-flash-20240904": {
            "rating": 1203.0000665743923,
            "rating_q975": 1220.371953179056,
            "rating_q025": 1185.6281799697288
        },
        "command-r-plus": {
            "rating": 1202.1303488054834,
            "rating_q975": 1210.390963153218,
            "rating_q025": 1193.8697344577488
        },
        "gpt-oss-20b": {
            "rating": 1201.92753735785,
            "rating_q975": 1219.4006629284083,
            "rating_q025": 1184.4544117872917
        },
        "c4ai-aya-expanse-32b": {
            "rating": 1201.1101424052522,
            "rating_q975": 1210.7120778823019,
            "rating_q025": 1191.5082069282025
        },
        "olmo-2-0325-32b-instruct": {
            "rating": 1200.2086475096921,
            "rating_q975": 1224.7689196984606,
            "rating_q025": 1175.6483753209236
        },
        "glm-4-0520": {
            "rating": 1199.720398937123,
            "rating_q975": 1214.6736394289142,
            "rating_q025": 1184.767158445332
        },
        "amazon-nova-lite-v1.0": {
            "rating": 1197.3956103409155,
            "rating_q975": 1207.578659372571,
            "rating_q025": 1187.2125613092599
        },
        "mistral-small-24b-instruct-2501": {
            "rating": 1195.91966203619,
            "rating_q975": 1207.7987231942523,
            "rating_q025": 1184.0406008781276
        },
        "gpt-4-0613": {
            "rating": 1192.404003878824,
            "rating_q975": 1200.3959128865463,
            "rating_q025": 1184.4120948711015
        },
        "gpt-4-0314": {
            "rating": 1191.4977245104815,
            "rating_q975": 1201.1687861918074,
            "rating_q025": 1181.8266628291556
        },
        "claude-3-sonnet-20240229": {
            "rating": 1187.599934233963,
            "rating_q975": 1195.5255461217644,
            "rating_q025": 1179.6743223461617
        },
        "qwen2-72b-instruct": {
            "rating": 1182.8353316639518,
            "rating_q975": 1192.0176610253795,
            "rating_q025": 1173.653002302524
        },
        "phi-4": {
            "rating": 1182.5261143770763,
            "rating_q975": 1191.8983114072087,
            "rating_q025": 1173.153917346944
        },
        "llama-3.1-tulu-3-8b": {
            "rating": 1180.3051024264737,
            "rating_q975": 1205.658682971994,
            "rating_q025": 1154.9515218809534
        },
        "ministral-8b-2410": {
            "rating": 1175.1401670964588,
            "rating_q975": 1196.6265119161562,
            "rating_q025": 1153.6538222767613
        },
        "amazon-nova-micro-v1.0": {
            "rating": 1173.5741932601995,
            "rating_q975": 1183.9823299009126,
            "rating_q025": 1163.1660566194864
        },
        "qwen2.5-coder-32b-instruct": {
            "rating": 1172.1813721616056,
            "rating_q975": 1191.208338848515,
            "rating_q025": 1153.1544054746962
        },
        "command-r-08-2024": {
            "rating": 1172.1110743341105,
            "rating_q975": 1187.2608308572649,
            "rating_q025": 1156.9613178109562
        },
        "c4ai-aya-expanse-8b": {
            "rating": 1170.277095404227,
            "rating_q975": 1184.972981122832,
            "rating_q025": 1155.5812096856223
        },
        "hunyuan-standard-256k": {
            "rating": 1168.4533586307612,
            "rating_q975": 1197.3075180548396,
            "rating_q025": 1139.5991992066827
        },
        "jamba-1.5-mini": {
            "rating": 1165.1749617587816,
            "rating_q975": 1180.5895928600737,
            "rating_q025": 1149.7603306574895
        },
        "mistral-large-2402": {
            "rating": 1162.7112983208585,
            "rating_q975": 1171.7853369214502,
            "rating_q025": 1153.637259720267
        },
        "mistral-medium": {
            "rating": 1160.0063040732775,
            "rating_q975": 1170.5920531602735,
            "rating_q025": 1149.4205549862816
        },
        "claude-3-haiku-20240307": {
            "rating": 1159.119866635474,
            "rating_q975": 1166.28612850381,
            "rating_q025": 1151.953604767138
        },
        "command-r": {
            "rating": 1156.4874525157397,
            "rating_q975": 1165.9193978754904,
            "rating_q025": 1147.055507155989
        },
        "llama-3.1-8b-instruct": {
            "rating": 1156.2692432398408,
            "rating_q975": 1164.1776718113556,
            "rating_q025": 1148.360814668326
        },
        "llama-3-8b-instruct": {
            "rating": 1151.793454887851,
            "rating_q975": 1159.5632507479759,
            "rating_q025": 1144.0236590277264
        },
        "wizardlm-70b": {
            "rating": 1151.249860980076,
            "rating_q975": 1168.0170069622036,
            "rating_q025": 1134.4827149979483
        },
        "qwen1.5-110b-chat": {
            "rating": 1149.900402136098,
            "rating_q975": 1161.2066931815052,
            "rating_q025": 1138.5941110906906
        },
        "gemma-2-2b-it": {
            "rating": 1148.434677836507,
            "rating_q975": 1156.1841254116173,
            "rating_q025": 1140.6852302613968
        },
        "mixtral-8x22b-instruct-v0.1": {
            "rating": 1142.6504295658146,
            "rating_q975": 1151.5965288531766,
            "rating_q025": 1133.7043302784527
        },
        "qwen1.5-72b-chat": {
            "rating": 1138.2491191049542,
            "rating_q975": 1148.0325746094734,
            "rating_q025": 1128.465663600435
        },
        "yi-1.5-34b-chat": {
            "rating": 1135.9063659180888,
            "rating_q975": 1146.709832104113,
            "rating_q025": 1125.1028997320645
        },
        "qwq-32b-preview": {
            "rating": 1134.172083925706,
            "rating_q975": 1162.6389980383744,
            "rating_q025": 1105.7051698130374
        },
        "reka-flash-21b-20240226-online": {
            "rating": 1132.7901118133054,
            "rating_q975": 1146.9879046356007,
            "rating_q025": 1118.5923189910102
        },
        "gemini-pro-dev-api": {
            "rating": 1132.3325677577627,
            "rating_q975": 1146.041383020055,
            "rating_q025": 1118.6237524954704
        },
        "granite-3.1-8b-instruct": {
            "rating": 1129.363865906625,
            "rating_q975": 1155.954623578617,
            "rating_q025": 1102.7731082346331
        },
        "vicuna-33b": {
            "rating": 1127.7237431474553,
            "rating_q975": 1139.4922182541359,
            "rating_q025": 1115.9552680407746
        },
        "openchat-3.5": {
            "rating": 1127.374086353215,
            "rating_q975": 1145.3973591046997,
            "rating_q025": 1109.3508136017304
        },
        "reka-flash-21b-20240226": {
            "rating": 1126.6568598218137,
            "rating_q975": 1138.5726498195068,
            "rating_q025": 1114.7410698241206
        },
        "internlm2_5-20b-chat": {
            "rating": 1123.4744681781426,
            "rating_q975": 1139.1922976573865,
            "rating_q025": 1107.7566386988988
        },
        "deepseek-coder-v2": {
            "rating": 1122.4883075387256,
            "rating_q975": 1135.6646572258358,
            "rating_q025": 1109.3119578516155
        },
        "granite-3.1-2b-instruct": {
            "rating": 1119.0122300382448,
            "rating_q975": 1148.057321437643,
            "rating_q025": 1089.9671386388466
        },
        "zephyr-orpo-141b-A35b-v0.1": {
            "rating": 1113.5776560987586,
            "rating_q975": 1136.6679663025536,
            "rating_q025": 1090.4873458949635
        },
        "yi-34b-chat": {
            "rating": 1110.6235613023218,
            "rating_q975": 1124.126815852054,
            "rating_q025": 1097.1203067525896
        },
        "mixtral-8x7b-instruct-v0.1": {
            "rating": 1110.4912985166875,
            "rating_q975": 1118.7983922048008,
            "rating_q025": 1102.1842048285741
        },
        "phi-3-medium-4k-instruct": {
            "rating": 1107.7730640546529,
            "rating_q975": 1118.2927610773672,
            "rating_q025": 1097.2533670319385
        },
        "dbrx-instruct-preview": {
            "rating": 1107.0205662040378,
            "rating_q975": 1118.363044009887,
            "rating_q025": 1095.6780883981885
        },
        "tulu-2-dpo-70b": {
            "rating": 1106.964658346569,
            "rating_q975": 1126.2221864064384,
            "rating_q025": 1087.7071302866996
        },
        "gemini-pro": {
            "rating": 1105.117511872823,
            "rating_q975": 1126.0479507956854,
            "rating_q025": 1084.1870729499603
        },
        "nous-hermes-2-mixtral-8x7b-dpo": {
            "rating": 1103.7547792032801,
            "rating_q975": 1127.16223613927,
            "rating_q025": 1080.3473222672903
        },
        "zephyr-7b-beta": {
            "rating": 1103.4609653442571,
            "rating_q975": 1119.373396378008,
            "rating_q025": 1087.5485343105063
        },
        "starling-lm-7b-alpha": {
            "rating": 1100.4566416887847,
            "rating_q975": 1115.7309305708873,
            "rating_q025": 1085.182352806682
        },
        "openhermes-2.5-mistral-7b": {
            "rating": 1099.2642117723353,
            "rating_q975": 1121.0322393585227,
            "rating_q025": 1077.496184186148
        },
        "starling-lm-7b-beta": {
            "rating": 1098.4301388322501,
            "rating_q975": 1112.6730083894706,
            "rating_q025": 1084.1872692750296
        },
        "llama-3.2-3b-instruct": {
            "rating": 1095.2074096710287,
            "rating_q975": 1113.9987440539812,
            "rating_q025": 1076.4160752880762
        },
        "gpt-3.5-turbo-0125": {
            "rating": 1094.1825023699025,
            "rating_q975": 1102.701534610622,
            "rating_q025": 1085.663470129183
        },
        "openchat-3.5-0106": {
            "rating": 1093.9879348290401,
            "rating_q975": 1108.7205288325833,
            "rating_q025": 1079.255340825497
        },
        "solar-10.7b-instruct-v1.0": {
            "rating": 1093.3377510187756,
            "rating_q975": 1117.598039276212,
            "rating_q025": 1069.0774627613393
        },
        "qwen1.5-14b-chat": {
            "rating": 1093.0140764463918,
            "rating_q975": 1106.9443645521915,
            "rating_q025": 1079.083788340592
        },
        "llama2-70b-steerlm-chat": {
            "rating": 1092.3627388360567,
            "rating_q975": 1116.9761575751024,
            "rating_q025": 1067.749320097011
        },
        "wizardlm-13b": {
            "rating": 1091.910656213783,
            "rating_q975": 1109.7986656001224,
            "rating_q025": 1074.0226468274439
        },
        "falcon-180b-chat": {
            "rating": 1090.6583351497102,
            "rating_q975": 1128.2812048268838,
            "rating_q025": 1053.0354654725365
        },
        "dolphin-2.2.1-mistral-7b": {
            "rating": 1087.643888757787,
            "rating_q975": 1121.6775523306007,
            "rating_q025": 1053.6102251849732
        },
        "qwen1.5-32b-chat": {
            "rating": 1085.9754214015184,
            "rating_q975": 1098.0576588163804,
            "rating_q025": 1073.8931839866564
        },
        "phi-3-small-8k-instruct": {
            "rating": 1084.995543836961,
            "rating_q975": 1097.7249905815793,
            "rating_q025": 1072.2660970923425
        },
        "snowflake-arctic-instruct": {
            "rating": 1083.714960367813,
            "rating_q975": 1095.5039599985334,
            "rating_q025": 1071.9259607370927
        },
        "guanaco-33b": {
            "rating": 1081.0122357445566,
            "rating_q975": 1108.690860758882,
            "rating_q025": 1053.3336107302312
        },
        "llama-2-70b-chat": {
            "rating": 1077.3149364073097,
            "rating_q975": 1087.1927221172018,
            "rating_q025": 1067.4371506974176
        },
        "mpt-30b-chat": {
            "rating": 1077.2432092239155,
            "rating_q975": 1106.3241204939156,
            "rating_q025": 1048.1622979539154
        },
        "granite-3.0-8b-instruct": {
            "rating": 1073.7606344157705,
            "rating_q975": 1094.135859747292,
            "rating_q025": 1053.385409084249
        },
        "zephyr-7b-alpha": {
            "rating": 1072.100861527705,
            "rating_q975": 1102.6603317225113,
            "rating_q025": 1041.541391332899
        },
        "mistral-7b-instruct-v0.2": {
            "rating": 1070.407138972343,
            "rating_q975": 1082.78206491232,
            "rating_q025": 1058.0322130323661
        },
        "deepseek-llm-67b-chat": {
            "rating": 1067.1265860948774,
            "rating_q975": 1089.1536583994796,
            "rating_q025": 1045.0995137902753
        },
        "gemma-1.1-7b-it": {
            "rating": 1062.8352232205923,
            "rating_q975": 1074.2504817788604,
            "rating_q025": 1051.4199646623242
        },
        "vicuna-13b": {
            "rating": 1059.3337786714796,
            "rating_q975": 1071.8756257423233,
            "rating_q025": 1046.791931600636
        },
        "llama-2-13b-chat": {
            "rating": 1049.3960142472265,
            "rating_q975": 1061.748592423675,
            "rating_q025": 1037.043436070778
        },
        "granite-3.0-2b-instruct": {
            "rating": 1047.544116280127,
            "rating_q975": 1068.2991058882503,
            "rating_q025": 1026.7891266720035
        },
        "phi-3-mini-4k-instruct-june-2024": {
            "rating": 1044.803804006718,
            "rating_q975": 1059.105373039851,
            "rating_q025": 1030.5022349735852
        },
        "phi-3-mini-4k-instruct": {
            "rating": 1037.1537018642766,
            "rating_q975": 1049.57216044908,
            "rating_q025": 1024.7352432794733
        },
        "llama-3.2-1b-instruct": {
            "rating": 1036.229014276948,
            "rating_q975": 1055.8029663729465,
            "rating_q025": 1016.6550621809496
        },
        "gpt-3.5-turbo-1106": {
            "rating": 1036.2042771420943,
            "rating_q975": 1051.4544086209014,
            "rating_q025": 1020.9541456632871
        },
        "llama-2-7b-chat": {
            "rating": 1035.820834439157,
            "rating_q975": 1049.2923176803954,
            "rating_q025": 1022.3493511979185
        },
        "qwen1.5-7b-chat": {
            "rating": 1034.8330680068982,
            "rating_q975": 1057.3768710632162,
            "rating_q025": 1012.2892649505801
        },
        "smollm2-1.7b-instruct": {
            "rating": 1033.0936558640421,
            "rating_q975": 1068.1830904250396,
            "rating_q025": 998.0042213030447
        },
        "stripedhyena-nous-7b": {
            "rating": 1033.0108097192965,
            "rating_q975": 1053.799679075612,
            "rating_q025": 1012.2219403629811
        },
        "codellama-34b-instruct": {
            "rating": 1032.7640725448005,
            "rating_q975": 1049.3526521781503,
            "rating_q025": 1016.1754929114506
        },
        "mistral-7b-instruct": {
            "rating": 1032.4831255138386,
            "rating_q975": 1049.3636598745472,
            "rating_q025": 1015.6025911531299
        },
        "qwen-14b-chat": {
            "rating": 1029.9328923158491,
            "rating_q975": 1050.7065907838094,
            "rating_q025": 1009.159193847889
        },
        "phi-3-mini-128k-instruct": {
            "rating": 1027.8801866990586,
            "rating_q975": 1041.6319394819918,
            "rating_q025": 1014.1284339161256
        },
        "gemma-7b-it": {
            "rating": 1025.801570316636,
            "rating_q975": 1043.3803623845226,
            "rating_q025": 1008.222778248749
        },
        "vicuna-7b": {
            "rating": 1023.7957509756221,
            "rating_q975": 1041.7375650042109,
            "rating_q025": 1005.8539369470335
        },
        "gemma-1.1-2b-it": {
            "rating": 999.8001113805045,
            "rating_q975": 1016.4714475651471,
            "rating_q025": 983.128775195862
        },
        "palm-2": {
            "rating": 994.2830584025244,
            "rating_q975": 1011.6046788264789,
            "rating_q025": 976.9614379785698
        },
        "olmo-7b-instruct": {
            "rating": 993.2830682857527,
            "rating_q975": 1013.4676786604159,
            "rating_q025": 973.0984579110896
        },
        "gemma-2b-it": {
            "rating": 988.1640281897353,
            "rating_q975": 1011.4842704998499,
            "rating_q025": 964.8437858796207
        },
        "gpt4all-13b-snoozy": {
            "rating": 974.5907449230299,
            "rating_q975": 1012.7120708160537,
            "rating_q025": 936.4694190300061
        },
        "koala-13b": {
            "rating": 974.3288834448933,
            "rating_q975": 994.9689227530423,
            "rating_q025": 953.6888441367444
        },
        "chatglm3-6b": {
            "rating": 972.6772059130672,
            "rating_q975": 995.781827471898,
            "rating_q025": 949.5725843542363
        },
        "alpaca-13b": {
            "rating": 970.9521091934563,
            "rating_q975": 993.3242342193738,
            "rating_q025": 948.5799841675388
        },
        "qwen1.5-4b-chat": {
            "rating": 970.6255291951868,
            "rating_q975": 989.3738222145663,
            "rating_q025": 951.8772361758073
        },
        "mpt-7b-chat": {
            "rating": 958.4532039043869,
            "rating_q975": 982.4459109619272,
            "rating_q025": 934.4604968468466
        },
        "chatglm2-6b": {
            "rating": 944.6809301938001,
            "rating_q975": 971.1579545085342,
            "rating_q025": 918.203905879066
        },
        "RWKV-4-Raven-14B": {
            "rating": 935.9337176013601,
            "rating_q975": 958.4554357267526,
            "rating_q025": 913.4119994759675
        },
        "oasst-pythia-12b": {
            "rating": 924.7580704653808,
            "rating_q975": 945.0225321259918,
            "rating_q025": 904.4936088047698
        },
        "fastchat-t5-3b": {
            "rating": 902.4368475726301,
            "rating_q975": 926.1093838765457,
            "rating_q025": 878.7643112687144
        },
        "chatglm-6b": {
            "rating": 902.1462819332302,
            "rating_q975": 926.4928973110665,
            "rating_q025": 877.7996665553939
        },
        "stablelm-tuned-alpha-7b": {
            "rating": 868.9860206292531,
            "rating_q975": 896.9852506168843,
            "rating_q025": 840.9867906416218
        },
        "dolly-v2-12b": {
            "rating": 865.6094952295578,
            "rating_q975": 893.1537555212467,
            "rating_q025": 838.0652349378688
        },
        "llama-13b": {
            "rating": 797.249370879221,
            "rating_q975": 830.0344071806151,
            "rating_q025": 764.464334577827
        }
    },
    "english": {
        "gemini-2.5-pro": {
            "rating": 1463.4516523825964,
            "rating_q975": 1468.408458604803,
            "rating_q025": 1458.49484616039
        },
        "glm-4.6": {
            "rating": 1454.7445603641936,
            "rating_q975": 1463.3157572433165,
            "rating_q025": 1446.1733634850707
        },
        "claude-sonnet-4-5-20250929-thinking-32k": {
            "rating": 1444.6142569817332,
            "rating_q975": 1452.5981620894217,
            "rating_q025": 1436.6303518740447
        },
        "longcat-flash-chat": {
            "rating": 1441.5613999148654,
            "rating_q975": 1449.855799965174,
            "rating_q025": 1433.266999864557
        },
        "qwen3-max-preview": {
            "rating": 1441.2127606021195,
            "rating_q975": 1447.5326494291646,
            "rating_q025": 1434.8928717750744
        },
        "mistral-medium-2508": {
            "rating": 1439.8857457249685,
            "rating_q975": 1445.8341036253578,
            "rating_q025": 1433.9373878245792
        },
        "deepseek-v3.2-exp": {
            "rating": 1439.5659219155816,
            "rating_q975": 1480.445462496538,
            "rating_q025": 1398.6863813346251
        },
        "deepseek-v3.2-exp-thinking": {
            "rating": 1437.953085220539,
            "rating_q975": 1447.0013051444555,
            "rating_q025": 1428.9048652966223
        },
        "claude-sonnet-4-5-20250929": {
            "rating": 1436.6512805165712,
            "rating_q975": 1446.8648585207452,
            "rating_q025": 1426.4377025123972
        },
        "grok-3-preview-02-24": {
            "rating": 1436.100638633243,
            "rating_q975": 1441.314789215612,
            "rating_q025": 1430.886488050874
        },
        "claude-opus-4-1-20250805-thinking-16k": {
            "rating": 1436.0168653960725,
            "rating_q975": 1442.095264830465,
            "rating_q025": 1429.9384659616799
        },
        "glm-4.5": {
            "rating": 1432.6465625504502,
            "rating_q975": 1438.9693507341021,
            "rating_q025": 1426.3237743667983
        },
        "deepseek-r1-0528": {
            "rating": 1432.5564369381764,
            "rating_q975": 1439.6343113834478,
            "rating_q025": 1425.478562492905
        },
        "deepseek-v3.1-thinking": {
            "rating": 1432.451434200582,
            "rating_q975": 1441.0190983527486,
            "rating_q025": 1423.8837700484155
        },
        "deepseek-v3.1": {
            "rating": 1430.9490010327036,
            "rating_q975": 1438.75251465984,
            "rating_q025": 1423.145487405567
        },
        "qwen3-vl-235b-a22b-instruct": {
            "rating": 1430.7243849825848,
            "rating_q975": 1439.7851467975804,
            "rating_q025": 1421.663623167589
        },
        "chatgpt-4o-latest-20250326": {
            "rating": 1429.683623993742,
            "rating_q975": 1434.4667337427866,
            "rating_q025": 1424.9005142446974
        },
        "qwen3-next-80b-a3b-instruct": {
            "rating": 1428.9472620496717,
            "rating_q975": 1435.6399762858834,
            "rating_q025": 1422.25454781346
        },
        "deepseek-v3.1-terminus-thinking": {
            "rating": 1427.9426637836073,
            "rating_q975": 1442.2406907405332,
            "rating_q025": 1413.6446368266813
        },
        "qwen3-235b-a22b-thinking-2507": {
            "rating": 1426.8835183865458,
            "rating_q975": 1435.751295294666,
            "rating_q025": 1418.0157414784255
        },
        "claude-opus-4-1-20250805": {
            "rating": 1425.251585246211,
            "rating_q975": 1430.839811359227,
            "rating_q025": 1419.6633591331952
        },
        "deepseek-v3.1-terminus": {
            "rating": 1424.3631551384715,
            "rating_q975": 1438.1167078078047,
            "rating_q025": 1410.6096024691383
        },
        "qwen3-235b-a22b-instruct-2507": {
            "rating": 1422.248569595586,
            "rating_q975": 1427.8212057854785,
            "rating_q025": 1416.6759334056937
        },
        "qwen3-max-2025-09-23": {
            "rating": 1420.4190662572414,
            "rating_q975": 1429.142600299031,
            "rating_q025": 1411.6955322154517
        },
        "grok-4-0709": {
            "rating": 1420.1374658104924,
            "rating_q975": 1425.5639877081462,
            "rating_q025": 1414.7109439128385
        },
        "gpt-4.5-preview-2025-02-27": {
            "rating": 1419.2922966344,
            "rating_q975": 1426.2896871288478,
            "rating_q025": 1412.294906139952
        },
        "o3-2025-04-16": {
            "rating": 1417.1946945990114,
            "rating_q975": 1421.9320115362425,
            "rating_q025": 1412.4573776617804
        },
        "qwen3-vl-235b-a22b-thinking": {
            "rating": 1415.9575717198618,
            "rating_q975": 1425.416004307785,
            "rating_q025": 1406.4991391319386
        },
        "gemini-2.5-flash": {
            "rating": 1415.4178967120633,
            "rating_q975": 1420.24009036865,
            "rating_q025": 1410.5957030554766
        },
        "grok-4-fast": {
            "rating": 1415.417700324012,
            "rating_q975": 1425.7119784695956,
            "rating_q025": 1405.1234221784284
        },
        "gemini-2.5-flash-preview-09-2025": {
            "rating": 1414.8230419785054,
            "rating_q975": 1422.4136156438326,
            "rating_q025": 1407.2324683131783
        },
        "claude-haiku-4-5-20251001": {
            "rating": 1412.684620707894,
            "rating_q975": 1421.2776609173482,
            "rating_q025": 1404.09158049844
        },
        "gpt-5-high": {
            "rating": 1410.4632525656643,
            "rating_q975": 1416.4550443723708,
            "rating_q025": 1404.4714607589578
        },
        "gpt-5-chat": {
            "rating": 1408.5661785625332,
            "rating_q975": 1414.485850275941,
            "rating_q025": 1402.6465068491254
        },
        "mai-1-preview": {
            "rating": 1405.423074092872,
            "rating_q975": 1412.4839400002677,
            "rating_q025": 1398.3622081854762
        },
        "hunyuan-t1-20250711": {
            "rating": 1395.7421172559134,
            "rating_q975": 1408.2876842361595,
            "rating_q025": 1383.1965502756673
        },
        "glm-4.5-air": {
            "rating": 1394.7212483525177,
            "rating_q975": 1400.5483563771102,
            "rating_q025": 1388.8941403279252
        },
        "qwen3-235b-a22b-no-thinking": {
            "rating": 1393.7737412339097,
            "rating_q975": 1399.2579819835482,
            "rating_q025": 1388.2895004842712
        },
        "gpt-4.1-2025-04-14": {
            "rating": 1392.9200772157594,
            "rating_q975": 1397.7871552375834,
            "rating_q025": 1388.0529991939354
        },
        "qwen3-next-80b-a3b-thinking": {
            "rating": 1391.8799645639256,
            "rating_q975": 1399.5170436330334,
            "rating_q025": 1384.2428854948178
        },
        "qwen3-30b-a3b-instruct-2507": {
            "rating": 1391.8016330265286,
            "rating_q975": 1398.1526089293257,
            "rating_q025": 1385.4506571237316
        },
        "ling-flash-2.0": {
            "rating": 1388.5322042860744,
            "rating_q975": 1398.4414136984437,
            "rating_q025": 1378.622994873705
        },
        "claude-opus-4-20250514-thinking-16k": {
            "rating": 1386.764580826215,
            "rating_q975": 1392.3528686292714,
            "rating_q025": 1381.1762930231587
        },
        "deepseek-v3-0324": {
            "rating": 1386.2642135433784,
            "rating_q975": 1391.0983573930055,
            "rating_q025": 1381.4300696937514
        },
        "deepseek-r1": {
            "rating": 1384.3202571801035,
            "rating_q975": 1390.2796626613476,
            "rating_q025": 1378.3608516988593
        },
        "hunyuan-turbos-20250416": {
            "rating": 1383.7762633171749,
            "rating_q975": 1391.8196096659397,
            "rating_q025": 1375.73291696841
        },
        "kimi-k2-0905-preview": {
            "rating": 1382.4587735570553,
            "rating_q975": 1391.2069827460962,
            "rating_q025": 1373.7105643680145
        },
        "gpt-5-mini-high": {
            "rating": 1381.9078200433323,
            "rating_q975": 1388.250870866452,
            "rating_q025": 1375.5647692202126
        },
        "o1-preview": {
            "rating": 1381.884193767273,
            "rating_q975": 1387.9984899636488,
            "rating_q025": 1375.7698975708972
        },
        "gemini-2.5-flash-lite-preview-09-2025-no-thinking": {
            "rating": 1381.1721884256888,
            "rating_q975": 1388.5810199811642,
            "rating_q025": 1373.7633568702133
        },
        "mistral-medium-2505": {
            "rating": 1380.9918788039313,
            "rating_q975": 1386.6972094766309,
            "rating_q025": 1375.2865481312317
        },
        "grok-3-mini-high": {
            "rating": 1377.4407320464286,
            "rating_q975": 1384.2389320380753,
            "rating_q025": 1370.642532054782
        },
        "amazon-nova-experimental-chat-10-09": {
            "rating": 1377.3423958184544,
            "rating_q975": 1387.8092372475426,
            "rating_q025": 1366.8755543893662
        },
        "qwen3-235b-a22b": {
            "rating": 1377.3244604684157,
            "rating_q975": 1383.1811493189346,
            "rating_q025": 1371.467771617897
        },
        "claude-opus-4-20250514": {
            "rating": 1375.349613567228,
            "rating_q975": 1380.7221787397168,
            "rating_q025": 1369.9770483947393
        },
        "qwen2.5-max": {
            "rating": 1375.276169497664,
            "rating_q975": 1380.1709636104586,
            "rating_q025": 1370.3813753848692
        },
        "kimi-k2-0711-preview": {
            "rating": 1374.9250354524968,
            "rating_q975": 1381.0354815737946,
            "rating_q025": 1368.814589331199
        },
        "gemini-2.5-flash-lite-preview-06-17-thinking": {
            "rating": 1374.24204875182,
            "rating_q975": 1379.8547993789002,
            "rating_q025": 1368.6292981247398
        },
        "gemma-3-27b-it": {
            "rating": 1373.3252671755056,
            "rating_q975": 1377.8308939235542,
            "rating_q025": 1368.819640427457
        },
        "gpt-oss-120b": {
            "rating": 1372.6741898502084,
            "rating_q975": 1378.6756172943074,
            "rating_q025": 1366.6727624061095
        },
        "grok-3-mini-beta": {
            "rating": 1372.662779102141,
            "rating_q975": 1378.8607365249038,
            "rating_q025": 1366.4648216793782
        },
        "o1-2024-12-17": {
            "rating": 1371.4903826313057,
            "rating_q975": 1376.8600827293171,
            "rating_q025": 1366.1206825332943
        },
        "minimax-m1": {
            "rating": 1371.208274629718,
            "rating_q975": 1376.5577584410053,
            "rating_q025": 1365.8587908184309
        },
        "step-3": {
            "rating": 1370.6972273602626,
            "rating_q975": 1381.0173140609331,
            "rating_q025": 1360.377140659592
        },
        "o4-mini-2025-04-16": {
            "rating": 1367.7556761286673,
            "rating_q975": 1372.6876555379163,
            "rating_q025": 1362.8236967194184
        },
        "claude-sonnet-4-20250514-thinking-32k": {
            "rating": 1366.912939621179,
            "rating_q975": 1372.5289848985485,
            "rating_q025": 1361.2968943438095
        },
        "ring-flash-2.0": {
            "rating": 1365.7289052412268,
            "rating_q975": 1375.5961484625534,
            "rating_q025": 1355.8616620199002
        },
        "qwen3-coder-480b-a35b-instruct": {
            "rating": 1364.324673628586,
            "rating_q975": 1370.6809224699375,
            "rating_q025": 1357.9684247872344
        },
        "mistral-small-2506": {
            "rating": 1361.9379328675898,
            "rating_q975": 1368.620234486092,
            "rating_q025": 1355.2556312490876
        },
        "glm-4.5v": {
            "rating": 1359.3625701499693,
            "rating_q975": 1371.3725277945011,
            "rating_q025": 1347.3526125054375
        },
        "nvidia-llama-3.3-nemotron-super-49b-v1.5": {
            "rating": 1358.586003927177,
            "rating_q975": 1372.682646697708,
            "rating_q025": 1344.489361156646
        },
        "qwen3-32b": {
            "rating": 1358.5203840721879,
            "rating_q975": 1370.8343098021783,
            "rating_q025": 1346.2064583421975
        },
        "gpt-4.1-mini-2025-04-14": {
            "rating": 1356.9694580078249,
            "rating_q975": 1362.2496806778986,
            "rating_q025": 1351.6892353377511
        },
        "step-1o-turbo-202506": {
            "rating": 1353.2905025084724,
            "rating_q975": 1362.2427095959704,
            "rating_q025": 1344.3382954209744
        },
        "llama-3.3-nemotron-49b-super-v1": {
            "rating": 1353.1930993595524,
            "rating_q975": 1368.7664927430285,
            "rating_q025": 1337.6197059760764
        },
        "o3-mini-high": {
            "rating": 1350.1258832805543,
            "rating_q975": 1356.5094734219695,
            "rating_q025": 1343.742293139139
        },
        "qwq-32b": {
            "rating": 1349.012576766391,
            "rating_q975": 1354.5124603201207,
            "rating_q025": 1343.5126932126614
        },
        "claude-sonnet-4-20250514": {
            "rating": 1348.1865437524539,
            "rating_q975": 1353.6435294735754,
            "rating_q025": 1342.7295580313323
        },
        "gemma-3-12b-it": {
            "rating": 1347.6225087114601,
            "rating_q975": 1359.3926703244506,
            "rating_q025": 1335.8523470984696
        },
        "deepseek-v3": {
            "rating": 1346.0359777630326,
            "rating_q975": 1351.777227890975,
            "rating_q025": 1340.2947276350903
        },
        "step-2-16k-exp-202412": {
            "rating": 1344.290538715263,
            "rating_q975": 1354.9608546696654,
            "rating_q025": 1333.6202227608605
        },
        "llama-3.1-nemotron-ultra-253b-v1": {
            "rating": 1344.2278361834153,
            "rating_q975": 1359.021207900555,
            "rating_q025": 1329.4344644662756
        },
        "command-a-03-2025": {
            "rating": 1341.2940459971535,
            "rating_q975": 1345.7636685851812,
            "rating_q025": 1336.8244234091258
        },
        "glm-4-plus-0111": {
            "rating": 1340.9000539925498,
            "rating_q975": 1351.1144280031303,
            "rating_q025": 1330.6856799819693
        },
        "o1-mini": {
            "rating": 1340.297161259418,
            "rating_q975": 1344.8132932801293,
            "rating_q025": 1335.7810292387069
        },
        "qwen-plus-0125": {
            "rating": 1338.3264086921974,
            "rating_q975": 1348.6777597082294,
            "rating_q025": 1327.9750576761655
        },
        "qwen3-30b-a3b": {
            "rating": 1335.2158365754603,
            "rating_q975": 1341.1328079980958,
            "rating_q025": 1329.2988651528249
        },
        "o3-mini": {
            "rating": 1334.1410373389608,
            "rating_q975": 1338.3650021095348,
            "rating_q025": 1329.9170725683869
        },
        "gemini-2.0-flash-lite-preview-02-05": {
            "rating": 1332.9497245882562,
            "rating_q975": 1338.210514088881,
            "rating_q025": 1327.6889350876315
        },
        "hunyuan-turbos-20250226": {
            "rating": 1332.0107771678154,
            "rating_q975": 1346.8925428144469,
            "rating_q025": 1317.1290115211839
        },
        "yi-lightning": {
            "rating": 1330.1720495749214,
            "rating_q975": 1336.530050091902,
            "rating_q025": 1323.8140490579408
        },
        "claude-3-7-sonnet-20250219-thinking-32k": {
            "rating": 1328.261000303945,
            "rating_q975": 1333.4132539842867,
            "rating_q025": 1323.108746623603
        },
        "hunyuan-turbo-0110": {
            "rating": 1328.06821414334,
            "rating_q975": 1342.3781286661297,
            "rating_q025": 1313.7582996205501
        },
        "gpt-5-nano-high": {
            "rating": 1326.224657039882,
            "rating_q975": 1335.6121278039734,
            "rating_q025": 1316.8371862757906
        },
        "gemini-1.5-pro-002": {
            "rating": 1322.7430603487521,
            "rating_q975": 1326.9109796467337,
            "rating_q025": 1318.5751410507705
        },
        "qwen2.5-plus-1127": {
            "rating": 1322.0762157231543,
            "rating_q975": 1329.8028112859233,
            "rating_q025": 1314.3496201603853
        },
        "grok-2-2024-08-13": {
            "rating": 1321.126407236102,
            "rating_q975": 1325.426302963038,
            "rating_q025": 1316.826511509166
        },
        "gemma-3n-e4b-it": {
            "rating": 1321.0608753348745,
            "rating_q975": 1327.466228090467,
            "rating_q025": 1314.655522579282
        },
        "llama-3.1-nemotron-70b-instruct": {
            "rating": 1314.9695264017485,
            "rating_q975": 1324.785032969946,
            "rating_q025": 1305.1540198335508
        },
        "gpt-4o-2024-05-13": {
            "rating": 1312.5188557051802,
            "rating_q975": 1316.8603420535067,
            "rating_q025": 1308.1773693568537
        },
        "llama-3.1-405b-instruct-bf16": {
            "rating": 1312.048444622727,
            "rating_q975": 1316.394614622243,
            "rating_q025": 1307.702274623211
        },
        "deepseek-v2.5-1210": {
            "rating": 1309.7891845668169,
            "rating_q975": 1320.013015001891,
            "rating_q025": 1299.5653541317427
        },
        "llama-3.1-405b-instruct-fp8": {
            "rating": 1308.1355062603118,
            "rating_q975": 1312.638397552031,
            "rating_q025": 1303.6326149685926
        },
        "claude-3-5-sonnet-20241022": {
            "rating": 1308.002246228944,
            "rating_q975": 1311.6192467814287,
            "rating_q025": 1304.3852456764591
        },
        "athene-v2-chat": {
            "rating": 1306.7784940103174,
            "rating_q975": 1312.2918073231526,
            "rating_q025": 1301.2651806974823
        },
        "hunyuan-large-2025-02-10": {
            "rating": 1305.6299512820979,
            "rating_q975": 1317.9194032478251,
            "rating_q025": 1293.3404993163706
        },
        "llama-3.3-70b-instruct": {
            "rating": 1304.7390303476905,
            "rating_q975": 1308.7948952458132,
            "rating_q025": 1300.6831654495677
        },
        "llama-4-maverick-17b-128e-instruct": {
            "rating": 1304.331030166205,
            "rating_q975": 1309.5283198127552,
            "rating_q025": 1299.1337405196548
        },
        "gpt-oss-20b": {
            "rating": 1303.8500957856209,
            "rating_q975": 1312.4553573367568,
            "rating_q025": 1295.2448342344849
        },
        "gpt-4.1-nano-2025-04-14": {
            "rating": 1303.3446660231514,
            "rating_q975": 1313.1417097214762,
            "rating_q025": 1293.5476223248265
        },
        "llama-4-scout-17b-16e-instruct": {
            "rating": 1303.0133857432534,
            "rating_q975": 1308.8541402712635,
            "rating_q025": 1297.1726312152432
        },
        "gpt-4o-mini-2024-07-18": {
            "rating": 1300.6840269583818,
            "rating_q975": 1304.6841389096787,
            "rating_q025": 1296.6839150070848
        },
        "gemma-3-4b-it": {
            "rating": 1300.0872912493696,
            "rating_q975": 1311.648483875404,
            "rating_q025": 1288.5260986233352
        },
        "mistral-small-3.1-24b-instruct-2503": {
            "rating": 1299.8050128231134,
            "rating_q975": 1305.4347919503216,
            "rating_q025": 1294.1752336959053
        },
        "grok-2-mini-2024-08-13": {
            "rating": 1298.433454323453,
            "rating_q975": 1303.0142872098565,
            "rating_q025": 1293.8526214370493
        },
        "gpt-4o-2024-08-06": {
            "rating": 1297.670856949448,
            "rating_q975": 1302.7899587688926,
            "rating_q025": 1292.5517551300036
        },
        "glm-4-plus": {
            "rating": 1296.7398529833454,
            "rating_q975": 1302.9549479670704,
            "rating_q025": 1290.5247579996203
        },
        "llama-3.1-70b-instruct": {
            "rating": 1294.074511877548,
            "rating_q975": 1298.6393310815631,
            "rating_q025": 1289.509692673533
        },
        "qwen-max-0919": {
            "rating": 1292.9773875261153,
            "rating_q975": 1300.135871258479,
            "rating_q025": 1285.8189037937516
        },
        "gpt-4-turbo-2024-04-09": {
            "rating": 1291.560536738165,
            "rating_q975": 1296.2309197659197,
            "rating_q025": 1286.8901537104102
        },
        "gemini-1.5-flash-002": {
            "rating": 1289.4196142709925,
            "rating_q975": 1294.6106972677776,
            "rating_q025": 1284.2285312742074
        },
        "mistral-large-2407": {
            "rating": 1289.1300061923398,
            "rating_q975": 1293.994105530726,
            "rating_q025": 1284.2659068539535
        },
        "athene-70b-0725": {
            "rating": 1287.716518658311,
            "rating_q975": 1294.5049628385104,
            "rating_q025": 1280.9280744781117
        },
        "claude-3-5-sonnet-20240620": {
            "rating": 1287.430192026055,
            "rating_q975": 1291.6816212476274,
            "rating_q025": 1283.1787628044826
        },
        "hunyuan-large-vision": {
            "rating": 1285.3224611927037,
            "rating_q975": 1297.0369061525334,
            "rating_q025": 1273.608016232874
        },
        "deepseek-v2.5": {
            "rating": 1284.6905551509583,
            "rating_q975": 1290.6614382166285,
            "rating_q025": 1278.719672085288
        },
        "mistral-large-2411": {
            "rating": 1283.9741212619106,
            "rating_q975": 1289.170517819602,
            "rating_q025": 1278.777724704219
        },
        "qwen2.5-72b-instruct": {
            "rating": 1282.968141024348,
            "rating_q975": 1287.8814607546435,
            "rating_q025": 1278.0548212940523
        },
        "hunyuan-standard-2025-02-10": {
            "rating": 1282.2412876686953,
            "rating_q975": 1294.6671196855746,
            "rating_q025": 1269.8154556518161
        },
        "gemini-advanced-0514": {
            "rating": 1281.8554177177375,
            "rating_q975": 1287.7415752945349,
            "rating_q025": 1275.9692601409402
        },
        "gemini-1.5-pro-001": {
            "rating": 1279.6293310360784,
            "rating_q975": 1284.5320795565592,
            "rating_q025": 1274.7265825155976
        },
        "llama-3-70b-instruct": {
            "rating": 1277.3284175189083,
            "rating_q975": 1281.7807949531486,
            "rating_q025": 1272.876040084668
        },
        "magistral-medium-2506": {
            "rating": 1277.3081231292585,
            "rating_q975": 1286.1459344525847,
            "rating_q025": 1268.4703118059324
        },
        "gpt-4-1106-preview": {
            "rating": 1277.2850900064882,
            "rating_q975": 1281.9745121273575,
            "rating_q025": 1272.595667885619
        },
        "gpt-4-0125-preview": {
            "rating": 1276.4350170314028,
            "rating_q975": 1281.344439542228,
            "rating_q025": 1271.5255945205777
        },
        "amazon-nova-pro-v1.0": {
            "rating": 1275.7372553007517,
            "rating_q975": 1281.0366890234038,
            "rating_q025": 1270.4378215780996
        },
        "llama-3.1-tulu-3-70b": {
            "rating": 1272.1387273958962,
            "rating_q975": 1285.3758226103273,
            "rating_q025": 1258.9016321814652
        },
        "claude-3-5-haiku-20241022": {
            "rating": 1269.6530670311877,
            "rating_q975": 1273.505874582548,
            "rating_q025": 1265.8002594798274
        },
        "jamba-1.5-large": {
            "rating": 1267.3252596634777,
            "rating_q975": 1276.4254284088427,
            "rating_q025": 1258.2250909181128
        },
        "llama-3.1-nemotron-51b-instruct": {
            "rating": 1266.7919242624844,
            "rating_q975": 1280.3308903433015,
            "rating_q025": 1253.2529581816673
        },
        "claude-3-opus-20240229": {
            "rating": 1262.8692618179243,
            "rating_q975": 1266.5678926586709,
            "rating_q025": 1259.1706309771778
        },
        "mistral-small-24b-instruct-2501": {
            "rating": 1256.397061689198,
            "rating_q975": 1263.2945921535643,
            "rating_q025": 1249.4995312248316
        },
        "reka-core-20240904": {
            "rating": 1255.749378499318,
            "rating_q975": 1264.9241067108085,
            "rating_q025": 1246.5746502878276
        },
        "olmo-2-0325-32b-instruct": {
            "rating": 1255.5943109957761,
            "rating_q975": 1268.5484544334606,
            "rating_q025": 1242.6401675580917
        },
        "qwen2.5-coder-32b-instruct": {
            "rating": 1247.7893794548672,
            "rating_q975": 1258.8561634691953,
            "rating_q025": 1236.7225954405392
        },
        "gemini-1.5-flash-001": {
            "rating": 1243.8443810331353,
            "rating_q975": 1249.009951181233,
            "rating_q025": 1238.6788108850376
        },
        "amazon-nova-lite-v1.0": {
            "rating": 1242.9164608892047,
            "rating_q975": 1249.0277699429625,
            "rating_q025": 1236.8051518354468
        },
        "gemma-2-9b-it-simpo": {
            "rating": 1242.877503989138,
            "rating_q975": 1251.4863878946067,
            "rating_q025": 1234.2686200836692
        },
        "gemma-2-27b-it": {
            "rating": 1242.3494429103746,
            "rating_q975": 1246.3597313363016,
            "rating_q025": 1238.3391544844476
        },
        "glm-4-0520": {
            "rating": 1241.654257988632,
            "rating_q975": 1250.7092835664084,
            "rating_q025": 1232.5992324108556
        },
        "command-r-plus-08-2024": {
            "rating": 1238.2282697530927,
            "rating_q975": 1246.426505276362,
            "rating_q025": 1230.0300342298235
        },
        "nemotron-4-340b-instruct": {
            "rating": 1236.9168418224729,
            "rating_q975": 1243.9810772275268,
            "rating_q025": 1229.8526064174189
        },
        "gemini-1.5-flash-8b-001": {
            "rating": 1232.0527246308745,
            "rating_q975": 1237.3602723274578,
            "rating_q025": 1226.7451769342913
        },
        "phi-4": {
            "rating": 1231.364271072233,
            "rating_q975": 1236.9472158956657,
            "rating_q025": 1225.7813262488
        },
        "c4ai-aya-expanse-32b": {
            "rating": 1229.3059712236202,
            "rating_q975": 1235.2336645039272,
            "rating_q025": 1223.3782779433132
        },
        "claude-3-sonnet-20240229": {
            "rating": 1226.4090081360648,
            "rating_q975": 1231.1402432320765,
            "rating_q025": 1221.6777730400531
        },
        "jamba-1.5-mini": {
            "rating": 1225.2131209810552,
            "rating_q975": 1234.113459097116,
            "rating_q025": 1216.3127828649945
        },
        "amazon-nova-micro-v1.0": {
            "rating": 1224.826436953077,
            "rating_q975": 1230.8849344243774,
            "rating_q025": 1218.7679394817767
        },
        "reka-flash-20240904": {
            "rating": 1223.3805447338354,
            "rating_q975": 1232.387519819143,
            "rating_q025": 1214.3735696485278
        },
        "qwen2-72b-instruct": {
            "rating": 1222.4501804874465,
            "rating_q975": 1228.3001968030035,
            "rating_q025": 1216.6001641718894
        },
        "gemma-2-9b-it": {
            "rating": 1220.3254677566704,
            "rating_q975": 1224.8258348766406,
            "rating_q025": 1215.8251006367002
        },
        "gpt-4-0314": {
            "rating": 1219.6300110144266,
            "rating_q975": 1225.3033386933234,
            "rating_q025": 1213.9566833355298
        },
        "llama-3.1-8b-instruct": {
            "rating": 1218.4246479767908,
            "rating_q975": 1223.3334004406825,
            "rating_q025": 1213.515895512899
        },
        "hunyuan-standard-256k": {
            "rating": 1216.5375732418538,
            "rating_q975": 1232.6640692866463,
            "rating_q025": 1200.4110771970613
        },
        "llama-3.1-tulu-3-8b": {
            "rating": 1215.4712726255989,
            "rating_q975": 1229.001820547003,
            "rating_q025": 1201.9407247041947
        },
        "yi-1.5-34b-chat": {
            "rating": 1214.8776293048159,
            "rating_q975": 1221.581401398287,
            "rating_q025": 1208.1738572113447
        },
        "llama-3-8b-instruct": {
            "rating": 1213.6414846743405,
            "rating_q975": 1218.3227346661138,
            "rating_q025": 1208.9602346825673
        },
        "command-r-plus": {
            "rating": 1213.5941668557718,
            "rating_q975": 1218.7198842606338,
            "rating_q025": 1208.46844945091
        },
        "ministral-8b-2410": {
            "rating": 1212.7000187061071,
            "rating_q975": 1224.5263210112946,
            "rating_q025": 1200.8737164009196
        },
        "claude-3-haiku-20240307": {
            "rating": 1206.5518520042597,
            "rating_q975": 1211.1889638086661,
            "rating_q025": 1201.9147401998532
        },
        "gpt-4-0613": {
            "rating": 1205.687029684452,
            "rating_q975": 1210.5540465599097,
            "rating_q025": 1200.8200128089943
        },
        "internlm2_5-20b-chat": {
            "rating": 1204.8233128224074,
            "rating_q975": 1213.9426825983655,
            "rating_q025": 1195.7039430464492
        },
        "mistral-large-2402": {
            "rating": 1199.9890595040033,
            "rating_q975": 1205.6563550972487,
            "rating_q025": 1194.321763910758
        },
        "command-r-08-2024": {
            "rating": 1198.7322840722527,
            "rating_q975": 1206.9295818420796,
            "rating_q025": 1190.5349863024258
        },
        "qwen1.5-110b-chat": {
            "rating": 1198.4275987825345,
            "rating_q975": 1205.5763197494061,
            "rating_q025": 1191.2788778156628
        },
        "deepseek-coder-v2": {
            "rating": 1194.8737510031965,
            "rating_q975": 1202.8322844657027,
            "rating_q025": 1186.9152175406903
        },
        "c4ai-aya-expanse-8b": {
            "rating": 1192.4203927383346,
            "rating_q975": 1200.9744770139775,
            "rating_q025": 1183.8663084626917
        },
        "granite-3.1-8b-instruct": {
            "rating": 1191.2943673992552,
            "rating_q975": 1205.1115292481686,
            "rating_q025": 1177.4772055503418
        },
        "mistral-medium": {
            "rating": 1191.1473768038863,
            "rating_q975": 1197.4805395318351,
            "rating_q025": 1184.8142140759376
        },
        "mixtral-8x22b-instruct-v0.1": {
            "rating": 1187.3602610618486,
            "rating_q975": 1192.8287627622917,
            "rating_q025": 1181.8917593614055
        },
        "qwen1.5-72b-chat": {
            "rating": 1187.1431178681155,
            "rating_q975": 1193.2728996291512,
            "rating_q025": 1181.0133361070798
        },
        "qwq-32b-preview": {
            "rating": 1184.9485429750143,
            "rating_q975": 1199.4961209734104,
            "rating_q025": 1170.4009649766183
        },
        "gemma-2-2b-it": {
            "rating": 1182.2886526264192,
            "rating_q975": 1187.0494449713499,
            "rating_q025": 1177.5278602814885
        },
        "reka-flash-21b-20240226-online": {
            "rating": 1181.4893524833071,
            "rating_q975": 1190.43919805186,
            "rating_q025": 1172.5395069147542
        },
        "llama-3.2-3b-instruct": {
            "rating": 1180.2119792441263,
            "rating_q975": 1189.7057567718482,
            "rating_q025": 1170.7182017164043
        },
        "reka-flash-21b-20240226": {
            "rating": 1179.5235675178392,
            "rating_q975": 1186.7873641333078,
            "rating_q025": 1172.2597709023705
        },
        "zephyr-orpo-141b-A35b-v0.1": {
            "rating": 1175.2171575924206,
            "rating_q975": 1188.3948677679707,
            "rating_q025": 1162.0394474168704
        },
        "command-r": {
            "rating": 1174.9996470181525,
            "rating_q975": 1180.7793160181484,
            "rating_q025": 1169.2199780181566
        },
        "granite-3.1-2b-instruct": {
            "rating": 1174.259165051294,
            "rating_q975": 1188.4409761976046,
            "rating_q025": 1160.0773539049835
        },
        "phi-3-medium-4k-instruct": {
            "rating": 1169.474715475886,
            "rating_q975": 1175.9243570730337,
            "rating_q025": 1163.025073878738
        },
        "mixtral-8x7b-instruct-v0.1": {
            "rating": 1168.2533892632882,
            "rating_q975": 1173.348288007713,
            "rating_q025": 1163.1584905188633
        },
        "starling-lm-7b-beta": {
            "rating": 1162.9621523463416,
            "rating_q975": 1171.763769295072,
            "rating_q025": 1154.160535397611
        },
        "gemini-pro-dev-api": {
            "rating": 1162.4483361933426,
            "rating_q975": 1170.8008184434264,
            "rating_q025": 1154.0958539432588
        },
        "qwen1.5-32b-chat": {
            "rating": 1160.5501430880875,
            "rating_q975": 1168.1217827224327,
            "rating_q025": 1152.9785034537422
        },
        "yi-34b-chat": {
            "rating": 1159.5208642643347,
            "rating_q975": 1167.3565358882017,
            "rating_q025": 1151.6851926404677
        },
        "llama-2-70b-chat": {
            "rating": 1156.757839493664,
            "rating_q975": 1163.1190054424874,
            "rating_q025": 1150.3966735448407
        },
        "dbrx-instruct-preview": {
            "rating": 1155.6563452485843,
            "rating_q975": 1163.1260383021836,
            "rating_q025": 1148.186652194985
        },
        "gemini-pro": {
            "rating": 1154.283139038249,
            "rating_q975": 1166.9632637442562,
            "rating_q025": 1141.6030143322416
        },
        "phi-3-small-8k-instruct": {
            "rating": 1151.4185073559356,
            "rating_q975": 1159.1959595798785,
            "rating_q025": 1143.6410551319927
        },
        "tulu-2-dpo-70b": {
            "rating": 1151.199394922976,
            "rating_q975": 1161.9640963717766,
            "rating_q025": 1140.4346934741752
        },
        "wizardlm-70b": {
            "rating": 1150.906302491402,
            "rating_q975": 1161.1461045529145,
            "rating_q025": 1140.6665004298893
        },
        "granite-3.0-8b-instruct": {
            "rating": 1150.0337709998153,
            "rating_q975": 1161.4003090677927,
            "rating_q025": 1138.6672329318378
        },
        "qwen1.5-14b-chat": {
            "rating": 1149.141812213223,
            "rating_q975": 1157.9428957153743,
            "rating_q025": 1140.3407287110715
        },
        "nous-hermes-2-mixtral-8x7b-dpo": {
            "rating": 1140.5339848038598,
            "rating_q975": 1153.3923670888237,
            "rating_q025": 1127.6756025188959
        },
        "gpt-3.5-turbo-0125": {
            "rating": 1140.1853314639695,
            "rating_q975": 1145.6168457327137,
            "rating_q025": 1134.7538171952253
        },
        "starling-lm-7b-alpha": {
            "rating": 1139.5932734360588,
            "rating_q975": 1148.557164314409,
            "rating_q025": 1130.6293825577086
        },
        "vicuna-33b": {
            "rating": 1134.512264165769,
            "rating_q975": 1141.7180950465745,
            "rating_q025": 1127.3064332849635
        },
        "mistral-7b-instruct-v0.2": {
            "rating": 1134.492015381073,
            "rating_q975": 1142.1153548605987,
            "rating_q025": 1126.8686759015475
        },
        "openchat-3.5-0106": {
            "rating": 1131.868476633295,
            "rating_q975": 1140.613061300593,
            "rating_q025": 1123.1238919659968
        },
        "phi-3-mini-4k-instruct-june-2024": {
            "rating": 1128.60212020771,
            "rating_q975": 1136.7283586444419,
            "rating_q025": 1120.475881770978
        },
        "openhermes-2.5-mistral-7b": {
            "rating": 1127.2023133247578,
            "rating_q975": 1138.717887093125,
            "rating_q025": 1115.6867395563906
        },
        "deepseek-llm-67b-chat": {
            "rating": 1126.9127904373968,
            "rating_q975": 1139.7711255954157,
            "rating_q025": 1114.0544552793779
        },
        "gemma-1.1-7b-it": {
            "rating": 1125.8398645549983,
            "rating_q975": 1132.8916533170895,
            "rating_q025": 1118.788075792907
        },
        "snowflake-arctic-instruct": {
            "rating": 1122.3907742848814,
            "rating_q975": 1129.7688302833697,
            "rating_q025": 1115.0127182863932
        },
        "llama-2-13b-chat": {
            "rating": 1121.2475931097897,
            "rating_q975": 1128.8858921182639,
            "rating_q025": 1113.6092941013155
        },
        "llama2-70b-steerlm-chat": {
            "rating": 1120.9252578653425,
            "rating_q975": 1134.7398487671758,
            "rating_q025": 1107.1106669635092
        },
        "granite-3.0-2b-instruct": {
            "rating": 1120.289678841287,
            "rating_q975": 1131.619880903807,
            "rating_q025": 1108.959476778767
        },
        "llama-3.2-1b-instruct": {
            "rating": 1119.0628533258243,
            "rating_q975": 1128.6616814261245,
            "rating_q025": 1109.4640252255242
        },
        "solar-10.7b-instruct-v1.0": {
            "rating": 1118.969573734421,
            "rating_q975": 1133.4905811674107,
            "rating_q025": 1104.4485663014311
        },
        "openchat-3.5": {
            "rating": 1117.8964115657845,
            "rating_q975": 1128.5623966240564,
            "rating_q025": 1107.2304265075127
        },
        "phi-3-mini-4k-instruct": {
            "rating": 1116.9900511469318,
            "rating_q975": 1124.987981094791,
            "rating_q025": 1108.9921211990727
        },
        "gpt-3.5-turbo-1106": {
            "rating": 1113.5119750112215,
            "rating_q975": 1123.139546136326,
            "rating_q025": 1103.8844038861168
        },
        "dolphin-2.2.1-mistral-7b": {
            "rating": 1112.5519051709612,
            "rating_q975": 1129.5381724283927,
            "rating_q025": 1095.5656379135296
        },
        "zephyr-7b-beta": {
            "rating": 1107.91230012602,
            "rating_q975": 1117.4924168883667,
            "rating_q025": 1098.3321833636733
        },
        "qwen1.5-7b-chat": {
            "rating": 1105.5933002992456,
            "rating_q975": 1116.7754793707863,
            "rating_q025": 1094.4111212277048
        },
        "mpt-30b-chat": {
            "rating": 1102.712828302391,
            "rating_q975": 1116.4984239884686,
            "rating_q025": 1088.9272326163134
        },
        "wizardlm-13b": {
            "rating": 1102.419246694351,
            "rating_q975": 1112.8863523321409,
            "rating_q025": 1091.952141056561
        },
        "smollm2-1.7b-instruct": {
            "rating": 1098.0551978360622,
            "rating_q975": 1116.8112926910062,
            "rating_q025": 1079.2991029811183
        },
        "llama-2-7b-chat": {
            "rating": 1096.4296753020967,
            "rating_q975": 1104.3009702595325,
            "rating_q025": 1088.558380344661
        },
        "codellama-70b-instruct": {
            "rating": 1095.8502463587783,
            "rating_q975": 1118.116389552068,
            "rating_q025": 1073.5841031654886
        },
        "zephyr-7b-alpha": {
            "rating": 1093.6761381612773,
            "rating_q975": 1111.304543794254,
            "rating_q025": 1076.0477325283007
        },
        "codellama-34b-instruct": {
            "rating": 1092.5929837405386,
            "rating_q975": 1102.2579580111592,
            "rating_q025": 1082.928009469918
        },
        "gemma-7b-it": {
            "rating": 1090.4990086384894,
            "rating_q975": 1101.6123266731634,
            "rating_q025": 1079.3856906038154
        },
        "guanaco-33b": {
            "rating": 1086.5003391339283,
            "rating_q975": 1100.0527988849542,
            "rating_q025": 1072.9478793829023
        },
        "phi-3-mini-128k-instruct": {
            "rating": 1084.3038234313494,
            "rating_q975": 1093.181372001695,
            "rating_q025": 1075.4262748610038
        },
        "vicuna-13b": {
            "rating": 1081.8153742323464,
            "rating_q975": 1089.262730749774,
            "rating_q025": 1074.3680177149188
        },
        "falcon-180b-chat": {
            "rating": 1081.7582859594686,
            "rating_q975": 1100.720377878781,
            "rating_q025": 1062.7961940401563
        },
        "stripedhyena-nous-7b": {
            "rating": 1070.9993316081532,
            "rating_q975": 1082.9780041245795,
            "rating_q025": 1059.0206590917269
        },
        "qwen-14b-chat": {
            "rating": 1069.1175894065705,
            "rating_q975": 1081.0287504974767,
            "rating_q025": 1057.2064283156642
        },
        "olmo-7b-instruct": {
            "rating": 1067.8905805305544,
            "rating_q975": 1080.837015323093,
            "rating_q025": 1054.9441457380158
        },
        "palm-2": {
            "rating": 1064.3413519827777,
            "rating_q975": 1074.3824192606671,
            "rating_q025": 1054.3002847048883
        },
        "mistral-7b-instruct": {
            "rating": 1060.4807029727085,
            "rating_q975": 1070.626194282487,
            "rating_q025": 1050.33521166293
        },
        "vicuna-7b": {
            "rating": 1052.733078118797,
            "rating_q975": 1062.7314596102515,
            "rating_q025": 1042.7346966273426
        },
        "gemma-1.1-2b-it": {
            "rating": 1051.585018994021,
            "rating_q975": 1061.2597702872226,
            "rating_q025": 1041.9102677008195
        },
        "gemma-2b-it": {
            "rating": 1033.29137604049,
            "rating_q975": 1046.656305208064,
            "rating_q025": 1019.9264468729158
        },
        "koala-13b": {
            "rating": 1022.7759942541729,
            "rating_q975": 1034.0449327708454,
            "rating_q025": 1011.5070557375004
        },
        "qwen1.5-4b-chat": {
            "rating": 1015.7650093624975,
            "rating_q975": 1026.6227430269894,
            "rating_q025": 1004.9072756980056
        },
        "chatglm3-6b": {
            "rating": 1004.1105449137278,
            "rating_q975": 1016.9054174490371,
            "rating_q025": 991.3156723784185
        },
        "gpt4all-13b-snoozy": {
            "rating": 989.3177092609544,
            "rating_q975": 1006.4939887812401,
            "rating_q025": 972.1414297406687
        },
        "mpt-7b-chat": {
            "rating": 981.8825296741672,
            "rating_q975": 994.967906633967,
            "rating_q025": 968.7971527143675
        },
        "chatglm2-6b": {
            "rating": 975.251080089467,
            "rating_q975": 990.3143464967923,
            "rating_q025": 960.1878136821417
        },
        "RWKV-4-Raven-14B": {
            "rating": 969.4898276758289,
            "rating_q975": 982.2555103429388,
            "rating_q025": 956.724145008719
        },
        "alpaca-13b": {
            "rating": 958.9159518870024,
            "rating_q975": 971.4173909990814,
            "rating_q025": 946.4145127749234
        },
        "oasst-pythia-12b": {
            "rating": 946.7486934490234,
            "rating_q975": 958.7012830779703,
            "rating_q025": 934.7961038200766
        },
        "chatglm-6b": {
            "rating": 939.695707646729,
            "rating_q975": 953.3745573186719,
            "rating_q025": 926.0168579747861
        },
        "fastchat-t5-3b": {
            "rating": 936.328480031782,
            "rating_q975": 949.8741337137147,
            "rating_q025": 922.7828263498492
        },
        "stablelm-tuned-alpha-7b": {
            "rating": 891.7568651273083,
            "rating_q975": 906.0307500685037,
            "rating_q025": 877.4829801861129
        },
        "dolly-v2-12b": {
            "rating": 868.9904700596895,
            "rating_q975": 884.023716582904,
            "rating_q025": 853.9572235364751
        },
        "llama-13b": {
            "rating": 846.7617597978092,
            "rating_q975": 864.1616379259164,
            "rating_q025": 829.361881669702
        }
    },
    "expert": {
        "claude-sonnet-4-5-20250929-thinking-32k": {
            "rating": 1477.831603143434,
            "rating_q975": 1503.4309583728445,
            "rating_q025": 1452.2322479140234
        },
        "gemini-2.5-pro": {
            "rating": 1459.240838482455,
            "rating_q975": 1470.9766619949203,
            "rating_q025": 1447.5050149699898
        },
        "qwen3-max-preview": {
            "rating": 1455.1392908562518,
            "rating_q975": 1473.3946686948182,
            "rating_q025": 1436.8839130176855
        },
        "claude-sonnet-4-5-20250929": {
            "rating": 1454.4040424855564,
            "rating_q975": 1488.0532022584457,
            "rating_q025": 1420.754882712667
        },
        "qwen3-235b-a22b-thinking-2507": {
            "rating": 1453.9078439175526,
            "rating_q975": 1482.190540629412,
            "rating_q025": 1425.625147205693
        },
        "qwen3-235b-a22b-instruct-2507": {
            "rating": 1441.8093139206799,
            "rating_q975": 1456.754982840997,
            "rating_q025": 1426.8636450003628
        },
        "claude-opus-4-1-20250805-thinking-16k": {
            "rating": 1441.576834561921,
            "rating_q975": 1459.1175762826224,
            "rating_q025": 1424.0360928412197
        },
        "gemini-2.5-flash-preview-09-2025": {
            "rating": 1438.0810250209822,
            "rating_q975": 1462.5164715499814,
            "rating_q025": 1413.645578491983
        },
        "qwen3-vl-235b-a22b-instruct": {
            "rating": 1436.1208425994905,
            "rating_q975": 1463.0522929203757,
            "rating_q025": 1409.1893922786053
        },
        "longcat-flash-chat": {
            "rating": 1433.320885445408,
            "rating_q975": 1459.4096253159457,
            "rating_q025": 1407.2321455748704
        },
        "gemini-2.5-flash": {
            "rating": 1432.037217922176,
            "rating_q975": 1443.354641295888,
            "rating_q025": 1420.719794548464
        },
        "glm-4.5": {
            "rating": 1427.2391759317904,
            "rating_q975": 1445.1391396612196,
            "rating_q025": 1409.3392122023613
        },
        "qwen3-vl-235b-a22b-thinking": {
            "rating": 1426.999367729456,
            "rating_q975": 1457.3208369574932,
            "rating_q025": 1396.677898501419
        },
        "glm-4.6": {
            "rating": 1426.2286852130026,
            "rating_q975": 1453.28721973114,
            "rating_q025": 1399.170150694865
        },
        "grok-4-0709": {
            "rating": 1419.8446440344956,
            "rating_q975": 1434.8926352947772,
            "rating_q025": 1404.796652774214
        },
        "gpt-5-high": {
            "rating": 1419.504924884625,
            "rating_q975": 1435.8963434014602,
            "rating_q025": 1403.11350636779
        },
        "claude-opus-4-1-20250805": {
            "rating": 1419.3727229423846,
            "rating_q975": 1434.0671430151472,
            "rating_q025": 1404.678302869622
        },
        "grok-3-preview-02-24": {
            "rating": 1417.0721472552518,
            "rating_q975": 1431.9987242889704,
            "rating_q025": 1402.1455702215333
        },
        "qwen3-next-80b-a3b-instruct": {
            "rating": 1415.2765213939417,
            "rating_q975": 1435.5918244802606,
            "rating_q025": 1394.9612183076229
        },
        "claude-haiku-4-5-20251001": {
            "rating": 1411.646844575281,
            "rating_q975": 1437.0824740808052,
            "rating_q025": 1386.2112150697567
        },
        "deepseek-v3.2-exp-thinking": {
            "rating": 1408.4800430839566,
            "rating_q975": 1438.2899413461287,
            "rating_q025": 1378.6701448217846
        },
        "qwen3-max-2025-09-23": {
            "rating": 1405.1812212700695,
            "rating_q975": 1432.0709749587377,
            "rating_q025": 1378.2914675814013
        },
        "deepseek-v3.1": {
            "rating": 1404.8343666655096,
            "rating_q975": 1427.04626047417,
            "rating_q025": 1382.6224728568493
        },
        "grok-4-fast": {
            "rating": 1403.9666772018895,
            "rating_q975": 1437.6022332930263,
            "rating_q025": 1370.3311211107527
        },
        "deepseek-v3.1-thinking": {
            "rating": 1403.4791105109587,
            "rating_q975": 1428.5425670030568,
            "rating_q025": 1378.4156540188606
        },
        "gpt-5-chat": {
            "rating": 1402.8369978931494,
            "rating_q975": 1419.4840623045557,
            "rating_q025": 1386.189933481743
        },
        "mistral-medium-2508": {
            "rating": 1400.7045445342667,
            "rating_q975": 1416.7385490622942,
            "rating_q025": 1384.6705400062392
        },
        "o3-2025-04-16": {
            "rating": 1399.1808116390441,
            "rating_q975": 1411.072322511021,
            "rating_q025": 1387.2893007670673
        },
        "gpt-4.5-preview-2025-02-27": {
            "rating": 1391.835157132424,
            "rating_q975": 1415.0768176032173,
            "rating_q025": 1368.5934966616308
        },
        "chatgpt-4o-latest-20250326": {
            "rating": 1389.9174548881124,
            "rating_q975": 1402.4494574564183,
            "rating_q025": 1377.3854523198065
        },
        "deepseek-r1-0528": {
            "rating": 1389.4432688779948,
            "rating_q975": 1408.747214298578,
            "rating_q025": 1370.1393234574116
        },
        "hunyuan-t1-20250711": {
            "rating": 1388.0409628809857,
            "rating_q975": 1426.8515157361503,
            "rating_q025": 1349.2304100258211
        },
        "grok-3-mini-high": {
            "rating": 1386.3520254684342,
            "rating_q975": 1405.0228965958827,
            "rating_q025": 1367.6811543409858
        },
        "qwen3-30b-a3b-instruct-2507": {
            "rating": 1385.288068873684,
            "rating_q975": 1402.5298578877123,
            "rating_q025": 1368.046279859656
        },
        "claude-opus-4-20250514-thinking-16k": {
            "rating": 1380.244918870037,
            "rating_q975": 1394.7553071832656,
            "rating_q025": 1365.7345305568085
        },
        "mai-1-preview": {
            "rating": 1379.6519061740362,
            "rating_q975": 1400.5449425865686,
            "rating_q025": 1358.7588697615038
        },
        "gpt-5-mini-high": {
            "rating": 1379.1874531267179,
            "rating_q975": 1398.7340448930431,
            "rating_q025": 1359.6408613603926
        },
        "kimi-k2-0905-preview": {
            "rating": 1377.694299053755,
            "rating_q975": 1404.5487666903387,
            "rating_q025": 1350.8398314171714
        },
        "claude-sonnet-4-20250514-thinking-32k": {
            "rating": 1372.6650828942147,
            "rating_q975": 1387.3110949906113,
            "rating_q025": 1358.0190707978181
        },
        "qwen3-235b-a22b-no-thinking": {
            "rating": 1368.262767703696,
            "rating_q975": 1382.1164703450509,
            "rating_q025": 1354.4090650623411
        },
        "qwen3-next-80b-a3b-thinking": {
            "rating": 1368.1172892415,
            "rating_q975": 1392.0737990077569,
            "rating_q025": 1344.160779475243
        },
        "gemini-2.5-flash-lite-preview-09-2025-no-thinking": {
            "rating": 1366.9956545720286,
            "rating_q975": 1389.3707365480911,
            "rating_q025": 1344.620572595966
        },
        "claude-opus-4-20250514": {
            "rating": 1364.860775292655,
            "rating_q975": 1377.5544572414376,
            "rating_q025": 1352.1670933438725
        },
        "gemini-2.5-flash-lite-preview-06-17-thinking": {
            "rating": 1364.4617981920715,
            "rating_q975": 1379.1487222543979,
            "rating_q025": 1349.774874129745
        },
        "gpt-4.1-2025-04-14": {
            "rating": 1363.2620068758715,
            "rating_q975": 1375.6003676399484,
            "rating_q025": 1350.9236461117946
        },
        "glm-4.5-air": {
            "rating": 1362.80090737718,
            "rating_q975": 1379.486405592104,
            "rating_q025": 1346.1154091622561
        },
        "qwen3-32b": {
            "rating": 1361.0713877350352,
            "rating_q975": 1398.1066144995414,
            "rating_q025": 1324.036160970529
        },
        "o3-mini-high": {
            "rating": 1360.7789080500781,
            "rating_q975": 1380.8430084981617,
            "rating_q025": 1340.7148076019946
        },
        "o1-2024-12-17": {
            "rating": 1359.4253098241015,
            "rating_q975": 1375.850160211675,
            "rating_q025": 1343.000459436528
        },
        "glm-4.5v": {
            "rating": 1358.8387621004433,
            "rating_q975": 1401.130388127683,
            "rating_q025": 1316.5471360732035
        },
        "grok-3-mini-beta": {
            "rating": 1358.8282864042765,
            "rating_q975": 1375.6704147213175,
            "rating_q025": 1341.9861580872355
        },
        "gpt-oss-120b": {
            "rating": 1352.6444143723882,
            "rating_q975": 1370.255724969927,
            "rating_q025": 1335.0331037748492
        },
        "ling-flash-2.0": {
            "rating": 1351.9606496527886,
            "rating_q975": 1381.5747832929135,
            "rating_q025": 1322.3465160126636
        },
        "deepseek-v3-0324": {
            "rating": 1347.1121720129775,
            "rating_q975": 1359.60473457049,
            "rating_q025": 1334.6196094554648
        },
        "qwen3-235b-a22b": {
            "rating": 1346.2511935616162,
            "rating_q975": 1362.23740467344,
            "rating_q025": 1330.2649824497923
        },
        "o4-mini-2025-04-16": {
            "rating": 1344.6606575974831,
            "rating_q975": 1357.274740977011,
            "rating_q025": 1332.0465742179551
        },
        "kimi-k2-0711-preview": {
            "rating": 1343.4928892403805,
            "rating_q975": 1359.171678917136,
            "rating_q025": 1327.814099563625
        },
        "mistral-medium-2505": {
            "rating": 1342.48428377638,
            "rating_q975": 1356.0832299384545,
            "rating_q025": 1328.8853376143054
        },
        "hunyuan-turbos-20250416": {
            "rating": 1339.5817076789347,
            "rating_q975": 1362.8785838527092,
            "rating_q025": 1316.2848315051601
        },
        "gpt-4.1-mini-2025-04-14": {
            "rating": 1337.380271743853,
            "rating_q975": 1350.5380598362826,
            "rating_q025": 1324.2224836514233
        },
        "amazon-nova-experimental-chat-10-09": {
            "rating": 1337.1256326621008,
            "rating_q975": 1372.9918366432432,
            "rating_q025": 1301.2594286809583
        },
        "qwen3-coder-480b-a35b-instruct": {
            "rating": 1336.92377962651,
            "rating_q975": 1353.5985838837594,
            "rating_q025": 1320.2489753692605
        },
        "o1-preview": {
            "rating": 1335.2996373858693,
            "rating_q975": 1349.0729510315596,
            "rating_q025": 1321.5263237401791
        },
        "ring-flash-2.0": {
            "rating": 1335.061002301645,
            "rating_q975": 1366.528982650415,
            "rating_q025": 1303.593021952875
        },
        "deepseek-r1": {
            "rating": 1334.3189416427444,
            "rating_q975": 1353.6073391956263,
            "rating_q025": 1315.0305440898626
        },
        "claude-sonnet-4-20250514": {
            "rating": 1333.744176372466,
            "rating_q975": 1347.085919159727,
            "rating_q025": 1320.402433585205
        },
        "qwen2.5-max": {
            "rating": 1333.533054093234,
            "rating_q975": 1346.9507647721023,
            "rating_q025": 1320.115343414366
        },
        "step-3": {
            "rating": 1329.7448866631212,
            "rating_q975": 1365.5483329594008,
            "rating_q025": 1293.9414403668416
        },
        "o3-mini": {
            "rating": 1328.692608837565,
            "rating_q975": 1339.8892241468911,
            "rating_q025": 1317.495993528239
        },
        "gpt-5-nano-high": {
            "rating": 1326.8859646657475,
            "rating_q975": 1360.2803727271878,
            "rating_q025": 1293.491556604307
        },
        "nvidia-llama-3.3-nemotron-super-49b-v1.5": {
            "rating": 1326.4139072857818,
            "rating_q975": 1365.3482950106913,
            "rating_q025": 1287.4795195608722
        },
        "qwen-plus-0125": {
            "rating": 1325.3382116616642,
            "rating_q975": 1354.8612004543265,
            "rating_q025": 1295.815222869002
        },
        "minimax-m1": {
            "rating": 1322.7245407647722,
            "rating_q975": 1337.3237585260497,
            "rating_q025": 1308.1253230034947
        },
        "qwq-32b": {
            "rating": 1321.9572867215313,
            "rating_q975": 1338.4859874848482,
            "rating_q025": 1305.4285859582144
        },
        "claude-3-7-sonnet-20250219-thinking-32k": {
            "rating": 1318.5200466747979,
            "rating_q975": 1332.395488976442,
            "rating_q025": 1304.6446043731537
        },
        "o1-mini": {
            "rating": 1313.4186544948807,
            "rating_q975": 1324.1300558481414,
            "rating_q025": 1302.70725314162
        },
        "qwen3-30b-a3b": {
            "rating": 1313.1536358659152,
            "rating_q975": 1329.3277624781867,
            "rating_q025": 1296.9795092536438
        },
        "step-1o-turbo-202506": {
            "rating": 1302.8089632271374,
            "rating_q975": 1329.0502414114035,
            "rating_q025": 1276.5676850428713
        },
        "deepseek-v3": {
            "rating": 1302.392874972652,
            "rating_q975": 1318.3326982765632,
            "rating_q025": 1286.4530516687407
        },
        "gemini-2.0-flash-lite-preview-02-05": {
            "rating": 1302.282467811551,
            "rating_q975": 1318.2551009830963,
            "rating_q025": 1286.3098346400056
        },
        "gemma-3-27b-it": {
            "rating": 1301.0757661312566,
            "rating_q975": 1313.624772662172,
            "rating_q025": 1288.5267596003412
        },
        "command-a-03-2025": {
            "rating": 1291.04151788408,
            "rating_q975": 1302.779496206844,
            "rating_q025": 1279.3035395613158
        },
        "mistral-small-2506": {
            "rating": 1289.8474091931553,
            "rating_q975": 1309.217548664493,
            "rating_q025": 1270.4772697218175
        },
        "qwen2.5-plus-1127": {
            "rating": 1286.76852722491,
            "rating_q975": 1307.3594218204178,
            "rating_q025": 1266.1776326294023
        },
        "yi-lightning": {
            "rating": 1282.6256997334403,
            "rating_q975": 1296.51174531467,
            "rating_q025": 1268.7396541522107
        },
        "glm-4-plus-0111": {
            "rating": 1277.2829469978674,
            "rating_q975": 1306.4727051593427,
            "rating_q025": 1248.093188836392
        },
        "gemini-1.5-pro-002": {
            "rating": 1275.9742101782963,
            "rating_q975": 1286.0054168787367,
            "rating_q025": 1265.9430034778559
        },
        "step-2-16k-exp-202412": {
            "rating": 1275.8846868540381,
            "rating_q975": 1306.6792308186423,
            "rating_q025": 1245.090142889434
        },
        "hunyuan-large-2025-02-10": {
            "rating": 1273.0895268872464,
            "rating_q975": 1309.3604115197759,
            "rating_q025": 1236.818642254717
        },
        "gpt-4.1-nano-2025-04-14": {
            "rating": 1269.8559409022487,
            "rating_q975": 1300.3546449906437,
            "rating_q025": 1239.3572368138537
        },
        "athene-v2-chat": {
            "rating": 1265.4570077948335,
            "rating_q975": 1279.7380037442113,
            "rating_q025": 1251.1760118454558
        },
        "deepseek-v2.5-1210": {
            "rating": 1263.7630185122498,
            "rating_q975": 1289.5736312983083,
            "rating_q025": 1237.9524057261913
        },
        "mistral-small-3.1-24b-instruct-2503": {
            "rating": 1263.4304989725401,
            "rating_q975": 1278.5622780539356,
            "rating_q025": 1248.2987198911446
        },
        "claude-3-5-sonnet-20241022": {
            "rating": 1263.3254018519217,
            "rating_q975": 1271.5970500576036,
            "rating_q025": 1255.0537536462398
        },
        "gpt-oss-20b": {
            "rating": 1260.4086834679993,
            "rating_q975": 1288.1089952194702,
            "rating_q025": 1232.7083717165283
        },
        "llama-4-maverick-17b-128e-instruct": {
            "rating": 1260.0642777706653,
            "rating_q975": 1273.4750384453316,
            "rating_q025": 1246.653517095999
        },
        "hunyuan-large-vision": {
            "rating": 1257.907808201966,
            "rating_q975": 1291.648853009027,
            "rating_q025": 1224.1667633949048
        },
        "grok-2-2024-08-13": {
            "rating": 1251.1944299213797,
            "rating_q975": 1261.0549354287905,
            "rating_q025": 1241.3339244139688
        },
        "glm-4-plus": {
            "rating": 1249.958672886671,
            "rating_q975": 1263.936679910979,
            "rating_q025": 1235.980665862363
        },
        "gemma-3n-e4b-it": {
            "rating": 1247.7067335620152,
            "rating_q975": 1265.5813216816166,
            "rating_q025": 1229.8321454424138
        },
        "gpt-4o-2024-05-13": {
            "rating": 1247.3477078372175,
            "rating_q975": 1256.3857657601707,
            "rating_q025": 1238.3096499142644
        },
        "gemma-3-12b-it": {
            "rating": 1246.3381172690297,
            "rating_q975": 1287.629680286987,
            "rating_q025": 1205.0465542510724
        },
        "qwen-max-0919": {
            "rating": 1245.563831563025,
            "rating_q975": 1263.034116039894,
            "rating_q025": 1228.093547086156
        },
        "hunyuan-standard-2025-02-10": {
            "rating": 1245.1154671998183,
            "rating_q975": 1284.4319967569922,
            "rating_q025": 1205.7989376426444
        },
        "claude-3-5-sonnet-20240620": {
            "rating": 1244.8332240111686,
            "rating_q975": 1254.8901718976488,
            "rating_q025": 1234.7762761246884
        },
        "qwen2.5-72b-instruct": {
            "rating": 1243.0240611200468,
            "rating_q975": 1254.2685236047344,
            "rating_q025": 1231.7795986353592
        },
        "gemini-1.5-pro-001": {
            "rating": 1242.3160695665038,
            "rating_q975": 1253.3858696960465,
            "rating_q025": 1231.246269436961
        },
        "llama-3.1-405b-instruct-fp8": {
            "rating": 1240.462806229323,
            "rating_q975": 1250.8698882066017,
            "rating_q025": 1230.0557242520442
        },
        "llama-3.1-nemotron-70b-instruct": {
            "rating": 1239.903805292627,
            "rating_q975": 1266.5564758572652,
            "rating_q025": 1213.251134727989
        },
        "gpt-4o-2024-08-06": {
            "rating": 1238.0584940722492,
            "rating_q975": 1249.8452287809707,
            "rating_q025": 1226.2717593635277
        },
        "deepseek-v2.5": {
            "rating": 1237.5078013390998,
            "rating_q975": 1251.5140755965517,
            "rating_q025": 1223.501527081648
        },
        "llama-4-scout-17b-16e-instruct": {
            "rating": 1235.5555167208327,
            "rating_q975": 1251.2751940510714,
            "rating_q025": 1219.835839390594
        },
        "grok-2-mini-2024-08-13": {
            "rating": 1235.3390905478218,
            "rating_q975": 1246.0876524358007,
            "rating_q025": 1224.590528659843
        },
        "gpt-4o-mini-2024-07-18": {
            "rating": 1231.1484929625974,
            "rating_q975": 1240.8945641881514,
            "rating_q025": 1221.4024217370434
        },
        "gemini-1.5-flash-002": {
            "rating": 1230.6075090188017,
            "rating_q975": 1242.8647161287868,
            "rating_q025": 1218.3503019088166
        },
        "mistral-large-2407": {
            "rating": 1229.4558479870234,
            "rating_q975": 1241.0932924805802,
            "rating_q025": 1217.8184034934666
        },
        "llama-3.1-405b-instruct-bf16": {
            "rating": 1226.5089478515065,
            "rating_q975": 1238.6240735139813,
            "rating_q025": 1214.3938221890317
        },
        "athene-70b-0725": {
            "rating": 1225.5385412737292,
            "rating_q975": 1244.3404132535625,
            "rating_q025": 1206.7366692938958
        },
        "llama-3.3-70b-instruct": {
            "rating": 1222.4079772369746,
            "rating_q975": 1232.9375701648114,
            "rating_q025": 1211.8783843091378
        },
        "magistral-medium-2506": {
            "rating": 1221.951861424623,
            "rating_q975": 1248.478664647251,
            "rating_q025": 1195.4250582019952
        },
        "gpt-4-turbo-2024-04-09": {
            "rating": 1221.408738884597,
            "rating_q975": 1231.4515264355728,
            "rating_q025": 1211.365951333621
        },
        "gemma-3-4b-it": {
            "rating": 1220.89244094266,
            "rating_q975": 1262.6525137055187,
            "rating_q025": 1179.1323681798012
        },
        "claude-3-opus-20240229": {
            "rating": 1220.2713904393895,
            "rating_q975": 1228.3184154358985,
            "rating_q025": 1212.2243654428805
        },
        "qwen2.5-coder-32b-instruct": {
            "rating": 1218.4782572697313,
            "rating_q975": 1251.14377265141,
            "rating_q025": 1185.8127418880526
        },
        "jamba-1.5-large": {
            "rating": 1215.2567876023845,
            "rating_q975": 1244.1447651468059,
            "rating_q025": 1186.3688100579632
        },
        "gemini-advanced-0514": {
            "rating": 1212.296082112638,
            "rating_q975": 1225.8953128107714,
            "rating_q025": 1198.6968514145046
        },
        "reka-core-20240904": {
            "rating": 1210.500992631898,
            "rating_q975": 1234.93119171948,
            "rating_q025": 1186.070793544316
        },
        "gpt-4-1106-preview": {
            "rating": 1208.702774024442,
            "rating_q975": 1219.688534124698,
            "rating_q025": 1197.7170139241862
        },
        "amazon-nova-pro-v1.0": {
            "rating": 1208.4751904955497,
            "rating_q975": 1223.6781774462452,
            "rating_q025": 1193.2722035448542
        },
        "llama-3.1-70b-instruct": {
            "rating": 1206.0534776232892,
            "rating_q975": 1216.585442018892,
            "rating_q025": 1195.5215132276862
        },
        "mistral-large-2411": {
            "rating": 1205.5576147126158,
            "rating_q975": 1219.8618409177802,
            "rating_q025": 1191.2533885074513
        },
        "claude-3-5-haiku-20241022": {
            "rating": 1204.755225741474,
            "rating_q975": 1214.9086902785116,
            "rating_q025": 1194.6017612044366
        },
        "gpt-4-0125-preview": {
            "rating": 1203.2454942898107,
            "rating_q975": 1214.2535189930359,
            "rating_q025": 1192.2374695865856
        },
        "phi-4": {
            "rating": 1200.626288678709,
            "rating_q975": 1217.4198421283418,
            "rating_q025": 1183.8327352290762
        },
        "amazon-nova-lite-v1.0": {
            "rating": 1199.0528438254046,
            "rating_q975": 1215.2075840643913,
            "rating_q025": 1182.8981035864178
        },
        "mistral-small-24b-instruct-2501": {
            "rating": 1198.8058060232424,
            "rating_q975": 1219.086074615268,
            "rating_q025": 1178.525537431217
        },
        "gemini-1.5-flash-001": {
            "rating": 1196.863904544367,
            "rating_q975": 1208.2871971483607,
            "rating_q025": 1185.4406119403732
        },
        "gemini-1.5-flash-8b-001": {
            "rating": 1182.882005368495,
            "rating_q975": 1195.0967906869896,
            "rating_q025": 1170.6672200500002
        },
        "amazon-nova-micro-v1.0": {
            "rating": 1180.8176443384255,
            "rating_q975": 1197.5619264404777,
            "rating_q025": 1164.0733622363732
        },
        "c4ai-aya-expanse-32b": {
            "rating": 1179.6349006969515,
            "rating_q975": 1192.7541029358854,
            "rating_q025": 1166.5156984580176
        },
        "deepseek-coder-v2": {
            "rating": 1179.5919021967334,
            "rating_q975": 1200.494631435678,
            "rating_q025": 1158.6891729577887
        },
        "reka-flash-20240904": {
            "rating": 1179.4742557413713,
            "rating_q975": 1202.2943046583255,
            "rating_q025": 1156.654206824417
        },
        "glm-4-0520": {
            "rating": 1176.0720480778723,
            "rating_q975": 1200.3327603593177,
            "rating_q025": 1151.8113357964269
        },
        "command-r-plus-08-2024": {
            "rating": 1171.1429972960595,
            "rating_q975": 1195.1598187946886,
            "rating_q025": 1147.1261757974305
        },
        "claude-3-sonnet-20240229": {
            "rating": 1169.669775504995,
            "rating_q975": 1180.5282576267502,
            "rating_q025": 1158.8112933832397
        },
        "qwen2-72b-instruct": {
            "rating": 1168.7253313950378,
            "rating_q975": 1182.6273212147455,
            "rating_q025": 1154.82334157533
        },
        "gemma-2-27b-it": {
            "rating": 1168.5451648550804,
            "rating_q975": 1177.9291275909702,
            "rating_q025": 1159.1612021191906
        },
        "nemotron-4-340b-instruct": {
            "rating": 1168.0523636192793,
            "rating_q975": 1186.2138132151783,
            "rating_q025": 1149.8909140233802
        },
        "ministral-8b-2410": {
            "rating": 1167.3942602604836,
            "rating_q975": 1197.011119982286,
            "rating_q025": 1137.7774005386814
        },
        "llama-3.1-nemotron-51b-instruct": {
            "rating": 1164.575416501616,
            "rating_q975": 1197.551987647137,
            "rating_q025": 1131.5988453560951
        },
        "gemma-2-9b-it-simpo": {
            "rating": 1152.518281397747,
            "rating_q975": 1181.776747000114,
            "rating_q025": 1123.2598157953798
        },
        "c4ai-aya-expanse-8b": {
            "rating": 1151.005575421599,
            "rating_q975": 1174.1074402091713,
            "rating_q025": 1127.9037106340265
        },
        "command-r-plus": {
            "rating": 1150.8391076780215,
            "rating_q975": 1162.3111331562495,
            "rating_q025": 1139.3670821997935
        },
        "internlm2_5-20b-chat": {
            "rating": 1148.1365387865021,
            "rating_q975": 1169.720817121295,
            "rating_q025": 1126.5522604517091
        },
        "llama-3-70b-instruct": {
            "rating": 1147.0183805332013,
            "rating_q975": 1156.7833142619852,
            "rating_q025": 1137.2534468044173
        },
        "gpt-4-0314": {
            "rating": 1146.393991947413,
            "rating_q975": 1161.0126018866206,
            "rating_q025": 1131.7753820082055
        },
        "claude-3-haiku-20240307": {
            "rating": 1145.1974994251507,
            "rating_q975": 1154.9473884002516,
            "rating_q025": 1135.4476104500498
        },
        "gemma-2-9b-it": {
            "rating": 1144.4728065249333,
            "rating_q975": 1155.3680950524356,
            "rating_q025": 1133.577517997431
        },
        "qwen1.5-110b-chat": {
            "rating": 1141.6616665549182,
            "rating_q975": 1157.4760757392003,
            "rating_q025": 1125.847257370636
        },
        "llama-3.1-8b-instruct": {
            "rating": 1141.3984601339284,
            "rating_q975": 1152.6997363728565,
            "rating_q025": 1130.0971838950004
        },
        "yi-1.5-34b-chat": {
            "rating": 1140.7913739615392,
            "rating_q975": 1158.614756021506,
            "rating_q025": 1122.9679919015723
        },
        "granite-3.1-8b-instruct": {
            "rating": 1139.5027873393774,
            "rating_q975": 1174.7288405955903,
            "rating_q025": 1104.2767340831645
        },
        "command-r-08-2024": {
            "rating": 1136.554227633322,
            "rating_q975": 1158.021334548322,
            "rating_q025": 1115.0871207183218
        },
        "qwen1.5-72b-chat": {
            "rating": 1133.912073628926,
            "rating_q975": 1148.408115460662,
            "rating_q025": 1119.41603179719
        },
        "jamba-1.5-mini": {
            "rating": 1133.2296317547439,
            "rating_q975": 1163.9071522912961,
            "rating_q025": 1102.5521112181916
        },
        "qwq-32b-preview": {
            "rating": 1132.0572657095609,
            "rating_q975": 1168.1753260222408,
            "rating_q025": 1095.9392053968809
        },
        "granite-3.1-2b-instruct": {
            "rating": 1129.2700794889438,
            "rating_q975": 1164.2387600433144,
            "rating_q025": 1094.3013989345732
        },
        "gpt-4-0613": {
            "rating": 1125.9475731439945,
            "rating_q975": 1137.8338221444321,
            "rating_q025": 1114.061324143557
        },
        "qwen1.5-32b-chat": {
            "rating": 1123.8690580666619,
            "rating_q975": 1141.4732323490516,
            "rating_q025": 1106.2648837842721
        },
        "mistral-medium": {
            "rating": 1123.1704510401871,
            "rating_q975": 1139.6388012393268,
            "rating_q025": 1106.7021008410475
        },
        "mistral-large-2402": {
            "rating": 1119.8516444797854,
            "rating_q975": 1132.6346275538126,
            "rating_q025": 1107.0686614057581
        },
        "reka-flash-21b-20240226-online": {
            "rating": 1114.4517341722521,
            "rating_q975": 1135.2763788733,
            "rating_q025": 1093.6270894712043
        },
        "llama-3-8b-instruct": {
            "rating": 1111.2731338720027,
            "rating_q975": 1122.042286609626,
            "rating_q025": 1100.5039811343795
        },
        "mixtral-8x22b-instruct-v0.1": {
            "rating": 1111.0904534074828,
            "rating_q975": 1123.9532246301942,
            "rating_q025": 1098.2276821847713
        },
        "command-r": {
            "rating": 1105.3474771842193,
            "rating_q975": 1118.3245018907412,
            "rating_q025": 1092.3704524776974
        },
        "phi-3-medium-4k-instruct": {
            "rating": 1105.229981167468,
            "rating_q975": 1122.430709822002,
            "rating_q025": 1088.029252512934
        },
        "reka-flash-21b-20240226": {
            "rating": 1104.466040025547,
            "rating_q975": 1120.9977844296677,
            "rating_q025": 1087.9342956214264
        },
        "gemma-2-2b-it": {
            "rating": 1094.1777402252847,
            "rating_q975": 1105.8751103073866,
            "rating_q025": 1082.4803701431827
        },
        "qwen1.5-14b-chat": {
            "rating": 1092.0271289058164,
            "rating_q975": 1111.467181840722,
            "rating_q025": 1072.5870759709107
        },
        "llama-3.2-3b-instruct": {
            "rating": 1087.3124262152833,
            "rating_q975": 1111.334975172248,
            "rating_q025": 1063.2898772583185
        },
        "granite-3.0-8b-instruct": {
            "rating": 1084.5359255862163,
            "rating_q975": 1115.4509400245934,
            "rating_q025": 1053.6209111478393
        },
        "mixtral-8x7b-instruct-v0.1": {
            "rating": 1084.0874778705993,
            "rating_q975": 1096.1988099989965,
            "rating_q025": 1071.976145742202
        },
        "starling-lm-7b-beta": {
            "rating": 1082.1998421633907,
            "rating_q975": 1101.4220367776122,
            "rating_q025": 1062.9776475491692
        },
        "dbrx-instruct-preview": {
            "rating": 1072.8082333129917,
            "rating_q975": 1088.3500426949768,
            "rating_q025": 1057.2664239310066
        },
        "gpt-3.5-turbo-1106": {
            "rating": 1067.2320355104557,
            "rating_q975": 1095.175335807088,
            "rating_q025": 1039.2887352138234
        },
        "phi-3-small-8k-instruct": {
            "rating": 1064.3654564805931,
            "rating_q975": 1082.9478969137149,
            "rating_q025": 1045.7830160474714
        },
        "gpt-3.5-turbo-0125": {
            "rating": 1063.5469987615288,
            "rating_q975": 1075.4688880001254,
            "rating_q025": 1051.6251095229322
        },
        "granite-3.0-2b-instruct": {
            "rating": 1061.4704824876383,
            "rating_q975": 1089.6013156227843,
            "rating_q025": 1033.3396493524922
        },
        "zephyr-orpo-141b-A35b-v0.1": {
            "rating": 1061.3996487112277,
            "rating_q975": 1101.6731658951596,
            "rating_q025": 1021.1261315272958
        },
        "yi-34b-chat": {
            "rating": 1059.0499648215907,
            "rating_q975": 1083.5854473408233,
            "rating_q025": 1034.5144823023581
        },
        "gemini-pro-dev-api": {
            "rating": 1058.2099278112903,
            "rating_q975": 1080.9580894181843,
            "rating_q025": 1035.4617662043963
        },
        "qwen1.5-7b-chat": {
            "rating": 1052.6751865707406,
            "rating_q975": 1089.142305095236,
            "rating_q025": 1016.2080680462453
        },
        "phi-3-mini-4k-instruct-june-2024": {
            "rating": 1049.6723852302382,
            "rating_q975": 1075.4776173643997,
            "rating_q025": 1023.8671530960768
        },
        "openchat-3.5-0106": {
            "rating": 1046.9026884695872,
            "rating_q975": 1069.3997983030376,
            "rating_q025": 1024.4055786361369
        },
        "phi-3-mini-4k-instruct": {
            "rating": 1044.22685106819,
            "rating_q975": 1063.0820425303043,
            "rating_q025": 1025.3716596060756
        },
        "openchat-3.5": {
            "rating": 1039.7301528360506,
            "rating_q975": 1081.0646106191325,
            "rating_q025": 998.3956950529687
        },
        "gemma-1.1-7b-it": {
            "rating": 1037.2015707427122,
            "rating_q975": 1054.1881641150876,
            "rating_q025": 1020.2149773703368
        },
        "llama-2-70b-chat": {
            "rating": 1036.7769432804596,
            "rating_q975": 1053.4110742685507,
            "rating_q025": 1020.1428122923685
        },
        "mistral-7b-instruct-v0.2": {
            "rating": 1034.0613672776385,
            "rating_q975": 1054.0539055292304,
            "rating_q025": 1014.0688290260466
        },
        "llama-2-7b-chat": {
            "rating": 1032.3371267672755,
            "rating_q975": 1059.7636840939724,
            "rating_q025": 1004.9105694405787
        },
        "starling-lm-7b-alpha": {
            "rating": 1032.0639082955863,
            "rating_q975": 1062.7114221631714,
            "rating_q025": 1001.4163944280012
        },
        "llama-2-13b-chat": {
            "rating": 1028.6290185874493,
            "rating_q975": 1053.5931854668013,
            "rating_q025": 1003.6648517080973
        },
        "vicuna-33b": {
            "rating": 1027.7190805609773,
            "rating_q975": 1054.103590784723,
            "rating_q025": 1001.3345703372316
        },
        "snowflake-arctic-instruct": {
            "rating": 1025.9228637099134,
            "rating_q975": 1042.4815245591096,
            "rating_q025": 1009.3642028607171
        },
        "olmo-7b-instruct": {
            "rating": 1024.9387319318998,
            "rating_q975": 1063.5272102998347,
            "rating_q025": 986.350253563965
        },
        "llama-3.2-1b-instruct": {
            "rating": 1004.183502616389,
            "rating_q975": 1031.1627576351088,
            "rating_q025": 977.2042475976691
        },
        "zephyr-7b-beta": {
            "rating": 1003.7292212824336,
            "rating_q975": 1041.8550616423308,
            "rating_q025": 965.6033809225364
        },
        "gemma-7b-it": {
            "rating": 1000.7224031606692,
            "rating_q975": 1030.9644423879759,
            "rating_q025": 970.4803639333625
        },
        "vicuna-13b": {
            "rating": 991.903695230405,
            "rating_q975": 1023.1496347478322,
            "rating_q025": 960.6577557129777
        },
        "phi-3-mini-128k-instruct": {
            "rating": 982.6877791817692,
            "rating_q975": 1002.4610606307572,
            "rating_q025": 962.9144977327812
        },
        "qwen1.5-4b-chat": {
            "rating": 976.4900282490311,
            "rating_q975": 1007.676487640102,
            "rating_q025": 945.3035688579602
        },
        "gemma-1.1-2b-it": {
            "rating": 967.8915526760024,
            "rating_q975": 993.3484412475746,
            "rating_q025": 942.4346641044303
        },
        "mistral-7b-instruct": {
            "rating": 951.604254432563,
            "rating_q975": 991.2946957499319,
            "rating_q025": 911.9138131151942
        }
    },
    "french": {
        "glm-4.6": {
            "rating": 1490.6519805928272,
            "rating_q975": 1546.333762602004,
            "rating_q025": 1434.9701985836502
        },
        "mistral-medium-2508": {
            "rating": 1483.429601711797,
            "rating_q975": 1515.0035903250437,
            "rating_q025": 1451.8556130985503
        },
        "gemini-2.5-pro": {
            "rating": 1477.3467630157825,
            "rating_q975": 1501.7949167459815,
            "rating_q025": 1452.8986092855835
        },
        "grok-3-preview-02-24": {
            "rating": 1468.3673081413351,
            "rating_q975": 1500.894289824146,
            "rating_q025": 1435.8403264585243
        },
        "longcat-flash-chat": {
            "rating": 1463.5556848966703,
            "rating_q975": 1513.5822606257173,
            "rating_q025": 1413.5291091676233
        },
        "qwen3-235b-a22b-instruct-2507": {
            "rating": 1461.5708474845394,
            "rating_q975": 1490.3925281139584,
            "rating_q025": 1432.7491668551204
        },
        "deepseek-v3.1": {
            "rating": 1460.1603322561316,
            "rating_q975": 1499.4635080345197,
            "rating_q025": 1420.8571564777435
        },
        "claude-opus-4-1-20250805-thinking-16k": {
            "rating": 1456.6531977020263,
            "rating_q975": 1489.6864239501488,
            "rating_q025": 1423.6199714539039
        },
        "qwen3-max-preview": {
            "rating": 1454.0437427022687,
            "rating_q975": 1488.0509687553583,
            "rating_q025": 1420.036516649179
        },
        "o3-2025-04-16": {
            "rating": 1450.7476665948132,
            "rating_q975": 1476.3517522941656,
            "rating_q025": 1425.1435808954607
        },
        "chatgpt-4o-latest-20250326": {
            "rating": 1449.1929705389593,
            "rating_q975": 1476.2590650882096,
            "rating_q025": 1422.126875989709
        },
        "claude-opus-4-1-20250805": {
            "rating": 1443.8041474911827,
            "rating_q975": 1471.4059764268175,
            "rating_q025": 1416.202318555548
        },
        "glm-4.5": {
            "rating": 1439.894284461281,
            "rating_q975": 1474.9908728221121,
            "rating_q025": 1404.7976961004497
        },
        "gemini-2.5-flash-preview-09-2025": {
            "rating": 1434.9748036970348,
            "rating_q975": 1478.961915961902,
            "rating_q025": 1390.9876914321676
        },
        "gemini-2.5-flash": {
            "rating": 1431.0021636219353,
            "rating_q975": 1454.8903738269623,
            "rating_q025": 1407.1139534169083
        },
        "mai-1-preview": {
            "rating": 1430.709231799922,
            "rating_q975": 1468.1153519740872,
            "rating_q025": 1393.3031116257569
        },
        "deepseek-r1-0528": {
            "rating": 1430.2130558483025,
            "rating_q975": 1469.9320725484286,
            "rating_q025": 1390.4940391481764
        },
        "grok-4-0709": {
            "rating": 1426.2794512788766,
            "rating_q975": 1457.6743728246759,
            "rating_q025": 1394.8845297330774
        },
        "gpt-4.5-preview-2025-02-27": {
            "rating": 1425.228765845872,
            "rating_q975": 1481.531692206113,
            "rating_q025": 1368.925839485631
        },
        "glm-4.5-air": {
            "rating": 1424.204732078592,
            "rating_q975": 1455.8695995686962,
            "rating_q025": 1392.539864588488
        },
        "qwen3-coder-480b-a35b-instruct": {
            "rating": 1420.6257699749306,
            "rating_q975": 1457.485703891408,
            "rating_q025": 1383.765836058453
        },
        "qwen3-next-80b-a3b-instruct": {
            "rating": 1420.526975010773,
            "rating_q975": 1458.1634934749804,
            "rating_q025": 1382.8904565465655
        },
        "gpt-5-chat": {
            "rating": 1419.838190975829,
            "rating_q975": 1453.3881137810113,
            "rating_q025": 1386.288268170647
        },
        "deepseek-v3.2-exp-thinking": {
            "rating": 1415.5233694730978,
            "rating_q975": 1465.6452106556794,
            "rating_q025": 1365.4015282905161
        },
        "qwen3-30b-a3b-instruct-2507": {
            "rating": 1415.5200760621071,
            "rating_q975": 1450.5742380358397,
            "rating_q025": 1380.4659140883746
        },
        "claude-sonnet-4-5-20250929-thinking-32k": {
            "rating": 1403.9687462148383,
            "rating_q975": 1453.3181059902715,
            "rating_q025": 1354.6193864394052
        },
        "qwen2.5-max": {
            "rating": 1401.7168549748549,
            "rating_q975": 1434.60006202826,
            "rating_q025": 1368.8336479214497
        },
        "gpt-4.1-2025-04-14": {
            "rating": 1401.3623666062183,
            "rating_q975": 1427.6785040907996,
            "rating_q025": 1375.046229121637
        },
        "gemini-2.5-flash-lite-preview-09-2025-no-thinking": {
            "rating": 1398.9660527400456,
            "rating_q975": 1442.9238249064467,
            "rating_q025": 1355.0082805736445
        },
        "claude-opus-4-20250514-thinking-16k": {
            "rating": 1397.5539254077585,
            "rating_q975": 1427.4783260327752,
            "rating_q025": 1367.6295247827418
        },
        "gpt-5-high": {
            "rating": 1397.1161923889542,
            "rating_q975": 1430.4945683966296,
            "rating_q025": 1363.737816381279
        },
        "gpt-5-mini-high": {
            "rating": 1395.2325897744024,
            "rating_q975": 1431.9485887956832,
            "rating_q025": 1358.5165907531216
        },
        "deepseek-v3-0324": {
            "rating": 1394.9942795123454,
            "rating_q975": 1422.1719535450075,
            "rating_q025": 1367.8166054796834
        },
        "gemini-2.5-flash-lite-preview-06-17-thinking": {
            "rating": 1393.5202008760764,
            "rating_q975": 1425.2917503678366,
            "rating_q025": 1361.7486513843162
        },
        "qwen3-next-80b-a3b-thinking": {
            "rating": 1389.9248822719767,
            "rating_q975": 1432.5078407482195,
            "rating_q025": 1347.341923795734
        },
        "qwen3-235b-a22b-no-thinking": {
            "rating": 1385.7841367693102,
            "rating_q975": 1414.710785287302,
            "rating_q025": 1356.8574882513183
        },
        "minimax-m1": {
            "rating": 1383.545078294141,
            "rating_q975": 1413.847293601342,
            "rating_q025": 1353.2428629869398
        },
        "claude-haiku-4-5-20251001": {
            "rating": 1382.6243415201527,
            "rating_q975": 1435.246256195323,
            "rating_q025": 1330.0024268449824
        },
        "hunyuan-turbos-20250416": {
            "rating": 1381.3422960728908,
            "rating_q975": 1430.4687657168276,
            "rating_q025": 1332.215826428954
        },
        "gemma-3-27b-it": {
            "rating": 1380.8777125091751,
            "rating_q975": 1406.582872350284,
            "rating_q025": 1355.1725526680661
        },
        "mistral-medium-2505": {
            "rating": 1380.8445317807784,
            "rating_q975": 1409.9433704686303,
            "rating_q025": 1351.7456930929266
        },
        "kimi-k2-0711-preview": {
            "rating": 1376.3920887886534,
            "rating_q975": 1409.4037045779862,
            "rating_q025": 1343.3804729993205
        },
        "claude-sonnet-4-20250514": {
            "rating": 1373.6287326638137,
            "rating_q975": 1401.761434320547,
            "rating_q025": 1345.4960310070803
        },
        "deepseek-r1": {
            "rating": 1373.4480781366376,
            "rating_q975": 1415.9393548164144,
            "rating_q025": 1330.9568014568608
        },
        "qwen3-235b-a22b": {
            "rating": 1370.6218112240235,
            "rating_q975": 1403.9818199329923,
            "rating_q025": 1337.2618025150548
        },
        "claude-sonnet-4-20250514-thinking-32k": {
            "rating": 1369.1530459003707,
            "rating_q975": 1398.6574357344996,
            "rating_q025": 1339.6486560662418
        },
        "grok-3-mini-beta": {
            "rating": 1367.7249908116007,
            "rating_q975": 1405.6325444264155,
            "rating_q025": 1329.817437196786
        },
        "o4-mini-2025-04-16": {
            "rating": 1365.886224013272,
            "rating_q975": 1393.0069792436823,
            "rating_q025": 1338.765468782862
        },
        "qwen3-30b-a3b": {
            "rating": 1364.8261849617645,
            "rating_q975": 1397.9725814522665,
            "rating_q025": 1331.6797884712626
        },
        "claude-opus-4-20250514": {
            "rating": 1361.0445697148575,
            "rating_q975": 1388.5622942080174,
            "rating_q025": 1333.5268452216976
        },
        "gpt-4.1-mini-2025-04-14": {
            "rating": 1360.625282176669,
            "rating_q975": 1388.7231453858396,
            "rating_q025": 1332.5274189674985
        },
        "command-a-03-2025": {
            "rating": 1355.8561535638398,
            "rating_q975": 1381.744522381698,
            "rating_q025": 1329.9677847459816
        },
        "gemini-2.0-flash-lite-preview-02-05": {
            "rating": 1355.3555589012706,
            "rating_q975": 1393.393389498184,
            "rating_q025": 1317.3177283043572
        },
        "grok-3-mini-high": {
            "rating": 1352.3810845815206,
            "rating_q975": 1397.3371288727126,
            "rating_q025": 1307.4250402903285
        },
        "o1-preview": {
            "rating": 1352.1503723776445,
            "rating_q975": 1385.6812555202075,
            "rating_q025": 1318.6194892350816
        },
        "gpt-oss-120b": {
            "rating": 1351.7948759215108,
            "rating_q975": 1384.5756106417743,
            "rating_q025": 1319.0141412012472
        },
        "o1-2024-12-17": {
            "rating": 1351.346494003969,
            "rating_q975": 1387.9203828079867,
            "rating_q025": 1314.7726051999512
        },
        "qwq-32b": {
            "rating": 1349.839352423749,
            "rating_q975": 1384.5562967511446,
            "rating_q025": 1315.1224080963534
        },
        "deepseek-v3": {
            "rating": 1349.3934009226691,
            "rating_q975": 1386.1672676080514,
            "rating_q025": 1312.6195342372869
        },
        "o3-mini-high": {
            "rating": 1341.3842995909524,
            "rating_q975": 1385.5995357875302,
            "rating_q025": 1297.1690633943747
        },
        "mistral-small-2506": {
            "rating": 1341.0261076087304,
            "rating_q975": 1382.4241321293605,
            "rating_q025": 1299.6280830881003
        },
        "athene-v2-chat": {
            "rating": 1340.2504941839782,
            "rating_q975": 1376.553283814005,
            "rating_q025": 1303.9477045539513
        },
        "qwen-max-0919": {
            "rating": 1337.107800770028,
            "rating_q975": 1377.2477420423952,
            "rating_q025": 1296.9678594976608
        },
        "gemma-3n-e4b-it": {
            "rating": 1336.622333536438,
            "rating_q975": 1371.975301589337,
            "rating_q025": 1301.2693654835389
        },
        "o3-mini": {
            "rating": 1332.5821737432136,
            "rating_q975": 1356.9791327250757,
            "rating_q025": 1308.1852147613515
        },
        "mistral-large-2411": {
            "rating": 1332.2185212237482,
            "rating_q975": 1372.6441533744342,
            "rating_q025": 1291.7928890730623
        },
        "grok-2-2024-08-13": {
            "rating": 1324.8469903011191,
            "rating_q975": 1349.1390571036877,
            "rating_q025": 1300.5549234985506
        },
        "glm-4-plus": {
            "rating": 1315.2178593338008,
            "rating_q975": 1350.4414379375653,
            "rating_q025": 1279.9942807300363
        },
        "gemini-advanced-0514": {
            "rating": 1314.0675094194862,
            "rating_q975": 1337.7174450732925,
            "rating_q025": 1290.41757376568
        },
        "gpt-4o-2024-05-13": {
            "rating": 1312.5469800134856,
            "rating_q975": 1330.7154719132882,
            "rating_q025": 1294.378488113683
        },
        "yi-lightning": {
            "rating": 1312.012848158292,
            "rating_q975": 1347.3481569564008,
            "rating_q025": 1276.6775393601831
        },
        "gemini-1.5-pro-002": {
            "rating": 1308.6212777730861,
            "rating_q975": 1335.5970741030455,
            "rating_q025": 1281.6454814431268
        },
        "claude-3-5-sonnet-20241022": {
            "rating": 1307.313468448007,
            "rating_q975": 1328.1197766920288,
            "rating_q025": 1286.507160203985
        },
        "gpt-4o-mini-2024-07-18": {
            "rating": 1303.979803334791,
            "rating_q975": 1326.3734469283527,
            "rating_q025": 1281.5861597412295
        },
        "claude-3-5-sonnet-20240620": {
            "rating": 1300.9824646565285,
            "rating_q975": 1321.937205269597,
            "rating_q025": 1280.02772404346
        },
        "o1-mini": {
            "rating": 1300.136909408086,
            "rating_q975": 1328.5309020855086,
            "rating_q025": 1271.7429167306634
        },
        "llama-4-scout-17b-16e-instruct": {
            "rating": 1298.05279289486,
            "rating_q975": 1329.9790371183012,
            "rating_q025": 1266.1265486714187
        },
        "deepseek-v2.5": {
            "rating": 1294.186841731589,
            "rating_q975": 1331.4095684591034,
            "rating_q025": 1256.9641150040748
        },
        "athene-70b-0725": {
            "rating": 1293.6022485232934,
            "rating_q975": 1334.668880060029,
            "rating_q025": 1252.5356169865577
        },
        "grok-2-mini-2024-08-13": {
            "rating": 1293.3896547687202,
            "rating_q975": 1320.3991421763549,
            "rating_q025": 1266.3801673610856
        },
        "llama-3.3-70b-instruct": {
            "rating": 1290.9006905802971,
            "rating_q975": 1316.5966677448482,
            "rating_q025": 1265.204713415746
        },
        "gpt-4-1106-preview": {
            "rating": 1289.8211027984867,
            "rating_q975": 1308.1098976498272,
            "rating_q025": 1271.5323079471461
        },
        "gpt-4-0125-preview": {
            "rating": 1288.461197202868,
            "rating_q975": 1307.6778065446936,
            "rating_q025": 1269.2445878610426
        },
        "claude-3-7-sonnet-20250219-thinking-32k": {
            "rating": 1285.9334216954214,
            "rating_q975": 1315.6891174946477,
            "rating_q025": 1256.1777258961952
        },
        "qwen2.5-72b-instruct": {
            "rating": 1285.5586771395388,
            "rating_q975": 1316.6781607061598,
            "rating_q025": 1254.4391935729177
        },
        "llama-3.1-405b-instruct-bf16": {
            "rating": 1284.9029286422906,
            "rating_q975": 1314.4808104037543,
            "rating_q025": 1255.325046880827
        },
        "gpt-4-turbo-2024-04-09": {
            "rating": 1283.0352969021658,
            "rating_q975": 1301.9824510696017,
            "rating_q025": 1264.08814273473
        },
        "claude-3-opus-20240229": {
            "rating": 1281.991123703432,
            "rating_q975": 1297.3759067844012,
            "rating_q025": 1266.606340622463
        },
        "amazon-nova-pro-v1.0": {
            "rating": 1281.5522730385073,
            "rating_q975": 1319.4415942795001,
            "rating_q025": 1243.6629517975146
        },
        "mistral-large-2407": {
            "rating": 1279.9862187104166,
            "rating_q975": 1307.7889536599018,
            "rating_q025": 1252.1834837609313
        },
        "llama-3.1-405b-instruct-fp8": {
            "rating": 1279.8612755178492,
            "rating_q975": 1305.4524243904827,
            "rating_q025": 1254.2701266452157
        },
        "gemini-1.5-pro-001": {
            "rating": 1279.7402524117992,
            "rating_q975": 1299.8815973027192,
            "rating_q025": 1259.5989075208793
        },
        "gpt-4o-2024-08-06": {
            "rating": 1269.5609289681565,
            "rating_q975": 1295.9910947542583,
            "rating_q025": 1243.1307631820548
        },
        "claude-3-5-haiku-20241022": {
            "rating": 1268.561426880283,
            "rating_q975": 1291.8688465043329,
            "rating_q025": 1245.2540072562333
        },
        "llama-3.1-70b-instruct": {
            "rating": 1268.4849599947693,
            "rating_q975": 1295.2745480144895,
            "rating_q025": 1241.695371975049
        },
        "gemini-1.5-flash-002": {
            "rating": 1265.3085988535627,
            "rating_q975": 1298.2225331407672,
            "rating_q025": 1232.3946645663582
        },
        "mistral-small-3.1-24b-instruct-2503": {
            "rating": 1264.403433020301,
            "rating_q975": 1297.0959892660246,
            "rating_q025": 1231.7108767745774
        },
        "magistral-medium-2506": {
            "rating": 1262.9238311474862,
            "rating_q975": 1313.2549013350374,
            "rating_q025": 1212.592760959935
        },
        "llama-4-maverick-17b-128e-instruct": {
            "rating": 1260.8063986095308,
            "rating_q975": 1288.2073524051293,
            "rating_q025": 1233.4054448139323
        },
        "c4ai-aya-expanse-32b": {
            "rating": 1254.9461692480013,
            "rating_q975": 1288.3430039366938,
            "rating_q025": 1221.5493345593088
        },
        "gemma-2-27b-it": {
            "rating": 1254.286201074292,
            "rating_q975": 1275.1745631631989,
            "rating_q025": 1233.397838985385
        },
        "gemini-1.5-flash-001": {
            "rating": 1247.7236821197766,
            "rating_q975": 1269.32427895878,
            "rating_q025": 1226.1230852807732
        },
        "amazon-nova-micro-v1.0": {
            "rating": 1246.0773152513339,
            "rating_q975": 1290.2943359410117,
            "rating_q025": 1201.860294561656
        },
        "amazon-nova-lite-v1.0": {
            "rating": 1242.0031597953707,
            "rating_q975": 1286.1813996312212,
            "rating_q025": 1197.8249199595202
        },
        "gemini-1.5-flash-8b-001": {
            "rating": 1241.9136706857628,
            "rating_q975": 1273.4026025387695,
            "rating_q025": 1210.424738832756
        },
        "llama-3-70b-instruct": {
            "rating": 1239.6906916128837,
            "rating_q975": 1256.1664109923872,
            "rating_q025": 1223.2149722333802
        },
        "claude-3-sonnet-20240229": {
            "rating": 1236.361741150447,
            "rating_q975": 1254.2489530793746,
            "rating_q025": 1218.4745292215193
        },
        "phi-4": {
            "rating": 1231.7536396585824,
            "rating_q975": 1271.044045992422,
            "rating_q025": 1192.4632333247428
        },
        "gpt-4-0314": {
            "rating": 1226.5482122537087,
            "rating_q975": 1250.084875363863,
            "rating_q025": 1203.0115491435545
        },
        "mistral-large-2402": {
            "rating": 1216.8696881871003,
            "rating_q975": 1238.0587500432607,
            "rating_q025": 1195.68062633094
        },
        "command-r-plus": {
            "rating": 1215.5838340913135,
            "rating_q975": 1235.671213236536,
            "rating_q025": 1195.496454946091
        },
        "mistral-small-24b-instruct-2501": {
            "rating": 1210.5635843991058,
            "rating_q975": 1260.3152471443582,
            "rating_q025": 1160.8119216538535
        },
        "nemotron-4-340b-instruct": {
            "rating": 1207.0533798979336,
            "rating_q975": 1239.5912844650568,
            "rating_q025": 1174.5154753308104
        },
        "claude-3-haiku-20240307": {
            "rating": 1201.3970804750086,
            "rating_q975": 1219.0993809730116,
            "rating_q025": 1183.6947799770055
        },
        "gemma-2-9b-it": {
            "rating": 1197.7849773094138,
            "rating_q975": 1221.9442720881834,
            "rating_q025": 1173.625682530644
        },
        "deepseek-coder-v2": {
            "rating": 1190.638635355662,
            "rating_q975": 1231.0011993517405,
            "rating_q025": 1150.2760713595835
        },
        "mistral-medium": {
            "rating": 1187.0678211231339,
            "rating_q975": 1212.0557514373606,
            "rating_q025": 1162.079890808907
        },
        "llama-3.1-8b-instruct": {
            "rating": 1186.3578297551567,
            "rating_q975": 1214.1048275597104,
            "rating_q025": 1158.610831950603
        },
        "reka-flash-21b-20240226": {
            "rating": 1183.022650467422,
            "rating_q975": 1212.5042139417242,
            "rating_q025": 1153.5410869931197
        },
        "qwen2-72b-instruct": {
            "rating": 1177.6532386051451,
            "rating_q975": 1201.9606890478094,
            "rating_q025": 1153.3457881624809
        },
        "gpt-4-0613": {
            "rating": 1177.5442730981774,
            "rating_q975": 1196.7127780031635,
            "rating_q025": 1158.3757681931913
        },
        "mixtral-8x7b-instruct-v0.1": {
            "rating": 1173.387246885659,
            "rating_q975": 1193.3344341272148,
            "rating_q025": 1153.440059644103
        },
        "mixtral-8x22b-instruct-v0.1": {
            "rating": 1173.074388808452,
            "rating_q975": 1196.5245430892987,
            "rating_q025": 1149.6242345276055
        },
        "command-r": {
            "rating": 1169.1976323277827,
            "rating_q975": 1192.1185116625527,
            "rating_q025": 1146.2767529930127
        },
        "reka-flash-21b-20240226-online": {
            "rating": 1168.5879138258265,
            "rating_q975": 1208.2047708524497,
            "rating_q025": 1128.9710567992033
        },
        "llama-3-8b-instruct": {
            "rating": 1167.3186714105918,
            "rating_q975": 1186.0532386038278,
            "rating_q025": 1148.5841042173558
        },
        "qwen1.5-72b-chat": {
            "rating": 1166.8297210450396,
            "rating_q975": 1189.5041681672485,
            "rating_q025": 1144.1552739228307
        },
        "gemma-2-2b-it": {
            "rating": 1164.4472372794926,
            "rating_q975": 1193.123336786698,
            "rating_q025": 1135.7711377722871
        },
        "yi-1.5-34b-chat": {
            "rating": 1162.5058819821454,
            "rating_q975": 1192.8266817503372,
            "rating_q025": 1132.1850822139536
        },
        "qwen1.5-110b-chat": {
            "rating": 1160.146222205775,
            "rating_q975": 1191.3370477099397,
            "rating_q025": 1128.9553967016104
        },
        "gemini-pro-dev-api": {
            "rating": 1152.4840677067546,
            "rating_q975": 1183.230794468266,
            "rating_q025": 1121.7373409452432
        },
        "phi-3-small-8k-instruct": {
            "rating": 1142.5074738868216,
            "rating_q975": 1177.0721499693586,
            "rating_q025": 1107.9427978042845
        },
        "snowflake-arctic-instruct": {
            "rating": 1141.0224955077138,
            "rating_q975": 1169.5047257562655,
            "rating_q025": 1112.540265259162
        },
        "gpt-3.5-turbo-0125": {
            "rating": 1125.456875874542,
            "rating_q975": 1145.7438379662603,
            "rating_q025": 1105.1699137828236
        },
        "qwen1.5-14b-chat": {
            "rating": 1124.1882007761087,
            "rating_q975": 1161.7024435263318,
            "rating_q025": 1086.6739580258857
        },
        "starling-lm-7b-beta": {
            "rating": 1123.4341956017117,
            "rating_q975": 1161.3216015431778,
            "rating_q025": 1085.5467896602456
        },
        "phi-3-medium-4k-instruct": {
            "rating": 1121.7380870159523,
            "rating_q975": 1154.2438088483652,
            "rating_q025": 1089.2323651835393
        },
        "qwen1.5-32b-chat": {
            "rating": 1106.926394089976,
            "rating_q975": 1140.9022088055813,
            "rating_q025": 1072.9505793743706
        },
        "dbrx-instruct-preview": {
            "rating": 1103.6934974287506,
            "rating_q975": 1131.95958784676,
            "rating_q025": 1075.427407010741
        },
        "openchat-3.5-0106": {
            "rating": 1099.3474073886696,
            "rating_q975": 1141.3027822378867,
            "rating_q025": 1057.3920325394524
        },
        "llama-2-70b-chat": {
            "rating": 1097.4580949564788,
            "rating_q975": 1123.2433978973697,
            "rating_q025": 1071.672792015588
        },
        "vicuna-33b": {
            "rating": 1093.2764826203427,
            "rating_q975": 1129.856998622874,
            "rating_q025": 1056.6959666178113
        },
        "starling-lm-7b-alpha": {
            "rating": 1092.560463513947,
            "rating_q975": 1134.6515896229396,
            "rating_q025": 1050.4693374049546
        },
        "yi-34b-chat": {
            "rating": 1088.4246350377625,
            "rating_q975": 1128.2528566318827,
            "rating_q025": 1048.5964134436424
        },
        "phi-3-mini-4k-instruct": {
            "rating": 1085.510124045045,
            "rating_q975": 1120.0525181246478,
            "rating_q025": 1050.967729965442
        },
        "gemma-1.1-7b-it": {
            "rating": 1074.1545034577332,
            "rating_q975": 1104.7794789920606,
            "rating_q025": 1043.5295279234058
        },
        "gpt-3.5-turbo-1106": {
            "rating": 1073.5767454722131,
            "rating_q975": 1111.5381083040404,
            "rating_q025": 1035.6153826403859
        },
        "llama-2-13b-chat": {
            "rating": 1052.9281554872223,
            "rating_q975": 1091.1272512938356,
            "rating_q025": 1014.729059680609
        },
        "phi-3-mini-128k-instruct": {
            "rating": 1046.7673327836812,
            "rating_q975": 1080.1992155066578,
            "rating_q025": 1013.3354500607048
        },
        "mistral-7b-instruct-v0.2": {
            "rating": 1043.1645951292974,
            "rating_q975": 1073.7417366096668,
            "rating_q025": 1012.5874536489281
        },
        "zephyr-7b-beta": {
            "rating": 1039.638542951403,
            "rating_q975": 1087.4690700458425,
            "rating_q025": 991.8080158569635
        },
        "stripedhyena-nous-7b": {
            "rating": 1038.5039169225695,
            "rating_q975": 1087.1738673479267,
            "rating_q025": 989.8339664972123
        },
        "gemma-7b-it": {
            "rating": 1030.2549712798912,
            "rating_q975": 1077.1725631542374,
            "rating_q025": 983.337379405545
        },
        "vicuna-13b": {
            "rating": 1028.896146983264,
            "rating_q975": 1072.9173070982383,
            "rating_q025": 984.8749868682897
        },
        "llama-2-7b-chat": {
            "rating": 980.3530784882922,
            "rating_q975": 1022.3018873858866,
            "rating_q025": 938.4042695906978
        },
        "mistral-7b-instruct": {
            "rating": 954.023545305819,
            "rating_q975": 1001.5997244003979,
            "rating_q025": 906.44736621124
        }
    },
    "full": {
        "gemini-2.5-pro": {
            "rating": 1465.625277217937,
            "rating_q975": 1469.5989558380963,
            "rating_q025": 1461.6515985977778
        },
        "glm-4.6": {
            "rating": 1445.1792559872335,
            "rating_q975": 1451.552223668318,
            "rating_q025": 1438.806288306149
        },
        "qwen3-max-preview": {
            "rating": 1437.485751935854,
            "rating_q975": 1442.3217873173521,
            "rating_q025": 1432.649716554356
        },
        "deepseek-v3.2-exp": {
            "rating": 1434.0670313286103,
            "rating_q975": 1461.088149762604,
            "rating_q025": 1407.0459128946165
        },
        "mistral-medium-2508": {
            "rating": 1431.3807182593366,
            "rating_q975": 1436.011986143988,
            "rating_q025": 1426.7494503746852
        },
        "glm-4.5": {
            "rating": 1427.8865441862843,
            "rating_q975": 1432.7683975567015,
            "rating_q025": 1423.004690815867
        },
        "claude-sonnet-4-5-20250929-thinking-32k": {
            "rating": 1426.4989411717793,
            "rating_q975": 1432.429610175199,
            "rating_q025": 1420.5682721683595
        },
        "chatgpt-4o-latest-20250326": {
            "rating": 1426.3125912744918,
            "rating_q975": 1430.1323475296244,
            "rating_q025": 1422.492835019359
        },
        "deepseek-r1-0528": {
            "rating": 1425.374303699052,
            "rating_q975": 1430.971989427773,
            "rating_q025": 1419.776617970331
        },
        "grok-3-preview-02-24": {
            "rating": 1424.153737043154,
            "rating_q975": 1428.371089801565,
            "rating_q025": 1419.936384284743
        },
        "qwen3-vl-235b-a22b-instruct": {
            "rating": 1422.1698196778452,
            "rating_q975": 1428.8367129133082,
            "rating_q025": 1415.5029264423822
        },
        "longcat-flash-chat": {
            "rating": 1421.968495791276,
            "rating_q975": 1428.3557136009506,
            "rating_q025": 1415.5812779816013
        },
        "deepseek-v3.2-exp-thinking": {
            "rating": 1421.6552794880704,
            "rating_q975": 1428.2248583394403,
            "rating_q025": 1415.0857006367005
        },
        "claude-sonnet-4-5-20250929": {
            "rating": 1421.6324138939167,
            "rating_q975": 1429.151586133395,
            "rating_q025": 1414.1132416544383
        },
        "claude-opus-4-1-20250805-thinking-16k": {
            "rating": 1419.718419502472,
            "rating_q975": 1424.3494640440101,
            "rating_q025": 1415.0873749609339
        },
        "qwen3-next-80b-a3b-instruct": {
            "rating": 1419.2293455646154,
            "rating_q975": 1424.385978954211,
            "rating_q025": 1414.07271217502
        },
        "deepseek-v3.1": {
            "rating": 1418.9688542124022,
            "rating_q975": 1425.0012820645568,
            "rating_q025": 1412.9364263602477
        },
        "deepseek-v3.1-terminus": {
            "rating": 1418.0654467290506,
            "rating_q975": 1427.6808406517973,
            "rating_q025": 1408.4500528063038
        },
        "deepseek-v3.1-terminus-thinking": {
            "rating": 1417.3345306411397,
            "rating_q975": 1427.2623527531784,
            "rating_q025": 1407.406708529101
        },
        "gpt-4.5-preview-2025-02-27": {
            "rating": 1417.2963939973833,
            "rating_q975": 1422.9214998877567,
            "rating_q025": 1411.67128810701
        },
        "qwen3-235b-a22b-instruct-2507": {
            "rating": 1416.81641278148,
            "rating_q975": 1421.1740330139748,
            "rating_q025": 1412.4587925489852
        },
        "deepseek-v3.1-thinking": {
            "rating": 1416.4283126464538,
            "rating_q975": 1423.0191832218868,
            "rating_q025": 1409.8374420710209
        },
        "gemini-2.5-flash": {
            "rating": 1414.1072764849398,
            "rating_q975": 1417.9939260408648,
            "rating_q025": 1410.2206269290148
        },
        "qwen3-max-2025-09-23": {
            "rating": 1414.0373923177344,
            "rating_q975": 1420.4692505292394,
            "rating_q025": 1407.6055341062295
        },
        "qwen3-235b-a22b-thinking-2507": {
            "rating": 1413.3213907869685,
            "rating_q975": 1419.7560104157617,
            "rating_q025": 1406.8867711581754
        },
        "claude-opus-4-1-20250805": {
            "rating": 1411.2709646657029,
            "rating_q975": 1415.698310350722,
            "rating_q025": 1406.8436189806837
        },
        "o3-2025-04-16": {
            "rating": 1411.1015598458416,
            "rating_q975": 1414.8644952855261,
            "rating_q025": 1407.3386244061571
        },
        "grok-4-0709": {
            "rating": 1410.2303579336447,
            "rating_q975": 1414.5020149629859,
            "rating_q025": 1405.9587009043034
        },
        "gemini-2.5-flash-preview-09-2025": {
            "rating": 1408.469927657332,
            "rating_q975": 1414.1045639881702,
            "rating_q025": 1402.8352913264937
        },
        "grok-4-fast": {
            "rating": 1407.4644782587584,
            "rating_q975": 1415.0310611652278,
            "rating_q025": 1399.897895352289
        },
        "gpt-5-high": {
            "rating": 1407.00594017973,
            "rating_q975": 1411.7130436439563,
            "rating_q025": 1402.2988367155037
        },
        "gpt-5-chat": {
            "rating": 1403.3996527979416,
            "rating_q975": 1407.9627876663296,
            "rating_q025": 1398.8365179295536
        },
        "qwen3-vl-235b-a22b-thinking": {
            "rating": 1400.0981465645682,
            "rating_q975": 1406.9162755333884,
            "rating_q025": 1393.280017595748
        },
        "hunyuan-t1-20250711": {
            "rating": 1397.9090633332653,
            "rating_q975": 1406.4282845248943,
            "rating_q025": 1389.3898421416363
        },
        "mai-1-preview": {
            "rating": 1393.7769759210428,
            "rating_q975": 1399.2275937074821,
            "rating_q025": 1388.3263581346034
        },
        "qwen3-235b-a22b-no-thinking": {
            "rating": 1391.8383774025451,
            "rating_q975": 1396.3317316705218,
            "rating_q025": 1387.3450231345685
        },
        "claude-haiku-4-5-20251001": {
            "rating": 1386.6012959838104,
            "rating_q975": 1392.980941647947,
            "rating_q025": 1380.2216503196737
        },
        "qwen3-30b-a3b-instruct-2507": {
            "rating": 1384.0411520353778,
            "rating_q975": 1388.9341681779792,
            "rating_q025": 1379.1481358927763
        },
        "gpt-4.1-2025-04-14": {
            "rating": 1383.237769735903,
            "rating_q975": 1387.1187266380257,
            "rating_q025": 1379.3568128337802
        },
        "glm-4.5-air": {
            "rating": 1382.5909846004847,
            "rating_q975": 1387.0917649911564,
            "rating_q025": 1378.090204209813
        },
        "gemini-2.5-flash-lite-preview-09-2025-no-thinking": {
            "rating": 1379.7760897560843,
            "rating_q975": 1385.3776789600063,
            "rating_q025": 1374.1745005521623
        },
        "kimi-k2-0905-preview": {
            "rating": 1378.7911664821695,
            "rating_q975": 1385.6264239980246,
            "rating_q025": 1371.9559089663144
        },
        "hunyuan-turbos-20250416": {
            "rating": 1375.251557246581,
            "rating_q975": 1381.5542495378659,
            "rating_q025": 1368.948864955296
        },
        "claude-opus-4-20250514-thinking-16k": {
            "rating": 1374.6794178140706,
            "rating_q975": 1379.0886456351695,
            "rating_q025": 1370.2701899929716
        },
        "gpt-5-mini-high": {
            "rating": 1374.4434350921629,
            "rating_q975": 1379.3086288426073,
            "rating_q025": 1369.5782413417185
        },
        "deepseek-v3-0324": {
            "rating": 1373.9952730618943,
            "rating_q975": 1377.8506850423769,
            "rating_q025": 1370.1398610814117
        },
        "deepseek-r1": {
            "rating": 1372.4377903791287,
            "rating_q975": 1377.1893873257952,
            "rating_q025": 1367.6861934324622
        },
        "kimi-k2-0711-preview": {
            "rating": 1370.2715519147441,
            "rating_q975": 1375.1081217583885,
            "rating_q025": 1365.4349820710997
        },
        "gemini-2.5-flash-lite-preview-06-17-thinking": {
            "rating": 1369.050125038838,
            "rating_q975": 1373.5368112895676,
            "rating_q025": 1364.5634387881082
        },
        "mistral-medium-2505": {
            "rating": 1368.333359796909,
            "rating_q975": 1373.0008996562958,
            "rating_q025": 1363.6658199375222
        },
        "grok-3-mini-high": {
            "rating": 1367.3932308410865,
            "rating_q975": 1372.698489714616,
            "rating_q025": 1362.087971967557
        },
        "qwen3-next-80b-a3b-thinking": {
            "rating": 1366.9241057116037,
            "rating_q975": 1372.80717725834,
            "rating_q025": 1361.0410341648674
        },
        "qwen2.5-max": {
            "rating": 1366.7281475541477,
            "rating_q975": 1370.686172588445,
            "rating_q025": 1362.7701225198502
        },
        "qwen3-235b-a22b": {
            "rating": 1366.4685285673656,
            "rating_q975": 1371.1621962434194,
            "rating_q025": 1361.7748608913118
        },
        "o1-2024-12-17": {
            "rating": 1365.4243131002006,
            "rating_q975": 1369.7713984931518,
            "rating_q025": 1361.0772277072494
        },
        "claude-opus-4-20250514": {
            "rating": 1364.505757705948,
            "rating_q975": 1368.8153453161149,
            "rating_q025": 1360.1961700957813
        },
        "ling-flash-2.0": {
            "rating": 1363.6917150970498,
            "rating_q975": 1370.8795494385215,
            "rating_q025": 1356.5038807555782
        },
        "grok-3-mini-beta": {
            "rating": 1363.0263263364773,
            "rating_q975": 1367.9978337768243,
            "rating_q025": 1358.0548188961302
        },
        "gpt-oss-120b": {
            "rating": 1362.62991408088,
            "rating_q975": 1367.2758335180454,
            "rating_q025": 1357.9839946437148
        },
        "amazon-nova-experimental-chat-10-09": {
            "rating": 1360.6516000684212,
            "rating_q975": 1368.2969818972472,
            "rating_q025": 1353.0062182395952
        },
        "gemma-3-27b-it": {
            "rating": 1357.647633470559,
            "rating_q975": 1361.2682670237136,
            "rating_q025": 1354.0269999174043
        },
        "qwen3-coder-480b-a35b-instruct": {
            "rating": 1356.3718716301973,
            "rating_q975": 1361.4029547620296,
            "rating_q025": 1351.340788498365
        },
        "o4-mini-2025-04-16": {
            "rating": 1353.7896360593477,
            "rating_q975": 1357.7521343139692,
            "rating_q025": 1349.8271378047261
        },
        "o1-preview": {
            "rating": 1352.8774704089744,
            "rating_q975": 1357.7753612721585,
            "rating_q025": 1347.9795795457903
        },
        "claude-sonnet-4-20250514-thinking-32k": {
            "rating": 1349.192195939605,
            "rating_q975": 1353.6637460501915,
            "rating_q025": 1344.7206458290184
        },
        "step-3": {
            "rating": 1348.7334699094372,
            "rating_q975": 1356.064946019325,
            "rating_q025": 1341.4019937995495
        },
        "minimax-m1": {
            "rating": 1346.9321053700282,
            "rating_q975": 1351.1958661693263,
            "rating_q025": 1342.6683445707301
        },
        "gpt-4.1-mini-2025-04-14": {
            "rating": 1340.341546993882,
            "rating_q975": 1344.6299175827314,
            "rating_q025": 1336.0531764050327
        },
        "qwen3-32b": {
            "rating": 1339.6067581248058,
            "rating_q975": 1348.9897179060704,
            "rating_q025": 1330.2237983435411
        },
        "mistral-small-2506": {
            "rating": 1339.316115832222,
            "rating_q975": 1344.4901256840444,
            "rating_q025": 1334.1421059803997
        },
        "claude-sonnet-4-20250514": {
            "rating": 1338.4420906556275,
            "rating_q975": 1342.844872430325,
            "rating_q025": 1334.0393088809299
        },
        "step-1o-turbo-202506": {
            "rating": 1336.397506990182,
            "rating_q975": 1343.0388180742184,
            "rating_q025": 1329.7561959061454
        },
        "nvidia-llama-3.3-nemotron-super-49b-v1.5": {
            "rating": 1336.2691280465965,
            "rating_q975": 1346.0711859025103,
            "rating_q025": 1326.4670701906828
        },
        "o3-mini-high": {
            "rating": 1336.1987148420449,
            "rating_q975": 1341.3665174584908,
            "rating_q025": 1331.030912225599
        },
        "glm-4.5v": {
            "rating": 1333.81488338669,
            "rating_q975": 1342.2014361697748,
            "rating_q025": 1325.4283306036054
        },
        "gemma-3-12b-it": {
            "rating": 1333.79800144951,
            "rating_q975": 1343.1880013305342,
            "rating_q025": 1324.4080015684856
        },
        "deepseek-v3": {
            "rating": 1333.0071812627014,
            "rating_q975": 1337.613837515227,
            "rating_q025": 1328.4005250101757
        },
        "ring-flash-2.0": {
            "rating": 1332.4814632659718,
            "rating_q975": 1339.6354806258055,
            "rating_q025": 1325.327445906138
        },
        "glm-4-plus-0111": {
            "rating": 1331.7464957329116,
            "rating_q975": 1340.1044323169367,
            "rating_q025": 1323.3885591488865
        },
        "command-a-03-2025": {
            "rating": 1329.8685132298242,
            "rating_q975": 1333.430785579078,
            "rating_q025": 1326.3062408805704
        },
        "gemini-2.0-flash-lite-preview-02-05": {
            "rating": 1329.7135838313886,
            "rating_q975": 1333.9044414215625,
            "rating_q025": 1325.5227262412147
        },
        "qwq-32b": {
            "rating": 1329.0146417981296,
            "rating_q975": 1333.385442722258,
            "rating_q025": 1324.6438408740012
        },
        "qwen-plus-0125": {
            "rating": 1326.4082907475092,
            "rating_q975": 1334.7060231116143,
            "rating_q025": 1318.1105583834042
        },
        "step-2-16k-exp-202412": {
            "rating": 1321.0709202818566,
            "rating_q975": 1329.5720250346499,
            "rating_q025": 1312.5698155290634
        },
        "gpt-5-nano-high": {
            "rating": 1320.2052949847903,
            "rating_q975": 1327.0276045889736,
            "rating_q025": 1313.382985380607
        },
        "gemini-1.5-pro-002": {
            "rating": 1319.7263327255637,
            "rating_q975": 1322.9163432373214,
            "rating_q025": 1316.536322213806
        },
        "o3-mini": {
            "rating": 1319.6442528604198,
            "rating_q975": 1323.1057368787317,
            "rating_q025": 1316.1827688421079
        },
        "llama-3.1-nemotron-ultra-253b-v1": {
            "rating": 1319.5509819919885,
            "rating_q975": 1331.1545135459355,
            "rating_q025": 1307.9474504380414
        },
        "hunyuan-turbos-20250226": {
            "rating": 1318.8249620713536,
            "rating_q975": 1330.5607866408711,
            "rating_q025": 1307.0891375018361
        },
        "qwen3-30b-a3b": {
            "rating": 1317.8596390910934,
            "rating_q975": 1322.5497298270823,
            "rating_q025": 1313.1695483551046
        },
        "o1-mini": {
            "rating": 1317.6493028585896,
            "rating_q975": 1321.1146678782582,
            "rating_q025": 1314.183937838921
        },
        "claude-3-7-sonnet-20250219-thinking-32k": {
            "rating": 1315.062516258696,
            "rating_q975": 1319.246498816414,
            "rating_q025": 1310.8785337009779
        },
        "hunyuan-turbo-0110": {
            "rating": 1311.0826746499986,
            "rating_q975": 1322.5529163984354,
            "rating_q025": 1299.6124329015618
        },
        "llama-3.3-nemotron-49b-super-v1": {
            "rating": 1308.7996696931248,
            "rating_q975": 1320.8699258009933,
            "rating_q025": 1296.7294135852562
        },
        "gemma-3n-e4b-it": {
            "rating": 1307.1681335986461,
            "rating_q975": 1312.2755720267853,
            "rating_q025": 1302.060695170507
        },
        "grok-2-2024-08-13": {
            "rating": 1305.2985675734444,
            "rating_q975": 1308.7925904343053,
            "rating_q025": 1301.8045447125835
        },
        "yi-lightning": {
            "rating": 1302.4236994178586,
            "rating_q975": 1307.2113447846064,
            "rating_q025": 1297.636054051111
        },
        "gpt-4o-2024-05-13": {
            "rating": 1301.0656773412638,
            "rating_q975": 1304.337081628319,
            "rating_q025": 1297.7942730542086
        },
        "qwen2.5-plus-1127": {
            "rating": 1299.3722545271362,
            "rating_q975": 1305.6199097264932,
            "rating_q025": 1293.1245993277792
        },
        "claude-3-5-sonnet-20241022": {
            "rating": 1298.4197291351036,
            "rating_q975": 1301.4074601850648,
            "rating_q025": 1295.4319980851424
        },
        "deepseek-v2.5-1210": {
            "rating": 1294.4332428891253,
            "rating_q975": 1302.6100425606965,
            "rating_q025": 1286.256443217554
        },
        "athene-v2-chat": {
            "rating": 1291.8508342452874,
            "rating_q975": 1296.2657920195447,
            "rating_q025": 1287.43587647103
        },
        "gemma-3-4b-it": {
            "rating": 1291.017353710387,
            "rating_q975": 1300.2755564503625,
            "rating_q025": 1281.7591509704114
        },
        "glm-4-plus": {
            "rating": 1290.2573269566717,
            "rating_q975": 1295.0505900282437,
            "rating_q025": 1285.4640638850997
        },
        "llama-4-maverick-17b-128e-instruct": {
            "rating": 1288.8174451012994,
            "rating_q975": 1293.047169815075,
            "rating_q025": 1284.5877203875239
        },
        "gpt-oss-20b": {
            "rating": 1288.681918953914,
            "rating_q975": 1295.0309704973986,
            "rating_q025": 1282.3328674104293
        },
        "hunyuan-large-2025-02-10": {
            "rating": 1288.2706070304375,
            "rating_q975": 1298.0554476872187,
            "rating_q025": 1278.4857663736564
        },
        "gemini-1.5-flash-002": {
            "rating": 1287.4998940579408,
            "rating_q975": 1291.5441944695312,
            "rating_q025": 1283.4555936463503
        },
        "gpt-4o-mini-2024-07-18": {
            "rating": 1287.1063662717975,
            "rating_q975": 1290.4291309858868,
            "rating_q025": 1283.7836015577082
        },
        "gpt-4.1-nano-2025-04-14": {
            "rating": 1285.1783699630987,
            "rating_q975": 1292.8461594896985,
            "rating_q025": 1277.510580436499
        },
        "llama-3.1-405b-instruct-bf16": {
            "rating": 1284.318290946475,
            "rating_q975": 1287.836266651441,
            "rating_q025": 1280.8003152415088
        },
        "gpt-4o-2024-08-06": {
            "rating": 1283.380136597465,
            "rating_q975": 1287.430768525052,
            "rating_q025": 1279.3295046698781
        },
        "llama-3.1-nemotron-70b-instruct": {
            "rating": 1283.3390759345684,
            "rating_q975": 1291.001603733619,
            "rating_q025": 1275.6765481355178
        },
        "qwen-max-0919": {
            "rating": 1282.6412016449808,
            "rating_q975": 1288.2228206786954,
            "rating_q025": 1277.0595826112663
        },
        "llama-3.1-405b-instruct-fp8": {
            "rating": 1282.5278716212165,
            "rating_q975": 1285.9204460601436,
            "rating_q025": 1279.1352971822894
        },
        "llama-4-scout-17b-16e-instruct": {
            "rating": 1281.6934798144368,
            "rating_q975": 1286.3809061136913,
            "rating_q025": 1277.0060535151824
        },
        "grok-2-mini-2024-08-13": {
            "rating": 1281.5641696313528,
            "rating_q975": 1285.1018299162747,
            "rating_q025": 1278.0265093464309
        },
        "claude-3-5-sonnet-20240620": {
            "rating": 1281.548380859071,
            "rating_q975": 1284.8133322228534,
            "rating_q025": 1278.2834294952884
        },
        "gemini-advanced-0514": {
            "rating": 1279.1831596072436,
            "rating_q975": 1284.230760590222,
            "rating_q025": 1274.1355586242653
        },
        "mistral-small-3.1-24b-instruct-2503": {
            "rating": 1278.9049697819846,
            "rating_q975": 1283.41134762636,
            "rating_q025": 1274.3985919376091
        },
        "llama-3.3-70b-instruct": {
            "rating": 1276.253813962193,
            "rating_q975": 1279.5832315254584,
            "rating_q025": 1272.9243963989275
        },
        "hunyuan-standard-2025-02-10": {
            "rating": 1274.7359060199199,
            "rating_q975": 1284.4410183665707,
            "rating_q025": 1265.030793673269
        },
        "gemini-1.5-pro-001": {
            "rating": 1274.1710974781436,
            "rating_q975": 1278.0180447467612,
            "rating_q025": 1270.324150209526
        },
        "gpt-4-turbo-2024-04-09": {
            "rating": 1272.433724217869,
            "rating_q975": 1276.2020575399151,
            "rating_q025": 1268.6653908958228
        },
        "deepseek-v2.5": {
            "rating": 1272.1210783884526,
            "rating_q975": 1276.68700905619,
            "rating_q025": 1267.5551477207152
        },
        "qwen2.5-72b-instruct": {
            "rating": 1269.7451523688824,
            "rating_q975": 1273.6545914167098,
            "rating_q025": 1265.835713321055
        },
        "mistral-large-2407": {
            "rating": 1266.7607466817872,
            "rating_q975": 1270.5204126734893,
            "rating_q025": 1263.001080690085
        },
        "mistral-large-2411": {
            "rating": 1265.9301719325408,
            "rating_q975": 1270.213793100701,
            "rating_q025": 1261.6465507643807
        },
        "hunyuan-large-vision": {
            "rating": 1265.8805666567641,
            "rating_q975": 1275.0349385071513,
            "rating_q025": 1256.726194806377
        },
        "athene-70b-0725": {
            "rating": 1265.375163059885,
            "rating_q975": 1270.9330437185165,
            "rating_q025": 1259.8172824012534
        },
        "gpt-4-1106-preview": {
            "rating": 1264.121904127045,
            "rating_q975": 1267.868314373163,
            "rating_q025": 1260.3754938809268
        },
        "gpt-4-0125-preview": {
            "rating": 1262.9951749972543,
            "rating_q975": 1266.9616806113906,
            "rating_q025": 1259.0286693831179
        },
        "claude-3-opus-20240229": {
            "rating": 1262.6822004124883,
            "rating_q975": 1265.533585581045,
            "rating_q025": 1259.8308152439317
        },
        "llama-3.1-70b-instruct": {
            "rating": 1261.9332449586532,
            "rating_q975": 1265.46751484499,
            "rating_q025": 1258.3989750723163
        },
        "amazon-nova-pro-v1.0": {
            "rating": 1258.7726133828053,
            "rating_q975": 1263.1722619831326,
            "rating_q025": 1254.372964782478
        },
        "claude-3-5-haiku-20241022": {
            "rating": 1256.4604840840734,
            "rating_q975": 1259.5651360513507,
            "rating_q025": 1253.3558321167961
        },
        "llama-3.1-tulu-3-70b": {
            "rating": 1255.8318750286107,
            "rating_q975": 1266.2746701598708,
            "rating_q025": 1245.3890798973507
        },
        "magistral-medium-2506": {
            "rating": 1255.5114629740237,
            "rating_q975": 1261.8929982950217,
            "rating_q025": 1249.1299276530258
        },
        "reka-core-20240904": {
            "rating": 1248.7813743466284,
            "rating_q975": 1255.8144281894372,
            "rating_q025": 1241.7483205038195
        },
        "gemini-1.5-flash-001": {
            "rating": 1239.8146226159026,
            "rating_q975": 1244.178549090588,
            "rating_q025": 1235.4506961412173
        },
        "jamba-1.5-large": {
            "rating": 1238.1419399589372,
            "rating_q975": 1245.3952674380932,
            "rating_q025": 1230.8886124797812
        },
        "mistral-small-24b-instruct-2501": {
            "rating": 1234.2403210610792,
            "rating_q975": 1240.0220200203153,
            "rating_q025": 1228.458622101843
        },
        "gemma-2-27b-it": {
            "rating": 1232.2767202232053,
            "rating_q975": 1235.452351791524,
            "rating_q025": 1229.1010886548866
        },
        "qwen2.5-coder-32b-instruct": {
            "rating": 1230.2393136868052,
            "rating_q975": 1238.2535752586025,
            "rating_q025": 1222.2250521150079
        },
        "command-r-plus-08-2024": {
            "rating": 1229.8851449256335,
            "rating_q975": 1236.3674078257475,
            "rating_q025": 1223.4028820255196
        },
        "amazon-nova-lite-v1.0": {
            "rating": 1229.1006545210385,
            "rating_q975": 1234.0988866920266,
            "rating_q025": 1224.1024223500503
        },
        "llama-3.1-nemotron-51b-instruct": {
            "rating": 1228.2612477715397,
            "rating_q975": 1238.187357428647,
            "rating_q025": 1218.3351381144325
        },
        "gemma-2-9b-it-simpo": {
            "rating": 1228.1239924510824,
            "rating_q975": 1234.9363345166746,
            "rating_q025": 1221.31165038549
        },
        "gemini-1.5-flash-8b-001": {
            "rating": 1227.1740166310722,
            "rating_q975": 1231.296706023679,
            "rating_q025": 1223.0513272384653
        },
        "glm-4-0520": {
            "rating": 1226.5680838276705,
            "rating_q975": 1233.482293628885,
            "rating_q025": 1219.6538740264562
        },
        "nemotron-4-340b-instruct": {
            "rating": 1225.6522554286844,
            "rating_q975": 1230.866183572311,
            "rating_q025": 1220.4383272850578
        },
        "c4ai-aya-expanse-32b": {
            "rating": 1224.8777170120547,
            "rating_q975": 1229.6021234876287,
            "rating_q025": 1220.1533105364808
        },
        "llama-3-70b-instruct": {
            "rating": 1221.7111221718592,
            "rating_q975": 1225.187381023771,
            "rating_q025": 1218.2348633199474
        },
        "reka-flash-20240904": {
            "rating": 1219.1293309203943,
            "rating_q975": 1226.0077839132812,
            "rating_q025": 1212.2508779275074
        },
        "claude-3-sonnet-20240229": {
            "rating": 1218.983705892269,
            "rating_q975": 1222.8762935517204,
            "rating_q025": 1215.0911182328175
        },
        "olmo-2-0325-32b-instruct": {
            "rating": 1218.7703795811926,
            "rating_q975": 1229.5456767172789,
            "rating_q025": 1207.9950824451064
        },
        "phi-4": {
            "rating": 1217.1989330532472,
            "rating_q975": 1221.6591411118407,
            "rating_q025": 1212.7387249946537
        },
        "amazon-nova-micro-v1.0": {
            "rating": 1210.2201762190216,
            "rating_q975": 1215.2049243081144,
            "rating_q025": 1205.2354281299288
        },
        "gemma-2-9b-it": {
            "rating": 1208.3023623518698,
            "rating_q975": 1211.9316083167282,
            "rating_q025": 1204.6731163870113
        },
        "gpt-4-0314": {
            "rating": 1206.4383725199384,
            "rating_q975": 1211.1651005300887,
            "rating_q025": 1201.7116445097881
        },
        "command-r-plus": {
            "rating": 1205.2569431034694,
            "rating_q975": 1209.4810251926212,
            "rating_q025": 1201.0328610143176
        },
        "qwen2-72b-instruct": {
            "rating": 1203.7710997521833,
            "rating_q975": 1208.589997345679,
            "rating_q025": 1198.9522021586877
        },
        "hunyuan-standard-256k": {
            "rating": 1203.5118987255923,
            "rating_q975": 1215.0915252206025,
            "rating_q025": 1191.9322722305822
        },
        "claude-3-haiku-20240307": {
            "rating": 1195.8515522952378,
            "rating_q975": 1199.465213169596,
            "rating_q025": 1192.2378914208796
        },
        "llama-3.1-tulu-3-8b": {
            "rating": 1195.2372895271842,
            "rating_q975": 1205.7203770632493,
            "rating_q025": 1184.754201991119
        },
        "ministral-8b-2410": {
            "rating": 1191.9926019135337,
            "rating_q975": 1200.9390277117034,
            "rating_q025": 1183.046176115364
        },
        "deepseek-coder-v2": {
            "rating": 1191.9525191158189,
            "rating_q975": 1198.26318491582,
            "rating_q025": 1185.6418533158178
        },
        "command-r-08-2024": {
            "rating": 1189.0051879178047,
            "rating_q975": 1195.4621899271906,
            "rating_q025": 1182.5481859084189
        },
        "jamba-1.5-mini": {
            "rating": 1188.1028084963277,
            "rating_q975": 1195.225136920886,
            "rating_q025": 1180.9804800717695
        },
        "llama-3.1-8b-instruct": {
            "rating": 1187.996666045024,
            "rating_q975": 1191.936572587064,
            "rating_q025": 1184.0567595029843
        },
        "c4ai-aya-expanse-8b": {
            "rating": 1187.0955065003036,
            "rating_q975": 1193.9201421172183,
            "rating_q025": 1180.2708708833889
        },
        "gpt-4-0613": {
            "rating": 1186.9929449006804,
            "rating_q975": 1190.967043858225,
            "rating_q025": 1183.0188459431358
        },
        "mistral-large-2402": {
            "rating": 1177.0200566147746,
            "rating_q975": 1181.6527803839065,
            "rating_q025": 1172.3873328456427
        },
        "qwen1.5-110b-chat": {
            "rating": 1175.6803279249898,
            "rating_q975": 1181.1278523257215,
            "rating_q025": 1170.232803524258
        },
        "yi-1.5-34b-chat": {
            "rating": 1173.5255687212511,
            "rating_q975": 1178.4707264565675,
            "rating_q025": 1168.5804109859348
        },
        "reka-flash-21b-20240226-online": {
            "rating": 1171.542831296695,
            "rating_q975": 1178.8377971411717,
            "rating_q025": 1164.2478654522185
        },
        "qwen1.5-72b-chat": {
            "rating": 1167.5674056389153,
            "rating_q975": 1172.7258582029167,
            "rating_q025": 1162.4089530749138
        },
        "llama-3-8b-instruct": {
            "rating": 1166.7635625482321,
            "rating_q975": 1170.3779490883985,
            "rating_q025": 1163.1491760080658
        },
        "mistral-medium": {
            "rating": 1166.3123264776682,
            "rating_q975": 1171.7108910080035,
            "rating_q025": 1160.913761947333
        },
        "reka-flash-21b-20240226": {
            "rating": 1166.0790896693761,
            "rating_q975": 1171.9475226200773,
            "rating_q025": 1160.210656718675
        },
        "command-r": {
            "rating": 1164.7738418873057,
            "rating_q975": 1169.4479827884184,
            "rating_q025": 1160.099700986193
        },
        "qwq-32b-preview": {
            "rating": 1163.4004937123282,
            "rating_q975": 1174.8139497190023,
            "rating_q025": 1151.987037705654
        },
        "mixtral-8x22b-instruct-v0.1": {
            "rating": 1162.8982183048538,
            "rating_q975": 1167.3227945735691,
            "rating_q025": 1158.4736420361385
        },
        "internlm2_5-20b-chat": {
            "rating": 1160.4777189254914,
            "rating_q975": 1167.4831175772447,
            "rating_q025": 1153.4723202737382
        },
        "gemma-2-2b-it": {
            "rating": 1156.985737174567,
            "rating_q975": 1160.8728052359052,
            "rating_q025": 1153.0986691132289
        },
        "granite-3.1-8b-instruct": {
            "rating": 1151.8791300191897,
            "rating_q975": 1162.7396494624936,
            "rating_q025": 1141.0186105758858
        },
        "gemini-pro-dev-api": {
            "rating": 1150.1556408342226,
            "rating_q975": 1157.3788365102234,
            "rating_q025": 1142.9324451582218
        },
        "zephyr-orpo-141b-A35b-v0.1": {
            "rating": 1145.5412491266743,
            "rating_q975": 1156.29426393559,
            "rating_q025": 1134.7882343177587
        },
        "qwen1.5-32b-chat": {
            "rating": 1139.2577972087872,
            "rating_q975": 1145.2959770001376,
            "rating_q025": 1133.219617417437
        },
        "phi-3-medium-4k-instruct": {
            "rating": 1138.5608483620335,
            "rating_q975": 1143.6047615349594,
            "rating_q025": 1133.5169351891077
        },
        "starling-lm-7b-beta": {
            "rating": 1133.7827940993204,
            "rating_q975": 1141.0809616376446,
            "rating_q025": 1126.4846265609963
        },
        "mixtral-8x7b-instruct-v0.1": {
            "rating": 1132.9315809384025,
            "rating_q975": 1137.107939945281,
            "rating_q025": 1128.755221931524
        },
        "gemini-pro": {
            "rating": 1132.3445407312865,
            "rating_q975": 1143.9100943290055,
            "rating_q025": 1120.7789871335676
        },
        "granite-3.1-2b-instruct": {
            "rating": 1130.1191348919542,
            "rating_q975": 1141.1348245156737,
            "rating_q025": 1119.1034452682347
        },
        "qwen1.5-14b-chat": {
            "rating": 1130.090065161699,
            "rating_q975": 1137.1155562418012,
            "rating_q025": 1123.0645740815967
        },
        "yi-34b-chat": {
            "rating": 1129.645367986133,
            "rating_q975": 1136.411659394017,
            "rating_q025": 1122.8790765782487
        },
        "gpt-3.5-turbo-0125": {
            "rating": 1126.4983638612416,
            "rating_q975": 1131.1045778794803,
            "rating_q025": 1121.892149843003
        },
        "tulu-2-dpo-70b": {
            "rating": 1122.6072569354023,
            "rating_q975": 1132.3725355874028,
            "rating_q025": 1112.8419782834019
        },
        "wizardlm-70b": {
            "rating": 1120.9262332578785,
            "rating_q975": 1130.351143740669,
            "rating_q025": 1111.501322775088
        },
        "dbrx-instruct-preview": {
            "rating": 1120.479430218969,
            "rating_q975": 1126.4750526140474,
            "rating_q025": 1114.4838078238904
        },
        "llama-2-70b-chat": {
            "rating": 1116.7292556274567,
            "rating_q975": 1122.1854655372094,
            "rating_q025": 1111.273045717704
        },
        "nous-hermes-2-mixtral-8x7b-dpo": {
            "rating": 1113.7003802611912,
            "rating_q975": 1125.5926968592096,
            "rating_q025": 1101.8080636631728
        },
        "phi-3-small-8k-instruct": {
            "rating": 1111.25354954841,
            "rating_q975": 1117.0665072045695,
            "rating_q025": 1105.4405918922507
        },
        "llama-3.2-3b-instruct": {
            "rating": 1110.3069473610913,
            "rating_q975": 1117.8122794119656,
            "rating_q025": 1102.801615310217
        },
        "starling-lm-7b-alpha": {
            "rating": 1109.1129352769424,
            "rating_q975": 1117.0749066643157,
            "rating_q025": 1101.150963889569
        },
        "openchat-3.5-0106": {
            "rating": 1108.1253549418443,
            "rating_q975": 1116.0690005508095,
            "rating_q025": 1100.181709332879
        },
        "vicuna-33b": {
            "rating": 1106.962399255057,
            "rating_q975": 1113.1075669931722,
            "rating_q025": 1100.817231516942
        },
        "deepseek-llm-67b-chat": {
            "rating": 1105.6288525895466,
            "rating_q975": 1117.3024444513132,
            "rating_q025": 1093.95526072778
        },
        "snowflake-arctic-instruct": {
            "rating": 1102.6358661122067,
            "rating_q975": 1108.4820981783935,
            "rating_q025": 1096.78963404602
        },
        "llama2-70b-steerlm-chat": {
            "rating": 1099.9510907448625,
            "rating_q975": 1112.5502911874855,
            "rating_q025": 1087.3518903022396
        },
        "granite-3.0-8b-instruct": {
            "rating": 1099.056239852434,
            "rating_q975": 1107.5686421144544,
            "rating_q025": 1090.5438375904134
        },
        "openchat-3.5": {
            "rating": 1098.2107120328371,
            "rating_q975": 1107.9291635691338,
            "rating_q025": 1088.4922604965404
        },
        "gemma-1.1-7b-it": {
            "rating": 1096.2860208687043,
            "rating_q975": 1102.2380566487786,
            "rating_q025": 1090.33398508863
        },
        "gpt-3.5-turbo-1106": {
            "rating": 1095.13302434658,
            "rating_q975": 1103.9197139969012,
            "rating_q025": 1086.3463346962587
        },
        "openhermes-2.5-mistral-7b": {
            "rating": 1094.85061176121,
            "rating_q975": 1105.2842205142356,
            "rating_q025": 1084.4170030081846
        },
        "mistral-7b-instruct-v0.2": {
            "rating": 1091.3647274214704,
            "rating_q975": 1097.900787110075,
            "rating_q025": 1084.8286677328658
        },
        "llama-2-13b-chat": {
            "rating": 1086.4105514874855,
            "rating_q975": 1093.0659031120365,
            "rating_q025": 1079.7551998629344
        },
        "solar-10.7b-instruct-v1.0": {
            "rating": 1085.5674799358205,
            "rating_q975": 1098.8186867927923,
            "rating_q025": 1072.3162730788488
        },
        "qwen1.5-7b-chat": {
            "rating": 1084.601635486049,
            "rating_q975": 1094.3225862065533,
            "rating_q025": 1074.8806847655446
        },
        "dolphin-2.2.1-mistral-7b": {
            "rating": 1081.8441547395648,
            "rating_q975": 1097.4716321802377,
            "rating_q025": 1066.216677298892
        },
        "granite-3.0-2b-instruct": {
            "rating": 1081.6395596270231,
            "rating_q975": 1089.821699036258,
            "rating_q025": 1073.4574202177882
        },
        "phi-3-mini-4k-instruct-june-2024": {
            "rating": 1080.5840006148385,
            "rating_q975": 1086.8777917882958,
            "rating_q025": 1074.2902094413812
        },
        "wizardlm-13b": {
            "rating": 1078.6805196767225,
            "rating_q975": 1088.0677202616707,
            "rating_q025": 1069.2933190917743
        },
        "phi-3-mini-4k-instruct": {
            "rating": 1074.9600120676794,
            "rating_q975": 1081.1712891311067,
            "rating_q025": 1068.748735004252
        },
        "zephyr-7b-beta": {
            "rating": 1071.0277556060587,
            "rating_q975": 1079.8146661790288,
            "rating_q025": 1062.2408450330886
        },
        "mpt-30b-chat": {
            "rating": 1070.6169873487645,
            "rating_q975": 1082.8979466313215,
            "rating_q025": 1058.3360280662075
        },
        "codellama-34b-instruct": {
            "rating": 1066.876163416171,
            "rating_q975": 1075.703277771237,
            "rating_q025": 1058.049049061105
        },
        "zephyr-7b-alpha": {
            "rating": 1060.7250936889952,
            "rating_q975": 1076.7218693170453,
            "rating_q025": 1044.7283180609452
        },
        "vicuna-13b": {
            "rating": 1059.6452324390573,
            "rating_q975": 1066.2808278698024,
            "rating_q025": 1053.0096370083122
        },
        "codellama-70b-instruct": {
            "rating": 1058.4732779139704,
            "rating_q975": 1076.8036156845108,
            "rating_q025": 1040.14294014343
        },
        "gemma-7b-it": {
            "rating": 1057.269702824175,
            "rating_q975": 1066.8714333029995,
            "rating_q025": 1047.6679723453506
        },
        "llama-3.2-1b-instruct": {
            "rating": 1056.7299564483096,
            "rating_q975": 1064.3789840911936,
            "rating_q025": 1049.0809288054256
        },
        "falcon-180b-chat": {
            "rating": 1056.1278287463506,
            "rating_q975": 1073.4504622485329,
            "rating_q025": 1038.8051952441683
        },
        "guanaco-33b": {
            "rating": 1055.7407835785775,
            "rating_q975": 1067.9803541566484,
            "rating_q025": 1043.5012130005066
        },
        "llama-2-7b-chat": {
            "rating": 1054.8933824310511,
            "rating_q975": 1061.8778319911116,
            "rating_q025": 1047.9089328709906
        },
        "phi-3-mini-128k-instruct": {
            "rating": 1053.123041007241,
            "rating_q975": 1060.3017966433824,
            "rating_q025": 1045.9442853710996
        },
        "qwen-14b-chat": {
            "rating": 1052.7258311018395,
            "rating_q975": 1063.702652601943,
            "rating_q025": 1041.749009601736
        },
        "smollm2-1.7b-instruct": {
            "rating": 1048.4225136433574,
            "rating_q975": 1062.5780863120287,
            "rating_q025": 1034.2669409746861
        },
        "stripedhyena-nous-7b": {
            "rating": 1039.475668064108,
            "rating_q975": 1050.5506995113165,
            "rating_q025": 1028.4006366168996
        },
        "vicuna-7b": {
            "rating": 1032.941353785081,
            "rating_q975": 1042.2086110737976,
            "rating_q025": 1023.6740964963645
        },
        "olmo-7b-instruct": {
            "rating": 1032.4675397677001,
            "rating_q975": 1043.6257989213536,
            "rating_q025": 1021.3092806140467
        },
        "palm-2": {
            "rating": 1028.9846595762592,
            "rating_q975": 1038.3450952503238,
            "rating_q025": 1019.6242239021947
        },
        "mistral-7b-instruct": {
            "rating": 1025.7921120172446,
            "rating_q975": 1035.0500947250205,
            "rating_q025": 1016.5341293094687
        },
        "gemma-1.1-2b-it": {
            "rating": 1024.842171399768,
            "rating_q975": 1032.4793450402453,
            "rating_q025": 1017.2049977592906
        },
        "gemma-2b-it": {
            "rating": 1003.9464603176489,
            "rating_q975": 1015.595222172232,
            "rating_q025": 992.2976984630658
        },
        "qwen1.5-4b-chat": {
            "rating": 999.20443392314,
            "rating_q975": 1008.4861916608888,
            "rating_q025": 989.9226761853911
        },
        "koala-13b": {
            "rating": 991.3931797644503,
            "rating_q975": 1001.4338688939398,
            "rating_q025": 981.3524906349609
        },
        "chatglm3-6b": {
            "rating": 973.8803103162925,
            "rating_q975": 985.5627259141613,
            "rating_q025": 962.1978947184236
        },
        "gpt4all-13b-snoozy": {
            "rating": 957.666579195565,
            "rating_q975": 973.042823578676,
            "rating_q025": 942.2903348124539
        },
        "mpt-7b-chat": {
            "rating": 957.3368254113042,
            "rating_q975": 969.3704258525626,
            "rating_q025": 945.3032249700458
        },
        "RWKV-4-Raven-14B": {
            "rating": 950.8400184102331,
            "rating_q975": 962.4357103618471,
            "rating_q025": 939.2443264586192
        },
        "chatglm2-6b": {
            "rating": 941.0839729475741,
            "rating_q975": 954.7414255386996,
            "rating_q025": 927.4265203564487
        },
        "alpaca-13b": {
            "rating": 934.9305752027572,
            "rating_q975": 946.5238174224794,
            "rating_q025": 923.3373329830349
        },
        "chatglm-6b": {
            "rating": 920.4846782426957,
            "rating_q975": 933.0627885880326,
            "rating_q025": 907.9065678973589
        },
        "oasst-pythia-12b": {
            "rating": 918.1757181236303,
            "rating_q975": 929.2301505375608,
            "rating_q025": 907.1212857096998
        },
        "fastchat-t5-3b": {
            "rating": 896.1514950425108,
            "rating_q975": 908.689221226488,
            "rating_q025": 883.6137688585335
        },
        "stablelm-tuned-alpha-7b": {
            "rating": 868.7778992265446,
            "rating_q975": 881.8480104222223,
            "rating_q025": 855.7077880308669
        },
        "dolly-v2-12b": {
            "rating": 853.2920182866599,
            "rating_q975": 867.0138650904604,
            "rating_q025": 839.5701714828593
        },
        "llama-13b": {
            "rating": 835.0524525125197,
            "rating_q975": 851.2323574112426,
            "rating_q025": 818.8725476137969
        }
    },
    "german": {
        "gemini-2.5-pro": {
            "rating": 1484.3956255961966,
            "rating_q975": 1502.054790293363,
            "rating_q025": 1466.7364608990301
        },
        "glm-4.6": {
            "rating": 1453.2321730559206,
            "rating_q975": 1495.7139616250913,
            "rating_q025": 1410.75038448675
        },
        "gpt-4.5-preview-2025-02-27": {
            "rating": 1453.0921193726092,
            "rating_q975": 1485.5814759332568,
            "rating_q025": 1420.6027628119616
        },
        "qwen3-max-preview": {
            "rating": 1451.1397884844528,
            "rating_q975": 1478.6602741106426,
            "rating_q025": 1423.619302858263
        },
        "claude-sonnet-4-5-20250929-thinking-32k": {
            "rating": 1434.4319663979868,
            "rating_q975": 1473.8380198279394,
            "rating_q025": 1395.0259129680342
        },
        "grok-4-0709": {
            "rating": 1430.5124015136591,
            "rating_q975": 1453.0325431884487,
            "rating_q025": 1407.9922598388696
        },
        "qwen3-235b-a22b-instruct-2507": {
            "rating": 1427.022286536249,
            "rating_q975": 1449.8022994417902,
            "rating_q025": 1404.242273630708
        },
        "deepseek-v3.2-exp-thinking": {
            "rating": 1426.0968797574455,
            "rating_q975": 1470.8433078955786,
            "rating_q025": 1381.3504516193125
        },
        "qwen3-max-2025-09-23": {
            "rating": 1424.1812670042657,
            "rating_q975": 1465.8700973642506,
            "rating_q025": 1382.4924366442808
        },
        "claude-opus-4-1-20250805-thinking-16k": {
            "rating": 1423.0209246382676,
            "rating_q975": 1447.5214127581567,
            "rating_q025": 1398.5204365183786
        },
        "mistral-medium-2508": {
            "rating": 1420.425446570096,
            "rating_q975": 1444.9243624463093,
            "rating_q025": 1395.9265306938828
        },
        "chatgpt-4o-latest-20250326": {
            "rating": 1420.3954481794572,
            "rating_q975": 1439.3753299212544,
            "rating_q025": 1401.41556643766
        },
        "grok-3-preview-02-24": {
            "rating": 1419.1943775685656,
            "rating_q975": 1440.8627324834188,
            "rating_q025": 1397.5260226537125
        },
        "o3-2025-04-16": {
            "rating": 1419.045363158943,
            "rating_q975": 1436.2906421484493,
            "rating_q025": 1401.8000841694368
        },
        "qwen3-vl-235b-a22b-thinking": {
            "rating": 1417.3038728937508,
            "rating_q975": 1463.2245054944624,
            "rating_q025": 1371.3832402930393
        },
        "qwen3-next-80b-a3b-instruct": {
            "rating": 1415.3571026640368,
            "rating_q975": 1445.4771841817956,
            "rating_q025": 1385.237021146278
        },
        "longcat-flash-chat": {
            "rating": 1413.846758087691,
            "rating_q975": 1450.9685840971026,
            "rating_q025": 1376.7249320782792
        },
        "gpt-5-high": {
            "rating": 1413.4642644466478,
            "rating_q975": 1438.4041197758106,
            "rating_q025": 1388.524409117485
        },
        "gemini-2.5-flash": {
            "rating": 1412.9655259177373,
            "rating_q975": 1429.530335897663,
            "rating_q025": 1396.4007159378116
        },
        "gemini-2.5-flash-preview-09-2025": {
            "rating": 1409.7428260325523,
            "rating_q975": 1448.4358793099877,
            "rating_q025": 1371.049772755117
        },
        "deepseek-v3.1": {
            "rating": 1407.7207540589327,
            "rating_q975": 1438.3460819096354,
            "rating_q025": 1377.09542620823
        },
        "gpt-5-chat": {
            "rating": 1407.3059975145982,
            "rating_q975": 1433.1819033598283,
            "rating_q025": 1381.430091669368
        },
        "mai-1-preview": {
            "rating": 1402.8448757401557,
            "rating_q975": 1432.8906942116635,
            "rating_q025": 1372.7990572686479
        },
        "deepseek-v3.1-thinking": {
            "rating": 1399.1398042388314,
            "rating_q975": 1432.3187352660714,
            "rating_q025": 1365.9608732115914
        },
        "glm-4.5": {
            "rating": 1399.06350568438,
            "rating_q975": 1425.3361155408484,
            "rating_q025": 1372.7908958279118
        },
        "qwen3-235b-a22b-thinking-2507": {
            "rating": 1398.4821308033515,
            "rating_q975": 1438.9896859050234,
            "rating_q025": 1357.9745757016797
        },
        "qwen3-vl-235b-a22b-instruct": {
            "rating": 1397.3556085393134,
            "rating_q975": 1439.7988101512183,
            "rating_q025": 1354.9124069274085
        },
        "kimi-k2-0905-preview": {
            "rating": 1394.2917540596668,
            "rating_q975": 1432.9215817759164,
            "rating_q025": 1355.6619263434172
        },
        "deepseek-r1-0528": {
            "rating": 1394.1297314299557,
            "rating_q975": 1419.8589066235104,
            "rating_q025": 1368.400556236401
        },
        "claude-opus-4-1-20250805": {
            "rating": 1393.9762292689113,
            "rating_q975": 1415.7972247845864,
            "rating_q025": 1372.1552337532362
        },
        "qwen3-235b-a22b-no-thinking": {
            "rating": 1384.6815186614779,
            "rating_q975": 1403.888957676065,
            "rating_q025": 1365.4740796468907
        },
        "qwen3-235b-a22b": {
            "rating": 1382.6079590094737,
            "rating_q975": 1404.6214116129845,
            "rating_q025": 1360.5945064059629
        },
        "deepseek-r1": {
            "rating": 1379.510383804259,
            "rating_q975": 1407.0405124588092,
            "rating_q025": 1351.9802551497087
        },
        "claude-opus-4-20250514-thinking-16k": {
            "rating": 1377.37823978329,
            "rating_q975": 1398.0594687229566,
            "rating_q025": 1356.6970108436233
        },
        "mistral-medium-2505": {
            "rating": 1376.557965633158,
            "rating_q975": 1395.643264630828,
            "rating_q025": 1357.4726666354877
        },
        "gemini-2.5-flash-lite-preview-09-2025-no-thinking": {
            "rating": 1376.2453038104281,
            "rating_q975": 1414.7195690988613,
            "rating_q025": 1337.771038521995
        },
        "gpt-4.1-2025-04-14": {
            "rating": 1375.3892299943454,
            "rating_q975": 1393.20966261496,
            "rating_q025": 1357.5687973737308
        },
        "deepseek-v3-0324": {
            "rating": 1373.8160968693371,
            "rating_q975": 1392.1828557291574,
            "rating_q025": 1355.4493380095169
        },
        "gemma-3-12b-it": {
            "rating": 1370.4297638142014,
            "rating_q975": 1412.6905978282205,
            "rating_q025": 1328.1689298001822
        },
        "glm-4.5-air": {
            "rating": 1367.7393694743191,
            "rating_q975": 1392.328875120556,
            "rating_q025": 1343.1498638280823
        },
        "claude-opus-4-20250514": {
            "rating": 1367.0064606502858,
            "rating_q975": 1385.0383785001468,
            "rating_q025": 1348.9745428004248
        },
        "gpt-5-mini-high": {
            "rating": 1366.1744658370092,
            "rating_q975": 1393.3265188013509,
            "rating_q025": 1339.0224128726675
        },
        "gemini-2.5-flash-lite-preview-06-17-thinking": {
            "rating": 1365.9695350599964,
            "rating_q975": 1387.4129200645248,
            "rating_q025": 1344.526150055468
        },
        "kimi-k2-0711-preview": {
            "rating": 1365.2579904633167,
            "rating_q975": 1389.189436462385,
            "rating_q025": 1341.3265444642484
        },
        "qwen3-30b-a3b-instruct-2507": {
            "rating": 1364.2508742840123,
            "rating_q975": 1391.2932774693872,
            "rating_q025": 1337.2084710986373
        },
        "step-3": {
            "rating": 1364.0841754079634,
            "rating_q975": 1411.3875051962946,
            "rating_q025": 1316.7808456196321
        },
        "gemma-3-27b-it": {
            "rating": 1356.711698656851,
            "rating_q975": 1374.5934890460153,
            "rating_q025": 1338.8299082676867
        },
        "qwen3-next-80b-a3b-thinking": {
            "rating": 1355.9625467950584,
            "rating_q975": 1390.5560713836167,
            "rating_q025": 1321.3690222065002
        },
        "grok-3-mini-high": {
            "rating": 1349.4774404543937,
            "rating_q975": 1378.6522180650122,
            "rating_q025": 1320.3026628437751
        },
        "claude-haiku-4-5-20251001": {
            "rating": 1345.6564117504672,
            "rating_q975": 1389.1140490252092,
            "rating_q025": 1302.1987744757253
        },
        "hunyuan-turbos-20250416": {
            "rating": 1344.7328303307847,
            "rating_q975": 1377.2162789937374,
            "rating_q025": 1312.249381667832
        },
        "mistral-small-2506": {
            "rating": 1343.7699417786437,
            "rating_q975": 1373.164940292144,
            "rating_q025": 1314.3749432651434
        },
        "qwen2.5-max": {
            "rating": 1343.2968525263284,
            "rating_q975": 1364.226568940419,
            "rating_q025": 1322.3671361122379
        },
        "gpt-4.1-mini-2025-04-14": {
            "rating": 1342.2648266219744,
            "rating_q975": 1361.2654287165044,
            "rating_q025": 1323.2642245274444
        },
        "gpt-oss-120b": {
            "rating": 1341.8792446228592,
            "rating_q975": 1368.3160043197706,
            "rating_q025": 1315.4424849259478
        },
        "minimax-m1": {
            "rating": 1341.5968293025685,
            "rating_q975": 1362.6063898637346,
            "rating_q025": 1320.5872687414023
        },
        "glm-4-plus-0111": {
            "rating": 1337.786407281091,
            "rating_q975": 1376.7921807046484,
            "rating_q025": 1298.7806338575335
        },
        "command-a-03-2025": {
            "rating": 1337.665040654128,
            "rating_q975": 1354.9721116983071,
            "rating_q025": 1320.357969609949
        },
        "qwen3-32b": {
            "rating": 1335.8178089997853,
            "rating_q975": 1376.60975763645,
            "rating_q025": 1295.0258603631205
        },
        "grok-3-mini-beta": {
            "rating": 1332.833811898478,
            "rating_q975": 1357.5618371113057,
            "rating_q025": 1308.1057866856502
        },
        "o1-2024-12-17": {
            "rating": 1331.7103014469915,
            "rating_q975": 1355.2060204792579,
            "rating_q025": 1308.214582414725
        },
        "claude-sonnet-4-20250514": {
            "rating": 1329.911030204891,
            "rating_q975": 1349.5105930243956,
            "rating_q025": 1310.3114673853863
        },
        "o4-mini-2025-04-16": {
            "rating": 1329.4991525994942,
            "rating_q975": 1347.8178073450908,
            "rating_q025": 1311.1804978538976
        },
        "qwen3-coder-480b-a35b-instruct": {
            "rating": 1326.950300190807,
            "rating_q975": 1355.266150649,
            "rating_q025": 1298.6344497326138
        },
        "gpt-5-nano-high": {
            "rating": 1324.4953340450852,
            "rating_q975": 1365.9682462998999,
            "rating_q025": 1283.0224217902705
        },
        "deepseek-v3": {
            "rating": 1319.1232832228493,
            "rating_q975": 1343.5237476573393,
            "rating_q025": 1294.7228187883593
        },
        "claude-sonnet-4-20250514-thinking-32k": {
            "rating": 1315.3096580828028,
            "rating_q975": 1337.0059501216838,
            "rating_q025": 1293.6133660439218
        },
        "qwq-32b": {
            "rating": 1307.812592567257,
            "rating_q975": 1330.5900463422997,
            "rating_q025": 1285.0351387922144
        },
        "gemma-3n-e4b-it": {
            "rating": 1307.265197753666,
            "rating_q975": 1329.6123294174633,
            "rating_q025": 1284.9180660898685
        },
        "step-1o-turbo-202506": {
            "rating": 1306.4043224755517,
            "rating_q975": 1338.2465640641758,
            "rating_q025": 1274.5620808869276
        },
        "o1-preview": {
            "rating": 1305.7081063960052,
            "rating_q975": 1326.4549344553336,
            "rating_q025": 1284.9612783366767
        },
        "qwen3-30b-a3b": {
            "rating": 1304.5649901765303,
            "rating_q975": 1326.4364493863095,
            "rating_q025": 1282.693530966751
        },
        "gemini-2.0-flash-lite-preview-02-05": {
            "rating": 1301.0405979615664,
            "rating_q975": 1323.1410239950796,
            "rating_q025": 1278.9401719280531
        },
        "o3-mini-high": {
            "rating": 1300.0719599173822,
            "rating_q975": 1329.3978223739566,
            "rating_q025": 1270.7460974608077
        },
        "o3-mini": {
            "rating": 1299.6668333911857,
            "rating_q975": 1316.3263808972215,
            "rating_q025": 1283.00728588515
        },
        "claude-3-7-sonnet-20250219-thinking-32k": {
            "rating": 1295.2996646797753,
            "rating_q975": 1315.0685250407919,
            "rating_q025": 1275.5308043187588
        },
        "claude-3-5-sonnet-20241022": {
            "rating": 1293.0174037297004,
            "rating_q975": 1305.8220932874879,
            "rating_q025": 1280.212714171913
        },
        "llama-4-maverick-17b-128e-instruct": {
            "rating": 1290.2461057814473,
            "rating_q975": 1309.81157554193,
            "rating_q025": 1270.6806360209646
        },
        "gpt-4.1-nano-2025-04-14": {
            "rating": 1283.6808690649032,
            "rating_q975": 1320.506907655153,
            "rating_q025": 1246.8548304746532
        },
        "grok-2-2024-08-13": {
            "rating": 1283.4063063104272,
            "rating_q975": 1297.9920542937132,
            "rating_q025": 1268.8205583271413
        },
        "gemini-1.5-pro-002": {
            "rating": 1282.8402739948629,
            "rating_q975": 1298.6059355790462,
            "rating_q025": 1267.0746124106795
        },
        "gpt-4o-2024-05-13": {
            "rating": 1278.6394509076051,
            "rating_q975": 1290.4202958385965,
            "rating_q025": 1266.8586059766137
        },
        "o1-mini": {
            "rating": 1274.9263194164193,
            "rating_q975": 1291.8641183419847,
            "rating_q025": 1257.988520490854
        },
        "glm-4-plus": {
            "rating": 1274.898703755905,
            "rating_q975": 1296.9141032144103,
            "rating_q025": 1252.8833042973997
        },
        "gemma-3-4b-it": {
            "rating": 1274.481482646533,
            "rating_q975": 1316.2815399987765,
            "rating_q025": 1232.6814252942897
        },
        "gemini-advanced-0514": {
            "rating": 1270.5437462084851,
            "rating_q975": 1286.599902367489,
            "rating_q025": 1254.4875900494812
        },
        "grok-2-mini-2024-08-13": {
            "rating": 1269.9059628832947,
            "rating_q975": 1285.8219365909038,
            "rating_q025": 1253.9899891756857
        },
        "gpt-4o-mini-2024-07-18": {
            "rating": 1267.7736340324755,
            "rating_q975": 1281.7220054084357,
            "rating_q025": 1253.8252626565152
        },
        "claude-3-5-sonnet-20240620": {
            "rating": 1267.1114192828945,
            "rating_q975": 1280.2277434731527,
            "rating_q025": 1253.9950950926363
        },
        "yi-lightning": {
            "rating": 1263.181280946025,
            "rating_q975": 1284.0848857795454,
            "rating_q025": 1242.2776761125047
        },
        "llama-4-scout-17b-16e-instruct": {
            "rating": 1263.1213490658583,
            "rating_q975": 1285.4593104447817,
            "rating_q025": 1240.783387686935
        },
        "gemini-1.5-flash-002": {
            "rating": 1259.5033072636197,
            "rating_q975": 1279.997833323143,
            "rating_q025": 1239.0087812040965
        },
        "athene-v2-chat": {
            "rating": 1258.0967155379064,
            "rating_q975": 1279.848010749805,
            "rating_q025": 1236.3454203260078
        },
        "mistral-small-3.1-24b-instruct-2503": {
            "rating": 1257.9035779568503,
            "rating_q975": 1279.771925535092,
            "rating_q025": 1236.0352303786087
        },
        "gpt-4-turbo-2024-04-09": {
            "rating": 1255.3344515453705,
            "rating_q975": 1267.9903819153874,
            "rating_q025": 1242.6785211753536
        },
        "claude-3-opus-20240229": {
            "rating": 1254.8095757742803,
            "rating_q975": 1265.482458662517,
            "rating_q025": 1244.1366928860436
        },
        "deepseek-v2.5-1210": {
            "rating": 1254.6929161835328,
            "rating_q975": 1300.3357396827014,
            "rating_q025": 1209.0500926843642
        },
        "gpt-4o-2024-08-06": {
            "rating": 1253.7075987005505,
            "rating_q975": 1270.029527220968,
            "rating_q025": 1237.385670180133
        },
        "qwen-max-0919": {
            "rating": 1250.3205417563972,
            "rating_q975": 1275.73663444353,
            "rating_q025": 1224.9044490692645
        },
        "mistral-large-2407": {
            "rating": 1250.012642687562,
            "rating_q975": 1266.4764220037944,
            "rating_q025": 1233.5488633713296
        },
        "llama-3.3-70b-instruct": {
            "rating": 1248.7563523650028,
            "rating_q975": 1265.5795725001815,
            "rating_q025": 1231.9331322298242
        },
        "llama-3.1-405b-instruct-bf16": {
            "rating": 1248.7188218253625,
            "rating_q975": 1267.3033487785938,
            "rating_q025": 1230.1342948721312
        },
        "gpt-oss-20b": {
            "rating": 1247.8598831995828,
            "rating_q975": 1288.9630813788772,
            "rating_q025": 1206.7566850202884
        },
        "athene-70b-0725": {
            "rating": 1247.6060234692845,
            "rating_q975": 1270.4995810811315,
            "rating_q025": 1224.7124658574376
        },
        "gpt-4-1106-preview": {
            "rating": 1246.5508019589654,
            "rating_q975": 1260.372012674406,
            "rating_q025": 1232.7295912435247
        },
        "llama-3.1-405b-instruct-fp8": {
            "rating": 1246.1678252796924,
            "rating_q975": 1260.9973525798964,
            "rating_q025": 1231.3382979794883
        },
        "gemini-1.5-pro-001": {
            "rating": 1245.5454734371735,
            "rating_q975": 1258.8806624712859,
            "rating_q025": 1232.2102844030612
        },
        "gpt-4-0125-preview": {
            "rating": 1241.0845601889432,
            "rating_q975": 1254.6538978222795,
            "rating_q025": 1227.515222555607
        },
        "mistral-large-2411": {
            "rating": 1240.02594622901,
            "rating_q975": 1262.137490057337,
            "rating_q025": 1217.9144024006832
        },
        "reka-core-20240904": {
            "rating": 1239.6474582783676,
            "rating_q975": 1279.7480192024998,
            "rating_q025": 1199.5468973542354
        },
        "claude-3-5-haiku-20241022": {
            "rating": 1236.6082622373851,
            "rating_q975": 1251.5064211916601,
            "rating_q025": 1221.7101032831101
        },
        "magistral-medium-2506": {
            "rating": 1236.437105767313,
            "rating_q975": 1269.7933099173983,
            "rating_q025": 1203.0809016172275
        },
        "amazon-nova-pro-v1.0": {
            "rating": 1235.5511706974269,
            "rating_q975": 1258.2232168610362,
            "rating_q025": 1212.8791245338175
        },
        "qwen2.5-72b-instruct": {
            "rating": 1230.4002764526485,
            "rating_q975": 1248.5758444277874,
            "rating_q025": 1212.2247084775097
        },
        "qwen2.5-plus-1127": {
            "rating": 1226.5041343909752,
            "rating_q975": 1261.5836671449335,
            "rating_q025": 1191.4246016370168
        },
        "amazon-nova-lite-v1.0": {
            "rating": 1224.2298006494343,
            "rating_q975": 1250.0530409865075,
            "rating_q025": 1198.406560312361
        },
        "deepseek-v2.5": {
            "rating": 1222.880897676604,
            "rating_q975": 1246.522726012827,
            "rating_q025": 1199.239069340381
        },
        "phi-4": {
            "rating": 1218.8473225654607,
            "rating_q975": 1243.8619977306748,
            "rating_q025": 1193.8326474002465
        },
        "llama-3.1-70b-instruct": {
            "rating": 1218.4016049423567,
            "rating_q975": 1234.0853299402636,
            "rating_q025": 1202.7178799444498
        },
        "gemma-2-9b-it-simpo": {
            "rating": 1216.0375347580714,
            "rating_q975": 1246.5265623689265,
            "rating_q025": 1185.5485071472162
        },
        "gemini-1.5-flash-001": {
            "rating": 1212.9527195452988,
            "rating_q975": 1226.9054308410073,
            "rating_q025": 1199.0000082495903
        },
        "command-r-plus-08-2024": {
            "rating": 1212.2908328042265,
            "rating_q975": 1245.199352175366,
            "rating_q025": 1179.3823134330871
        },
        "mistral-small-24b-instruct-2501": {
            "rating": 1208.0837196309405,
            "rating_q975": 1241.3754738733064,
            "rating_q025": 1174.7919653885747
        },
        "gemma-2-27b-it": {
            "rating": 1205.3790680045017,
            "rating_q975": 1218.3624306104493,
            "rating_q025": 1192.3957053985541
        },
        "gemini-1.5-flash-8b-001": {
            "rating": 1201.8673302554412,
            "rating_q975": 1221.9314935152681,
            "rating_q025": 1181.8031669956142
        },
        "claude-3-sonnet-20240229": {
            "rating": 1200.0932987702831,
            "rating_q975": 1213.496062278094,
            "rating_q025": 1186.6905352624722
        },
        "c4ai-aya-expanse-32b": {
            "rating": 1195.4460633828485,
            "rating_q975": 1218.3467578220163,
            "rating_q025": 1172.5453689436806
        },
        "jamba-1.5-large": {
            "rating": 1194.3726771370425,
            "rating_q975": 1230.69696322362,
            "rating_q025": 1158.048391050465
        },
        "gpt-4-0314": {
            "rating": 1194.357118786968,
            "rating_q975": 1212.2539572426826,
            "rating_q025": 1176.4602803312532
        },
        "command-r-plus": {
            "rating": 1191.2968056787622,
            "rating_q975": 1204.88795362498,
            "rating_q025": 1177.7056577325445
        },
        "amazon-nova-micro-v1.0": {
            "rating": 1190.0259421805615,
            "rating_q975": 1216.4148550422794,
            "rating_q025": 1163.6370293188436
        },
        "nemotron-4-340b-instruct": {
            "rating": 1188.1699900139643,
            "rating_q975": 1210.3096634066806,
            "rating_q025": 1166.030316621248
        },
        "c4ai-aya-expanse-8b": {
            "rating": 1185.4478021822651,
            "rating_q975": 1221.8246535978788,
            "rating_q025": 1149.0709507666515
        },
        "gemma-2-9b-it": {
            "rating": 1182.197243924213,
            "rating_q975": 1197.0459113820493,
            "rating_q025": 1167.3485764663765
        },
        "glm-4-0520": {
            "rating": 1180.107004729391,
            "rating_q975": 1209.3779457774606,
            "rating_q025": 1150.8360636813215
        },
        "mistral-large-2402": {
            "rating": 1175.3113473928474,
            "rating_q975": 1191.0068984455083,
            "rating_q025": 1159.6157963401865
        },
        "reka-flash-20240904": {
            "rating": 1174.7139003856005,
            "rating_q975": 1212.94457416118,
            "rating_q025": 1136.483226610021
        },
        "command-r-08-2024": {
            "rating": 1172.521546927456,
            "rating_q975": 1204.8295171012462,
            "rating_q025": 1140.2135767536658
        },
        "claude-3-haiku-20240307": {
            "rating": 1169.711157704195,
            "rating_q975": 1182.0292114684023,
            "rating_q025": 1157.393103939988
        },
        "llama-3-70b-instruct": {
            "rating": 1165.5820889955198,
            "rating_q975": 1177.4398797116396,
            "rating_q025": 1153.7242982794
        },
        "jamba-1.5-mini": {
            "rating": 1160.436100356941,
            "rating_q975": 1197.9401497871752,
            "rating_q025": 1122.932050926707
        },
        "deepseek-coder-v2": {
            "rating": 1159.9238710523482,
            "rating_q975": 1185.347065943825,
            "rating_q025": 1134.5006761608713
        },
        "gpt-4-0613": {
            "rating": 1157.5826274618144,
            "rating_q975": 1172.1133673662266,
            "rating_q025": 1143.051887557402
        },
        "mistral-medium": {
            "rating": 1152.395678301478,
            "rating_q975": 1173.690155405036,
            "rating_q025": 1131.10120119792
        },
        "reka-flash-21b-20240226": {
            "rating": 1149.2432554258555,
            "rating_q975": 1169.774885424611,
            "rating_q025": 1128.7116254271
        },
        "reka-flash-21b-20240226-online": {
            "rating": 1147.989930231559,
            "rating_q975": 1173.766059590074,
            "rating_q025": 1122.2138008730437
        },
        "qwen2-72b-instruct": {
            "rating": 1146.8617074179197,
            "rating_q975": 1163.406055258789,
            "rating_q025": 1130.3173595770504
        },
        "llama-3.1-8b-instruct": {
            "rating": 1141.0749762830574,
            "rating_q975": 1157.661049458699,
            "rating_q025": 1124.4889031074158
        },
        "mixtral-8x22b-instruct-v0.1": {
            "rating": 1136.9905201952874,
            "rating_q975": 1152.8279378870577,
            "rating_q025": 1121.1531025035172
        },
        "gemini-pro-dev-api": {
            "rating": 1122.257506775079,
            "rating_q975": 1151.0170572642219,
            "rating_q025": 1093.4979562859362
        },
        "command-r": {
            "rating": 1122.1629841913502,
            "rating_q975": 1139.4218019472096,
            "rating_q025": 1104.9041664354909
        },
        "qwen1.5-110b-chat": {
            "rating": 1120.06760659854,
            "rating_q975": 1139.8429942445061,
            "rating_q025": 1100.2922189525736
        },
        "gemma-2-2b-it": {
            "rating": 1111.5562703902133,
            "rating_q975": 1129.2462415622754,
            "rating_q025": 1093.8662992181512
        },
        "mixtral-8x7b-instruct-v0.1": {
            "rating": 1110.4987058626411,
            "rating_q975": 1125.4279387755532,
            "rating_q025": 1095.569472949729
        },
        "yi-1.5-34b-chat": {
            "rating": 1107.8991343349735,
            "rating_q975": 1127.4713794330894,
            "rating_q025": 1088.3268892368576
        },
        "llama-3-8b-instruct": {
            "rating": 1101.7549765709682,
            "rating_q975": 1114.7902185315827,
            "rating_q025": 1088.7197346103537
        },
        "phi-3-medium-4k-instruct": {
            "rating": 1099.1533147776,
            "rating_q975": 1119.2849757140714,
            "rating_q025": 1079.0216538411285
        },
        "gpt-3.5-turbo-0125": {
            "rating": 1086.779493799227,
            "rating_q975": 1102.4238744696322,
            "rating_q025": 1071.135113128822
        },
        "qwen1.5-72b-chat": {
            "rating": 1080.9756489766378,
            "rating_q975": 1099.6948789794587,
            "rating_q025": 1062.2564189738168
        },
        "wizardlm-70b": {
            "rating": 1079.797312608034,
            "rating_q975": 1123.9726210106655,
            "rating_q025": 1035.6220042054024
        },
        "starling-lm-7b-beta": {
            "rating": 1077.7939472759351,
            "rating_q975": 1107.708405673154,
            "rating_q025": 1047.8794888787163
        },
        "phi-3-small-8k-instruct": {
            "rating": 1076.1436903304448,
            "rating_q975": 1099.5911967435065,
            "rating_q025": 1052.696183917383
        },
        "snowflake-arctic-instruct": {
            "rating": 1070.4670074879073,
            "rating_q975": 1091.820431059916,
            "rating_q025": 1049.1135839158985
        },
        "openchat-3.5-0106": {
            "rating": 1061.1917595600635,
            "rating_q975": 1094.2651707327634,
            "rating_q025": 1028.1183483873635
        },
        "internlm2_5-20b-chat": {
            "rating": 1059.145451933317,
            "rating_q975": 1095.9241451499643,
            "rating_q025": 1022.3667587166697
        },
        "vicuna-33b": {
            "rating": 1057.8439253549018,
            "rating_q975": 1086.4757278605568,
            "rating_q025": 1029.2121228492467
        },
        "gpt-3.5-turbo-1106": {
            "rating": 1055.6763831871663,
            "rating_q975": 1090.061085724301,
            "rating_q025": 1021.2916806500315
        },
        "qwen1.5-32b-chat": {
            "rating": 1054.4716265616908,
            "rating_q975": 1076.083751116899,
            "rating_q025": 1032.8595020064824
        },
        "dbrx-instruct-preview": {
            "rating": 1053.3948102962117,
            "rating_q975": 1075.5494942786268,
            "rating_q025": 1031.2401263137967
        },
        "llama-3.2-3b-instruct": {
            "rating": 1052.4140540037188,
            "rating_q975": 1092.5410835865632,
            "rating_q025": 1012.2870244208743
        },
        "gemma-1.1-7b-it": {
            "rating": 1050.9909950109536,
            "rating_q975": 1071.7751541409677,
            "rating_q025": 1030.2068358809395
        },
        "phi-3-mini-4k-instruct": {
            "rating": 1039.812055403939,
            "rating_q975": 1062.7145387872972,
            "rating_q025": 1016.9095720205809
        },
        "qwen1.5-14b-chat": {
            "rating": 1039.0962890656017,
            "rating_q975": 1064.0710596348727,
            "rating_q025": 1014.1215184963307
        },
        "yi-34b-chat": {
            "rating": 1038.678321446403,
            "rating_q975": 1069.9039450099121,
            "rating_q025": 1007.452697882894
        },
        "llama-2-70b-chat": {
            "rating": 1037.5086019674159,
            "rating_q975": 1058.6208457218129,
            "rating_q025": 1016.3963582130189
        },
        "phi-3-mini-4k-instruct-june-2024": {
            "rating": 1027.699210139218,
            "rating_q975": 1059.196551764988,
            "rating_q025": 996.2018685134478
        },
        "starling-lm-7b-alpha": {
            "rating": 1023.3247847718147,
            "rating_q975": 1065.1401868696519,
            "rating_q025": 981.5093826739776
        },
        "llama-3.2-1b-instruct": {
            "rating": 1009.9413639879724,
            "rating_q975": 1049.3604790179193,
            "rating_q025": 970.5222489580254
        },
        "llama-2-13b-chat": {
            "rating": 1003.6217673943552,
            "rating_q975": 1032.857707958249,
            "rating_q025": 974.3858268304614
        },
        "phi-3-mini-128k-instruct": {
            "rating": 1002.8029357710955,
            "rating_q975": 1026.3904389620718,
            "rating_q025": 979.2154325801192
        },
        "zephyr-7b-beta": {
            "rating": 988.6714976214189,
            "rating_q975": 1036.3468599353457,
            "rating_q025": 940.996135307492
        },
        "vicuna-13b": {
            "rating": 988.3702371316504,
            "rating_q975": 1024.0677501391765,
            "rating_q025": 952.6727241241242
        },
        "mistral-7b-instruct-v0.2": {
            "rating": 981.6357942993143,
            "rating_q975": 1008.0771178146449,
            "rating_q025": 955.1944707839837
        },
        "gemma-7b-it": {
            "rating": 979.780186046467,
            "rating_q975": 1023.6647021846534,
            "rating_q025": 935.8956699082805
        },
        "llama-2-7b-chat": {
            "rating": 973.3924342000776,
            "rating_q975": 1007.2980697084134,
            "rating_q025": 939.4867986917417
        },
        "gemma-1.1-2b-it": {
            "rating": 941.6997280760818,
            "rating_q975": 975.6012472331264,
            "rating_q025": 907.7982089190372
        },
        "mistral-7b-instruct": {
            "rating": 927.6055286214117,
            "rating_q975": 972.8849335741918,
            "rating_q025": 882.3261236686317
        },
        "qwen1.5-4b-chat": {
            "rating": 899.4679977890121,
            "rating_q975": 937.915448315533,
            "rating_q025": 861.0205472624912
        }
    },
    "hard_6": {
        "deepseek-v3.2-exp": {
            "rating": 1465.294020978825,
            "rating_q975": 1502.868636685155,
            "rating_q025": 1427.7194052724951
        },
        "gemini-2.5-pro": {
            "rating": 1463.0016952856192,
            "rating_q975": 1468.196966537419,
            "rating_q025": 1457.8064240338194
        },
        "claude-sonnet-4-5-20250929-thinking-32k": {
            "rating": 1457.746233540842,
            "rating_q975": 1465.6517871735527,
            "rating_q025": 1449.8406799081313
        },
        "glm-4.6": {
            "rating": 1450.0997331791716,
            "rating_q975": 1458.5442434160097,
            "rating_q025": 1441.6552229423335
        },
        "qwen3-max-preview": {
            "rating": 1447.1371314524654,
            "rating_q975": 1453.5353153807341,
            "rating_q025": 1440.7389475241966
        },
        "claude-opus-4-1-20250805-thinking-16k": {
            "rating": 1446.6980999216742,
            "rating_q975": 1452.918168688357,
            "rating_q025": 1440.4780311549914
        },
        "claude-sonnet-4-5-20250929": {
            "rating": 1441.4286043235832,
            "rating_q975": 1451.503861887554,
            "rating_q025": 1431.3533467596124
        },
        "claude-opus-4-1-20250805": {
            "rating": 1435.8587773990964,
            "rating_q975": 1441.6496905370286,
            "rating_q025": 1430.0678642611642
        },
        "qwen3-235b-a22b-instruct-2507": {
            "rating": 1432.716417490681,
            "rating_q975": 1438.4590133810952,
            "rating_q025": 1426.9738216002665
        },
        "longcat-flash-chat": {
            "rating": 1432.047443795891,
            "rating_q975": 1440.3666442712713,
            "rating_q025": 1423.7282433205107
        },
        "mistral-medium-2508": {
            "rating": 1431.0273566199087,
            "rating_q975": 1437.1278958696587,
            "rating_q025": 1424.9268173701587
        },
        "grok-3-preview-02-24": {
            "rating": 1430.9367092504463,
            "rating_q975": 1437.2850762190078,
            "rating_q025": 1424.5883422818847
        },
        "qwen3-vl-235b-a22b-instruct": {
            "rating": 1430.0456159888327,
            "rating_q975": 1439.0330975656286,
            "rating_q025": 1421.0581344120367
        },
        "qwen3-next-80b-a3b-instruct": {
            "rating": 1429.1048448931222,
            "rating_q975": 1435.810407217269,
            "rating_q025": 1422.3992825689754
        },
        "glm-4.5": {
            "rating": 1428.433013505031,
            "rating_q975": 1434.9478157749506,
            "rating_q025": 1421.9182112351116
        },
        "qwen3-max-2025-09-23": {
            "rating": 1424.4835040068656,
            "rating_q975": 1433.0626688879422,
            "rating_q025": 1415.904339125789
        },
        "deepseek-v3.1-terminus-thinking": {
            "rating": 1423.2879418270559,
            "rating_q975": 1437.695003483264,
            "rating_q025": 1408.8808801708478
        },
        "deepseek-v3.2-exp-thinking": {
            "rating": 1423.0291829058392,
            "rating_q975": 1431.7787116472891,
            "rating_q025": 1414.2796541643893
        },
        "chatgpt-4o-latest-20250326": {
            "rating": 1419.6635660409204,
            "rating_q975": 1424.9153201242339,
            "rating_q025": 1414.411811957607
        },
        "claude-haiku-4-5-20251001": {
            "rating": 1417.7034658940065,
            "rating_q975": 1426.059510249785,
            "rating_q025": 1409.347421538228
        },
        "gemini-2.5-flash": {
            "rating": 1416.790688806683,
            "rating_q975": 1421.912227932147,
            "rating_q025": 1411.6691496812189
        },
        "deepseek-v3.1-thinking": {
            "rating": 1416.7714367731037,
            "rating_q975": 1425.535997637714,
            "rating_q025": 1408.0068759084934
        },
        "qwen3-235b-a22b-thinking-2507": {
            "rating": 1416.4649116680746,
            "rating_q975": 1425.9746282317242,
            "rating_q025": 1406.955195104425
        },
        "gpt-5-high": {
            "rating": 1415.8284970928526,
            "rating_q975": 1422.0735275337415,
            "rating_q025": 1409.5834666519636
        },
        "deepseek-r1-0528": {
            "rating": 1415.3878103629713,
            "rating_q975": 1423.1309469565185,
            "rating_q025": 1407.6446737694241
        },
        "deepseek-v3.1": {
            "rating": 1414.4691905874026,
            "rating_q975": 1422.3820836337018,
            "rating_q025": 1406.5562975411035
        },
        "grok-4-fast": {
            "rating": 1411.1941890833155,
            "rating_q975": 1421.8198775691974,
            "rating_q025": 1400.5685005974335
        },
        "gemini-2.5-flash-preview-09-2025": {
            "rating": 1408.5793260373591,
            "rating_q975": 1416.0008229046343,
            "rating_q025": 1401.157829170084
        },
        "grok-4-0709": {
            "rating": 1407.5428553527165,
            "rating_q975": 1413.153748698097,
            "rating_q025": 1401.931962007336
        },
        "qwen3-vl-235b-a22b-thinking": {
            "rating": 1406.5274849331934,
            "rating_q975": 1415.80831426671,
            "rating_q025": 1397.2466555996766
        },
        "deepseek-v3.1-terminus": {
            "rating": 1406.1151681001875,
            "rating_q975": 1419.4074224674387,
            "rating_q025": 1392.8229137329363
        },
        "gpt-5-chat": {
            "rating": 1404.4446304183634,
            "rating_q975": 1410.5190751664563,
            "rating_q025": 1398.3701856702705
        },
        "o3-2025-04-16": {
            "rating": 1403.0395562152755,
            "rating_q975": 1408.1804537628761,
            "rating_q025": 1397.898658667675
        },
        "gpt-4.5-preview-2025-02-27": {
            "rating": 1402.0259932362042,
            "rating_q975": 1411.968480811777,
            "rating_q025": 1392.0835056606313
        },
        "qwen3-30b-a3b-instruct-2507": {
            "rating": 1397.5949276547096,
            "rating_q975": 1404.0495588223703,
            "rating_q025": 1391.140296487049
        },
        "hunyuan-t1-20250711": {
            "rating": 1397.0810521166736,
            "rating_q975": 1410.2506259815102,
            "rating_q025": 1383.911478251837
        },
        "claude-opus-4-20250514-thinking-16k": {
            "rating": 1396.733462154344,
            "rating_q975": 1402.5527080673633,
            "rating_q025": 1390.9142162413245
        },
        "qwen3-235b-a22b-no-thinking": {
            "rating": 1391.241378244196,
            "rating_q975": 1397.0111267561217,
            "rating_q025": 1385.4716297322705
        },
        "mai-1-preview": {
            "rating": 1386.2700640506728,
            "rating_q975": 1393.516255940508,
            "rating_q025": 1379.0238721608375
        },
        "gpt-4.1-2025-04-14": {
            "rating": 1383.5390738726276,
            "rating_q975": 1388.802663077804,
            "rating_q025": 1378.275484667451
        },
        "kimi-k2-0905-preview": {
            "rating": 1383.0867521248351,
            "rating_q975": 1391.9712004869768,
            "rating_q025": 1374.2023037626934
        },
        "gpt-5-mini-high": {
            "rating": 1380.3037098381876,
            "rating_q975": 1386.830282021585,
            "rating_q025": 1373.7771376547903
        },
        "gemini-2.5-flash-lite-preview-09-2025-no-thinking": {
            "rating": 1378.8111750462435,
            "rating_q975": 1386.2227738626898,
            "rating_q025": 1371.3995762297973
        },
        "glm-4.5-air": {
            "rating": 1376.0058347341403,
            "rating_q975": 1381.9856027414385,
            "rating_q025": 1370.0260667268421
        },
        "claude-opus-4-20250514": {
            "rating": 1374.3151737000128,
            "rating_q975": 1379.9069785372442,
            "rating_q025": 1368.7233688627814
        },
        "gemini-2.5-flash-lite-preview-06-17-thinking": {
            "rating": 1373.3257585004214,
            "rating_q975": 1379.250415609167,
            "rating_q025": 1367.4011013916759
        },
        "grok-3-mini-high": {
            "rating": 1372.30963575071,
            "rating_q975": 1379.51276164952,
            "rating_q025": 1365.1065098519
        },
        "hunyuan-turbos-20250416": {
            "rating": 1371.1464155348078,
            "rating_q975": 1380.5912336358172,
            "rating_q025": 1361.7015974337985
        },
        "claude-sonnet-4-20250514-thinking-32k": {
            "rating": 1370.7402459707782,
            "rating_q975": 1376.600899062889,
            "rating_q025": 1364.8795928786674
        },
        "qwen3-coder-480b-a35b-instruct": {
            "rating": 1370.3022580407908,
            "rating_q975": 1376.9355739407583,
            "rating_q025": 1363.6689421408232
        },
        "o1-2024-12-17": {
            "rating": 1370.0648150227655,
            "rating_q975": 1377.6128331634068,
            "rating_q025": 1362.5167968821243
        },
        "qwen3-next-80b-a3b-thinking": {
            "rating": 1369.6898522630356,
            "rating_q975": 1377.3794977130333,
            "rating_q025": 1362.000206813038
        },
        "kimi-k2-0711-preview": {
            "rating": 1365.3010864670414,
            "rating_q975": 1371.7511848385989,
            "rating_q025": 1358.850988095484
        },
        "o3-mini-high": {
            "rating": 1363.6208708930671,
            "rating_q975": 1372.6549812032604,
            "rating_q025": 1354.586760582874
        },
        "deepseek-v3-0324": {
            "rating": 1363.181304386385,
            "rating_q975": 1368.5155710191684,
            "rating_q025": 1357.8470377536014
        },
        "grok-3-mini-beta": {
            "rating": 1363.0658917430787,
            "rating_q975": 1369.7366112181578,
            "rating_q025": 1356.3951722679997
        },
        "ling-flash-2.0": {
            "rating": 1363.0490746311427,
            "rating_q975": 1372.9880241799863,
            "rating_q025": 1353.1101250822992
        },
        "mistral-medium-2505": {
            "rating": 1362.3835968066203,
            "rating_q975": 1368.4446787593224,
            "rating_q025": 1356.3225148539182
        },
        "qwen3-235b-a22b": {
            "rating": 1361.644415271352,
            "rating_q975": 1368.0402550195631,
            "rating_q025": 1355.248575523141
        },
        "deepseek-r1": {
            "rating": 1359.9002952656397,
            "rating_q975": 1368.7420665144207,
            "rating_q025": 1351.0585240168587
        },
        "amazon-nova-experimental-chat-10-09": {
            "rating": 1358.6954005552689,
            "rating_q975": 1368.9002231756133,
            "rating_q025": 1348.4905779349244
        },
        "qwen2.5-max": {
            "rating": 1357.5992585088184,
            "rating_q975": 1363.7607351193546,
            "rating_q025": 1351.437781898282
        },
        "gpt-oss-120b": {
            "rating": 1356.915220713882,
            "rating_q975": 1363.062239900075,
            "rating_q025": 1350.7682015276891
        },
        "o1-preview": {
            "rating": 1352.8854492962423,
            "rating_q975": 1360.412064669384,
            "rating_q025": 1345.3588339231005
        },
        "claude-sonnet-4-20250514": {
            "rating": 1352.4674845856748,
            "rating_q975": 1358.1968326217411,
            "rating_q025": 1346.7381365496085
        },
        "step-3": {
            "rating": 1352.1168005853008,
            "rating_q975": 1362.843725905635,
            "rating_q025": 1341.3898752649666
        },
        "o4-mini-2025-04-16": {
            "rating": 1350.1826785770104,
            "rating_q975": 1355.4771150148313,
            "rating_q025": 1344.8882421391895
        },
        "gpt-4.1-mini-2025-04-14": {
            "rating": 1347.4800613631198,
            "rating_q975": 1353.2491516745977,
            "rating_q025": 1341.710971051642
        },
        "ring-flash-2.0": {
            "rating": 1344.3937280865603,
            "rating_q975": 1354.237548279461,
            "rating_q025": 1334.5499078936596
        },
        "minimax-m1": {
            "rating": 1342.153974844405,
            "rating_q975": 1347.7768062602443,
            "rating_q025": 1336.5311434285657
        },
        "gemma-3-27b-it": {
            "rating": 1338.8668650672453,
            "rating_q975": 1344.0951436434757,
            "rating_q025": 1333.6385864910148
        },
        "mistral-small-2506": {
            "rating": 1334.9424831152755,
            "rating_q975": 1341.9398977248754,
            "rating_q025": 1327.9450685056756
        },
        "step-1o-turbo-202506": {
            "rating": 1334.1187325078295,
            "rating_q975": 1343.890332274968,
            "rating_q025": 1324.347132740691
        },
        "qwen3-32b": {
            "rating": 1332.3321122478033,
            "rating_q975": 1348.4498427503856,
            "rating_q025": 1316.2143817452209
        },
        "glm-4.5v": {
            "rating": 1332.1844617148681,
            "rating_q975": 1344.3217492001384,
            "rating_q025": 1320.0471742295979
        },
        "o1-mini": {
            "rating": 1331.831317987443,
            "rating_q975": 1337.6065084256543,
            "rating_q025": 1326.0561275492319
        },
        "o3-mini": {
            "rating": 1331.8184476942704,
            "rating_q975": 1336.753160087649,
            "rating_q025": 1326.8837353008919
        },
        "claude-3-7-sonnet-20250219-thinking-32k": {
            "rating": 1331.7344408467713,
            "rating_q975": 1337.7335364699222,
            "rating_q025": 1325.7353452236205
        },
        "nvidia-llama-3.3-nemotron-super-49b-v1.5": {
            "rating": 1330.6523721881842,
            "rating_q975": 1345.5258365953378,
            "rating_q025": 1315.7789077810307
        },
        "gpt-5-nano-high": {
            "rating": 1326.1274784445934,
            "rating_q975": 1335.9359804475916,
            "rating_q025": 1316.3189764415952
        },
        "qwq-32b": {
            "rating": 1325.240870236428,
            "rating_q975": 1331.760070155437,
            "rating_q025": 1318.721670317419
        },
        "command-a-03-2025": {
            "rating": 1324.489687605154,
            "rating_q975": 1329.468021786319,
            "rating_q025": 1319.5113534239888
        },
        "gemini-2.0-flash-lite-preview-02-05": {
            "rating": 1323.3665258444078,
            "rating_q975": 1330.652345579936,
            "rating_q025": 1316.0807061088794
        },
        "hunyuan-turbos-20250226": {
            "rating": 1322.4405574184748,
            "rating_q975": 1345.4583091868533,
            "rating_q025": 1299.4228056500963
        },
        "qwen-plus-0125": {
            "rating": 1315.4036325870122,
            "rating_q975": 1329.6385227217613,
            "rating_q025": 1301.1687424522631
        },
        "qwen3-30b-a3b": {
            "rating": 1314.4358421836898,
            "rating_q975": 1320.8714126893028,
            "rating_q025": 1308.0002716780768
        },
        "llama-3.1-nemotron-ultra-253b-v1": {
            "rating": 1313.7961649124911,
            "rating_q975": 1335.1816843407742,
            "rating_q025": 1292.410645484208
        },
        "deepseek-v3": {
            "rating": 1310.9485524359627,
            "rating_q975": 1318.8773786316635,
            "rating_q025": 1303.019726240262
        },
        "llama-3.3-nemotron-49b-super-v1": {
            "rating": 1310.0343941980996,
            "rating_q975": 1334.5350901596992,
            "rating_q025": 1285.5336982365
        },
        "gemma-3-12b-it": {
            "rating": 1308.6425258555282,
            "rating_q975": 1326.455097540395,
            "rating_q025": 1290.8299541706615
        },
        "hunyuan-turbo-0110": {
            "rating": 1305.756204927126,
            "rating_q975": 1329.4307354363937,
            "rating_q025": 1282.0816744178583
        },
        "claude-3-5-sonnet-20241022": {
            "rating": 1304.850922241269,
            "rating_q975": 1308.981962026627,
            "rating_q025": 1300.7198824559111
        },
        "yi-lightning": {
            "rating": 1301.0080608281362,
            "rating_q975": 1308.8313577836243,
            "rating_q025": 1293.184763872648
        },
        "qwen2.5-plus-1127": {
            "rating": 1298.6033270425992,
            "rating_q975": 1309.1231196349024,
            "rating_q025": 1288.083534450296
        },
        "step-2-16k-exp-202412": {
            "rating": 1297.1487879374022,
            "rating_q975": 1312.4766522773318,
            "rating_q025": 1281.8209235974725
        },
        "gemini-1.5-pro-002": {
            "rating": 1295.4123256418907,
            "rating_q975": 1300.756173916892,
            "rating_q025": 1290.0684773668893
        },
        "glm-4-plus-0111": {
            "rating": 1292.8902352816121,
            "rating_q975": 1307.206561649251,
            "rating_q025": 1278.5739089139734
        },
        "athene-v2-chat": {
            "rating": 1291.276465520053,
            "rating_q975": 1298.475141423189,
            "rating_q025": 1284.0777896169172
        },
        "deepseek-v2.5-1210": {
            "rating": 1288.8851935823866,
            "rating_q975": 1302.1550067234937,
            "rating_q025": 1275.6153804412795
        },
        "hunyuan-large-2025-02-10": {
            "rating": 1285.2401862207735,
            "rating_q975": 1304.1572199034595,
            "rating_q025": 1266.3231525380875
        },
        "gemma-3n-e4b-it": {
            "rating": 1285.1554690955031,
            "rating_q975": 1292.3142933968616,
            "rating_q025": 1277.9966447941447
        },
        "gpt-4.1-nano-2025-04-14": {
            "rating": 1284.2538460913497,
            "rating_q975": 1297.8931358684056,
            "rating_q025": 1270.6145563142938
        },
        "llama-4-maverick-17b-128e-instruct": {
            "rating": 1281.881137613766,
            "rating_q975": 1287.7084803689272,
            "rating_q025": 1276.0537948586048
        },
        "gpt-4o-2024-05-13": {
            "rating": 1279.760154105688,
            "rating_q975": 1284.9327059651662,
            "rating_q025": 1274.5876022462096
        },
        "mistral-small-3.1-24b-instruct-2503": {
            "rating": 1278.3316406735712,
            "rating_q975": 1284.3262103283985,
            "rating_q025": 1272.337071018744
        },
        "gpt-oss-20b": {
            "rating": 1275.136150540306,
            "rating_q975": 1284.1807130097861,
            "rating_q025": 1266.091588070826
        },
        "claude-3-5-sonnet-20240620": {
            "rating": 1274.4234925017386,
            "rating_q975": 1279.838722679796,
            "rating_q025": 1269.008262323681
        },
        "glm-4-plus": {
            "rating": 1271.692150540663,
            "rating_q975": 1279.2595465598351,
            "rating_q025": 1264.124754521491
        },
        "grok-2-2024-08-13": {
            "rating": 1271.1176057368498,
            "rating_q975": 1276.4716394468699,
            "rating_q025": 1265.7635720268297
        },
        "deepseek-v2.5": {
            "rating": 1269.6711885620348,
            "rating_q975": 1277.0765494341504,
            "rating_q025": 1262.2658276899192
        },
        "qwen2.5-72b-instruct": {
            "rating": 1269.598527815061,
            "rating_q975": 1275.7719234795857,
            "rating_q025": 1263.4251321505365
        },
        "qwen-max-0919": {
            "rating": 1268.4554844081051,
            "rating_q975": 1277.5950178666703,
            "rating_q025": 1259.31595094954
        },
        "llama-3.1-405b-instruct-bf16": {
            "rating": 1268.2685929001707,
            "rating_q975": 1274.0184613264437,
            "rating_q025": 1262.5187244738977
        },
        "magistral-medium-2506": {
            "rating": 1267.3596000324346,
            "rating_q975": 1275.7641087543905,
            "rating_q025": 1258.9550913104788
        },
        "llama-4-scout-17b-16e-instruct": {
            "rating": 1266.567743834473,
            "rating_q975": 1272.8435102198146,
            "rating_q025": 1260.2919774491315
        },
        "gpt-4o-mini-2024-07-18": {
            "rating": 1266.0913441701734,
            "rating_q975": 1271.1419545853753,
            "rating_q025": 1261.0407337549716
        },
        "llama-3.1-nemotron-70b-instruct": {
            "rating": 1265.2129248504114,
            "rating_q975": 1277.933195273183,
            "rating_q025": 1252.4926544276398
        },
        "hunyuan-standard-2025-02-10": {
            "rating": 1264.1221898573717,
            "rating_q975": 1282.949471950891,
            "rating_q025": 1245.2949077638525
        },
        "gpt-4o-2024-08-06": {
            "rating": 1263.0955658699268,
            "rating_q975": 1269.3421739235007,
            "rating_q025": 1256.8489578163528
        },
        "llama-3.1-405b-instruct-fp8": {
            "rating": 1262.7739059012872,
            "rating_q975": 1268.3962247017225,
            "rating_q025": 1257.1515871008519
        },
        "llama-3.3-70b-instruct": {
            "rating": 1257.6514114231622,
            "rating_q975": 1262.4983991881036,
            "rating_q025": 1252.804423658221
        },
        "hunyuan-large-vision": {
            "rating": 1257.1259235475982,
            "rating_q975": 1270.4206856894582,
            "rating_q025": 1243.8311614057382
        },
        "gemini-1.5-flash-002": {
            "rating": 1255.9995329501007,
            "rating_q975": 1262.488446011194,
            "rating_q025": 1249.5106198890076
        },
        "mistral-large-2411": {
            "rating": 1255.700725031317,
            "rating_q975": 1262.5491774275051,
            "rating_q025": 1248.8522726351289
        },
        "mistral-large-2407": {
            "rating": 1255.6929278122593,
            "rating_q975": 1261.827648078003,
            "rating_q025": 1249.5582075465156
        },
        "grok-2-mini-2024-08-13": {
            "rating": 1253.880613698802,
            "rating_q975": 1259.539096896803,
            "rating_q025": 1248.2221305008013
        },
        "gemini-1.5-pro-001": {
            "rating": 1253.8392253377406,
            "rating_q975": 1259.816391801593,
            "rating_q025": 1247.8620588738881
        },
        "gemma-3-4b-it": {
            "rating": 1251.563175980083,
            "rating_q975": 1268.9056964395347,
            "rating_q025": 1234.2206555206315
        },
        "qwen2.5-coder-32b-instruct": {
            "rating": 1250.6823254815108,
            "rating_q975": 1265.0727377667827,
            "rating_q025": 1236.291913196239
        },
        "gpt-4-turbo-2024-04-09": {
            "rating": 1249.907451921988,
            "rating_q975": 1255.6486593379022,
            "rating_q025": 1244.1662445060738
        },
        "claude-3-5-haiku-20241022": {
            "rating": 1249.57012451916,
            "rating_q975": 1254.11580614232,
            "rating_q025": 1245.0244428959998
        },
        "gemini-advanced-0514": {
            "rating": 1247.5047006808873,
            "rating_q975": 1254.6602918241117,
            "rating_q025": 1240.3491095376628
        },
        "claude-3-opus-20240229": {
            "rating": 1244.1847256516967,
            "rating_q975": 1248.781347627006,
            "rating_q025": 1239.5881036763874
        },
        "amazon-nova-pro-v1.0": {
            "rating": 1243.9632607659114,
            "rating_q975": 1251.0909819017604,
            "rating_q025": 1236.8355396300624
        },
        "athene-70b-0725": {
            "rating": 1242.0473417561711,
            "rating_q975": 1250.5384958113957,
            "rating_q025": 1233.5561877009466
        },
        "llama-3.1-70b-instruct": {
            "rating": 1240.177240839831,
            "rating_q975": 1245.814582128415,
            "rating_q025": 1234.5398995512471
        },
        "gpt-4-1106-preview": {
            "rating": 1240.1246437864183,
            "rating_q975": 1246.0179314551333,
            "rating_q025": 1234.2313561177034
        },
        "gpt-4-0125-preview": {
            "rating": 1237.5580113594465,
            "rating_q975": 1243.5734200331779,
            "rating_q025": 1231.542602685715
        },
        "mistral-small-24b-instruct-2501": {
            "rating": 1231.546434543312,
            "rating_q975": 1241.0702347981846,
            "rating_q025": 1222.0226342884393
        },
        "amazon-nova-lite-v1.0": {
            "rating": 1219.0853329232664,
            "rating_q975": 1227.2637324318357,
            "rating_q025": 1210.906933414697
        },
        "llama-3.1-tulu-3-70b": {
            "rating": 1219.043046219195,
            "rating_q975": 1237.748352590619,
            "rating_q025": 1200.337739847771
        },
        "phi-4": {
            "rating": 1218.735816202741,
            "rating_q975": 1226.4026136586447,
            "rating_q025": 1211.0690187468374
        },
        "gemini-1.5-flash-001": {
            "rating": 1218.5717232787008,
            "rating_q975": 1224.6698235288643,
            "rating_q025": 1212.4736230285373
        },
        "jamba-1.5-large": {
            "rating": 1217.1676421099696,
            "rating_q975": 1228.73968623998,
            "rating_q025": 1205.5955979799592
        },
        "hunyuan-standard-256k": {
            "rating": 1216.775916930063,
            "rating_q975": 1237.3606481408199,
            "rating_q025": 1196.191185719306
        },
        "glm-4-0520": {
            "rating": 1210.4701421299253,
            "rating_q975": 1221.5494144062043,
            "rating_q025": 1199.3908698536463
        },
        "reka-core-20240904": {
            "rating": 1210.0893698709838,
            "rating_q975": 1221.568622489859,
            "rating_q025": 1198.6101172521085
        },
        "gemini-1.5-flash-8b-001": {
            "rating": 1208.1023866362616,
            "rating_q975": 1214.5830407682538,
            "rating_q025": 1201.6217325042694
        },
        "olmo-2-0325-32b-instruct": {
            "rating": 1207.8789007757032,
            "rating_q975": 1227.887799243689,
            "rating_q025": 1187.8700023077174
        },
        "deepseek-coder-v2": {
            "rating": 1205.5456091289434,
            "rating_q975": 1215.3249073504526,
            "rating_q025": 1195.7663109074342
        },
        "llama-3.1-nemotron-51b-instruct": {
            "rating": 1202.5841711287794,
            "rating_q975": 1219.9504958753707,
            "rating_q025": 1185.217846382188
        },
        "nemotron-4-340b-instruct": {
            "rating": 1200.4597662461883,
            "rating_q975": 1209.317654107471,
            "rating_q025": 1191.6018783849056
        },
        "gpt-4-0314": {
            "rating": 1198.5285662019328,
            "rating_q975": 1206.2190364725693,
            "rating_q025": 1190.8380959312963
        },
        "gemma-2-27b-it": {
            "rating": 1197.3917313603758,
            "rating_q975": 1202.3552676724596,
            "rating_q025": 1192.428195048292
        },
        "claude-3-sonnet-20240229": {
            "rating": 1195.7668111336532,
            "rating_q975": 1201.6275092325673,
            "rating_q025": 1189.906113034739
        },
        "gemma-2-9b-it-simpo": {
            "rating": 1195.5898478749225,
            "rating_q975": 1206.8993863899218,
            "rating_q025": 1184.2803093599232
        },
        "llama-3-70b-instruct": {
            "rating": 1194.0794718222648,
            "rating_q975": 1199.5501886004904,
            "rating_q025": 1188.6087550440393
        },
        "c4ai-aya-expanse-32b": {
            "rating": 1192.1215731635457,
            "rating_q975": 1199.4981347416203,
            "rating_q025": 1184.745011585471
        },
        "amazon-nova-micro-v1.0": {
            "rating": 1190.5082983120508,
            "rating_q975": 1198.6391370811466,
            "rating_q025": 1182.377459542955
        },
        "ministral-8b-2410": {
            "rating": 1190.1828264553278,
            "rating_q975": 1205.3196100468763,
            "rating_q025": 1175.0460428637793
        },
        "qwen2-72b-instruct": {
            "rating": 1189.3259219148745,
            "rating_q975": 1196.523089879039,
            "rating_q025": 1182.12875395071
        },
        "command-r-plus-08-2024": {
            "rating": 1184.9857724260469,
            "rating_q975": 1195.420638079848,
            "rating_q025": 1174.5509067722458
        },
        "reka-flash-20240904": {
            "rating": 1180.9080660537634,
            "rating_q975": 1192.0537162477524,
            "rating_q025": 1169.7624158597744
        },
        "llama-3.1-8b-instruct": {
            "rating": 1174.057955047058,
            "rating_q975": 1180.002590082856,
            "rating_q025": 1168.11332001126
        },
        "llama-3.1-tulu-3-8b": {
            "rating": 1173.471293204126,
            "rating_q975": 1193.4062866851555,
            "rating_q025": 1153.5362997230964
        },
        "gpt-4-0613": {
            "rating": 1173.2840330819504,
            "rating_q975": 1179.6754737083186,
            "rating_q025": 1166.8925924555822
        },
        "claude-3-haiku-20240307": {
            "rating": 1172.9680637903643,
            "rating_q975": 1178.4843470156613,
            "rating_q025": 1167.4517805650673
        },
        "gemma-2-9b-it": {
            "rating": 1170.5881917537736,
            "rating_q975": 1176.2607807451682,
            "rating_q025": 1164.915602762379
        },
        "qwen1.5-110b-chat": {
            "rating": 1167.1319159803625,
            "rating_q975": 1175.8458432811904,
            "rating_q025": 1158.4179886795346
        },
        "jamba-1.5-mini": {
            "rating": 1166.0577498428765,
            "rating_q975": 1177.8494779940434,
            "rating_q025": 1154.2660216917097
        },
        "mistral-large-2402": {
            "rating": 1166.0097441826138,
            "rating_q975": 1172.8927293680097,
            "rating_q025": 1159.1267589972178
        },
        "command-r-plus": {
            "rating": 1165.4296215620848,
            "rating_q975": 1171.7152297451194,
            "rating_q025": 1159.1440133790502
        },
        "command-r-08-2024": {
            "rating": 1163.7392514493497,
            "rating_q975": 1173.9605700056668,
            "rating_q025": 1153.5179328930326
        },
        "qwq-32b-preview": {
            "rating": 1161.5771552381532,
            "rating_q975": 1180.9870804601298,
            "rating_q025": 1142.1672300161765
        },
        "yi-1.5-34b-chat": {
            "rating": 1158.4905897726765,
            "rating_q975": 1166.7425698091731,
            "rating_q025": 1150.2386097361798
        },
        "internlm2_5-20b-chat": {
            "rating": 1157.5912284265637,
            "rating_q975": 1168.9214132813331,
            "rating_q025": 1146.2610435717943
        },
        "c4ai-aya-expanse-8b": {
            "rating": 1155.9262564001178,
            "rating_q975": 1167.1311647163243,
            "rating_q025": 1144.7213480839114
        },
        "mixtral-8x22b-instruct-v0.1": {
            "rating": 1148.7746077347883,
            "rating_q975": 1155.6214869890712,
            "rating_q025": 1141.9277284805055
        },
        "mistral-medium": {
            "rating": 1148.1242849489267,
            "rating_q975": 1156.7694322672485,
            "rating_q025": 1139.479137630605
        },
        "qwen1.5-72b-chat": {
            "rating": 1146.8203222342418,
            "rating_q975": 1154.5996409897002,
            "rating_q025": 1139.0410034787833
        },
        "granite-3.1-8b-instruct": {
            "rating": 1145.486735460781,
            "rating_q975": 1165.2426171776142,
            "rating_q025": 1125.7308537439476
        },
        "granite-3.1-2b-instruct": {
            "rating": 1136.6912250019614,
            "rating_q975": 1155.892531497301,
            "rating_q025": 1117.4899185066217
        },
        "reka-flash-21b-20240226-online": {
            "rating": 1136.4780201285212,
            "rating_q975": 1147.2090207194599,
            "rating_q025": 1125.7470195375824
        },
        "reka-flash-21b-20240226": {
            "rating": 1135.512817633325,
            "rating_q975": 1144.320538108628,
            "rating_q025": 1126.7050971580222
        },
        "llama-3-8b-instruct": {
            "rating": 1132.5677298586381,
            "rating_q975": 1138.5559463469174,
            "rating_q025": 1126.5795133703589
        },
        "qwen1.5-32b-chat": {
            "rating": 1129.6465389812192,
            "rating_q975": 1138.8944627147682,
            "rating_q025": 1120.3986152476703
        },
        "phi-3-medium-4k-instruct": {
            "rating": 1125.5591101010268,
            "rating_q975": 1133.5501566159464,
            "rating_q025": 1117.5680635861072
        },
        "starling-lm-7b-beta": {
            "rating": 1117.676440693483,
            "rating_q975": 1128.382960594003,
            "rating_q025": 1106.9699207929632
        },
        "zephyr-orpo-141b-A35b-v0.1": {
            "rating": 1115.794332151186,
            "rating_q975": 1132.5986089200574,
            "rating_q025": 1098.9900553823145
        },
        "command-r": {
            "rating": 1113.9050911839868,
            "rating_q975": 1121.0285564039455,
            "rating_q025": 1106.781625964028
        },
        "mixtral-8x7b-instruct-v0.1": {
            "rating": 1113.7681361914438,
            "rating_q975": 1120.3989467569068,
            "rating_q025": 1107.1373256259808
        },
        "qwen1.5-14b-chat": {
            "rating": 1112.6414761681397,
            "rating_q975": 1123.2246186264772,
            "rating_q025": 1102.0583337098021
        },
        "dbrx-instruct-preview": {
            "rating": 1112.2687219244194,
            "rating_q975": 1121.2617627853376,
            "rating_q025": 1103.2756810635012
        },
        "gemma-2-2b-it": {
            "rating": 1112.0931706968267,
            "rating_q975": 1118.2405553141014,
            "rating_q025": 1105.9457860795521
        },
        "gemini-pro-dev-api": {
            "rating": 1108.3245357785677,
            "rating_q975": 1119.5776631887393,
            "rating_q025": 1097.071408368396
        },
        "gpt-3.5-turbo-0125": {
            "rating": 1106.9867874799163,
            "rating_q975": 1113.5777867905472,
            "rating_q025": 1100.3957881692854
        },
        "tulu-2-dpo-70b": {
            "rating": 1103.5278658421375,
            "rating_q975": 1119.8892673704902,
            "rating_q025": 1087.166464313785
        },
        "yi-34b-chat": {
            "rating": 1102.6629842573855,
            "rating_q975": 1113.227477748149,
            "rating_q025": 1092.0984907666218
        },
        "phi-3-small-8k-instruct": {
            "rating": 1098.931049196036,
            "rating_q975": 1108.3711492126047,
            "rating_q025": 1089.4909491794672
        },
        "gpt-3.5-turbo-1106": {
            "rating": 1097.4046757492379,
            "rating_q975": 1110.3160481321959,
            "rating_q025": 1084.4933033662799
        },
        "llama-3.2-3b-instruct": {
            "rating": 1094.5245817649757,
            "rating_q975": 1106.6686279056453,
            "rating_q025": 1082.380535624306
        },
        "gemini-pro": {
            "rating": 1092.5029301798522,
            "rating_q975": 1110.315497974061,
            "rating_q025": 1074.6903623856435
        },
        "granite-3.0-8b-instruct": {
            "rating": 1091.3021351983052,
            "rating_q975": 1106.0030901324828,
            "rating_q025": 1076.6011802641276
        },
        "phi-3-mini-4k-instruct-june-2024": {
            "rating": 1086.5507196893773,
            "rating_q975": 1097.2771000979578,
            "rating_q025": 1075.8243392807967
        },
        "openchat-3.5-0106": {
            "rating": 1083.7736467945565,
            "rating_q975": 1094.9138821266909,
            "rating_q025": 1072.6334114624221
        },
        "wizardlm-70b": {
            "rating": 1078.5218107802493,
            "rating_q975": 1093.8681401573535,
            "rating_q025": 1063.175481403145
        },
        "starling-lm-7b-alpha": {
            "rating": 1074.7951030602314,
            "rating_q975": 1087.4238387346554,
            "rating_q025": 1062.1663673858075
        },
        "granite-3.0-2b-instruct": {
            "rating": 1072.4637556107473,
            "rating_q975": 1086.995684287406,
            "rating_q025": 1057.9318269340886
        },
        "llama-2-70b-chat": {
            "rating": 1072.1341341481468,
            "rating_q975": 1080.3126205633168,
            "rating_q025": 1063.9556477329768
        },
        "snowflake-arctic-instruct": {
            "rating": 1071.5531805890141,
            "rating_q975": 1080.6549509881795,
            "rating_q025": 1062.4514101898487
        },
        "openhermes-2.5-mistral-7b": {
            "rating": 1070.4080080235044,
            "rating_q975": 1087.4989193863992,
            "rating_q025": 1053.3170966606096
        },
        "phi-3-mini-4k-instruct": {
            "rating": 1070.1780347471306,
            "rating_q975": 1079.62406085857,
            "rating_q025": 1060.7320086356913
        },
        "gemma-1.1-7b-it": {
            "rating": 1069.7989573612872,
            "rating_q975": 1078.2753257126615,
            "rating_q025": 1061.322589009913
        },
        "deepseek-llm-67b-chat": {
            "rating": 1068.9769061941993,
            "rating_q975": 1087.7807474650351,
            "rating_q025": 1050.1730649233634
        },
        "mistral-7b-instruct-v0.2": {
            "rating": 1066.7324427691071,
            "rating_q975": 1076.3731586470974,
            "rating_q025": 1057.0917268911169
        },
        "vicuna-33b": {
            "rating": 1065.5606875304957,
            "rating_q975": 1075.5649887963712,
            "rating_q025": 1055.5563862646202
        },
        "qwen1.5-7b-chat": {
            "rating": 1064.4371414924135,
            "rating_q975": 1080.0019603949404,
            "rating_q025": 1048.8723225898866
        },
        "openchat-3.5": {
            "rating": 1064.2818478708364,
            "rating_q975": 1079.982034368729,
            "rating_q025": 1048.5816613729437
        },
        "solar-10.7b-instruct-v1.0": {
            "rating": 1061.7455482291443,
            "rating_q975": 1081.5199163931154,
            "rating_q025": 1041.9711800651733
        },
        "smollm2-1.7b-instruct": {
            "rating": 1055.3570293000735,
            "rating_q975": 1080.1722494454305,
            "rating_q025": 1030.5418091547165
        },
        "dolphin-2.2.1-mistral-7b": {
            "rating": 1053.398014293305,
            "rating_q975": 1081.7449160661943,
            "rating_q025": 1025.051112520416
        },
        "nous-hermes-2-mixtral-8x7b-dpo": {
            "rating": 1052.335797684509,
            "rating_q975": 1069.9951573286887,
            "rating_q025": 1034.6764380403295
        },
        "llama-2-13b-chat": {
            "rating": 1050.284229837259,
            "rating_q975": 1060.5445826265072,
            "rating_q025": 1040.023877048011
        },
        "mpt-30b-chat": {
            "rating": 1049.4794921711823,
            "rating_q975": 1077.1247449059183,
            "rating_q025": 1021.8342394364463
        },
        "codellama-70b-instruct": {
            "rating": 1049.1947812705357,
            "rating_q975": 1081.449831114172,
            "rating_q025": 1016.9397314268995
        },
        "llama2-70b-steerlm-chat": {
            "rating": 1045.8922652086617,
            "rating_q975": 1066.822000013167,
            "rating_q025": 1024.9625304041563
        },
        "llama-3.2-1b-instruct": {
            "rating": 1043.4345088209338,
            "rating_q975": 1055.9965283409565,
            "rating_q025": 1030.8724893009112
        },
        "gemma-7b-it": {
            "rating": 1040.7135696131072,
            "rating_q975": 1054.2493058129528,
            "rating_q025": 1027.1778334132616
        },
        "codellama-34b-instruct": {
            "rating": 1030.6909221418343,
            "rating_q975": 1045.472316464719,
            "rating_q025": 1015.9095278189496
        },
        "phi-3-mini-128k-instruct": {
            "rating": 1027.4691713609004,
            "rating_q975": 1038.247448793585,
            "rating_q025": 1016.690893928216
        },
        "qwen-14b-chat": {
            "rating": 1025.4125792012683,
            "rating_q975": 1044.6524436046232,
            "rating_q025": 1006.1727147979134
        },
        "zephyr-7b-beta": {
            "rating": 1025.2474156344929,
            "rating_q975": 1039.727243278939,
            "rating_q025": 1010.7675879900468
        },
        "zephyr-7b-alpha": {
            "rating": 1023.8395506221052,
            "rating_q975": 1054.07563420057,
            "rating_q025": 993.6034670436404
        },
        "vicuna-13b": {
            "rating": 1022.2309624747455,
            "rating_q975": 1032.9477736582096,
            "rating_q025": 1011.5141512912816
        },
        "wizardlm-13b": {
            "rating": 1016.1469999133824,
            "rating_q975": 1032.8616980708598,
            "rating_q025": 999.4323017559049
        },
        "llama-2-7b-chat": {
            "rating": 1008.0895431932622,
            "rating_q975": 1018.9985508898029,
            "rating_q025": 997.1805354967215
        },
        "falcon-180b-chat": {
            "rating": 1006.0614113805093,
            "rating_q975": 1042.091638572558,
            "rating_q025": 970.0311841884607
        },
        "gemma-1.1-2b-it": {
            "rating": 1003.788628186155,
            "rating_q975": 1015.6013869183041,
            "rating_q025": 991.975869454006
        },
        "palm-2": {
            "rating": 1003.2809443311016,
            "rating_q975": 1019.0703322705588,
            "rating_q025": 987.4915563916445
        },
        "guanaco-33b": {
            "rating": 1002.5857122309615,
            "rating_q975": 1028.2272553546877,
            "rating_q025": 976.9441691072352
        },
        "mistral-7b-instruct": {
            "rating": 1000.6368005369832,
            "rating_q975": 1016.0186404939714,
            "rating_q025": 985.254960579995
        },
        "stripedhyena-nous-7b": {
            "rating": 997.2030747676965,
            "rating_q975": 1014.2701324034402,
            "rating_q025": 980.1360171319528
        },
        "vicuna-7b": {
            "rating": 993.5237984155458,
            "rating_q975": 1010.6101974401198,
            "rating_q025": 976.4373993909718
        },
        "olmo-7b-instruct": {
            "rating": 992.5099375642515,
            "rating_q975": 1009.4555021308536,
            "rating_q025": 975.5643729976493
        },
        "gemma-2b-it": {
            "rating": 987.4044885678222,
            "rating_q975": 1005.0803708837063,
            "rating_q025": 969.7286062519381
        },
        "qwen1.5-4b-chat": {
            "rating": 974.706658958731,
            "rating_q975": 988.7848365494733,
            "rating_q025": 960.6284813679888
        },
        "chatglm3-6b": {
            "rating": 951.5846894462178,
            "rating_q975": 971.9402837265874,
            "rating_q025": 931.2290951658482
        },
        "gpt4all-13b-snoozy": {
            "rating": 934.5638331801733,
            "rating_q975": 965.799763815107,
            "rating_q025": 903.3279025452397
        },
        "koala-13b": {
            "rating": 927.8816166944438,
            "rating_q975": 946.516806323372,
            "rating_q025": 909.2464270655156
        },
        "chatglm2-6b": {
            "rating": 914.773474443596,
            "rating_q975": 941.9786486943752,
            "rating_q025": 887.5683001928168
        },
        "chatglm-6b": {
            "rating": 899.102120546814,
            "rating_q975": 921.0313134497965,
            "rating_q025": 877.1729276438316
        },
        "RWKV-4-Raven-14B": {
            "rating": 893.78900059579,
            "rating_q975": 914.68997940885,
            "rating_q025": 872.8880217827299
        },
        "mpt-7b-chat": {
            "rating": 893.6029708315086,
            "rating_q975": 916.2871419453893,
            "rating_q025": 870.918799717628
        },
        "oasst-pythia-12b": {
            "rating": 882.5994926566235,
            "rating_q975": 902.1248755594709,
            "rating_q025": 863.0741097537762
        },
        "stablelm-tuned-alpha-7b": {
            "rating": 832.8339044816355,
            "rating_q975": 858.2369974003266,
            "rating_q025": 807.4308115629444
        },
        "alpaca-13b": {
            "rating": 823.4726452129087,
            "rating_q975": 843.6569362004839,
            "rating_q025": 803.2883542253335
        },
        "fastchat-t5-3b": {
            "rating": 812.1550854320651,
            "rating_q975": 833.9946350563956,
            "rating_q025": 790.3155358077346
        },
        "dolly-v2-12b": {
            "rating": 801.522533719841,
            "rating_q975": 826.543107418906,
            "rating_q025": 776.5019600207761
        },
        "llama-13b": {
            "rating": 725.5714768808708,
            "rating_q975": 756.8670456601026,
            "rating_q025": 694.2759081016391
        }
    },
    "hard_english_6": {
        "claude-sonnet-4-5-20250929-thinking-32k": {
            "rating": 1470.4781713133614,
            "rating_q975": 1481.1347252048463,
            "rating_q025": 1459.8216174218765
        },
        "gemini-2.5-pro": {
            "rating": 1459.278913288041,
            "rating_q975": 1465.632854346624,
            "rating_q025": 1452.9249722294578
        },
        "glm-4.6": {
            "rating": 1457.4955322553535,
            "rating_q975": 1469.0787979552526,
            "rating_q025": 1445.9122665554544
        },
        "claude-opus-4-1-20250805-thinking-16k": {
            "rating": 1457.4819141159637,
            "rating_q975": 1465.4745905402626,
            "rating_q025": 1449.4892376916648
        },
        "claude-sonnet-4-5-20250929": {
            "rating": 1447.1210432967532,
            "rating_q975": 1461.2459981646664,
            "rating_q025": 1432.99608842884
        },
        "claude-opus-4-1-20250805": {
            "rating": 1446.6190329745034,
            "rating_q975": 1453.8279851769025,
            "rating_q025": 1439.4100807721043
        },
        "qwen3-max-preview": {
            "rating": 1445.2652276781362,
            "rating_q975": 1453.5762857746477,
            "rating_q025": 1436.9541695816247
        },
        "longcat-flash-chat": {
            "rating": 1443.7069125384483,
            "rating_q975": 1454.914560256869,
            "rating_q025": 1432.4992648200275
        },
        "grok-3-preview-02-24": {
            "rating": 1441.3395047989968,
            "rating_q975": 1449.2158819754436,
            "rating_q025": 1433.46312762255
        },
        "deepseek-v3.2-exp-thinking": {
            "rating": 1440.8782821419609,
            "rating_q975": 1453.1304585933613,
            "rating_q025": 1428.6261056905605
        },
        "qwen3-vl-235b-a22b-instruct": {
            "rating": 1440.7962124795622,
            "rating_q975": 1453.2970220250586,
            "rating_q025": 1428.2954029340658
        },
        "claude-haiku-4-5-20251001": {
            "rating": 1438.208201777599,
            "rating_q975": 1449.531464913141,
            "rating_q025": 1426.884938642057
        },
        "qwen3-next-80b-a3b-instruct": {
            "rating": 1437.6707311183472,
            "rating_q975": 1446.4623208947949,
            "rating_q025": 1428.8791413418996
        },
        "qwen3-235b-a22b-instruct-2507": {
            "rating": 1434.9147723375597,
            "rating_q975": 1442.191152556284,
            "rating_q025": 1427.6383921188356
        },
        "mistral-medium-2508": {
            "rating": 1432.195748903531,
            "rating_q975": 1439.8315202553554,
            "rating_q025": 1424.5599775517067
        },
        "qwen3-235b-a22b-thinking-2507": {
            "rating": 1430.8529763088054,
            "rating_q975": 1444.0060078583874,
            "rating_q025": 1417.6999447592234
        },
        "qwen3-max-2025-09-23": {
            "rating": 1430.7590825903092,
            "rating_q975": 1442.595143817437,
            "rating_q025": 1418.9230213631813
        },
        "deepseek-v3.1-thinking": {
            "rating": 1428.6854687868044,
            "rating_q975": 1440.7985495322175,
            "rating_q025": 1416.5723880413914
        },
        "deepseek-v3.1-terminus-thinking": {
            "rating": 1426.2748011972913,
            "rating_q975": 1446.4583022928143,
            "rating_q025": 1406.0913001017682
        },
        "glm-4.5": {
            "rating": 1425.4118145945486,
            "rating_q975": 1433.819840102672,
            "rating_q025": 1417.003789086425
        },
        "gpt-5-high": {
            "rating": 1422.629351263024,
            "rating_q975": 1430.592584414414,
            "rating_q025": 1414.6661181116342
        },
        "grok-4-fast": {
            "rating": 1422.120891992458,
            "rating_q975": 1437.1696305066662,
            "rating_q025": 1407.0721534782497
        },
        "chatgpt-4o-latest-20250326": {
            "rating": 1419.9111816876068,
            "rating_q975": 1426.4358278193738,
            "rating_q025": 1413.3865355558398
        },
        "deepseek-r1-0528": {
            "rating": 1419.8334017448578,
            "rating_q975": 1430.0790050674757,
            "rating_q025": 1409.58779842224
        },
        "deepseek-v3.1": {
            "rating": 1417.9699756748475,
            "rating_q975": 1428.4810442582457,
            "rating_q025": 1407.4589070914494
        },
        "gemini-2.5-flash": {
            "rating": 1417.741219877693,
            "rating_q975": 1424.0010709616981,
            "rating_q025": 1411.481368793688
        },
        "qwen3-vl-235b-a22b-thinking": {
            "rating": 1414.118079110688,
            "rating_q975": 1426.9598855127874,
            "rating_q025": 1401.2762727085887
        },
        "grok-4-0709": {
            "rating": 1411.5427658749431,
            "rating_q975": 1418.662034157307,
            "rating_q025": 1404.4234975925792
        },
        "deepseek-v3.1-terminus": {
            "rating": 1411.1070747513318,
            "rating_q975": 1429.5273835718497,
            "rating_q025": 1392.6867659308139
        },
        "o3-2025-04-16": {
            "rating": 1409.244050805753,
            "rating_q975": 1415.5260749159586,
            "rating_q025": 1402.9620266955474
        },
        "claude-opus-4-20250514-thinking-16k": {
            "rating": 1407.6486711894247,
            "rating_q975": 1414.9810185422573,
            "rating_q025": 1400.3163238365921
        },
        "gpt-4.5-preview-2025-02-27": {
            "rating": 1406.4751521366925,
            "rating_q975": 1418.6639225301417,
            "rating_q025": 1394.2863817432433
        },
        "qwen3-30b-a3b-instruct-2507": {
            "rating": 1406.2821962427793,
            "rating_q975": 1414.665502458874,
            "rating_q025": 1397.8988900266845
        },
        "gemini-2.5-flash-preview-09-2025": {
            "rating": 1406.1438781493916,
            "rating_q975": 1416.2338923179127,
            "rating_q025": 1396.0538639808706
        },
        "gpt-5-chat": {
            "rating": 1404.634878930691,
            "rating_q975": 1412.4272584690223,
            "rating_q025": 1396.8424993923597
        },
        "mai-1-preview": {
            "rating": 1395.2730139907317,
            "rating_q975": 1404.8770870027138,
            "rating_q025": 1385.6689409787496
        },
        "gpt-4.1-2025-04-14": {
            "rating": 1392.7933496282953,
            "rating_q975": 1399.272673175925,
            "rating_q025": 1386.3140260806656
        },
        "hunyuan-t1-20250711": {
            "rating": 1392.5312492488724,
            "rating_q975": 1411.682985305101,
            "rating_q025": 1373.3795131926438
        },
        "claude-sonnet-4-20250514-thinking-32k": {
            "rating": 1389.5972509108626,
            "rating_q975": 1396.9765547960362,
            "rating_q025": 1382.217947025689
        },
        "qwen3-235b-a22b-no-thinking": {
            "rating": 1389.3320435334526,
            "rating_q975": 1396.5016551108888,
            "rating_q025": 1382.1624319560165
        },
        "ling-flash-2.0": {
            "rating": 1387.8441204315152,
            "rating_q975": 1401.3801391936743,
            "rating_q025": 1374.3081016693561
        },
        "gpt-5-mini-high": {
            "rating": 1387.4660567765748,
            "rating_q975": 1395.9722288964454,
            "rating_q025": 1378.9598846567042
        },
        "glm-4.5-air": {
            "rating": 1386.079631814535,
            "rating_q975": 1393.773170546247,
            "rating_q025": 1378.3860930828232
        },
        "qwen3-next-80b-a3b-thinking": {
            "rating": 1385.1743101200057,
            "rating_q975": 1395.4314652813177,
            "rating_q025": 1374.9171549586936
        },
        "qwen3-coder-480b-a35b-instruct": {
            "rating": 1383.1558446287045,
            "rating_q975": 1391.6537158009287,
            "rating_q025": 1374.6579734564802
        },
        "kimi-k2-0905-preview": {
            "rating": 1383.045883711987,
            "rating_q975": 1395.0743748930795,
            "rating_q025": 1371.0173925308945
        },
        "gemini-2.5-flash-lite-preview-09-2025-no-thinking": {
            "rating": 1381.2287312678325,
            "rating_q975": 1390.9841425419024,
            "rating_q025": 1371.4733199937625
        },
        "claude-opus-4-20250514": {
            "rating": 1381.0690673824506,
            "rating_q975": 1387.9581086226715,
            "rating_q025": 1374.1800261422297
        },
        "amazon-nova-experimental-chat-10-09": {
            "rating": 1380.24062327427,
            "rating_q975": 1394.4586900280906,
            "rating_q025": 1366.0225565204496
        },
        "grok-3-mini-high": {
            "rating": 1377.807184111602,
            "rating_q975": 1387.3202835451546,
            "rating_q025": 1368.2940846780496
        },
        "o1-preview": {
            "rating": 1376.3595478505886,
            "rating_q975": 1385.5743193051223,
            "rating_q025": 1367.1447763960548
        },
        "deepseek-v3-0324": {
            "rating": 1375.9449934629595,
            "rating_q975": 1382.4747611666094,
            "rating_q025": 1369.4152257593096
        },
        "gemini-2.5-flash-lite-preview-06-17-thinking": {
            "rating": 1375.3654412355347,
            "rating_q975": 1382.7894177138594,
            "rating_q025": 1367.94146475721
        },
        "ring-flash-2.0": {
            "rating": 1374.9136333359738,
            "rating_q975": 1388.4986242648788,
            "rating_q025": 1361.3286424070689
        },
        "deepseek-r1": {
            "rating": 1374.8552021372918,
            "rating_q975": 1385.8527388846837,
            "rating_q025": 1363.8576653899
        },
        "o3-mini-high": {
            "rating": 1374.5609150295822,
            "rating_q975": 1385.389954998209,
            "rating_q025": 1363.7318750609554
        },
        "step-3": {
            "rating": 1374.331343463806,
            "rating_q975": 1389.3197130447782,
            "rating_q025": 1359.3429738828338
        },
        "grok-3-mini-beta": {
            "rating": 1373.8290962444719,
            "rating_q975": 1382.233294030454,
            "rating_q025": 1365.4248984584897
        },
        "mistral-medium-2505": {
            "rating": 1372.6027747989287,
            "rating_q975": 1380.1094861722565,
            "rating_q025": 1365.096063425601
        },
        "hunyuan-turbos-20250416": {
            "rating": 1372.2081440431923,
            "rating_q975": 1384.6300164044042,
            "rating_q025": 1359.7862716819805
        },
        "qwen3-235b-a22b": {
            "rating": 1372.0284320480116,
            "rating_q975": 1380.0994747917182,
            "rating_q025": 1363.957389304305
        },
        "o1-2024-12-17": {
            "rating": 1371.9797813296893,
            "rating_q975": 1381.1581366737769,
            "rating_q025": 1362.8014259856018
        },
        "kimi-k2-0711-preview": {
            "rating": 1366.8427704849375,
            "rating_q975": 1374.9764827785075,
            "rating_q025": 1358.7090581913676
        },
        "o4-mini-2025-04-16": {
            "rating": 1366.0605812520325,
            "rating_q975": 1372.59231775686,
            "rating_q025": 1359.528844747205
        },
        "gpt-oss-120b": {
            "rating": 1362.6761914420767,
            "rating_q975": 1370.5422158053327,
            "rating_q025": 1354.8101670788208
        },
        "gpt-4.1-mini-2025-04-14": {
            "rating": 1362.0101702387472,
            "rating_q975": 1369.0610346496098,
            "rating_q025": 1354.9593058278845
        },
        "qwen2.5-max": {
            "rating": 1362.006881565782,
            "rating_q975": 1369.5578621728648,
            "rating_q025": 1354.455900958699
        },
        "claude-sonnet-4-20250514": {
            "rating": 1361.6690370071303,
            "rating_q975": 1368.7284974182173,
            "rating_q025": 1354.6095765960433
        },
        "mistral-small-2506": {
            "rating": 1358.389015012084,
            "rating_q975": 1367.6307535666008,
            "rating_q025": 1349.1472764575672
        },
        "minimax-m1": {
            "rating": 1356.9249121056139,
            "rating_q975": 1364.0099825258578,
            "rating_q025": 1349.83984168537
        },
        "glm-4.5v": {
            "rating": 1354.047998207133,
            "rating_q975": 1370.927513256048,
            "rating_q025": 1337.1684831582181
        },
        "o1-mini": {
            "rating": 1351.6585937086943,
            "rating_q975": 1358.7003789885748,
            "rating_q025": 1344.6168084288138
        },
        "step-1o-turbo-202506": {
            "rating": 1351.4349307530492,
            "rating_q975": 1364.6276108735603,
            "rating_q025": 1338.2422506325381
        },
        "qwen3-32b": {
            "rating": 1348.8067121887548,
            "rating_q975": 1369.626320413307,
            "rating_q025": 1327.9871039642026
        },
        "gemma-3-27b-it": {
            "rating": 1347.4551331121295,
            "rating_q975": 1353.8776783376784,
            "rating_q025": 1341.0325878865806
        },
        "claude-3-7-sonnet-20250219-thinking-32k": {
            "rating": 1344.1951987823413,
            "rating_q975": 1351.5806749944804,
            "rating_q025": 1336.8097225702022
        },
        "o3-mini": {
            "rating": 1343.6996701083697,
            "rating_q975": 1349.7343290843517,
            "rating_q025": 1337.6650111323877
        },
        "nvidia-llama-3.3-nemotron-super-49b-v1.5": {
            "rating": 1343.2481229781442,
            "rating_q975": 1364.0750342211331,
            "rating_q025": 1322.4212117351553
        },
        "qwq-32b": {
            "rating": 1340.2589002541488,
            "rating_q975": 1348.468249536075,
            "rating_q025": 1332.0495509722225
        },
        "gpt-5-nano-high": {
            "rating": 1338.3322804258546,
            "rating_q975": 1351.9091860582873,
            "rating_q025": 1324.7553747934219
        },
        "llama-3.3-nemotron-49b-super-v1": {
            "rating": 1337.5807343867605,
            "rating_q975": 1367.0854481624779,
            "rating_q025": 1308.076020611043
        },
        "hunyuan-turbos-20250226": {
            "rating": 1335.5033961181994,
            "rating_q975": 1363.6999812075157,
            "rating_q025": 1307.306811028883
        },
        "llama-3.1-nemotron-ultra-253b-v1": {
            "rating": 1335.1838445668052,
            "rating_q975": 1362.1297353702646,
            "rating_q025": 1308.2379537633458
        },
        "command-a-03-2025": {
            "rating": 1334.3389596919274,
            "rating_q975": 1340.5093795748917,
            "rating_q025": 1328.168539808963
        },
        "qwen-plus-0125": {
            "rating": 1333.4993138988377,
            "rating_q975": 1350.8461555474357,
            "rating_q025": 1316.1524722502397
        },
        "qwen3-30b-a3b": {
            "rating": 1330.8193011377302,
            "rating_q975": 1339.0120224308905,
            "rating_q025": 1322.62657984457
        },
        "gemini-2.0-flash-lite-preview-02-05": {
            "rating": 1329.9360813601409,
            "rating_q975": 1338.708486829486,
            "rating_q025": 1321.1636758907957
        },
        "hunyuan-turbo-0110": {
            "rating": 1324.9179525197953,
            "rating_q975": 1352.7557175766406,
            "rating_q025": 1297.08018746295
        },
        "deepseek-v3": {
            "rating": 1323.761386920965,
            "rating_q975": 1333.1700009232711,
            "rating_q025": 1314.3527729186587
        },
        "yi-lightning": {
            "rating": 1322.5730776966616,
            "rating_q975": 1332.154355395675,
            "rating_q025": 1312.991799997648
        },
        "qwen2.5-plus-1127": {
            "rating": 1318.7575275351703,
            "rating_q975": 1331.6069446718066,
            "rating_q025": 1305.908110398534
        },
        "gemma-3-12b-it": {
            "rating": 1317.9317157106682,
            "rating_q975": 1338.7162178804895,
            "rating_q025": 1297.147213540847
        },
        "claude-3-5-sonnet-20241022": {
            "rating": 1313.8230207431184,
            "rating_q975": 1318.8263703174096,
            "rating_q025": 1308.8196711688272
        },
        "step-2-16k-exp-202412": {
            "rating": 1308.5801340594746,
            "rating_q975": 1327.1733747988255,
            "rating_q025": 1289.9868933201237
        },
        "athene-v2-chat": {
            "rating": 1304.282934253642,
            "rating_q975": 1313.103445842293,
            "rating_q025": 1295.462422664991
        },
        "deepseek-v2.5-1210": {
            "rating": 1300.4210751937878,
            "rating_q975": 1316.6905521688582,
            "rating_q025": 1284.1515982187175
        },
        "gemini-1.5-pro-002": {
            "rating": 1299.559941259905,
            "rating_q975": 1305.9615900782085,
            "rating_q025": 1293.1582924416014
        },
        "llama-4-maverick-17b-128e-instruct": {
            "rating": 1298.1305113508565,
            "rating_q975": 1305.2270895046727,
            "rating_q025": 1291.0339331970404
        },
        "mistral-small-3.1-24b-instruct-2503": {
            "rating": 1296.460023699558,
            "rating_q975": 1303.9182669929667,
            "rating_q025": 1289.0017804061492
        },
        "hunyuan-large-2025-02-10": {
            "rating": 1294.9799881444048,
            "rating_q975": 1317.6817771573078,
            "rating_q025": 1272.2781991315019
        },
        "gpt-oss-20b": {
            "rating": 1294.6987098162892,
            "rating_q975": 1307.2400426006652,
            "rating_q025": 1282.1573770319133
        },
        "gemma-3n-e4b-it": {
            "rating": 1293.5395308421362,
            "rating_q975": 1302.6832382652017,
            "rating_q025": 1284.3958234190707
        },
        "gpt-4o-2024-05-13": {
            "rating": 1293.1321381421465,
            "rating_q975": 1299.1814177346932,
            "rating_q025": 1287.0828585495997
        },
        "glm-4-plus-0111": {
            "rating": 1292.375801687132,
            "rating_q975": 1309.905739673648,
            "rating_q025": 1274.845863700616
        },
        "gpt-4.1-nano-2025-04-14": {
            "rating": 1291.9603194872689,
            "rating_q975": 1309.1269477279536,
            "rating_q025": 1274.793691246584
        },
        "llama-3.1-405b-instruct-bf16": {
            "rating": 1291.7658463655348,
            "rating_q975": 1298.7274186608533,
            "rating_q025": 1284.8042740702163
        },
        "llama-4-scout-17b-16e-instruct": {
            "rating": 1290.9122221448415,
            "rating_q975": 1298.792059887144,
            "rating_q025": 1283.032384402539
        },
        "magistral-medium-2506": {
            "rating": 1287.9416112243973,
            "rating_q975": 1299.6561074249264,
            "rating_q025": 1276.2271150238682
        },
        "llama-3.1-405b-instruct-fp8": {
            "rating": 1284.0482211071771,
            "rating_q975": 1290.7712103235228,
            "rating_q025": 1277.3252318908314
        },
        "claude-3-5-sonnet-20240620": {
            "rating": 1283.1639415820136,
            "rating_q975": 1289.6746964609652,
            "rating_q025": 1276.6531867030621
        },
        "llama-3.1-nemotron-70b-instruct": {
            "rating": 1282.9443288127827,
            "rating_q975": 1299.509258275441,
            "rating_q025": 1266.3793993501245
        },
        "qwen-max-0919": {
            "rating": 1281.3820899968532,
            "rating_q975": 1292.5058978665904,
            "rating_q025": 1270.258282127116
        },
        "deepseek-v2.5": {
            "rating": 1280.6023698665038,
            "rating_q975": 1289.64966009306,
            "rating_q025": 1271.5550796399475
        },
        "grok-2-2024-08-13": {
            "rating": 1280.5721314445468,
            "rating_q975": 1287.0004250383734,
            "rating_q025": 1274.1438378507203
        },
        "qwen2.5-72b-instruct": {
            "rating": 1280.0756082526382,
            "rating_q975": 1287.5522876983664,
            "rating_q025": 1272.59892880691
        },
        "glm-4-plus": {
            "rating": 1280.0685728667142,
            "rating_q975": 1289.401644314239,
            "rating_q025": 1270.7355014191894
        },
        "hunyuan-large-vision": {
            "rating": 1279.4379399481595,
            "rating_q975": 1296.4783093928793,
            "rating_q025": 1262.3975705034397
        },
        "gpt-4o-mini-2024-07-18": {
            "rating": 1278.7620833848903,
            "rating_q975": 1284.7698602856635,
            "rating_q025": 1272.754306484117
        },
        "llama-3.3-70b-instruct": {
            "rating": 1278.1062320544652,
            "rating_q975": 1284.023001826366,
            "rating_q025": 1272.1894622825644
        },
        "gpt-4o-2024-08-06": {
            "rating": 1277.550438771623,
            "rating_q975": 1284.9514093567507,
            "rating_q025": 1270.1494681864954
        },
        "hunyuan-standard-2025-02-10": {
            "rating": 1275.6863795959762,
            "rating_q975": 1299.0938591125514,
            "rating_q025": 1252.278900079401
        },
        "mistral-large-2407": {
            "rating": 1270.31058829694,
            "rating_q975": 1277.6839702344816,
            "rating_q025": 1262.9372063593985
        },
        "qwen2.5-coder-32b-instruct": {
            "rating": 1269.9100067945196,
            "rating_q975": 1289.3780143085396,
            "rating_q025": 1250.4419992804997
        },
        "mistral-large-2411": {
            "rating": 1268.3985604999634,
            "rating_q975": 1276.7476161678892,
            "rating_q025": 1260.0495048320377
        },
        "grok-2-mini-2024-08-13": {
            "rating": 1268.1132085437407,
            "rating_q975": 1274.8816634298348,
            "rating_q025": 1261.3447536576466
        },
        "gpt-4-turbo-2024-04-09": {
            "rating": 1266.8213011295927,
            "rating_q975": 1273.5108903169278,
            "rating_q025": 1260.1317119422577
        },
        "claude-3-5-haiku-20241022": {
            "rating": 1266.591157923027,
            "rating_q975": 1272.1846358396742,
            "rating_q025": 1260.9976800063796
        },
        "gemini-1.5-flash-002": {
            "rating": 1265.4368182630437,
            "rating_q975": 1273.3303102607747,
            "rating_q025": 1257.5433262653128
        },
        "llama-3.1-70b-instruct": {
            "rating": 1261.9648302094297,
            "rating_q975": 1268.7587788568374,
            "rating_q025": 1255.170881562022
        },
        "gemini-1.5-pro-001": {
            "rating": 1259.2198452569155,
            "rating_q975": 1266.1617172300737,
            "rating_q025": 1252.2779732837573
        },
        "amazon-nova-pro-v1.0": {
            "rating": 1258.7135671413303,
            "rating_q975": 1267.3218113867815,
            "rating_q025": 1250.105322895879
        },
        "athene-70b-0725": {
            "rating": 1255.3385660058834,
            "rating_q975": 1265.2186018827924,
            "rating_q025": 1245.4585301289744
        },
        "gpt-4-1106-preview": {
            "rating": 1254.504353000777,
            "rating_q975": 1261.3382611886475,
            "rating_q025": 1247.6704448129065
        },
        "gemma-3-4b-it": {
            "rating": 1252.4224035218012,
            "rating_q975": 1273.0388599902767,
            "rating_q025": 1231.8059470533258
        },
        "gpt-4-0125-preview": {
            "rating": 1251.944775281496,
            "rating_q975": 1258.9334363995695,
            "rating_q025": 1244.9561141634226
        },
        "gemini-advanced-0514": {
            "rating": 1250.5809504389972,
            "rating_q975": 1259.0874400909734,
            "rating_q025": 1242.074460787021
        },
        "olmo-2-0325-32b-instruct": {
            "rating": 1244.8828052915405,
            "rating_q975": 1268.8386117370505,
            "rating_q025": 1220.9269988460305
        },
        "claude-3-opus-20240229": {
            "rating": 1243.7388801764928,
            "rating_q975": 1249.1536834754957,
            "rating_q025": 1238.32407687749
        },
        "mistral-small-24b-instruct-2501": {
            "rating": 1242.7218142096376,
            "rating_q975": 1254.3677505280202,
            "rating_q025": 1231.075877891255
        },
        "llama-3.1-tulu-3-70b": {
            "rating": 1237.4218714344288,
            "rating_q975": 1261.0106377814227,
            "rating_q025": 1213.833105087435
        },
        "jamba-1.5-large": {
            "rating": 1232.3591569523214,
            "rating_q975": 1246.1579057671129,
            "rating_q025": 1218.56040813753
        },
        "llama-3-70b-instruct": {
            "rating": 1231.1887610419699,
            "rating_q975": 1237.6345193989205,
            "rating_q025": 1224.7430026850193
        },
        "phi-4": {
            "rating": 1230.6498257754392,
            "rating_q975": 1239.8663772813104,
            "rating_q025": 1221.433274269568
        },
        "hunyuan-standard-256k": {
            "rating": 1228.8638764734671,
            "rating_q975": 1257.250935130776,
            "rating_q025": 1200.4768178161582
        },
        "amazon-nova-lite-v1.0": {
            "rating": 1226.1519856119476,
            "rating_q975": 1236.1637820867013,
            "rating_q025": 1216.1401891371938
        },
        "gemini-1.5-flash-001": {
            "rating": 1225.26282664598,
            "rating_q975": 1232.3734750750943,
            "rating_q025": 1218.1521782168659
        },
        "glm-4-0520": {
            "rating": 1218.5348064471086,
            "rating_q975": 1231.9705325261853,
            "rating_q025": 1205.099080368032
        },
        "deepseek-coder-v2": {
            "rating": 1217.7790795412213,
            "rating_q975": 1229.5823577272524,
            "rating_q025": 1205.9758013551902
        },
        "reka-core-20240904": {
            "rating": 1216.1182799534322,
            "rating_q975": 1230.2412193444075,
            "rating_q025": 1201.995340562457
        },
        "gemini-1.5-flash-8b-001": {
            "rating": 1214.8407187297694,
            "rating_q975": 1222.7733452989464,
            "rating_q025": 1206.9080921605923
        },
        "gpt-4-0314": {
            "rating": 1208.7752633210703,
            "rating_q975": 1217.4682109580353,
            "rating_q025": 1200.0823156841052
        },
        "ministral-8b-2410": {
            "rating": 1206.994176960284,
            "rating_q975": 1227.1502144234,
            "rating_q025": 1186.838139497168
        },
        "gemma-2-27b-it": {
            "rating": 1206.5413667075773,
            "rating_q975": 1212.465000826095,
            "rating_q025": 1200.6177325890594
        },
        "qwen2-72b-instruct": {
            "rating": 1206.2340025042108,
            "rating_q975": 1214.719025495336,
            "rating_q025": 1197.7489795130857
        },
        "llama-3.1-nemotron-51b-instruct": {
            "rating": 1205.8483685975261,
            "rating_q975": 1228.3609367642132,
            "rating_q025": 1183.335800430839
        },
        "amazon-nova-micro-v1.0": {
            "rating": 1204.4822778325265,
            "rating_q975": 1214.3961967366497,
            "rating_q025": 1194.5683589284033
        },
        "claude-3-sonnet-20240229": {
            "rating": 1202.8655149332212,
            "rating_q975": 1209.8686060553257,
            "rating_q025": 1195.8624238111167
        },
        "nemotron-4-340b-instruct": {
            "rating": 1202.460920244582,
            "rating_q975": 1213.322518555232,
            "rating_q025": 1191.599321933932
        },
        "gemma-2-9b-it-simpo": {
            "rating": 1201.94283910996,
            "rating_q975": 1215.5888453665427,
            "rating_q025": 1188.2968328533773
        },
        "llama-3.1-8b-instruct": {
            "rating": 1196.5546102194219,
            "rating_q975": 1203.768377800876,
            "rating_q025": 1189.3408426379679
        },
        "c4ai-aya-expanse-32b": {
            "rating": 1196.51191341102,
            "rating_q975": 1205.516727788872,
            "rating_q025": 1187.507099033168
        },
        "command-r-plus-08-2024": {
            "rating": 1195.4501733707955,
            "rating_q975": 1208.5346773019696,
            "rating_q025": 1182.3656694396213
        },
        "internlm2_5-20b-chat": {
            "rating": 1190.077709567007,
            "rating_q975": 1204.45053682896,
            "rating_q025": 1175.7048823050543
        },
        "gpt-4-0613": {
            "rating": 1188.9200677566373,
            "rating_q975": 1196.2905784814177,
            "rating_q025": 1181.549557031857
        },
        "reka-flash-20240904": {
            "rating": 1186.7339459837233,
            "rating_q975": 1200.5232649897423,
            "rating_q025": 1172.9446269777043
        },
        "qwen1.5-110b-chat": {
            "rating": 1185.6121478015666,
            "rating_q975": 1195.8811653047696,
            "rating_q025": 1175.3431302983636
        },
        "jamba-1.5-mini": {
            "rating": 1182.5879202548967,
            "rating_q975": 1196.7523536272352,
            "rating_q025": 1168.4234868825583
        },
        "claude-3-haiku-20240307": {
            "rating": 1182.0571405832688,
            "rating_q975": 1188.4565905053275,
            "rating_q025": 1175.6576906612102
        },
        "yi-1.5-34b-chat": {
            "rating": 1180.0010589209787,
            "rating_q975": 1189.897068597008,
            "rating_q025": 1170.1050492449494
        },
        "llama-3.1-tulu-3-8b": {
            "rating": 1179.10741077495,
            "rating_q975": 1204.7628907713854,
            "rating_q025": 1153.4519307785147
        },
        "mistral-large-2402": {
            "rating": 1178.8275891054568,
            "rating_q975": 1186.9103827458302,
            "rating_q025": 1170.7447954650834
        },
        "gemma-2-9b-it": {
            "rating": 1178.3339279293086,
            "rating_q975": 1185.1420139069965,
            "rating_q025": 1171.5258419516208
        },
        "command-r-08-2024": {
            "rating": 1172.3690026161848,
            "rating_q975": 1185.0991621763403,
            "rating_q025": 1159.6388430560294
        },
        "command-r-plus": {
            "rating": 1172.08278499295,
            "rating_q975": 1179.481664827086,
            "rating_q025": 1164.6839051588142
        },
        "qwq-32b-preview": {
            "rating": 1171.4619665396801,
            "rating_q975": 1196.2674469199628,
            "rating_q025": 1146.6564861593974
        },
        "granite-3.1-8b-instruct": {
            "rating": 1166.0125926234382,
            "rating_q975": 1190.041825984612,
            "rating_q025": 1141.9833592622645
        },
        "llama-3-8b-instruct": {
            "rating": 1164.4280492403434,
            "rating_q975": 1171.3749042502632,
            "rating_q025": 1157.4811942304236
        },
        "mixtral-8x22b-instruct-v0.1": {
            "rating": 1163.831782543773,
            "rating_q975": 1171.8759290143603,
            "rating_q025": 1155.7876360731857
        },
        "qwen1.5-72b-chat": {
            "rating": 1163.0282132459042,
            "rating_q975": 1171.7878016689194,
            "rating_q025": 1154.268624822889
        },
        "mistral-medium": {
            "rating": 1158.7586305809334,
            "rating_q975": 1168.4041286095792,
            "rating_q025": 1149.1131325522877
        },
        "granite-3.1-2b-instruct": {
            "rating": 1156.6323466112842,
            "rating_q975": 1181.2600891339484,
            "rating_q025": 1132.00460408862
        },
        "c4ai-aya-expanse-8b": {
            "rating": 1155.4830351976052,
            "rating_q975": 1169.7224177258834,
            "rating_q025": 1141.243652669327
        },
        "reka-flash-21b-20240226-online": {
            "rating": 1148.182746862983,
            "rating_q975": 1160.6484047405863,
            "rating_q025": 1135.7170889853799
        },
        "qwen1.5-32b-chat": {
            "rating": 1147.5954662660843,
            "rating_q975": 1158.5241992087088,
            "rating_q025": 1136.6667333234598
        },
        "reka-flash-21b-20240226": {
            "rating": 1145.1421533336897,
            "rating_q975": 1155.4677687340454,
            "rating_q025": 1134.816537933334
        },
        "phi-3-medium-4k-instruct": {
            "rating": 1143.0915671844268,
            "rating_q975": 1152.7176632612538,
            "rating_q025": 1133.4654711075998
        },
        "llama-3.2-3b-instruct": {
            "rating": 1142.2573274887184,
            "rating_q975": 1157.1318692010586,
            "rating_q025": 1127.3827857763781
        },
        "dbrx-instruct-preview": {
            "rating": 1138.6223350670912,
            "rating_q975": 1149.229238117399,
            "rating_q025": 1128.0154320167833
        },
        "mixtral-8x7b-instruct-v0.1": {
            "rating": 1135.7326872482734,
            "rating_q975": 1143.2824656172554,
            "rating_q025": 1128.1829088792913
        },
        "zephyr-orpo-141b-A35b-v0.1": {
            "rating": 1134.5584054452402,
            "rating_q975": 1154.921542557011,
            "rating_q025": 1114.1952683334694
        },
        "starling-lm-7b-beta": {
            "rating": 1131.6015446817323,
            "rating_q975": 1144.1573874156386,
            "rating_q025": 1119.045701947826
        },
        "gemma-2-2b-it": {
            "rating": 1128.6598150061213,
            "rating_q975": 1136.0935200434421,
            "rating_q025": 1121.2261099688005
        },
        "phi-3-small-8k-instruct": {
            "rating": 1125.9331352114189,
            "rating_q975": 1137.390252175108,
            "rating_q025": 1114.4760182477298
        },
        "tulu-2-dpo-70b": {
            "rating": 1125.1120686645506,
            "rating_q975": 1142.626745147738,
            "rating_q025": 1107.5973921813634
        },
        "qwen1.5-14b-chat": {
            "rating": 1124.4019620257143,
            "rating_q975": 1136.932217710237,
            "rating_q025": 1111.8717063411916
        },
        "command-r": {
            "rating": 1123.2817840087305,
            "rating_q975": 1131.7271784352677,
            "rating_q025": 1114.8363895821933
        },
        "granite-3.0-8b-instruct": {
            "rating": 1122.8566648057013,
            "rating_q975": 1142.3626487735708,
            "rating_q025": 1103.3506808378318
        },
        "gpt-3.5-turbo-0125": {
            "rating": 1122.5582890501792,
            "rating_q975": 1130.0791345578084,
            "rating_q025": 1115.03744354255
        },
        "yi-34b-chat": {
            "rating": 1120.522418212544,
            "rating_q975": 1132.440708874783,
            "rating_q025": 1108.6041275503048
        },
        "gemini-pro-dev-api": {
            "rating": 1117.5577947850063,
            "rating_q975": 1130.0664111134513,
            "rating_q025": 1105.0491784565613
        },
        "phi-3-mini-4k-instruct-june-2024": {
            "rating": 1115.0597187278483,
            "rating_q975": 1127.8671037471884,
            "rating_q025": 1102.2523337085083
        },
        "gpt-3.5-turbo-1106": {
            "rating": 1114.5827930833825,
            "rating_q975": 1128.4318295415142,
            "rating_q025": 1100.7337566252509
        },
        "gemini-pro": {
            "rating": 1111.1529187061785,
            "rating_q975": 1130.1745740305971,
            "rating_q025": 1092.13126338176
        },
        "wizardlm-70b": {
            "rating": 1096.7269341948618,
            "rating_q975": 1113.1255656240073,
            "rating_q025": 1080.3283027657162
        },
        "phi-3-mini-4k-instruct": {
            "rating": 1096.0100660983276,
            "rating_q975": 1107.3953160589258,
            "rating_q025": 1084.6248161377293
        },
        "starling-lm-7b-alpha": {
            "rating": 1095.9152520230307,
            "rating_q975": 1109.9797522310907,
            "rating_q025": 1081.8507518149706
        },
        "openchat-3.5-0106": {
            "rating": 1095.6219573532544,
            "rating_q975": 1107.9389156367815,
            "rating_q025": 1083.3049990697273
        },
        "llama-2-70b-chat": {
            "rating": 1092.0892504779854,
            "rating_q975": 1101.1807215349686,
            "rating_q025": 1082.9977794210022
        },
        "gemma-1.1-7b-it": {
            "rating": 1091.5394722834692,
            "rating_q975": 1101.7071621555717,
            "rating_q025": 1081.3717824113667
        },
        "mistral-7b-instruct-v0.2": {
            "rating": 1090.4452729192567,
            "rating_q975": 1101.3693497803615,
            "rating_q025": 1079.5211960581519
        },
        "snowflake-arctic-instruct": {
            "rating": 1089.3788832809664,
            "rating_q975": 1100.041881439016,
            "rating_q025": 1078.715885122917
        },
        "granite-3.0-2b-instruct": {
            "rating": 1087.786670766938,
            "rating_q975": 1107.0961258956822,
            "rating_q025": 1068.4772156381937
        },
        "llama-3.2-1b-instruct": {
            "rating": 1087.5000265877652,
            "rating_q975": 1102.402610665499,
            "rating_q025": 1072.5974425100314
        },
        "openhermes-2.5-mistral-7b": {
            "rating": 1087.2028084210122,
            "rating_q975": 1105.9020659108874,
            "rating_q025": 1068.503550931137
        },
        "deepseek-llm-67b-chat": {
            "rating": 1086.2626926123262,
            "rating_q975": 1106.4084113296244,
            "rating_q025": 1066.116973895028
        },
        "mpt-30b-chat": {
            "rating": 1082.0058967369448,
            "rating_q975": 1112.4637070090253,
            "rating_q025": 1051.5480864648644
        },
        "vicuna-33b": {
            "rating": 1080.1508402869915,
            "rating_q975": 1091.328374893525,
            "rating_q025": 1068.973305680458
        },
        "solar-10.7b-instruct-v1.0": {
            "rating": 1076.8576249774992,
            "rating_q975": 1098.511485898068,
            "rating_q025": 1055.2037640569304
        },
        "qwen1.5-7b-chat": {
            "rating": 1075.9534436320669,
            "rating_q975": 1093.4325341004717,
            "rating_q025": 1058.474353163662
        },
        "codellama-70b-instruct": {
            "rating": 1075.7910468472637,
            "rating_q975": 1113.7460982049777,
            "rating_q025": 1037.8359954895498
        },
        "smollm2-1.7b-instruct": {
            "rating": 1073.7870955202138,
            "rating_q975": 1106.3445233599018,
            "rating_q025": 1041.2296676805258
        },
        "llama-2-13b-chat": {
            "rating": 1073.5527201788695,
            "rating_q975": 1085.3397314120048,
            "rating_q025": 1061.7657089457343
        },
        "openchat-3.5": {
            "rating": 1071.6524506780238,
            "rating_q975": 1088.472039168499,
            "rating_q025": 1054.8328621875487
        },
        "dolphin-2.2.1-mistral-7b": {
            "rating": 1068.8468723482385,
            "rating_q975": 1100.843578101916,
            "rating_q025": 1036.8501665945612
        },
        "nous-hermes-2-mixtral-8x7b-dpo": {
            "rating": 1067.0360611443316,
            "rating_q975": 1085.655077563622,
            "rating_q025": 1048.4170447250413
        },
        "gemma-7b-it": {
            "rating": 1061.4249963656189,
            "rating_q975": 1076.6439936762413,
            "rating_q025": 1046.2059990549965
        },
        "llama2-70b-steerlm-chat": {
            "rating": 1057.053827611662,
            "rating_q975": 1080.1618111585967,
            "rating_q025": 1033.9458440647272
        },
        "phi-3-mini-128k-instruct": {
            "rating": 1051.9446036844577,
            "rating_q975": 1064.2848191241542,
            "rating_q025": 1039.6043882447611
        },
        "zephyr-7b-beta": {
            "rating": 1048.0401991879091,
            "rating_q975": 1063.520230023829,
            "rating_q025": 1032.5601683519892
        },
        "codellama-34b-instruct": {
            "rating": 1047.2221418685829,
            "rating_q975": 1063.2839322240568,
            "rating_q025": 1031.160351513109
        },
        "zephyr-7b-alpha": {
            "rating": 1043.966162933976,
            "rating_q975": 1077.5583882036399,
            "rating_q025": 1010.3739376643119
        },
        "qwen-14b-chat": {
            "rating": 1041.0399743060036,
            "rating_q975": 1061.6482680635097,
            "rating_q025": 1020.4316805484974
        },
        "vicuna-13b": {
            "rating": 1036.1107153946564,
            "rating_q975": 1048.0917600593962,
            "rating_q025": 1024.1296707299166
        },
        "palm-2": {
            "rating": 1035.362197556131,
            "rating_q975": 1052.045983040014,
            "rating_q025": 1018.6784120722477
        },
        "wizardlm-13b": {
            "rating": 1034.174629451683,
            "rating_q975": 1052.587104858071,
            "rating_q025": 1015.7621540452949
        },
        "llama-2-7b-chat": {
            "rating": 1032.22478227362,
            "rating_q975": 1044.583609587793,
            "rating_q025": 1019.8659549594468
        },
        "gemma-1.1-2b-it": {
            "rating": 1026.2071742383084,
            "rating_q975": 1040.5209413056314,
            "rating_q025": 1011.8934071709855
        },
        "mistral-7b-instruct": {
            "rating": 1022.5048660304335,
            "rating_q975": 1039.0033982809055,
            "rating_q025": 1006.0063337799617
        },
        "guanaco-33b": {
            "rating": 1019.3969597224229,
            "rating_q975": 1047.7840277875973,
            "rating_q025": 991.0098916572485
        },
        "stripedhyena-nous-7b": {
            "rating": 1015.7301863330224,
            "rating_q975": 1033.920885072119,
            "rating_q025": 997.5394875939257
        },
        "olmo-7b-instruct": {
            "rating": 1011.8372514358616,
            "rating_q975": 1030.5673094871393,
            "rating_q025": 993.107193384584
        },
        "vicuna-7b": {
            "rating": 1004.3953212568782,
            "rating_q975": 1023.0533054375278,
            "rating_q025": 985.7373370762286
        },
        "gemma-2b-it": {
            "rating": 997.0506928906941,
            "rating_q975": 1017.2575032735347,
            "rating_q025": 976.8438825078536
        },
        "qwen1.5-4b-chat": {
            "rating": 983.5149937426936,
            "rating_q975": 999.5738971277424,
            "rating_q025": 967.4560903576448
        },
        "chatglm3-6b": {
            "rating": 977.2643866779938,
            "rating_q975": 998.8770693469128,
            "rating_q025": 955.6517040090748
        },
        "gpt4all-13b-snoozy": {
            "rating": 955.3275246525502,
            "rating_q975": 989.5951786374231,
            "rating_q025": 921.0598706676773
        },
        "koala-13b": {
            "rating": 942.9046382852109,
            "rating_q975": 962.8240009787127,
            "rating_q025": 922.9852755917092
        },
        "chatglm2-6b": {
            "rating": 938.1274008972903,
            "rating_q975": 967.6047209990343,
            "rating_q025": 908.6500807955463
        },
        "mpt-7b-chat": {
            "rating": 908.2007084794091,
            "rating_q975": 932.7318562160183,
            "rating_q025": 883.6695607427998
        },
        "RWKV-4-Raven-14B": {
            "rating": 900.7658668849222,
            "rating_q975": 923.2344257944092,
            "rating_q025": 878.2973079754352
        },
        "oasst-pythia-12b": {
            "rating": 897.2944190864328,
            "rating_q975": 918.2336728956989,
            "rating_q025": 876.3551652771666
        },
        "chatglm-6b": {
            "rating": 896.0445264213986,
            "rating_q975": 919.7413522497594,
            "rating_q025": 872.3477005930378
        },
        "stablelm-tuned-alpha-7b": {
            "rating": 848.8539785951052,
            "rating_q975": 876.5356287548631,
            "rating_q025": 821.1723284353474
        },
        "alpaca-13b": {
            "rating": 839.0031490487513,
            "rating_q975": 860.8716599867189,
            "rating_q025": 817.1346381107837
        },
        "fastchat-t5-3b": {
            "rating": 829.4360965964081,
            "rating_q975": 852.8822636510146,
            "rating_q025": 805.9899295418016
        },
        "dolly-v2-12b": {
            "rating": 808.8284475843066,
            "rating_q975": 836.0489517648161,
            "rating_q025": 781.607943403797
        },
        "llama-13b": {
            "rating": 733.9670633219182,
            "rating_q975": 768.2573815560244,
            "rating_q025": 699.676745087812
        }
    },
    "if": {
        "claude-sonnet-4-5-20250929-thinking-32k": {
            "rating": 1450.6157401834218,
            "rating_q975": 1461.0796684493948,
            "rating_q025": 1440.1518119174489
        },
        "gemini-2.5-pro": {
            "rating": 1440.7889524388213,
            "rating_q975": 1446.8546845840408,
            "rating_q025": 1434.7232202936018
        },
        "claude-opus-4-1-20250805-thinking-16k": {
            "rating": 1438.938048240358,
            "rating_q975": 1446.648880829588,
            "rating_q025": 1431.227215651128
        },
        "claude-sonnet-4-5-20250929": {
            "rating": 1431.5010478757258,
            "rating_q975": 1445.3976392568902,
            "rating_q025": 1417.6044564945614
        },
        "claude-opus-4-1-20250805": {
            "rating": 1428.744534931532,
            "rating_q975": 1435.6805485475118,
            "rating_q025": 1421.808521315552
        },
        "glm-4.6": {
            "rating": 1422.2794277227956,
            "rating_q975": 1433.4238006676956,
            "rating_q025": 1411.1350547778957
        },
        "qwen3-max-preview": {
            "rating": 1420.3369007656056,
            "rating_q975": 1428.2337335593138,
            "rating_q025": 1412.4400679718974
        },
        "claude-haiku-4-5-20251001": {
            "rating": 1414.4470103160747,
            "rating_q975": 1425.4549019863025,
            "rating_q025": 1403.439118645847
        },
        "grok-3-preview-02-24": {
            "rating": 1407.2013256895848,
            "rating_q975": 1413.6435248822531,
            "rating_q025": 1400.7591264969165
        },
        "qwen3-235b-a22b-instruct-2507": {
            "rating": 1406.7005007617513,
            "rating_q975": 1413.602060483227,
            "rating_q025": 1399.7989410402756
        },
        "qwen3-vl-235b-a22b-instruct": {
            "rating": 1405.9371259530071,
            "rating_q975": 1417.7395185852847,
            "rating_q025": 1394.1347333207295
        },
        "claude-opus-4-20250514-thinking-16k": {
            "rating": 1404.3456663099955,
            "rating_q975": 1411.2961080596422,
            "rating_q025": 1397.3952245603489
        },
        "glm-4.5": {
            "rating": 1403.5631290909885,
            "rating_q975": 1411.5012404019096,
            "rating_q025": 1395.6250177800673
        },
        "gemini-2.5-flash": {
            "rating": 1403.4508097488447,
            "rating_q975": 1409.3465031779065,
            "rating_q025": 1397.5551163197829
        },
        "gpt-4.5-preview-2025-02-27": {
            "rating": 1401.847734604829,
            "rating_q975": 1410.0119932234388,
            "rating_q025": 1393.683475986219
        },
        "deepseek-v3.1-thinking": {
            "rating": 1400.6807566097643,
            "rating_q975": 1411.8400907555197,
            "rating_q025": 1389.521422464009
        },
        "mistral-medium-2508": {
            "rating": 1399.6943581760138,
            "rating_q975": 1407.0288196094118,
            "rating_q025": 1392.3598967426158
        },
        "deepseek-v3.1-terminus-thinking": {
            "rating": 1398.3669019232996,
            "rating_q975": 1418.4512145629615,
            "rating_q025": 1378.2825892836377
        },
        "deepseek-v3.2-exp-thinking": {
            "rating": 1397.7740943824772,
            "rating_q975": 1409.310933007203,
            "rating_q025": 1386.2372557577514
        },
        "qwen3-max-2025-09-23": {
            "rating": 1397.6395081469293,
            "rating_q975": 1409.0072113047804,
            "rating_q025": 1386.2718049890782
        },
        "gemini-2.5-flash-preview-09-2025": {
            "rating": 1397.6205159029755,
            "rating_q975": 1407.188729920201,
            "rating_q025": 1388.05230188575
        },
        "longcat-flash-chat": {
            "rating": 1395.5688458688371,
            "rating_q975": 1406.3175003837503,
            "rating_q025": 1384.820191353924
        },
        "chatgpt-4o-latest-20250326": {
            "rating": 1395.1917019924053,
            "rating_q975": 1400.981226412853,
            "rating_q025": 1389.4021775719577
        },
        "grok-4-fast": {
            "rating": 1391.6150939743286,
            "rating_q975": 1406.0384616802291,
            "rating_q025": 1377.191726268428
        },
        "gpt-5-high": {
            "rating": 1389.5491747228523,
            "rating_q975": 1397.084813210576,
            "rating_q025": 1382.0135362351286
        },
        "deepseek-v3.1": {
            "rating": 1388.593112729921,
            "rating_q975": 1398.4596151712383,
            "rating_q025": 1378.7266102886035
        },
        "qwen3-235b-a22b-thinking-2507": {
            "rating": 1388.3745837402184,
            "rating_q975": 1400.8133868976404,
            "rating_q025": 1375.9357805827965
        },
        "qwen3-next-80b-a3b-instruct": {
            "rating": 1387.8066351818095,
            "rating_q975": 1396.163384576619,
            "rating_q025": 1379.449885787
        },
        "grok-4-0709": {
            "rating": 1385.7446255170037,
            "rating_q975": 1392.5094020239212,
            "rating_q025": 1378.9798490100861
        },
        "gpt-5-chat": {
            "rating": 1381.3086035844137,
            "rating_q975": 1388.7267646267924,
            "rating_q025": 1373.890442542035
        },
        "deepseek-r1-0528": {
            "rating": 1379.2873802311024,
            "rating_q975": 1388.7265204881303,
            "rating_q025": 1369.8482399740744
        },
        "deepseek-v3.1-terminus": {
            "rating": 1379.196200108697,
            "rating_q975": 1397.2310594010582,
            "rating_q025": 1361.1613408163357
        },
        "hunyuan-t1-20250711": {
            "rating": 1374.090280712535,
            "rating_q975": 1391.6976398130857,
            "rating_q025": 1356.4829216119845
        },
        "claude-sonnet-4-20250514-thinking-32k": {
            "rating": 1373.938603500096,
            "rating_q975": 1380.9828314224574,
            "rating_q025": 1366.8943755777345
        },
        "qwen3-vl-235b-a22b-thinking": {
            "rating": 1371.4502576176062,
            "rating_q975": 1383.8545191293745,
            "rating_q025": 1359.045996105838
        },
        "claude-opus-4-20250514": {
            "rating": 1370.3553881157438,
            "rating_q975": 1376.897444786609,
            "rating_q025": 1363.8133314448787
        },
        "o3-2025-04-16": {
            "rating": 1368.9141428088785,
            "rating_q975": 1374.6964356115193,
            "rating_q025": 1363.1318500062378
        },
        "gemini-2.5-flash-lite-preview-06-17-thinking": {
            "rating": 1365.5210335536963,
            "rating_q975": 1372.511278881147,
            "rating_q025": 1358.5307882262455
        },
        "gpt-4.1-2025-04-14": {
            "rating": 1364.4691092119344,
            "rating_q975": 1370.4400905838702,
            "rating_q025": 1358.4981278399987
        },
        "o1-2024-12-17": {
            "rating": 1364.3470378312047,
            "rating_q975": 1370.647648187796,
            "rating_q025": 1358.0464274746134
        },
        "qwen3-30b-a3b-instruct-2507": {
            "rating": 1361.336483919924,
            "rating_q975": 1369.2890414663493,
            "rating_q025": 1353.3839263734985
        },
        "gemini-2.5-flash-lite-preview-09-2025-no-thinking": {
            "rating": 1359.7544218648452,
            "rating_q975": 1369.1529646016031,
            "rating_q025": 1350.3558791280873
        },
        "qwen3-235b-a22b-no-thinking": {
            "rating": 1358.3355213644159,
            "rating_q975": 1365.1198416814461,
            "rating_q025": 1351.5512010473856
        },
        "gpt-5-mini-high": {
            "rating": 1357.6098816761469,
            "rating_q975": 1365.6764296982394,
            "rating_q025": 1349.5433336540543
        },
        "mai-1-preview": {
            "rating": 1356.8075439601082,
            "rating_q975": 1366.032851535735,
            "rating_q025": 1347.5822363844813
        },
        "deepseek-r1": {
            "rating": 1354.974071695915,
            "rating_q975": 1362.2599270042313,
            "rating_q025": 1347.6882163875987
        },
        "qwen3-coder-480b-a35b-instruct": {
            "rating": 1353.8852785280574,
            "rating_q975": 1361.8770702912186,
            "rating_q025": 1345.8934867648961
        },
        "grok-3-mini-high": {
            "rating": 1353.7993884271202,
            "rating_q975": 1362.8229263735432,
            "rating_q025": 1344.7758504806973
        },
        "glm-4.5-air": {
            "rating": 1352.002985126234,
            "rating_q975": 1359.3329155576546,
            "rating_q025": 1344.6730546948136
        },
        "claude-3-7-sonnet-20250219-thinking-32k": {
            "rating": 1349.148533875513,
            "rating_q975": 1355.5133038303395,
            "rating_q025": 1342.7837639206866
        },
        "claude-sonnet-4-20250514": {
            "rating": 1346.8767732511694,
            "rating_q975": 1353.5403201047973,
            "rating_q025": 1340.2132263975416
        },
        "grok-3-mini-beta": {
            "rating": 1345.1939391591175,
            "rating_q975": 1353.155062229049,
            "rating_q025": 1337.232816089186
        },
        "kimi-k2-0905-preview": {
            "rating": 1345.0106158862836,
            "rating_q975": 1356.6768596241668,
            "rating_q025": 1333.3443721484005
        },
        "deepseek-v3-0324": {
            "rating": 1342.8554464471788,
            "rating_q975": 1348.7173166078323,
            "rating_q025": 1336.9935762865252
        },
        "qwen3-next-80b-a3b-thinking": {
            "rating": 1340.9211221495584,
            "rating_q975": 1350.8797625639718,
            "rating_q025": 1330.962481735145
        },
        "o1-preview": {
            "rating": 1339.84193147959,
            "rating_q975": 1346.4895060820943,
            "rating_q025": 1333.1943568770855
        },
        "hunyuan-turbos-20250416": {
            "rating": 1339.4722830476805,
            "rating_q975": 1350.980611933489,
            "rating_q025": 1327.9639541618722
        },
        "mistral-medium-2505": {
            "rating": 1335.4079165868966,
            "rating_q975": 1342.4872782518125,
            "rating_q025": 1328.3285549219806
        },
        "o3-mini-high": {
            "rating": 1334.5785179284962,
            "rating_q975": 1342.0871907509497,
            "rating_q025": 1327.0698451060427
        },
        "amazon-nova-experimental-chat-10-09": {
            "rating": 1333.136403706591,
            "rating_q975": 1347.186050596501,
            "rating_q025": 1319.086756816681
        },
        "qwen3-235b-a22b": {
            "rating": 1332.5644350558982,
            "rating_q975": 1340.2673180782647,
            "rating_q025": 1324.8615520335318
        },
        "qwen2.5-max": {
            "rating": 1332.1135494308533,
            "rating_q975": 1337.9236819196965,
            "rating_q025": 1326.30341694201
        },
        "gpt-4.1-mini-2025-04-14": {
            "rating": 1330.171202580694,
            "rating_q975": 1336.63242370053,
            "rating_q025": 1323.709981460858
        },
        "step-3": {
            "rating": 1327.5365349403764,
            "rating_q975": 1341.9478900415957,
            "rating_q025": 1313.1251798391572
        },
        "o4-mini-2025-04-16": {
            "rating": 1321.230629834809,
            "rating_q975": 1327.2785873613914,
            "rating_q025": 1315.1826723082265
        },
        "kimi-k2-0711-preview": {
            "rating": 1321.066433718959,
            "rating_q975": 1328.7555646752799,
            "rating_q025": 1313.377302762638
        },
        "gemma-3-27b-it": {
            "rating": 1319.4015145622247,
            "rating_q975": 1324.992827458254,
            "rating_q025": 1313.8102016661956
        },
        "ling-flash-2.0": {
            "rating": 1316.0237184042064,
            "rating_q975": 1329.492601912258,
            "rating_q025": 1302.554834896155
        },
        "minimax-m1": {
            "rating": 1314.55413198972,
            "rating_q975": 1321.2339192049824,
            "rating_q025": 1307.8743447744575
        },
        "o3-mini": {
            "rating": 1313.605030090354,
            "rating_q975": 1318.6033031902186,
            "rating_q025": 1308.6067569904892
        },
        "deepseek-v3": {
            "rating": 1313.0445826429734,
            "rating_q975": 1319.6719552108932,
            "rating_q025": 1306.4172100750536
        },
        "hunyuan-turbos-20250226": {
            "rating": 1312.0695158339404,
            "rating_q975": 1330.0446052508896,
            "rating_q025": 1294.0944264169912
        },
        "ring-flash-2.0": {
            "rating": 1311.2235947990614,
            "rating_q975": 1324.6902255325754,
            "rating_q025": 1297.7569640655474
        },
        "gpt-oss-120b": {
            "rating": 1310.810831051022,
            "rating_q975": 1318.371652829232,
            "rating_q025": 1303.250009272812
        },
        "step-1o-turbo-202506": {
            "rating": 1310.298705090075,
            "rating_q975": 1322.692213869719,
            "rating_q025": 1297.905196310431
        },
        "glm-4.5v": {
            "rating": 1310.1796972406178,
            "rating_q975": 1326.227035414302,
            "rating_q025": 1294.1323590669335
        },
        "mistral-small-2506": {
            "rating": 1309.2371331289366,
            "rating_q975": 1318.038949248181,
            "rating_q025": 1300.4353170096922
        },
        "command-a-03-2025": {
            "rating": 1307.5238398806637,
            "rating_q975": 1312.9763036799145,
            "rating_q025": 1302.0713760814128
        },
        "llama-3.1-nemotron-ultra-253b-v1": {
            "rating": 1306.171982102254,
            "rating_q975": 1327.3665753825912,
            "rating_q025": 1284.977388821917
        },
        "gemini-2.0-flash-lite-preview-02-05": {
            "rating": 1303.139094553085,
            "rating_q975": 1309.2678597121026,
            "rating_q025": 1297.0103293940674
        },
        "qwen3-32b": {
            "rating": 1302.3813955537212,
            "rating_q975": 1321.2256647981803,
            "rating_q025": 1283.537126309262
        },
        "o1-mini": {
            "rating": 1302.327545639212,
            "rating_q975": 1307.2804702658996,
            "rating_q025": 1297.3746210125246
        },
        "qwen-plus-0125": {
            "rating": 1301.3196041260046,
            "rating_q975": 1313.3196323853003,
            "rating_q025": 1289.3195758667089
        },
        "gpt-5-nano-high": {
            "rating": 1301.082640776677,
            "rating_q975": 1314.2718567304646,
            "rating_q025": 1287.8934248228893
        },
        "gemma-3-12b-it": {
            "rating": 1297.5012104698274,
            "rating_q975": 1313.6330781339773,
            "rating_q025": 1281.3693428056774
        },
        "qwq-32b": {
            "rating": 1297.4539426644483,
            "rating_q975": 1304.3726334416735,
            "rating_q025": 1290.535251887223
        },
        "nvidia-llama-3.3-nemotron-super-49b-v1.5": {
            "rating": 1297.307231513647,
            "rating_q975": 1316.9027075923743,
            "rating_q025": 1277.7117554349195
        },
        "claude-3-5-sonnet-20241022": {
            "rating": 1296.0730146431015,
            "rating_q975": 1300.1687046997558,
            "rating_q025": 1291.9773245864471
        },
        "gemini-1.5-pro-002": {
            "rating": 1295.5376873898613,
            "rating_q975": 1300.1957313105595,
            "rating_q025": 1290.879643469163
        },
        "glm-4-plus-0111": {
            "rating": 1291.905274036585,
            "rating_q975": 1304.249012931201,
            "rating_q025": 1279.5615351419692
        },
        "llama-3.3-nemotron-49b-super-v1": {
            "rating": 1291.8526470305555,
            "rating_q975": 1311.3040351837249,
            "rating_q025": 1272.4012588773862
        },
        "step-2-16k-exp-202412": {
            "rating": 1284.5276117218614,
            "rating_q975": 1296.9483432819245,
            "rating_q025": 1272.1068801617982
        },
        "qwen3-30b-a3b": {
            "rating": 1284.2030515830206,
            "rating_q975": 1291.9667895360562,
            "rating_q025": 1276.439313629985
        },
        "deepseek-v2.5-1210": {
            "rating": 1278.3296753899779,
            "rating_q975": 1289.3797324924744,
            "rating_q025": 1267.2796182874813
        },
        "yi-lightning": {
            "rating": 1277.4456753941863,
            "rating_q975": 1284.1258010988015,
            "rating_q025": 1270.7655496895711
        },
        "hunyuan-turbo-0110": {
            "rating": 1276.9666072385476,
            "rating_q975": 1294.9733667119447,
            "rating_q025": 1258.9598477651505
        },
        "gpt-4o-2024-05-13": {
            "rating": 1276.248383632816,
            "rating_q975": 1280.9316638208932,
            "rating_q025": 1271.565103444739
        },
        "hunyuan-large-2025-02-10": {
            "rating": 1275.1967616768484,
            "rating_q975": 1290.681087958447,
            "rating_q025": 1259.7124353952497
        },
        "qwen2.5-plus-1127": {
            "rating": 1273.0929009158808,
            "rating_q975": 1281.9484444154418,
            "rating_q025": 1264.2373574163198
        },
        "athene-v2-chat": {
            "rating": 1269.2188296191384,
            "rating_q975": 1275.295286327637,
            "rating_q025": 1263.1423729106398
        },
        "grok-2-2024-08-13": {
            "rating": 1268.600575744104,
            "rating_q975": 1273.2751816920597,
            "rating_q025": 1263.9259697961481
        },
        "claude-3-5-sonnet-20240620": {
            "rating": 1268.1240375503598,
            "rating_q975": 1272.9271730396372,
            "rating_q025": 1263.3209020610825
        },
        "llama-4-maverick-17b-128e-instruct": {
            "rating": 1267.4944535518455,
            "rating_q975": 1273.9370766411746,
            "rating_q025": 1261.0518304625164
        },
        "gpt-4o-2024-08-06": {
            "rating": 1265.477750231451,
            "rating_q975": 1271.0024301957653,
            "rating_q025": 1259.9530702671366
        },
        "gpt-4.1-nano-2025-04-14": {
            "rating": 1265.314635066683,
            "rating_q975": 1277.6987625092877,
            "rating_q025": 1252.9305076240782
        },
        "mistral-small-3.1-24b-instruct-2503": {
            "rating": 1264.1841644910144,
            "rating_q975": 1271.3079752934889,
            "rating_q025": 1257.0603536885399
        },
        "glm-4-plus": {
            "rating": 1262.6545863432675,
            "rating_q975": 1269.3100649488692,
            "rating_q025": 1255.9991077376658
        },
        "qwen-max-0919": {
            "rating": 1260.6735512511077,
            "rating_q975": 1268.4213985259923,
            "rating_q025": 1252.925703976223
        },
        "llama-3.1-405b-instruct-bf16": {
            "rating": 1257.7505299492245,
            "rating_q975": 1262.6899900067745,
            "rating_q025": 1252.8110698916746
        },
        "magistral-medium-2506": {
            "rating": 1257.727985578686,
            "rating_q975": 1268.5257957419092,
            "rating_q025": 1246.9301754154628
        },
        "llama-3.1-405b-instruct-fp8": {
            "rating": 1257.2816862805662,
            "rating_q975": 1262.239507611757,
            "rating_q025": 1252.3238649493753
        },
        "gpt-4o-mini-2024-07-18": {
            "rating": 1256.8567464965936,
            "rating_q975": 1261.3240845816802,
            "rating_q025": 1252.389408411507
        },
        "gemini-1.5-flash-002": {
            "rating": 1256.424110384578,
            "rating_q975": 1262.0159630867715,
            "rating_q025": 1250.8322576823844
        },
        "gemma-3n-e4b-it": {
            "rating": 1255.9033323786275,
            "rating_q975": 1264.359092125359,
            "rating_q025": 1247.447572631896
        },
        "qwen2.5-72b-instruct": {
            "rating": 1252.7330446799451,
            "rating_q975": 1258.0902782500639,
            "rating_q025": 1247.3758111098264
        },
        "gemini-advanced-0514": {
            "rating": 1252.1238415853059,
            "rating_q975": 1258.6415094386373,
            "rating_q025": 1245.6061737319744
        },
        "gemini-1.5-pro-001": {
            "rating": 1252.082667047664,
            "rating_q975": 1257.6058074660666,
            "rating_q025": 1246.5595266292614
        },
        "hunyuan-large-vision": {
            "rating": 1251.14541185789,
            "rating_q975": 1267.9155021583877,
            "rating_q025": 1234.3753215573922
        },
        "llama-3.1-nemotron-70b-instruct": {
            "rating": 1250.7528079526985,
            "rating_q975": 1261.4358331109129,
            "rating_q025": 1240.0697827944841
        },
        "llama-4-scout-17b-16e-instruct": {
            "rating": 1249.2477474553177,
            "rating_q975": 1256.558237729642,
            "rating_q025": 1241.9372571809934
        },
        "gpt-4-turbo-2024-04-09": {
            "rating": 1248.1455569595903,
            "rating_q975": 1253.3787583327132,
            "rating_q025": 1242.9123555864674
        },
        "deepseek-v2.5": {
            "rating": 1248.1267739525906,
            "rating_q975": 1254.575976372469,
            "rating_q025": 1241.6775715327121
        },
        "mistral-large-2411": {
            "rating": 1247.4067461435948,
            "rating_q975": 1253.1997226734497,
            "rating_q025": 1241.6137696137398
        },
        "claude-3-opus-20240229": {
            "rating": 1246.6397326983333,
            "rating_q975": 1250.7674980372915,
            "rating_q025": 1242.5119673593751
        },
        "mistral-large-2407": {
            "rating": 1246.553260588624,
            "rating_q975": 1251.9272269654496,
            "rating_q025": 1241.1792942117984
        },
        "hunyuan-standard-2025-02-10": {
            "rating": 1243.9325459234433,
            "rating_q975": 1259.0615610508275,
            "rating_q025": 1228.803530796059
        },
        "grok-2-mini-2024-08-13": {
            "rating": 1243.4877671550885,
            "rating_q975": 1248.4546152618059,
            "rating_q025": 1238.520919048371
        },
        "llama-3.3-70b-instruct": {
            "rating": 1240.9813742119716,
            "rating_q975": 1245.7359770078306,
            "rating_q025": 1236.2267714161126
        },
        "gpt-4-1106-preview": {
            "rating": 1238.897176049427,
            "rating_q975": 1244.2585050751263,
            "rating_q025": 1233.5358470237275
        },
        "claude-3-5-haiku-20241022": {
            "rating": 1238.3265059235187,
            "rating_q975": 1242.7765379946131,
            "rating_q025": 1233.8764738524242
        },
        "gemma-3-4b-it": {
            "rating": 1237.8038332116348,
            "rating_q975": 1254.0349084402212,
            "rating_q025": 1221.5727579830484
        },
        "gpt-oss-20b": {
            "rating": 1237.0093949993725,
            "rating_q975": 1249.2232723618743,
            "rating_q025": 1224.7955176368707
        },
        "amazon-nova-pro-v1.0": {
            "rating": 1233.7237474073513,
            "rating_q975": 1239.764836820236,
            "rating_q025": 1227.6826579944666
        },
        "gpt-4-0125-preview": {
            "rating": 1233.4718844131958,
            "rating_q975": 1238.9771856717878,
            "rating_q025": 1227.9665831546038
        },
        "llama-3.1-tulu-3-70b": {
            "rating": 1231.609653688146,
            "rating_q975": 1246.9858986238535,
            "rating_q025": 1216.2334087524384
        },
        "llama-3.1-70b-instruct": {
            "rating": 1230.2729531280988,
            "rating_q975": 1235.2595575935763,
            "rating_q025": 1225.2863486626213
        },
        "athene-70b-0725": {
            "rating": 1224.8567574561448,
            "rating_q975": 1232.3646152631406,
            "rating_q025": 1217.348899649149
        },
        "qwen2.5-coder-32b-instruct": {
            "rating": 1220.7326362985605,
            "rating_q975": 1232.4283023066773,
            "rating_q025": 1209.0369702904436
        },
        "mistral-small-24b-instruct-2501": {
            "rating": 1212.2808433754526,
            "rating_q975": 1220.2692936724648,
            "rating_q025": 1204.2923930784405
        },
        "jamba-1.5-large": {
            "rating": 1211.4670179059035,
            "rating_q975": 1222.0223230809497,
            "rating_q025": 1200.9117127308573
        },
        "gemini-1.5-flash-001": {
            "rating": 1210.4861710694938,
            "rating_q975": 1216.192750202659,
            "rating_q025": 1204.7795919363286
        },
        "reka-core-20240904": {
            "rating": 1210.3069058406618,
            "rating_q975": 1220.198421017497,
            "rating_q025": 1200.4153906638267
        },
        "gemma-2-27b-it": {
            "rating": 1204.8062913329222,
            "rating_q975": 1209.2032487624683,
            "rating_q025": 1200.4093339033761
        },
        "amazon-nova-lite-v1.0": {
            "rating": 1203.9347183286354,
            "rating_q975": 1210.7446525672015,
            "rating_q025": 1197.1247840900694
        },
        "nemotron-4-340b-instruct": {
            "rating": 1201.8561235317359,
            "rating_q975": 1209.8079271604151,
            "rating_q025": 1193.9043199030566
        },
        "glm-4-0520": {
            "rating": 1201.0979788313991,
            "rating_q975": 1211.1903165767924,
            "rating_q025": 1191.0056410860059
        },
        "phi-4": {
            "rating": 1199.818154937861,
            "rating_q975": 1206.2105951717722,
            "rating_q025": 1193.4257147039498
        },
        "hunyuan-standard-256k": {
            "rating": 1199.7021204206776,
            "rating_q975": 1216.4425098895374,
            "rating_q025": 1182.9617309518178
        },
        "gpt-4-0314": {
            "rating": 1199.0620811053413,
            "rating_q975": 1206.1350777993557,
            "rating_q025": 1191.989084411327
        },
        "llama-3.1-nemotron-51b-instruct": {
            "rating": 1198.6994436265134,
            "rating_q975": 1213.1743156722382,
            "rating_q025": 1184.2245715807885
        },
        "claude-3-sonnet-20240229": {
            "rating": 1197.8036772819487,
            "rating_q975": 1203.2009069214396,
            "rating_q025": 1192.4064476424578
        },
        "gemini-1.5-flash-8b-001": {
            "rating": 1197.6839154519423,
            "rating_q975": 1203.3334241814173,
            "rating_q025": 1192.0344067224673
        },
        "command-r-plus-08-2024": {
            "rating": 1195.1649750078873,
            "rating_q975": 1204.2912105324815,
            "rating_q025": 1186.038739483293
        },
        "c4ai-aya-expanse-32b": {
            "rating": 1195.0183997359159,
            "rating_q975": 1201.4400098018198,
            "rating_q025": 1188.596789670012
        },
        "llama-3-70b-instruct": {
            "rating": 1193.1890193639924,
            "rating_q975": 1198.242215377492,
            "rating_q025": 1188.135823350493
        },
        "gemma-2-9b-it-simpo": {
            "rating": 1189.86022372684,
            "rating_q975": 1199.717943339971,
            "rating_q025": 1180.0025041137092
        },
        "gpt-4-0613": {
            "rating": 1187.0330539033691,
            "rating_q975": 1192.8283477465834,
            "rating_q025": 1181.2377600601549
        },
        "olmo-2-0325-32b-instruct": {
            "rating": 1186.1760938717384,
            "rating_q975": 1203.3738271950592,
            "rating_q025": 1168.9783605484176
        },
        "reka-flash-20240904": {
            "rating": 1184.0190813811473,
            "rating_q975": 1193.8725501169924,
            "rating_q025": 1174.1656126453022
        },
        "qwen2-72b-instruct": {
            "rating": 1179.751605077942,
            "rating_q975": 1186.3159057329717,
            "rating_q025": 1173.1873044229123
        },
        "deepseek-coder-v2": {
            "rating": 1178.651899508077,
            "rating_q975": 1187.6019200232975,
            "rating_q025": 1169.7018789928563
        },
        "command-r-plus": {
            "rating": 1178.4575098467108,
            "rating_q975": 1184.3030706733243,
            "rating_q025": 1172.6119490200972
        },
        "gemma-2-9b-it": {
            "rating": 1177.2190032302285,
            "rating_q975": 1182.1566473046832,
            "rating_q025": 1172.2813591557738
        },
        "amazon-nova-micro-v1.0": {
            "rating": 1174.1563037829487,
            "rating_q975": 1180.9670669302402,
            "rating_q025": 1167.3455406356572
        },
        "llama-3.1-tulu-3-8b": {
            "rating": 1173.7448958554942,
            "rating_q975": 1189.1209881123868,
            "rating_q025": 1158.3688035986015
        },
        "claude-3-haiku-20240307": {
            "rating": 1172.2519070604353,
            "rating_q975": 1177.2653965427567,
            "rating_q025": 1167.238417578114
        },
        "mistral-large-2402": {
            "rating": 1167.9512102809958,
            "rating_q975": 1174.3526927473122,
            "rating_q025": 1161.5497278146795
        },
        "command-r-08-2024": {
            "rating": 1166.1836837571252,
            "rating_q975": 1175.160308542761,
            "rating_q025": 1157.2070589714895
        },
        "ministral-8b-2410": {
            "rating": 1159.7915672440865,
            "rating_q975": 1172.3689784524113,
            "rating_q025": 1147.2141560357618
        },
        "llama-3.1-8b-instruct": {
            "rating": 1158.4386377754963,
            "rating_q975": 1163.6690088168339,
            "rating_q025": 1153.2082667341588
        },
        "qwen1.5-110b-chat": {
            "rating": 1156.5013064988975,
            "rating_q975": 1164.4075842361667,
            "rating_q025": 1148.5950287616283
        },
        "qwq-32b-preview": {
            "rating": 1156.4392247156024,
            "rating_q975": 1172.323811406892,
            "rating_q025": 1140.554638024313
        },
        "c4ai-aya-expanse-8b": {
            "rating": 1154.061978126283,
            "rating_q975": 1163.4289355945214,
            "rating_q025": 1144.6950206580448
        },
        "mistral-medium": {
            "rating": 1150.5376528566976,
            "rating_q975": 1158.5106350064832,
            "rating_q025": 1142.564670706912
        },
        "jamba-1.5-mini": {
            "rating": 1147.0950299820522,
            "rating_q975": 1157.5080452006544,
            "rating_q025": 1136.68201476345
        },
        "mixtral-8x22b-instruct-v0.1": {
            "rating": 1145.7299682049852,
            "rating_q975": 1151.9986015588013,
            "rating_q025": 1139.461334851169
        },
        "qwen1.5-72b-chat": {
            "rating": 1140.1976419813418,
            "rating_q975": 1147.372596803391,
            "rating_q025": 1133.0226871592927
        },
        "yi-1.5-34b-chat": {
            "rating": 1137.6774333771527,
            "rating_q975": 1145.185752097037,
            "rating_q025": 1130.1691146572684
        },
        "internlm2_5-20b-chat": {
            "rating": 1134.93246205764,
            "rating_q975": 1144.766022769282,
            "rating_q025": 1125.0989013459978
        },
        "granite-3.1-8b-instruct": {
            "rating": 1131.9263609310838,
            "rating_q975": 1148.0929244269382,
            "rating_q025": 1115.7597974352293
        },
        "reka-flash-21b-20240226-online": {
            "rating": 1128.2608167507306,
            "rating_q975": 1138.3439057007195,
            "rating_q025": 1118.1777278007416
        },
        "llama-3-8b-instruct": {
            "rating": 1126.0563386257259,
            "rating_q975": 1131.4785503547605,
            "rating_q025": 1120.6341268966912
        },
        "command-r": {
            "rating": 1123.7591985144577,
            "rating_q975": 1130.3148900410454,
            "rating_q025": 1117.20350698787
        },
        "reka-flash-21b-20240226": {
            "rating": 1120.0657358293306,
            "rating_q975": 1128.3349951806088,
            "rating_q025": 1111.7964764780525
        },
        "gpt-3.5-turbo-0125": {
            "rating": 1117.3852264877773,
            "rating_q975": 1123.546657602367,
            "rating_q025": 1111.2237953731876
        },
        "gemma-2-2b-it": {
            "rating": 1116.6586984513394,
            "rating_q975": 1121.9170427333495,
            "rating_q025": 1111.4003541693294
        },
        "zephyr-orpo-141b-A35b-v0.1": {
            "rating": 1116.3087368738984,
            "rating_q975": 1131.7492100542777,
            "rating_q025": 1100.868263693519
        },
        "granite-3.1-2b-instruct": {
            "rating": 1115.0178122436926,
            "rating_q975": 1131.115048148436,
            "rating_q025": 1098.920576338949
        },
        "qwen1.5-32b-chat": {
            "rating": 1114.8602198000533,
            "rating_q975": 1123.2571885317461,
            "rating_q025": 1106.4632510683605
        },
        "gemini-pro-dev-api": {
            "rating": 1112.8836693280693,
            "rating_q975": 1123.3032719694265,
            "rating_q025": 1102.4640666867122
        },
        "phi-3-medium-4k-instruct": {
            "rating": 1112.481024877989,
            "rating_q975": 1119.6258138888418,
            "rating_q025": 1105.3362358671363
        },
        "dbrx-instruct-preview": {
            "rating": 1110.4148230598862,
            "rating_q975": 1118.719903906813,
            "rating_q025": 1102.1097422129594
        },
        "gemini-pro": {
            "rating": 1109.2620601958547,
            "rating_q975": 1125.737609384642,
            "rating_q025": 1092.7865110070675
        },
        "tulu-2-dpo-70b": {
            "rating": 1108.9395335942586,
            "rating_q975": 1123.5681427227207,
            "rating_q025": 1094.3109244657965
        },
        "mixtral-8x7b-instruct-v0.1": {
            "rating": 1107.833494980502,
            "rating_q975": 1113.9113010975996,
            "rating_q025": 1101.7556888634047
        },
        "qwen1.5-14b-chat": {
            "rating": 1100.6196526807717,
            "rating_q975": 1110.4295191946555,
            "rating_q025": 1090.8097861668878
        },
        "starling-lm-7b-beta": {
            "rating": 1095.3117215349175,
            "rating_q975": 1105.1966259737296,
            "rating_q025": 1085.4268170961054
        },
        "wizardlm-70b": {
            "rating": 1091.794200997391,
            "rating_q975": 1105.1282614395598,
            "rating_q025": 1078.4601405552223
        },
        "gpt-3.5-turbo-1106": {
            "rating": 1090.7012192125128,
            "rating_q975": 1102.8653524001038,
            "rating_q025": 1078.5370860249218
        },
        "yi-34b-chat": {
            "rating": 1089.6654099335303,
            "rating_q975": 1099.2584265247433,
            "rating_q025": 1080.0723933423174
        },
        "llama-3.2-3b-instruct": {
            "rating": 1088.155956239766,
            "rating_q975": 1098.7661385795861,
            "rating_q025": 1077.545773899946
        },
        "granite-3.0-8b-instruct": {
            "rating": 1087.2592927963196,
            "rating_q975": 1099.2919499482152,
            "rating_q025": 1075.226635644424
        },
        "phi-3-small-8k-instruct": {
            "rating": 1085.3444966533873,
            "rating_q975": 1093.8301288181071,
            "rating_q025": 1076.8588644886675
        },
        "deepseek-llm-67b-chat": {
            "rating": 1077.4454119858399,
            "rating_q975": 1094.4299220865694,
            "rating_q025": 1060.4609018851104
        },
        "openchat-3.5-0106": {
            "rating": 1075.0116758684749,
            "rating_q975": 1085.366582780928,
            "rating_q025": 1064.6567689560218
        },
        "llama-2-70b-chat": {
            "rating": 1070.2104477641158,
            "rating_q975": 1077.7266821904827,
            "rating_q025": 1062.6942133377488
        },
        "starling-lm-7b-alpha": {
            "rating": 1069.1144640606303,
            "rating_q975": 1080.3824300209908,
            "rating_q025": 1057.8464981002699
        },
        "openhermes-2.5-mistral-7b": {
            "rating": 1069.036345616623,
            "rating_q975": 1084.3624733177905,
            "rating_q025": 1053.7102179154556
        },
        "openchat-3.5": {
            "rating": 1068.520564687038,
            "rating_q975": 1082.5800324588452,
            "rating_q025": 1054.4610969152307
        },
        "snowflake-arctic-instruct": {
            "rating": 1065.3770268541805,
            "rating_q975": 1073.7010867090248,
            "rating_q025": 1057.0529669993361
        },
        "vicuna-33b": {
            "rating": 1063.3124207622773,
            "rating_q975": 1072.152261323129,
            "rating_q025": 1054.4725802014254
        },
        "llama2-70b-steerlm-chat": {
            "rating": 1060.0525777834616,
            "rating_q975": 1078.2059771853249,
            "rating_q025": 1041.8991783815984
        },
        "mistral-7b-instruct-v0.2": {
            "rating": 1058.665480104359,
            "rating_q975": 1067.5039199299938,
            "rating_q025": 1049.827040278724
        },
        "qwen1.5-7b-chat": {
            "rating": 1056.6544809163497,
            "rating_q975": 1070.5510088723854,
            "rating_q025": 1042.757952960314
        },
        "phi-3-mini-4k-instruct-june-2024": {
            "rating": 1056.3943169230179,
            "rating_q975": 1065.8708291788057,
            "rating_q025": 1046.91780466723
        },
        "gemma-1.1-7b-it": {
            "rating": 1056.1790642132955,
            "rating_q975": 1063.9580952119927,
            "rating_q025": 1048.4000332145984
        },
        "nous-hermes-2-mixtral-8x7b-dpo": {
            "rating": 1055.2215918999495,
            "rating_q975": 1071.4527431210415,
            "rating_q025": 1038.9904406788576
        },
        "granite-3.0-2b-instruct": {
            "rating": 1054.8908656027238,
            "rating_q975": 1067.040714637266,
            "rating_q025": 1042.7410165681815
        },
        "mpt-30b-chat": {
            "rating": 1052.4999182750503,
            "rating_q975": 1073.9633293341192,
            "rating_q025": 1031.0365072159814
        },
        "dolphin-2.2.1-mistral-7b": {
            "rating": 1051.1960327499728,
            "rating_q975": 1076.0616140034,
            "rating_q025": 1026.3304514965455
        },
        "phi-3-mini-4k-instruct": {
            "rating": 1050.897439048938,
            "rating_q975": 1059.5081258253635,
            "rating_q025": 1042.2867522725123
        },
        "wizardlm-13b": {
            "rating": 1046.9003620217973,
            "rating_q975": 1060.8246123820327,
            "rating_q025": 1032.9761116615618
        },
        "solar-10.7b-instruct-v1.0": {
            "rating": 1046.2875974433614,
            "rating_q975": 1064.659523056833,
            "rating_q025": 1027.9156718298898
        },
        "falcon-180b-chat": {
            "rating": 1045.3559360205863,
            "rating_q975": 1074.1921450222603,
            "rating_q025": 1016.5197270189124
        },
        "llama-2-13b-chat": {
            "rating": 1044.072840185167,
            "rating_q975": 1053.2652494640668,
            "rating_q025": 1034.8804309062673
        },
        "vicuna-13b": {
            "rating": 1034.001709319536,
            "rating_q975": 1043.4483300602024,
            "rating_q025": 1024.5550885788698
        },
        "zephyr-7b-alpha": {
            "rating": 1033.6408852436252,
            "rating_q975": 1058.5969592605068,
            "rating_q025": 1008.6848112267438
        },
        "smollm2-1.7b-instruct": {
            "rating": 1031.540868883255,
            "rating_q975": 1052.6066462866768,
            "rating_q025": 1010.475091479833
        },
        "llama-3.2-1b-instruct": {
            "rating": 1030.9000387962328,
            "rating_q975": 1041.8676440588545,
            "rating_q025": 1019.9324335336112
        },
        "zephyr-7b-beta": {
            "rating": 1030.0057959797,
            "rating_q975": 1042.7138156888507,
            "rating_q025": 1017.2977762705493
        },
        "qwen-14b-chat": {
            "rating": 1029.6147474271015,
            "rating_q975": 1046.123609483845,
            "rating_q025": 1013.1058853703579
        },
        "codellama-34b-instruct": {
            "rating": 1026.855865462712,
            "rating_q975": 1039.671577103514,
            "rating_q025": 1014.04015382191
        },
        "phi-3-mini-128k-instruct": {
            "rating": 1022.3960491514782,
            "rating_q975": 1032.424900708657,
            "rating_q025": 1012.3671975942995
        },
        "codellama-70b-instruct": {
            "rating": 1021.8698671901863,
            "rating_q975": 1052.474922905683,
            "rating_q025": 991.2648114746896
        },
        "gemma-7b-it": {
            "rating": 1015.6443099420136,
            "rating_q975": 1028.4103617642388,
            "rating_q025": 1002.8782581197884
        },
        "stripedhyena-nous-7b": {
            "rating": 1008.9114079989639,
            "rating_q975": 1024.1739662300245,
            "rating_q025": 993.6488497679034
        },
        "palm-2": {
            "rating": 1008.6344581936827,
            "rating_q975": 1022.058276204322,
            "rating_q025": 995.2106401830433
        },
        "llama-2-7b-chat": {
            "rating": 1004.3724309532529,
            "rating_q975": 1014.1055716827024,
            "rating_q025": 994.6392902238034
        },
        "mistral-7b-instruct": {
            "rating": 1002.5752676687918,
            "rating_q975": 1016.1291137953045,
            "rating_q025": 989.021421542279
        },
        "vicuna-7b": {
            "rating": 993.6209543724902,
            "rating_q975": 1007.670000184994,
            "rating_q025": 979.5719085599865
        },
        "gemma-1.1-2b-it": {
            "rating": 990.6280228782662,
            "rating_q975": 1001.4327549501606,
            "rating_q025": 979.8232908063717
        },
        "guanaco-33b": {
            "rating": 990.2846325850503,
            "rating_q975": 1011.3364830064686,
            "rating_q025": 969.232782163632
        },
        "olmo-7b-instruct": {
            "rating": 978.6061582436573,
            "rating_q975": 994.3942353089527,
            "rating_q025": 962.8180811783619
        },
        "qwen1.5-4b-chat": {
            "rating": 977.1989923052561,
            "rating_q975": 990.0493690400905,
            "rating_q025": 964.3486155704217
        },
        "gemma-2b-it": {
            "rating": 969.5673258183602,
            "rating_q975": 985.7246793197301,
            "rating_q025": 953.4099723169904
        },
        "chatglm3-6b": {
            "rating": 953.8466002817509,
            "rating_q975": 971.6111120792601,
            "rating_q025": 936.0820884842416
        },
        "gpt4all-13b-snoozy": {
            "rating": 945.9770210657375,
            "rating_q975": 971.0642561832451,
            "rating_q025": 920.8897859482299
        },
        "koala-13b": {
            "rating": 943.4083106469952,
            "rating_q975": 958.7359880549322,
            "rating_q025": 928.0806332390582
        },
        "mpt-7b-chat": {
            "rating": 908.1107355919539,
            "rating_q975": 926.4950919486666,
            "rating_q025": 889.7263792352412
        },
        "chatglm-6b": {
            "rating": 901.7224151713974,
            "rating_q975": 919.5396760340101,
            "rating_q025": 883.9051543087847
        },
        "chatglm2-6b": {
            "rating": 900.8156962565088,
            "rating_q975": 923.5731156071079,
            "rating_q025": 878.0582769059097
        },
        "alpaca-13b": {
            "rating": 891.3115451928629,
            "rating_q975": 907.7923689778345,
            "rating_q025": 874.8307214078914
        },
        "oasst-pythia-12b": {
            "rating": 886.4023567815656,
            "rating_q975": 902.3312960879713,
            "rating_q025": 870.4734174751599
        },
        "RWKV-4-Raven-14B": {
            "rating": 881.9489205457508,
            "rating_q975": 898.8010944714596,
            "rating_q025": 865.0967466200419
        },
        "fastchat-t5-3b": {
            "rating": 856.9492578657508,
            "rating_q975": 875.6190067014444,
            "rating_q025": 838.2795090300573
        },
        "stablelm-tuned-alpha-7b": {
            "rating": 831.2844081871068,
            "rating_q975": 851.7898874254755,
            "rating_q025": 810.7789289487381
        },
        "dolly-v2-12b": {
            "rating": 814.0719758000521,
            "rating_q975": 835.3080379195178,
            "rating_q025": 792.8359136805864
        },
        "llama-13b": {
            "rating": 779.8683791560362,
            "rating_q975": 804.9094522217009,
            "rating_q025": 754.8273060903715
        }
    },
    "industry_business_and_management_and_financial_operations": {
        "gemini-2.5-pro": {
            "rating": 1440.930640574712,
            "rating_q975": 1448.2505323746311,
            "rating_q025": 1433.610748774793
        },
        "qwen3-max-preview": {
            "rating": 1437.941263913608,
            "rating_q975": 1447.4265415747932,
            "rating_q025": 1428.455986252423
        },
        "qwen3-vl-235b-a22b-instruct": {
            "rating": 1433.1289421327733,
            "rating_q975": 1447.7746636213692,
            "rating_q025": 1418.4832206441774
        },
        "mistral-medium-2508": {
            "rating": 1429.8856781621116,
            "rating_q975": 1438.8240203046355,
            "rating_q025": 1420.9473360195877
        },
        "longcat-flash-chat": {
            "rating": 1427.0126002952588,
            "rating_q975": 1440.013063950559,
            "rating_q025": 1414.0121366399587
        },
        "qwen3-next-80b-a3b-instruct": {
            "rating": 1423.0391866725117,
            "rating_q975": 1433.4621171246054,
            "rating_q025": 1412.616256220418
        },
        "chatgpt-4o-latest-20250326": {
            "rating": 1421.7966230567474,
            "rating_q975": 1429.7617095144194,
            "rating_q025": 1413.8315365990754
        },
        "glm-4.5": {
            "rating": 1421.2677764339458,
            "rating_q975": 1430.8536937806905,
            "rating_q025": 1411.681859087201
        },
        "qwen3-235b-a22b-instruct-2507": {
            "rating": 1418.70023414305,
            "rating_q975": 1426.9673051115153,
            "rating_q025": 1410.4331631745847
        },
        "claude-sonnet-4-5-20250929": {
            "rating": 1417.441018714572,
            "rating_q975": 1433.4578746162103,
            "rating_q025": 1401.4241628129337
        },
        "glm-4.6": {
            "rating": 1416.5310347085624,
            "rating_q975": 1430.4196963949032,
            "rating_q025": 1402.6423730222216
        },
        "qwen3-235b-a22b-thinking-2507": {
            "rating": 1413.153682375536,
            "rating_q975": 1428.1611913487052,
            "rating_q025": 1398.1461734023667
        },
        "deepseek-v3.1-terminus-thinking": {
            "rating": 1412.8062795803125,
            "rating_q975": 1435.2118650457553,
            "rating_q025": 1390.4006941148698
        },
        "claude-sonnet-4-5-20250929-thinking-32k": {
            "rating": 1408.5789026414714,
            "rating_q975": 1421.4598419647537,
            "rating_q025": 1395.697963318189
        },
        "deepseek-v3.1-thinking": {
            "rating": 1408.1068696788097,
            "rating_q975": 1421.7444490130626,
            "rating_q025": 1394.4692903445568
        },
        "claude-opus-4-1-20250805-thinking-16k": {
            "rating": 1407.583640428633,
            "rating_q975": 1416.6656499350677,
            "rating_q025": 1398.5016309221985
        },
        "deepseek-v3.1": {
            "rating": 1406.9310868246794,
            "rating_q975": 1419.080176428022,
            "rating_q025": 1394.7819972213367
        },
        "grok-3-preview-02-24": {
            "rating": 1405.690177398774,
            "rating_q975": 1415.3613046104813,
            "rating_q025": 1396.0190501870668
        },
        "gemini-2.5-flash-preview-09-2025": {
            "rating": 1405.4860055838383,
            "rating_q975": 1417.6260799562356,
            "rating_q025": 1393.345931211441
        },
        "gemini-2.5-flash": {
            "rating": 1404.1471462132292,
            "rating_q975": 1411.390635463496,
            "rating_q025": 1396.9036569629625
        },
        "deepseek-r1-0528": {
            "rating": 1398.473430198976,
            "rating_q975": 1409.7955630854892,
            "rating_q025": 1387.151297312463
        },
        "claude-opus-4-1-20250805": {
            "rating": 1398.33791493625,
            "rating_q975": 1406.5170992190247,
            "rating_q025": 1390.1587306534752
        },
        "gpt-5-chat": {
            "rating": 1396.4654165440481,
            "rating_q975": 1405.573749103135,
            "rating_q025": 1387.3570839849613
        },
        "qwen3-max-2025-09-23": {
            "rating": 1396.286104561283,
            "rating_q975": 1410.214170012383,
            "rating_q025": 1382.3580391101832
        },
        "deepseek-v3.2-exp-thinking": {
            "rating": 1393.8510672717416,
            "rating_q975": 1407.847118412502,
            "rating_q025": 1379.8550161309813
        },
        "o3-2025-04-16": {
            "rating": 1393.7155548372025,
            "rating_q975": 1401.0735759889953,
            "rating_q025": 1386.3575336854096
        },
        "qwen3-30b-a3b-instruct-2507": {
            "rating": 1390.6433737433545,
            "rating_q975": 1400.2818191908957,
            "rating_q025": 1381.0049282958132
        },
        "qwen3-235b-a22b-no-thinking": {
            "rating": 1390.0800763578095,
            "rating_q975": 1398.361537056812,
            "rating_q025": 1381.798615658807
        },
        "grok-4-0709": {
            "rating": 1389.1257324834653,
            "rating_q975": 1397.464333715306,
            "rating_q025": 1380.7871312516245
        },
        "qwen3-vl-235b-a22b-thinking": {
            "rating": 1388.012161946304,
            "rating_q975": 1402.7829042504868,
            "rating_q025": 1373.2414196421214
        },
        "deepseek-v3.1-terminus": {
            "rating": 1387.0145241347584,
            "rating_q975": 1408.670857067696,
            "rating_q025": 1365.3581912018208
        },
        "claude-haiku-4-5-20251001": {
            "rating": 1386.4581116897798,
            "rating_q975": 1400.4194975974144,
            "rating_q025": 1372.4967257821452
        },
        "gpt-4.5-preview-2025-02-27": {
            "rating": 1384.262873756554,
            "rating_q975": 1399.9156893252296,
            "rating_q025": 1368.6100581878784
        },
        "hunyuan-turbos-20250416": {
            "rating": 1383.5052350753333,
            "rating_q975": 1399.3928980597439,
            "rating_q025": 1367.6175720909227
        },
        "grok-4-fast": {
            "rating": 1383.131964798412,
            "rating_q975": 1400.122253718256,
            "rating_q025": 1366.1416758785679
        },
        "gpt-5-high": {
            "rating": 1377.2052838037914,
            "rating_q975": 1386.4133244832028,
            "rating_q025": 1367.99724312438
        },
        "gemma-3-12b-it": {
            "rating": 1374.5649306435291,
            "rating_q975": 1404.9259209850297,
            "rating_q025": 1344.2039403020285
        },
        "hunyuan-t1-20250711": {
            "rating": 1372.6726046562374,
            "rating_q975": 1394.1120262796883,
            "rating_q025": 1351.2331830327864
        },
        "mai-1-preview": {
            "rating": 1371.201749030116,
            "rating_q975": 1381.6689914283481,
            "rating_q025": 1360.7345066318837
        },
        "glm-4.5-air": {
            "rating": 1371.132532874064,
            "rating_q975": 1380.0517483492765,
            "rating_q025": 1362.2133173988516
        },
        "gpt-4.1-2025-04-14": {
            "rating": 1367.000369115473,
            "rating_q975": 1374.6162403661897,
            "rating_q025": 1359.3844978647562
        },
        "gpt-5-mini-high": {
            "rating": 1361.3789259534296,
            "rating_q975": 1371.06710951375,
            "rating_q025": 1351.6907423931093
        },
        "qwen3-next-80b-a3b-thinking": {
            "rating": 1361.108683032039,
            "rating_q975": 1373.1993224542755,
            "rating_q025": 1349.0180436098024
        },
        "gemini-2.5-flash-lite-preview-09-2025-no-thinking": {
            "rating": 1360.1847771796893,
            "rating_q975": 1371.8845078266183,
            "rating_q025": 1348.4850465327602
        },
        "gemma-3-27b-it": {
            "rating": 1359.9470833355363,
            "rating_q975": 1367.7136614810438,
            "rating_q025": 1352.1805051900287
        },
        "ling-flash-2.0": {
            "rating": 1357.699199347851,
            "rating_q975": 1373.8890221141844,
            "rating_q025": 1341.5093765815175
        },
        "gemini-2.5-flash-lite-preview-06-17-thinking": {
            "rating": 1354.3400117422123,
            "rating_q975": 1362.9885060461618,
            "rating_q025": 1345.6915174382627
        },
        "gpt-oss-120b": {
            "rating": 1353.5597162906827,
            "rating_q975": 1362.7329864583985,
            "rating_q025": 1344.3864461229668
        },
        "mistral-medium-2505": {
            "rating": 1351.7320765933446,
            "rating_q975": 1360.6404030937274,
            "rating_q025": 1342.8237500929617
        },
        "amazon-nova-experimental-chat-10-09": {
            "rating": 1351.5300161545638,
            "rating_q975": 1369.6041247692367,
            "rating_q025": 1333.4559075398909
        },
        "qwen2.5-max": {
            "rating": 1349.6337112395852,
            "rating_q975": 1359.4327049926867,
            "rating_q025": 1339.8347174864837
        },
        "deepseek-v3-0324": {
            "rating": 1348.9708401061546,
            "rating_q975": 1356.7564613265117,
            "rating_q025": 1341.1852188857974
        },
        "qwen3-235b-a22b": {
            "rating": 1348.9535312099906,
            "rating_q975": 1358.6455897007836,
            "rating_q025": 1339.2614727191976
        },
        "kimi-k2-0905-preview": {
            "rating": 1348.113975222756,
            "rating_q975": 1362.3697460792068,
            "rating_q025": 1333.858204366305
        },
        "deepseek-r1": {
            "rating": 1346.6243891580675,
            "rating_q975": 1360.3998305078785,
            "rating_q025": 1332.8489478082565
        },
        "qwen3-coder-480b-a35b-instruct": {
            "rating": 1344.6381491038192,
            "rating_q975": 1354.6204047706472,
            "rating_q025": 1334.6558934369912
        },
        "grok-3-mini-beta": {
            "rating": 1342.6228853450505,
            "rating_q975": 1352.8178955434828,
            "rating_q025": 1332.4278751466181
        },
        "step-3": {
            "rating": 1342.2662921811946,
            "rating_q975": 1359.1772387491665,
            "rating_q025": 1325.3553456132227
        },
        "grok-3-mini-high": {
            "rating": 1341.706844194154,
            "rating_q975": 1353.164072654903,
            "rating_q025": 1330.2496157334049
        },
        "claude-opus-4-20250514-thinking-16k": {
            "rating": 1341.5097430024368,
            "rating_q975": 1349.9612444179397,
            "rating_q025": 1333.058241586934
        },
        "kimi-k2-0711-preview": {
            "rating": 1341.2279615658838,
            "rating_q975": 1350.6513824961844,
            "rating_q025": 1331.8045406355832
        },
        "claude-opus-4-20250514": {
            "rating": 1335.3085741649722,
            "rating_q975": 1343.3333717325813,
            "rating_q025": 1327.2837765973632
        },
        "gemini-2.0-flash-lite-preview-02-05": {
            "rating": 1333.268731204983,
            "rating_q975": 1344.9189250644547,
            "rating_q025": 1321.6185373455112
        },
        "ring-flash-2.0": {
            "rating": 1327.07631061497,
            "rating_q975": 1343.2359800138074,
            "rating_q025": 1310.9166412161326
        },
        "mistral-small-2506": {
            "rating": 1326.6310497769787,
            "rating_q975": 1337.7730320776625,
            "rating_q025": 1315.4890674762948
        },
        "o1-2024-12-17": {
            "rating": 1326.495760018137,
            "rating_q975": 1337.9072481552676,
            "rating_q025": 1315.0842718810063
        },
        "glm-4-plus-0111": {
            "rating": 1326.0497301970067,
            "rating_q975": 1349.7313351281355,
            "rating_q025": 1302.368125265878
        },
        "step-1o-turbo-202506": {
            "rating": 1325.4472100681235,
            "rating_q975": 1341.1023314792583,
            "rating_q025": 1309.7920886569887
        },
        "o4-mini-2025-04-16": {
            "rating": 1324.276864288348,
            "rating_q975": 1332.0158558230883,
            "rating_q025": 1316.5378727536076
        },
        "hunyuan-turbos-20250226": {
            "rating": 1323.127271257855,
            "rating_q975": 1356.2149208369751,
            "rating_q025": 1290.0396216787349
        },
        "gpt-4.1-mini-2025-04-14": {
            "rating": 1321.9525212051897,
            "rating_q975": 1330.2842113032812,
            "rating_q025": 1313.6208311070982
        },
        "qwq-32b": {
            "rating": 1320.0461414939384,
            "rating_q975": 1329.9714853273317,
            "rating_q025": 1310.1207976605451
        },
        "minimax-m1": {
            "rating": 1319.4270747937953,
            "rating_q975": 1327.5729386781074,
            "rating_q025": 1311.2812109094832
        },
        "qwen3-32b": {
            "rating": 1317.6598261651961,
            "rating_q975": 1344.18691299272,
            "rating_q025": 1291.1327393376723
        },
        "claude-sonnet-4-20250514": {
            "rating": 1315.7835451943008,
            "rating_q975": 1324.0426720397265,
            "rating_q025": 1307.524418348875
        },
        "claude-sonnet-4-20250514-thinking-32k": {
            "rating": 1314.1160665970651,
            "rating_q975": 1322.7212064729833,
            "rating_q025": 1305.510926721147
        },
        "command-a-03-2025": {
            "rating": 1311.8404918180229,
            "rating_q975": 1319.165828198983,
            "rating_q025": 1304.5151554370627
        },
        "o3-mini-high": {
            "rating": 1311.4618354263441,
            "rating_q975": 1325.0649460606903,
            "rating_q025": 1297.858724791998
        },
        "gemma-3-4b-it": {
            "rating": 1310.544251443707,
            "rating_q975": 1341.1548323268178,
            "rating_q025": 1279.9336705605963
        },
        "nvidia-llama-3.3-nemotron-super-49b-v1.5": {
            "rating": 1308.6820903720904,
            "rating_q975": 1331.6845218422595,
            "rating_q025": 1285.6796589019214
        },
        "qwen3-30b-a3b": {
            "rating": 1308.2373429060588,
            "rating_q975": 1317.8560655979463,
            "rating_q025": 1298.6186202141712
        },
        "gpt-5-nano-high": {
            "rating": 1307.6852864345678,
            "rating_q975": 1323.3242970055467,
            "rating_q025": 1292.046275863589
        },
        "hunyuan-turbo-0110": {
            "rating": 1307.594147688572,
            "rating_q975": 1342.1516346282363,
            "rating_q025": 1273.036660748908
        },
        "deepseek-v3": {
            "rating": 1305.5230416797176,
            "rating_q975": 1317.7153643365227,
            "rating_q025": 1293.3307190229125
        },
        "glm-4.5v": {
            "rating": 1303.9671776765524,
            "rating_q975": 1323.492229794803,
            "rating_q025": 1284.4421255583018
        },
        "o1-preview": {
            "rating": 1303.020296243078,
            "rating_q975": 1313.3137248929875,
            "rating_q025": 1292.7268675931687
        },
        "qwen-plus-0125": {
            "rating": 1302.7036520816496,
            "rating_q975": 1325.9545696421794,
            "rating_q025": 1279.4527345211197
        },
        "llama-3.1-nemotron-ultra-253b-v1": {
            "rating": 1301.6203364771904,
            "rating_q975": 1335.8297774193172,
            "rating_q025": 1267.4108955350637
        },
        "gemma-3n-e4b-it": {
            "rating": 1297.3267276002337,
            "rating_q975": 1307.954609755677,
            "rating_q025": 1286.6988454447903
        },
        "o3-mini": {
            "rating": 1287.726712550274,
            "rating_q975": 1294.9395765878194,
            "rating_q025": 1280.5138485127286
        },
        "qwen2.5-plus-1127": {
            "rating": 1287.488896761662,
            "rating_q975": 1304.8234701884355,
            "rating_q025": 1270.1543233348887
        },
        "o1-mini": {
            "rating": 1285.4924283603104,
            "rating_q975": 1293.6804611563848,
            "rating_q025": 1277.304395564236
        },
        "llama-3.3-nemotron-49b-super-v1": {
            "rating": 1285.335830540784,
            "rating_q975": 1320.5490726100031,
            "rating_q025": 1250.1225884715648
        },
        "gemini-1.5-pro-002": {
            "rating": 1284.473787054767,
            "rating_q975": 1292.327374511064,
            "rating_q025": 1276.62019959847
        },
        "gpt-oss-20b": {
            "rating": 1282.2729102093463,
            "rating_q975": 1296.5268162495033,
            "rating_q025": 1268.0190041691892
        },
        "step-2-16k-exp-202412": {
            "rating": 1281.6749447746079,
            "rating_q975": 1306.5783961031987,
            "rating_q025": 1256.771493446017
        },
        "athene-v2-chat": {
            "rating": 1272.6687715862977,
            "rating_q975": 1283.6528735815814,
            "rating_q025": 1261.684669591014
        },
        "glm-4-plus": {
            "rating": 1271.4455580032725,
            "rating_q975": 1282.3668331952476,
            "rating_q025": 1260.5242828112973
        },
        "yi-lightning": {
            "rating": 1269.7730375445412,
            "rating_q975": 1280.583358057065,
            "rating_q025": 1258.9627170320175
        },
        "claude-3-7-sonnet-20250219-thinking-32k": {
            "rating": 1267.8415455567633,
            "rating_q975": 1276.5463832807034,
            "rating_q025": 1259.1367078328233
        },
        "gpt-4.1-nano-2025-04-14": {
            "rating": 1266.4680036378518,
            "rating_q975": 1288.5986920579185,
            "rating_q025": 1244.337315217785
        },
        "grok-2-2024-08-13": {
            "rating": 1263.7596314669117,
            "rating_q975": 1271.48288567743,
            "rating_q025": 1256.0363772563935
        },
        "gpt-4o-mini-2024-07-18": {
            "rating": 1263.308999013816,
            "rating_q975": 1270.6795118775087,
            "rating_q025": 1255.9384861501233
        },
        "gemini-1.5-flash-002": {
            "rating": 1262.9823336179734,
            "rating_q975": 1272.3519546280843,
            "rating_q025": 1253.6127126078625
        },
        "llama-4-maverick-17b-128e-instruct": {
            "rating": 1261.2221618773908,
            "rating_q975": 1269.5241014591654,
            "rating_q025": 1252.9202222956162
        },
        "llama-3.1-nemotron-70b-instruct": {
            "rating": 1260.6997933629946,
            "rating_q975": 1279.727388907219,
            "rating_q025": 1241.6721978187702
        },
        "llama-4-scout-17b-16e-instruct": {
            "rating": 1260.1830743263158,
            "rating_q975": 1269.3962284160725,
            "rating_q025": 1250.9699202365591
        },
        "gpt-4o-2024-05-13": {
            "rating": 1260.161719667738,
            "rating_q975": 1267.347207023563,
            "rating_q025": 1252.976232311913
        },
        "deepseek-v2.5-1210": {
            "rating": 1257.8633047917833,
            "rating_q975": 1279.329085914525,
            "rating_q025": 1236.3975236690417
        },
        "mistral-small-3.1-24b-instruct-2503": {
            "rating": 1257.3886281062414,
            "rating_q975": 1266.2907255930857,
            "rating_q025": 1248.4865306193972
        },
        "qwen-max-0919": {
            "rating": 1254.6744602373797,
            "rating_q975": 1267.2595164087406,
            "rating_q025": 1242.0894040660187
        },
        "hunyuan-standard-2025-02-10": {
            "rating": 1253.825041977651,
            "rating_q975": 1283.1401838061606,
            "rating_q025": 1224.5099001491412
        },
        "claude-3-5-sonnet-20241022": {
            "rating": 1253.2559470273654,
            "rating_q975": 1259.2476806652257,
            "rating_q025": 1247.2642133895051
        },
        "grok-2-mini-2024-08-13": {
            "rating": 1252.214416675512,
            "rating_q975": 1260.3044481714403,
            "rating_q025": 1244.1243851795837
        },
        "qwen2.5-72b-instruct": {
            "rating": 1251.5175403815751,
            "rating_q975": 1260.4903398520996,
            "rating_q025": 1242.5447409110507
        },
        "gemini-1.5-pro-001": {
            "rating": 1246.9561633886578,
            "rating_q975": 1255.5184256563798,
            "rating_q025": 1238.3939011209359
        },
        "deepseek-v2.5": {
            "rating": 1246.8825597732496,
            "rating_q975": 1258.1326046761765,
            "rating_q025": 1235.6325148703227
        },
        "llama-3.1-405b-instruct-fp8": {
            "rating": 1246.158347243369,
            "rating_q975": 1254.290641921581,
            "rating_q025": 1238.026052565157
        },
        "gemini-advanced-0514": {
            "rating": 1244.6732892160767,
            "rating_q975": 1254.9766104991343,
            "rating_q025": 1234.369967933019
        },
        "athene-70b-0725": {
            "rating": 1244.4195356014543,
            "rating_q975": 1257.6267434211802,
            "rating_q025": 1231.2123277817284
        },
        "llama-3.1-405b-instruct-bf16": {
            "rating": 1243.3612594994133,
            "rating_q975": 1252.1701196601314,
            "rating_q025": 1234.5523993386953
        },
        "llama-3.3-70b-instruct": {
            "rating": 1242.0548146043404,
            "rating_q975": 1249.4431093948485,
            "rating_q025": 1234.6665198138323
        },
        "hunyuan-large-2025-02-10": {
            "rating": 1240.3131987121265,
            "rating_q975": 1271.7648275379147,
            "rating_q025": 1208.8615698863382
        },
        "mistral-large-2411": {
            "rating": 1237.3824998580753,
            "rating_q975": 1247.8564435693584,
            "rating_q025": 1226.9085561467923
        },
        "llama-3.1-70b-instruct": {
            "rating": 1233.6702818499398,
            "rating_q975": 1241.8346318793733,
            "rating_q025": 1225.5059318205062
        },
        "claude-3-5-sonnet-20240620": {
            "rating": 1233.6058275193132,
            "rating_q975": 1241.460848258054,
            "rating_q025": 1225.7508067805722
        },
        "hunyuan-large-vision": {
            "rating": 1230.5556278830331,
            "rating_q975": 1252.5899961256157,
            "rating_q025": 1208.5212596404506
        },
        "gpt-4o-2024-08-06": {
            "rating": 1230.3315458474458,
            "rating_q975": 1239.1644125154378,
            "rating_q025": 1221.4986791794538
        },
        "amazon-nova-pro-v1.0": {
            "rating": 1227.3772244092165,
            "rating_q975": 1238.4971364302373,
            "rating_q025": 1216.2573123881957
        },
        "llama-3.1-tulu-3-70b": {
            "rating": 1225.0649171834066,
            "rating_q975": 1257.874798952756,
            "rating_q025": 1192.2550354140571
        },
        "mistral-large-2407": {
            "rating": 1224.5737114473932,
            "rating_q975": 1233.6302324844632,
            "rating_q025": 1215.517190410323
        },
        "gemini-1.5-flash-001": {
            "rating": 1224.057114421796,
            "rating_q975": 1233.0855693729573,
            "rating_q025": 1215.028659470635
        },
        "qwen2.5-coder-32b-instruct": {
            "rating": 1222.3028732026596,
            "rating_q975": 1244.250986396271,
            "rating_q025": 1200.3547600090483
        },
        "magistral-medium-2506": {
            "rating": 1221.2494919564535,
            "rating_q975": 1234.894218995176,
            "rating_q025": 1207.604764917731
        },
        "claude-3-5-haiku-20241022": {
            "rating": 1220.8988182574412,
            "rating_q975": 1227.7094312915137,
            "rating_q025": 1214.0882052233687
        },
        "gemma-2-9b-it-simpo": {
            "rating": 1220.878835340914,
            "rating_q975": 1238.0104897702317,
            "rating_q025": 1203.7471809115964
        },
        "claude-3-opus-20240229": {
            "rating": 1220.768971941758,
            "rating_q975": 1227.3167691077092,
            "rating_q025": 1214.221174775807
        },
        "gpt-4-turbo-2024-04-09": {
            "rating": 1220.544717887571,
            "rating_q975": 1228.6959127991197,
            "rating_q025": 1212.3935229760225
        },
        "amazon-nova-lite-v1.0": {
            "rating": 1217.2744900470889,
            "rating_q975": 1229.9771456277667,
            "rating_q025": 1204.571834466411
        },
        "reka-core-20240904": {
            "rating": 1216.1705147659486,
            "rating_q975": 1235.7157828241197,
            "rating_q025": 1196.6252467077775
        },
        "gpt-4-0125-preview": {
            "rating": 1215.4241225824728,
            "rating_q975": 1223.9889305354627,
            "rating_q025": 1206.859314629483
        },
        "llama-3.1-nemotron-51b-instruct": {
            "rating": 1214.038409357784,
            "rating_q975": 1241.1579481582608,
            "rating_q025": 1186.9188705573074
        },
        "command-r-plus-08-2024": {
            "rating": 1213.7194041152566,
            "rating_q975": 1230.7923026123758,
            "rating_q025": 1196.6465056181373
        },
        "gemini-1.5-flash-8b-001": {
            "rating": 1209.347178033252,
            "rating_q975": 1218.7510180724382,
            "rating_q025": 1199.9433379940658
        },
        "gpt-4-1106-preview": {
            "rating": 1209.2349106835118,
            "rating_q975": 1217.7227060349958,
            "rating_q025": 1200.7471153320278
        },
        "c4ai-aya-expanse-32b": {
            "rating": 1208.6565151035493,
            "rating_q975": 1219.391124758595,
            "rating_q025": 1197.9219054485036
        },
        "gemma-2-27b-it": {
            "rating": 1206.4415470397482,
            "rating_q975": 1213.665612437633,
            "rating_q025": 1199.2174816418635
        },
        "mistral-small-24b-instruct-2501": {
            "rating": 1205.7922182678146,
            "rating_q975": 1221.2873722467855,
            "rating_q025": 1190.2970642888438
        },
        "phi-4": {
            "rating": 1197.3363866004238,
            "rating_q975": 1209.2311121740595,
            "rating_q025": 1185.441661026788
        },
        "llama-3.1-tulu-3-8b": {
            "rating": 1195.0969619589014,
            "rating_q975": 1227.5212874333142,
            "rating_q025": 1162.6726364844885
        },
        "jamba-1.5-large": {
            "rating": 1195.0306255932787,
            "rating_q975": 1213.3834713426816,
            "rating_q025": 1176.677779843876
        },
        "reka-flash-20240904": {
            "rating": 1189.842065693126,
            "rating_q975": 1208.3800125828618,
            "rating_q025": 1171.30411880339
        },
        "command-r-plus": {
            "rating": 1188.9536045526838,
            "rating_q975": 1198.1418597051966,
            "rating_q025": 1179.765349400171
        },
        "gemma-2-9b-it": {
            "rating": 1188.4152366434628,
            "rating_q975": 1196.6272270778043,
            "rating_q025": 1180.2032462091213
        },
        "nemotron-4-340b-instruct": {
            "rating": 1183.481809455788,
            "rating_q975": 1196.5754607185734,
            "rating_q025": 1170.3881581930025
        },
        "amazon-nova-micro-v1.0": {
            "rating": 1180.7788957069238,
            "rating_q975": 1193.7484212801587,
            "rating_q025": 1167.8093701336888
        },
        "olmo-2-0325-32b-instruct": {
            "rating": 1178.4112044876492,
            "rating_q975": 1211.4143255089075,
            "rating_q025": 1145.408083466391
        },
        "hunyuan-standard-256k": {
            "rating": 1176.2839664644403,
            "rating_q975": 1208.0199497295314,
            "rating_q025": 1144.5479831993491
        },
        "c4ai-aya-expanse-8b": {
            "rating": 1174.928293634976,
            "rating_q975": 1192.8171782357551,
            "rating_q025": 1157.0394090341968
        },
        "glm-4-0520": {
            "rating": 1174.1824369154124,
            "rating_q975": 1191.410329985448,
            "rating_q025": 1156.9545438453767
        },
        "claude-3-sonnet-20240229": {
            "rating": 1172.442494278458,
            "rating_q975": 1181.1742136601165,
            "rating_q025": 1163.7107748967996
        },
        "ministral-8b-2410": {
            "rating": 1171.3014484014348,
            "rating_q975": 1194.7941763972124,
            "rating_q025": 1147.8087204056571
        },
        "llama-3-70b-instruct": {
            "rating": 1170.9149379878718,
            "rating_q975": 1178.7478700159018,
            "rating_q025": 1163.0820059598418
        },
        "llama-3.1-8b-instruct": {
            "rating": 1164.5571941151002,
            "rating_q975": 1173.2055765981202,
            "rating_q025": 1155.9088116320802
        },
        "claude-3-haiku-20240307": {
            "rating": 1156.2308045158163,
            "rating_q975": 1164.0946012353338,
            "rating_q025": 1148.3670077962988
        },
        "jamba-1.5-mini": {
            "rating": 1155.7638602250277,
            "rating_q975": 1173.9415694053296,
            "rating_q025": 1137.5861510447257
        },
        "command-r-08-2024": {
            "rating": 1155.5102282566131,
            "rating_q975": 1172.7967271089817,
            "rating_q025": 1138.2237294042445
        },
        "deepseek-coder-v2": {
            "rating": 1153.5329968857077,
            "rating_q975": 1167.9407918864601,
            "rating_q025": 1139.1252018849552
        },
        "qwen2-72b-instruct": {
            "rating": 1144.9613367027632,
            "rating_q975": 1155.4362341583617,
            "rating_q025": 1134.4864392471648
        },
        "gpt-4-0314": {
            "rating": 1143.4692263328664,
            "rating_q975": 1154.446901508931,
            "rating_q025": 1132.4915511568017
        },
        "granite-3.1-8b-instruct": {
            "rating": 1141.3828022776988,
            "rating_q975": 1175.06048786607,
            "rating_q025": 1107.7051166893277
        },
        "command-r": {
            "rating": 1139.895468559832,
            "rating_q975": 1150.1974477876493,
            "rating_q025": 1129.5934893320145
        },
        "qwen1.5-110b-chat": {
            "rating": 1138.8084754621304,
            "rating_q975": 1151.0622067367522,
            "rating_q025": 1126.5547441875087
        },
        "granite-3.1-2b-instruct": {
            "rating": 1137.7601843209254,
            "rating_q975": 1167.2297712129948,
            "rating_q025": 1108.290597428856
        },
        "reka-flash-21b-20240226-online": {
            "rating": 1133.7877924706843,
            "rating_q975": 1149.3403529708023,
            "rating_q025": 1118.2352319705662
        },
        "yi-1.5-34b-chat": {
            "rating": 1133.16690615862,
            "rating_q975": 1145.260601395356,
            "rating_q025": 1121.0732109218839
        },
        "gemini-pro-dev-api": {
            "rating": 1129.3158443691311,
            "rating_q975": 1146.38799657736,
            "rating_q025": 1112.2436921609024
        },
        "mistral-large-2402": {
            "rating": 1128.8883696562134,
            "rating_q975": 1138.8883391293757,
            "rating_q025": 1118.888400183051
        },
        "llama-3-8b-instruct": {
            "rating": 1125.6653680704821,
            "rating_q975": 1134.4404390133834,
            "rating_q025": 1116.8902971275809
        },
        "reka-flash-21b-20240226": {
            "rating": 1125.4923979653593,
            "rating_q975": 1138.5310256774846,
            "rating_q025": 1112.4537702532339
        },
        "gemma-2-2b-it": {
            "rating": 1124.387541432834,
            "rating_q975": 1133.3684890715447,
            "rating_q025": 1115.4065937941234
        },
        "gpt-4-0613": {
            "rating": 1120.3967963640005,
            "rating_q975": 1129.5474063340394,
            "rating_q025": 1111.2461863939616
        },
        "mistral-medium": {
            "rating": 1118.0730523303541,
            "rating_q975": 1130.6104708673847,
            "rating_q025": 1105.5356337933235
        },
        "mixtral-8x22b-instruct-v0.1": {
            "rating": 1117.2077111218846,
            "rating_q975": 1127.1057854327928,
            "rating_q025": 1107.3096368109764
        },
        "qwen1.5-72b-chat": {
            "rating": 1115.4519436824855,
            "rating_q975": 1126.8953341729139,
            "rating_q025": 1104.0085531920572
        },
        "internlm2_5-20b-chat": {
            "rating": 1113.630768638577,
            "rating_q975": 1130.3834150652276,
            "rating_q025": 1096.8781222119262
        },
        "starling-lm-7b-beta": {
            "rating": 1102.7042753563378,
            "rating_q975": 1118.900832353308,
            "rating_q025": 1086.5077183593676
        },
        "phi-3-medium-4k-instruct": {
            "rating": 1097.6876240704144,
            "rating_q975": 1109.6713457450214,
            "rating_q025": 1085.7039023958073
        },
        "qwq-32b-preview": {
            "rating": 1096.2483834253421,
            "rating_q975": 1128.4581990583413,
            "rating_q025": 1064.038567792343
        },
        "qwen1.5-32b-chat": {
            "rating": 1092.7116935959152,
            "rating_q975": 1106.2614804803263,
            "rating_q025": 1079.1619067115041
        },
        "yi-34b-chat": {
            "rating": 1086.978438581913,
            "rating_q975": 1103.636670115533,
            "rating_q025": 1070.320207048293
        },
        "zephyr-orpo-141b-A35b-v0.1": {
            "rating": 1086.8669791962247,
            "rating_q975": 1114.8542034379598,
            "rating_q025": 1058.8797549544897
        },
        "mixtral-8x7b-instruct-v0.1": {
            "rating": 1082.1859070731075,
            "rating_q975": 1091.8901829847982,
            "rating_q025": 1072.4816311614168
        },
        "qwen1.5-14b-chat": {
            "rating": 1081.8569758229446,
            "rating_q975": 1097.265273863527,
            "rating_q025": 1066.4486777823622
        },
        "llama-2-70b-chat": {
            "rating": 1081.042410586859,
            "rating_q975": 1092.9559341022546,
            "rating_q025": 1069.1288870714634
        },
        "gemini-pro": {
            "rating": 1080.9300486037196,
            "rating_q975": 1111.0366506623611,
            "rating_q025": 1050.823446545078
        },
        "llama2-70b-steerlm-chat": {
            "rating": 1076.6151997801976,
            "rating_q975": 1112.8009427345914,
            "rating_q025": 1040.4294568258038
        },
        "wizardlm-70b": {
            "rating": 1076.2520761083815,
            "rating_q975": 1100.301125439931,
            "rating_q025": 1052.203026776832
        },
        "tulu-2-dpo-70b": {
            "rating": 1075.6959549531211,
            "rating_q975": 1101.3301229469862,
            "rating_q025": 1050.061786959256
        },
        "phi-3-small-8k-instruct": {
            "rating": 1075.6316770580997,
            "rating_q975": 1089.1732552725273,
            "rating_q025": 1062.0900988436722
        },
        "gpt-3.5-turbo-0125": {
            "rating": 1074.416243840283,
            "rating_q975": 1083.9195019531994,
            "rating_q025": 1064.9129857273665
        },
        "openchat-3.5-0106": {
            "rating": 1072.6556262739182,
            "rating_q975": 1090.657699722762,
            "rating_q025": 1054.6535528250745
        },
        "llama-3.2-3b-instruct": {
            "rating": 1072.0685065906353,
            "rating_q975": 1091.762281099836,
            "rating_q025": 1052.3747320814346
        },
        "starling-lm-7b-alpha": {
            "rating": 1071.4138469597665,
            "rating_q975": 1091.8885891084208,
            "rating_q025": 1050.9391048111122
        },
        "dbrx-instruct-preview": {
            "rating": 1070.7160489403582,
            "rating_q975": 1083.898940296977,
            "rating_q025": 1057.5331575837395
        },
        "nous-hermes-2-mixtral-8x7b-dpo": {
            "rating": 1069.6531399609987,
            "rating_q975": 1105.1024838696358,
            "rating_q025": 1034.2037960523617
        },
        "qwen1.5-7b-chat": {
            "rating": 1062.870351035047,
            "rating_q975": 1090.930604582133,
            "rating_q025": 1034.810097487961
        },
        "gemma-1.1-7b-it": {
            "rating": 1061.364055610202,
            "rating_q975": 1074.128646209877,
            "rating_q025": 1048.5994650105272
        },
        "llama-2-13b-chat": {
            "rating": 1054.1051834958039,
            "rating_q975": 1070.143679752253,
            "rating_q025": 1038.0666872393547
        },
        "vicuna-33b": {
            "rating": 1052.3878696129582,
            "rating_q975": 1067.8904127614196,
            "rating_q025": 1036.8853264644968
        },
        "deepseek-llm-67b-chat": {
            "rating": 1046.0250337320185,
            "rating_q975": 1074.8323677990895,
            "rating_q025": 1017.2176996649474
        },
        "granite-3.0-8b-instruct": {
            "rating": 1039.098431146465,
            "rating_q975": 1061.5800277862447,
            "rating_q025": 1016.616834506685
        },
        "mistral-7b-instruct-v0.2": {
            "rating": 1036.4141808184663,
            "rating_q975": 1051.9393681635258,
            "rating_q025": 1020.8889934734067
        },
        "openchat-3.5": {
            "rating": 1034.6937858765878,
            "rating_q975": 1058.993144955186,
            "rating_q025": 1010.3944267979896
        },
        "granite-3.0-2b-instruct": {
            "rating": 1033.5101973743558,
            "rating_q975": 1055.0222264541867,
            "rating_q025": 1011.9981682945248
        },
        "codellama-34b-instruct": {
            "rating": 1031.9633800149918,
            "rating_q975": 1056.7249558422093,
            "rating_q025": 1007.2018041877743
        },
        "phi-3-mini-4k-instruct": {
            "rating": 1030.9967224090972,
            "rating_q975": 1044.384916445924,
            "rating_q025": 1017.6085283722703
        },
        "snowflake-arctic-instruct": {
            "rating": 1029.900441483553,
            "rating_q975": 1043.2569422778136,
            "rating_q025": 1016.5439406892926
        },
        "llama-2-7b-chat": {
            "rating": 1026.3821336184606,
            "rating_q975": 1044.3894095927762,
            "rating_q025": 1008.374857644145
        },
        "gemma-7b-it": {
            "rating": 1024.1434388792864,
            "rating_q975": 1045.7702406659914,
            "rating_q025": 1002.5166370925813
        },
        "openhermes-2.5-mistral-7b": {
            "rating": 1022.8181650445072,
            "rating_q975": 1052.8470689944813,
            "rating_q025": 992.789261094533
        },
        "phi-3-mini-4k-instruct-june-2024": {
            "rating": 1021.0257505361052,
            "rating_q975": 1037.7985744389655,
            "rating_q025": 1004.2529266332449
        },
        "solar-10.7b-instruct-v1.0": {
            "rating": 1019.5577712454124,
            "rating_q975": 1054.318631339425,
            "rating_q025": 984.7969111513996
        },
        "gpt-3.5-turbo-1106": {
            "rating": 1018.0229561053158,
            "rating_q975": 1037.3054673595366,
            "rating_q025": 998.7404448510949
        },
        "olmo-7b-instruct": {
            "rating": 1017.2509456789774,
            "rating_q975": 1043.5633076779213,
            "rating_q025": 990.9385836800333
        },
        "mpt-30b-chat": {
            "rating": 1006.6174665316782,
            "rating_q975": 1046.2240966294964,
            "rating_q025": 967.01083643386
        },
        "wizardlm-13b": {
            "rating": 1004.5725885150231,
            "rating_q975": 1029.3350909467156,
            "rating_q025": 979.8100860833307
        },
        "vicuna-13b": {
            "rating": 1003.9623199991279,
            "rating_q975": 1021.2210917713173,
            "rating_q025": 986.7035482269384
        },
        "qwen-14b-chat": {
            "rating": 998.9742562844369,
            "rating_q975": 1028.0929418905944,
            "rating_q025": 969.8555706782795
        },
        "zephyr-7b-beta": {
            "rating": 998.818821292214,
            "rating_q975": 1019.3641915827723,
            "rating_q025": 978.2734510016558
        },
        "llama-3.2-1b-instruct": {
            "rating": 998.2715262741935,
            "rating_q975": 1018.8220759197562,
            "rating_q025": 977.7209766286309
        },
        "gemma-2b-it": {
            "rating": 997.2010463152521,
            "rating_q975": 1025.4453995585845,
            "rating_q025": 968.9566930719199
        },
        "phi-3-mini-128k-instruct": {
            "rating": 989.2493435954035,
            "rating_q975": 1005.0861850082415,
            "rating_q025": 973.4125021825655
        },
        "gemma-1.1-2b-it": {
            "rating": 979.5312243734742,
            "rating_q975": 998.647900081501,
            "rating_q025": 960.4145486654473
        },
        "vicuna-7b": {
            "rating": 970.8033198750686,
            "rating_q975": 998.787914041893,
            "rating_q025": 942.8187257082442
        },
        "guanaco-33b": {
            "rating": 969.4930504370864,
            "rating_q975": 1009.7550877166484,
            "rating_q025": 929.2310131575243
        },
        "smollm2-1.7b-instruct": {
            "rating": 969.0300719556565,
            "rating_q975": 1014.5620572425273,
            "rating_q025": 923.4980866687856
        },
        "stripedhyena-nous-7b": {
            "rating": 968.6000355676423,
            "rating_q975": 998.4742199065499,
            "rating_q025": 938.7258512287347
        },
        "qwen1.5-4b-chat": {
            "rating": 963.9726144657297,
            "rating_q975": 987.5146101106283,
            "rating_q025": 940.4306188208312
        },
        "palm-2": {
            "rating": 957.2423902670147,
            "rating_q975": 981.7747069434342,
            "rating_q025": 932.7100735905951
        },
        "mistral-7b-instruct": {
            "rating": 950.7611178942632,
            "rating_q975": 974.7364764405362,
            "rating_q025": 926.7857593479902
        },
        "koala-13b": {
            "rating": 934.4615851978948,
            "rating_q975": 964.8468702187452,
            "rating_q025": 904.0763001770445
        },
        "chatglm3-6b": {
            "rating": 930.036142853611,
            "rating_q975": 962.4933892256088,
            "rating_q025": 897.5788964816131
        },
        "RWKV-4-Raven-14B": {
            "rating": 886.1316604288111,
            "rating_q975": 921.2508567546217,
            "rating_q025": 851.0124641030004
        },
        "chatglm2-6b": {
            "rating": 885.3082399340624,
            "rating_q975": 928.257324490294,
            "rating_q025": 842.3591553778308
        },
        "fastchat-t5-3b": {
            "rating": 865.6774381799278,
            "rating_q975": 905.6064780493172,
            "rating_q025": 825.7483983105384
        },
        "mpt-7b-chat": {
            "rating": 862.7100460905967,
            "rating_q975": 900.2178877207263,
            "rating_q025": 825.2022044604672
        },
        "chatglm-6b": {
            "rating": 843.5602382786574,
            "rating_q975": 882.6781274343598,
            "rating_q025": 804.442349122955
        },
        "oasst-pythia-12b": {
            "rating": 820.1154622952951,
            "rating_q975": 851.4976011807912,
            "rating_q025": 788.7333234097989
        },
        "alpaca-13b": {
            "rating": 810.5784464808195,
            "rating_q975": 845.7192748026667,
            "rating_q025": 775.4376181589722
        },
        "stablelm-tuned-alpha-7b": {
            "rating": 784.0750614226072,
            "rating_q975": 827.0202095410004,
            "rating_q025": 741.1299133042139
        },
        "dolly-v2-12b": {
            "rating": 731.9353923915431,
            "rating_q975": 778.7575652451897,
            "rating_q025": 685.1132195378966
        }
    },
    "industry_entertainment_and_sports_and_media": {
        "gemini-2.5-pro": {
            "rating": 1453.5067256020266,
            "rating_q975": 1460.5005561803368,
            "rating_q025": 1446.5128950237163
        },
        "grok-3-preview-02-24": {
            "rating": 1414.5391698090264,
            "rating_q975": 1422.6494316227663,
            "rating_q025": 1406.4289079952864
        },
        "chatgpt-4o-latest-20250326": {
            "rating": 1411.330114029001,
            "rating_q975": 1418.4078781680967,
            "rating_q025": 1404.2523498899052
        },
        "glm-4.6": {
            "rating": 1408.8651013039855,
            "rating_q975": 1422.7209146365424,
            "rating_q025": 1395.0092879714286
        },
        "claude-sonnet-4-5-20250929": {
            "rating": 1407.6610270376339,
            "rating_q975": 1424.8493586558768,
            "rating_q025": 1390.472695419391
        },
        "claude-sonnet-4-5-20250929-thinking-32k": {
            "rating": 1405.4730898220992,
            "rating_q975": 1418.2175348248923,
            "rating_q025": 1392.728644819306
        },
        "glm-4.5": {
            "rating": 1404.5759161429846,
            "rating_q975": 1413.7308882381187,
            "rating_q025": 1395.4209440478505
        },
        "qwen3-max-preview": {
            "rating": 1401.806285813839,
            "rating_q975": 1411.0841850813833,
            "rating_q025": 1392.5283865462945
        },
        "gpt-4.5-preview-2025-02-27": {
            "rating": 1398.985634193599,
            "rating_q975": 1410.7054144513106,
            "rating_q025": 1387.2658539358874
        },
        "deepseek-r1-0528": {
            "rating": 1398.7176735347673,
            "rating_q975": 1409.1700321222575,
            "rating_q025": 1388.2653149472771
        },
        "gemini-2.5-flash": {
            "rating": 1396.259097709259,
            "rating_q975": 1402.9893133988205,
            "rating_q025": 1389.5288820196977
        },
        "grok-4-0709": {
            "rating": 1393.578555163703,
            "rating_q975": 1401.4439805985858,
            "rating_q025": 1385.7131297288201
        },
        "deepseek-v3.1-thinking": {
            "rating": 1393.5389309976752,
            "rating_q975": 1405.980917156921,
            "rating_q025": 1381.0969448384294
        },
        "claude-opus-4-1-20250805-thinking-16k": {
            "rating": 1392.8564620129525,
            "rating_q975": 1401.7045602981964,
            "rating_q025": 1384.0083637277087
        },
        "gemini-2.5-flash-preview-09-2025": {
            "rating": 1392.2960664847924,
            "rating_q975": 1404.2681695200342,
            "rating_q025": 1380.3239634495505
        },
        "deepseek-v3.2-exp-thinking": {
            "rating": 1389.924942275901,
            "rating_q975": 1404.2609190911032,
            "rating_q025": 1375.5889654606988
        },
        "claude-opus-4-1-20250805": {
            "rating": 1387.453469769802,
            "rating_q975": 1395.2732043489902,
            "rating_q025": 1379.6337351906138
        },
        "gpt-5-high": {
            "rating": 1384.0278323233838,
            "rating_q975": 1392.5806971327272,
            "rating_q025": 1375.4749675140404
        },
        "mistral-medium-2508": {
            "rating": 1383.5997730610914,
            "rating_q975": 1392.1253523642497,
            "rating_q025": 1375.074193757933
        },
        "deepseek-v3.1-terminus-thinking": {
            "rating": 1383.3631735111258,
            "rating_q975": 1407.195895809699,
            "rating_q025": 1359.5304512125524
        },
        "deepseek-v3.1-terminus": {
            "rating": 1381.8234443732595,
            "rating_q975": 1405.1243406684737,
            "rating_q025": 1358.5225480780452
        },
        "qwen3-max-2025-09-23": {
            "rating": 1381.7597895126469,
            "rating_q975": 1395.9375285836738,
            "rating_q025": 1367.58205044162
        },
        "deepseek-v3.1": {
            "rating": 1381.2169185382581,
            "rating_q975": 1392.4858110871178,
            "rating_q025": 1369.9480259893985
        },
        "grok-4-fast": {
            "rating": 1378.9403712563817,
            "rating_q975": 1394.9589606243378,
            "rating_q025": 1362.9217818884256
        },
        "o3-2025-04-16": {
            "rating": 1377.0948828094713,
            "rating_q975": 1383.851659433402,
            "rating_q025": 1370.3381061855407
        },
        "qwen3-vl-235b-a22b-thinking": {
            "rating": 1370.8674291514783,
            "rating_q975": 1386.2260318751605,
            "rating_q025": 1355.508826427796
        },
        "qwen3-vl-235b-a22b-instruct": {
            "rating": 1367.379782299934,
            "rating_q975": 1382.4752209440355,
            "rating_q025": 1352.2843436558326
        },
        "gpt-5-chat": {
            "rating": 1365.9701802907762,
            "rating_q975": 1374.6337751814892,
            "rating_q025": 1357.306585400063
        },
        "qwen3-235b-a22b-instruct-2507": {
            "rating": 1365.1408523702316,
            "rating_q975": 1372.993080057344,
            "rating_q025": 1357.2886246831192
        },
        "claude-opus-4-20250514-thinking-16k": {
            "rating": 1364.738457670627,
            "rating_q975": 1372.724432824801,
            "rating_q025": 1356.752482516453
        },
        "qwen3-235b-a22b-thinking-2507": {
            "rating": 1363.5645158738323,
            "rating_q975": 1377.944051292068,
            "rating_q025": 1349.1849804555966
        },
        "gpt-4.1-2025-04-14": {
            "rating": 1363.5456060672363,
            "rating_q975": 1370.5583653686238,
            "rating_q025": 1356.532846765849
        },
        "claude-haiku-4-5-20251001": {
            "rating": 1362.881649820552,
            "rating_q975": 1376.7348953630278,
            "rating_q025": 1349.028404278076
        },
        "longcat-flash-chat": {
            "rating": 1361.017414830547,
            "rating_q975": 1374.0949975159215,
            "rating_q025": 1347.9398321451727
        },
        "o1-2024-12-17": {
            "rating": 1358.1953685642277,
            "rating_q975": 1366.5366335071774,
            "rating_q025": 1349.854103621278
        },
        "deepseek-v3-0324": {
            "rating": 1355.8247984357513,
            "rating_q975": 1362.7679456308892,
            "rating_q025": 1348.8816512406133
        },
        "mai-1-preview": {
            "rating": 1355.8244803695613,
            "rating_q975": 1366.4464730871953,
            "rating_q025": 1345.2024876519274
        },
        "gemini-2.5-flash-lite-preview-06-17-thinking": {
            "rating": 1354.2012337651283,
            "rating_q975": 1362.2214152206284,
            "rating_q025": 1346.1810523096283
        },
        "hunyuan-t1-20250711": {
            "rating": 1353.2709265568642,
            "rating_q975": 1372.3745027735442,
            "rating_q025": 1334.1673503401842
        },
        "gemini-2.5-flash-lite-preview-09-2025-no-thinking": {
            "rating": 1351.9458649653448,
            "rating_q975": 1363.6303942461493,
            "rating_q025": 1340.2613356845402
        },
        "qwen3-next-80b-a3b-instruct": {
            "rating": 1349.9048271857116,
            "rating_q975": 1359.9730309640963,
            "rating_q025": 1339.836623407327
        },
        "qwen3-235b-a22b-no-thinking": {
            "rating": 1348.8342926016874,
            "rating_q975": 1356.5130966709437,
            "rating_q025": 1341.155488532431
        },
        "claude-opus-4-20250514": {
            "rating": 1348.2531553892895,
            "rating_q975": 1355.7041039050944,
            "rating_q025": 1340.8022068734847
        },
        "deepseek-r1": {
            "rating": 1347.0125315366545,
            "rating_q975": 1356.6670862223934,
            "rating_q025": 1337.3579768509155
        },
        "kimi-k2-0905-preview": {
            "rating": 1343.213987471313,
            "rating_q975": 1356.6071702922814,
            "rating_q025": 1329.8208046503446
        },
        "gpt-5-mini-high": {
            "rating": 1341.3197725995365,
            "rating_q975": 1350.7281592621785,
            "rating_q025": 1331.9113859368945
        },
        "glm-4.5-air": {
            "rating": 1339.6018991943552,
            "rating_q975": 1348.0065874869927,
            "rating_q025": 1331.1972109017177
        },
        "qwen3-30b-a3b-instruct-2507": {
            "rating": 1335.5809462628115,
            "rating_q975": 1344.8274759232393,
            "rating_q025": 1326.3344166023837
        },
        "kimi-k2-0711-preview": {
            "rating": 1334.2568028380867,
            "rating_q975": 1342.9530893913322,
            "rating_q025": 1325.5605162848412
        },
        "hunyuan-turbos-20250416": {
            "rating": 1333.9918074871734,
            "rating_q975": 1347.1011827073885,
            "rating_q025": 1320.8824322669584
        },
        "mistral-medium-2505": {
            "rating": 1333.314739517165,
            "rating_q975": 1341.3886837958682,
            "rating_q025": 1325.2407952384617
        },
        "amazon-nova-experimental-chat-10-09": {
            "rating": 1331.416975457869,
            "rating_q975": 1348.414236817571,
            "rating_q025": 1314.419714098167
        },
        "o1-preview": {
            "rating": 1331.3862060150268,
            "rating_q975": 1340.7880204497917,
            "rating_q025": 1321.984391580262
        },
        "grok-3-mini-high": {
            "rating": 1331.2136903482533,
            "rating_q975": 1341.8514903148925,
            "rating_q025": 1320.575890381614
        },
        "claude-sonnet-4-20250514-thinking-32k": {
            "rating": 1330.3987028179442,
            "rating_q975": 1338.4555450287573,
            "rating_q025": 1322.3418606071311
        },
        "qwen2.5-max": {
            "rating": 1326.7001556741623,
            "rating_q975": 1334.1993415643872,
            "rating_q025": 1319.2009697839374
        },
        "grok-3-mini-beta": {
            "rating": 1326.6215925324425,
            "rating_q975": 1335.9721247132115,
            "rating_q025": 1317.2710603516734
        },
        "step-3": {
            "rating": 1326.1036967916707,
            "rating_q975": 1343.0918857447032,
            "rating_q025": 1309.1155078386382
        },
        "deepseek-v3": {
            "rating": 1324.1902234881866,
            "rating_q975": 1333.2510649930011,
            "rating_q025": 1315.129381983372
        },
        "gemma-3-27b-it": {
            "rating": 1320.1933899050887,
            "rating_q975": 1326.9266721219262,
            "rating_q025": 1313.4601076882511
        },
        "claude-sonnet-4-20250514": {
            "rating": 1318.174144712588,
            "rating_q975": 1325.954028677273,
            "rating_q025": 1310.394260747903
        },
        "qwen3-coder-480b-a35b-instruct": {
            "rating": 1315.877786665824,
            "rating_q975": 1325.0330855518034,
            "rating_q025": 1306.7224877798446
        },
        "qwen3-235b-a22b": {
            "rating": 1315.846188005548,
            "rating_q975": 1324.3800050464638,
            "rating_q025": 1307.312370964632
        },
        "o4-mini-2025-04-16": {
            "rating": 1312.3998361646547,
            "rating_q975": 1319.4555624332966,
            "rating_q025": 1305.344109896013
        },
        "claude-3-7-sonnet-20250219-thinking-32k": {
            "rating": 1311.018716255653,
            "rating_q975": 1318.6914219875334,
            "rating_q025": 1303.3460105237727
        },
        "qwen3-next-80b-a3b-thinking": {
            "rating": 1307.1417516048198,
            "rating_q975": 1319.0657318776364,
            "rating_q025": 1295.2177713320032
        },
        "minimax-m1": {
            "rating": 1307.0400361009547,
            "rating_q975": 1314.6801933778543,
            "rating_q025": 1299.3998788240551
        },
        "command-a-03-2025": {
            "rating": 1306.210574558954,
            "rating_q975": 1312.7127552972804,
            "rating_q025": 1299.7083938206276
        },
        "gemini-1.5-pro-002": {
            "rating": 1305.8446000261977,
            "rating_q975": 1312.2695545151553,
            "rating_q025": 1299.41964553724
        },
        "mistral-small-2506": {
            "rating": 1305.2460988425805,
            "rating_q975": 1315.292627611238,
            "rating_q025": 1295.199570073923
        },
        "glm-4.5v": {
            "rating": 1301.8627454742705,
            "rating_q975": 1320.7541929833721,
            "rating_q025": 1282.9712979651688
        },
        "gpt-4.1-mini-2025-04-14": {
            "rating": 1300.125143518049,
            "rating_q975": 1307.6925172580397,
            "rating_q025": 1292.5577697780584
        },
        "gemma-3-12b-it": {
            "rating": 1297.9101474810045,
            "rating_q975": 1319.1241960704522,
            "rating_q025": 1276.6960988915569
        },
        "gemini-2.0-flash-lite-preview-02-05": {
            "rating": 1297.2251925402697,
            "rating_q975": 1305.6941572370665,
            "rating_q025": 1288.756227843473
        },
        "ling-flash-2.0": {
            "rating": 1295.320927925814,
            "rating_q975": 1312.0830983919366,
            "rating_q025": 1278.5587574596914
        },
        "step-1o-turbo-202506": {
            "rating": 1292.3529679740548,
            "rating_q975": 1306.8870915824116,
            "rating_q025": 1277.818844365698
        },
        "step-2-16k-exp-202412": {
            "rating": 1291.6494396415715,
            "rating_q975": 1309.994222914365,
            "rating_q025": 1273.3046563687778
        },
        "glm-4-plus-0111": {
            "rating": 1291.4116533582176,
            "rating_q975": 1308.6799147797333,
            "rating_q025": 1274.1433919367018
        },
        "gpt-4o-2024-05-13": {
            "rating": 1290.0019516237285,
            "rating_q975": 1296.473130163176,
            "rating_q025": 1283.530773084281
        },
        "gpt-oss-120b": {
            "rating": 1289.5593996476741,
            "rating_q975": 1298.2270660743734,
            "rating_q025": 1280.8917332209749
        },
        "llama-3.3-nemotron-49b-super-v1": {
            "rating": 1287.6882016300758,
            "rating_q975": 1314.8953462005109,
            "rating_q025": 1260.4810570596408
        },
        "ring-flash-2.0": {
            "rating": 1287.674587484819,
            "rating_q975": 1303.947179514193,
            "rating_q025": 1271.401995455445
        },
        "o3-mini-high": {
            "rating": 1283.4318193935121,
            "rating_q975": 1293.6234889003103,
            "rating_q025": 1273.2401498867139
        },
        "grok-2-2024-08-13": {
            "rating": 1282.6804479699886,
            "rating_q975": 1289.3133439788603,
            "rating_q025": 1276.0475519611168
        },
        "nvidia-llama-3.3-nemotron-super-49b-v1.5": {
            "rating": 1281.4213835964738,
            "rating_q975": 1303.8942983486381,
            "rating_q025": 1258.9484688443094
        },
        "qwen3-32b": {
            "rating": 1279.980476601867,
            "rating_q975": 1300.7123505022555,
            "rating_q025": 1259.2486027014784
        },
        "claude-3-5-sonnet-20241022": {
            "rating": 1279.9273163104478,
            "rating_q975": 1285.2501017586665,
            "rating_q025": 1274.6045308622292
        },
        "qwq-32b": {
            "rating": 1278.5740131061536,
            "rating_q975": 1287.1873765438972,
            "rating_q025": 1269.96064966841
        },
        "llama-3.1-nemotron-ultra-253b-v1": {
            "rating": 1276.9701209235473,
            "rating_q975": 1300.5681436650566,
            "rating_q025": 1253.372098182038
        },
        "deepseek-v2.5-1210": {
            "rating": 1275.7100558281998,
            "rating_q975": 1291.631295235536,
            "rating_q025": 1259.7888164208634
        },
        "o3-mini": {
            "rating": 1273.4641072969748,
            "rating_q975": 1279.5927924196628,
            "rating_q025": 1267.3354221742868
        },
        "yi-lightning": {
            "rating": 1272.7192284139223,
            "rating_q975": 1282.621754344849,
            "rating_q025": 1262.8167024829957
        },
        "gpt-5-nano-high": {
            "rating": 1271.7612196586242,
            "rating_q975": 1287.9030729506733,
            "rating_q025": 1255.6193663665752
        },
        "gemini-advanced-0514": {
            "rating": 1271.19196461219,
            "rating_q975": 1280.47387387431,
            "rating_q025": 1261.9100553500703
        },
        "qwen-plus-0125": {
            "rating": 1270.369970523193,
            "rating_q975": 1287.0541268780894,
            "rating_q025": 1253.6858141682965
        },
        "gpt-4o-2024-08-06": {
            "rating": 1267.9088779510303,
            "rating_q975": 1275.8405668671808,
            "rating_q025": 1259.9771890348798
        },
        "hunyuan-turbo-0110": {
            "rating": 1266.8540562586577,
            "rating_q975": 1291.9618671068513,
            "rating_q025": 1241.746245410464
        },
        "gemma-3n-e4b-it": {
            "rating": 1263.4876358701515,
            "rating_q975": 1272.852727151354,
            "rating_q025": 1254.122544588949
        },
        "hunyuan-large-2025-02-10": {
            "rating": 1262.3213660209997,
            "rating_q975": 1284.4642336563966,
            "rating_q025": 1240.1784983856028
        },
        "qwen3-30b-a3b": {
            "rating": 1259.5824787055403,
            "rating_q975": 1268.3368091415496,
            "rating_q025": 1250.828148269531
        },
        "gpt-4-turbo-2024-04-09": {
            "rating": 1258.4711822985432,
            "rating_q975": 1265.6111370783399,
            "rating_q025": 1251.3312275187466
        },
        "o1-mini": {
            "rating": 1257.0119043740715,
            "rating_q975": 1263.8520206008347,
            "rating_q025": 1250.1717881473082
        },
        "gpt-4o-mini-2024-07-18": {
            "rating": 1253.7244948481998,
            "rating_q975": 1259.8631571818696,
            "rating_q025": 1247.58583251453
        },
        "hunyuan-turbos-20250226": {
            "rating": 1253.3802641755415,
            "rating_q975": 1279.0119234092188,
            "rating_q025": 1227.7486049418642
        },
        "llama-4-maverick-17b-128e-instruct": {
            "rating": 1252.7288943811454,
            "rating_q975": 1260.2654874403206,
            "rating_q025": 1245.1923013219703
        },
        "gemini-1.5-pro-001": {
            "rating": 1251.8522852282085,
            "rating_q975": 1259.3162319573314,
            "rating_q025": 1244.3883384990856
        },
        "gemini-1.5-flash-002": {
            "rating": 1251.684087293636,
            "rating_q975": 1259.5731360985394,
            "rating_q025": 1243.7950384887324
        },
        "mistral-small-3.1-24b-instruct-2503": {
            "rating": 1251.5320847616367,
            "rating_q975": 1259.6035541736483,
            "rating_q025": 1243.4606153496252
        },
        "llama-3.1-405b-instruct-fp8": {
            "rating": 1250.3403333293027,
            "rating_q975": 1257.297977876602,
            "rating_q025": 1243.3826887820032
        },
        "glm-4-plus": {
            "rating": 1250.2703453046893,
            "rating_q975": 1260.0763875884813,
            "rating_q025": 1240.4643030208972
        },
        "llama-3.1-nemotron-70b-instruct": {
            "rating": 1249.4228335915568,
            "rating_q975": 1268.0433855886,
            "rating_q025": 1230.8022815945137
        },
        "llama-4-scout-17b-16e-instruct": {
            "rating": 1246.4008413295169,
            "rating_q975": 1254.880049855617,
            "rating_q025": 1237.9216328034167
        },
        "magistral-medium-2506": {
            "rating": 1245.571904851785,
            "rating_q975": 1258.882088058456,
            "rating_q025": 1232.2617216451138
        },
        "qwen2.5-plus-1127": {
            "rating": 1244.820149328345,
            "rating_q975": 1257.6730368208055,
            "rating_q025": 1231.9672618358845
        },
        "gpt-4.1-nano-2025-04-14": {
            "rating": 1244.2401913804192,
            "rating_q975": 1261.5514188399136,
            "rating_q025": 1226.9289639209248
        },
        "gpt-4-1106-preview": {
            "rating": 1243.0725022869517,
            "rating_q975": 1250.5337092913492,
            "rating_q025": 1235.6112952825542
        },
        "mistral-large-2407": {
            "rating": 1242.2297743108147,
            "rating_q975": 1250.1498837012941,
            "rating_q025": 1234.3096649203353
        },
        "llama-3.3-70b-instruct": {
            "rating": 1241.8767465738417,
            "rating_q975": 1247.896928981587,
            "rating_q025": 1235.8565641660964
        },
        "llama-3.1-405b-instruct-bf16": {
            "rating": 1241.1855621494892,
            "rating_q975": 1248.1809168769555,
            "rating_q025": 1234.190207422023
        },
        "llama-3.1-tulu-3-70b": {
            "rating": 1240.7047267475332,
            "rating_q975": 1263.1576925125828,
            "rating_q025": 1218.2517609824836
        },
        "qwen-max-0919": {
            "rating": 1240.5206699428093,
            "rating_q975": 1252.1209458571511,
            "rating_q025": 1228.9203940284674
        },
        "claude-3-5-sonnet-20240620": {
            "rating": 1239.18752098583,
            "rating_q975": 1246.1397845033355,
            "rating_q025": 1232.2352574683243
        },
        "gpt-4-0125-preview": {
            "rating": 1237.5108966019018,
            "rating_q975": 1245.1514305369355,
            "rating_q025": 1229.870362666868
        },
        "gemma-3-4b-it": {
            "rating": 1233.7457846608268,
            "rating_q975": 1254.2592987890375,
            "rating_q025": 1213.232270532616
        },
        "grok-2-mini-2024-08-13": {
            "rating": 1233.2606205705333,
            "rating_q975": 1240.2051775024113,
            "rating_q025": 1226.3160636386554
        },
        "athene-70b-0725": {
            "rating": 1232.7007500174773,
            "rating_q975": 1243.0573640025393,
            "rating_q025": 1222.3441360324152
        },
        "mistral-large-2411": {
            "rating": 1230.731053153601,
            "rating_q975": 1238.8105872387512,
            "rating_q025": 1222.6515190684506
        },
        "deepseek-v2.5": {
            "rating": 1230.5360203765392,
            "rating_q975": 1240.322634390169,
            "rating_q025": 1220.7494063629094
        },
        "llama-3.1-70b-instruct": {
            "rating": 1230.4589677952413,
            "rating_q975": 1237.4793919979554,
            "rating_q025": 1223.4385435925271
        },
        "athene-v2-chat": {
            "rating": 1228.8466406061157,
            "rating_q975": 1237.5689191301203,
            "rating_q025": 1220.124362082111
        },
        "olmo-2-0325-32b-instruct": {
            "rating": 1224.1879907457514,
            "rating_q975": 1247.573406452092,
            "rating_q025": 1200.8025750394108
        },
        "command-r-plus-08-2024": {
            "rating": 1223.3927890349034,
            "rating_q975": 1237.909634051904,
            "rating_q025": 1208.8759440179028
        },
        "hunyuan-large-vision": {
            "rating": 1222.7578130997665,
            "rating_q975": 1242.6817961671984,
            "rating_q025": 1202.8338300323346
        },
        "hunyuan-standard-2025-02-10": {
            "rating": 1222.6897048669482,
            "rating_q975": 1244.6141687818795,
            "rating_q025": 1200.765240952017
        },
        "claude-3-5-haiku-20241022": {
            "rating": 1222.6501101282954,
            "rating_q975": 1228.2882960297773,
            "rating_q025": 1217.0119242268136
        },
        "claude-3-opus-20240229": {
            "rating": 1220.4449341391928,
            "rating_q975": 1226.1130820576536,
            "rating_q025": 1214.776786220732
        },
        "gpt-oss-20b": {
            "rating": 1219.5101472022561,
            "rating_q975": 1234.0802810251819,
            "rating_q025": 1204.9400133793304
        },
        "jamba-1.5-large": {
            "rating": 1218.505140746798,
            "rating_q975": 1233.811941330903,
            "rating_q025": 1203.1983401626928
        },
        "gemma-2-9b-it-simpo": {
            "rating": 1215.0195584383748,
            "rating_q975": 1229.0370837767093,
            "rating_q025": 1201.0020331000403
        },
        "gemma-2-27b-it": {
            "rating": 1213.0212704113796,
            "rating_q975": 1219.0692179242258,
            "rating_q025": 1206.9733228985335
        },
        "qwen2.5-72b-instruct": {
            "rating": 1211.594973123738,
            "rating_q975": 1219.3228840088123,
            "rating_q025": 1203.867062238664
        },
        "amazon-nova-pro-v1.0": {
            "rating": 1210.0345005724153,
            "rating_q975": 1218.4250384029724,
            "rating_q025": 1201.643962741858
        },
        "gemini-1.5-flash-001": {
            "rating": 1208.2541859545952,
            "rating_q975": 1215.928526028395,
            "rating_q025": 1200.5798458807953
        },
        "nemotron-4-340b-instruct": {
            "rating": 1208.084828923882,
            "rating_q975": 1219.3306873714253,
            "rating_q025": 1196.8389704763388
        },
        "reka-core-20240904": {
            "rating": 1207.4282408983327,
            "rating_q975": 1224.3379973389465,
            "rating_q025": 1190.5184844577188
        },
        "llama-3-70b-instruct": {
            "rating": 1195.6764626048853,
            "rating_q975": 1202.576164118727,
            "rating_q025": 1188.7767610910435
        },
        "llama-3.1-nemotron-51b-instruct": {
            "rating": 1190.8748597646331,
            "rating_q975": 1214.8004996103011,
            "rating_q025": 1166.9492199189651
        },
        "command-r-plus": {
            "rating": 1189.9758744375085,
            "rating_q975": 1198.0135687827603,
            "rating_q025": 1181.9381800922567
        },
        "glm-4-0520": {
            "rating": 1185.9025535351975,
            "rating_q975": 1200.27707446118,
            "rating_q025": 1171.528032609215
        },
        "gemini-1.5-flash-8b-001": {
            "rating": 1185.4546333283374,
            "rating_q975": 1193.5975325041948,
            "rating_q025": 1177.31173415248
        },
        "gemma-2-9b-it": {
            "rating": 1185.3262557215758,
            "rating_q975": 1191.994438243188,
            "rating_q025": 1178.6580731999636
        },
        "gpt-4-0314": {
            "rating": 1184.8500369152825,
            "rating_q975": 1194.363442725276,
            "rating_q025": 1175.3366311052891
        },
        "mistral-small-24b-instruct-2501": {
            "rating": 1184.4406290161658,
            "rating_q975": 1195.7556128789797,
            "rating_q025": 1173.1256451533518
        },
        "c4ai-aya-expanse-32b": {
            "rating": 1183.998277718173,
            "rating_q975": 1192.9532772810842,
            "rating_q025": 1175.043278155262
        },
        "gpt-4-0613": {
            "rating": 1180.5689884898702,
            "rating_q975": 1188.442681016938,
            "rating_q025": 1172.6952959628024
        },
        "reka-flash-20240904": {
            "rating": 1177.4031490761313,
            "rating_q975": 1193.9942295411367,
            "rating_q025": 1160.8120686111258
        },
        "amazon-nova-lite-v1.0": {
            "rating": 1176.3359179868512,
            "rating_q975": 1186.1401771539568,
            "rating_q025": 1166.5316588197456
        },
        "claude-3-sonnet-20240229": {
            "rating": 1171.6961187506456,
            "rating_q975": 1179.313750068864,
            "rating_q025": 1164.0784874324272
        },
        "qwen2-72b-instruct": {
            "rating": 1166.021325340293,
            "rating_q975": 1174.9369875364337,
            "rating_q025": 1157.1056631441525
        },
        "amazon-nova-micro-v1.0": {
            "rating": 1163.4924897165265,
            "rating_q975": 1173.4017101986428,
            "rating_q025": 1153.5832692344102
        },
        "command-r-08-2024": {
            "rating": 1162.85037857915,
            "rating_q975": 1176.911571598785,
            "rating_q025": 1148.7891855595149
        },
        "phi-4": {
            "rating": 1162.1238306683445,
            "rating_q975": 1170.951698953712,
            "rating_q025": 1153.295962382977
        },
        "llama-3.1-tulu-3-8b": {
            "rating": 1161.122033604218,
            "rating_q975": 1184.0820966970264,
            "rating_q025": 1138.1619705114094
        },
        "jamba-1.5-mini": {
            "rating": 1158.4309904375805,
            "rating_q975": 1173.4950266387063,
            "rating_q025": 1143.3669542364546
        },
        "hunyuan-standard-256k": {
            "rating": 1153.4130237166576,
            "rating_q975": 1182.4700905562156,
            "rating_q025": 1124.3559568770995
        },
        "claude-3-haiku-20240307": {
            "rating": 1152.2274638125111,
            "rating_q975": 1159.162678199446,
            "rating_q025": 1145.2922494255763
        },
        "mistral-large-2402": {
            "rating": 1151.2753872496846,
            "rating_q975": 1160.0178303044497,
            "rating_q025": 1142.5329441949195
        },
        "c4ai-aya-expanse-8b": {
            "rating": 1150.7129661270035,
            "rating_q975": 1164.2547800536945,
            "rating_q025": 1137.1711522003125
        },
        "qwen2.5-coder-32b-instruct": {
            "rating": 1150.6152375064648,
            "rating_q975": 1169.1384933284426,
            "rating_q025": 1132.091981684487
        },
        "llama-3.1-8b-instruct": {
            "rating": 1145.2965283326669,
            "rating_q975": 1152.8701240428175,
            "rating_q025": 1137.7229326225163
        },
        "command-r": {
            "rating": 1142.6626454180903,
            "rating_q975": 1151.6732831945355,
            "rating_q025": 1133.652007641645
        },
        "ministral-8b-2410": {
            "rating": 1141.2938303724882,
            "rating_q975": 1161.6371828506703,
            "rating_q025": 1120.950477894306
        },
        "mixtral-8x22b-instruct-v0.1": {
            "rating": 1139.479033066711,
            "rating_q975": 1148.1625182780583,
            "rating_q025": 1130.7955478553638
        },
        "qwen1.5-110b-chat": {
            "rating": 1139.092982377532,
            "rating_q975": 1149.958043769341,
            "rating_q025": 1128.2279209857231
        },
        "mistral-medium": {
            "rating": 1138.0135274139056,
            "rating_q975": 1148.5207830307459,
            "rating_q025": 1127.5062717970654
        },
        "reka-flash-21b-20240226-online": {
            "rating": 1134.525984807096,
            "rating_q975": 1148.565249481715,
            "rating_q025": 1120.4867201324769
        },
        "llama-3-8b-instruct": {
            "rating": 1132.1084794005828,
            "rating_q975": 1139.6266989961277,
            "rating_q025": 1124.590259805038
        },
        "zephyr-orpo-141b-A35b-v0.1": {
            "rating": 1128.6348377680158,
            "rating_q975": 1151.7041225349908,
            "rating_q025": 1105.5655530010408
        },
        "gemma-2-2b-it": {
            "rating": 1127.3084069824172,
            "rating_q975": 1134.7183598138818,
            "rating_q025": 1119.8984541509526
        },
        "qwen1.5-72b-chat": {
            "rating": 1125.7172815129259,
            "rating_q975": 1135.5454160898555,
            "rating_q025": 1115.8891469359962
        },
        "deepseek-coder-v2": {
            "rating": 1122.7976149031633,
            "rating_q975": 1135.3562354338885,
            "rating_q025": 1110.2389943724381
        },
        "yi-1.5-34b-chat": {
            "rating": 1120.9997057019782,
            "rating_q975": 1131.437008625333,
            "rating_q025": 1110.5624027786234
        },
        "tulu-2-dpo-70b": {
            "rating": 1116.1200334261948,
            "rating_q975": 1136.2534349746254,
            "rating_q025": 1095.9866318777642
        },
        "qwq-32b-preview": {
            "rating": 1115.530928487117,
            "rating_q975": 1141.8737402294487,
            "rating_q025": 1089.1881167447855
        },
        "wizardlm-70b": {
            "rating": 1112.8525762685217,
            "rating_q975": 1130.2939879290366,
            "rating_q025": 1095.4111646080069
        },
        "granite-3.1-8b-instruct": {
            "rating": 1111.4531264184225,
            "rating_q975": 1136.6057156755066,
            "rating_q025": 1086.3005371613383
        },
        "yi-34b-chat": {
            "rating": 1107.0972120034965,
            "rating_q975": 1120.332460676532,
            "rating_q025": 1093.8619633304609
        },
        "mixtral-8x7b-instruct-v0.1": {
            "rating": 1105.792201233553,
            "rating_q975": 1113.926416883556,
            "rating_q025": 1097.65798558355
        },
        "granite-3.1-2b-instruct": {
            "rating": 1105.212786757715,
            "rating_q975": 1129.2760912661724,
            "rating_q025": 1081.1494822492577
        },
        "internlm2_5-20b-chat": {
            "rating": 1103.5251883085666,
            "rating_q975": 1119.1588942708734,
            "rating_q025": 1087.8914823462599
        },
        "vicuna-33b": {
            "rating": 1103.4789122315196,
            "rating_q975": 1115.399461553411,
            "rating_q025": 1091.5583629096284
        },
        "reka-flash-21b-20240226": {
            "rating": 1101.6478165497979,
            "rating_q975": 1113.2685472096964,
            "rating_q025": 1090.0270858898994
        },
        "gemini-pro-dev-api": {
            "rating": 1099.993467174853,
            "rating_q975": 1113.9011369862453,
            "rating_q025": 1086.0857973634609
        },
        "dbrx-instruct-preview": {
            "rating": 1099.2682634454047,
            "rating_q975": 1110.5212932121356,
            "rating_q025": 1088.015233678674
        },
        "openchat-3.5": {
            "rating": 1096.9615257808532,
            "rating_q975": 1114.413371482803,
            "rating_q025": 1079.5096800789033
        },
        "gpt-3.5-turbo-0125": {
            "rating": 1089.3214064462634,
            "rating_q975": 1097.6429365541944,
            "rating_q025": 1080.9998763383323
        },
        "gemini-pro": {
            "rating": 1085.5653121205387,
            "rating_q975": 1106.1913736839465,
            "rating_q025": 1064.939250557131
        },
        "starling-lm-7b-beta": {
            "rating": 1085.4032296548553,
            "rating_q975": 1099.997959035411,
            "rating_q025": 1070.8085002742996
        },
        "llama-3.2-3b-instruct": {
            "rating": 1084.2540827193793,
            "rating_q975": 1101.8687703275275,
            "rating_q025": 1066.6393951112311
        },
        "starling-lm-7b-alpha": {
            "rating": 1083.0586272381624,
            "rating_q975": 1098.3613693490702,
            "rating_q025": 1067.7558851272547
        },
        "phi-3-medium-4k-instruct": {
            "rating": 1082.2744624940392,
            "rating_q975": 1092.5222128376622,
            "rating_q025": 1072.0267121504162
        },
        "qwen1.5-32b-chat": {
            "rating": 1081.672988642197,
            "rating_q975": 1093.659032731365,
            "rating_q025": 1069.686944553029
        },
        "wizardlm-13b": {
            "rating": 1075.6481331366003,
            "rating_q975": 1094.2436288662025,
            "rating_q025": 1057.0526374069982
        },
        "openchat-3.5-0106": {
            "rating": 1074.8001324932097,
            "rating_q975": 1089.2470177547832,
            "rating_q025": 1060.3532472316363
        },
        "openhermes-2.5-mistral-7b": {
            "rating": 1074.521744447488,
            "rating_q975": 1095.7233835359061,
            "rating_q025": 1053.3201053590697
        },
        "guanaco-33b": {
            "rating": 1073.3489369226218,
            "rating_q975": 1102.8485506633199,
            "rating_q025": 1043.8493231819236
        },
        "llama2-70b-steerlm-chat": {
            "rating": 1069.6827421891358,
            "rating_q975": 1094.525996050753,
            "rating_q025": 1044.8394883275184
        },
        "snowflake-arctic-instruct": {
            "rating": 1069.5647543455373,
            "rating_q975": 1081.309941495969,
            "rating_q025": 1057.8195671951055
        },
        "qwen1.5-14b-chat": {
            "rating": 1069.3194022856437,
            "rating_q975": 1082.9016088267754,
            "rating_q025": 1055.737195744512
        },
        "nous-hermes-2-mixtral-8x7b-dpo": {
            "rating": 1067.269210503463,
            "rating_q975": 1091.165409199013,
            "rating_q025": 1043.373011807913
        },
        "llama-2-70b-chat": {
            "rating": 1064.9404785109177,
            "rating_q975": 1074.7679480179347,
            "rating_q025": 1055.1130090039007
        },
        "zephyr-7b-beta": {
            "rating": 1063.2068239391713,
            "rating_q975": 1079.221550490891,
            "rating_q025": 1047.1920973874514
        },
        "granite-3.0-8b-instruct": {
            "rating": 1062.2314453401634,
            "rating_q975": 1082.2591950292017,
            "rating_q025": 1042.2036956511251
        },
        "deepseek-llm-67b-chat": {
            "rating": 1062.2182876176598,
            "rating_q975": 1084.001846593386,
            "rating_q025": 1040.4347286419336
        },
        "falcon-180b-chat": {
            "rating": 1059.0452815239257,
            "rating_q975": 1097.8499107472385,
            "rating_q025": 1020.240652300613
        },
        "solar-10.7b-instruct-v1.0": {
            "rating": 1059.0047957832164,
            "rating_q975": 1083.7828702612128,
            "rating_q025": 1034.22672130522
        },
        "mistral-7b-instruct-v0.2": {
            "rating": 1058.5162747686443,
            "rating_q975": 1070.5963684208882,
            "rating_q025": 1046.4361811164003
        },
        "phi-3-small-8k-instruct": {
            "rating": 1056.4173565386036,
            "rating_q975": 1068.712394141296,
            "rating_q025": 1044.1223189359112
        },
        "mpt-30b-chat": {
            "rating": 1055.705225143872,
            "rating_q975": 1085.1021122624873,
            "rating_q025": 1026.3083380252567
        },
        "gemma-1.1-7b-it": {
            "rating": 1051.1384487437722,
            "rating_q975": 1062.3431952802532,
            "rating_q025": 1039.9337022072912
        },
        "dolphin-2.2.1-mistral-7b": {
            "rating": 1050.2913706172899,
            "rating_q975": 1084.652825717042,
            "rating_q025": 1015.9299155175376
        },
        "zephyr-7b-alpha": {
            "rating": 1048.9218380851646,
            "rating_q975": 1081.5931242931038,
            "rating_q025": 1016.2505518772253
        },
        "llama-2-13b-chat": {
            "rating": 1048.4154165858135,
            "rating_q975": 1060.7965359388613,
            "rating_q025": 1036.0342972327658
        },
        "granite-3.0-2b-instruct": {
            "rating": 1038.2369947549448,
            "rating_q975": 1058.7027857537676,
            "rating_q025": 1017.7712037561221
        },
        "gpt-3.5-turbo-1106": {
            "rating": 1033.16257272881,
            "rating_q975": 1048.4977480036648,
            "rating_q025": 1017.827397453955
        },
        "phi-3-mini-4k-instruct-june-2024": {
            "rating": 1031.4561839281287,
            "rating_q975": 1045.146134596427,
            "rating_q025": 1017.7662332598305
        },
        "vicuna-13b": {
            "rating": 1031.4359174962347,
            "rating_q975": 1043.9387012135858,
            "rating_q025": 1018.9331337788834
        },
        "qwen1.5-7b-chat": {
            "rating": 1030.5849239321974,
            "rating_q975": 1053.1445473652038,
            "rating_q025": 1008.0253004991908
        },
        "llama-3.2-1b-instruct": {
            "rating": 1025.1473513928293,
            "rating_q975": 1043.5614872086453,
            "rating_q025": 1006.7332155770132
        },
        "llama-2-7b-chat": {
            "rating": 1020.3250177032182,
            "rating_q975": 1033.8433474675533,
            "rating_q025": 1006.8066879388832
        },
        "phi-3-mini-4k-instruct": {
            "rating": 1020.022636949064,
            "rating_q975": 1032.0267786002516,
            "rating_q025": 1008.0184952978763
        },
        "vicuna-7b": {
            "rating": 1017.1254190554398,
            "rating_q975": 1034.7605913756072,
            "rating_q025": 999.4902467352725
        },
        "codellama-34b-instruct": {
            "rating": 1015.012426098819,
            "rating_q975": 1031.9249011318257,
            "rating_q025": 998.0999510658123
        },
        "stripedhyena-nous-7b": {
            "rating": 1011.9721740812803,
            "rating_q975": 1033.372210417843,
            "rating_q025": 990.5721377447176
        },
        "smollm2-1.7b-instruct": {
            "rating": 1011.6399498473365,
            "rating_q975": 1045.0912266463292,
            "rating_q025": 978.1886730483437
        },
        "phi-3-mini-128k-instruct": {
            "rating": 1009.9338096251952,
            "rating_q975": 1023.7201935476887,
            "rating_q025": 996.1474257027016
        },
        "gemma-7b-it": {
            "rating": 1002.0534570752685,
            "rating_q975": 1019.6982531486223,
            "rating_q025": 984.4086610019148
        },
        "mistral-7b-instruct": {
            "rating": 1000.1125677033809,
            "rating_q975": 1017.6286014578116,
            "rating_q025": 982.5965339489503
        },
        "qwen-14b-chat": {
            "rating": 997.0990942606325,
            "rating_q975": 1018.5336132137837,
            "rating_q025": 975.6645753074812
        },
        "palm-2": {
            "rating": 992.7577274549246,
            "rating_q975": 1010.2354842525616,
            "rating_q025": 975.2799706572877
        },
        "olmo-7b-instruct": {
            "rating": 991.4854796458154,
            "rating_q975": 1012.2903554409245,
            "rating_q025": 970.6806038507063
        },
        "gemma-1.1-2b-it": {
            "rating": 980.7862417007136,
            "rating_q975": 997.4339875518885,
            "rating_q025": 964.1384958495387
        },
        "gemma-2b-it": {
            "rating": 968.1626979714615,
            "rating_q975": 990.9675084570787,
            "rating_q025": 945.3578874858443
        },
        "qwen1.5-4b-chat": {
            "rating": 953.1764866523092,
            "rating_q975": 971.3956510577874,
            "rating_q025": 934.957322246831
        },
        "koala-13b": {
            "rating": 945.362480554877,
            "rating_q975": 965.9330149273519,
            "rating_q025": 924.7919461824022
        },
        "gpt4all-13b-snoozy": {
            "rating": 941.9558993709048,
            "rating_q975": 980.3678280745337,
            "rating_q025": 903.543970667276
        },
        "alpaca-13b": {
            "rating": 932.3257351383976,
            "rating_q975": 954.583695536145,
            "rating_q025": 910.0677747406502
        },
        "chatglm3-6b": {
            "rating": 929.0403380416753,
            "rating_q975": 952.8819097710962,
            "rating_q025": 905.1987663122545
        },
        "mpt-7b-chat": {
            "rating": 928.6898727127082,
            "rating_q975": 952.9545569102137,
            "rating_q025": 904.4251885152026
        },
        "chatglm2-6b": {
            "rating": 922.3793308539764,
            "rating_q975": 951.0335677419492,
            "rating_q025": 893.7250939660036
        },
        "RWKV-4-Raven-14B": {
            "rating": 903.816562494231,
            "rating_q975": 926.0071996435988,
            "rating_q025": 881.6259253448632
        },
        "oasst-pythia-12b": {
            "rating": 885.6187541174088,
            "rating_q975": 906.8671917529698,
            "rating_q025": 864.3703164818478
        },
        "fastchat-t5-3b": {
            "rating": 860.5683182946361,
            "rating_q975": 885.2170931113325,
            "rating_q025": 835.9195434779398
        },
        "chatglm-6b": {
            "rating": 841.4660397046732,
            "rating_q975": 866.1926682677221,
            "rating_q025": 816.7394111416244
        },
        "stablelm-tuned-alpha-7b": {
            "rating": 823.5218395672528,
            "rating_q975": 852.1863094063857,
            "rating_q025": 794.8573697281198
        },
        "dolly-v2-12b": {
            "rating": 809.496197138234,
            "rating_q975": 837.0307117886634,
            "rating_q025": 781.9616824878046
        },
        "llama-13b": {
            "rating": 785.2980556620187,
            "rating_q975": 817.0948586341315,
            "rating_q025": 753.5012526899059
        }
    },
    "industry_legal_and_government": {
        "gemini-2.5-pro": {
            "rating": 1488.1113917300554,
            "rating_q975": 1498.9097641870096,
            "rating_q025": 1477.3130192731012
        },
        "deepseek-v3.1-terminus-thinking": {
            "rating": 1456.759455961967,
            "rating_q975": 1492.2720294929559,
            "rating_q025": 1421.246882430978
        },
        "glm-4.6": {
            "rating": 1452.559488122201,
            "rating_q975": 1478.1891602640158,
            "rating_q025": 1426.9298159803861
        },
        "mistral-medium-2508": {
            "rating": 1449.256487887356,
            "rating_q975": 1463.4498459627523,
            "rating_q025": 1435.0631298119595
        },
        "chatgpt-4o-latest-20250326": {
            "rating": 1442.72591386336,
            "rating_q975": 1454.7319505455755,
            "rating_q025": 1430.7198771811443
        },
        "qwen3-vl-235b-a22b-instruct": {
            "rating": 1441.5741047205704,
            "rating_q975": 1466.6848896534068,
            "rating_q025": 1416.463319787734
        },
        "glm-4.5": {
            "rating": 1439.4973664480763,
            "rating_q975": 1455.3062442959692,
            "rating_q025": 1423.6884886001833
        },
        "grok-3-preview-02-24": {
            "rating": 1438.8782335041658,
            "rating_q975": 1452.803707847011,
            "rating_q025": 1424.9527591613205
        },
        "qwen3-next-80b-a3b-instruct": {
            "rating": 1435.600107798919,
            "rating_q975": 1453.0402149769561,
            "rating_q025": 1418.1600006208819
        },
        "grok-4-0709": {
            "rating": 1434.1927123350674,
            "rating_q975": 1447.2245100758566,
            "rating_q025": 1421.1609145942782
        },
        "gemini-2.5-flash": {
            "rating": 1433.8755818024724,
            "rating_q975": 1444.3420334817088,
            "rating_q025": 1423.409130123236
        },
        "gpt-4.5-preview-2025-02-27": {
            "rating": 1433.8158836936366,
            "rating_q975": 1456.282314326342,
            "rating_q025": 1411.3494530609312
        },
        "gpt-5-chat": {
            "rating": 1431.7418446624954,
            "rating_q975": 1446.881297436867,
            "rating_q025": 1416.6023918881237
        },
        "o3-2025-04-16": {
            "rating": 1431.3420290194495,
            "rating_q975": 1442.1576360230476,
            "rating_q025": 1420.5264220158513
        },
        "qwen3-max-preview": {
            "rating": 1428.309390861618,
            "rating_q975": 1444.0143872346375,
            "rating_q025": 1412.6043944885987
        },
        "gemini-2.5-flash-preview-09-2025": {
            "rating": 1424.6556648989679,
            "rating_q975": 1445.7189198181131,
            "rating_q025": 1403.5924099798226
        },
        "gpt-5-high": {
            "rating": 1423.176458449038,
            "rating_q975": 1438.3818007516916,
            "rating_q025": 1407.9711161463842
        },
        "claude-opus-4-1-20250805-thinking-16k": {
            "rating": 1422.1890160597468,
            "rating_q975": 1437.3456931348612,
            "rating_q025": 1407.0323389846324
        },
        "qwen3-235b-a22b-instruct-2507": {
            "rating": 1421.6957660605597,
            "rating_q975": 1435.0511553108336,
            "rating_q025": 1408.3403768102858
        },
        "deepseek-v3.1": {
            "rating": 1421.6830736805725,
            "rating_q975": 1440.1950676753947,
            "rating_q025": 1403.1710796857503
        },
        "deepseek-v3.2-exp-thinking": {
            "rating": 1419.8866347205944,
            "rating_q975": 1445.6257496936578,
            "rating_q025": 1394.147519747531
        },
        "claude-sonnet-4-5-20250929": {
            "rating": 1419.0719032203272,
            "rating_q975": 1448.4408973201707,
            "rating_q025": 1389.7029091204836
        },
        "deepseek-r1-0528": {
            "rating": 1418.1833194175608,
            "rating_q975": 1434.4652746732343,
            "rating_q025": 1401.9013641618874
        },
        "claude-opus-4-1-20250805": {
            "rating": 1416.4958953077232,
            "rating_q975": 1429.0778678442307,
            "rating_q025": 1403.9139227712158
        },
        "claude-sonnet-4-5-20250929-thinking-32k": {
            "rating": 1416.4675325727449,
            "rating_q975": 1439.667505390889,
            "rating_q025": 1393.2675597546008
        },
        "grok-4-fast": {
            "rating": 1416.1261480665592,
            "rating_q975": 1443.407202709231,
            "rating_q025": 1388.8450934238874
        },
        "deepseek-v3.1-terminus": {
            "rating": 1413.9492732863746,
            "rating_q975": 1448.9671542640465,
            "rating_q025": 1378.9313923087027
        },
        "deepseek-v3.1-thinking": {
            "rating": 1413.4969541805083,
            "rating_q975": 1434.1807102267285,
            "rating_q025": 1392.813198134288
        },
        "longcat-flash-chat": {
            "rating": 1413.1210134421976,
            "rating_q975": 1434.1896906418167,
            "rating_q025": 1392.0523362425786
        },
        "qwen3-235b-a22b-thinking-2507": {
            "rating": 1410.0755880758475,
            "rating_q975": 1434.2668117140865,
            "rating_q025": 1385.8843644376084
        },
        "mai-1-preview": {
            "rating": 1407.9037881719685,
            "rating_q975": 1425.463139075143,
            "rating_q025": 1390.3444372687939
        },
        "kimi-k2-0905-preview": {
            "rating": 1405.8340098368224,
            "rating_q975": 1428.4056600567287,
            "rating_q025": 1383.262359616916
        },
        "qwen3-max-2025-09-23": {
            "rating": 1404.2820687768924,
            "rating_q975": 1428.961210624109,
            "rating_q025": 1379.6029269296757
        },
        "qwen3-vl-235b-a22b-thinking": {
            "rating": 1403.8372633207925,
            "rating_q975": 1429.3259817193732,
            "rating_q025": 1378.3485449222119
        },
        "gpt-4.1-2025-04-14": {
            "rating": 1401.6397086009492,
            "rating_q975": 1413.0691143454508,
            "rating_q025": 1390.2103028564477
        },
        "hunyuan-t1-20250711": {
            "rating": 1401.1965841449305,
            "rating_q975": 1435.2751892069011,
            "rating_q025": 1367.11797908296
        },
        "qwen3-235b-a22b-no-thinking": {
            "rating": 1392.2204194488834,
            "rating_q975": 1404.4135610486335,
            "rating_q025": 1380.0272778491333
        },
        "grok-3-mini-high": {
            "rating": 1390.6964719505916,
            "rating_q975": 1408.0027950538008,
            "rating_q025": 1373.3901488473823
        },
        "gemini-2.5-flash-lite-preview-09-2025-no-thinking": {
            "rating": 1390.259544843089,
            "rating_q975": 1411.6932967509854,
            "rating_q025": 1368.8257929351928
        },
        "mistral-medium-2505": {
            "rating": 1387.4675062015465,
            "rating_q975": 1400.418356804352,
            "rating_q025": 1374.516655598741
        },
        "qwen3-30b-a3b-instruct-2507": {
            "rating": 1385.9771343694083,
            "rating_q975": 1401.568611295974,
            "rating_q025": 1370.3856574428426
        },
        "glm-4.5-air": {
            "rating": 1384.5452803156768,
            "rating_q975": 1399.2574821067763,
            "rating_q025": 1369.8330785245773
        },
        "gemma-3-12b-it": {
            "rating": 1381.9409616935704,
            "rating_q975": 1420.8850651118303,
            "rating_q025": 1342.9968582753106
        },
        "amazon-nova-experimental-chat-10-09": {
            "rating": 1380.4820900503632,
            "rating_q975": 1415.7665348439823,
            "rating_q025": 1345.1976452567442
        },
        "deepseek-v3-0324": {
            "rating": 1379.8470118637447,
            "rating_q975": 1391.2879452808224,
            "rating_q025": 1368.406078446667
        },
        "gemma-3-27b-it": {
            "rating": 1376.3740237710037,
            "rating_q975": 1387.9778295761707,
            "rating_q025": 1364.7702179658368
        },
        "qwen2.5-max": {
            "rating": 1374.8263599520112,
            "rating_q975": 1388.5621903332378,
            "rating_q025": 1361.0905295707846
        },
        "gemini-2.5-flash-lite-preview-06-17-thinking": {
            "rating": 1374.3811341065718,
            "rating_q975": 1387.592310411588,
            "rating_q025": 1361.1699578015557
        },
        "deepseek-r1": {
            "rating": 1371.812984755201,
            "rating_q975": 1389.2273011102448,
            "rating_q025": 1354.398668400157
        },
        "gpt-5-mini-high": {
            "rating": 1371.3240638994237,
            "rating_q975": 1387.341972448386,
            "rating_q025": 1355.3061553504613
        },
        "claude-opus-4-20250514": {
            "rating": 1370.9926096788988,
            "rating_q975": 1382.6343841680296,
            "rating_q025": 1359.350835189768
        },
        "ling-flash-2.0": {
            "rating": 1370.5884141446595,
            "rating_q975": 1398.1979829804195,
            "rating_q025": 1342.9788453088995
        },
        "grok-3-mini-beta": {
            "rating": 1370.4521952122427,
            "rating_q975": 1385.8699204510222,
            "rating_q025": 1355.0344699734633
        },
        "hunyuan-turbos-20250416": {
            "rating": 1370.0177013642149,
            "rating_q975": 1391.263590027024,
            "rating_q025": 1348.7718127014057
        },
        "o1-2024-12-17": {
            "rating": 1369.2535267077326,
            "rating_q975": 1384.6060588380585,
            "rating_q025": 1353.9009945774067
        },
        "claude-haiku-4-5-20251001": {
            "rating": 1368.1189073617224,
            "rating_q975": 1395.4835387240462,
            "rating_q025": 1340.7542759993987
        },
        "claude-opus-4-20250514-thinking-16k": {
            "rating": 1363.8245332233157,
            "rating_q975": 1376.648124167678,
            "rating_q025": 1351.0009422789535
        },
        "glm-4-plus-0111": {
            "rating": 1363.1687336125235,
            "rating_q975": 1393.15225642385,
            "rating_q025": 1333.185210801197
        },
        "qwen3-next-80b-a3b-thinking": {
            "rating": 1360.7517237293744,
            "rating_q975": 1381.2455844593953,
            "rating_q025": 1340.2578629993534
        },
        "qwen3-coder-480b-a35b-instruct": {
            "rating": 1357.8144308839887,
            "rating_q975": 1373.8290510820889,
            "rating_q025": 1341.7998106858886
        },
        "qwen3-235b-a22b": {
            "rating": 1357.0913414342122,
            "rating_q975": 1371.2814266974679,
            "rating_q025": 1342.9012561709565
        },
        "kimi-k2-0711-preview": {
            "rating": 1354.9167196505593,
            "rating_q975": 1369.732076861277,
            "rating_q025": 1340.1013624398418
        },
        "o4-mini-2025-04-16": {
            "rating": 1350.96314048527,
            "rating_q975": 1362.8019989866507,
            "rating_q025": 1339.1242819838894
        },
        "qwen-plus-0125": {
            "rating": 1349.6229344960989,
            "rating_q975": 1378.2201667744373,
            "rating_q025": 1321.0257022177605
        },
        "gpt-4.1-mini-2025-04-14": {
            "rating": 1348.118190302535,
            "rating_q975": 1360.3546262860114,
            "rating_q025": 1335.8817543190585
        },
        "gpt-oss-120b": {
            "rating": 1348.0315688927355,
            "rating_q975": 1363.1525139609023,
            "rating_q025": 1332.9106238245688
        },
        "step-1o-turbo-202506": {
            "rating": 1348.020538774107,
            "rating_q975": 1371.038747760946,
            "rating_q025": 1325.002329787268
        },
        "o1-preview": {
            "rating": 1347.8466290927372,
            "rating_q975": 1361.6233803226435,
            "rating_q025": 1334.069877862831
        },
        "command-a-03-2025": {
            "rating": 1347.0366517603557,
            "rating_q975": 1358.0251231909929,
            "rating_q025": 1336.0481803297184
        },
        "nvidia-llama-3.3-nemotron-super-49b-v1.5": {
            "rating": 1345.927205374777,
            "rating_q975": 1382.4625267044835,
            "rating_q025": 1309.3918840450706
        },
        "gemini-2.0-flash-lite-preview-02-05": {
            "rating": 1345.455967491516,
            "rating_q975": 1360.6034253925757,
            "rating_q025": 1330.3085095904564
        },
        "mistral-small-2506": {
            "rating": 1345.4239538921868,
            "rating_q975": 1362.5499967894423,
            "rating_q025": 1328.2979109949313
        },
        "step-3": {
            "rating": 1342.9860921005472,
            "rating_q975": 1371.5632261637725,
            "rating_q025": 1314.408958037322
        },
        "minimax-m1": {
            "rating": 1342.7644925803463,
            "rating_q975": 1355.2112002035685,
            "rating_q025": 1330.317784957124
        },
        "deepseek-v3": {
            "rating": 1342.5534787977813,
            "rating_q975": 1358.6127481057456,
            "rating_q025": 1326.494209489817
        },
        "claude-sonnet-4-20250514": {
            "rating": 1341.9833892222314,
            "rating_q975": 1354.3318627327217,
            "rating_q025": 1329.634915711741
        },
        "qwq-32b": {
            "rating": 1337.9820019128379,
            "rating_q975": 1352.3126595916012,
            "rating_q025": 1323.6513442340745
        },
        "step-2-16k-exp-202412": {
            "rating": 1337.7416595538498,
            "rating_q975": 1371.3163264493437,
            "rating_q025": 1304.1669926583559
        },
        "claude-sonnet-4-20250514-thinking-32k": {
            "rating": 1336.890140739188,
            "rating_q975": 1350.1492039782106,
            "rating_q025": 1323.6310775001652
        },
        "glm-4.5v": {
            "rating": 1335.8875235214155,
            "rating_q975": 1370.6648325227718,
            "rating_q025": 1301.1102145200591
        },
        "o3-mini-high": {
            "rating": 1329.7206365296672,
            "rating_q975": 1347.5226087008498,
            "rating_q025": 1311.9186643584846
        },
        "gemini-1.5-pro-002": {
            "rating": 1329.2421464645497,
            "rating_q975": 1339.5783616724616,
            "rating_q025": 1318.9059312566378
        },
        "yi-lightning": {
            "rating": 1329.1779032774969,
            "rating_q975": 1343.3712618527725,
            "rating_q025": 1314.9845447022212
        },
        "gemma-3-4b-it": {
            "rating": 1328.9446097815496,
            "rating_q975": 1365.1703473647658,
            "rating_q025": 1292.7188721983334
        },
        "grok-2-2024-08-13": {
            "rating": 1326.7893262896655,
            "rating_q975": 1336.936212592514,
            "rating_q025": 1316.642439986817
        },
        "qwen3-32b": {
            "rating": 1326.0243074519312,
            "rating_q975": 1358.595138402764,
            "rating_q025": 1293.4534765010985
        },
        "qwen3-30b-a3b": {
            "rating": 1317.1443068957128,
            "rating_q975": 1331.0848506352309,
            "rating_q025": 1303.2037631561948
        },
        "o1-mini": {
            "rating": 1316.4995350155887,
            "rating_q975": 1327.3716766861169,
            "rating_q025": 1305.6273933450605
        },
        "gpt-4o-2024-05-13": {
            "rating": 1315.0791162797395,
            "rating_q975": 1324.116224113013,
            "rating_q025": 1306.042008446466
        },
        "glm-4-plus": {
            "rating": 1310.59177675692,
            "rating_q975": 1325.0574948557994,
            "rating_q025": 1296.1260586580404
        },
        "gemma-3n-e4b-it": {
            "rating": 1310.5560512358982,
            "rating_q975": 1326.174220113906,
            "rating_q025": 1294.9378823578904
        },
        "ring-flash-2.0": {
            "rating": 1309.6564836587645,
            "rating_q975": 1338.4143514329094,
            "rating_q025": 1280.8986158846196
        },
        "qwen2.5-plus-1127": {
            "rating": 1308.6246699852372,
            "rating_q975": 1332.272159683852,
            "rating_q025": 1284.9771802866226
        },
        "gpt-4o-mini-2024-07-18": {
            "rating": 1305.910364224737,
            "rating_q975": 1315.796415071622,
            "rating_q025": 1296.0243133778517
        },
        "gemini-advanced-0514": {
            "rating": 1305.7901992700802,
            "rating_q975": 1319.2496879775838,
            "rating_q025": 1292.3307105625765
        },
        "llama-3.1-405b-instruct-fp8": {
            "rating": 1304.4879834357157,
            "rating_q975": 1315.16434829914,
            "rating_q025": 1293.8116185722913
        },
        "o3-mini": {
            "rating": 1304.3952672658806,
            "rating_q975": 1314.4906116204102,
            "rating_q025": 1294.2999229113511
        },
        "gemini-1.5-flash-002": {
            "rating": 1303.8544614302202,
            "rating_q975": 1316.5371015109608,
            "rating_q025": 1291.1718213494796
        },
        "llama-3.1-nemotron-70b-instruct": {
            "rating": 1303.7703870084047,
            "rating_q975": 1330.098289113127,
            "rating_q025": 1277.4424849036823
        },
        "gpt-5-nano-high": {
            "rating": 1303.726563765992,
            "rating_q975": 1331.158649849856,
            "rating_q025": 1276.2944776821282
        },
        "claude-3-7-sonnet-20250219-thinking-32k": {
            "rating": 1303.5523404779165,
            "rating_q975": 1316.001148088069,
            "rating_q025": 1291.103532867764
        },
        "llama-3.1-405b-instruct-bf16": {
            "rating": 1302.6535223285687,
            "rating_q975": 1314.8677808966552,
            "rating_q025": 1290.4392637604822
        },
        "athene-v2-chat": {
            "rating": 1300.3531236678673,
            "rating_q975": 1315.5755775143139,
            "rating_q025": 1285.1306698214207
        },
        "gpt-4.1-nano-2025-04-14": {
            "rating": 1298.9848455294775,
            "rating_q975": 1327.4472907448444,
            "rating_q025": 1270.5224003141107
        },
        "athene-70b-0725": {
            "rating": 1294.0387194563073,
            "rating_q975": 1312.6624428249818,
            "rating_q025": 1275.4149960876327
        },
        "grok-2-mini-2024-08-13": {
            "rating": 1293.4897938848976,
            "rating_q975": 1304.539804530513,
            "rating_q025": 1282.4397832392822
        },
        "hunyuan-standard-2025-02-10": {
            "rating": 1290.5253106487557,
            "rating_q975": 1324.7341604896444,
            "rating_q025": 1256.316460807867
        },
        "qwen2.5-72b-instruct": {
            "rating": 1289.1030416249887,
            "rating_q975": 1301.1308301500449,
            "rating_q025": 1277.0752530999325
        },
        "llama-4-scout-17b-16e-instruct": {
            "rating": 1287.5209823716586,
            "rating_q975": 1301.5050663785985,
            "rating_q025": 1273.5368983647188
        },
        "llama-4-maverick-17b-128e-instruct": {
            "rating": 1286.764065152146,
            "rating_q975": 1299.007559045672,
            "rating_q025": 1274.52057125862
        },
        "llama-3.3-70b-instruct": {
            "rating": 1286.3889819434028,
            "rating_q975": 1296.838844700415,
            "rating_q025": 1275.9391191863906
        },
        "llama-3.1-70b-instruct": {
            "rating": 1285.1124349482673,
            "rating_q975": 1296.0343764732345,
            "rating_q025": 1274.1904934233
        },
        "deepseek-v2.5": {
            "rating": 1285.10055754434,
            "rating_q975": 1299.872866929072,
            "rating_q025": 1270.3282481596082
        },
        "gpt-oss-20b": {
            "rating": 1284.8126694311832,
            "rating_q975": 1308.2095328167197,
            "rating_q025": 1261.4158060456466
        },
        "qwen-max-0919": {
            "rating": 1284.0758188584664,
            "rating_q975": 1301.5726040701388,
            "rating_q025": 1266.579033646794
        },
        "amazon-nova-pro-v1.0": {
            "rating": 1282.3897614157324,
            "rating_q975": 1298.2088814744975,
            "rating_q025": 1266.5706413569674
        },
        "hunyuan-large-2025-02-10": {
            "rating": 1281.519037078953,
            "rating_q975": 1317.822645766491,
            "rating_q025": 1245.2154283914151
        },
        "claude-3-5-sonnet-20241022": {
            "rating": 1280.8541031824084,
            "rating_q975": 1289.0704305586992,
            "rating_q025": 1272.6377758061176
        },
        "deepseek-v2.5-1210": {
            "rating": 1279.926802315888,
            "rating_q975": 1309.1615542647849,
            "rating_q025": 1250.692050366991
        },
        "mistral-large-2407": {
            "rating": 1277.6975283252737,
            "rating_q975": 1289.1974574249004,
            "rating_q025": 1266.1975992256469
        },
        "gpt-4o-2024-08-06": {
            "rating": 1276.397556075847,
            "rating_q975": 1288.0850535975055,
            "rating_q025": 1264.7100585541884
        },
        "mistral-large-2411": {
            "rating": 1275.6852545104434,
            "rating_q975": 1290.290828238837,
            "rating_q025": 1261.0796807820498
        },
        "reka-core-20240904": {
            "rating": 1274.6788669892146,
            "rating_q975": 1303.2905308091758,
            "rating_q025": 1246.0672031692534
        },
        "mistral-small-3.1-24b-instruct-2503": {
            "rating": 1273.4991065574268,
            "rating_q975": 1286.7596789099073,
            "rating_q025": 1260.2385342049463
        },
        "gemini-1.5-pro-001": {
            "rating": 1271.1897227916338,
            "rating_q975": 1282.029684532557,
            "rating_q025": 1260.3497610507106
        },
        "gemma-2-9b-it-simpo": {
            "rating": 1269.6034897735626,
            "rating_q975": 1293.7990914348093,
            "rating_q025": 1245.407888112316
        },
        "command-r-plus-08-2024": {
            "rating": 1269.5505719926464,
            "rating_q975": 1292.7708380451572,
            "rating_q025": 1246.3303059401355
        },
        "claude-3-5-sonnet-20240620": {
            "rating": 1267.181744635721,
            "rating_q975": 1277.1359265424962,
            "rating_q025": 1257.227562728946
        },
        "claude-3-opus-20240229": {
            "rating": 1265.825416078238,
            "rating_q975": 1274.0695410042863,
            "rating_q025": 1257.5812911521898
        },
        "gpt-4-turbo-2024-04-09": {
            "rating": 1265.5198007909964,
            "rating_q975": 1275.7204480129253,
            "rating_q025": 1255.3191535690676
        },
        "jamba-1.5-large": {
            "rating": 1265.3344971081476,
            "rating_q975": 1292.2599061539831,
            "rating_q025": 1238.409088062312
        },
        "gpt-4-0125-preview": {
            "rating": 1262.4676451385144,
            "rating_q975": 1273.267029949198,
            "rating_q025": 1251.6682603278307
        },
        "qwen2.5-coder-32b-instruct": {
            "rating": 1258.0691813338487,
            "rating_q975": 1292.4446712077438,
            "rating_q025": 1223.6936914599537
        },
        "claude-3-5-haiku-20241022": {
            "rating": 1257.5606251169002,
            "rating_q975": 1267.1444141208988,
            "rating_q025": 1247.9768361129015
        },
        "llama-3.1-nemotron-51b-instruct": {
            "rating": 1256.0111503683506,
            "rating_q975": 1292.0122097232527,
            "rating_q025": 1220.0100910134486
        },
        "gpt-4-1106-preview": {
            "rating": 1250.103663820431,
            "rating_q975": 1260.6421821438405,
            "rating_q025": 1239.5651454970214
        },
        "gemini-1.5-flash-8b-001": {
            "rating": 1249.087447143122,
            "rating_q975": 1261.805059561527,
            "rating_q025": 1236.369834724717
        },
        "c4ai-aya-expanse-32b": {
            "rating": 1249.0205987542636,
            "rating_q975": 1262.8365564893586,
            "rating_q025": 1235.2046410191685
        },
        "gemini-1.5-flash-001": {
            "rating": 1248.6620813972318,
            "rating_q975": 1260.0417207178905,
            "rating_q025": 1237.282442076573
        },
        "nemotron-4-340b-instruct": {
            "rating": 1247.1095681304164,
            "rating_q975": 1264.6922972149212,
            "rating_q025": 1229.5268390459116
        },
        "hunyuan-large-vision": {
            "rating": 1246.7035221827784,
            "rating_q975": 1278.211688109811,
            "rating_q025": 1215.195356255746
        },
        "command-r-plus": {
            "rating": 1246.2359868321255,
            "rating_q975": 1257.708606122503,
            "rating_q025": 1234.763367541748
        },
        "glm-4-0520": {
            "rating": 1245.335716748672,
            "rating_q975": 1269.600503938899,
            "rating_q025": 1221.070929558445
        },
        "gemma-2-27b-it": {
            "rating": 1242.4695131659391,
            "rating_q975": 1251.9098015047305,
            "rating_q025": 1233.0292248271478
        },
        "phi-4": {
            "rating": 1241.527052155605,
            "rating_q975": 1257.7871437571603,
            "rating_q025": 1225.2669605540495
        },
        "amazon-nova-lite-v1.0": {
            "rating": 1238.5779865591503,
            "rating_q975": 1256.4718803492062,
            "rating_q025": 1220.6840927690944
        },
        "command-r-08-2024": {
            "rating": 1230.8389222570402,
            "rating_q975": 1254.6564775399524,
            "rating_q025": 1207.021366974128
        },
        "llama-3-70b-instruct": {
            "rating": 1228.9320490111122,
            "rating_q975": 1238.6632242154749,
            "rating_q025": 1219.2008738067495
        },
        "olmo-2-0325-32b-instruct": {
            "rating": 1228.8746567096873,
            "rating_q975": 1270.0453230440335,
            "rating_q025": 1187.7039903753412
        },
        "magistral-medium-2506": {
            "rating": 1228.5142376268082,
            "rating_q975": 1250.8170521725688,
            "rating_q025": 1206.2114230810475
        },
        "c4ai-aya-expanse-8b": {
            "rating": 1226.1690265980747,
            "rating_q975": 1250.9086100830489,
            "rating_q025": 1201.4294431131004
        },
        "jamba-1.5-mini": {
            "rating": 1224.80906364778,
            "rating_q975": 1249.5379037021885,
            "rating_q025": 1200.0802235933716
        },
        "amazon-nova-micro-v1.0": {
            "rating": 1222.0482134551276,
            "rating_q975": 1240.3396086962282,
            "rating_q025": 1203.756818214027
        },
        "mistral-small-24b-instruct-2501": {
            "rating": 1219.9736919947918,
            "rating_q975": 1240.4609400793863,
            "rating_q025": 1199.4864439101973
        },
        "reka-flash-20240904": {
            "rating": 1218.3358103455812,
            "rating_q975": 1247.7127495638279,
            "rating_q025": 1188.9588711273345
        },
        "gemma-2-9b-it": {
            "rating": 1216.4747792787912,
            "rating_q975": 1227.1543954186473,
            "rating_q025": 1205.795163138935
        },
        "claude-3-sonnet-20240229": {
            "rating": 1214.9318533922874,
            "rating_q975": 1225.9053784219748,
            "rating_q025": 1203.9583283626
        },
        "ministral-8b-2410": {
            "rating": 1212.567964882981,
            "rating_q975": 1245.578154992013,
            "rating_q025": 1179.557774773949
        },
        "command-r": {
            "rating": 1208.0691956564601,
            "rating_q975": 1221.0227106033349,
            "rating_q025": 1195.1156807095854
        },
        "llama-3.1-8b-instruct": {
            "rating": 1207.2844654787182,
            "rating_q975": 1218.7728159445826,
            "rating_q025": 1195.7961150128538
        },
        "yi-1.5-34b-chat": {
            "rating": 1197.6736407062892,
            "rating_q975": 1213.5257024968623,
            "rating_q025": 1181.8215789157161
        },
        "reka-flash-21b-20240226-online": {
            "rating": 1195.3791183253754,
            "rating_q975": 1215.6622661557801,
            "rating_q025": 1175.0959704949707
        },
        "qwen2-72b-instruct": {
            "rating": 1194.3370591085618,
            "rating_q975": 1207.5987497166038,
            "rating_q025": 1181.0753685005197
        },
        "gpt-4-0314": {
            "rating": 1192.4717532306831,
            "rating_q975": 1206.0503831082528,
            "rating_q025": 1178.8931233531134
        },
        "claude-3-haiku-20240307": {
            "rating": 1192.423523413967,
            "rating_q975": 1202.2390864203608,
            "rating_q025": 1182.607960407573
        },
        "qwen1.5-110b-chat": {
            "rating": 1189.2024877232218,
            "rating_q975": 1205.7294574960802,
            "rating_q025": 1172.6755179503634
        },
        "reka-flash-21b-20240226": {
            "rating": 1181.8644006550153,
            "rating_q975": 1199.1048612845027,
            "rating_q025": 1164.6239400255279
        },
        "mistral-large-2402": {
            "rating": 1181.664668843347,
            "rating_q975": 1194.3957676099026,
            "rating_q025": 1168.9335700767915
        },
        "qwen1.5-72b-chat": {
            "rating": 1174.8843759046554,
            "rating_q975": 1189.281412493376,
            "rating_q025": 1160.4873393159348
        },
        "granite-3.1-8b-instruct": {
            "rating": 1171.8449122709676,
            "rating_q975": 1212.9349292775469,
            "rating_q025": 1130.7548952643883
        },
        "mistral-medium": {
            "rating": 1171.271599274057,
            "rating_q975": 1187.0992746677503,
            "rating_q025": 1155.4439238803639
        },
        "gemma-2-2b-it": {
            "rating": 1170.893814111349,
            "rating_q975": 1182.8721404848902,
            "rating_q025": 1158.9154877378078
        },
        "llama-3-8b-instruct": {
            "rating": 1168.9534725667186,
            "rating_q975": 1179.691883328193,
            "rating_q025": 1158.2150618052442
        },
        "gemini-pro-dev-api": {
            "rating": 1166.9942439799793,
            "rating_q975": 1187.828665299318,
            "rating_q025": 1146.1598226606407
        },
        "mixtral-8x22b-instruct-v0.1": {
            "rating": 1166.2356348422081,
            "rating_q975": 1179.0268142138495,
            "rating_q025": 1153.4444554705667
        },
        "deepseek-coder-v2": {
            "rating": 1163.4493368891997,
            "rating_q975": 1183.4007659401589,
            "rating_q025": 1143.4979078382405
        },
        "hunyuan-standard-256k": {
            "rating": 1162.9958476026811,
            "rating_q975": 1205.8980688963554,
            "rating_q025": 1120.0936263090068
        },
        "gpt-4-0613": {
            "rating": 1155.7085679102747,
            "rating_q975": 1167.2032582421245,
            "rating_q025": 1144.213877578425
        },
        "internlm2_5-20b-chat": {
            "rating": 1152.6959877650402,
            "rating_q975": 1175.499926134473,
            "rating_q025": 1129.8920493956073
        },
        "starling-lm-7b-beta": {
            "rating": 1152.0243006242276,
            "rating_q975": 1172.6930682211469,
            "rating_q025": 1131.3555330273084
        },
        "qwq-32b-preview": {
            "rating": 1143.2919387798224,
            "rating_q975": 1184.7907290986104,
            "rating_q025": 1101.7931484610344
        },
        "qwen1.5-32b-chat": {
            "rating": 1142.076717993394,
            "rating_q975": 1159.4922756898204,
            "rating_q025": 1124.6611602969674
        },
        "yi-34b-chat": {
            "rating": 1138.80949433566,
            "rating_q975": 1160.388900369361,
            "rating_q025": 1117.230088301959
        },
        "tulu-2-dpo-70b": {
            "rating": 1135.5843657391986,
            "rating_q975": 1165.6998290775157,
            "rating_q025": 1105.4689024008815
        },
        "zephyr-orpo-141b-A35b-v0.1": {
            "rating": 1135.1600534607817,
            "rating_q975": 1172.8309307840839,
            "rating_q025": 1097.4891761374795
        },
        "mixtral-8x7b-instruct-v0.1": {
            "rating": 1133.225198861104,
            "rating_q975": 1145.1234028595804,
            "rating_q025": 1121.3269948626275
        },
        "phi-3-medium-4k-instruct": {
            "rating": 1131.9117805311537,
            "rating_q975": 1147.635167509828,
            "rating_q025": 1116.1883935524793
        },
        "wizardlm-70b": {
            "rating": 1130.3767453636956,
            "rating_q975": 1159.5234800108447,
            "rating_q025": 1101.2300107165465
        },
        "starling-lm-7b-alpha": {
            "rating": 1123.3899498202397,
            "rating_q975": 1150.1320267284902,
            "rating_q025": 1096.6478729119892
        },
        "qwen1.5-14b-chat": {
            "rating": 1120.559422395973,
            "rating_q975": 1139.7703517305022,
            "rating_q025": 1101.3484930614436
        },
        "gpt-3.5-turbo-0125": {
            "rating": 1119.3227706218577,
            "rating_q975": 1131.1685480288102,
            "rating_q025": 1107.4769932149052
        },
        "llama-3.2-3b-instruct": {
            "rating": 1116.4918736041088,
            "rating_q975": 1144.3512453629685,
            "rating_q025": 1088.6325018452492
        },
        "llama-2-70b-chat": {
            "rating": 1114.8976119422255,
            "rating_q975": 1129.7855752021221,
            "rating_q025": 1100.0096486823288
        },
        "openchat-3.5": {
            "rating": 1114.1396025586382,
            "rating_q975": 1142.599350757834,
            "rating_q025": 1085.6798543594425
        },
        "gemini-pro": {
            "rating": 1107.7150206926653,
            "rating_q975": 1140.9395000487752,
            "rating_q025": 1074.4905413365555
        },
        "openchat-3.5-0106": {
            "rating": 1106.4838766282169,
            "rating_q975": 1130.2838074060214,
            "rating_q025": 1082.6839458504123
        },
        "qwen1.5-7b-chat": {
            "rating": 1105.7988619235434,
            "rating_q975": 1145.8190548175467,
            "rating_q025": 1065.7786690295402
        },
        "dbrx-instruct-preview": {
            "rating": 1105.6390737975585,
            "rating_q975": 1121.8780895044013,
            "rating_q025": 1089.4000580907157
        },
        "phi-3-small-8k-instruct": {
            "rating": 1104.0631866218143,
            "rating_q975": 1121.6968802843296,
            "rating_q025": 1086.429492959299
        },
        "wizardlm-13b": {
            "rating": 1100.989702436922,
            "rating_q975": 1133.3466911450819,
            "rating_q025": 1068.6327137287622
        },
        "openhermes-2.5-mistral-7b": {
            "rating": 1100.7711965895348,
            "rating_q975": 1136.625136569566,
            "rating_q025": 1064.9172566095037
        },
        "mistral-7b-instruct-v0.2": {
            "rating": 1100.0285325994496,
            "rating_q975": 1119.8452451498865,
            "rating_q025": 1080.2118200490127
        },
        "vicuna-33b": {
            "rating": 1099.9186341210525,
            "rating_q975": 1118.8571247682414,
            "rating_q025": 1080.9801434738636
        },
        "zephyr-7b-beta": {
            "rating": 1096.3437594911125,
            "rating_q975": 1121.8300749575253,
            "rating_q025": 1070.8574440246996
        },
        "gemma-1.1-7b-it": {
            "rating": 1095.2248771891582,
            "rating_q975": 1111.9665558497534,
            "rating_q025": 1078.483198528563
        },
        "snowflake-arctic-instruct": {
            "rating": 1092.6347409998552,
            "rating_q975": 1110.5173869704374,
            "rating_q025": 1074.752095029273
        },
        "deepseek-llm-67b-chat": {
            "rating": 1090.4581290697902,
            "rating_q975": 1125.5327168144927,
            "rating_q025": 1055.3835413250877
        },
        "granite-3.0-2b-instruct": {
            "rating": 1087.4970350795993,
            "rating_q975": 1118.350872931602,
            "rating_q025": 1056.6431972275966
        },
        "granite-3.0-8b-instruct": {
            "rating": 1085.4688602451567,
            "rating_q975": 1118.6018486612707,
            "rating_q025": 1052.3358718290428
        },
        "solar-10.7b-instruct-v1.0": {
            "rating": 1083.6404832737785,
            "rating_q975": 1123.139009197489,
            "rating_q025": 1044.141957350068
        },
        "llama-2-13b-chat": {
            "rating": 1081.1188620308035,
            "rating_q975": 1101.5791033213868,
            "rating_q025": 1060.6586207402202
        },
        "phi-3-mini-4k-instruct": {
            "rating": 1072.2349530128133,
            "rating_q975": 1090.9113228702631,
            "rating_q025": 1053.5585831553635
        },
        "llama-3.2-1b-instruct": {
            "rating": 1071.9814458871424,
            "rating_q975": 1100.9834728756925,
            "rating_q025": 1042.9794188985923
        },
        "phi-3-mini-4k-instruct-june-2024": {
            "rating": 1069.3505744850067,
            "rating_q975": 1093.801107151178,
            "rating_q025": 1044.9000418188355
        },
        "llama-2-7b-chat": {
            "rating": 1066.6995024980854,
            "rating_q975": 1089.0433415114558,
            "rating_q025": 1044.355663484715
        },
        "codellama-34b-instruct": {
            "rating": 1065.3456852672148,
            "rating_q975": 1097.7722904979041,
            "rating_q025": 1032.9190800365254
        },
        "vicuna-13b": {
            "rating": 1057.8667540180522,
            "rating_q975": 1079.6199325404853,
            "rating_q025": 1036.1135754956192
        },
        "gpt-3.5-turbo-1106": {
            "rating": 1057.4727487746582,
            "rating_q975": 1080.0072974765608,
            "rating_q025": 1034.9382000727555
        },
        "qwen-14b-chat": {
            "rating": 1051.7983699831038,
            "rating_q975": 1089.885933408862,
            "rating_q025": 1013.7108065573458
        },
        "olmo-7b-instruct": {
            "rating": 1047.9717080026444,
            "rating_q975": 1082.8665882666814,
            "rating_q025": 1013.0768277386073
        },
        "gemma-7b-it": {
            "rating": 1045.9852685155581,
            "rating_q975": 1074.6107521210845,
            "rating_q025": 1017.3597849100316
        },
        "vicuna-7b": {
            "rating": 1033.282864379742,
            "rating_q975": 1068.5623623603856,
            "rating_q025": 998.0033663990984
        },
        "mistral-7b-instruct": {
            "rating": 1026.2001797206262,
            "rating_q975": 1055.3828223832677,
            "rating_q025": 997.0175370579849
        },
        "gemma-2b-it": {
            "rating": 1020.8698313803739,
            "rating_q975": 1059.29399467955,
            "rating_q025": 982.4456680811976
        },
        "qwen1.5-4b-chat": {
            "rating": 1011.5008226372829,
            "rating_q975": 1043.5265127150562,
            "rating_q025": 979.4751325595096
        },
        "phi-3-mini-128k-instruct": {
            "rating": 1007.7169902073952,
            "rating_q975": 1029.3092248608557,
            "rating_q025": 986.1247555539346
        },
        "palm-2": {
            "rating": 1006.7434308855402,
            "rating_q975": 1038.672977240479,
            "rating_q025": 974.8138845306015
        },
        "stripedhyena-nous-7b": {
            "rating": 1001.5657774455605,
            "rating_q975": 1036.9630169187365,
            "rating_q025": 966.1685379723845
        },
        "gemma-1.1-2b-it": {
            "rating": 996.0013582147177,
            "rating_q975": 1024.0025203819453,
            "rating_q025": 968.00019604749
        },
        "RWKV-4-Raven-14B": {
            "rating": 976.9756206203947,
            "rating_q975": 1026.042547652173,
            "rating_q025": 927.9086935886165
        },
        "chatglm3-6b": {
            "rating": 974.5588951259117,
            "rating_q975": 1016.1947317503256,
            "rating_q025": 932.9230585014978
        },
        "koala-13b": {
            "rating": 964.8891451090121,
            "rating_q975": 1005.7558412717572,
            "rating_q025": 924.0224489462671
        },
        "oasst-pythia-12b": {
            "rating": 923.4743988596056,
            "rating_q975": 964.6133167005814,
            "rating_q025": 882.3354810186297
        },
        "alpaca-13b": {
            "rating": 912.0922647606318,
            "rating_q975": 956.1245054913404,
            "rating_q025": 868.0600240299232
        },
        "fastchat-t5-3b": {
            "rating": 899.9679334110315,
            "rating_q975": 948.305234110674,
            "rating_q025": 851.630632711389
        },
        "chatglm-6b": {
            "rating": 896.5864832221223,
            "rating_q975": 944.5118460263645,
            "rating_q025": 848.66112041788
        }
    },
    "industry_life_and_physical_and_social_science": {
        "gemini-2.5-pro": {
            "rating": 1491.932317698482,
            "rating_q975": 1499.0068664825856,
            "rating_q025": 1484.8577689143783
        },
        "glm-4.6": {
            "rating": 1465.8684959023162,
            "rating_q975": 1480.4393089343948,
            "rating_q025": 1451.2976828702376
        },
        "qwen3-max-preview": {
            "rating": 1458.6518556789292,
            "rating_q975": 1468.8213515677573,
            "rating_q025": 1448.482359790101
        },
        "mistral-medium-2508": {
            "rating": 1457.7322138942277,
            "rating_q975": 1467.0763145470241,
            "rating_q025": 1448.3881132414313
        },
        "deepseek-v3.1-terminus": {
            "rating": 1455.8211478553908,
            "rating_q975": 1480.5556971379183,
            "rating_q025": 1431.0865985728633
        },
        "deepseek-v3.1-terminus-thinking": {
            "rating": 1449.8961954397435,
            "rating_q975": 1475.1646628613175,
            "rating_q025": 1424.6277280181694
        },
        "qwen3-vl-235b-a22b-instruct": {
            "rating": 1449.8550429623076,
            "rating_q975": 1466.1537973909922,
            "rating_q025": 1433.556288533623
        },
        "glm-4.5": {
            "rating": 1447.5814070795793,
            "rating_q975": 1457.3517450163718,
            "rating_q025": 1437.811069142787
        },
        "chatgpt-4o-latest-20250326": {
            "rating": 1444.931132248072,
            "rating_q975": 1452.2216102951616,
            "rating_q025": 1437.6406542009822
        },
        "grok-4-0709": {
            "rating": 1441.0393338629833,
            "rating_q975": 1449.2704678289172,
            "rating_q025": 1432.8081998970495
        },
        "deepseek-v3.2-exp-thinking": {
            "rating": 1440.9847341153318,
            "rating_q975": 1456.1750653843756,
            "rating_q025": 1425.794402846288
        },
        "gemini-2.5-flash-preview-09-2025": {
            "rating": 1440.1819993535378,
            "rating_q975": 1453.364292806103,
            "rating_q025": 1426.9997059009725
        },
        "deepseek-v3.1": {
            "rating": 1439.678577138157,
            "rating_q975": 1452.0567219962509,
            "rating_q025": 1427.300432280063
        },
        "grok-3-preview-02-24": {
            "rating": 1438.5689543367164,
            "rating_q975": 1446.5915555898493,
            "rating_q025": 1430.5463530835834
        },
        "qwen3-next-80b-a3b-instruct": {
            "rating": 1438.5458537558206,
            "rating_q975": 1449.7530617629586,
            "rating_q025": 1427.3386457486827
        },
        "claude-sonnet-4-5-20250929-thinking-32k": {
            "rating": 1436.529337777436,
            "rating_q975": 1450.3375924723182,
            "rating_q025": 1422.7210830825538
        },
        "qwen3-235b-a22b-instruct-2507": {
            "rating": 1435.7847371919786,
            "rating_q975": 1444.2861010784293,
            "rating_q025": 1427.283373305528
        },
        "qwen3-235b-a22b-thinking-2507": {
            "rating": 1435.2868296967304,
            "rating_q975": 1450.3592133262516,
            "rating_q025": 1420.214446067209
        },
        "o3-2025-04-16": {
            "rating": 1435.0716933807785,
            "rating_q975": 1442.0837688612703,
            "rating_q025": 1428.0596179002866
        },
        "claude-sonnet-4-5-20250929": {
            "rating": 1434.332988777703,
            "rating_q975": 1453.084615763722,
            "rating_q025": 1415.5813617916838
        },
        "deepseek-v3.1-thinking": {
            "rating": 1432.964521029147,
            "rating_q975": 1446.5215903841531,
            "rating_q025": 1419.4074516741407
        },
        "hunyuan-t1-20250711": {
            "rating": 1431.4386874950048,
            "rating_q975": 1453.5400887986482,
            "rating_q025": 1409.3372861913615
        },
        "gemini-2.5-flash": {
            "rating": 1431.1793381965679,
            "rating_q975": 1438.12419436715,
            "rating_q025": 1424.2344820259857
        },
        "deepseek-r1-0528": {
            "rating": 1428.3089776451977,
            "rating_q975": 1438.6828440534498,
            "rating_q025": 1417.9351112369457
        },
        "longcat-flash-chat": {
            "rating": 1425.0095804690666,
            "rating_q975": 1439.169730972796,
            "rating_q025": 1410.849429965337
        },
        "gpt-4.5-preview-2025-02-27": {
            "rating": 1424.1197924907542,
            "rating_q975": 1435.8683001913746,
            "rating_q025": 1412.3712847901338
        },
        "claude-opus-4-1-20250805-thinking-16k": {
            "rating": 1420.4576883909897,
            "rating_q975": 1429.8862898783161,
            "rating_q025": 1411.0290869036633
        },
        "grok-4-fast": {
            "rating": 1420.3762302020587,
            "rating_q975": 1439.0960790104496,
            "rating_q025": 1401.6563813936677
        },
        "qwen3-max-2025-09-23": {
            "rating": 1419.4343025640044,
            "rating_q975": 1434.8523849377948,
            "rating_q025": 1404.016220190214
        },
        "gpt-5-chat": {
            "rating": 1417.3472686708762,
            "rating_q975": 1426.5732431218544,
            "rating_q025": 1408.1212942198981
        },
        "qwen3-vl-235b-a22b-thinking": {
            "rating": 1415.4359566972457,
            "rating_q975": 1432.143728027982,
            "rating_q025": 1398.7281853665095
        },
        "claude-opus-4-1-20250805": {
            "rating": 1415.1581219989737,
            "rating_q975": 1423.4885718770768,
            "rating_q025": 1406.8276721208706
        },
        "mai-1-preview": {
            "rating": 1410.8402886865558,
            "rating_q975": 1421.7917784111041,
            "rating_q025": 1399.8887989620075
        },
        "glm-4.5-air": {
            "rating": 1410.5203858524335,
            "rating_q975": 1419.6607317571538,
            "rating_q025": 1401.3800399477132
        },
        "qwen3-235b-a22b-no-thinking": {
            "rating": 1406.3316520984101,
            "rating_q975": 1414.4915769269235,
            "rating_q025": 1398.1717272698968
        },
        "gpt-5-high": {
            "rating": 1405.7628367598345,
            "rating_q975": 1414.9826012005353,
            "rating_q025": 1396.5430723191337
        },
        "hunyuan-turbos-20250416": {
            "rating": 1400.474681135666,
            "rating_q975": 1413.6820637161302,
            "rating_q025": 1387.267298555202
        },
        "gemini-2.5-flash-lite-preview-09-2025-no-thinking": {
            "rating": 1396.0319729209293,
            "rating_q975": 1409.1935893667678,
            "rating_q025": 1382.8703564750908
        },
        "qwen3-30b-a3b-instruct-2507": {
            "rating": 1395.0074973589676,
            "rating_q975": 1404.832466820479,
            "rating_q025": 1385.182527897456
        },
        "ling-flash-2.0": {
            "rating": 1388.657928945012,
            "rating_q975": 1406.6088209376421,
            "rating_q025": 1370.7070369523817
        },
        "grok-3-mini-high": {
            "rating": 1386.9622053453127,
            "rating_q975": 1398.1968240032636,
            "rating_q025": 1375.7275866873617
        },
        "claude-haiku-4-5-20251001": {
            "rating": 1386.7854656830757,
            "rating_q975": 1402.256361802325,
            "rating_q025": 1371.3145695638264
        },
        "gemma-3-27b-it": {
            "rating": 1385.8248266500152,
            "rating_q975": 1392.85801175588,
            "rating_q025": 1378.7916415441505
        },
        "kimi-k2-0905-preview": {
            "rating": 1385.739032416696,
            "rating_q975": 1401.0986323720247,
            "rating_q025": 1370.3794324613675
        },
        "qwen2.5-max": {
            "rating": 1385.2856483474545,
            "rating_q975": 1393.1806162216037,
            "rating_q025": 1377.3906804733053
        },
        "deepseek-v3-0324": {
            "rating": 1384.5842450396021,
            "rating_q975": 1391.758500697874,
            "rating_q025": 1377.4099893813302
        },
        "gpt-4.1-2025-04-14": {
            "rating": 1384.5269965521052,
            "rating_q975": 1391.709956386462,
            "rating_q025": 1377.3440367177484
        },
        "qwen3-next-80b-a3b-thinking": {
            "rating": 1382.5396886048875,
            "rating_q975": 1395.3885275761463,
            "rating_q025": 1369.6908496336287
        },
        "mistral-medium-2505": {
            "rating": 1381.7151579999531,
            "rating_q975": 1390.045853688876,
            "rating_q025": 1373.3844623110303
        },
        "gpt-oss-120b": {
            "rating": 1380.470897079443,
            "rating_q975": 1390.0231623994953,
            "rating_q025": 1370.9186317593906
        },
        "deepseek-r1": {
            "rating": 1378.6892288327988,
            "rating_q975": 1388.811918283671,
            "rating_q025": 1368.5665393819265
        },
        "grok-3-mini-beta": {
            "rating": 1377.8288922835407,
            "rating_q975": 1387.4584421518987,
            "rating_q025": 1368.1993424151826
        },
        "gemini-2.5-flash-lite-preview-06-17-thinking": {
            "rating": 1377.0235625208943,
            "rating_q975": 1385.5347640676434,
            "rating_q025": 1368.5123609741452
        },
        "qwen3-235b-a22b": {
            "rating": 1377.0019141168611,
            "rating_q975": 1385.9503256918235,
            "rating_q025": 1368.0535025418988
        },
        "gpt-5-mini-high": {
            "rating": 1376.6164793432945,
            "rating_q975": 1386.7213183751094,
            "rating_q025": 1366.5116403114796
        },
        "qwen3-32b": {
            "rating": 1375.2337342152616,
            "rating_q975": 1395.6873154470345,
            "rating_q025": 1354.7801529834887
        },
        "amazon-nova-experimental-chat-10-09": {
            "rating": 1374.0262264163287,
            "rating_q975": 1392.73759296185,
            "rating_q025": 1355.3148598708074
        },
        "o1-2024-12-17": {
            "rating": 1372.7284280599306,
            "rating_q975": 1381.3623940919513,
            "rating_q025": 1364.09446202791
        },
        "claude-opus-4-20250514-thinking-16k": {
            "rating": 1369.828945973959,
            "rating_q975": 1378.137752040621,
            "rating_q025": 1361.5201399072969
        },
        "gemma-3-12b-it": {
            "rating": 1368.4606915870932,
            "rating_q975": 1389.131688918085,
            "rating_q025": 1347.7896942561013
        },
        "minimax-m1": {
            "rating": 1368.4153550132137,
            "rating_q975": 1376.4012553755542,
            "rating_q025": 1360.4294546508731
        },
        "kimi-k2-0711-preview": {
            "rating": 1367.9105453884558,
            "rating_q975": 1377.225232645584,
            "rating_q025": 1358.5958581313278
        },
        "step-1o-turbo-202506": {
            "rating": 1364.3766559209728,
            "rating_q975": 1378.8844659247584,
            "rating_q025": 1349.8688459171872
        },
        "nvidia-llama-3.3-nemotron-super-49b-v1.5": {
            "rating": 1364.1336874557735,
            "rating_q975": 1387.0541273054116,
            "rating_q025": 1341.2132476061354
        },
        "claude-opus-4-20250514": {
            "rating": 1363.5231608036522,
            "rating_q975": 1371.329663179732,
            "rating_q025": 1355.7166584275724
        },
        "step-3": {
            "rating": 1359.0380884491822,
            "rating_q975": 1377.2225061266884,
            "rating_q025": 1340.853670771676
        },
        "o4-mini-2025-04-16": {
            "rating": 1357.0518603433031,
            "rating_q975": 1364.4069739076733,
            "rating_q025": 1349.696746778933
        },
        "qwen-plus-0125": {
            "rating": 1356.2807576733678,
            "rating_q975": 1374.7551923794463,
            "rating_q025": 1337.8063229672894
        },
        "glm-4-plus-0111": {
            "rating": 1353.8739988388118,
            "rating_q975": 1372.2525802620614,
            "rating_q025": 1335.495417415562
        },
        "o1-preview": {
            "rating": 1352.7227578849554,
            "rating_q975": 1361.5671882552913,
            "rating_q025": 1343.8783275146195
        },
        "qwen3-coder-480b-a35b-instruct": {
            "rating": 1350.9218959020143,
            "rating_q975": 1360.8788493814063,
            "rating_q025": 1340.9649424226222
        },
        "qwq-32b": {
            "rating": 1349.8827611906686,
            "rating_q975": 1358.644408936559,
            "rating_q025": 1341.121113444778
        },
        "claude-sonnet-4-20250514-thinking-32k": {
            "rating": 1347.38559366338,
            "rating_q975": 1355.757073036086,
            "rating_q025": 1339.014114290674
        },
        "mistral-small-2506": {
            "rating": 1345.3410799477099,
            "rating_q975": 1356.2637858833928,
            "rating_q025": 1334.418374012027
        },
        "claude-sonnet-4-20250514": {
            "rating": 1342.5892787801456,
            "rating_q975": 1350.692591299148,
            "rating_q025": 1334.4859662611432
        },
        "o3-mini-high": {
            "rating": 1342.4704746961918,
            "rating_q975": 1352.757053294725,
            "rating_q025": 1332.1838960976586
        },
        "ring-flash-2.0": {
            "rating": 1341.2390432670225,
            "rating_q975": 1359.1507454551006,
            "rating_q025": 1323.3273410789443
        },
        "command-a-03-2025": {
            "rating": 1339.0559659692872,
            "rating_q975": 1345.880400866661,
            "rating_q025": 1332.2315310719134
        },
        "llama-3.3-nemotron-49b-super-v1": {
            "rating": 1336.1663613816322,
            "rating_q975": 1364.5288211112832,
            "rating_q025": 1307.8039016519813
        },
        "deepseek-v3": {
            "rating": 1336.0819236394204,
            "rating_q975": 1345.5230837704214,
            "rating_q025": 1326.6407635084195
        },
        "gemini-2.0-flash-lite-preview-02-05": {
            "rating": 1335.2584402436478,
            "rating_q975": 1344.104472444032,
            "rating_q025": 1326.4124080432637
        },
        "step-2-16k-exp-202412": {
            "rating": 1333.880866896702,
            "rating_q975": 1353.329722397105,
            "rating_q025": 1314.432011396299
        },
        "glm-4.5v": {
            "rating": 1333.1406216648627,
            "rating_q975": 1354.9880375178798,
            "rating_q025": 1311.2932058118456
        },
        "gpt-4.1-mini-2025-04-14": {
            "rating": 1331.7677793854486,
            "rating_q975": 1339.6272201520162,
            "rating_q025": 1323.908338618881
        },
        "hunyuan-turbo-0110": {
            "rating": 1330.6153214915767,
            "rating_q975": 1357.8321562770982,
            "rating_q025": 1303.398486706055
        },
        "llama-3.1-nemotron-ultra-253b-v1": {
            "rating": 1327.7435480810414,
            "rating_q975": 1353.547053167993,
            "rating_q025": 1301.9400429940897
        },
        "gemma-3n-e4b-it": {
            "rating": 1327.6971887033492,
            "rating_q975": 1337.5553884616734,
            "rating_q025": 1317.838988945025
        },
        "qwen3-30b-a3b": {
            "rating": 1325.570037803366,
            "rating_q975": 1334.5883225023279,
            "rating_q025": 1316.551753104404
        },
        "gemini-1.5-pro-002": {
            "rating": 1324.5197423818795,
            "rating_q975": 1331.0477824547932,
            "rating_q025": 1317.9917023089658
        },
        "qwen2.5-plus-1127": {
            "rating": 1321.359197680737,
            "rating_q975": 1334.7856355025729,
            "rating_q025": 1307.9327598589011
        },
        "gpt-5-nano-high": {
            "rating": 1321.1519512239356,
            "rating_q975": 1337.506467636356,
            "rating_q025": 1304.7974348115151
        },
        "o3-mini": {
            "rating": 1320.2152466792234,
            "rating_q975": 1326.6147145926116,
            "rating_q025": 1313.8157787658351
        },
        "o1-mini": {
            "rating": 1319.7593401246245,
            "rating_q975": 1326.6639138769137,
            "rating_q025": 1312.8547663723352
        },
        "hunyuan-turbos-20250226": {
            "rating": 1319.6839539699354,
            "rating_q975": 1347.3531463080944,
            "rating_q025": 1292.0147616317763
        },
        "yi-lightning": {
            "rating": 1319.5418202491878,
            "rating_q975": 1328.9056190689685,
            "rating_q025": 1310.1780214294072
        },
        "grok-2-2024-08-13": {
            "rating": 1318.383203065367,
            "rating_q975": 1325.0902291582945,
            "rating_q025": 1311.6761769724396
        },
        "athene-v2-chat": {
            "rating": 1311.0065767630497,
            "rating_q975": 1319.8789465539492,
            "rating_q025": 1302.1342069721502
        },
        "gemma-3-4b-it": {
            "rating": 1308.2027187972817,
            "rating_q975": 1329.0256426614417,
            "rating_q025": 1287.3797949331217
        },
        "grok-2-mini-2024-08-13": {
            "rating": 1303.5164313777536,
            "rating_q975": 1310.5799337264334,
            "rating_q025": 1296.4529290290739
        },
        "claude-3-7-sonnet-20250219-thinking-32k": {
            "rating": 1303.4013088977342,
            "rating_q975": 1311.3807851818142,
            "rating_q025": 1295.4218326136543
        },
        "gemini-1.5-flash-002": {
            "rating": 1303.25530518826,
            "rating_q975": 1311.2593922085723,
            "rating_q025": 1295.2512181679479
        },
        "gpt-oss-20b": {
            "rating": 1301.579949299232,
            "rating_q975": 1316.4912156039468,
            "rating_q025": 1286.6686829945174
        },
        "gpt-4.1-nano-2025-04-14": {
            "rating": 1301.0064474124367,
            "rating_q975": 1317.3835956878058,
            "rating_q025": 1284.6292991370676
        },
        "gpt-4o-2024-05-13": {
            "rating": 1298.898027282538,
            "rating_q975": 1305.1954336523806,
            "rating_q025": 1292.6006209126951
        },
        "llama-3.1-405b-instruct-bf16": {
            "rating": 1298.7426704501258,
            "rating_q975": 1305.7624778391712,
            "rating_q025": 1291.7228630610805
        },
        "glm-4-plus": {
            "rating": 1298.7081471656024,
            "rating_q975": 1308.0365197851809,
            "rating_q025": 1289.379774546024
        },
        "athene-70b-0725": {
            "rating": 1297.3497308199662,
            "rating_q975": 1308.6175969682427,
            "rating_q025": 1286.0818646716898
        },
        "llama-3.1-nemotron-70b-instruct": {
            "rating": 1296.995572360052,
            "rating_q975": 1313.0370224152045,
            "rating_q025": 1280.9541223048993
        },
        "hunyuan-large-2025-02-10": {
            "rating": 1295.3446805533918,
            "rating_q975": 1316.3095808715427,
            "rating_q025": 1274.3797802352408
        },
        "deepseek-v2.5-1210": {
            "rating": 1292.522190394725,
            "rating_q975": 1309.1586416975717,
            "rating_q025": 1275.8857390918781
        },
        "llama-4-maverick-17b-128e-instruct": {
            "rating": 1291.5419291646874,
            "rating_q975": 1299.4128872561068,
            "rating_q025": 1283.670971073268
        },
        "gpt-4o-mini-2024-07-18": {
            "rating": 1289.9026815652119,
            "rating_q975": 1296.1139363809662,
            "rating_q025": 1283.6914267494576
        },
        "llama-3.3-70b-instruct": {
            "rating": 1289.1208429467936,
            "rating_q975": 1295.340158917185,
            "rating_q025": 1282.9015269764022
        },
        "hunyuan-standard-2025-02-10": {
            "rating": 1288.4054077519172,
            "rating_q975": 1310.0650337672307,
            "rating_q025": 1266.7457817366037
        },
        "llama-3.1-405b-instruct-fp8": {
            "rating": 1288.174476388408,
            "rating_q975": 1295.0951413329226,
            "rating_q025": 1281.2538114438935
        },
        "qwen-max-0919": {
            "rating": 1283.0352379092078,
            "rating_q975": 1293.9375902369275,
            "rating_q025": 1272.1328855814882
        },
        "llama-4-scout-17b-16e-instruct": {
            "rating": 1282.4821644536205,
            "rating_q975": 1291.4384678833894,
            "rating_q025": 1273.5258610238516
        },
        "llama-3.1-70b-instruct": {
            "rating": 1279.8669962858878,
            "rating_q975": 1286.8771630828446,
            "rating_q025": 1272.856829488931
        },
        "qwen2.5-72b-instruct": {
            "rating": 1278.8322247451574,
            "rating_q975": 1286.3625674885807,
            "rating_q025": 1271.3018820017342
        },
        "gpt-4o-2024-08-06": {
            "rating": 1277.869414096361,
            "rating_q975": 1285.564918512931,
            "rating_q025": 1270.173909679791
        },
        "deepseek-v2.5": {
            "rating": 1277.462632851987,
            "rating_q975": 1286.722854127895,
            "rating_q025": 1268.2024115760792
        },
        "claude-3-5-sonnet-20241022": {
            "rating": 1274.9683305955127,
            "rating_q975": 1280.2849481258322,
            "rating_q025": 1269.6517130651932
        },
        "claude-3-5-sonnet-20240620": {
            "rating": 1274.0478599425044,
            "rating_q975": 1280.8631310696962,
            "rating_q025": 1267.2325888153125
        },
        "mistral-small-3.1-24b-instruct-2503": {
            "rating": 1272.5159215378294,
            "rating_q975": 1281.2483761398314,
            "rating_q025": 1263.7834669358274
        },
        "gemini-advanced-0514": {
            "rating": 1271.657446103375,
            "rating_q975": 1280.6225110535452,
            "rating_q025": 1262.6923811532047
        },
        "gemini-1.5-pro-001": {
            "rating": 1271.2423737707495,
            "rating_q975": 1278.749372140559,
            "rating_q025": 1263.73537540094
        },
        "llama-3.1-tulu-3-70b": {
            "rating": 1270.8106182638498,
            "rating_q975": 1295.2812023033684,
            "rating_q025": 1246.3400342243312
        },
        "mistral-large-2407": {
            "rating": 1270.0344086153827,
            "rating_q975": 1277.9060300774734,
            "rating_q025": 1262.1627871532921
        },
        "reka-core-20240904": {
            "rating": 1269.6838021830674,
            "rating_q975": 1285.7075532934862,
            "rating_q025": 1253.6600510726487
        },
        "hunyuan-large-vision": {
            "rating": 1266.898217216672,
            "rating_q975": 1286.7977606923562,
            "rating_q025": 1246.998673740988
        },
        "mistral-large-2411": {
            "rating": 1264.0494861167786,
            "rating_q975": 1272.522404463159,
            "rating_q025": 1255.576567770398
        },
        "gpt-4-turbo-2024-04-09": {
            "rating": 1259.6102319307347,
            "rating_q975": 1266.6232063680418,
            "rating_q025": 1252.5972574934276
        },
        "amazon-nova-pro-v1.0": {
            "rating": 1259.0150255363578,
            "rating_q975": 1268.0016437799181,
            "rating_q025": 1250.0284072927975
        },
        "gpt-4-1106-preview": {
            "rating": 1258.4096591159282,
            "rating_q975": 1265.7001792245799,
            "rating_q025": 1251.1191390072765
        },
        "claude-3-opus-20240229": {
            "rating": 1257.7583334388419,
            "rating_q975": 1263.401137835857,
            "rating_q025": 1252.1155290418267
        },
        "command-r-plus-08-2024": {
            "rating": 1256.021294283291,
            "rating_q975": 1270.29122017296,
            "rating_q025": 1241.7513683936218
        },
        "gpt-4-0125-preview": {
            "rating": 1253.9727002490845,
            "rating_q975": 1261.3860040610537,
            "rating_q025": 1246.5593964371153
        },
        "jamba-1.5-large": {
            "rating": 1253.1723468260561,
            "rating_q975": 1269.0167593455963,
            "rating_q025": 1237.327934306516
        },
        "claude-3-5-haiku-20241022": {
            "rating": 1249.946521238369,
            "rating_q975": 1255.9204238929012,
            "rating_q025": 1243.972618583837
        },
        "olmo-2-0325-32b-instruct": {
            "rating": 1243.0491685098464,
            "rating_q975": 1266.9016298314486,
            "rating_q025": 1219.196707188244
        },
        "magistral-medium-2506": {
            "rating": 1239.6575419657834,
            "rating_q975": 1254.1728727826235,
            "rating_q025": 1225.1422111489433
        },
        "mistral-small-24b-instruct-2501": {
            "rating": 1238.8286287428257,
            "rating_q975": 1250.4283091827776,
            "rating_q025": 1227.2289483028737
        },
        "c4ai-aya-expanse-32b": {
            "rating": 1236.479842408705,
            "rating_q975": 1245.4333410814593,
            "rating_q025": 1227.5263437359508
        },
        "gemini-1.5-flash-8b-001": {
            "rating": 1236.416957827025,
            "rating_q975": 1244.4362185025368,
            "rating_q025": 1228.3976971515133
        },
        "amazon-nova-lite-v1.0": {
            "rating": 1236.1311443181846,
            "rating_q975": 1246.2597258272756,
            "rating_q025": 1226.0025628090937
        },
        "gemini-1.5-flash-001": {
            "rating": 1235.6815009782795,
            "rating_q975": 1243.447441865521,
            "rating_q025": 1227.915560091038
        },
        "gemma-2-9b-it-simpo": {
            "rating": 1235.055569445789,
            "rating_q975": 1249.7515070555528,
            "rating_q025": 1220.359631836025
        },
        "nemotron-4-340b-instruct": {
            "rating": 1232.8062863464731,
            "rating_q975": 1244.3008060124203,
            "rating_q025": 1221.311766680526
        },
        "gemma-2-27b-it": {
            "rating": 1232.1911641427141,
            "rating_q975": 1238.3282941465534,
            "rating_q025": 1226.0540341388748
        },
        "llama-3.1-nemotron-51b-instruct": {
            "rating": 1229.9071145870364,
            "rating_q975": 1251.428083543394,
            "rating_q025": 1208.3861456306788
        },
        "llama-3-70b-instruct": {
            "rating": 1229.708287796976,
            "rating_q975": 1236.6706084728378,
            "rating_q025": 1222.7459671211143
        },
        "glm-4-0520": {
            "rating": 1228.7810428520538,
            "rating_q975": 1243.7075879425645,
            "rating_q025": 1213.8544977615431
        },
        "reka-flash-20240904": {
            "rating": 1226.7124240637572,
            "rating_q975": 1242.503203009939,
            "rating_q025": 1210.9216451175755
        },
        "qwen2.5-coder-32b-instruct": {
            "rating": 1225.4333623069397,
            "rating_q975": 1243.50115247867,
            "rating_q025": 1207.3655721352093
        },
        "command-r-08-2024": {
            "rating": 1222.8779285467838,
            "rating_q975": 1237.0472387207399,
            "rating_q025": 1208.7086183728277
        },
        "command-r-plus": {
            "rating": 1220.306191895092,
            "rating_q975": 1228.3423855990272,
            "rating_q025": 1212.269998191157
        },
        "amazon-nova-micro-v1.0": {
            "rating": 1214.287615544822,
            "rating_q975": 1224.5914368657182,
            "rating_q025": 1203.983794223926
        },
        "claude-3-sonnet-20240229": {
            "rating": 1212.96268234145,
            "rating_q975": 1220.308397102709,
            "rating_q025": 1205.6169675801912
        },
        "phi-4": {
            "rating": 1210.4372785107373,
            "rating_q975": 1219.8869371750845,
            "rating_q025": 1200.98761984639
        },
        "c4ai-aya-expanse-8b": {
            "rating": 1208.0029824711235,
            "rating_q975": 1222.1596375166725,
            "rating_q025": 1193.8463274255744
        },
        "gemma-2-9b-it": {
            "rating": 1207.5652124947042,
            "rating_q975": 1214.5146030889075,
            "rating_q025": 1200.6158219005008
        },
        "hunyuan-standard-256k": {
            "rating": 1204.9827560699396,
            "rating_q975": 1229.8388696568695,
            "rating_q025": 1180.1266424830096
        },
        "qwen2-72b-instruct": {
            "rating": 1199.0986782145665,
            "rating_q975": 1208.1927276568251,
            "rating_q025": 1190.0046287723078
        },
        "llama-3.1-8b-instruct": {
            "rating": 1197.313619629198,
            "rating_q975": 1204.8439093627696,
            "rating_q025": 1189.7833298956264
        },
        "llama-3.1-tulu-3-8b": {
            "rating": 1197.3011792056882,
            "rating_q975": 1221.9712346102324,
            "rating_q025": 1172.631123801144
        },
        "jamba-1.5-mini": {
            "rating": 1194.1582111866892,
            "rating_q975": 1209.8072264190134,
            "rating_q025": 1178.509195954365
        },
        "ministral-8b-2410": {
            "rating": 1193.076978324335,
            "rating_q975": 1212.9146835750537,
            "rating_q025": 1173.2392730736162
        },
        "claude-3-haiku-20240307": {
            "rating": 1182.4207515716569,
            "rating_q975": 1189.2830839350754,
            "rating_q025": 1175.5584192082383
        },
        "gpt-4-0314": {
            "rating": 1180.713209569406,
            "rating_q975": 1189.7880739170457,
            "rating_q025": 1171.6383452217663
        },
        "yi-1.5-34b-chat": {
            "rating": 1176.4713167837972,
            "rating_q975": 1187.07059342984,
            "rating_q025": 1165.8720401377543
        },
        "command-r": {
            "rating": 1174.5338085445328,
            "rating_q975": 1183.5447787913702,
            "rating_q025": 1165.5228382976954
        },
        "llama-3-8b-instruct": {
            "rating": 1174.3157053698678,
            "rating_q975": 1181.9119242089564,
            "rating_q025": 1166.7194865307792
        },
        "reka-flash-21b-20240226-online": {
            "rating": 1171.6338658055133,
            "rating_q975": 1185.035006227952,
            "rating_q025": 1158.2327253830747
        },
        "qwen1.5-110b-chat": {
            "rating": 1170.115388684529,
            "rating_q975": 1180.958659070349,
            "rating_q025": 1159.272118298709
        },
        "internlm2_5-20b-chat": {
            "rating": 1169.0463911989918,
            "rating_q975": 1183.6661496926206,
            "rating_q025": 1154.426632705363
        },
        "deepseek-coder-v2": {
            "rating": 1166.4046036760997,
            "rating_q975": 1179.149375684388,
            "rating_q025": 1153.6598316678114
        },
        "reka-flash-21b-20240226": {
            "rating": 1163.430230542444,
            "rating_q975": 1174.6676661071187,
            "rating_q025": 1152.1927949777692
        },
        "gemma-2-2b-it": {
            "rating": 1162.8248907369402,
            "rating_q975": 1170.3832769812263,
            "rating_q025": 1155.2665044926541
        },
        "mistral-medium": {
            "rating": 1162.6276779110585,
            "rating_q975": 1172.9536870260438,
            "rating_q025": 1152.3016687960733
        },
        "qwen1.5-72b-chat": {
            "rating": 1162.270067663695,
            "rating_q975": 1171.9224772594662,
            "rating_q025": 1152.617658067924
        },
        "qwq-32b-preview": {
            "rating": 1158.170848532854,
            "rating_q975": 1183.4039303192858,
            "rating_q025": 1132.9377667464223
        },
        "mistral-large-2402": {
            "rating": 1157.7002652564818,
            "rating_q975": 1166.4596666263622,
            "rating_q025": 1148.9408638866014
        },
        "gpt-4-0613": {
            "rating": 1157.5144127580957,
            "rating_q975": 1165.4030893288764,
            "rating_q025": 1149.625736187315
        },
        "mixtral-8x22b-instruct-v0.1": {
            "rating": 1154.9375541686227,
            "rating_q975": 1163.6940876490078,
            "rating_q025": 1146.1810206882376
        },
        "gemini-pro-dev-api": {
            "rating": 1147.6773636659207,
            "rating_q975": 1161.1829669053616,
            "rating_q025": 1134.1717604264798
        },
        "zephyr-orpo-141b-A35b-v0.1": {
            "rating": 1146.8595842296045,
            "rating_q975": 1167.7322259510674,
            "rating_q025": 1125.9869425081415
        },
        "starling-lm-7b-beta": {
            "rating": 1146.2402296587186,
            "rating_q975": 1159.810793313246,
            "rating_q025": 1132.6696660041912
        },
        "phi-3-medium-4k-instruct": {
            "rating": 1141.8503660689953,
            "rating_q975": 1152.2270859286157,
            "rating_q025": 1131.473646209375
        },
        "granite-3.1-8b-instruct": {
            "rating": 1141.144194799956,
            "rating_q975": 1166.2940242479908,
            "rating_q025": 1115.9943653519213
        },
        "yi-34b-chat": {
            "rating": 1137.7155609484316,
            "rating_q975": 1150.8719522089464,
            "rating_q025": 1124.559169687917
        },
        "qwen1.5-32b-chat": {
            "rating": 1136.5044672986835,
            "rating_q975": 1147.8300301150784,
            "rating_q025": 1125.1789044822885
        },
        "llama-2-70b-chat": {
            "rating": 1123.7457783045843,
            "rating_q975": 1133.551357510587,
            "rating_q025": 1113.9401990985816
        },
        "gemini-pro": {
            "rating": 1122.4029967000024,
            "rating_q975": 1142.81637859329,
            "rating_q025": 1101.9896148067148
        },
        "mixtral-8x7b-instruct-v0.1": {
            "rating": 1121.1652278106249,
            "rating_q975": 1129.283726941985,
            "rating_q025": 1113.0467286792648
        },
        "starling-lm-7b-alpha": {
            "rating": 1114.2779224058563,
            "rating_q975": 1129.3427658113371,
            "rating_q025": 1099.2130790003755
        },
        "wizardlm-70b": {
            "rating": 1112.9552105028688,
            "rating_q975": 1130.8055233087307,
            "rating_q025": 1095.104897697007
        },
        "granite-3.1-2b-instruct": {
            "rating": 1112.033373407377,
            "rating_q975": 1139.3373945934281,
            "rating_q025": 1084.7293522213258
        },
        "phi-3-small-8k-instruct": {
            "rating": 1110.8543718467713,
            "rating_q975": 1122.9819119805732,
            "rating_q025": 1098.7268317129694
        },
        "llama-3.2-3b-instruct": {
            "rating": 1110.0801566253208,
            "rating_q975": 1127.3378005806574,
            "rating_q025": 1092.8225126699842
        },
        "tulu-2-dpo-70b": {
            "rating": 1108.877814772195,
            "rating_q975": 1127.5965299852503,
            "rating_q025": 1090.1590995591398
        },
        "nous-hermes-2-mixtral-8x7b-dpo": {
            "rating": 1107.8500569664918,
            "rating_q975": 1130.84078484017,
            "rating_q025": 1084.8593290928136
        },
        "qwen1.5-14b-chat": {
            "rating": 1107.4949977662197,
            "rating_q975": 1120.7410673966936,
            "rating_q025": 1094.248928135746
        },
        "dbrx-instruct-preview": {
            "rating": 1104.1131230021228,
            "rating_q975": 1115.5945930214803,
            "rating_q025": 1092.6316529827654
        },
        "vicuna-33b": {
            "rating": 1103.534577038758,
            "rating_q975": 1114.9888031173623,
            "rating_q025": 1092.0803509601537
        },
        "granite-3.0-8b-instruct": {
            "rating": 1103.0595818178904,
            "rating_q975": 1122.163324254957,
            "rating_q025": 1083.9558393808238
        },
        "llama2-70b-steerlm-chat": {
            "rating": 1098.2642102565242,
            "rating_q975": 1122.2144780625215,
            "rating_q025": 1074.3139424505268
        },
        "gpt-3.5-turbo-0125": {
            "rating": 1091.3309148179874,
            "rating_q975": 1099.5792437102507,
            "rating_q025": 1083.082585925724
        },
        "llama-2-13b-chat": {
            "rating": 1085.9889972307988,
            "rating_q975": 1098.6897777524086,
            "rating_q025": 1073.2882167091889
        },
        "snowflake-arctic-instruct": {
            "rating": 1085.944141923464,
            "rating_q975": 1097.4024214476542,
            "rating_q025": 1074.4858623992739
        },
        "mistral-7b-instruct-v0.2": {
            "rating": 1082.7783858566756,
            "rating_q975": 1095.1738751767025,
            "rating_q025": 1070.3828965366488
        },
        "openchat-3.5-0106": {
            "rating": 1082.595713315503,
            "rating_q975": 1096.5733770030147,
            "rating_q025": 1068.6180496279912
        },
        "gemma-1.1-7b-it": {
            "rating": 1082.2836407052253,
            "rating_q975": 1093.2662203418834,
            "rating_q025": 1071.3010610685672
        },
        "qwen1.5-7b-chat": {
            "rating": 1080.022692433854,
            "rating_q975": 1101.096402316182,
            "rating_q025": 1058.948982551526
        },
        "granite-3.0-2b-instruct": {
            "rating": 1076.3626641430355,
            "rating_q975": 1095.0177239914885,
            "rating_q025": 1057.7076042945826
        },
        "solar-10.7b-instruct-v1.0": {
            "rating": 1076.1526357003406,
            "rating_q975": 1099.9716008509972,
            "rating_q025": 1052.333670549684
        },
        "wizardlm-13b": {
            "rating": 1072.9432542498475,
            "rating_q975": 1091.1833516821976,
            "rating_q025": 1054.7031568174975
        },
        "phi-3-mini-4k-instruct-june-2024": {
            "rating": 1072.0426300898796,
            "rating_q975": 1086.5034046575254,
            "rating_q025": 1057.5818555222338
        },
        "openchat-3.5": {
            "rating": 1071.4161377252526,
            "rating_q975": 1089.2116551794345,
            "rating_q025": 1053.6206202710707
        },
        "codellama-34b-instruct": {
            "rating": 1069.9318860102453,
            "rating_q975": 1087.504427300172,
            "rating_q025": 1052.3593447203186
        },
        "deepseek-llm-67b-chat": {
            "rating": 1069.8366886759209,
            "rating_q975": 1091.850480302668,
            "rating_q025": 1047.8228970491737
        },
        "dolphin-2.2.1-mistral-7b": {
            "rating": 1069.3830638002155,
            "rating_q975": 1103.0047846311425,
            "rating_q025": 1035.7613429692885
        },
        "openhermes-2.5-mistral-7b": {
            "rating": 1069.321828479327,
            "rating_q975": 1089.790755752224,
            "rating_q025": 1048.85290120643
        },
        "phi-3-mini-4k-instruct": {
            "rating": 1065.8663724629755,
            "rating_q975": 1078.2023527531103,
            "rating_q025": 1053.5303921728407
        },
        "zephyr-7b-beta": {
            "rating": 1064.0403259116547,
            "rating_q975": 1079.8157729367397,
            "rating_q025": 1048.2648788865697
        },
        "guanaco-33b": {
            "rating": 1063.4051808381994,
            "rating_q975": 1090.4313215457896,
            "rating_q025": 1036.3790401306092
        },
        "llama-3.2-1b-instruct": {
            "rating": 1058.8590109332627,
            "rating_q975": 1076.6691539383726,
            "rating_q025": 1041.0488679281527
        },
        "gpt-3.5-turbo-1106": {
            "rating": 1055.2295721210119,
            "rating_q975": 1070.2045508385188,
            "rating_q025": 1040.254593403505
        },
        "smollm2-1.7b-instruct": {
            "rating": 1052.7026737632423,
            "rating_q975": 1088.3021342249858,
            "rating_q025": 1017.1032133014987
        },
        "llama-2-7b-chat": {
            "rating": 1051.048595788032,
            "rating_q975": 1064.341225797623,
            "rating_q025": 1037.7559657784407
        },
        "mpt-30b-chat": {
            "rating": 1042.28189026171,
            "rating_q975": 1069.0196295416472,
            "rating_q025": 1015.5441509817729
        },
        "vicuna-13b": {
            "rating": 1038.4069319911046,
            "rating_q975": 1051.2653919754569,
            "rating_q025": 1025.5484720067523
        },
        "zephyr-7b-alpha": {
            "rating": 1033.1460194527958,
            "rating_q975": 1068.0726717909924,
            "rating_q025": 998.2193671145993
        },
        "phi-3-mini-128k-instruct": {
            "rating": 1027.0300178104733,
            "rating_q975": 1040.5049160944586,
            "rating_q025": 1013.555119526488
        },
        "gemma-7b-it": {
            "rating": 1024.5939250044578,
            "rating_q975": 1041.8037111728847,
            "rating_q025": 1007.3841388360308
        },
        "falcon-180b-chat": {
            "rating": 1022.6542931812762,
            "rating_q975": 1065.109357681914,
            "rating_q025": 980.1992286806385
        },
        "stripedhyena-nous-7b": {
            "rating": 1015.9541283217671,
            "rating_q975": 1036.950381118471,
            "rating_q025": 994.9578755250635
        },
        "palm-2": {
            "rating": 1015.2880770245529,
            "rating_q975": 1033.5194428390569,
            "rating_q025": 997.0567112100488
        },
        "qwen-14b-chat": {
            "rating": 1014.4677824027024,
            "rating_q975": 1036.029989308046,
            "rating_q025": 992.9055754973589
        },
        "olmo-7b-instruct": {
            "rating": 1011.9434961090767,
            "rating_q975": 1031.8505565568644,
            "rating_q025": 992.036435661289
        },
        "vicuna-7b": {
            "rating": 1004.9011252303088,
            "rating_q975": 1023.8651519561555,
            "rating_q025": 985.9370985044621
        },
        "mistral-7b-instruct": {
            "rating": 1002.1835623460529,
            "rating_q975": 1020.25558416908,
            "rating_q025": 984.1115405230258
        },
        "gemma-1.1-2b-it": {
            "rating": 1000.5954300185542,
            "rating_q975": 1016.6693388794425,
            "rating_q025": 984.5215211576659
        },
        "koala-13b": {
            "rating": 990.0577237981602,
            "rating_q975": 1010.7789543008732,
            "rating_q025": 969.3364932954471
        },
        "qwen1.5-4b-chat": {
            "rating": 980.7217508370675,
            "rating_q975": 999.0867905662935,
            "rating_q025": 962.3567111078414
        },
        "gemma-2b-it": {
            "rating": 954.4690729171807,
            "rating_q975": 977.3347998123292,
            "rating_q025": 931.6033460220323
        },
        "chatglm3-6b": {
            "rating": 935.545857322355,
            "rating_q975": 958.789174215444,
            "rating_q025": 912.3025404292661
        },
        "RWKV-4-Raven-14B": {
            "rating": 931.6406471491939,
            "rating_q975": 955.4620559354748,
            "rating_q025": 907.819238362913
        },
        "chatglm2-6b": {
            "rating": 920.1851741729888,
            "rating_q975": 950.9376417426397,
            "rating_q025": 889.4327066033379
        },
        "mpt-7b-chat": {
            "rating": 917.1170926946212,
            "rating_q975": 941.8523488533996,
            "rating_q025": 892.3818365358428
        },
        "gpt4all-13b-snoozy": {
            "rating": 905.7549211712169,
            "rating_q975": 942.7647698062572,
            "rating_q025": 868.7450725361766
        },
        "oasst-pythia-12b": {
            "rating": 900.5140050294224,
            "rating_q975": 921.6958875015417,
            "rating_q025": 879.332122557303
        },
        "alpaca-13b": {
            "rating": 886.6380380903032,
            "rating_q975": 908.5899833431464,
            "rating_q025": 864.68609283746
        },
        "fastchat-t5-3b": {
            "rating": 869.3561294657222,
            "rating_q975": 894.8840807888784,
            "rating_q025": 843.8281781425661
        },
        "chatglm-6b": {
            "rating": 853.3064954781796,
            "rating_q975": 878.7078523645556,
            "rating_q025": 827.9051385918036
        },
        "llama-13b": {
            "rating": 810.0280048722186,
            "rating_q975": 843.0392471413758,
            "rating_q025": 777.0167626030615
        },
        "stablelm-tuned-alpha-7b": {
            "rating": 807.0915129960849,
            "rating_q975": 834.7743861528807,
            "rating_q025": 779.4086398392892
        },
        "dolly-v2-12b": {
            "rating": 804.6525988084102,
            "rating_q975": 833.7009996827497,
            "rating_q025": 775.6041979340706
        }
    },
    "industry_mathematical": {
        "claude-sonnet-4-5-20250929-thinking-32k": {
            "rating": 1467.1419469322282,
            "rating_q975": 1491.1226815141467,
            "rating_q025": 1443.1612123503096
        },
        "gemini-2.5-pro": {
            "rating": 1461.543935280738,
            "rating_q975": 1472.0626014004415,
            "rating_q025": 1451.0252691610344
        },
        "glm-4.6": {
            "rating": 1454.1645134579787,
            "rating_q975": 1480.7519758048315,
            "rating_q025": 1427.577051111126
        },
        "qwen3-max-preview": {
            "rating": 1452.1126605761413,
            "rating_q975": 1469.104978020569,
            "rating_q025": 1435.1203431317135
        },
        "deepseek-v3.1-thinking": {
            "rating": 1446.6917970394252,
            "rating_q975": 1470.7188579902504,
            "rating_q025": 1422.6647360886
        },
        "longcat-flash-chat": {
            "rating": 1445.4458764130848,
            "rating_q975": 1470.424874784884,
            "rating_q025": 1420.4668780412856
        },
        "qwen3-235b-a22b-thinking-2507": {
            "rating": 1443.442390031232,
            "rating_q975": 1467.7210900478321,
            "rating_q025": 1419.1636900146318
        },
        "qwen3-vl-235b-a22b-thinking": {
            "rating": 1442.7866710130806,
            "rating_q975": 1472.447389486324,
            "rating_q025": 1413.1259525398373
        },
        "qwen3-235b-a22b-instruct-2507": {
            "rating": 1442.141034933896,
            "rating_q975": 1455.6452918626048,
            "rating_q025": 1428.6367780051871
        },
        "qwen3-next-80b-a3b-instruct": {
            "rating": 1439.7628833884105,
            "rating_q975": 1459.4854265397769,
            "rating_q025": 1420.0403402370441
        },
        "claude-opus-4-1-20250805": {
            "rating": 1438.5337630835656,
            "rating_q975": 1451.4011320619768,
            "rating_q025": 1425.6663941051545
        },
        "glm-4.5": {
            "rating": 1437.2841090785353,
            "rating_q975": 1454.0680100862,
            "rating_q025": 1420.5002080708705
        },
        "claude-opus-4-1-20250805-thinking-16k": {
            "rating": 1436.5306958744172,
            "rating_q975": 1451.9686182566493,
            "rating_q025": 1421.0927734921852
        },
        "grok-4-0709": {
            "rating": 1436.2180612204168,
            "rating_q975": 1450.1815476065412,
            "rating_q025": 1422.2545748342923
        },
        "o3-2025-04-16": {
            "rating": 1432.680259436861,
            "rating_q975": 1443.0548090349357,
            "rating_q025": 1422.3057098387862
        },
        "grok-4-fast": {
            "rating": 1432.3632828008458,
            "rating_q975": 1463.875746963083,
            "rating_q025": 1400.8508186386086
        },
        "gemini-2.5-flash-preview-09-2025": {
            "rating": 1431.3277987737758,
            "rating_q975": 1454.8651161932864,
            "rating_q025": 1407.7904813542652
        },
        "qwen3-max-2025-09-23": {
            "rating": 1427.4893176074777,
            "rating_q975": 1453.098412929011,
            "rating_q025": 1401.8802222859445
        },
        "deepseek-v3.2-exp-thinking": {
            "rating": 1427.4335301150543,
            "rating_q975": 1458.209142011843,
            "rating_q025": 1396.6579182182656
        },
        "gemini-2.5-flash": {
            "rating": 1425.5845133604769,
            "rating_q975": 1435.4692113579572,
            "rating_q025": 1415.6998153629966
        },
        "qwen3-32b": {
            "rating": 1425.2650003633273,
            "rating_q975": 1457.1881820161875,
            "rating_q025": 1393.3418187104671
        },
        "mistral-medium-2508": {
            "rating": 1420.5310880462416,
            "rating_q975": 1435.1934697977663,
            "rating_q025": 1405.868706294717
        },
        "deepseek-v3.1": {
            "rating": 1420.2744943010837,
            "rating_q975": 1439.8225954990587,
            "rating_q025": 1400.7263931031086
        },
        "qwen3-vl-235b-a22b-instruct": {
            "rating": 1419.4223385046546,
            "rating_q975": 1445.6481007759578,
            "rating_q025": 1393.1965762333514
        },
        "qwen3-30b-a3b-instruct-2507": {
            "rating": 1415.448091488963,
            "rating_q975": 1431.78085085443,
            "rating_q025": 1399.115332123496
        },
        "gpt-4.5-preview-2025-02-27": {
            "rating": 1414.9723456665702,
            "rating_q975": 1430.3296340363104,
            "rating_q025": 1399.61505729683
        },
        "deepseek-r1-0528": {
            "rating": 1414.964946065031,
            "rating_q975": 1433.3227148198398,
            "rating_q025": 1396.6071773102221
        },
        "gpt-5-high": {
            "rating": 1411.7308661943441,
            "rating_q975": 1426.3444218121065,
            "rating_q025": 1397.1173105765818
        },
        "grok-3-preview-02-24": {
            "rating": 1410.1989956131745,
            "rating_q975": 1421.4413221680459,
            "rating_q025": 1398.956669058303
        },
        "claude-haiku-4-5-20251001": {
            "rating": 1410.1699803293038,
            "rating_q975": 1435.9328092786477,
            "rating_q025": 1384.40715137996
        },
        "minimax-m1": {
            "rating": 1409.2548013175938,
            "rating_q975": 1422.307064436693,
            "rating_q025": 1396.2025381984945
        },
        "mai-1-preview": {
            "rating": 1407.3962157531305,
            "rating_q975": 1427.7129246957065,
            "rating_q025": 1387.0795068105544
        },
        "qwen3-235b-a22b-no-thinking": {
            "rating": 1405.8164115575591,
            "rating_q975": 1417.758515519898,
            "rating_q025": 1393.8743075952202
        },
        "qwen3-235b-a22b": {
            "rating": 1403.9380254579335,
            "rating_q975": 1418.4550419454367,
            "rating_q025": 1389.4210089704302
        },
        "o3-mini-high": {
            "rating": 1403.5572844940612,
            "rating_q975": 1417.186128422195,
            "rating_q025": 1389.9284405659273
        },
        "chatgpt-4o-latest-20250326": {
            "rating": 1403.415893484186,
            "rating_q975": 1413.4707964647916,
            "rating_q025": 1393.3609905035803
        },
        "kimi-k2-0905-preview": {
            "rating": 1402.6921153158885,
            "rating_q975": 1426.4258427805644,
            "rating_q025": 1378.9583878512126
        },
        "nvidia-llama-3.3-nemotron-super-49b-v1.5": {
            "rating": 1401.9240414565804,
            "rating_q975": 1440.2644793670027,
            "rating_q025": 1363.5836035461582
        },
        "claude-sonnet-4-5-20250929": {
            "rating": 1401.7832260080522,
            "rating_q975": 1433.1931822616712,
            "rating_q025": 1370.3732697544333
        },
        "amazon-nova-experimental-chat-10-09": {
            "rating": 1400.9998010691118,
            "rating_q975": 1437.4633661495477,
            "rating_q025": 1364.5362359886758
        },
        "gpt-5-chat": {
            "rating": 1400.869569798986,
            "rating_q975": 1416.4515680800828,
            "rating_q025": 1385.2875715178893
        },
        "glm-4.5-air": {
            "rating": 1398.6304115407454,
            "rating_q975": 1414.7596196471402,
            "rating_q025": 1382.5012034343506
        },
        "qwen3-next-80b-a3b-thinking": {
            "rating": 1396.407510126223,
            "rating_q975": 1418.949384041338,
            "rating_q025": 1373.8656362111083
        },
        "o1-2024-12-17": {
            "rating": 1395.1291920337542,
            "rating_q975": 1406.1980333567071,
            "rating_q025": 1384.0603507108012
        },
        "claude-opus-4-20250514-thinking-16k": {
            "rating": 1394.9922233326913,
            "rating_q975": 1407.5757315723645,
            "rating_q025": 1382.4087150930181
        },
        "deepseek-r1": {
            "rating": 1393.165580554926,
            "rating_q975": 1407.5373730779875,
            "rating_q025": 1378.7937880318646
        },
        "hunyuan-t1-20250711": {
            "rating": 1388.7893761623745,
            "rating_q975": 1427.0411020639765,
            "rating_q025": 1350.5376502607726
        },
        "gpt-5-mini-high": {
            "rating": 1388.5795416810083,
            "rating_q975": 1406.029155115662,
            "rating_q025": 1371.1299282463547
        },
        "claude-sonnet-4-20250514-thinking-32k": {
            "rating": 1387.5280660625783,
            "rating_q975": 1400.5710315346075,
            "rating_q025": 1374.485100590549
        },
        "gpt-oss-120b": {
            "rating": 1386.6970823192971,
            "rating_q975": 1402.4156946721387,
            "rating_q025": 1370.9784699664556
        },
        "o1-preview": {
            "rating": 1385.472751417433,
            "rating_q975": 1395.3388597842286,
            "rating_q025": 1375.6066430506376
        },
        "o4-mini-2025-04-16": {
            "rating": 1385.3127145151195,
            "rating_q975": 1396.1320110999884,
            "rating_q025": 1374.4934179302506
        },
        "o3-mini": {
            "rating": 1385.2232371772793,
            "rating_q975": 1393.806891756659,
            "rating_q025": 1376.6395825978996
        },
        "step-3": {
            "rating": 1383.1271846492464,
            "rating_q975": 1416.5352642644552,
            "rating_q025": 1349.7191050340375
        },
        "claude-opus-4-20250514": {
            "rating": 1378.2716454559913,
            "rating_q975": 1389.4131294531849,
            "rating_q025": 1367.1301614587978
        },
        "ling-flash-2.0": {
            "rating": 1378.1793541255608,
            "rating_q975": 1406.7278068201997,
            "rating_q025": 1349.630901430922
        },
        "gemini-2.5-flash-lite-preview-09-2025-no-thinking": {
            "rating": 1376.949646414264,
            "rating_q975": 1400.1112220327109,
            "rating_q025": 1353.788070795817
        },
        "qwen3-coder-480b-a35b-instruct": {
            "rating": 1375.6465155741275,
            "rating_q975": 1391.2112949513016,
            "rating_q025": 1360.0817361969534
        },
        "qwen3-30b-a3b": {
            "rating": 1374.0489230141932,
            "rating_q975": 1388.0076921982009,
            "rating_q025": 1360.0901538301855
        },
        "grok-3-mini-high": {
            "rating": 1373.2137235048172,
            "rating_q975": 1390.931125501336,
            "rating_q025": 1355.4963215082983
        },
        "qwen2.5-max": {
            "rating": 1373.2080533695585,
            "rating_q975": 1383.2382217316278,
            "rating_q025": 1363.177885007489
        },
        "ring-flash-2.0": {
            "rating": 1372.1502810935472,
            "rating_q975": 1402.7566063247648,
            "rating_q025": 1341.5439558623295
        },
        "gemini-2.5-flash-lite-preview-06-17-thinking": {
            "rating": 1371.8764861690245,
            "rating_q975": 1384.4544473307137,
            "rating_q025": 1359.2985250073352
        },
        "o1-mini": {
            "rating": 1371.4172579786066,
            "rating_q975": 1379.1180072748905,
            "rating_q025": 1363.7165086823227
        },
        "deepseek-v3-0324": {
            "rating": 1368.1618528433783,
            "rating_q975": 1378.6373736477053,
            "rating_q025": 1357.6863320390512
        },
        "hunyuan-turbos-20250416": {
            "rating": 1366.6982408895256,
            "rating_q975": 1386.2006231489322,
            "rating_q025": 1347.195858630119
        },
        "kimi-k2-0711-preview": {
            "rating": 1363.382440889805,
            "rating_q975": 1377.913063452221,
            "rating_q025": 1348.8518183273889
        },
        "claude-sonnet-4-20250514": {
            "rating": 1362.3930701528884,
            "rating_q975": 1374.3201375279016,
            "rating_q025": 1350.4660027778752
        },
        "grok-3-mini-beta": {
            "rating": 1362.0265379540417,
            "rating_q975": 1376.0797343762952,
            "rating_q025": 1347.9733415317883
        },
        "gpt-4.1-2025-04-14": {
            "rating": 1361.4322839578226,
            "rating_q975": 1371.9704944294858,
            "rating_q025": 1350.8940734861594
        },
        "mistral-small-2506": {
            "rating": 1359.9909810476724,
            "rating_q975": 1377.689444102192,
            "rating_q025": 1342.2925179931528
        },
        "qwq-32b": {
            "rating": 1358.6599520285347,
            "rating_q975": 1372.456808877533,
            "rating_q025": 1344.8630951795365
        },
        "mistral-medium-2505": {
            "rating": 1355.5982945319238,
            "rating_q975": 1367.3714483783117,
            "rating_q025": 1343.8251406855359
        },
        "step-1o-turbo-202506": {
            "rating": 1352.5124899727446,
            "rating_q975": 1374.4343168584257,
            "rating_q025": 1330.5906630870634
        },
        "gpt-4.1-mini-2025-04-14": {
            "rating": 1351.6742375156796,
            "rating_q975": 1363.0058962968935,
            "rating_q025": 1340.3425787344656
        },
        "llama-3.3-nemotron-49b-super-v1": {
            "rating": 1350.7934115945498,
            "rating_q975": 1387.9925382829479,
            "rating_q025": 1313.5942849061516
        },
        "claude-3-7-sonnet-20250219-thinking-32k": {
            "rating": 1345.5295223847768,
            "rating_q975": 1356.7420748713992,
            "rating_q025": 1334.3169698981544
        },
        "gemma-3-12b-it": {
            "rating": 1341.1712253107348,
            "rating_q975": 1371.4295865957893,
            "rating_q025": 1310.9128640256804
        },
        "glm-4.5v": {
            "rating": 1339.089592314433,
            "rating_q975": 1376.5729871215392,
            "rating_q025": 1301.606197507327
        },
        "gpt-5-nano-high": {
            "rating": 1337.1563180608769,
            "rating_q975": 1365.1503176138142,
            "rating_q025": 1309.1623185079395
        },
        "qwen-plus-0125": {
            "rating": 1336.9144102918042,
            "rating_q975": 1358.12495086262,
            "rating_q025": 1315.7038697209885
        },
        "gemma-3-27b-it": {
            "rating": 1331.2189235070716,
            "rating_q975": 1341.026865750231,
            "rating_q025": 1321.4109812639122
        },
        "gemini-1.5-pro-002": {
            "rating": 1330.110035118485,
            "rating_q975": 1337.1726893761715,
            "rating_q025": 1323.0473808607985
        },
        "gemini-2.0-flash-lite-preview-02-05": {
            "rating": 1323.101438852955,
            "rating_q975": 1333.972290105526,
            "rating_q025": 1312.2305876003838
        },
        "deepseek-v3": {
            "rating": 1319.0849117075752,
            "rating_q975": 1330.3794184405645,
            "rating_q025": 1307.790404974586
        },
        "command-a-03-2025": {
            "rating": 1316.442985414337,
            "rating_q975": 1326.0993245452573,
            "rating_q025": 1306.7866462834168
        },
        "step-2-16k-exp-202412": {
            "rating": 1315.253644297987,
            "rating_q975": 1337.3445006776142,
            "rating_q025": 1293.1627879183598
        },
        "claude-3-5-sonnet-20241022": {
            "rating": 1312.9245152670871,
            "rating_q975": 1319.0748715561592,
            "rating_q025": 1306.774158978015
        },
        "yi-lightning": {
            "rating": 1312.1353610884576,
            "rating_q975": 1322.0787217622662,
            "rating_q025": 1302.1920004146489
        },
        "qwen2.5-plus-1127": {
            "rating": 1310.760450088276,
            "rating_q975": 1325.1000004243751,
            "rating_q025": 1296.4208997521769
        },
        "athene-v2-chat": {
            "rating": 1310.6675300368722,
            "rating_q975": 1320.4294263158101,
            "rating_q025": 1300.9056337579343
        },
        "gpt-oss-20b": {
            "rating": 1310.0605597387203,
            "rating_q975": 1333.5830509834789,
            "rating_q025": 1286.5380684939616
        },
        "hunyuan-large-vision": {
            "rating": 1309.8341511118288,
            "rating_q975": 1337.4635479631218,
            "rating_q025": 1282.2047542605358
        },
        "hunyuan-large-2025-02-10": {
            "rating": 1309.717864653478,
            "rating_q975": 1335.7338022705121,
            "rating_q025": 1283.701927036444
        },
        "hunyuan-turbo-0110": {
            "rating": 1302.7437525980258,
            "rating_q975": 1336.7523870089958,
            "rating_q025": 1268.7351181870558
        },
        "llama-4-maverick-17b-128e-instruct": {
            "rating": 1301.9174144225644,
            "rating_q975": 1313.0939306336425,
            "rating_q025": 1290.7408982114864
        },
        "claude-3-5-sonnet-20240620": {
            "rating": 1299.290923683961,
            "rating_q975": 1306.2550531788675,
            "rating_q025": 1292.3267941890545
        },
        "glm-4-plus-0111": {
            "rating": 1296.728664634501,
            "rating_q975": 1317.3621123406322,
            "rating_q025": 1276.0952169283698
        },
        "qwen2.5-72b-instruct": {
            "rating": 1295.64777655025,
            "rating_q975": 1303.739617496561,
            "rating_q025": 1287.555935603939
        },
        "hunyuan-standard-2025-02-10": {
            "rating": 1294.488832811834,
            "rating_q975": 1319.9175223889722,
            "rating_q025": 1269.060143234696
        },
        "hunyuan-turbos-20250226": {
            "rating": 1294.0999349874073,
            "rating_q975": 1326.2463327108044,
            "rating_q025": 1261.9535372640103
        },
        "llama-3.1-nemotron-70b-instruct": {
            "rating": 1292.8126692281226,
            "rating_q975": 1310.9055018507977,
            "rating_q025": 1274.7198366054474
        },
        "llama-4-scout-17b-16e-instruct": {
            "rating": 1292.014265109459,
            "rating_q975": 1305.3273720018692,
            "rating_q025": 1278.701158217049
        },
        "gpt-4o-2024-05-13": {
            "rating": 1289.8166445124843,
            "rating_q975": 1296.180150340176,
            "rating_q025": 1283.4531386847927
        },
        "grok-2-2024-08-13": {
            "rating": 1289.3443676762956,
            "rating_q975": 1296.190880107243,
            "rating_q025": 1282.4978552453483
        },
        "gpt-4o-2024-08-06": {
            "rating": 1288.7727986492291,
            "rating_q975": 1296.5549699572082,
            "rating_q025": 1280.99062734125
        },
        "glm-4-plus": {
            "rating": 1288.314388162576,
            "rating_q975": 1298.3415846379935,
            "rating_q025": 1278.2871916871586
        },
        "gemini-1.5-flash-002": {
            "rating": 1284.7784017940035,
            "rating_q975": 1293.3556879002626,
            "rating_q025": 1276.2011156877443
        },
        "qwen-max-0919": {
            "rating": 1284.4504325205974,
            "rating_q975": 1297.0654098954283,
            "rating_q025": 1271.8354551457664
        },
        "gemma-3n-e4b-it": {
            "rating": 1284.1868960328638,
            "rating_q975": 1299.1670119817318,
            "rating_q025": 1269.206780083996
        },
        "deepseek-v2.5-1210": {
            "rating": 1283.5319930616556,
            "rating_q975": 1300.9345662455842,
            "rating_q025": 1266.129419877727
        },
        "gemini-1.5-pro-001": {
            "rating": 1281.930023817415,
            "rating_q975": 1289.382074794394,
            "rating_q025": 1274.4779728404362
        },
        "llama-3.1-405b-instruct-fp8": {
            "rating": 1281.7544954201746,
            "rating_q975": 1288.94234466111,
            "rating_q025": 1274.5666461792393
        },
        "llama-3.1-405b-instruct-bf16": {
            "rating": 1281.4595697217433,
            "rating_q975": 1289.4934184134638,
            "rating_q025": 1273.4257210300227
        },
        "gemini-advanced-0514": {
            "rating": 1281.1891198476492,
            "rating_q975": 1290.5757448312984,
            "rating_q025": 1271.802494864
        },
        "mistral-small-3.1-24b-instruct-2503": {
            "rating": 1279.6435557999066,
            "rating_q975": 1292.648525506686,
            "rating_q025": 1266.6385860931273
        },
        "gpt-4.1-nano-2025-04-14": {
            "rating": 1279.61608501519,
            "rating_q975": 1303.7546514813932,
            "rating_q025": 1255.4775185489868
        },
        "deepseek-v2.5": {
            "rating": 1279.4672648408791,
            "rating_q975": 1289.3034355519817,
            "rating_q025": 1269.6310941297766
        },
        "grok-2-mini-2024-08-13": {
            "rating": 1278.1321422821857,
            "rating_q975": 1285.4383772869242,
            "rating_q025": 1270.8259072774472
        },
        "gpt-4o-mini-2024-07-18": {
            "rating": 1276.307171384226,
            "rating_q975": 1282.8210265164307,
            "rating_q025": 1269.7933162520212
        },
        "gpt-4-1106-preview": {
            "rating": 1275.577044852395,
            "rating_q975": 1282.9827684556622,
            "rating_q025": 1268.1713212491277
        },
        "gpt-4-turbo-2024-04-09": {
            "rating": 1273.3701732382178,
            "rating_q975": 1280.5563271171234,
            "rating_q025": 1266.1840193593123
        },
        "llama-3.3-70b-instruct": {
            "rating": 1272.1334489114083,
            "rating_q975": 1279.672698991844,
            "rating_q025": 1264.5941988309726
        },
        "mistral-large-2407": {
            "rating": 1271.4635112916474,
            "rating_q975": 1279.2702534198168,
            "rating_q025": 1263.656769163478
        },
        "magistral-medium-2506": {
            "rating": 1270.3838908099433,
            "rating_q975": 1295.5402469483922,
            "rating_q025": 1245.2275346714944
        },
        "claude-3-opus-20240229": {
            "rating": 1269.2219647834954,
            "rating_q975": 1274.9922146837087,
            "rating_q025": 1263.4517148832822
        },
        "amazon-nova-pro-v1.0": {
            "rating": 1266.339150640001,
            "rating_q975": 1276.3306568132912,
            "rating_q025": 1256.3476444667108
        },
        "gpt-4-0125-preview": {
            "rating": 1266.3242724738188,
            "rating_q975": 1273.8242156543242,
            "rating_q025": 1258.8243292933134
        },
        "mistral-large-2411": {
            "rating": 1262.689100989868,
            "rating_q975": 1272.2521367415113,
            "rating_q025": 1253.1260652382246
        },
        "gemma-3-4b-it": {
            "rating": 1260.7682829082598,
            "rating_q975": 1291.006485163556,
            "rating_q025": 1230.5300806529638
        },
        "phi-4": {
            "rating": 1259.3028512798192,
            "rating_q975": 1270.5199131859831,
            "rating_q025": 1248.0857893736552
        },
        "llama-3.1-70b-instruct": {
            "rating": 1258.771061202025,
            "rating_q975": 1266.0888408360786,
            "rating_q025": 1251.4532815679715
        },
        "claude-3-5-haiku-20241022": {
            "rating": 1256.1651661766427,
            "rating_q975": 1263.6552869885656,
            "rating_q025": 1248.6750453647198
        },
        "llama-3.1-tulu-3-70b": {
            "rating": 1251.880078183256,
            "rating_q975": 1279.7115341406304,
            "rating_q025": 1224.0486222258817
        },
        "mistral-small-24b-instruct-2501": {
            "rating": 1249.0745345296334,
            "rating_q975": 1263.1970190600744,
            "rating_q025": 1234.9520499991925
        },
        "qwen2.5-coder-32b-instruct": {
            "rating": 1248.8899887033672,
            "rating_q975": 1269.4077288071276,
            "rating_q025": 1228.3722485996068
        },
        "hunyuan-standard-256k": {
            "rating": 1248.879335879652,
            "rating_q975": 1280.2149146842812,
            "rating_q025": 1217.5437570750228
        },
        "reka-core-20240904": {
            "rating": 1244.4615354260004,
            "rating_q975": 1259.7319219589106,
            "rating_q025": 1229.1911488930903
        },
        "gemini-1.5-flash-001": {
            "rating": 1243.620395993456,
            "rating_q975": 1251.320021498296,
            "rating_q025": 1235.920770488616
        },
        "amazon-nova-lite-v1.0": {
            "rating": 1240.2333775299435,
            "rating_q975": 1251.4010551988697,
            "rating_q025": 1229.0656998610173
        },
        "athene-70b-0725": {
            "rating": 1238.7930445424677,
            "rating_q975": 1249.3049222062884,
            "rating_q025": 1228.281166878647
        },
        "deepseek-coder-v2": {
            "rating": 1238.5676960481476,
            "rating_q975": 1252.2093612312472,
            "rating_q025": 1224.926030865048
        },
        "qwen2-72b-instruct": {
            "rating": 1235.7682720220484,
            "rating_q975": 1245.0949722998075,
            "rating_q025": 1226.4415717442894
        },
        "glm-4-0520": {
            "rating": 1234.8847586214438,
            "rating_q975": 1250.9659151244182,
            "rating_q025": 1218.8036021184694
        },
        "llama-3.1-nemotron-51b-instruct": {
            "rating": 1234.1405453949415,
            "rating_q975": 1259.5212457280109,
            "rating_q025": 1208.759845061872
        },
        "jamba-1.5-large": {
            "rating": 1233.1665758195904,
            "rating_q975": 1249.6194007805775,
            "rating_q025": 1216.7137508586034
        },
        "gpt-4-0314": {
            "rating": 1233.033648790005,
            "rating_q975": 1242.570630988772,
            "rating_q025": 1223.4966665912377
        },
        "gemini-1.5-flash-8b-001": {
            "rating": 1231.3751652163717,
            "rating_q975": 1239.7866461349915,
            "rating_q025": 1222.9636842977518
        },
        "qwq-32b-preview": {
            "rating": 1227.2166948794759,
            "rating_q975": 1253.5966033898217,
            "rating_q025": 1200.83678636913
        },
        "gemma-2-27b-it": {
            "rating": 1226.9643587068822,
            "rating_q975": 1233.2783898873888,
            "rating_q025": 1220.6503275263756
        },
        "nemotron-4-340b-instruct": {
            "rating": 1221.055194348204,
            "rating_q975": 1233.1918005355565,
            "rating_q025": 1208.9185881608514
        },
        "llama-3-70b-instruct": {
            "rating": 1219.135741681048,
            "rating_q975": 1226.0633932028072,
            "rating_q025": 1212.208090159289
        },
        "claude-3-sonnet-20240229": {
            "rating": 1218.8211798809862,
            "rating_q975": 1226.4478563791304,
            "rating_q025": 1211.194503382842
        },
        "amazon-nova-micro-v1.0": {
            "rating": 1217.5151520416812,
            "rating_q975": 1229.0420837257595,
            "rating_q025": 1205.9882203576028
        },
        "c4ai-aya-expanse-32b": {
            "rating": 1213.8403189689516,
            "rating_q975": 1223.6316743596578,
            "rating_q025": 1204.0489635782453
        },
        "reka-flash-20240904": {
            "rating": 1207.693115751641,
            "rating_q975": 1222.5773777472182,
            "rating_q025": 1192.8088537560639
        },
        "gpt-4-0613": {
            "rating": 1206.4976453159156,
            "rating_q975": 1214.569650055839,
            "rating_q025": 1198.4256405759922
        },
        "command-r-plus-08-2024": {
            "rating": 1203.7593914964611,
            "rating_q975": 1218.2851862461512,
            "rating_q025": 1189.2335967467711
        },
        "olmo-2-0325-32b-instruct": {
            "rating": 1201.494736912633,
            "rating_q975": 1231.4132254288704,
            "rating_q025": 1171.5762483963956
        },
        "gemma-2-9b-it-simpo": {
            "rating": 1201.4183890726445,
            "rating_q975": 1216.8007443174267,
            "rating_q025": 1186.0360338278622
        },
        "gemma-2-9b-it": {
            "rating": 1199.0082322084168,
            "rating_q975": 1206.342652268505,
            "rating_q025": 1191.6738121483286
        },
        "llama-3.1-tulu-3-8b": {
            "rating": 1198.2281823333062,
            "rating_q975": 1227.6044412820956,
            "rating_q025": 1168.8519233845168
        },
        "qwen1.5-110b-chat": {
            "rating": 1196.009954022751,
            "rating_q975": 1207.2502832332925,
            "rating_q025": 1184.7696248122093
        },
        "mistral-large-2402": {
            "rating": 1195.4076109108369,
            "rating_q975": 1204.2106788767558,
            "rating_q025": 1186.604542944918
        },
        "claude-3-haiku-20240307": {
            "rating": 1193.1333425627,
            "rating_q975": 1200.0787429746504,
            "rating_q025": 1186.1879421507494
        },
        "granite-3.1-2b-instruct": {
            "rating": 1192.2572262698227,
            "rating_q975": 1220.6983520178467,
            "rating_q025": 1163.8161005217987
        },
        "yi-1.5-34b-chat": {
            "rating": 1191.0561369181619,
            "rating_q975": 1202.1791636003247,
            "rating_q025": 1179.933110235999
        },
        "ministral-8b-2410": {
            "rating": 1189.8841230670282,
            "rating_q975": 1211.5503140023782,
            "rating_q025": 1168.2179321316783
        },
        "granite-3.1-8b-instruct": {
            "rating": 1187.6255659844537,
            "rating_q975": 1218.188658410158,
            "rating_q025": 1157.0624735587494
        },
        "internlm2_5-20b-chat": {
            "rating": 1186.7483573393345,
            "rating_q975": 1202.7527206105988,
            "rating_q025": 1170.7439940680702
        },
        "llama-3.1-8b-instruct": {
            "rating": 1185.8430555201023,
            "rating_q975": 1193.539471929202,
            "rating_q025": 1178.1466391110027
        },
        "mixtral-8x22b-instruct-v0.1": {
            "rating": 1184.5608739380439,
            "rating_q975": 1193.3693666856288,
            "rating_q025": 1175.752381190459
        },
        "mistral-medium": {
            "rating": 1183.237288023688,
            "rating_q975": 1194.0258114897572,
            "rating_q025": 1172.448764557619
        },
        "c4ai-aya-expanse-8b": {
            "rating": 1182.5472564015372,
            "rating_q975": 1198.1781215193482,
            "rating_q025": 1166.9163912837262
        },
        "phi-3-medium-4k-instruct": {
            "rating": 1181.64984304782,
            "rating_q975": 1192.2703552987596,
            "rating_q025": 1171.0293307968805
        },
        "qwen1.5-72b-chat": {
            "rating": 1177.3617030454811,
            "rating_q975": 1187.0476227305883,
            "rating_q025": 1167.675783360374
        },
        "reka-flash-21b-20240226-online": {
            "rating": 1171.7012911451457,
            "rating_q975": 1185.8230121819267,
            "rating_q025": 1157.5795701083646
        },
        "command-r-08-2024": {
            "rating": 1171.5091371659814,
            "rating_q975": 1185.571076238139,
            "rating_q025": 1157.4471980938238
        },
        "command-r-plus": {
            "rating": 1170.812774324568,
            "rating_q975": 1179.0375089491274,
            "rating_q025": 1162.5880397000085
        },
        "qwen1.5-32b-chat": {
            "rating": 1168.2438304831978,
            "rating_q975": 1180.2429799959757,
            "rating_q025": 1156.24468097042
        },
        "jamba-1.5-mini": {
            "rating": 1166.704993606254,
            "rating_q975": 1183.592414623646,
            "rating_q025": 1149.817572588862
        },
        "reka-flash-21b-20240226": {
            "rating": 1164.4709007515596,
            "rating_q975": 1175.9891242301062,
            "rating_q025": 1152.952677273013
        },
        "llama-3-8b-instruct": {
            "rating": 1159.0951743750268,
            "rating_q975": 1166.5256837028087,
            "rating_q025": 1151.6646650472449
        },
        "phi-3-small-8k-instruct": {
            "rating": 1158.5996362209507,
            "rating_q975": 1171.7395368648681,
            "rating_q025": 1145.4597355770334
        },
        "granite-3.0-8b-instruct": {
            "rating": 1157.8639441840814,
            "rating_q975": 1178.8157600354643,
            "rating_q025": 1136.9121283326986
        },
        "phi-3-mini-4k-instruct-june-2024": {
            "rating": 1151.9868284982801,
            "rating_q975": 1166.1941062966268,
            "rating_q025": 1137.7795506999335
        },
        "gemma-2-2b-it": {
            "rating": 1151.26767375162,
            "rating_q975": 1159.0707269370848,
            "rating_q025": 1143.464620566155
        },
        "zephyr-orpo-141b-A35b-v0.1": {
            "rating": 1151.0850769072877,
            "rating_q975": 1174.8111274575372,
            "rating_q025": 1127.3590263570381
        },
        "mixtral-8x7b-instruct-v0.1": {
            "rating": 1148.6174068570263,
            "rating_q975": 1156.8697813678646,
            "rating_q025": 1140.365032346188
        },
        "gemini-pro": {
            "rating": 1141.9470525236482,
            "rating_q975": 1162.5487859628972,
            "rating_q025": 1121.345319084399
        },
        "qwen1.5-14b-chat": {
            "rating": 1140.885014107133,
            "rating_q975": 1154.2544072356197,
            "rating_q025": 1127.5156209786462
        },
        "granite-3.0-2b-instruct": {
            "rating": 1136.5879121660412,
            "rating_q975": 1157.2449631020836,
            "rating_q025": 1115.9308612299988
        },
        "dbrx-instruct-preview": {
            "rating": 1136.3587257848621,
            "rating_q975": 1147.9189459610243,
            "rating_q025": 1124.7985056087
        },
        "starling-lm-7b-beta": {
            "rating": 1135.4236820621454,
            "rating_q975": 1149.5915967027095,
            "rating_q025": 1121.2557674215814
        },
        "gpt-3.5-turbo-1106": {
            "rating": 1134.1325662607678,
            "rating_q975": 1150.378453408993,
            "rating_q025": 1117.8866791125427
        },
        "llama-3.2-3b-instruct": {
            "rating": 1134.0487840704068,
            "rating_q975": 1150.4816639726043,
            "rating_q025": 1117.6159041682092
        },
        "gpt-3.5-turbo-0125": {
            "rating": 1132.6026237027556,
            "rating_q975": 1140.9153180017038,
            "rating_q025": 1124.2899294038075
        },
        "command-r": {
            "rating": 1130.5403177271698,
            "rating_q975": 1140.0112181426236,
            "rating_q025": 1121.069417311716
        },
        "gemini-pro-dev-api": {
            "rating": 1129.3228279587279,
            "rating_q975": 1143.8409030703688,
            "rating_q025": 1114.804752847087
        },
        "smollm2-1.7b-instruct": {
            "rating": 1128.7465319084877,
            "rating_q975": 1162.6548950681522,
            "rating_q025": 1094.8381687488231
        },
        "yi-34b-chat": {
            "rating": 1121.6817994891467,
            "rating_q975": 1135.5156164856758,
            "rating_q025": 1107.8479824926176
        },
        "phi-3-mini-4k-instruct": {
            "rating": 1115.442543096985,
            "rating_q975": 1127.9937243009538,
            "rating_q025": 1102.8913618930162
        },
        "wizardlm-70b": {
            "rating": 1112.875589264771,
            "rating_q975": 1133.2534381552928,
            "rating_q025": 1092.4977403742491
        },
        "qwen1.5-7b-chat": {
            "rating": 1112.4072956712907,
            "rating_q975": 1135.2020659601628,
            "rating_q025": 1089.6125253824187
        },
        "tulu-2-dpo-70b": {
            "rating": 1104.4285661440863,
            "rating_q975": 1124.6814425386626,
            "rating_q025": 1084.17568974951
        },
        "snowflake-arctic-instruct": {
            "rating": 1103.5133762499809,
            "rating_q975": 1114.967662151538,
            "rating_q025": 1092.0590903484238
        },
        "gemma-1.1-7b-it": {
            "rating": 1103.299665919003,
            "rating_q975": 1114.729658242135,
            "rating_q025": 1091.869673595871
        },
        "llama-3.2-1b-instruct": {
            "rating": 1103.22737666285,
            "rating_q975": 1120.7982931887793,
            "rating_q025": 1085.6564601369207
        },
        "openhermes-2.5-mistral-7b": {
            "rating": 1102.4986827344421,
            "rating_q975": 1124.4805597245338,
            "rating_q025": 1080.5168057443504
        },
        "openchat-3.5-0106": {
            "rating": 1099.5417367288278,
            "rating_q975": 1114.17694857233,
            "rating_q025": 1084.9065248853256
        },
        "deepseek-llm-67b-chat": {
            "rating": 1098.7142985184878,
            "rating_q975": 1125.1902934731038,
            "rating_q025": 1072.2383035638718
        },
        "llama-2-70b-chat": {
            "rating": 1094.6696670674798,
            "rating_q975": 1105.1102894083808,
            "rating_q025": 1084.2290447265789
        },
        "mistral-7b-instruct-v0.2": {
            "rating": 1091.593286006312,
            "rating_q975": 1104.006979924772,
            "rating_q025": 1079.179592087852
        },
        "phi-3-mini-128k-instruct": {
            "rating": 1089.3214470372036,
            "rating_q975": 1102.5643501585332,
            "rating_q025": 1076.078543915874
        },
        "starling-lm-7b-alpha": {
            "rating": 1088.4961412184982,
            "rating_q975": 1105.4068071732834,
            "rating_q025": 1071.585475263713
        },
        "vicuna-33b": {
            "rating": 1081.7379899971927,
            "rating_q975": 1094.8007177220481,
            "rating_q025": 1068.6752622723372
        },
        "qwen-14b-chat": {
            "rating": 1078.6631814804093,
            "rating_q975": 1104.330883416246,
            "rating_q025": 1052.9954795445726
        },
        "llama-2-13b-chat": {
            "rating": 1074.5960344191158,
            "rating_q975": 1088.2655146749694,
            "rating_q025": 1060.9265541632622
        },
        "openchat-3.5": {
            "rating": 1074.486548184738,
            "rating_q975": 1094.290723885983,
            "rating_q025": 1054.682372483493
        },
        "llama2-70b-steerlm-chat": {
            "rating": 1070.5567063120689,
            "rating_q975": 1100.4571933911764,
            "rating_q025": 1040.6562192329613
        },
        "gemma-7b-it": {
            "rating": 1067.4783901136907,
            "rating_q975": 1084.681815505638,
            "rating_q025": 1050.2749647217433
        },
        "solar-10.7b-instruct-v1.0": {
            "rating": 1062.0694208458158,
            "rating_q975": 1085.4175151603936,
            "rating_q025": 1038.721326531238
        },
        "dolphin-2.2.1-mistral-7b": {
            "rating": 1060.881717403534,
            "rating_q975": 1095.5288063116775,
            "rating_q025": 1026.2346284953903
        },
        "codellama-34b-instruct": {
            "rating": 1060.5074657809494,
            "rating_q975": 1081.5448254245143,
            "rating_q025": 1039.4701061373844
        },
        "mpt-30b-chat": {
            "rating": 1058.6984995896837,
            "rating_q975": 1096.0158295924173,
            "rating_q025": 1021.38116958695
        },
        "nous-hermes-2-mixtral-8x7b-dpo": {
            "rating": 1055.4939486386072,
            "rating_q975": 1081.1932940618228,
            "rating_q025": 1029.7946032153916
        },
        "zephyr-7b-beta": {
            "rating": 1049.4124545513662,
            "rating_q975": 1067.330517978003,
            "rating_q025": 1031.4943911247294
        },
        "gemma-1.1-2b-it": {
            "rating": 1049.064288643489,
            "rating_q975": 1065.857783480849,
            "rating_q025": 1032.2707938061287
        },
        "palm-2": {
            "rating": 1048.5399542955358,
            "rating_q975": 1069.3987138324205,
            "rating_q025": 1027.6811947586511
        },
        "llama-2-7b-chat": {
            "rating": 1044.2819630934864,
            "rating_q975": 1059.2753707066265,
            "rating_q025": 1029.2885554803463
        },
        "vicuna-13b": {
            "rating": 1027.2078980809054,
            "rating_q975": 1041.9040919705872,
            "rating_q025": 1012.5117041912237
        },
        "stripedhyena-nous-7b": {
            "rating": 1026.6905456046106,
            "rating_q975": 1049.862792455746,
            "rating_q025": 1003.5182987534753
        },
        "guanaco-33b": {
            "rating": 1025.4647541224167,
            "rating_q975": 1061.0412695495552,
            "rating_q025": 989.8882386952783
        },
        "olmo-7b-instruct": {
            "rating": 1024.135275571139,
            "rating_q975": 1044.2913703606948,
            "rating_q025": 1003.979180781583
        },
        "wizardlm-13b": {
            "rating": 1020.5557735807771,
            "rating_q975": 1043.705552568733,
            "rating_q025": 997.405994592821
        },
        "mistral-7b-instruct": {
            "rating": 1014.6970607508362,
            "rating_q975": 1035.5895899951688,
            "rating_q025": 993.8045315065035
        },
        "gemma-2b-it": {
            "rating": 1010.8617079321127,
            "rating_q975": 1035.202996292209,
            "rating_q025": 986.5204195720164
        },
        "qwen1.5-4b-chat": {
            "rating": 1003.6772250148359,
            "rating_q975": 1023.3879325304873,
            "rating_q025": 983.9665174991845
        },
        "vicuna-7b": {
            "rating": 985.2367207824184,
            "rating_q975": 1008.8903572878403,
            "rating_q025": 961.5830842769965
        },
        "chatglm3-6b": {
            "rating": 969.8141310086896,
            "rating_q975": 996.4547947206404,
            "rating_q025": 943.1734672967389
        },
        "koala-13b": {
            "rating": 934.0999546497592,
            "rating_q975": 956.9317997247801,
            "rating_q025": 911.2681095747382
        },
        "RWKV-4-Raven-14B": {
            "rating": 924.5055059302864,
            "rating_q975": 950.520364881921,
            "rating_q025": 898.4906469786519
        },
        "chatglm-6b": {
            "rating": 917.5014820389191,
            "rating_q975": 945.2295715228363,
            "rating_q025": 889.7733925550019
        },
        "mpt-7b-chat": {
            "rating": 912.3545646697432,
            "rating_q975": 941.0508051005844,
            "rating_q025": 883.6583242389021
        },
        "oasst-pythia-12b": {
            "rating": 896.1725062801238,
            "rating_q975": 921.253539691327,
            "rating_q025": 871.0914728689206
        },
        "alpaca-13b": {
            "rating": 884.8529740792408,
            "rating_q975": 910.3532284909385,
            "rating_q025": 859.352719667543
        },
        "fastchat-t5-3b": {
            "rating": 856.752954753662,
            "rating_q975": 885.3292685036631,
            "rating_q025": 828.176641003661
        },
        "dolly-v2-12b": {
            "rating": 845.4390267008445,
            "rating_q975": 876.2824576057058,
            "rating_q025": 814.5955957959832
        },
        "stablelm-tuned-alpha-7b": {
            "rating": 840.5952154814947,
            "rating_q975": 872.2511427440066,
            "rating_q025": 808.9392882189828
        },
        "llama-13b": {
            "rating": 838.9789193156205,
            "rating_q975": 876.2854883032638,
            "rating_q025": 801.6723503279771
        }
    },
    "industry_medicine_and_healthcare": {
        "gemini-2.5-pro": {
            "rating": 1485.6573735087802,
            "rating_q975": 1497.0501680562909,
            "rating_q025": 1474.2645789612695
        },
        "deepseek-v3.2-exp-thinking": {
            "rating": 1474.3293080823596,
            "rating_q975": 1503.777584623313,
            "rating_q025": 1444.8810315414062
        },
        "qwen3-max-preview": {
            "rating": 1473.5154635067527,
            "rating_q975": 1491.046956245536,
            "rating_q025": 1455.9839707679694
        },
        "grok-3-preview-02-24": {
            "rating": 1470.0645027650182,
            "rating_q975": 1485.0928577677798,
            "rating_q025": 1455.0361477622566
        },
        "mistral-medium-2508": {
            "rating": 1468.9746773858662,
            "rating_q975": 1484.8932750030515,
            "rating_q025": 1453.056079768681
        },
        "deepseek-v3.1-terminus-thinking": {
            "rating": 1465.9931820642166,
            "rating_q975": 1504.8879655664978,
            "rating_q025": 1427.0983985619355
        },
        "longcat-flash-chat": {
            "rating": 1462.0377357616521,
            "rating_q975": 1485.8409331410983,
            "rating_q025": 1438.234538382206
        },
        "chatgpt-4o-latest-20250326": {
            "rating": 1461.2575898163273,
            "rating_q975": 1474.1055489752391,
            "rating_q025": 1448.4096306574154
        },
        "qwen3-next-80b-a3b-instruct": {
            "rating": 1460.0885213499405,
            "rating_q975": 1479.4540327185555,
            "rating_q025": 1440.7230099813255
        },
        "qwen3-235b-a22b-thinking-2507": {
            "rating": 1458.912543716913,
            "rating_q975": 1484.589270250761,
            "rating_q025": 1433.235817183065
        },
        "glm-4.5": {
            "rating": 1458.5530806522238,
            "rating_q975": 1475.4328014783116,
            "rating_q025": 1441.673359826136
        },
        "hunyuan-t1-20250711": {
            "rating": 1458.5059512404143,
            "rating_q975": 1496.8926870749913,
            "rating_q025": 1420.1192154058374
        },
        "o3-2025-04-16": {
            "rating": 1455.9790572813645,
            "rating_q975": 1467.7761493040875,
            "rating_q025": 1444.1819652586414
        },
        "glm-4.6": {
            "rating": 1454.0950591180108,
            "rating_q975": 1483.8437154306698,
            "rating_q025": 1424.3464028053518
        },
        "deepseek-v3.1-terminus": {
            "rating": 1452.142945265573,
            "rating_q975": 1490.2161994401174,
            "rating_q025": 1414.0696910910285
        },
        "qwen3-235b-a22b-instruct-2507": {
            "rating": 1451.5643811276848,
            "rating_q975": 1466.2713809451081,
            "rating_q025": 1436.8573813102614
        },
        "grok-4-0709": {
            "rating": 1449.739836464472,
            "rating_q975": 1464.1424151845602,
            "rating_q025": 1435.337257744384
        },
        "deepseek-v3.1-thinking": {
            "rating": 1448.3883626624902,
            "rating_q975": 1470.9689064221532,
            "rating_q025": 1425.8078189028272
        },
        "deepseek-r1-0528": {
            "rating": 1446.548611955371,
            "rating_q975": 1463.914177674211,
            "rating_q025": 1429.1830462365308
        },
        "deepseek-v3.1": {
            "rating": 1442.5628656086035,
            "rating_q975": 1462.2180449341602,
            "rating_q025": 1422.9076862830468
        },
        "qwen3-vl-235b-a22b-instruct": {
            "rating": 1438.9079502141533,
            "rating_q975": 1467.4170981511024,
            "rating_q025": 1410.3988022772041
        },
        "gemini-2.5-flash": {
            "rating": 1431.0957955189442,
            "rating_q975": 1442.3141637001881,
            "rating_q025": 1419.8774273377003
        },
        "claude-sonnet-4-5-20250929": {
            "rating": 1430.1827415956077,
            "rating_q975": 1462.236426791504,
            "rating_q025": 1398.1290563997113
        },
        "grok-4-fast": {
            "rating": 1422.2486004411649,
            "rating_q975": 1452.872894072618,
            "rating_q025": 1391.6243068097117
        },
        "mai-1-preview": {
            "rating": 1421.6674403633547,
            "rating_q975": 1440.1169647748657,
            "rating_q025": 1403.2179159518437
        },
        "gpt-5-high": {
            "rating": 1421.0403803925533,
            "rating_q975": 1436.7887295594903,
            "rating_q025": 1405.2920312256163
        },
        "gemini-2.5-flash-preview-09-2025": {
            "rating": 1420.3699979522419,
            "rating_q975": 1444.424943243531,
            "rating_q025": 1396.3150526609527
        },
        "gpt-5-chat": {
            "rating": 1417.1097769923067,
            "rating_q975": 1433.1914431310813,
            "rating_q025": 1401.028110853532
        },
        "qwen3-vl-235b-a22b-thinking": {
            "rating": 1416.702380064882,
            "rating_q975": 1445.8619016650891,
            "rating_q025": 1387.5428584646747
        },
        "claude-opus-4-1-20250805-thinking-16k": {
            "rating": 1416.2208140803014,
            "rating_q975": 1432.3975839297225,
            "rating_q025": 1400.0440442308802
        },
        "qwen3-max-2025-09-23": {
            "rating": 1415.9095645688017,
            "rating_q975": 1444.2348851502795,
            "rating_q025": 1387.5842439873238
        },
        "gpt-4.5-preview-2025-02-27": {
            "rating": 1415.8191691622592,
            "rating_q975": 1440.1621228089869,
            "rating_q025": 1391.4762155155315
        },
        "hunyuan-turbos-20250416": {
            "rating": 1415.0989671514988,
            "rating_q975": 1439.529348981931,
            "rating_q025": 1390.6685853210665
        },
        "qwen3-235b-a22b-no-thinking": {
            "rating": 1411.6614713095207,
            "rating_q975": 1424.6690582900026,
            "rating_q025": 1398.6538843290389
        },
        "glm-4.5-air": {
            "rating": 1411.1525441959911,
            "rating_q975": 1426.9668909240697,
            "rating_q025": 1395.3381974679126
        },
        "claude-sonnet-4-5-20250929-thinking-32k": {
            "rating": 1410.1412802409304,
            "rating_q975": 1436.8367918244776,
            "rating_q025": 1383.4457686573833
        },
        "claude-opus-4-1-20250805": {
            "rating": 1403.3784998747049,
            "rating_q975": 1417.3277416204419,
            "rating_q025": 1389.4292581289678
        },
        "grok-3-mini-high": {
            "rating": 1397.0532232763949,
            "rating_q975": 1415.9838681688318,
            "rating_q025": 1378.122578383958
        },
        "qwen3-30b-a3b-instruct-2507": {
            "rating": 1395.815796911156,
            "rating_q975": 1412.6339451418792,
            "rating_q025": 1378.9976486804328
        },
        "claude-haiku-4-5-20251001": {
            "rating": 1394.5429409716212,
            "rating_q975": 1424.3953577341865,
            "rating_q025": 1364.6905242090559
        },
        "glm-4-plus-0111": {
            "rating": 1393.2391652388596,
            "rating_q975": 1427.1219381540436,
            "rating_q025": 1359.3563923236757
        },
        "qwen3-next-80b-a3b-thinking": {
            "rating": 1392.7192160687507,
            "rating_q975": 1415.448256774941,
            "rating_q025": 1369.9901753625604
        },
        "gemma-3-27b-it": {
            "rating": 1392.5255418876925,
            "rating_q975": 1405.2730764899982,
            "rating_q025": 1379.7780072853868
        },
        "gemini-2.5-flash-lite-preview-06-17-thinking": {
            "rating": 1391.2964956836383,
            "rating_q975": 1405.3475062717869,
            "rating_q025": 1377.2454850954898
        },
        "qwen2.5-max": {
            "rating": 1388.6217060794263,
            "rating_q975": 1403.374523131682,
            "rating_q025": 1373.8688890271706
        },
        "gpt-oss-120b": {
            "rating": 1387.618186583278,
            "rating_q975": 1403.946841117609,
            "rating_q025": 1371.289532048947
        },
        "kimi-k2-0905-preview": {
            "rating": 1387.1741559920508,
            "rating_q975": 1411.0436274263957,
            "rating_q025": 1363.304684557706
        },
        "deepseek-v3-0324": {
            "rating": 1386.5584530496992,
            "rating_q975": 1398.554290289054,
            "rating_q025": 1374.5626158103444
        },
        "gemini-2.5-flash-lite-preview-09-2025-no-thinking": {
            "rating": 1385.4416051237743,
            "rating_q975": 1410.86019395128,
            "rating_q025": 1360.0230162962685
        },
        "gpt-4.1-2025-04-14": {
            "rating": 1385.1248170904873,
            "rating_q975": 1397.5682698038936,
            "rating_q025": 1372.681364377081
        },
        "mistral-medium-2505": {
            "rating": 1384.4291046149694,
            "rating_q975": 1398.2483604329593,
            "rating_q025": 1370.6098487969796
        },
        "gpt-5-mini-high": {
            "rating": 1381.164392556647,
            "rating_q975": 1398.6167352886278,
            "rating_q025": 1363.7120498246663
        },
        "ling-flash-2.0": {
            "rating": 1379.5896759135385,
            "rating_q975": 1409.9227332179696,
            "rating_q025": 1349.2566186091074
        },
        "minimax-m1": {
            "rating": 1377.3098912515359,
            "rating_q975": 1390.6954280536643,
            "rating_q025": 1363.9243544494075
        },
        "nvidia-llama-3.3-nemotron-super-49b-v1.5": {
            "rating": 1375.672101955027,
            "rating_q975": 1416.8392682218416,
            "rating_q025": 1334.5049356882125
        },
        "deepseek-r1": {
            "rating": 1375.0155272467612,
            "rating_q975": 1395.4995564390488,
            "rating_q025": 1354.5314980544736
        },
        "kimi-k2-0711-preview": {
            "rating": 1374.9664935884625,
            "rating_q975": 1390.046583667482,
            "rating_q025": 1359.886403509443
        },
        "qwen3-32b": {
            "rating": 1373.1483418030898,
            "rating_q975": 1412.2912846911713,
            "rating_q025": 1334.0053989150083
        },
        "amazon-nova-experimental-chat-10-09": {
            "rating": 1371.180853785136,
            "rating_q975": 1413.5310705225393,
            "rating_q025": 1328.8306370477326
        },
        "grok-3-mini-beta": {
            "rating": 1369.0207010900265,
            "rating_q975": 1385.0859640673468,
            "rating_q025": 1352.9554381127061
        },
        "qwen3-235b-a22b": {
            "rating": 1368.9229045790294,
            "rating_q975": 1384.262606634511,
            "rating_q025": 1353.5832025235477
        },
        "o4-mini-2025-04-16": {
            "rating": 1366.3051118757796,
            "rating_q975": 1378.9725449558637,
            "rating_q025": 1353.6376787956956
        },
        "claude-opus-4-20250514": {
            "rating": 1366.0876186402281,
            "rating_q975": 1378.5440710362413,
            "rating_q025": 1353.631166244215
        },
        "claude-opus-4-20250514-thinking-16k": {
            "rating": 1362.9222114122756,
            "rating_q975": 1376.288594615782,
            "rating_q025": 1349.5558282087693
        },
        "step-3": {
            "rating": 1362.5813358552796,
            "rating_q975": 1393.88484773737,
            "rating_q025": 1331.2778239731892
        },
        "o1-2024-12-17": {
            "rating": 1360.6119144500913,
            "rating_q975": 1377.2746293687399,
            "rating_q025": 1343.9491995314427
        },
        "step-2-16k-exp-202412": {
            "rating": 1359.8504787525974,
            "rating_q975": 1395.208490462079,
            "rating_q025": 1324.4924670431158
        },
        "step-1o-turbo-202506": {
            "rating": 1359.0286561719743,
            "rating_q975": 1382.0949027408958,
            "rating_q025": 1335.9624096030527
        },
        "glm-4.5v": {
            "rating": 1356.2724656613718,
            "rating_q975": 1394.761994132718,
            "rating_q025": 1317.7829371900257
        },
        "qwen-plus-0125": {
            "rating": 1355.0605571692834,
            "rating_q975": 1387.1061765193663,
            "rating_q025": 1323.0149378192004
        },
        "mistral-small-2506": {
            "rating": 1351.0682410967102,
            "rating_q975": 1368.9608529477061,
            "rating_q025": 1333.1756292457142
        },
        "deepseek-v3": {
            "rating": 1350.2105819556527,
            "rating_q975": 1367.996281071926,
            "rating_q025": 1332.4248828393795
        },
        "gemini-2.0-flash-lite-preview-02-05": {
            "rating": 1350.1897333514698,
            "rating_q975": 1368.636218979258,
            "rating_q025": 1331.7432477236816
        },
        "qwen3-coder-480b-a35b-instruct": {
            "rating": 1348.138085501958,
            "rating_q975": 1365.0799451291077,
            "rating_q025": 1331.196225874808
        },
        "ring-flash-2.0": {
            "rating": 1346.548342909093,
            "rating_q975": 1377.368381125828,
            "rating_q025": 1315.728304692358
        },
        "qwq-32b": {
            "rating": 1346.1842864318578,
            "rating_q975": 1361.9881560793124,
            "rating_q025": 1330.3804167844032
        },
        "gemma-3-4b-it": {
            "rating": 1346.0431742452909,
            "rating_q975": 1385.4072266235773,
            "rating_q025": 1306.6791218670044
        },
        "hunyuan-large-2025-02-10": {
            "rating": 1345.1217627658818,
            "rating_q975": 1383.7265502368057,
            "rating_q025": 1306.516975294958
        },
        "gpt-5-nano-high": {
            "rating": 1344.9954082323372,
            "rating_q975": 1372.2907034996633,
            "rating_q025": 1317.7001129650112
        },
        "command-a-03-2025": {
            "rating": 1339.7483950357173,
            "rating_q975": 1351.5624993595025,
            "rating_q025": 1327.9342907119321
        },
        "gemma-3-12b-it": {
            "rating": 1339.598258143451,
            "rating_q975": 1387.3953821985124,
            "rating_q025": 1291.8011340883895
        },
        "o3-mini-high": {
            "rating": 1335.2131156180585,
            "rating_q975": 1356.0607662827358,
            "rating_q025": 1314.3654649533812
        },
        "claude-sonnet-4-20250514": {
            "rating": 1334.228176258159,
            "rating_q975": 1347.5544140539573,
            "rating_q025": 1320.9019384623607
        },
        "claude-sonnet-4-20250514-thinking-32k": {
            "rating": 1330.092768794711,
            "rating_q975": 1343.7590172217308,
            "rating_q025": 1316.4265203676912
        },
        "gemma-3n-e4b-it": {
            "rating": 1329.9376054675313,
            "rating_q975": 1346.432695123699,
            "rating_q025": 1313.4425158113636
        },
        "gpt-4.1-mini-2025-04-14": {
            "rating": 1329.8656160253342,
            "rating_q975": 1342.8634896470953,
            "rating_q025": 1316.8677424035732
        },
        "qwen3-30b-a3b": {
            "rating": 1324.4529837674604,
            "rating_q975": 1339.507921487688,
            "rating_q025": 1309.3980460472328
        },
        "gpt-oss-20b": {
            "rating": 1323.0153689379824,
            "rating_q975": 1348.4819394111807,
            "rating_q025": 1297.548798464784
        },
        "hunyuan-standard-2025-02-10": {
            "rating": 1314.4067969787523,
            "rating_q975": 1351.188871714393,
            "rating_q025": 1277.6247222431116
        },
        "o1-preview": {
            "rating": 1312.8108168227068,
            "rating_q975": 1327.4578080363233,
            "rating_q025": 1298.1638256090903
        },
        "grok-2-2024-08-13": {
            "rating": 1311.6419527842047,
            "rating_q975": 1322.4774790101642,
            "rating_q025": 1300.8064265582452
        },
        "yi-lightning": {
            "rating": 1311.0739843242902,
            "rating_q975": 1326.4621793665297,
            "rating_q025": 1295.6857892820508
        },
        "gemini-1.5-pro-002": {
            "rating": 1310.6055071224873,
            "rating_q975": 1322.1550272737165,
            "rating_q025": 1299.055986971258
        },
        "qwen2.5-plus-1127": {
            "rating": 1306.8369183127293,
            "rating_q975": 1332.952223183759,
            "rating_q025": 1280.7216134416994
        },
        "llama-3.1-nemotron-70b-instruct": {
            "rating": 1305.8010445622917,
            "rating_q975": 1336.0285892952509,
            "rating_q025": 1275.5734998293326
        },
        "o3-mini": {
            "rating": 1304.5748454355858,
            "rating_q975": 1315.8096252090659,
            "rating_q025": 1293.3400656621056
        },
        "grok-2-mini-2024-08-13": {
            "rating": 1302.6030934210385,
            "rating_q975": 1314.4729120202448,
            "rating_q025": 1290.733274821832
        },
        "o1-mini": {
            "rating": 1301.9832879685657,
            "rating_q975": 1313.6651387208415,
            "rating_q025": 1290.30143721629
        },
        "athene-v2-chat": {
            "rating": 1300.9711385754524,
            "rating_q975": 1317.4861377559357,
            "rating_q025": 1284.4561393949691
        },
        "deepseek-v2.5-1210": {
            "rating": 1297.1683414713095,
            "rating_q975": 1329.613903426801,
            "rating_q025": 1264.722779515818
        },
        "gemini-1.5-flash-002": {
            "rating": 1295.1020074670928,
            "rating_q975": 1309.3217030458845,
            "rating_q025": 1280.882311888301
        },
        "claude-3-7-sonnet-20250219-thinking-32k": {
            "rating": 1295.0068436360034,
            "rating_q975": 1308.4481593586775,
            "rating_q025": 1281.5655279133293
        },
        "glm-4-plus": {
            "rating": 1294.2940256282507,
            "rating_q975": 1309.1053279168366,
            "rating_q025": 1279.4827233396647
        },
        "llama-3.1-405b-instruct-bf16": {
            "rating": 1291.401826311522,
            "rating_q975": 1304.6936131802202,
            "rating_q025": 1278.1100394428238
        },
        "gpt-4o-mini-2024-07-18": {
            "rating": 1286.4988078714287,
            "rating_q975": 1296.719391213304,
            "rating_q025": 1276.2782245295532
        },
        "llama-4-maverick-17b-128e-instruct": {
            "rating": 1286.083544740183,
            "rating_q975": 1299.4724173412521,
            "rating_q025": 1272.694672139114
        },
        "gpt-4o-2024-05-13": {
            "rating": 1283.2406404726814,
            "rating_q975": 1292.7364360307076,
            "rating_q025": 1273.7448449146552
        },
        "gpt-4.1-nano-2025-04-14": {
            "rating": 1281.3473987332634,
            "rating_q975": 1314.0156405715657,
            "rating_q025": 1248.6791568949611
        },
        "llama-4-scout-17b-16e-instruct": {
            "rating": 1281.2449192109557,
            "rating_q975": 1296.1985277458136,
            "rating_q025": 1266.2913106760977
        },
        "llama-3.3-70b-instruct": {
            "rating": 1281.1778962778626,
            "rating_q975": 1292.655726061591,
            "rating_q025": 1269.7000664941343
        },
        "athene-70b-0725": {
            "rating": 1275.9527500855047,
            "rating_q975": 1294.1479043235256,
            "rating_q025": 1257.7575958474838
        },
        "reka-core-20240904": {
            "rating": 1275.748842152947,
            "rating_q975": 1303.815551043975,
            "rating_q025": 1247.682133261919
        },
        "llama-3.1-405b-instruct-fp8": {
            "rating": 1275.16532644655,
            "rating_q975": 1286.3685250421813,
            "rating_q025": 1263.9621278509185
        },
        "mistral-small-3.1-24b-instruct-2503": {
            "rating": 1272.3274591059844,
            "rating_q975": 1286.8057982104986,
            "rating_q025": 1257.8491200014703
        },
        "amazon-nova-pro-v1.0": {
            "rating": 1265.2985112840538,
            "rating_q975": 1282.5336190168566,
            "rating_q025": 1248.063403551251
        },
        "qwen-max-0919": {
            "rating": 1263.9918419688331,
            "rating_q975": 1282.116553565298,
            "rating_q025": 1245.8671303723681
        },
        "deepseek-v2.5": {
            "rating": 1263.7291015666283,
            "rating_q975": 1280.094908034588,
            "rating_q025": 1247.3632950986687
        },
        "qwen2.5-72b-instruct": {
            "rating": 1263.5900064398709,
            "rating_q975": 1276.713771869709,
            "rating_q025": 1250.4662410100327
        },
        "claude-3-5-sonnet-20241022": {
            "rating": 1262.09958947528,
            "rating_q975": 1271.1551293872283,
            "rating_q025": 1253.0440495633318
        },
        "llama-3.1-70b-instruct": {
            "rating": 1261.564674794468,
            "rating_q975": 1273.0911754493711,
            "rating_q025": 1250.0381741395647
        },
        "mistral-large-2411": {
            "rating": 1259.6341762768825,
            "rating_q975": 1275.8855794172207,
            "rating_q025": 1243.3827731365443
        },
        "gpt-4o-2024-08-06": {
            "rating": 1256.1207401188208,
            "rating_q975": 1269.0236616589348,
            "rating_q025": 1243.2178185787068
        },
        "gemini-advanced-0514": {
            "rating": 1254.0371268101958,
            "rating_q975": 1267.4574246195284,
            "rating_q025": 1240.6168290008632
        },
        "mistral-large-2407": {
            "rating": 1250.7540230227405,
            "rating_q975": 1263.1394599851487,
            "rating_q025": 1238.3685860603323
        },
        "magistral-medium-2506": {
            "rating": 1249.992266686788,
            "rating_q975": 1273.2630168243345,
            "rating_q025": 1226.7215165492416
        },
        "claude-3-5-sonnet-20240620": {
            "rating": 1249.6904871121399,
            "rating_q975": 1259.96617738082,
            "rating_q025": 1239.4147968434597
        },
        "gpt-4-turbo-2024-04-09": {
            "rating": 1243.846428533167,
            "rating_q975": 1254.3418570506851,
            "rating_q025": 1233.3510000156489
        },
        "command-r-plus-08-2024": {
            "rating": 1240.848985690106,
            "rating_q975": 1264.6418364780793,
            "rating_q025": 1217.0561349021327
        },
        "gpt-4-0125-preview": {
            "rating": 1236.8624032150128,
            "rating_q975": 1247.6676722706836,
            "rating_q025": 1226.057134159342
        },
        "claude-3-opus-20240229": {
            "rating": 1235.6403292894747,
            "rating_q975": 1244.1126430039192,
            "rating_q025": 1227.1680155750303
        },
        "hunyuan-large-vision": {
            "rating": 1234.580543597809,
            "rating_q975": 1266.3284347729373,
            "rating_q025": 1202.832652422681
        },
        "claude-3-5-haiku-20241022": {
            "rating": 1230.3888498251308,
            "rating_q975": 1241.0724957677733,
            "rating_q025": 1219.7052038824884
        },
        "gpt-4-1106-preview": {
            "rating": 1228.450713274227,
            "rating_q975": 1239.2173001263022,
            "rating_q025": 1217.6841264221516
        },
        "c4ai-aya-expanse-32b": {
            "rating": 1227.4850904474106,
            "rating_q975": 1243.219780283506,
            "rating_q025": 1211.7504006113152
        },
        "gemma-2-9b-it-simpo": {
            "rating": 1225.4020683059318,
            "rating_q975": 1251.0750916570537,
            "rating_q025": 1199.72904495481
        },
        "mistral-small-24b-instruct-2501": {
            "rating": 1220.4595875186533,
            "rating_q975": 1244.1208166341798,
            "rating_q025": 1196.7983584031267
        },
        "llama-3-70b-instruct": {
            "rating": 1218.518370713516,
            "rating_q975": 1228.4953448226092,
            "rating_q025": 1208.541396604423
        },
        "gemini-1.5-flash-8b-001": {
            "rating": 1218.4274822177697,
            "rating_q975": 1232.5320849449654,
            "rating_q025": 1204.322879490574
        },
        "amazon-nova-lite-v1.0": {
            "rating": 1217.279349347544,
            "rating_q975": 1236.7197125117607,
            "rating_q025": 1197.8389861833273
        },
        "gemini-1.5-pro-001": {
            "rating": 1217.1608291162138,
            "rating_q975": 1228.4751896929006,
            "rating_q025": 1205.846468539527
        },
        "amazon-nova-micro-v1.0": {
            "rating": 1212.7237224922137,
            "rating_q975": 1231.3270703505245,
            "rating_q025": 1194.1203746339029
        },
        "command-r-08-2024": {
            "rating": 1211.3763476921565,
            "rating_q975": 1236.0259181479357,
            "rating_q025": 1186.7267772363773
        },
        "command-r-plus": {
            "rating": 1208.0288473043338,
            "rating_q975": 1219.81029761996,
            "rating_q025": 1196.2473969887076
        },
        "c4ai-aya-expanse-8b": {
            "rating": 1207.9631731108282,
            "rating_q975": 1234.6512676769194,
            "rating_q025": 1181.275078544737
        },
        "glm-4-0520": {
            "rating": 1206.9216252954866,
            "rating_q975": 1230.9064065816417,
            "rating_q025": 1182.9368440093315
        },
        "phi-4": {
            "rating": 1206.6222028572502,
            "rating_q975": 1225.8085918388683,
            "rating_q025": 1187.435813875632
        },
        "gemma-2-27b-it": {
            "rating": 1202.1555634038505,
            "rating_q975": 1212.3495202717525,
            "rating_q025": 1191.9616065359485
        },
        "reka-flash-20240904": {
            "rating": 1201.4188059118248,
            "rating_q975": 1228.2387500079037,
            "rating_q025": 1174.598861815746
        },
        "jamba-1.5-large": {
            "rating": 1201.1705986865036,
            "rating_q975": 1228.5215475797274,
            "rating_q025": 1173.8196497932797
        },
        "nemotron-4-340b-instruct": {
            "rating": 1199.4898608662015,
            "rating_q975": 1217.6566947668082,
            "rating_q025": 1181.3230269655949
        },
        "claude-3-sonnet-20240229": {
            "rating": 1192.966870883774,
            "rating_q975": 1204.0037036358221,
            "rating_q025": 1181.9300381317257
        },
        "gemini-1.5-flash-001": {
            "rating": 1191.5146046344253,
            "rating_q975": 1203.48887213798,
            "rating_q025": 1179.5403371308705
        },
        "llama-3.1-nemotron-51b-instruct": {
            "rating": 1191.4562429440907,
            "rating_q975": 1231.279007739842,
            "rating_q025": 1151.6334781483395
        },
        "qwen2.5-coder-32b-instruct": {
            "rating": 1191.4502862763436,
            "rating_q975": 1228.1749752173175,
            "rating_q025": 1154.7255973353697
        },
        "llama-3.1-8b-instruct": {
            "rating": 1186.4350302979178,
            "rating_q975": 1198.5921076473421,
            "rating_q025": 1174.2779529484935
        },
        "olmo-2-0325-32b-instruct": {
            "rating": 1186.3108937326629,
            "rating_q975": 1231.3605381837488,
            "rating_q025": 1141.261249281577
        },
        "jamba-1.5-mini": {
            "rating": 1185.8178310574776,
            "rating_q975": 1212.1709028428236,
            "rating_q025": 1159.4647592721317
        },
        "ministral-8b-2410": {
            "rating": 1185.0057659813615,
            "rating_q975": 1218.5164993593935,
            "rating_q025": 1151.4950326033295
        },
        "qwen2-72b-instruct": {
            "rating": 1179.807719488197,
            "rating_q975": 1193.5076139250127,
            "rating_q025": 1166.1078250513815
        },
        "gemma-2-9b-it": {
            "rating": 1170.6207843949214,
            "rating_q975": 1182.286767334251,
            "rating_q025": 1158.954801455592
        },
        "claude-3-haiku-20240307": {
            "rating": 1169.9285828999252,
            "rating_q975": 1179.9089028365693,
            "rating_q025": 1159.9482629632812
        },
        "yi-1.5-34b-chat": {
            "rating": 1163.6459902753998,
            "rating_q975": 1180.548498900137,
            "rating_q025": 1146.7434816506625
        },
        "command-r": {
            "rating": 1157.255567310795,
            "rating_q975": 1170.4548457190333,
            "rating_q025": 1144.0562889025566
        },
        "internlm2_5-20b-chat": {
            "rating": 1156.8219392234487,
            "rating_q975": 1181.45608176878,
            "rating_q025": 1132.1877966781174
        },
        "llama-3-8b-instruct": {
            "rating": 1152.8624298692587,
            "rating_q975": 1163.9586912673249,
            "rating_q025": 1141.7661684711925
        },
        "reka-flash-21b-20240226": {
            "rating": 1152.2933032504873,
            "rating_q975": 1169.5602061831435,
            "rating_q025": 1135.026400317831
        },
        "qwen1.5-110b-chat": {
            "rating": 1150.8049768454366,
            "rating_q975": 1167.4578890110633,
            "rating_q025": 1134.1520646798099
        },
        "gpt-4-0314": {
            "rating": 1149.7900105249182,
            "rating_q975": 1163.6405855543558,
            "rating_q025": 1135.9394354954807
        },
        "gemma-2-2b-it": {
            "rating": 1149.308215973178,
            "rating_q975": 1162.1026412862534,
            "rating_q025": 1136.5137906601026
        },
        "reka-flash-21b-20240226-online": {
            "rating": 1147.7712266677086,
            "rating_q975": 1168.638674014064,
            "rating_q025": 1126.903779321353
        },
        "qwen1.5-72b-chat": {
            "rating": 1141.2818754275845,
            "rating_q975": 1155.1417886652816,
            "rating_q025": 1127.4219621898874
        },
        "gemini-pro-dev-api": {
            "rating": 1139.541724169632,
            "rating_q975": 1159.5786021057313,
            "rating_q025": 1119.5048462335328
        },
        "deepseek-coder-v2": {
            "rating": 1138.0001103065886,
            "rating_q975": 1158.2940739465596,
            "rating_q025": 1117.7061466666175
        },
        "mistral-large-2402": {
            "rating": 1137.8189379474734,
            "rating_q975": 1150.4844740213568,
            "rating_q025": 1125.15340187359
        },
        "mistral-medium": {
            "rating": 1136.9573013056643,
            "rating_q975": 1152.330493635426,
            "rating_q025": 1121.5841089759026
        },
        "starling-lm-7b-beta": {
            "rating": 1133.1386123363777,
            "rating_q975": 1154.1134928614879,
            "rating_q025": 1112.1637318112676
        },
        "gpt-4-0613": {
            "rating": 1128.1556459751675,
            "rating_q975": 1139.692278395707,
            "rating_q025": 1116.619013554628
        },
        "mixtral-8x22b-instruct-v0.1": {
            "rating": 1124.4292583927293,
            "rating_q975": 1137.233569681147,
            "rating_q025": 1111.6249471043116
        },
        "phi-3-medium-4k-instruct": {
            "rating": 1123.6792611391659,
            "rating_q975": 1140.1798444758551,
            "rating_q025": 1107.1786778024766
        },
        "gemini-pro": {
            "rating": 1121.0687786742953,
            "rating_q975": 1158.5979302999165,
            "rating_q025": 1083.5396270486742
        },
        "starling-lm-7b-alpha": {
            "rating": 1116.1740538072395,
            "rating_q975": 1141.2354369696063,
            "rating_q025": 1091.1126706448727
        },
        "qwen1.5-32b-chat": {
            "rating": 1115.685462854665,
            "rating_q975": 1133.5004614018908,
            "rating_q025": 1097.8704643074393
        },
        "zephyr-orpo-141b-A35b-v0.1": {
            "rating": 1110.604212395526,
            "rating_q975": 1145.5862389439715,
            "rating_q025": 1075.6221858470806
        },
        "llama-3.2-3b-instruct": {
            "rating": 1109.7047205742565,
            "rating_q975": 1139.439784448609,
            "rating_q025": 1079.969656699904
        },
        "qwen1.5-14b-chat": {
            "rating": 1109.583551981127,
            "rating_q975": 1129.51175092995,
            "rating_q025": 1089.6553530323038
        },
        "yi-34b-chat": {
            "rating": 1107.159101466918,
            "rating_q975": 1128.86269928138,
            "rating_q025": 1085.455503652456
        },
        "phi-3-small-8k-instruct": {
            "rating": 1102.3788301087004,
            "rating_q975": 1121.1537818322379,
            "rating_q025": 1083.603878385163
        },
        "mixtral-8x7b-instruct-v0.1": {
            "rating": 1098.4285877181642,
            "rating_q975": 1110.1303454627307,
            "rating_q025": 1086.7268299735977
        },
        "wizardlm-70b": {
            "rating": 1098.256748062088,
            "rating_q975": 1128.672674734576,
            "rating_q025": 1067.8408213896
        },
        "llama-2-70b-chat": {
            "rating": 1098.001086842799,
            "rating_q975": 1112.643797414527,
            "rating_q025": 1083.358376271071
        },
        "gpt-3.5-turbo-0125": {
            "rating": 1079.1861463372404,
            "rating_q975": 1090.909188756694,
            "rating_q025": 1067.4631039177868
        },
        "openchat-3.5-0106": {
            "rating": 1078.018660245652,
            "rating_q975": 1099.1897329034264,
            "rating_q025": 1056.8475875878776
        },
        "gemma-1.1-7b-it": {
            "rating": 1077.202774925262,
            "rating_q975": 1095.0357386859773,
            "rating_q025": 1059.3698111645467
        },
        "llama-2-13b-chat": {
            "rating": 1076.0500499498412,
            "rating_q975": 1096.3417740299556,
            "rating_q025": 1055.7583258697268
        },
        "mistral-7b-instruct-v0.2": {
            "rating": 1072.945157882303,
            "rating_q975": 1090.9945969036294,
            "rating_q025": 1054.8957188609766
        },
        "dbrx-instruct-preview": {
            "rating": 1072.7793627058036,
            "rating_q975": 1089.8216804186336,
            "rating_q025": 1055.7370449929736
        },
        "wizardlm-13b": {
            "rating": 1070.7460437302148,
            "rating_q975": 1105.733992035344,
            "rating_q025": 1035.7580954250855
        },
        "openchat-3.5": {
            "rating": 1070.5876060171124,
            "rating_q975": 1100.2772431015114,
            "rating_q025": 1040.8979689327134
        },
        "snowflake-arctic-instruct": {
            "rating": 1068.507077902576,
            "rating_q975": 1086.7261463545879,
            "rating_q025": 1050.288009450564
        },
        "deepseek-llm-67b-chat": {
            "rating": 1066.342639551643,
            "rating_q975": 1094.8602086356939,
            "rating_q025": 1037.8250704675922
        },
        "vicuna-33b": {
            "rating": 1064.584381359185,
            "rating_q975": 1083.2043239376235,
            "rating_q025": 1045.9644387807466
        },
        "tulu-2-dpo-70b": {
            "rating": 1064.5634583956582,
            "rating_q975": 1096.038898100687,
            "rating_q025": 1033.0880186906295
        },
        "granite-3.0-8b-instruct": {
            "rating": 1063.0097614290698,
            "rating_q975": 1098.6905591863697,
            "rating_q025": 1027.32896367177
        },
        "qwen1.5-7b-chat": {
            "rating": 1061.0176300130981,
            "rating_q975": 1096.8225254416354,
            "rating_q025": 1025.2127345845608
        },
        "nous-hermes-2-mixtral-8x7b-dpo": {
            "rating": 1060.931058572723,
            "rating_q975": 1093.050441743973,
            "rating_q025": 1028.8116754014732
        },
        "openhermes-2.5-mistral-7b": {
            "rating": 1056.5270804420907,
            "rating_q975": 1092.0925184760233,
            "rating_q025": 1020.9616424081581
        },
        "solar-10.7b-instruct-v1.0": {
            "rating": 1051.854510355405,
            "rating_q975": 1092.3479020127402,
            "rating_q025": 1011.3611186980698
        },
        "phi-3-mini-4k-instruct-june-2024": {
            "rating": 1047.5370732541915,
            "rating_q975": 1072.6491487442538,
            "rating_q025": 1022.424997764129
        },
        "llama-2-7b-chat": {
            "rating": 1040.0471221400144,
            "rating_q975": 1062.5282342847256,
            "rating_q025": 1017.566009995303
        },
        "olmo-7b-instruct": {
            "rating": 1039.1577146805375,
            "rating_q975": 1071.2625096805878,
            "rating_q025": 1007.0529196804873
        },
        "phi-3-mini-4k-instruct": {
            "rating": 1035.0828732047446,
            "rating_q975": 1054.8379047369017,
            "rating_q025": 1015.3278416725875
        },
        "gemma-7b-it": {
            "rating": 1032.5874552979035,
            "rating_q975": 1057.8249303546656,
            "rating_q025": 1007.3499802411413
        },
        "zephyr-7b-beta": {
            "rating": 1032.398949684082,
            "rating_q975": 1058.4213629013057,
            "rating_q025": 1006.3765364668585
        },
        "codellama-34b-instruct": {
            "rating": 1031.1690429091263,
            "rating_q975": 1062.4114998165362,
            "rating_q025": 999.9265860017165
        },
        "vicuna-13b": {
            "rating": 1023.4825580558827,
            "rating_q975": 1045.2697610556177,
            "rating_q025": 1001.6953550561478
        },
        "qwen-14b-chat": {
            "rating": 1015.2377643216275,
            "rating_q975": 1053.7091563593463,
            "rating_q025": 976.7663722839089
        },
        "llama-3.2-1b-instruct": {
            "rating": 1014.3653454249646,
            "rating_q975": 1045.3471778161925,
            "rating_q025": 983.3835130337368
        },
        "gpt-3.5-turbo-1106": {
            "rating": 1010.6459416346602,
            "rating_q975": 1032.61096522359,
            "rating_q025": 988.6809180457304
        },
        "granite-3.0-2b-instruct": {
            "rating": 1008.3425485588408,
            "rating_q975": 1044.5938055930383,
            "rating_q025": 972.0912915246432
        },
        "vicuna-7b": {
            "rating": 1002.6155739132089,
            "rating_q975": 1038.487263739943,
            "rating_q025": 966.7438840864747
        },
        "phi-3-mini-128k-instruct": {
            "rating": 1000.5685671994263,
            "rating_q975": 1021.5123761414777,
            "rating_q025": 979.6247582573749
        },
        "mistral-7b-instruct": {
            "rating": 998.3709917052499,
            "rating_q975": 1025.6879548296463,
            "rating_q025": 971.0540285808536
        },
        "gemma-1.1-2b-it": {
            "rating": 995.435181940361,
            "rating_q975": 1021.8261303297511,
            "rating_q025": 969.0442335509708
        },
        "stripedhyena-nous-7b": {
            "rating": 989.3130845692108,
            "rating_q975": 1019.9535716783126,
            "rating_q025": 958.6725974601089
        },
        "palm-2": {
            "rating": 966.9229075824903,
            "rating_q975": 1003.7813411513669,
            "rating_q025": 930.0644740136138
        },
        "koala-13b": {
            "rating": 960.6606602072748,
            "rating_q975": 1001.2850902594438,
            "rating_q025": 920.0362301551057
        },
        "qwen1.5-4b-chat": {
            "rating": 960.6279380075306,
            "rating_q975": 991.294493765037,
            "rating_q025": 929.9613822500241
        },
        "RWKV-4-Raven-14B": {
            "rating": 949.2136965869322,
            "rating_q975": 998.4338304418798,
            "rating_q025": 899.9935627319846
        },
        "gemma-2b-it": {
            "rating": 943.0256827773455,
            "rating_q975": 980.2721679441796,
            "rating_q025": 905.7791976105115
        },
        "chatglm3-6b": {
            "rating": 894.8033808861145,
            "rating_q975": 936.5792242305935,
            "rating_q025": 853.0275375416355
        },
        "chatglm-6b": {
            "rating": 828.5569274047609,
            "rating_q975": 882.2823177017978,
            "rating_q025": 774.8315371077241
        },
        "alpaca-13b": {
            "rating": 824.6394589471092,
            "rating_q975": 875.1468327381165,
            "rating_q025": 774.132085156102
        },
        "oasst-pythia-12b": {
            "rating": 823.7132301916677,
            "rating_q975": 872.2286636297005,
            "rating_q025": 775.1977967536349
        }
    },
    "industry_software_and_it_services": {
        "claude-sonnet-4-5-20250929-thinking-32k": {
            "rating": 1467.9467702698169,
            "rating_q975": 1477.2066956843453,
            "rating_q025": 1458.6868448552884
        },
        "gemini-2.5-pro": {
            "rating": 1467.3361221215323,
            "rating_q975": 1472.991196294472,
            "rating_q025": 1461.6810479485925
        },
        "glm-4.6": {
            "rating": 1467.0889754724774,
            "rating_q975": 1477.1221873268746,
            "rating_q025": 1457.0557636180802
        },
        "qwen3-max-preview": {
            "rating": 1459.7670076514114,
            "rating_q975": 1467.0183762662027,
            "rating_q025": 1452.51563903662
        },
        "longcat-flash-chat": {
            "rating": 1459.1229868219145,
            "rating_q975": 1468.8092663422337,
            "rating_q025": 1449.4367073015953
        },
        "claude-opus-4-1-20250805-thinking-16k": {
            "rating": 1457.4868428709178,
            "rating_q975": 1464.4288675551102,
            "rating_q025": 1450.5448181867255
        },
        "qwen3-next-80b-a3b-instruct": {
            "rating": 1452.0532981676085,
            "rating_q975": 1459.6940921091511,
            "rating_q025": 1444.412504226066
        },
        "claude-sonnet-4-5-20250929": {
            "rating": 1451.8289892510445,
            "rating_q975": 1464.105177057358,
            "rating_q025": 1439.552801444731
        },
        "claude-opus-4-1-20250805": {
            "rating": 1446.4078950309713,
            "rating_q975": 1452.8197230349529,
            "rating_q025": 1439.9960670269897
        },
        "qwen3-vl-235b-a22b-instruct": {
            "rating": 1445.0926706400305,
            "rating_q975": 1455.5647051011551,
            "rating_q025": 1434.620636178906
        },
        "qwen3-235b-a22b-instruct-2507": {
            "rating": 1444.4923182216676,
            "rating_q975": 1450.847014467901,
            "rating_q025": 1438.137621975434
        },
        "mistral-medium-2508": {
            "rating": 1442.9148938981434,
            "rating_q975": 1449.6674374568215,
            "rating_q025": 1436.1623503394653
        },
        "glm-4.5": {
            "rating": 1439.4382207969097,
            "rating_q975": 1446.6282632034026,
            "rating_q025": 1432.2481783904168
        },
        "qwen3-max-2025-09-23": {
            "rating": 1437.8223694566439,
            "rating_q975": 1447.9292165647842,
            "rating_q025": 1427.7155223485036
        },
        "deepseek-v3.2-exp-thinking": {
            "rating": 1436.8468179037689,
            "rating_q975": 1447.3347094946962,
            "rating_q025": 1426.3589263128415
        },
        "grok-3-preview-02-24": {
            "rating": 1436.480946581537,
            "rating_q975": 1443.1849211730591,
            "rating_q025": 1429.7769719900148
        },
        "deepseek-r1-0528": {
            "rating": 1435.2120920655784,
            "rating_q975": 1443.5694449706427,
            "rating_q025": 1426.854739160514
        },
        "grok-4-fast": {
            "rating": 1432.257143712041,
            "rating_q975": 1444.6503713653242,
            "rating_q025": 1419.8639160587577
        },
        "claude-haiku-4-5-20251001": {
            "rating": 1429.7156091262261,
            "rating_q975": 1439.6699971384337,
            "rating_q025": 1419.7612211140186
        },
        "qwen3-235b-a22b-thinking-2507": {
            "rating": 1428.6861306853723,
            "rating_q975": 1439.5086596297908,
            "rating_q025": 1417.8636017409538
        },
        "deepseek-v3.1-thinking": {
            "rating": 1427.4096956568453,
            "rating_q975": 1437.5079108940113,
            "rating_q025": 1417.3114804196794
        },
        "qwen3-vl-235b-a22b-thinking": {
            "rating": 1427.0074978845564,
            "rating_q975": 1437.925389830305,
            "rating_q025": 1416.0896059388078
        },
        "deepseek-v3.1": {
            "rating": 1426.6649467749803,
            "rating_q975": 1435.5774831635542,
            "rating_q025": 1417.7524103864064
        },
        "chatgpt-4o-latest-20250326": {
            "rating": 1425.5257806848092,
            "rating_q975": 1431.2989555538295,
            "rating_q025": 1419.752605815789
        },
        "deepseek-v3.1-terminus-thinking": {
            "rating": 1423.8111638939029,
            "rating_q975": 1441.0511958270633,
            "rating_q025": 1406.5711319607424
        },
        "gpt-5-high": {
            "rating": 1421.0722460836262,
            "rating_q975": 1427.9578329411397,
            "rating_q025": 1414.1866592261126
        },
        "gemini-2.5-flash": {
            "rating": 1421.0091712386366,
            "rating_q975": 1426.5606753725842,
            "rating_q025": 1415.4576671046889
        },
        "qwen3-30b-a3b-instruct-2507": {
            "rating": 1418.082580369053,
            "rating_q975": 1425.2915014901166,
            "rating_q025": 1410.8736592479893
        },
        "o3-2025-04-16": {
            "rating": 1415.9260197342583,
            "rating_q975": 1421.4830110268335,
            "rating_q025": 1410.369028441683
        },
        "deepseek-v3.1-terminus": {
            "rating": 1413.1648848099023,
            "rating_q975": 1429.2853769445383,
            "rating_q025": 1397.0443926752664
        },
        "gpt-4.5-preview-2025-02-27": {
            "rating": 1411.330721511747,
            "rating_q975": 1421.4072987317493,
            "rating_q025": 1401.2541442917448
        },
        "grok-4-0709": {
            "rating": 1411.1183222996701,
            "rating_q975": 1417.3031878780976,
            "rating_q025": 1404.9334567212427
        },
        "gemini-2.5-flash-preview-09-2025": {
            "rating": 1408.9061010147411,
            "rating_q975": 1417.6076982469392,
            "rating_q025": 1400.204503782543
        },
        "qwen3-235b-a22b-no-thinking": {
            "rating": 1408.0867277904542,
            "rating_q975": 1414.3246589661735,
            "rating_q025": 1401.848796614735
        },
        "gpt-5-chat": {
            "rating": 1407.4017026287033,
            "rating_q975": 1414.1802910637848,
            "rating_q025": 1400.6231141936219
        },
        "hunyuan-t1-20250711": {
            "rating": 1406.682566392357,
            "rating_q975": 1421.2917908901145,
            "rating_q025": 1392.0733418945997
        },
        "claude-opus-4-20250514-thinking-16k": {
            "rating": 1405.453540659402,
            "rating_q975": 1411.850321009882,
            "rating_q025": 1399.056760308922
        },
        "mai-1-preview": {
            "rating": 1403.7690006902378,
            "rating_q975": 1411.9187531354364,
            "rating_q025": 1395.6192482450392
        },
        "ling-flash-2.0": {
            "rating": 1402.7770338052994,
            "rating_q975": 1414.3156494972113,
            "rating_q025": 1391.2384181133875
        },
        "glm-4.5-air": {
            "rating": 1400.0488278022083,
            "rating_q975": 1406.7535197783088,
            "rating_q025": 1393.3441358261077
        },
        "qwen3-next-80b-a3b-thinking": {
            "rating": 1394.8518874353817,
            "rating_q975": 1403.6343800181833,
            "rating_q025": 1386.0693948525802
        },
        "kimi-k2-0905-preview": {
            "rating": 1394.8169332789523,
            "rating_q975": 1405.054033851013,
            "rating_q025": 1384.5798327068917
        },
        "gpt-5-mini-high": {
            "rating": 1392.9392190458605,
            "rating_q975": 1400.2885540864233,
            "rating_q025": 1385.5898840052976
        },
        "gpt-4.1-2025-04-14": {
            "rating": 1391.5849291464942,
            "rating_q975": 1397.3001618061458,
            "rating_q025": 1385.8696964868427
        },
        "hunyuan-turbos-20250416": {
            "rating": 1391.5205999064283,
            "rating_q975": 1402.0831925804432,
            "rating_q025": 1380.9580072324134
        },
        "qwen3-coder-480b-a35b-instruct": {
            "rating": 1390.5886098033845,
            "rating_q975": 1397.966995872583,
            "rating_q025": 1383.210223734186
        },
        "qwen3-235b-a22b": {
            "rating": 1385.7754876632891,
            "rating_q975": 1392.8552536799132,
            "rating_q025": 1378.695721646665
        },
        "kimi-k2-0711-preview": {
            "rating": 1384.6091621256583,
            "rating_q975": 1391.6374881057811,
            "rating_q025": 1377.5808361455354
        },
        "amazon-nova-experimental-chat-10-09": {
            "rating": 1384.1394072164137,
            "rating_q975": 1396.6314969761133,
            "rating_q025": 1371.647317456714
        },
        "mistral-medium-2505": {
            "rating": 1383.862625909469,
            "rating_q975": 1390.4558581802808,
            "rating_q025": 1377.2693936386572
        },
        "gpt-oss-120b": {
            "rating": 1382.762559973204,
            "rating_q975": 1389.6675517327906,
            "rating_q025": 1375.8575682136172
        },
        "gemini-2.5-flash-lite-preview-09-2025-no-thinking": {
            "rating": 1381.6963945881878,
            "rating_q975": 1390.280584159423,
            "rating_q025": 1373.1122050169527
        },
        "claude-sonnet-4-20250514-thinking-32k": {
            "rating": 1380.7118382679512,
            "rating_q975": 1387.135205193613,
            "rating_q025": 1374.2884713422893
        },
        "claude-opus-4-20250514": {
            "rating": 1377.855026971053,
            "rating_q975": 1383.9211200657573,
            "rating_q025": 1371.7889338763484
        },
        "deepseek-v3-0324": {
            "rating": 1377.799541034618,
            "rating_q975": 1383.553790998415,
            "rating_q025": 1372.045291070821
        },
        "gemini-2.5-flash-lite-preview-06-17-thinking": {
            "rating": 1376.6853512045725,
            "rating_q975": 1383.1597455428296,
            "rating_q025": 1370.2109568663154
        },
        "deepseek-r1": {
            "rating": 1374.5152603192053,
            "rating_q975": 1383.576135307886,
            "rating_q025": 1365.4543853305245
        },
        "grok-3-mini-high": {
            "rating": 1374.0003333127124,
            "rating_q975": 1381.9756818763167,
            "rating_q025": 1366.0249847491082
        },
        "qwen2.5-max": {
            "rating": 1371.0700893780495,
            "rating_q975": 1377.5902647674404,
            "rating_q025": 1364.5499139886585
        },
        "grok-3-mini-beta": {
            "rating": 1370.9081672243803,
            "rating_q975": 1378.1990935281679,
            "rating_q025": 1363.6172409205928
        },
        "ring-flash-2.0": {
            "rating": 1367.688709914446,
            "rating_q975": 1379.174241347722,
            "rating_q025": 1356.20317848117
        },
        "o4-mini-2025-04-16": {
            "rating": 1366.9785844371852,
            "rating_q975": 1372.7739596454715,
            "rating_q025": 1361.183209228899
        },
        "o1-2024-12-17": {
            "rating": 1366.1047193654747,
            "rating_q975": 1373.629875867278,
            "rating_q025": 1358.5795628636713
        },
        "qwen3-32b": {
            "rating": 1366.0754453441573,
            "rating_q975": 1385.4201683444944,
            "rating_q025": 1346.7307223438202
        },
        "o3-mini-high": {
            "rating": 1363.2083735069268,
            "rating_q975": 1372.397746332598,
            "rating_q025": 1354.0190006812556
        },
        "step-3": {
            "rating": 1362.9570160133678,
            "rating_q975": 1375.4784601685128,
            "rating_q025": 1350.4355718582228
        },
        "mistral-small-2506": {
            "rating": 1361.3316499095154,
            "rating_q975": 1369.0847328782538,
            "rating_q025": 1353.578566940777
        },
        "gpt-4.1-mini-2025-04-14": {
            "rating": 1361.2742503672118,
            "rating_q975": 1367.4332301034817,
            "rating_q025": 1355.115270630942
        },
        "o1-preview": {
            "rating": 1361.261711356465,
            "rating_q975": 1368.9528883964178,
            "rating_q025": 1353.570534316512
        },
        "minimax-m1": {
            "rating": 1360.4073429093762,
            "rating_q975": 1366.6389294887272,
            "rating_q025": 1354.1757563300253
        },
        "claude-sonnet-4-20250514": {
            "rating": 1359.1284618115972,
            "rating_q975": 1365.3034721067797,
            "rating_q025": 1352.9534515164146
        },
        "gemma-3-27b-it": {
            "rating": 1355.6528242133552,
            "rating_q975": 1361.2231328667178,
            "rating_q025": 1350.0825155599925
        },
        "glm-4.5v": {
            "rating": 1355.4720220356471,
            "rating_q975": 1369.450407331586,
            "rating_q025": 1341.4936367397083
        },
        "step-1o-turbo-202506": {
            "rating": 1353.4916345005263,
            "rating_q975": 1364.4873034121138,
            "rating_q025": 1342.4959655889388
        },
        "o1-mini": {
            "rating": 1353.2553716491345,
            "rating_q975": 1359.2083986001876,
            "rating_q025": 1347.3023446980815
        },
        "nvidia-llama-3.3-nemotron-super-49b-v1.5": {
            "rating": 1352.8330782208427,
            "rating_q975": 1369.4162036097152,
            "rating_q025": 1336.2499528319702
        },
        "hunyuan-turbos-20250226": {
            "rating": 1351.233099109381,
            "rating_q975": 1376.2615006411804,
            "rating_q025": 1326.2046975775818
        },
        "qwq-32b": {
            "rating": 1347.2162539179665,
            "rating_q975": 1354.247671279711,
            "rating_q025": 1340.1848365562219
        },
        "gpt-5-nano-high": {
            "rating": 1344.9348859374065,
            "rating_q975": 1356.114703768999,
            "rating_q025": 1333.755068105814
        },
        "o3-mini": {
            "rating": 1343.4435118686945,
            "rating_q975": 1348.7036954230489,
            "rating_q025": 1338.18332831434
        },
        "qwen-plus-0125": {
            "rating": 1342.1149113568672,
            "rating_q975": 1357.2016540947648,
            "rating_q025": 1327.0281686189696
        },
        "qwen3-30b-a3b": {
            "rating": 1339.9311605747127,
            "rating_q975": 1346.9142043573977,
            "rating_q025": 1332.9481167920278
        },
        "deepseek-v3": {
            "rating": 1336.3685765483503,
            "rating_q975": 1344.6154104926825,
            "rating_q025": 1328.1217426040182
        },
        "command-a-03-2025": {
            "rating": 1336.2346475276288,
            "rating_q975": 1341.6087337372458,
            "rating_q025": 1330.8605613180118
        },
        "gemini-2.0-flash-lite-preview-02-05": {
            "rating": 1335.023493519751,
            "rating_q975": 1342.7464586346066,
            "rating_q025": 1327.3005284048952
        },
        "hunyuan-turbo-0110": {
            "rating": 1331.2576264424988,
            "rating_q975": 1354.6623031481113,
            "rating_q025": 1307.8529497368863
        },
        "llama-3.1-nemotron-ultra-253b-v1": {
            "rating": 1326.7045836940488,
            "rating_q975": 1350.5395523359748,
            "rating_q025": 1302.8696150521228
        },
        "claude-3-7-sonnet-20250219-thinking-32k": {
            "rating": 1324.5904495747093,
            "rating_q975": 1330.9989824574302,
            "rating_q025": 1318.1819166919884
        },
        "glm-4-plus-0111": {
            "rating": 1319.9182605975739,
            "rating_q975": 1334.7320181092928,
            "rating_q025": 1305.104503085855
        },
        "qwen2.5-plus-1127": {
            "rating": 1315.6501476257822,
            "rating_q975": 1326.9177321219736,
            "rating_q025": 1304.3825631295908
        },
        "gpt-oss-20b": {
            "rating": 1315.6100967280186,
            "rating_q975": 1325.7327895411854,
            "rating_q025": 1305.4874039148517
        },
        "claude-3-5-sonnet-20241022": {
            "rating": 1315.304919162212,
            "rating_q975": 1319.6333670169558,
            "rating_q025": 1310.976471307468
        },
        "step-2-16k-exp-202412": {
            "rating": 1314.7354869627245,
            "rating_q975": 1330.4079592186135,
            "rating_q025": 1299.0630147068355
        },
        "yi-lightning": {
            "rating": 1313.416940602027,
            "rating_q975": 1321.46055276425,
            "rating_q025": 1305.3733284398038
        },
        "gemma-3-12b-it": {
            "rating": 1313.1260639661916,
            "rating_q975": 1332.0531825388393,
            "rating_q025": 1294.198945393544
        },
        "deepseek-v2.5-1210": {
            "rating": 1312.817482910174,
            "rating_q975": 1326.8372487516917,
            "rating_q025": 1298.7977170686563
        },
        "gemma-3n-e4b-it": {
            "rating": 1310.4973642506343,
            "rating_q975": 1318.2697818398212,
            "rating_q025": 1302.7249466614473
        },
        "athene-v2-chat": {
            "rating": 1309.6005928111508,
            "rating_q975": 1317.037788826875,
            "rating_q025": 1302.1633967954267
        },
        "hunyuan-large-2025-02-10": {
            "rating": 1305.9111664373675,
            "rating_q975": 1325.5338159859436,
            "rating_q025": 1286.2885168887913
        },
        "gpt-4.1-nano-2025-04-14": {
            "rating": 1304.7534496272553,
            "rating_q975": 1319.570716680706,
            "rating_q025": 1289.9361825738047
        },
        "gemini-1.5-pro-002": {
            "rating": 1303.224956846834,
            "rating_q975": 1308.7628255563038,
            "rating_q025": 1297.687088137364
        },
        "mistral-small-3.1-24b-instruct-2503": {
            "rating": 1302.4689246445346,
            "rating_q975": 1308.983464807043,
            "rating_q025": 1295.9543844820262
        },
        "llama-4-maverick-17b-128e-instruct": {
            "rating": 1300.2780583820313,
            "rating_q975": 1306.4840057432834,
            "rating_q025": 1294.0721110207792
        },
        "llama-3.3-nemotron-49b-super-v1": {
            "rating": 1300.2324339610295,
            "rating_q975": 1324.7966804796895,
            "rating_q025": 1275.6681874423696
        },
        "gpt-4o-2024-05-13": {
            "rating": 1296.7194163977406,
            "rating_q975": 1302.0329599084725,
            "rating_q025": 1291.4058728870086
        },
        "deepseek-v2.5": {
            "rating": 1294.7971253236092,
            "rating_q975": 1302.6042383011757,
            "rating_q025": 1286.9900123460427
        },
        "grok-2-2024-08-13": {
            "rating": 1294.0740749887473,
            "rating_q975": 1299.6591456192964,
            "rating_q025": 1288.4890043581981
        },
        "qwen2.5-72b-instruct": {
            "rating": 1291.7872486967476,
            "rating_q975": 1298.140407646177,
            "rating_q025": 1285.4340897473182
        },
        "glm-4-plus": {
            "rating": 1290.7816610391446,
            "rating_q975": 1298.5814402622368,
            "rating_q025": 1282.9818818160525
        },
        "gpt-4o-mini-2024-07-18": {
            "rating": 1290.3482287602876,
            "rating_q975": 1295.569134548813,
            "rating_q025": 1285.1273229717622
        },
        "qwen-max-0919": {
            "rating": 1290.158599421533,
            "rating_q975": 1299.43087568616,
            "rating_q025": 1280.8863231569057
        },
        "llama-3.1-405b-instruct-bf16": {
            "rating": 1290.0555055870495,
            "rating_q975": 1296.0270855762676,
            "rating_q025": 1284.0839255978315
        },
        "claude-3-5-sonnet-20240620": {
            "rating": 1288.1047260284167,
            "rating_q975": 1293.7429505776533,
            "rating_q025": 1282.4665014791801
        },
        "llama-4-scout-17b-16e-instruct": {
            "rating": 1286.9954022389434,
            "rating_q975": 1293.8846489805999,
            "rating_q025": 1280.1061554972869
        },
        "hunyuan-standard-2025-02-10": {
            "rating": 1283.951094714016,
            "rating_q975": 1303.2433482335118,
            "rating_q025": 1264.6588411945204
        },
        "llama-3.1-nemotron-70b-instruct": {
            "rating": 1282.9878361241053,
            "rating_q975": 1295.4446468644426,
            "rating_q025": 1270.531025383768
        },
        "magistral-medium-2506": {
            "rating": 1282.9444283768246,
            "rating_q975": 1292.6164543769075,
            "rating_q025": 1273.2724023767416
        },
        "hunyuan-large-vision": {
            "rating": 1282.5614556288288,
            "rating_q975": 1296.892393986475,
            "rating_q025": 1268.2305172711824
        },
        "llama-3.1-405b-instruct-fp8": {
            "rating": 1280.7124073353339,
            "rating_q975": 1286.5007602188864,
            "rating_q025": 1274.9240544517813
        },
        "gemini-1.5-flash-002": {
            "rating": 1277.7055218541168,
            "rating_q975": 1284.3350276944793,
            "rating_q025": 1271.0760160137543
        },
        "gpt-4o-2024-08-06": {
            "rating": 1277.4000532299901,
            "rating_q975": 1283.8821449268366,
            "rating_q025": 1270.9179615331436
        },
        "grok-2-mini-2024-08-13": {
            "rating": 1277.1857643792582,
            "rating_q975": 1283.0861889991986,
            "rating_q025": 1271.2853397593178
        },
        "mistral-large-2407": {
            "rating": 1275.7857892849006,
            "rating_q975": 1282.2330576454888,
            "rating_q025": 1269.3385209243124
        },
        "llama-3.3-70b-instruct": {
            "rating": 1274.1854643777233,
            "rating_q975": 1279.376027231994,
            "rating_q025": 1268.9949015234527
        },
        "mistral-large-2411": {
            "rating": 1273.735925865913,
            "rating_q975": 1280.8470780576915,
            "rating_q025": 1266.6247736741345
        },
        "claude-3-5-haiku-20241022": {
            "rating": 1272.2816990599583,
            "rating_q975": 1277.1082087410657,
            "rating_q025": 1267.455189378851
        },
        "gemini-1.5-pro-001": {
            "rating": 1271.9422555472142,
            "rating_q975": 1278.1422832321362,
            "rating_q025": 1265.7422278622923
        },
        "amazon-nova-pro-v1.0": {
            "rating": 1270.4361906192357,
            "rating_q975": 1277.7863368195653,
            "rating_q025": 1263.086044418906
        },
        "gemma-3-4b-it": {
            "rating": 1268.2064570794382,
            "rating_q975": 1286.8057032978752,
            "rating_q025": 1249.6072108610012
        },
        "gpt-4-turbo-2024-04-09": {
            "rating": 1266.8356456019815,
            "rating_q975": 1272.7686402404788,
            "rating_q025": 1260.9026509634841
        },
        "gemini-advanced-0514": {
            "rating": 1266.1931662821517,
            "rating_q975": 1273.616648940527,
            "rating_q025": 1258.7696836237762
        },
        "athene-70b-0725": {
            "rating": 1264.8538459997098,
            "rating_q975": 1273.9106544632364,
            "rating_q025": 1255.7970375361833
        },
        "qwen2.5-coder-32b-instruct": {
            "rating": 1260.894516614028,
            "rating_q975": 1275.585622409988,
            "rating_q025": 1246.2034108180678
        },
        "llama-3.1-70b-instruct": {
            "rating": 1259.5351098060262,
            "rating_q975": 1265.377030382966,
            "rating_q025": 1253.6931892290863
        },
        "claude-3-opus-20240229": {
            "rating": 1258.3831385445924,
            "rating_q975": 1263.088064351299,
            "rating_q025": 1253.6782127378858
        },
        "gpt-4-1106-preview": {
            "rating": 1249.8121362041497,
            "rating_q975": 1255.8822637974613,
            "rating_q025": 1243.7420086108382
        },
        "gpt-4-0125-preview": {
            "rating": 1249.1630331410047,
            "rating_q975": 1255.4045208671907,
            "rating_q025": 1242.9215454148186
        },
        "mistral-small-24b-instruct-2501": {
            "rating": 1247.773726454545,
            "rating_q975": 1257.62240957692,
            "rating_q025": 1237.9250433321702
        },
        "llama-3.1-tulu-3-70b": {
            "rating": 1241.8062285724623,
            "rating_q975": 1261.7465512553586,
            "rating_q025": 1221.865905889566
        },
        "amazon-nova-lite-v1.0": {
            "rating": 1241.0019725350155,
            "rating_q975": 1249.3857157234963,
            "rating_q025": 1232.6182293465347
        },
        "gemini-1.5-flash-001": {
            "rating": 1241.000713051771,
            "rating_q975": 1247.4328138244762,
            "rating_q025": 1234.568612279066
        },
        "deepseek-coder-v2": {
            "rating": 1238.5043087770082,
            "rating_q975": 1248.556564332815,
            "rating_q025": 1228.4520532212014
        },
        "jamba-1.5-large": {
            "rating": 1236.3872646102948,
            "rating_q975": 1248.4018795874754,
            "rating_q025": 1224.3726496331142
        },
        "reka-core-20240904": {
            "rating": 1231.2038877562748,
            "rating_q975": 1243.7373426059362,
            "rating_q025": 1218.6704329066133
        },
        "llama-3.1-nemotron-51b-instruct": {
            "rating": 1230.4667454003106,
            "rating_q975": 1248.076718168849,
            "rating_q025": 1212.8567726317722
        },
        "phi-4": {
            "rating": 1227.705677500647,
            "rating_q975": 1235.6366294263573,
            "rating_q025": 1219.7747255749366
        },
        "gemma-2-27b-it": {
            "rating": 1227.500286894057,
            "rating_q975": 1232.6541579557127,
            "rating_q025": 1222.3464158324011
        },
        "gemini-1.5-flash-8b-001": {
            "rating": 1226.9111658958618,
            "rating_q975": 1233.601995643882,
            "rating_q025": 1220.2203361478416
        },
        "glm-4-0520": {
            "rating": 1225.250219995716,
            "rating_q975": 1236.7176895576197,
            "rating_q025": 1213.7827504338122
        },
        "hunyuan-standard-256k": {
            "rating": 1221.7658148830278,
            "rating_q975": 1242.5644587564507,
            "rating_q025": 1200.967171009605
        },
        "claude-3-sonnet-20240229": {
            "rating": 1220.5504917767612,
            "rating_q975": 1226.5531818156487,
            "rating_q025": 1214.5478017378737
        },
        "nemotron-4-340b-instruct": {
            "rating": 1214.8094583406828,
            "rating_q975": 1223.9330896207766,
            "rating_q025": 1205.685827060589
        },
        "amazon-nova-micro-v1.0": {
            "rating": 1214.7790844917608,
            "rating_q975": 1223.3299044585613,
            "rating_q025": 1206.2282645249604
        },
        "olmo-2-0325-32b-instruct": {
            "rating": 1214.0516307852126,
            "rating_q975": 1235.802351098129,
            "rating_q025": 1192.3009104722962
        },
        "ministral-8b-2410": {
            "rating": 1212.6759726035737,
            "rating_q975": 1228.3132339270114,
            "rating_q025": 1197.0387112801359
        },
        "c4ai-aya-expanse-32b": {
            "rating": 1212.0139827968685,
            "rating_q975": 1219.5680134651184,
            "rating_q025": 1204.4599521286186
        },
        "gemma-2-9b-it-simpo": {
            "rating": 1210.925943454687,
            "rating_q975": 1222.7571292593332,
            "rating_q025": 1199.094757650041
        },
        "llama-3-70b-instruct": {
            "rating": 1203.9931041709674,
            "rating_q975": 1209.7447082986232,
            "rating_q025": 1198.2415000433116
        },
        "reka-flash-20240904": {
            "rating": 1198.535802745911,
            "rating_q975": 1210.9743433237504,
            "rating_q025": 1186.0972621680717
        },
        "command-r-plus-08-2024": {
            "rating": 1196.7247533258553,
            "rating_q975": 1207.6784829046276,
            "rating_q025": 1185.771023747083
        },
        "gemma-2-9b-it": {
            "rating": 1196.135480548308,
            "rating_q975": 1201.950975736489,
            "rating_q025": 1190.3199853601268
        },
        "llama-3.1-8b-instruct": {
            "rating": 1194.6418542637953,
            "rating_q975": 1200.9335870493474,
            "rating_q025": 1188.3501214782432
        },
        "gpt-4-0314": {
            "rating": 1194.1708554231002,
            "rating_q975": 1201.9091361792957,
            "rating_q025": 1186.4325746669047
        },
        "claude-3-haiku-20240307": {
            "rating": 1193.4887726719364,
            "rating_q975": 1199.1985239688545,
            "rating_q025": 1187.7790213750184
        },
        "qwen2-72b-instruct": {
            "rating": 1192.577884200689,
            "rating_q975": 1199.9972841690949,
            "rating_q025": 1185.158484232283
        },
        "llama-3.1-tulu-3-8b": {
            "rating": 1190.9559560635853,
            "rating_q975": 1210.8305429240618,
            "rating_q025": 1171.0813692031088
        },
        "jamba-1.5-mini": {
            "rating": 1188.4248238864825,
            "rating_q975": 1200.8339526227671,
            "rating_q025": 1176.0156951501979
        },
        "command-r-plus": {
            "rating": 1185.4812161530208,
            "rating_q975": 1191.919270655775,
            "rating_q025": 1179.0431616502665
        },
        "c4ai-aya-expanse-8b": {
            "rating": 1176.5387847761015,
            "rating_q975": 1188.3094909625315,
            "rating_q025": 1164.7680785896714
        },
        "qwen1.5-110b-chat": {
            "rating": 1173.9596056724602,
            "rating_q975": 1182.807256166255,
            "rating_q025": 1165.1119551786653
        },
        "command-r-08-2024": {
            "rating": 1173.30242624747,
            "rating_q975": 1184.1603969749997,
            "rating_q025": 1162.4444555199404
        },
        "yi-1.5-34b-chat": {
            "rating": 1171.2112205614192,
            "rating_q975": 1179.8258975542103,
            "rating_q025": 1162.596543568628
        },
        "mistral-large-2402": {
            "rating": 1170.4161836986095,
            "rating_q975": 1177.5626243909142,
            "rating_q025": 1163.269743006305
        },
        "gpt-4-0613": {
            "rating": 1168.261880232382,
            "rating_q975": 1174.8063604316667,
            "rating_q025": 1161.7174000330974
        },
        "reka-flash-21b-20240226-online": {
            "rating": 1164.7109354937502,
            "rating_q975": 1175.5853355057125,
            "rating_q025": 1153.836535481788
        },
        "internlm2_5-20b-chat": {
            "rating": 1163.3607974384645,
            "rating_q975": 1175.0698441785485,
            "rating_q025": 1151.6517506983805
        },
        "granite-3.1-8b-instruct": {
            "rating": 1161.8849229249022,
            "rating_q975": 1182.3608364511526,
            "rating_q025": 1141.4090093986517
        },
        "qwen1.5-72b-chat": {
            "rating": 1160.5182626030055,
            "rating_q975": 1168.6515640100715,
            "rating_q025": 1152.3849611959395
        },
        "llama-3-8b-instruct": {
            "rating": 1155.902996519944,
            "rating_q975": 1162.2228434406295,
            "rating_q025": 1149.5831495992586
        },
        "reka-flash-21b-20240226": {
            "rating": 1155.0689030617345,
            "rating_q975": 1164.043910803525,
            "rating_q025": 1146.093895319944
        },
        "mixtral-8x22b-instruct-v0.1": {
            "rating": 1153.8810174638256,
            "rating_q975": 1161.039856228814,
            "rating_q025": 1146.7221786988373
        },
        "qwq-32b-preview": {
            "rating": 1153.5594013469695,
            "rating_q975": 1174.1458491486508,
            "rating_q025": 1132.9729535452882
        },
        "mistral-medium": {
            "rating": 1153.2226707601858,
            "rating_q975": 1162.0545375982679,
            "rating_q025": 1144.3908039221037
        },
        "qwen1.5-32b-chat": {
            "rating": 1146.3615634163061,
            "rating_q975": 1155.7406834740518,
            "rating_q025": 1136.9824433585604
        },
        "command-r": {
            "rating": 1142.3018449718738,
            "rating_q975": 1149.598776127579,
            "rating_q025": 1135.0049138161687
        },
        "starling-lm-7b-beta": {
            "rating": 1141.364337718458,
            "rating_q975": 1152.2462120884793,
            "rating_q025": 1130.4824633484368
        },
        "qwen1.5-14b-chat": {
            "rating": 1140.532766959892,
            "rating_q975": 1151.3337336627085,
            "rating_q025": 1129.7318002570753
        },
        "granite-3.1-2b-instruct": {
            "rating": 1139.4467300863416,
            "rating_q975": 1159.7347372174895,
            "rating_q025": 1119.1587229551938
        },
        "zephyr-orpo-141b-A35b-v0.1": {
            "rating": 1133.3336342060709,
            "rating_q975": 1150.1454650210937,
            "rating_q025": 1116.521803391048
        },
        "phi-3-medium-4k-instruct": {
            "rating": 1133.2752777323185,
            "rating_q975": 1141.611221522161,
            "rating_q025": 1124.939333942476
        },
        "gemma-2-2b-it": {
            "rating": 1131.9576088340218,
            "rating_q975": 1138.3774296467734,
            "rating_q025": 1125.5377880212702
        },
        "gemini-pro-dev-api": {
            "rating": 1130.7569740586182,
            "rating_q975": 1142.1364451942875,
            "rating_q025": 1119.377502922949
        },
        "mixtral-8x7b-instruct-v0.1": {
            "rating": 1124.7356936070255,
            "rating_q975": 1131.539807410636,
            "rating_q025": 1117.931579803415
        },
        "yi-34b-chat": {
            "rating": 1121.5529092595862,
            "rating_q975": 1132.2628320530607,
            "rating_q025": 1110.8429864661116
        },
        "dbrx-instruct-preview": {
            "rating": 1116.3173004364733,
            "rating_q975": 1125.5395252818473,
            "rating_q025": 1107.0950755910992
        },
        "gpt-3.5-turbo-0125": {
            "rating": 1115.1346199762172,
            "rating_q975": 1122.0299350280693,
            "rating_q025": 1108.2393049243651
        },
        "gemini-pro": {
            "rating": 1110.574569088122,
            "rating_q975": 1129.2982847702629,
            "rating_q025": 1091.850853405981
        },
        "tulu-2-dpo-70b": {
            "rating": 1109.7327512384143,
            "rating_q975": 1126.3937133968018,
            "rating_q025": 1093.0717890800267
        },
        "phi-3-small-8k-instruct": {
            "rating": 1108.3358478876848,
            "rating_q975": 1118.0466990357638,
            "rating_q025": 1098.6249967396059
        },
        "openchat-3.5-0106": {
            "rating": 1104.561795523375,
            "rating_q975": 1116.2668712709497,
            "rating_q025": 1092.8567197758002
        },
        "llama-3.2-3b-instruct": {
            "rating": 1102.7161748167007,
            "rating_q975": 1115.6019124193606,
            "rating_q025": 1089.8304372140408
        },
        "granite-3.0-8b-instruct": {
            "rating": 1099.941659314089,
            "rating_q975": 1114.6657555567315,
            "rating_q025": 1085.2175630714466
        },
        "llama-2-70b-chat": {
            "rating": 1098.5738653401606,
            "rating_q975": 1106.830390077509,
            "rating_q025": 1090.3173406028122
        },
        "gemma-1.1-7b-it": {
            "rating": 1095.089585992811,
            "rating_q975": 1103.7669805240016,
            "rating_q025": 1086.4121914616203
        },
        "deepseek-llm-67b-chat": {
            "rating": 1094.513337783113,
            "rating_q975": 1113.322808530645,
            "rating_q025": 1075.703867035581
        },
        "nous-hermes-2-mixtral-8x7b-dpo": {
            "rating": 1094.318370374964,
            "rating_q975": 1113.1382793468524,
            "rating_q025": 1075.4984614030755
        },
        "starling-lm-7b-alpha": {
            "rating": 1091.3088070285658,
            "rating_q975": 1104.3046472206704,
            "rating_q025": 1078.312966836461
        },
        "gpt-3.5-turbo-1106": {
            "rating": 1090.8323768394498,
            "rating_q975": 1103.990100969103,
            "rating_q025": 1077.6746527097966
        },
        "qwen1.5-7b-chat": {
            "rating": 1089.8931792183605,
            "rating_q975": 1106.294082352934,
            "rating_q025": 1073.492276083787
        },
        "phi-3-mini-4k-instruct-june-2024": {
            "rating": 1087.7813561204666,
            "rating_q975": 1099.0135134066154,
            "rating_q025": 1076.5491988343178
        },
        "wizardlm-70b": {
            "rating": 1087.5449983944163,
            "rating_q975": 1102.867221601569,
            "rating_q025": 1072.2227751872636
        },
        "snowflake-arctic-instruct": {
            "rating": 1087.470755112055,
            "rating_q975": 1097.1262172432819,
            "rating_q025": 1077.8152929808282
        },
        "vicuna-33b": {
            "rating": 1085.2115850011473,
            "rating_q975": 1095.3020574262855,
            "rating_q025": 1075.1211125760092
        },
        "openchat-3.5": {
            "rating": 1083.2043340523803,
            "rating_q975": 1098.7648438008969,
            "rating_q025": 1067.6438243038638
        },
        "mistral-7b-instruct-v0.2": {
            "rating": 1082.5067367400463,
            "rating_q975": 1092.4763913433128,
            "rating_q025": 1072.5370821367799
        },
        "phi-3-mini-4k-instruct": {
            "rating": 1081.6797225787902,
            "rating_q975": 1091.427915401759,
            "rating_q025": 1071.9315297558214
        },
        "granite-3.0-2b-instruct": {
            "rating": 1078.7866244248098,
            "rating_q975": 1093.0376826316724,
            "rating_q025": 1064.5355662179472
        },
        "openhermes-2.5-mistral-7b": {
            "rating": 1076.3553495406477,
            "rating_q975": 1094.020383667204,
            "rating_q025": 1058.6903154140914
        },
        "llama-2-13b-chat": {
            "rating": 1072.0942955016626,
            "rating_q975": 1082.3370693178792,
            "rating_q025": 1061.851521685446
        },
        "solar-10.7b-instruct-v1.0": {
            "rating": 1067.7185564368103,
            "rating_q975": 1088.474112333683,
            "rating_q025": 1046.9630005399376
        },
        "codellama-34b-instruct": {
            "rating": 1062.2481002973968,
            "rating_q975": 1077.2123904365355,
            "rating_q025": 1047.2838101582581
        },
        "gemma-7b-it": {
            "rating": 1059.7067717543878,
            "rating_q975": 1073.7286201476827,
            "rating_q025": 1045.6849233610928
        },
        "mpt-30b-chat": {
            "rating": 1056.9930248144165,
            "rating_q975": 1082.1160826244266,
            "rating_q025": 1031.8699670044064
        },
        "codellama-70b-instruct": {
            "rating": 1056.3714344865662,
            "rating_q975": 1089.268111704567,
            "rating_q025": 1023.4747572685652
        },
        "llama-3.2-1b-instruct": {
            "rating": 1055.8196177943016,
            "rating_q975": 1069.1260199540172,
            "rating_q025": 1042.513215634586
        },
        "llama2-70b-steerlm-chat": {
            "rating": 1055.32676645325,
            "rating_q975": 1076.2833092464512,
            "rating_q025": 1034.3702236600489
        },
        "zephyr-7b-alpha": {
            "rating": 1052.7300072087423,
            "rating_q975": 1082.0903802521525,
            "rating_q025": 1023.3696341653321
        },
        "qwen-14b-chat": {
            "rating": 1052.0778681107154,
            "rating_q975": 1070.6343909413836,
            "rating_q025": 1033.5213452800472
        },
        "wizardlm-13b": {
            "rating": 1051.943030967126,
            "rating_q975": 1068.0124657955473,
            "rating_q025": 1035.873596138705
        },
        "zephyr-7b-beta": {
            "rating": 1047.6578732644002,
            "rating_q975": 1061.9497208724636,
            "rating_q025": 1033.366025656337
        },
        "vicuna-13b": {
            "rating": 1047.442912573803,
            "rating_q975": 1058.1687140834354,
            "rating_q025": 1036.7171110641705
        },
        "smollm2-1.7b-instruct": {
            "rating": 1046.2940536824594,
            "rating_q975": 1072.9035447864073,
            "rating_q025": 1019.6845625785116
        },
        "dolphin-2.2.1-mistral-7b": {
            "rating": 1046.056693318603,
            "rating_q975": 1074.9968422469938,
            "rating_q025": 1017.1165443902123
        },
        "olmo-7b-instruct": {
            "rating": 1037.026381086685,
            "rating_q975": 1054.5608281088541,
            "rating_q025": 1019.4919340645158
        },
        "phi-3-mini-128k-instruct": {
            "rating": 1033.7882954576057,
            "rating_q975": 1045.0176938901282,
            "rating_q025": 1022.5588970250832
        },
        "gemma-1.1-2b-it": {
            "rating": 1031.082736845995,
            "rating_q975": 1043.0016391765641,
            "rating_q025": 1019.163834515426
        },
        "llama-2-7b-chat": {
            "rating": 1028.6548746460978,
            "rating_q975": 1039.6602098486608,
            "rating_q025": 1017.6495394435349
        },
        "falcon-180b-chat": {
            "rating": 1023.8748565355921,
            "rating_q975": 1058.0441988771604,
            "rating_q025": 989.7055141940237
        },
        "stripedhyena-nous-7b": {
            "rating": 1021.239876620305,
            "rating_q975": 1039.0470102697861,
            "rating_q025": 1003.4327429708239
        },
        "gemma-2b-it": {
            "rating": 1019.3531813562333,
            "rating_q975": 1037.2640520368266,
            "rating_q025": 1001.4423106756401
        },
        "vicuna-7b": {
            "rating": 1016.4327572355294,
            "rating_q975": 1032.852376456222,
            "rating_q025": 1000.013138014837
        },
        "mistral-7b-instruct": {
            "rating": 1014.1392149734266,
            "rating_q975": 1029.976767352822,
            "rating_q025": 998.3016625940312
        },
        "guanaco-33b": {
            "rating": 1012.1561374541621,
            "rating_q975": 1036.4044546672012,
            "rating_q025": 987.907820241123
        },
        "palm-2": {
            "rating": 999.116939350862,
            "rating_q975": 1014.4510307450006,
            "rating_q025": 983.7828479567235
        },
        "qwen1.5-4b-chat": {
            "rating": 993.9858264188408,
            "rating_q975": 1008.459388284243,
            "rating_q025": 979.5122645534386
        },
        "chatglm3-6b": {
            "rating": 968.9525350377064,
            "rating_q975": 989.681031251849,
            "rating_q025": 948.2240388235638
        },
        "koala-13b": {
            "rating": 960.055018410147,
            "rating_q975": 978.3359198579241,
            "rating_q025": 941.7741169623699
        },
        "gpt4all-13b-snoozy": {
            "rating": 930.573961535267,
            "rating_q975": 960.875054843539,
            "rating_q025": 900.272868226995
        },
        "chatglm2-6b": {
            "rating": 916.8871689692537,
            "rating_q975": 941.9696745609689,
            "rating_q025": 891.8046633775385
        },
        "RWKV-4-Raven-14B": {
            "rating": 913.8901494491827,
            "rating_q975": 934.121389153087,
            "rating_q025": 893.6589097452784
        },
        "mpt-7b-chat": {
            "rating": 911.8614021895066,
            "rating_q975": 934.169097273842,
            "rating_q025": 889.5537071051713
        },
        "chatglm-6b": {
            "rating": 887.7570068987756,
            "rating_q975": 908.120913052586,
            "rating_q025": 867.3931007449651
        },
        "oasst-pythia-12b": {
            "rating": 880.7233848243565,
            "rating_q975": 900.0064327716705,
            "rating_q025": 861.4403368770425
        },
        "stablelm-tuned-alpha-7b": {
            "rating": 857.0393715745397,
            "rating_q975": 881.7091866421681,
            "rating_q025": 832.3695565069113
        },
        "fastchat-t5-3b": {
            "rating": 835.2118293998893,
            "rating_q975": 856.2668988180263,
            "rating_q025": 814.1567599817523
        },
        "alpaca-13b": {
            "rating": 825.7057793511455,
            "rating_q975": 845.7830613541938,
            "rating_q025": 805.6284973480971
        },
        "dolly-v2-12b": {
            "rating": 788.337596915365,
            "rating_q975": 812.6332570260092,
            "rating_q025": 764.0419368047208
        },
        "llama-13b": {
            "rating": 718.5216027000204,
            "rating_q975": 748.1885271944615,
            "rating_q025": 688.8546782055793
        }
    },
    "industry_writing_and_literature_and_language": {
        "gemini-2.5-pro": {
            "rating": 1463.9555678618676,
            "rating_q975": 1470.5250111800142,
            "rating_q025": 1457.386124543721
        },
        "glm-4.6": {
            "rating": 1421.2695214822718,
            "rating_q975": 1433.9902320992942,
            "rating_q025": 1408.5488108652494
        },
        "claude-sonnet-4-5-20250929": {
            "rating": 1421.2237274626966,
            "rating_q975": 1436.946462082265,
            "rating_q025": 1405.5009928431282
        },
        "claude-sonnet-4-5-20250929-thinking-32k": {
            "rating": 1418.1381425584811,
            "rating_q975": 1429.833773704162,
            "rating_q025": 1406.4425114128003
        },
        "claude-opus-4-1-20250805-thinking-16k": {
            "rating": 1414.241923337443,
            "rating_q975": 1422.5148183563824,
            "rating_q025": 1405.9690283185037
        },
        "chatgpt-4o-latest-20250326": {
            "rating": 1411.2274458754569,
            "rating_q975": 1417.6575829464866,
            "rating_q025": 1404.797308804427
        },
        "gpt-4.5-preview-2025-02-27": {
            "rating": 1410.1903910455733,
            "rating_q975": 1419.7388698410134,
            "rating_q025": 1400.6419122501331
        },
        "claude-opus-4-1-20250805": {
            "rating": 1409.8805469257063,
            "rating_q975": 1417.1921877768768,
            "rating_q025": 1402.5689060745358
        },
        "grok-3-preview-02-24": {
            "rating": 1408.9176167026517,
            "rating_q975": 1415.9395775984688,
            "rating_q025": 1401.8956558068346
        },
        "gemini-2.5-flash": {
            "rating": 1407.9199429135904,
            "rating_q975": 1414.1627660738875,
            "rating_q025": 1401.6771197532933
        },
        "qwen3-max-preview": {
            "rating": 1407.7061430203723,
            "rating_q975": 1416.1599625620695,
            "rating_q025": 1399.2523234786752
        },
        "deepseek-v3.1-terminus": {
            "rating": 1407.097377219096,
            "rating_q975": 1427.8386293640358,
            "rating_q025": 1386.3561250741561
        },
        "deepseek-v3.1-thinking": {
            "rating": 1403.622939127184,
            "rating_q975": 1414.9338800260487,
            "rating_q025": 1392.3119982283195
        },
        "deepseek-v3.1-terminus-thinking": {
            "rating": 1402.0654408310836,
            "rating_q975": 1423.2432716952158,
            "rating_q025": 1380.8876099669515
        },
        "deepseek-r1-0528": {
            "rating": 1402.0629653392787,
            "rating_q975": 1411.4437734764456,
            "rating_q025": 1392.6821572021117
        },
        "glm-4.5": {
            "rating": 1401.3397061160877,
            "rating_q975": 1409.7273905527884,
            "rating_q025": 1392.952021679387
        },
        "grok-4-0709": {
            "rating": 1399.2399319843412,
            "rating_q975": 1406.56578596481,
            "rating_q025": 1391.9140780038724
        },
        "gemini-2.5-flash-preview-09-2025": {
            "rating": 1397.360354175034,
            "rating_q975": 1408.5201057958907,
            "rating_q025": 1386.2006025541773
        },
        "deepseek-v3.1": {
            "rating": 1396.772637629158,
            "rating_q975": 1406.9654987136687,
            "rating_q025": 1386.5797765446473
        },
        "deepseek-v3.2-exp-thinking": {
            "rating": 1393.2657869273032,
            "rating_q975": 1406.29549265763,
            "rating_q025": 1380.2360811969766
        },
        "qwen3-max-2025-09-23": {
            "rating": 1392.5134928427476,
            "rating_q975": 1405.5608815617938,
            "rating_q025": 1379.4661041237014
        },
        "grok-4-fast": {
            "rating": 1391.3308826200541,
            "rating_q975": 1406.0997677786513,
            "rating_q025": 1376.561997461457
        },
        "qwen3-vl-235b-a22b-instruct": {
            "rating": 1391.044377064853,
            "rating_q975": 1404.6752327890588,
            "rating_q025": 1377.4135213406473
        },
        "mistral-medium-2508": {
            "rating": 1389.8238850141813,
            "rating_q975": 1397.706309081522,
            "rating_q025": 1381.9414609468406
        },
        "qwen3-235b-a22b-thinking-2507": {
            "rating": 1386.972053367303,
            "rating_q975": 1400.164160338915,
            "rating_q025": 1373.779946395691
        },
        "claude-opus-4-20250514-thinking-16k": {
            "rating": 1386.299565000024,
            "rating_q975": 1393.6357543647237,
            "rating_q025": 1378.9633756353242
        },
        "gpt-5-chat": {
            "rating": 1384.0716982805466,
            "rating_q975": 1392.145423073625,
            "rating_q025": 1375.9979734874682
        },
        "qwen3-235b-a22b-instruct-2507": {
            "rating": 1383.502497108131,
            "rating_q975": 1390.8191074706845,
            "rating_q025": 1376.1858867455774
        },
        "gpt-5-high": {
            "rating": 1383.1890582406213,
            "rating_q975": 1391.1111521537612,
            "rating_q025": 1375.2669643274814
        },
        "hunyuan-t1-20250711": {
            "rating": 1383.0908246117638,
            "rating_q975": 1401.201754349781,
            "rating_q025": 1364.9798948737466
        },
        "claude-haiku-4-5-20251001": {
            "rating": 1379.6949855158903,
            "rating_q975": 1392.6391237538976,
            "rating_q025": 1366.750847277883
        },
        "claude-opus-4-20250514": {
            "rating": 1378.6780895606312,
            "rating_q975": 1385.6139878592514,
            "rating_q025": 1371.742191262011
        },
        "gemini-2.5-flash-lite-preview-09-2025-no-thinking": {
            "rating": 1375.1162197452725,
            "rating_q975": 1386.0223871554535,
            "rating_q025": 1364.2100523350914
        },
        "o3-2025-04-16": {
            "rating": 1373.3781642633478,
            "rating_q975": 1379.5638514901214,
            "rating_q025": 1367.1924770365742
        },
        "gemini-2.5-flash-lite-preview-06-17-thinking": {
            "rating": 1371.09980782281,
            "rating_q975": 1378.5570318424886,
            "rating_q025": 1363.6425838031312
        },
        "gpt-4.1-2025-04-14": {
            "rating": 1367.490411256317,
            "rating_q975": 1373.9228130231406,
            "rating_q025": 1361.0580094894933
        },
        "longcat-flash-chat": {
            "rating": 1366.0335786738124,
            "rating_q975": 1377.7586453912281,
            "rating_q025": 1354.3085119563966
        },
        "qwen3-235b-a22b-no-thinking": {
            "rating": 1364.3463205205946,
            "rating_q975": 1371.4650323001956,
            "rating_q025": 1357.2276087409937
        },
        "qwen3-vl-235b-a22b-thinking": {
            "rating": 1364.1011055141703,
            "rating_q975": 1378.1629457774548,
            "rating_q025": 1350.0392652508858
        },
        "deepseek-v3-0324": {
            "rating": 1363.9644717781637,
            "rating_q975": 1370.3443139532833,
            "rating_q025": 1357.584629603044
        },
        "deepseek-r1": {
            "rating": 1363.2762969870905,
            "rating_q975": 1371.2818521258387,
            "rating_q025": 1355.2707418483424
        },
        "mai-1-preview": {
            "rating": 1359.325334653653,
            "rating_q975": 1368.862267499116,
            "rating_q025": 1349.7884018081902
        },
        "o1-2024-12-17": {
            "rating": 1358.9988609192324,
            "rating_q975": 1366.1080041793305,
            "rating_q025": 1351.8897176591342
        },
        "claude-sonnet-4-20250514-thinking-32k": {
            "rating": 1355.324387735744,
            "rating_q975": 1362.6997968729374,
            "rating_q025": 1347.9489785985506
        },
        "qwen3-next-80b-a3b-instruct": {
            "rating": 1352.8616936407989,
            "rating_q975": 1362.1143038137634,
            "rating_q025": 1343.6090834678344
        },
        "glm-4.5-air": {
            "rating": 1352.3975481182094,
            "rating_q975": 1360.22033575374,
            "rating_q025": 1344.5747604826788
        },
        "hunyuan-turbos-20250416": {
            "rating": 1350.3581788074282,
            "rating_q975": 1361.7592408258681,
            "rating_q025": 1338.9571167889883
        },
        "mistral-medium-2505": {
            "rating": 1350.2755133292892,
            "rating_q975": 1357.7128899453999,
            "rating_q025": 1342.8381367131785
        },
        "gpt-5-mini-high": {
            "rating": 1347.9333251461,
            "rating_q975": 1356.3843294233525,
            "rating_q025": 1339.4823208688476
        },
        "claude-sonnet-4-20250514": {
            "rating": 1346.7335981023032,
            "rating_q975": 1353.8026360652573,
            "rating_q025": 1339.664560139349
        },
        "grok-3-mini-high": {
            "rating": 1346.1178143259604,
            "rating_q975": 1355.8717972664392,
            "rating_q025": 1336.3638313854815
        },
        "gemma-3-27b-it": {
            "rating": 1345.287127876049,
            "rating_q975": 1351.3404487733467,
            "rating_q025": 1339.2338069787513
        },
        "qwen2.5-max": {
            "rating": 1345.0730622623462,
            "rating_q975": 1351.667342228972,
            "rating_q025": 1338.4787822957203
        },
        "grok-3-mini-beta": {
            "rating": 1344.2874242804628,
            "rating_q975": 1352.8145138551386,
            "rating_q025": 1335.760334705787
        },
        "kimi-k2-0905-preview": {
            "rating": 1342.0226979937502,
            "rating_q975": 1354.224447352599,
            "rating_q025": 1329.8209486349012
        },
        "qwen3-coder-480b-a35b-instruct": {
            "rating": 1338.480686746031,
            "rating_q975": 1347.0291417032993,
            "rating_q025": 1329.932231788763
        },
        "o1-preview": {
            "rating": 1338.4755867063704,
            "rating_q975": 1346.2590474655517,
            "rating_q025": 1330.6921259471892
        },
        "qwen3-235b-a22b": {
            "rating": 1338.2452163072205,
            "rating_q975": 1346.043318417951,
            "rating_q025": 1330.44711419649
        },
        "qwen3-30b-a3b-instruct-2507": {
            "rating": 1336.7933822309353,
            "rating_q975": 1345.3081976450146,
            "rating_q025": 1328.278566816856
        },
        "claude-3-7-sonnet-20250219-thinking-32k": {
            "rating": 1335.4284393194548,
            "rating_q975": 1342.1875818472652,
            "rating_q025": 1328.6692967916445
        },
        "amazon-nova-experimental-chat-10-09": {
            "rating": 1332.108915189324,
            "rating_q975": 1348.0806739478323,
            "rating_q025": 1316.1371564308158
        },
        "deepseek-v3": {
            "rating": 1330.0552747137913,
            "rating_q975": 1338.0118100476043,
            "rating_q025": 1322.0987393799783
        },
        "kimi-k2-0711-preview": {
            "rating": 1328.7012311471562,
            "rating_q975": 1336.6924771549086,
            "rating_q025": 1320.709985139404
        },
        "glm-4-plus-0111": {
            "rating": 1325.5575497598666,
            "rating_q975": 1340.6222830178922,
            "rating_q025": 1310.492816501841
        },
        "gemini-1.5-pro-002": {
            "rating": 1325.4374422585397,
            "rating_q975": 1331.0099483193933,
            "rating_q025": 1319.8649361976861
        },
        "command-a-03-2025": {
            "rating": 1324.9864076989877,
            "rating_q975": 1330.933640200538,
            "rating_q025": 1319.0391751974373
        },
        "qwen3-next-80b-a3b-thinking": {
            "rating": 1323.3767715540387,
            "rating_q975": 1334.1295097827133,
            "rating_q025": 1312.624033325364
        },
        "step-3": {
            "rating": 1321.0430643112334,
            "rating_q975": 1336.1514095149707,
            "rating_q025": 1305.934719107496
        },
        "gemini-2.0-flash-lite-preview-02-05": {
            "rating": 1320.415737155563,
            "rating_q975": 1327.595204319096,
            "rating_q025": 1313.23626999203
        },
        "gpt-4.1-mini-2025-04-14": {
            "rating": 1317.768844202108,
            "rating_q975": 1324.6842292531953,
            "rating_q025": 1310.8534591510208
        },
        "o4-mini-2025-04-16": {
            "rating": 1317.345444288887,
            "rating_q975": 1323.8434111617623,
            "rating_q025": 1310.8474774160115
        },
        "minimax-m1": {
            "rating": 1313.284239203515,
            "rating_q975": 1320.3643895288862,
            "rating_q025": 1306.2040888781437
        },
        "claude-3-5-sonnet-20241022": {
            "rating": 1312.790651621806,
            "rating_q975": 1317.4058637069809,
            "rating_q025": 1308.1754395366313
        },
        "o3-mini-high": {
            "rating": 1312.0567800027604,
            "rating_q975": 1320.6949012240398,
            "rating_q025": 1303.418658781481
        },
        "mistral-small-2506": {
            "rating": 1310.3316376883722,
            "rating_q975": 1319.769547103883,
            "rating_q025": 1300.8937282728614
        },
        "step-1o-turbo-202506": {
            "rating": 1308.387920658666,
            "rating_q975": 1321.650970453184,
            "rating_q025": 1295.1248708641479
        },
        "gemma-3-12b-it": {
            "rating": 1306.616787416794,
            "rating_q975": 1324.19395047512,
            "rating_q025": 1289.0396243584682
        },
        "glm-4.5v": {
            "rating": 1302.5248532323737,
            "rating_q975": 1320.29401014309,
            "rating_q025": 1284.7556963216575
        },
        "step-2-16k-exp-202412": {
            "rating": 1302.4789758178936,
            "rating_q975": 1317.9472436058031,
            "rating_q025": 1287.010708029984
        },
        "gpt-oss-120b": {
            "rating": 1301.727679140718,
            "rating_q975": 1309.813732576604,
            "rating_q025": 1293.641625704832
        },
        "qwq-32b": {
            "rating": 1300.6586528675841,
            "rating_q975": 1308.1552113663747,
            "rating_q025": 1293.1620943687935
        },
        "hunyuan-turbos-20250226": {
            "rating": 1300.329899173723,
            "rating_q975": 1321.693009394519,
            "rating_q025": 1278.9667889529271
        },
        "llama-3.1-nemotron-ultra-253b-v1": {
            "rating": 1299.8402087475492,
            "rating_q975": 1320.95226701477,
            "rating_q025": 1278.7281504803284
        },
        "llama-3.3-nemotron-49b-super-v1": {
            "rating": 1298.520219544906,
            "rating_q975": 1321.322220804887,
            "rating_q025": 1275.7182182849251
        },
        "qwen3-32b": {
            "rating": 1298.2524089110404,
            "rating_q975": 1315.0862679047013,
            "rating_q025": 1281.4185499173796
        },
        "gpt-4o-2024-05-13": {
            "rating": 1296.5106312965545,
            "rating_q975": 1302.029906282042,
            "rating_q025": 1290.991356311067
        },
        "qwen-plus-0125": {
            "rating": 1294.7906611324318,
            "rating_q975": 1309.5201271655064,
            "rating_q025": 1280.061195099357
        },
        "o3-mini": {
            "rating": 1294.19427923358,
            "rating_q975": 1299.7010408719052,
            "rating_q025": 1288.6875175952546
        },
        "ring-flash-2.0": {
            "rating": 1294.0107458946945,
            "rating_q975": 1309.3136431773798,
            "rating_q025": 1278.7078486120092
        },
        "ling-flash-2.0": {
            "rating": 1292.592132619386,
            "rating_q975": 1307.9430228241674,
            "rating_q025": 1277.2412424146044
        },
        "gemini-1.5-flash-002": {
            "rating": 1292.349172817232,
            "rating_q975": 1299.0392892240138,
            "rating_q025": 1285.6590564104504
        },
        "nvidia-llama-3.3-nemotron-super-49b-v1.5": {
            "rating": 1291.6707671111217,
            "rating_q975": 1313.264137298064,
            "rating_q025": 1270.0773969241793
        },
        "qwen3-30b-a3b": {
            "rating": 1291.360354869419,
            "rating_q975": 1299.2181513260214,
            "rating_q025": 1283.5025584128168
        },
        "grok-2-2024-08-13": {
            "rating": 1291.0260027378636,
            "rating_q975": 1296.6143627102444,
            "rating_q025": 1285.4376427654827
        },
        "hunyuan-turbo-0110": {
            "rating": 1289.6887659941667,
            "rating_q975": 1309.695745791976,
            "rating_q025": 1269.6817861963575
        },
        "gpt-4o-2024-08-06": {
            "rating": 1288.8808262443104,
            "rating_q975": 1295.4536594530393,
            "rating_q025": 1282.3079930355814
        },
        "gemini-1.5-pro-001": {
            "rating": 1287.9223082007911,
            "rating_q975": 1294.4253030972764,
            "rating_q025": 1281.419313304306
        },
        "gemma-3-4b-it": {
            "rating": 1287.393810576425,
            "rating_q975": 1304.463797162562,
            "rating_q025": 1270.323823990288
        },
        "gemma-3n-e4b-it": {
            "rating": 1286.4409769317817,
            "rating_q975": 1295.0661967751205,
            "rating_q025": 1277.815757088443
        },
        "gemini-advanced-0514": {
            "rating": 1284.8989956355858,
            "rating_q975": 1292.5470493466737,
            "rating_q025": 1277.250941924498
        },
        "gpt-5-nano-high": {
            "rating": 1284.4938613936156,
            "rating_q975": 1298.6788637304255,
            "rating_q025": 1270.3088590568057
        },
        "deepseek-v2.5-1210": {
            "rating": 1282.3293474771017,
            "rating_q975": 1295.5893789702534,
            "rating_q025": 1269.06931598395
        },
        "gpt-4o-mini-2024-07-18": {
            "rating": 1281.0319264291281,
            "rating_q975": 1286.2586434647742,
            "rating_q025": 1275.805209393482
        },
        "claude-3-5-sonnet-20240620": {
            "rating": 1279.3895758908532,
            "rating_q975": 1285.1936540148351,
            "rating_q025": 1273.5854977668712
        },
        "o1-mini": {
            "rating": 1278.7278838541943,
            "rating_q975": 1284.4869478230662,
            "rating_q025": 1272.9688198853223
        },
        "llama-4-maverick-17b-128e-instruct": {
            "rating": 1278.5121369956432,
            "rating_q975": 1285.368271341955,
            "rating_q025": 1271.6560026493314
        },
        "gpt-4-turbo-2024-04-09": {
            "rating": 1277.7791689096325,
            "rating_q975": 1283.9216402675095,
            "rating_q025": 1271.6366975517556
        },
        "glm-4-plus": {
            "rating": 1277.2097245631794,
            "rating_q975": 1285.2715371846944,
            "rating_q025": 1269.1479119416645
        },
        "yi-lightning": {
            "rating": 1275.326578956761,
            "rating_q975": 1283.3144595319225,
            "rating_q025": 1267.3386983815997
        },
        "llama-3.1-405b-instruct-fp8": {
            "rating": 1273.0690490408042,
            "rating_q975": 1278.9174395548857,
            "rating_q025": 1267.2206585267227
        },
        "llama-4-scout-17b-16e-instruct": {
            "rating": 1272.837207277208,
            "rating_q975": 1280.5018392509544,
            "rating_q025": 1265.1725753034618
        },
        "qwen2.5-plus-1127": {
            "rating": 1272.3295012445258,
            "rating_q975": 1283.1135136306755,
            "rating_q025": 1261.545488858376
        },
        "hunyuan-large-2025-02-10": {
            "rating": 1270.0561320841437,
            "rating_q975": 1288.8613701269592,
            "rating_q025": 1251.2508940413281
        },
        "llama-3.1-405b-instruct-bf16": {
            "rating": 1269.5736082546714,
            "rating_q975": 1275.4211718524004,
            "rating_q025": 1263.7260446569423
        },
        "qwen-max-0919": {
            "rating": 1269.0772651250932,
            "rating_q975": 1278.3510282606699,
            "rating_q025": 1259.8035019895165
        },
        "mistral-small-3.1-24b-instruct-2503": {
            "rating": 1268.610297603487,
            "rating_q975": 1276.0866808967692,
            "rating_q025": 1261.1339143102048
        },
        "claude-3-opus-20240229": {
            "rating": 1267.5309373179953,
            "rating_q975": 1272.4097845803303,
            "rating_q025": 1262.6520900556602
        },
        "gpt-4-1106-preview": {
            "rating": 1263.3780010520518,
            "rating_q975": 1269.6185492955904,
            "rating_q025": 1257.1374528085132
        },
        "grok-2-mini-2024-08-13": {
            "rating": 1261.1737969415099,
            "rating_q975": 1267.0719343414848,
            "rating_q025": 1255.2756595415349
        },
        "gpt-4.1-nano-2025-04-14": {
            "rating": 1260.6890332868375,
            "rating_q975": 1274.947587956758,
            "rating_q025": 1246.4304786169168
        },
        "mistral-large-2411": {
            "rating": 1259.4530091044585,
            "rating_q975": 1266.3723930019908,
            "rating_q025": 1252.5336252069262
        },
        "magistral-medium-2506": {
            "rating": 1259.2268948765604,
            "rating_q975": 1271.3495425150377,
            "rating_q025": 1247.1042472380832
        },
        "hunyuan-large-vision": {
            "rating": 1257.864946077913,
            "rating_q975": 1275.8066932201264,
            "rating_q025": 1239.9231989356995
        },
        "mistral-large-2407": {
            "rating": 1256.9158457753133,
            "rating_q975": 1263.4706012095087,
            "rating_q025": 1250.361090341118
        },
        "gpt-4-0125-preview": {
            "rating": 1256.1685309085933,
            "rating_q975": 1262.575669190765,
            "rating_q025": 1249.7613926264216
        },
        "hunyuan-standard-2025-02-10": {
            "rating": 1256.0876017099743,
            "rating_q975": 1274.290602440252,
            "rating_q025": 1237.8846009796964
        },
        "llama-3.3-70b-instruct": {
            "rating": 1254.8242087061708,
            "rating_q975": 1260.1656461858493,
            "rating_q025": 1249.4827712264923
        },
        "claude-3-5-haiku-20241022": {
            "rating": 1254.7319005796298,
            "rating_q975": 1259.698857725048,
            "rating_q025": 1249.7649434342118
        },
        "llama-3.1-tulu-3-70b": {
            "rating": 1253.5503094922603,
            "rating_q975": 1272.9537432543086,
            "rating_q025": 1234.146875730212
        },
        "athene-v2-chat": {
            "rating": 1253.2348960229301,
            "rating_q975": 1260.6189151044314,
            "rating_q025": 1245.8508769414289
        },
        "llama-3.1-nemotron-70b-instruct": {
            "rating": 1251.6604133490873,
            "rating_q975": 1265.3071027722463,
            "rating_q025": 1238.0137239259284
        },
        "gemini-1.5-flash-001": {
            "rating": 1250.8400125087337,
            "rating_q975": 1257.4625204885292,
            "rating_q025": 1244.2175045289382
        },
        "gemma-2-27b-it": {
            "rating": 1247.7381168028942,
            "rating_q975": 1252.8854385591692,
            "rating_q025": 1242.5907950466192
        },
        "qwen2.5-72b-instruct": {
            "rating": 1245.9875409045749,
            "rating_q975": 1252.4539864799822,
            "rating_q025": 1239.5210953291676
        },
        "deepseek-v2.5": {
            "rating": 1245.9330926461466,
            "rating_q975": 1253.9188707661692,
            "rating_q025": 1237.947314526124
        },
        "amazon-nova-pro-v1.0": {
            "rating": 1245.7635883983426,
            "rating_q975": 1252.9384513467396,
            "rating_q025": 1238.5887254499455
        },
        "reka-core-20240904": {
            "rating": 1241.0257069837498,
            "rating_q975": 1254.2513370681802,
            "rating_q025": 1227.8000768993195
        },
        "command-r-plus-08-2024": {
            "rating": 1240.0743240377767,
            "rating_q975": 1251.2163395084187,
            "rating_q025": 1228.9323085671347
        },
        "athene-70b-0725": {
            "rating": 1239.7602532693381,
            "rating_q975": 1248.4558256749212,
            "rating_q025": 1231.064680863755
        },
        "gpt-oss-20b": {
            "rating": 1237.2316569187992,
            "rating_q975": 1250.0591603303415,
            "rating_q025": 1224.404153507257
        },
        "llama-3.1-70b-instruct": {
            "rating": 1235.0351329984737,
            "rating_q975": 1240.9646503222725,
            "rating_q025": 1229.105615674675
        },
        "jamba-1.5-large": {
            "rating": 1226.3178753229488,
            "rating_q975": 1238.8868569993438,
            "rating_q025": 1213.7488936465538
        },
        "gemini-1.5-flash-8b-001": {
            "rating": 1225.776847349245,
            "rating_q975": 1232.5796740625183,
            "rating_q025": 1218.9740206359716
        },
        "gemma-2-9b-it-simpo": {
            "rating": 1224.998443866652,
            "rating_q975": 1236.5635370332352,
            "rating_q025": 1213.4333507000688
        },
        "nemotron-4-340b-instruct": {
            "rating": 1222.4644895897688,
            "rating_q975": 1231.672373225046,
            "rating_q025": 1213.2566059544918
        },
        "c4ai-aya-expanse-32b": {
            "rating": 1221.0829820372956,
            "rating_q975": 1228.6113440895933,
            "rating_q025": 1213.5546199849978
        },
        "llama-3.1-nemotron-51b-instruct": {
            "rating": 1218.5604788621736,
            "rating_q975": 1236.7189965791993,
            "rating_q025": 1200.4019611451479
        },
        "gemma-2-9b-it": {
            "rating": 1218.1525406621686,
            "rating_q975": 1223.8349268438112,
            "rating_q025": 1212.470154480526
        },
        "command-r-plus": {
            "rating": 1217.7948192172355,
            "rating_q975": 1224.6882026140297,
            "rating_q025": 1210.9014358204413
        },
        "gpt-4-0314": {
            "rating": 1217.6459173354729,
            "rating_q975": 1225.8265105521893,
            "rating_q025": 1209.4653241187564
        },
        "claude-3-sonnet-20240229": {
            "rating": 1216.550900425474,
            "rating_q975": 1222.9258293548078,
            "rating_q025": 1210.1759714961404
        },
        "reka-flash-20240904": {
            "rating": 1215.658438587835,
            "rating_q975": 1228.5462906989094,
            "rating_q025": 1202.7705864767606
        },
        "gpt-4-0613": {
            "rating": 1213.2487228157092,
            "rating_q975": 1219.8900030210618,
            "rating_q025": 1206.6074426103567
        },
        "mistral-small-24b-instruct-2501": {
            "rating": 1213.0007391582421,
            "rating_q975": 1222.3172403928836,
            "rating_q025": 1203.6842379236007
        },
        "amazon-nova-lite-v1.0": {
            "rating": 1210.0720058052996,
            "rating_q975": 1218.2148529422468,
            "rating_q025": 1201.9291586683523
        },
        "glm-4-0520": {
            "rating": 1209.1662335634169,
            "rating_q975": 1221.0320531006887,
            "rating_q025": 1197.300414026145
        },
        "llama-3-70b-instruct": {
            "rating": 1205.1254279599452,
            "rating_q975": 1211.1831256060022,
            "rating_q025": 1199.0677303138882
        },
        "olmo-2-0325-32b-instruct": {
            "rating": 1203.1726189433352,
            "rating_q975": 1222.6751079112864,
            "rating_q025": 1183.670129975384
        },
        "qwen2-72b-instruct": {
            "rating": 1200.501941257033,
            "rating_q975": 1208.110151248314,
            "rating_q025": 1192.893731265752
        },
        "phi-4": {
            "rating": 1197.0432581579093,
            "rating_q975": 1204.5782052773607,
            "rating_q025": 1189.508311038458
        },
        "claude-3-haiku-20240307": {
            "rating": 1192.8854067045386,
            "rating_q975": 1198.86126962653,
            "rating_q025": 1186.9095437825472
        },
        "command-r-08-2024": {
            "rating": 1192.0595868342507,
            "rating_q975": 1203.5165891197641,
            "rating_q025": 1180.6025845487372
        },
        "amazon-nova-micro-v1.0": {
            "rating": 1191.561543214218,
            "rating_q975": 1199.7564182708597,
            "rating_q025": 1183.3666681575764
        },
        "qwen2.5-coder-32b-instruct": {
            "rating": 1189.3746992508827,
            "rating_q975": 1203.9423759744855,
            "rating_q025": 1174.80702252728
        },
        "c4ai-aya-expanse-8b": {
            "rating": 1184.500766748968,
            "rating_q975": 1195.5691665365664,
            "rating_q025": 1173.4323669613698
        },
        "ministral-8b-2410": {
            "rating": 1179.451104622454,
            "rating_q975": 1194.891048379474,
            "rating_q025": 1164.0111608654342
        },
        "mistral-large-2402": {
            "rating": 1178.771049207568,
            "rating_q975": 1186.235667170844,
            "rating_q025": 1171.306431244292
        },
        "llama-3.1-tulu-3-8b": {
            "rating": 1176.588278549964,
            "rating_q975": 1196.0745548144853,
            "rating_q025": 1157.1020022854425
        },
        "hunyuan-standard-256k": {
            "rating": 1172.4423077783222,
            "rating_q975": 1193.2521054208696,
            "rating_q025": 1151.6325101357747
        },
        "mistral-medium": {
            "rating": 1171.1901063554742,
            "rating_q975": 1180.397908700077,
            "rating_q025": 1161.9823040108713
        },
        "qwen1.5-110b-chat": {
            "rating": 1169.5385842685776,
            "rating_q975": 1178.8384144629345,
            "rating_q025": 1160.2387540742207
        },
        "deepseek-coder-v2": {
            "rating": 1169.3340112766014,
            "rating_q975": 1180.0217409510647,
            "rating_q025": 1158.646281602138
        },
        "jamba-1.5-mini": {
            "rating": 1164.218961901623,
            "rating_q975": 1176.6410234571379,
            "rating_q025": 1151.7969003461083
        },
        "llama-3.1-8b-instruct": {
            "rating": 1161.1430145857958,
            "rating_q975": 1167.4496042352955,
            "rating_q025": 1154.836424936296
        },
        "command-r": {
            "rating": 1160.6380715108482,
            "rating_q975": 1168.2646718095414,
            "rating_q025": 1153.0114712121551
        },
        "mixtral-8x22b-instruct-v0.1": {
            "rating": 1159.9836865375744,
            "rating_q975": 1167.3475781846187,
            "rating_q025": 1152.61979489053
        },
        "reka-flash-21b-20240226-online": {
            "rating": 1159.1779830403939,
            "rating_q975": 1171.1324135375785,
            "rating_q025": 1147.2235525432093
        },
        "qwen1.5-72b-chat": {
            "rating": 1158.491606143412,
            "rating_q975": 1166.8234586547399,
            "rating_q025": 1150.159753632084
        },
        "gemma-2-2b-it": {
            "rating": 1156.1188338998963,
            "rating_q975": 1162.287933193939,
            "rating_q025": 1149.9497346058538
        },
        "reka-flash-21b-20240226": {
            "rating": 1151.4062051114292,
            "rating_q975": 1161.1630310917883,
            "rating_q025": 1141.6493791310702
        },
        "llama-3-8b-instruct": {
            "rating": 1146.9089270252634,
            "rating_q975": 1153.3122457867062,
            "rating_q025": 1140.5056082638207
        },
        "wizardlm-70b": {
            "rating": 1143.8727753385037,
            "rating_q975": 1158.6237117685425,
            "rating_q025": 1129.121838908465
        },
        "yi-1.5-34b-chat": {
            "rating": 1142.834138750218,
            "rating_q975": 1151.496240747207,
            "rating_q025": 1134.1720367532291
        },
        "gemini-pro-dev-api": {
            "rating": 1142.5278904619622,
            "rating_q975": 1154.2927768001946,
            "rating_q025": 1130.7630041237298
        },
        "zephyr-orpo-141b-A35b-v0.1": {
            "rating": 1138.6808137217452,
            "rating_q975": 1156.5939655592565,
            "rating_q025": 1120.7676618842338
        },
        "qwq-32b-preview": {
            "rating": 1138.4584802879426,
            "rating_q975": 1159.1961483068394,
            "rating_q025": 1117.7208122690458
        },
        "gpt-3.5-turbo-0125": {
            "rating": 1138.273122337272,
            "rating_q975": 1145.4254090184686,
            "rating_q025": 1131.1208356560755
        },
        "granite-3.1-8b-instruct": {
            "rating": 1137.025661727926,
            "rating_q975": 1157.4147675533038,
            "rating_q025": 1116.6365559025483
        },
        "internlm2_5-20b-chat": {
            "rating": 1134.8676869670708,
            "rating_q975": 1146.8529689054922,
            "rating_q025": 1122.8824050286494
        },
        "gemini-pro": {
            "rating": 1125.9884797368716,
            "rating_q975": 1144.9635916636903,
            "rating_q025": 1107.0133678100528
        },
        "phi-3-medium-4k-instruct": {
            "rating": 1125.6717433151503,
            "rating_q975": 1134.0907681695458,
            "rating_q025": 1117.2527184607547
        },
        "tulu-2-dpo-70b": {
            "rating": 1122.470387114473,
            "rating_q975": 1139.2599601060301,
            "rating_q025": 1105.6808141229158
        },
        "mixtral-8x7b-instruct-v0.1": {
            "rating": 1121.896195092555,
            "rating_q975": 1128.9719333616492,
            "rating_q025": 1114.8204568234607
        },
        "dbrx-instruct-preview": {
            "rating": 1120.7701843673237,
            "rating_q975": 1130.4087902824754,
            "rating_q025": 1111.131578452172
        },
        "vicuna-33b": {
            "rating": 1117.9470012694148,
            "rating_q975": 1127.9618333547048,
            "rating_q025": 1107.9321691841249
        },
        "qwen1.5-32b-chat": {
            "rating": 1117.9050200980691,
            "rating_q975": 1128.0181314967754,
            "rating_q025": 1107.791908699363
        },
        "yi-34b-chat": {
            "rating": 1115.6722726219496,
            "rating_q975": 1126.932251776589,
            "rating_q025": 1104.41229346731
        },
        "openchat-3.5": {
            "rating": 1115.4918562423218,
            "rating_q975": 1131.1737467355074,
            "rating_q025": 1099.8099657491362
        },
        "qwen1.5-14b-chat": {
            "rating": 1111.8760303128097,
            "rating_q975": 1123.0857786550273,
            "rating_q025": 1100.666281970592
        },
        "starling-lm-7b-beta": {
            "rating": 1110.589371795777,
            "rating_q975": 1122.601799889145,
            "rating_q025": 1098.576943702409
        },
        "deepseek-llm-67b-chat": {
            "rating": 1109.1530816360878,
            "rating_q975": 1128.1218412071573,
            "rating_q025": 1090.1843220650183
        },
        "openchat-3.5-0106": {
            "rating": 1104.260459099411,
            "rating_q975": 1116.4873889259347,
            "rating_q025": 1092.0335292728873
        },
        "nous-hermes-2-mixtral-8x7b-dpo": {
            "rating": 1104.1587115980428,
            "rating_q975": 1124.2159135333225,
            "rating_q025": 1084.1015096627632
        },
        "falcon-180b-chat": {
            "rating": 1104.1074508026604,
            "rating_q975": 1136.9230290796547,
            "rating_q025": 1071.2918725256661
        },
        "snowflake-arctic-instruct": {
            "rating": 1100.1647237192428,
            "rating_q975": 1110.0403226429128,
            "rating_q025": 1090.289124795573
        },
        "wizardlm-13b": {
            "rating": 1097.6149905711113,
            "rating_q975": 1113.1008892860605,
            "rating_q025": 1082.1290918561622
        },
        "starling-lm-7b-alpha": {
            "rating": 1097.3455022406288,
            "rating_q975": 1110.3279551532305,
            "rating_q025": 1084.363049328027
        },
        "openhermes-2.5-mistral-7b": {
            "rating": 1095.524336135903,
            "rating_q975": 1114.0522085719385,
            "rating_q025": 1076.9964636998675
        },
        "llama-3.2-3b-instruct": {
            "rating": 1094.5850934347607,
            "rating_q975": 1108.2974116301873,
            "rating_q025": 1080.872775239334
        },
        "llama2-70b-steerlm-chat": {
            "rating": 1093.4587010927348,
            "rating_q975": 1115.0939503212742,
            "rating_q025": 1071.8234518641955
        },
        "phi-3-small-8k-instruct": {
            "rating": 1092.8539029313306,
            "rating_q975": 1102.735423867816,
            "rating_q025": 1082.9723819948451
        },
        "llama-2-70b-chat": {
            "rating": 1091.8588285313724,
            "rating_q975": 1100.3774298485966,
            "rating_q025": 1083.3402272141482
        },
        "granite-3.1-2b-instruct": {
            "rating": 1091.104756100256,
            "rating_q975": 1112.1484682689688,
            "rating_q025": 1070.0610439315433
        },
        "gpt-3.5-turbo-1106": {
            "rating": 1090.0987718150036,
            "rating_q975": 1103.6636327320255,
            "rating_q025": 1076.5339108979817
        },
        "solar-10.7b-instruct-v1.0": {
            "rating": 1086.9951855285394,
            "rating_q975": 1108.3662579304744,
            "rating_q025": 1065.6241131266045
        },
        "dolphin-2.2.1-mistral-7b": {
            "rating": 1085.007785011371,
            "rating_q975": 1114.186776691416,
            "rating_q025": 1055.8287933313259
        },
        "zephyr-7b-beta": {
            "rating": 1084.8020847447724,
            "rating_q975": 1098.8282296059572,
            "rating_q025": 1070.7759398835876
        },
        "zephyr-7b-alpha": {
            "rating": 1080.8198665086009,
            "rating_q975": 1106.609594170185,
            "rating_q025": 1055.0301388470168
        },
        "mpt-30b-chat": {
            "rating": 1078.57840344181,
            "rating_q975": 1101.5566212077833,
            "rating_q025": 1055.6001856758367
        },
        "vicuna-13b": {
            "rating": 1078.1325265293658,
            "rating_q975": 1088.7868958668653,
            "rating_q025": 1067.4781571918663
        },
        "granite-3.0-8b-instruct": {
            "rating": 1077.7800525115051,
            "rating_q975": 1092.9633449809085,
            "rating_q025": 1062.5967600421018
        },
        "gemma-1.1-7b-it": {
            "rating": 1072.419576100572,
            "rating_q975": 1081.5347399519633,
            "rating_q025": 1063.3044122491806
        },
        "mistral-7b-instruct-v0.2": {
            "rating": 1072.1476780403416,
            "rating_q975": 1082.5505629310646,
            "rating_q025": 1061.7447931496185
        },
        "guanaco-33b": {
            "rating": 1065.594915699914,
            "rating_q975": 1088.7926549830684,
            "rating_q025": 1042.3971764167597
        },
        "qwen1.5-7b-chat": {
            "rating": 1063.6008696138733,
            "rating_q975": 1081.431669468385,
            "rating_q025": 1045.7700697593616
        },
        "llama-2-13b-chat": {
            "rating": 1060.778410530418,
            "rating_q975": 1071.3868578651663,
            "rating_q025": 1050.1699631956694
        },
        "phi-3-mini-4k-instruct-june-2024": {
            "rating": 1055.1996452621252,
            "rating_q975": 1066.3229193088764,
            "rating_q025": 1044.076371215374
        },
        "phi-3-mini-4k-instruct": {
            "rating": 1053.6339648642838,
            "rating_q975": 1063.810972511462,
            "rating_q025": 1043.4569572171056
        },
        "granite-3.0-2b-instruct": {
            "rating": 1049.3787101527778,
            "rating_q975": 1064.5184692475557,
            "rating_q025": 1034.2389510579999
        },
        "qwen-14b-chat": {
            "rating": 1049.1661261956076,
            "rating_q975": 1067.4056551635417,
            "rating_q025": 1030.9265972276735
        },
        "vicuna-7b": {
            "rating": 1047.8126165761514,
            "rating_q975": 1062.977078506739,
            "rating_q025": 1032.6481546455639
        },
        "codellama-34b-instruct": {
            "rating": 1047.367462796912,
            "rating_q975": 1061.9419251911406,
            "rating_q025": 1032.7930004026832
        },
        "phi-3-mini-128k-instruct": {
            "rating": 1039.7934162786084,
            "rating_q975": 1051.3704727418326,
            "rating_q025": 1028.2163598153843
        },
        "llama-2-7b-chat": {
            "rating": 1036.6891844848242,
            "rating_q975": 1048.1214492422555,
            "rating_q025": 1025.2569197273929
        },
        "stripedhyena-nous-7b": {
            "rating": 1033.7907438271936,
            "rating_q975": 1051.8261944870426,
            "rating_q025": 1015.7552931673448
        },
        "gemma-7b-it": {
            "rating": 1032.908437316652,
            "rating_q975": 1047.5250820660115,
            "rating_q025": 1018.2917925672924
        },
        "mistral-7b-instruct": {
            "rating": 1029.6331807995798,
            "rating_q975": 1044.7626719427712,
            "rating_q025": 1014.5036896563885
        },
        "llama-3.2-1b-instruct": {
            "rating": 1028.6638490489681,
            "rating_q975": 1043.30837696368,
            "rating_q025": 1014.0193211342562
        },
        "smollm2-1.7b-instruct": {
            "rating": 1025.5202261803977,
            "rating_q975": 1052.188666174485,
            "rating_q025": 998.8517861863104
        },
        "codellama-70b-instruct": {
            "rating": 1015.5470956602544,
            "rating_q975": 1053.578525741691,
            "rating_q025": 977.5156655788177
        },
        "palm-2": {
            "rating": 1005.8741103260941,
            "rating_q975": 1021.0510279773191,
            "rating_q025": 990.697192674869
        },
        "gemma-1.1-2b-it": {
            "rating": 1005.2987939010734,
            "rating_q975": 1018.3479023045876,
            "rating_q025": 992.2496854975592
        },
        "olmo-7b-instruct": {
            "rating": 1002.3471998292129,
            "rating_q975": 1020.2967421479417,
            "rating_q025": 984.397657510484
        },
        "qwen1.5-4b-chat": {
            "rating": 1000.4533044959683,
            "rating_q975": 1015.2713531956265,
            "rating_q025": 985.63525579631
        },
        "koala-13b": {
            "rating": 978.806697531229,
            "rating_q975": 996.827839462022,
            "rating_q025": 960.785555600436
        },
        "gemma-2b-it": {
            "rating": 977.4371273697527,
            "rating_q975": 996.1715240142997,
            "rating_q025": 958.7027307252057
        },
        "chatglm3-6b": {
            "rating": 972.8692963769599,
            "rating_q975": 993.254516881435,
            "rating_q025": 952.4840758724848
        },
        "gpt4all-13b-snoozy": {
            "rating": 972.5155139553435,
            "rating_q975": 1005.0614634797025,
            "rating_q025": 939.9695644309845
        },
        "mpt-7b-chat": {
            "rating": 972.0053637850829,
            "rating_q975": 992.7859589702394,
            "rating_q025": 951.2247685999263
        },
        "alpaca-13b": {
            "rating": 967.5121549377002,
            "rating_q975": 987.1633198027911,
            "rating_q025": 947.8609900726093
        },
        "chatglm2-6b": {
            "rating": 951.9530958880347,
            "rating_q975": 974.8322362343299,
            "rating_q025": 929.0739555417395
        },
        "RWKV-4-Raven-14B": {
            "rating": 933.3937694053461,
            "rating_q975": 952.874610544955,
            "rating_q025": 913.9129282657373
        },
        "oasst-pythia-12b": {
            "rating": 927.3367615708601,
            "rating_q975": 945.2791368911312,
            "rating_q025": 909.3943862505889
        },
        "chatglm-6b": {
            "rating": 924.7436513761982,
            "rating_q975": 945.1718331936006,
            "rating_q025": 904.3154695587957
        },
        "fastchat-t5-3b": {
            "rating": 906.87690486504,
            "rating_q975": 927.9994618842509,
            "rating_q025": 885.7543478458292
        },
        "dolly-v2-12b": {
            "rating": 871.6988565672993,
            "rating_q975": 895.283466712894,
            "rating_q025": 848.1142464217047
        },
        "stablelm-tuned-alpha-7b": {
            "rating": 867.3416620466587,
            "rating_q975": 891.5249088070626,
            "rating_q025": 843.1584152862548
        },
        "llama-13b": {
            "rating": 808.6222079588983,
            "rating_q975": 837.3957900046885,
            "rating_q025": 779.8486259131082
        }
    },
    "japanese": {
        "gemini-2.5-pro": {
            "rating": 1469.2911992102443,
            "rating_q975": 1487.902274369611,
            "rating_q025": 1450.6801240508776
        },
        "gemini-2.5-flash-preview-09-2025": {
            "rating": 1420.152423179735,
            "rating_q975": 1475.075362610722,
            "rating_q025": 1365.229483748748
        },
        "gpt-4.5-preview-2025-02-27": {
            "rating": 1417.9398118146653,
            "rating_q975": 1455.7939042920943,
            "rating_q025": 1380.0857193372362
        },
        "o3-2025-04-16": {
            "rating": 1414.1354601724006,
            "rating_q975": 1432.3959485949315,
            "rating_q025": 1395.8749717498697
        },
        "gpt-5-chat": {
            "rating": 1410.2582844109575,
            "rating_q975": 1441.7154406702623,
            "rating_q025": 1378.8011281516526
        },
        "glm-4.5": {
            "rating": 1410.0436165199442,
            "rating_q975": 1433.4821449621859,
            "rating_q025": 1386.6050880777025
        },
        "gpt-5-high": {
            "rating": 1409.8838948675457,
            "rating_q975": 1432.238615424747,
            "rating_q025": 1387.5291743103444
        },
        "gemini-2.5-flash-lite-preview-09-2025-no-thinking": {
            "rating": 1408.6571772627087,
            "rating_q975": 1467.107863664973,
            "rating_q025": 1350.2064908604445
        },
        "chatgpt-4o-latest-20250326": {
            "rating": 1402.4321182743984,
            "rating_q975": 1423.5311452212031,
            "rating_q025": 1381.3330913275936
        },
        "grok-4-0709": {
            "rating": 1396.757735852504,
            "rating_q975": 1417.9677087759899,
            "rating_q025": 1375.5477629290183
        },
        "gemini-2.5-flash": {
            "rating": 1395.5404093793563,
            "rating_q975": 1412.9271425863294,
            "rating_q025": 1378.1536761723833
        },
        "grok-3-preview-02-24": {
            "rating": 1393.4282514581985,
            "rating_q975": 1414.2050397699604,
            "rating_q025": 1372.6514631464365
        },
        "qwen3-next-80b-a3b-instruct": {
            "rating": 1390.1668652440037,
            "rating_q975": 1428.4991191347397,
            "rating_q025": 1351.8346113532677
        },
        "qwen3-235b-a22b-instruct-2507": {
            "rating": 1386.5328127615464,
            "rating_q975": 1407.833229971132,
            "rating_q025": 1365.232395551961
        },
        "qwen3-max-preview": {
            "rating": 1385.5891558032913,
            "rating_q975": 1418.8482341185577,
            "rating_q025": 1352.330077488025
        },
        "mistral-medium-2508": {
            "rating": 1384.5816257562067,
            "rating_q975": 1412.6879507317549,
            "rating_q025": 1356.4753007806585
        },
        "deepseek-r1-0528": {
            "rating": 1377.2095692634991,
            "rating_q975": 1402.4051780002608,
            "rating_q025": 1352.0139605267375
        },
        "claude-opus-4-1-20250805-thinking-16k": {
            "rating": 1376.549235948647,
            "rating_q975": 1405.980524054794,
            "rating_q025": 1347.1179478425001
        },
        "qwen3-235b-a22b-thinking-2507": {
            "rating": 1373.5512684592775,
            "rating_q975": 1402.6150542933492,
            "rating_q025": 1344.4874826252058
        },
        "qwen3-235b-a22b-no-thinking": {
            "rating": 1369.3261687509864,
            "rating_q975": 1390.223178921851,
            "rating_q025": 1348.4291585801218
        },
        "deepseek-v3.1": {
            "rating": 1365.8623394385695,
            "rating_q975": 1398.6582094686726,
            "rating_q025": 1333.0664694084664
        },
        "deepseek-v3.1-thinking": {
            "rating": 1362.3814632312385,
            "rating_q975": 1399.1274801580012,
            "rating_q025": 1325.6354463044759
        },
        "claude-opus-4-1-20250805": {
            "rating": 1362.052478498544,
            "rating_q975": 1385.0690800338357,
            "rating_q025": 1339.0358769632521
        },
        "mai-1-preview": {
            "rating": 1358.669200532822,
            "rating_q975": 1394.0839478473943,
            "rating_q025": 1323.2544532182499
        },
        "gemini-2.5-flash-lite-preview-06-17-thinking": {
            "rating": 1354.0199619482,
            "rating_q975": 1375.7162472747286,
            "rating_q025": 1332.3236766216714
        },
        "gpt-5-mini-high": {
            "rating": 1351.7774556922016,
            "rating_q975": 1384.2911478868004,
            "rating_q025": 1319.2637634976027
        },
        "o1-2024-12-17": {
            "rating": 1351.44406585346,
            "rating_q975": 1376.6312830548109,
            "rating_q025": 1326.256848652109
        },
        "glm-4.5-air": {
            "rating": 1347.2067881503303,
            "rating_q975": 1369.071435285943,
            "rating_q025": 1325.3421410147178
        },
        "qwen3-30b-a3b-instruct-2507": {
            "rating": 1342.9366197340833,
            "rating_q975": 1366.3875938346425,
            "rating_q025": 1319.485645633524
        },
        "hunyuan-turbos-20250416": {
            "rating": 1341.0572464506874,
            "rating_q975": 1373.1016029590087,
            "rating_q025": 1309.0128899423662
        },
        "grok-3-mini-beta": {
            "rating": 1338.1102281587646,
            "rating_q975": 1362.1612736445895,
            "rating_q025": 1314.0591826729396
        },
        "kimi-k2-0711-preview": {
            "rating": 1337.8380130821572,
            "rating_q975": 1357.9752726267568,
            "rating_q025": 1317.7007535375576
        },
        "kimi-k2-0905-preview": {
            "rating": 1332.6479064477967,
            "rating_q975": 1379.6329430754947,
            "rating_q025": 1285.6628698200986
        },
        "claude-opus-4-20250514-thinking-16k": {
            "rating": 1331.2447281629836,
            "rating_q975": 1353.2982862837155,
            "rating_q025": 1309.1911700422518
        },
        "deepseek-v3-0324": {
            "rating": 1330.0070725483356,
            "rating_q975": 1349.2657817590991,
            "rating_q025": 1310.748363337572
        },
        "claude-sonnet-4-5-20250929-thinking-32k": {
            "rating": 1329.761069300271,
            "rating_q975": 1383.3548573209089,
            "rating_q025": 1276.167281279633
        },
        "deepseek-r1": {
            "rating": 1329.1215021912726,
            "rating_q975": 1354.405040643856,
            "rating_q025": 1303.8379637386893
        },
        "claude-opus-4-20250514": {
            "rating": 1326.2973509933317,
            "rating_q975": 1345.6099666797024,
            "rating_q025": 1306.984735306961
        },
        "gpt-4.1-2025-04-14": {
            "rating": 1323.8837903129634,
            "rating_q975": 1343.358300680964,
            "rating_q025": 1304.4092799449627
        },
        "grok-3-mini-high": {
            "rating": 1319.7607028079285,
            "rating_q975": 1347.1356921311808,
            "rating_q025": 1292.3857134846762
        },
        "gpt-oss-120b": {
            "rating": 1318.7120386981135,
            "rating_q975": 1347.16459977982,
            "rating_q025": 1290.259477616407
        },
        "qwen3-coder-480b-a35b-instruct": {
            "rating": 1313.615231060219,
            "rating_q975": 1334.076736655801,
            "rating_q025": 1293.153725464637
        },
        "mistral-medium-2505": {
            "rating": 1311.0084424568854,
            "rating_q975": 1331.4221808512975,
            "rating_q025": 1290.5947040624733
        },
        "qwen3-235b-a22b": {
            "rating": 1309.1039534333106,
            "rating_q975": 1331.8422232373089,
            "rating_q025": 1286.3656836293123
        },
        "qwen2.5-max": {
            "rating": 1308.9644162452732,
            "rating_q975": 1330.2194956257474,
            "rating_q025": 1287.709336864799
        },
        "o4-mini-2025-04-16": {
            "rating": 1308.45023385977,
            "rating_q975": 1327.782803901941,
            "rating_q025": 1289.117663817599
        },
        "gemini-2.0-flash-lite-preview-02-05": {
            "rating": 1308.2635297889617,
            "rating_q975": 1332.364457444025,
            "rating_q025": 1284.1626021338984
        },
        "o1-preview": {
            "rating": 1304.3349420913787,
            "rating_q975": 1327.241841798932,
            "rating_q025": 1281.4280423838254
        },
        "gemini-1.5-pro-002": {
            "rating": 1298.6495479464866,
            "rating_q975": 1314.9835287622207,
            "rating_q025": 1282.3155671307525
        },
        "command-a-03-2025": {
            "rating": 1293.534765135555,
            "rating_q975": 1312.1062821007722,
            "rating_q025": 1274.963248170338
        },
        "gemma-3-27b-it": {
            "rating": 1292.4858852549212,
            "rating_q975": 1311.7570081132521,
            "rating_q025": 1273.2147623965902
        },
        "longcat-flash-chat": {
            "rating": 1289.056625159864,
            "rating_q975": 1334.760081286698,
            "rating_q025": 1243.35316903303
        },
        "gpt-4.1-mini-2025-04-14": {
            "rating": 1287.9372711087597,
            "rating_q975": 1307.6808973933157,
            "rating_q025": 1268.1936448242036
        },
        "o3-mini-high": {
            "rating": 1287.6986591216644,
            "rating_q975": 1317.3963734127763,
            "rating_q025": 1258.0009448305525
        },
        "claude-sonnet-4-20250514": {
            "rating": 1287.3578846238117,
            "rating_q975": 1307.63150457674,
            "rating_q025": 1267.0842646708834
        },
        "mistral-small-2506": {
            "rating": 1287.309672153963,
            "rating_q975": 1312.7026319495117,
            "rating_q025": 1261.9167123584143
        },
        "nvidia-llama-3.3-nemotron-super-49b-v1.5": {
            "rating": 1285.9777763053492,
            "rating_q975": 1315.7890002563227,
            "rating_q025": 1256.1665523543757
        },
        "claude-sonnet-4-20250514-thinking-32k": {
            "rating": 1283.3369430757257,
            "rating_q975": 1305.7781999468527,
            "rating_q025": 1260.8956862045986
        },
        "qwen3-next-80b-a3b-thinking": {
            "rating": 1280.6505486754884,
            "rating_q975": 1324.8932501221227,
            "rating_q025": 1236.407847228854
        },
        "gemma-3n-e4b-it": {
            "rating": 1278.2946149395916,
            "rating_q975": 1300.9582701397205,
            "rating_q025": 1255.6309597394627
        },
        "step-1o-turbo-202506": {
            "rating": 1277.76583799319,
            "rating_q975": 1319.7206527528247,
            "rating_q025": 1235.8110232335553
        },
        "deepseek-v3": {
            "rating": 1274.3378738723216,
            "rating_q975": 1297.1494758618896,
            "rating_q025": 1251.5262718827535
        },
        "o3-mini": {
            "rating": 1270.6462729507634,
            "rating_q975": 1286.7726817085877,
            "rating_q025": 1254.5198641929392
        },
        "claude-3-7-sonnet-20250219-thinking-32k": {
            "rating": 1270.4255688724024,
            "rating_q975": 1290.0331289983624,
            "rating_q025": 1250.8180087464425
        },
        "gpt-4o-2024-05-13": {
            "rating": 1263.433936616285,
            "rating_q975": 1276.7137304299151,
            "rating_q025": 1250.154142802655
        },
        "gemini-1.5-flash-002": {
            "rating": 1261.7650915934514,
            "rating_q975": 1282.336705712364,
            "rating_q025": 1241.193477474539
        },
        "qwen3-30b-a3b": {
            "rating": 1256.3709976631612,
            "rating_q975": 1278.8197604164052,
            "rating_q025": 1233.9222349099173
        },
        "qwq-32b": {
            "rating": 1255.5696757468777,
            "rating_q975": 1280.504782242296,
            "rating_q025": 1230.6345692514594
        },
        "qwen-plus-0125": {
            "rating": 1255.4318701086381,
            "rating_q975": 1293.8448799638006,
            "rating_q025": 1217.0188602534756
        },
        "gpt-oss-20b": {
            "rating": 1254.628092225063,
            "rating_q975": 1295.4312090642056,
            "rating_q025": 1213.8249753859204
        },
        "o1-mini": {
            "rating": 1252.3936653874118,
            "rating_q975": 1269.4100149219073,
            "rating_q025": 1235.3773158529164
        },
        "grok-2-2024-08-13": {
            "rating": 1251.7775958835387,
            "rating_q975": 1266.7330131659996,
            "rating_q025": 1236.8221786010777
        },
        "gemini-advanced-0514": {
            "rating": 1247.4805133649543,
            "rating_q975": 1266.8456674683962,
            "rating_q025": 1228.1153592615124
        },
        "gemini-1.5-pro-001": {
            "rating": 1245.639541894945,
            "rating_q975": 1260.9127537444353,
            "rating_q025": 1230.3663300454548
        },
        "gpt-4o-2024-08-06": {
            "rating": 1240.8199946949376,
            "rating_q975": 1258.0930138622318,
            "rating_q025": 1223.5469755276433
        },
        "claude-3-5-sonnet-20241022": {
            "rating": 1239.082982605454,
            "rating_q975": 1251.9413586655198,
            "rating_q025": 1226.224606545388
        },
        "yi-lightning": {
            "rating": 1237.1386285508113,
            "rating_q975": 1259.8918134314572,
            "rating_q025": 1214.3854436701654
        },
        "claude-3-5-sonnet-20240620": {
            "rating": 1236.9308677696367,
            "rating_q975": 1251.1429298550534,
            "rating_q025": 1222.7188056842201
        },
        "glm-4-plus-0111": {
            "rating": 1235.6015626701137,
            "rating_q975": 1273.0814866841529,
            "rating_q025": 1198.1216386560745
        },
        "deepseek-v2.5-1210": {
            "rating": 1232.457533577895,
            "rating_q975": 1272.8396863725359,
            "rating_q025": 1192.075380783254
        },
        "athene-v2-chat": {
            "rating": 1222.0348761825005,
            "rating_q975": 1244.2049550659265,
            "rating_q025": 1199.8647972990746
        },
        "gpt-4o-mini-2024-07-18": {
            "rating": 1222.0069785145215,
            "rating_q975": 1235.4702191964238,
            "rating_q025": 1208.5437378326192
        },
        "minimax-m1": {
            "rating": 1221.4064344318072,
            "rating_q975": 1243.269915133652,
            "rating_q025": 1199.5429537299624
        },
        "grok-2-mini-2024-08-13": {
            "rating": 1219.648062307766,
            "rating_q975": 1235.9172221210301,
            "rating_q025": 1203.3789024945017
        },
        "glm-4-plus": {
            "rating": 1216.3081211453568,
            "rating_q975": 1242.0404535582663,
            "rating_q025": 1190.5757887324473
        },
        "gpt-4-1106-preview": {
            "rating": 1215.644560474679,
            "rating_q975": 1232.5408297005856,
            "rating_q025": 1198.7482912487726
        },
        "mistral-small-3.1-24b-instruct-2503": {
            "rating": 1214.5455212235024,
            "rating_q975": 1236.836618724719,
            "rating_q025": 1192.2544237222858
        },
        "llama-3.1-405b-instruct-bf16": {
            "rating": 1213.9225743991885,
            "rating_q975": 1233.245095379789,
            "rating_q025": 1194.600053418588
        },
        "qwen2.5-plus-1127": {
            "rating": 1212.8910427449944,
            "rating_q975": 1244.478197874338,
            "rating_q025": 1181.3038876156506
        },
        "qwen-max-0919": {
            "rating": 1212.0375178730394,
            "rating_q975": 1243.7251593578144,
            "rating_q025": 1180.3498763882644
        },
        "llama-4-scout-17b-16e-instruct": {
            "rating": 1211.6517539467825,
            "rating_q975": 1233.937209390139,
            "rating_q025": 1189.366298503426
        },
        "llama-4-maverick-17b-128e-instruct": {
            "rating": 1211.4983382488472,
            "rating_q975": 1232.9112775789954,
            "rating_q025": 1190.085398918699
        },
        "claude-3-opus-20240229": {
            "rating": 1209.9530654866212,
            "rating_q975": 1221.9770046980677,
            "rating_q025": 1197.9291262751747
        },
        "amazon-nova-pro-v1.0": {
            "rating": 1205.8565773044857,
            "rating_q975": 1230.7103357280723,
            "rating_q025": 1181.002818880899
        },
        "gpt-4.1-nano-2025-04-14": {
            "rating": 1203.4111330970482,
            "rating_q975": 1248.3192137175686,
            "rating_q025": 1158.5030524765277
        },
        "gpt-4-0125-preview": {
            "rating": 1202.1252792530076,
            "rating_q975": 1218.9471119731197,
            "rating_q025": 1185.3034465328956
        },
        "gpt-4-turbo-2024-04-09": {
            "rating": 1201.0640821374259,
            "rating_q975": 1215.6420086118937,
            "rating_q025": 1186.486155662958
        },
        "deepseek-v2.5": {
            "rating": 1198.0662814927568,
            "rating_q975": 1223.4160173510188,
            "rating_q025": 1172.7165456344949
        },
        "gemini-1.5-flash-001": {
            "rating": 1192.7578688453266,
            "rating_q975": 1209.068218599128,
            "rating_q025": 1176.4475190915252
        },
        "mistral-large-2407": {
            "rating": 1191.885063243213,
            "rating_q975": 1207.971345602087,
            "rating_q025": 1175.7987808843388
        },
        "magistral-medium-2506": {
            "rating": 1190.2881126972138,
            "rating_q975": 1223.7598445484641,
            "rating_q025": 1156.8163808459635
        },
        "qwen2.5-72b-instruct": {
            "rating": 1186.201637324638,
            "rating_q975": 1206.0304098515269,
            "rating_q025": 1166.3728647977493
        },
        "claude-3-5-haiku-20241022": {
            "rating": 1185.4739182978406,
            "rating_q975": 1201.2036598523391,
            "rating_q025": 1169.744176743342
        },
        "gemma-2-27b-it": {
            "rating": 1182.9056888515652,
            "rating_q975": 1196.8662663076257,
            "rating_q025": 1168.9451113955047
        },
        "llama-3.1-405b-instruct-fp8": {
            "rating": 1177.6411574839894,
            "rating_q975": 1192.452834919576,
            "rating_q025": 1162.829480048403
        },
        "mistral-large-2411": {
            "rating": 1175.4512002953516,
            "rating_q975": 1197.0238200670574,
            "rating_q025": 1153.8785805236457
        },
        "command-r-plus-08-2024": {
            "rating": 1173.3624630198847,
            "rating_q975": 1210.4774327927662,
            "rating_q025": 1136.2474932470031
        },
        "c4ai-aya-expanse-32b": {
            "rating": 1172.3257359401955,
            "rating_q975": 1193.9562609975887,
            "rating_q025": 1150.6952108828023
        },
        "phi-4": {
            "rating": 1164.3470736391357,
            "rating_q975": 1190.1911659479542,
            "rating_q025": 1138.5029813303172
        },
        "command-r-plus": {
            "rating": 1161.2643641941868,
            "rating_q975": 1178.776304015846,
            "rating_q025": 1143.7524243725275
        },
        "llama-3.3-70b-instruct": {
            "rating": 1159.0496688480634,
            "rating_q975": 1176.464246283078,
            "rating_q025": 1141.635091413049
        },
        "amazon-nova-micro-v1.0": {
            "rating": 1158.8003853370446,
            "rating_q975": 1185.2009922761488,
            "rating_q025": 1132.3997783979405
        },
        "amazon-nova-lite-v1.0": {
            "rating": 1158.328353274007,
            "rating_q975": 1185.108879227836,
            "rating_q025": 1131.547827320178
        },
        "gemini-1.5-flash-8b-001": {
            "rating": 1157.2900824753629,
            "rating_q975": 1178.4616745861272,
            "rating_q025": 1136.1184903645985
        },
        "gemma-2-9b-it": {
            "rating": 1151.0190810277313,
            "rating_q975": 1166.930347453793,
            "rating_q025": 1135.1078146016696
        },
        "command-r-08-2024": {
            "rating": 1150.2957025625713,
            "rating_q975": 1182.7683294252172,
            "rating_q025": 1117.8230756999253
        },
        "gemma-2-9b-it-simpo": {
            "rating": 1146.428983440911,
            "rating_q975": 1177.9222223567876,
            "rating_q025": 1114.9357445250344
        },
        "athene-70b-0725": {
            "rating": 1144.3605411966355,
            "rating_q975": 1166.16952750966,
            "rating_q025": 1122.551554883611
        },
        "gpt-4-0314": {
            "rating": 1143.4021326535499,
            "rating_q975": 1168.0420040919641,
            "rating_q025": 1118.7622612151356
        },
        "llama-3.1-70b-instruct": {
            "rating": 1139.970128041366,
            "rating_q975": 1155.238613178717,
            "rating_q025": 1124.701642904015
        },
        "claude-3-sonnet-20240229": {
            "rating": 1138.9644724289815,
            "rating_q975": 1155.3301430233355,
            "rating_q025": 1122.5988018346275
        },
        "nemotron-4-340b-instruct": {
            "rating": 1134.7797956071681,
            "rating_q975": 1162.9170436014792,
            "rating_q025": 1106.642547612857
        },
        "deepseek-coder-v2": {
            "rating": 1134.493257823285,
            "rating_q975": 1165.6652247679367,
            "rating_q025": 1103.3212908786331
        },
        "c4ai-aya-expanse-8b": {
            "rating": 1130.33414058454,
            "rating_q975": 1164.2462473649764,
            "rating_q025": 1096.4220338041034
        },
        "jamba-1.5-large": {
            "rating": 1124.751684856552,
            "rating_q975": 1160.3891886224658,
            "rating_q025": 1089.114181090638
        },
        "gpt-4-0613": {
            "rating": 1120.6698013357582,
            "rating_q975": 1138.8372485804846,
            "rating_q025": 1102.5023540910317
        },
        "qwen2-72b-instruct": {
            "rating": 1117.9330052224286,
            "rating_q975": 1137.5849675716363,
            "rating_q025": 1098.281042873221
        },
        "mistral-small-24b-instruct-2501": {
            "rating": 1116.4551056423118,
            "rating_q975": 1151.9133102185053,
            "rating_q025": 1080.9969010661182
        },
        "claude-3-haiku-20240307": {
            "rating": 1109.509471435347,
            "rating_q975": 1124.3642486589383,
            "rating_q025": 1094.6546942117557
        },
        "command-r": {
            "rating": 1099.7797536606163,
            "rating_q975": 1120.9634402912352,
            "rating_q025": 1078.5960670299974
        },
        "gemma-2-2b-it": {
            "rating": 1091.0647665591675,
            "rating_q975": 1108.00058288267,
            "rating_q025": 1074.1289502356651
        },
        "reka-flash-21b-20240226-online": {
            "rating": 1080.7685745924268,
            "rating_q975": 1114.9929902443905,
            "rating_q025": 1046.5441589404631
        },
        "qwen1.5-110b-chat": {
            "rating": 1079.7838211376284,
            "rating_q975": 1105.3042042035158,
            "rating_q025": 1054.263438071741
        },
        "llama-3.1-8b-instruct": {
            "rating": 1068.3911991546684,
            "rating_q975": 1085.9231298027692,
            "rating_q025": 1050.8592685065676
        },
        "qwen1.5-72b-chat": {
            "rating": 1065.5007357725665,
            "rating_q975": 1092.3724883525313,
            "rating_q025": 1038.6289831926017
        },
        "reka-flash-21b-20240226": {
            "rating": 1056.648773408211,
            "rating_q975": 1084.6324543074015,
            "rating_q025": 1028.6650925090203
        },
        "gpt-3.5-turbo-0125": {
            "rating": 1050.8691543834357,
            "rating_q975": 1071.3545176896448,
            "rating_q025": 1030.3837910772265
        },
        "phi-3-medium-4k-instruct": {
            "rating": 1048.4476680306957,
            "rating_q975": 1071.323921577642,
            "rating_q025": 1025.5714144837493
        },
        "mixtral-8x22b-instruct-v0.1": {
            "rating": 1042.470715805881,
            "rating_q975": 1062.3709686515656,
            "rating_q025": 1022.5704629601961
        },
        "qwen1.5-32b-chat": {
            "rating": 1034.5567915335876,
            "rating_q975": 1067.332320837563,
            "rating_q025": 1001.781262229612
        },
        "gemini-pro-dev-api": {
            "rating": 1029.567053002268,
            "rating_q975": 1073.8952352170977,
            "rating_q025": 985.2388707874384
        },
        "yi-1.5-34b-chat": {
            "rating": 1028.2588260316604,
            "rating_q975": 1055.0159739208616,
            "rating_q025": 1001.5016781424592
        },
        "qwen1.5-14b-chat": {
            "rating": 1027.843396125806,
            "rating_q975": 1067.0118423982015,
            "rating_q025": 988.6749498534108
        },
        "jamba-1.5-mini": {
            "rating": 1026.924522094332,
            "rating_q975": 1061.5246541499423,
            "rating_q025": 992.3243900387214
        },
        "llama-3-70b-instruct": {
            "rating": 1024.1938415839663,
            "rating_q975": 1037.9911889943098,
            "rating_q025": 1010.3964941736228
        },
        "mistral-medium": {
            "rating": 1020.102694149007,
            "rating_q975": 1052.939682251664,
            "rating_q025": 987.2657060463499
        },
        "mistral-large-2402": {
            "rating": 1015.8092908313124,
            "rating_q975": 1037.0763476514917,
            "rating_q025": 994.542234011133
        },
        "yi-34b-chat": {
            "rating": 1005.817862358559,
            "rating_q975": 1048.463803580184,
            "rating_q025": 963.171921136934
        },
        "starling-lm-7b-beta": {
            "rating": 1005.3795269360593,
            "rating_q975": 1048.5135217544384,
            "rating_q025": 962.2455321176801
        },
        "dbrx-instruct-preview": {
            "rating": 996.3502918848935,
            "rating_q975": 1025.8591281027925,
            "rating_q025": 966.8414556669945
        },
        "gemma-1.1-7b-it": {
            "rating": 976.9832095124536,
            "rating_q975": 1006.0220045993455,
            "rating_q025": 947.9444144255618
        },
        "snowflake-arctic-instruct": {
            "rating": 976.4670918569925,
            "rating_q975": 1000.4645564190611,
            "rating_q025": 952.469627294924
        },
        "llama-3-8b-instruct": {
            "rating": 974.0950600976928,
            "rating_q975": 990.4212735506261,
            "rating_q025": 957.7688466447595
        },
        "phi-3-small-8k-instruct": {
            "rating": 972.3601851567114,
            "rating_q975": 1002.9862248217204,
            "rating_q025": 941.7341454917024
        },
        "vicuna-33b": {
            "rating": 964.2559788044218,
            "rating_q975": 1005.6030610246393,
            "rating_q025": 922.9088965842044
        },
        "phi-3-mini-4k-instruct-june-2024": {
            "rating": 964.0549785637781,
            "rating_q975": 996.0302421747068,
            "rating_q025": 932.0797149528495
        },
        "phi-3-mini-4k-instruct": {
            "rating": 940.720260323003,
            "rating_q975": 973.8549296057023,
            "rating_q025": 907.5855910403037
        },
        "mixtral-8x7b-instruct-v0.1": {
            "rating": 938.4668505232229,
            "rating_q975": 959.6571183818696,
            "rating_q025": 917.2765826645762
        },
        "llama-2-70b-chat": {
            "rating": 934.9448079599508,
            "rating_q975": 967.3197128298029,
            "rating_q025": 902.5699030900987
        },
        "vicuna-13b": {
            "rating": 925.2844988270809,
            "rating_q975": 977.0613168799126,
            "rating_q025": 873.5076807742493
        },
        "phi-3-mini-128k-instruct": {
            "rating": 905.7657184549868,
            "rating_q975": 936.6101216022703,
            "rating_q025": 874.9213153077033
        },
        "llama-2-13b-chat": {
            "rating": 900.9324942123246,
            "rating_q975": 949.9873610634668,
            "rating_q025": 851.8776273611825
        },
        "mistral-7b-instruct-v0.2": {
            "rating": 885.0834586560313,
            "rating_q975": 931.0195428956183,
            "rating_q025": 839.1473744164443
        }
    },
    "korean": {
        "gemini-2.5-pro": {
            "rating": 1450.2040682297234,
            "rating_q975": 1469.0085670546791,
            "rating_q025": 1431.3995694047676
        },
        "glm-4.6": {
            "rating": 1403.805225090162,
            "rating_q975": 1446.7104081500615,
            "rating_q025": 1360.9000420302623
        },
        "chatgpt-4o-latest-20250326": {
            "rating": 1400.121673041541,
            "rating_q975": 1421.8985523085344,
            "rating_q025": 1378.3447937745477
        },
        "hunyuan-t1-20250711": {
            "rating": 1396.1123987129574,
            "rating_q975": 1440.2851696921039,
            "rating_q025": 1351.939627733811
        },
        "o1-2024-12-17": {
            "rating": 1393.7952284048067,
            "rating_q975": 1423.9762447815467,
            "rating_q025": 1363.6142120280667
        },
        "gemini-2.5-flash-preview-09-2025": {
            "rating": 1393.5709622853465,
            "rating_q975": 1427.9535604506484,
            "rating_q025": 1359.1883641200445
        },
        "qwen3-vl-235b-a22b-instruct": {
            "rating": 1389.6646791179799,
            "rating_q975": 1427.6296220537017,
            "rating_q025": 1351.699736182258
        },
        "qwen3-max-preview": {
            "rating": 1389.4645799629454,
            "rating_q975": 1414.691009768729,
            "rating_q025": 1364.238150157162
        },
        "gpt-4.5-preview-2025-02-27": {
            "rating": 1388.7717489394004,
            "rating_q975": 1431.3390997229592,
            "rating_q025": 1346.2043981558415
        },
        "glm-4.5": {
            "rating": 1381.4072204524161,
            "rating_q975": 1406.5227751136385,
            "rating_q025": 1356.2916657911937
        },
        "gemini-2.5-flash": {
            "rating": 1380.8703814999687,
            "rating_q975": 1399.7852107013048,
            "rating_q025": 1361.9555522986327
        },
        "qwen3-235b-a22b-instruct-2507": {
            "rating": 1378.8700473058543,
            "rating_q975": 1401.502088285371,
            "rating_q025": 1356.2380063263377
        },
        "grok-4-0709": {
            "rating": 1378.6634650374133,
            "rating_q975": 1401.95789816492,
            "rating_q025": 1355.3690319099067
        },
        "mistral-medium-2508": {
            "rating": 1378.5066608962063,
            "rating_q975": 1399.4141432533504,
            "rating_q025": 1357.5991785390622
        },
        "claude-opus-4-1-20250805-thinking-16k": {
            "rating": 1377.3445035358013,
            "rating_q975": 1401.3072685323905,
            "rating_q025": 1353.3817385392122
        },
        "claude-sonnet-4-5-20250929-thinking-32k": {
            "rating": 1376.9599433658693,
            "rating_q975": 1416.1431269749053,
            "rating_q025": 1337.7767597568334
        },
        "amazon-nova-experimental-chat-10-09": {
            "rating": 1369.6023542169464,
            "rating_q975": 1426.3498874277423,
            "rating_q025": 1312.8548210061506
        },
        "grok-3-preview-02-24": {
            "rating": 1365.1202082634734,
            "rating_q975": 1392.2124950301595,
            "rating_q025": 1338.0279214967873
        },
        "qwen3-235b-a22b-no-thinking": {
            "rating": 1364.4577164493965,
            "rating_q975": 1388.346459028458,
            "rating_q025": 1340.568973870335
        },
        "gpt-5-high": {
            "rating": 1363.5904947034123,
            "rating_q975": 1387.2621122975493,
            "rating_q025": 1339.9188771092754
        },
        "gemini-2.5-flash-lite-preview-09-2025-no-thinking": {
            "rating": 1361.5951382311382,
            "rating_q975": 1397.158930407633,
            "rating_q025": 1326.0313460546433
        },
        "qwen3-max-2025-09-23": {
            "rating": 1360.0372087463222,
            "rating_q975": 1397.9899384384883,
            "rating_q025": 1322.0844790541562
        },
        "claude-opus-4-1-20250805": {
            "rating": 1359.093149109759,
            "rating_q975": 1380.0601900810736,
            "rating_q025": 1338.1261081384444
        },
        "gpt-5-chat": {
            "rating": 1358.2904466780224,
            "rating_q975": 1381.8774120764242,
            "rating_q025": 1334.7034812796205
        },
        "o3-2025-04-16": {
            "rating": 1358.2117342219926,
            "rating_q975": 1377.5846584752067,
            "rating_q025": 1338.8388099687786
        },
        "qwen3-vl-235b-a22b-thinking": {
            "rating": 1358.185658364472,
            "rating_q975": 1398.7819993227656,
            "rating_q025": 1317.5893174061782
        },
        "qwen3-235b-a22b-thinking-2507": {
            "rating": 1358.173033459119,
            "rating_q975": 1400.351238895775,
            "rating_q025": 1315.9948280224633
        },
        "longcat-flash-chat": {
            "rating": 1355.158098238491,
            "rating_q975": 1390.2597820645542,
            "rating_q025": 1320.0564144124278
        },
        "gemini-2.5-flash-lite-preview-06-17-thinking": {
            "rating": 1353.2759170519516,
            "rating_q975": 1376.96911082622,
            "rating_q025": 1329.5827232776833
        },
        "qwen3-next-80b-a3b-instruct": {
            "rating": 1352.1278058472114,
            "rating_q975": 1382.7981742038085,
            "rating_q025": 1321.4574374906144
        },
        "hunyuan-turbos-20250416": {
            "rating": 1349.1587058143373,
            "rating_q975": 1399.9295136462708,
            "rating_q025": 1298.3878979824037
        },
        "gpt-4.1-2025-04-14": {
            "rating": 1347.3314432971906,
            "rating_q975": 1367.7426694047197,
            "rating_q025": 1326.9202171896616
        },
        "deepseek-v3.2-exp-thinking": {
            "rating": 1342.150078988986,
            "rating_q975": 1386.8088326120187,
            "rating_q025": 1297.4913253659533
        },
        "deepseek-r1-0528": {
            "rating": 1341.0253425347516,
            "rating_q975": 1376.3505394435772,
            "rating_q025": 1305.700145625926
        },
        "mai-1-preview": {
            "rating": 1340.6263546967077,
            "rating_q975": 1368.4024938706311,
            "rating_q025": 1312.8502155227843
        },
        "grok-3-mini-high": {
            "rating": 1339.641276502332,
            "rating_q975": 1373.6634955074967,
            "rating_q025": 1305.6190574971672
        },
        "ling-flash-2.0": {
            "rating": 1336.1548139600402,
            "rating_q975": 1376.001830914235,
            "rating_q025": 1296.3077970058455
        },
        "deepseek-v3.1": {
            "rating": 1332.432829541109,
            "rating_q975": 1359.9931237985256,
            "rating_q025": 1304.8725352836923
        },
        "grok-4-fast": {
            "rating": 1331.9406700081024,
            "rating_q975": 1373.2809677026082,
            "rating_q025": 1290.6003723135966
        },
        "deepseek-v3.1-thinking": {
            "rating": 1330.6214293027033,
            "rating_q975": 1362.7713963348979,
            "rating_q025": 1298.4714622705087
        },
        "qwen3-30b-a3b-instruct-2507": {
            "rating": 1330.032294365656,
            "rating_q975": 1356.0922068396435,
            "rating_q025": 1303.9723818916686
        },
        "deepseek-r1": {
            "rating": 1327.0402795899108,
            "rating_q975": 1365.7536560099434,
            "rating_q025": 1288.3269031698783
        },
        "qwen3-235b-a22b": {
            "rating": 1320.9226059523598,
            "rating_q975": 1348.0979137307681,
            "rating_q025": 1293.7472981739515
        },
        "gemini-2.0-flash-lite-preview-02-05": {
            "rating": 1319.8718012296072,
            "rating_q975": 1350.5210740884606,
            "rating_q025": 1289.2225283707537
        },
        "claude-opus-4-20250514-thinking-16k": {
            "rating": 1310.4809974388222,
            "rating_q975": 1334.1319239164718,
            "rating_q025": 1286.8300709611726
        },
        "claude-haiku-4-5-20251001": {
            "rating": 1310.0165978767618,
            "rating_q975": 1356.1025263848874,
            "rating_q025": 1263.9306693686362
        },
        "o3-mini-high": {
            "rating": 1309.693969607083,
            "rating_q975": 1349.5718901345736,
            "rating_q025": 1269.8160490795926
        },
        "deepseek-v3-0324": {
            "rating": 1308.8577733199106,
            "rating_q975": 1329.2614507912797,
            "rating_q025": 1288.4540958485416
        },
        "o4-mini-2025-04-16": {
            "rating": 1308.82753075823,
            "rating_q975": 1329.376060550309,
            "rating_q025": 1288.2790009661512
        },
        "gpt-5-mini-high": {
            "rating": 1307.218040799704,
            "rating_q975": 1332.9864413203397,
            "rating_q025": 1281.4496402790685
        },
        "glm-4.5-air": {
            "rating": 1304.8257721205366,
            "rating_q975": 1330.6899929081244,
            "rating_q025": 1278.9615513329488
        },
        "qwen2.5-max": {
            "rating": 1303.7796294549678,
            "rating_q975": 1330.459912978047,
            "rating_q025": 1277.0993459318886
        },
        "claude-opus-4-20250514": {
            "rating": 1302.2580641617212,
            "rating_q975": 1322.5980462597117,
            "rating_q025": 1281.9180820637307
        },
        "gemma-3-27b-it": {
            "rating": 1301.477978469465,
            "rating_q975": 1322.5062832985836,
            "rating_q025": 1280.4496736403462
        },
        "grok-3-mini-beta": {
            "rating": 1301.0680681006163,
            "rating_q975": 1330.6196204755363,
            "rating_q025": 1271.5165157256963
        },
        "kimi-k2-0905-preview": {
            "rating": 1298.0281536414047,
            "rating_q975": 1335.6129183512214,
            "rating_q025": 1260.443388931588
        },
        "mistral-medium-2505": {
            "rating": 1295.6165108456453,
            "rating_q975": 1319.6773304446772,
            "rating_q025": 1271.5556912466134
        },
        "qwen3-coder-480b-a35b-instruct": {
            "rating": 1295.372758809862,
            "rating_q975": 1322.568004826138,
            "rating_q025": 1268.1775127935862
        },
        "gpt-4.1-mini-2025-04-14": {
            "rating": 1295.1678484512336,
            "rating_q975": 1317.4383958324051,
            "rating_q025": 1272.897301070062
        },
        "gemini-1.5-pro-002": {
            "rating": 1293.0733077952502,
            "rating_q975": 1314.5034005506975,
            "rating_q025": 1271.643215039803
        },
        "o1-preview": {
            "rating": 1287.702901026953,
            "rating_q975": 1315.0569222650804,
            "rating_q025": 1260.3488797888256
        },
        "qwen3-next-80b-a3b-thinking": {
            "rating": 1286.1920887141564,
            "rating_q975": 1321.6685242121073,
            "rating_q025": 1250.7156532162055
        },
        "command-a-03-2025": {
            "rating": 1286.0038566855899,
            "rating_q975": 1305.433404738774,
            "rating_q025": 1266.5743086324057
        },
        "claude-sonnet-4-20250514": {
            "rating": 1284.3038984812492,
            "rating_q975": 1305.7488262937584,
            "rating_q025": 1262.85897066874
        },
        "kimi-k2-0711-preview": {
            "rating": 1278.7491227477058,
            "rating_q975": 1304.082691896594,
            "rating_q025": 1253.4155535988175
        },
        "gpt-oss-120b": {
            "rating": 1276.2488031159162,
            "rating_q975": 1301.8669770199235,
            "rating_q025": 1250.6306292119089
        },
        "claude-sonnet-4-20250514-thinking-32k": {
            "rating": 1270.0914598057286,
            "rating_q975": 1294.0812317797656,
            "rating_q025": 1246.1016878316916
        },
        "qwq-32b": {
            "rating": 1266.5868202226313,
            "rating_q975": 1296.690180150507,
            "rating_q025": 1236.4834602947556
        },
        "mistral-small-2506": {
            "rating": 1266.4574368504288,
            "rating_q975": 1298.470293500562,
            "rating_q025": 1234.4445802002956
        },
        "step-3": {
            "rating": 1259.847883518877,
            "rating_q975": 1304.6368985146644,
            "rating_q025": 1215.0588685230898
        },
        "gemma-3n-e4b-it": {
            "rating": 1259.6120803080403,
            "rating_q975": 1287.1620549599945,
            "rating_q025": 1232.062105656086
        },
        "o3-mini": {
            "rating": 1259.1367737874043,
            "rating_q975": 1277.9689570389596,
            "rating_q025": 1240.304590535849
        },
        "qwen3-30b-a3b": {
            "rating": 1258.6084823241804,
            "rating_q975": 1286.3384654332103,
            "rating_q025": 1230.8784992151504
        },
        "gpt-5-nano-high": {
            "rating": 1250.723831757228,
            "rating_q975": 1292.9890819138282,
            "rating_q025": 1208.458581600628
        },
        "ring-flash-2.0": {
            "rating": 1249.7069935722725,
            "rating_q975": 1291.4380412674511,
            "rating_q025": 1207.9759458770939
        },
        "claude-3-7-sonnet-20250219-thinking-32k": {
            "rating": 1247.0079955740707,
            "rating_q975": 1270.137041489738,
            "rating_q025": 1223.8789496584034
        },
        "deepseek-v3": {
            "rating": 1245.5584972325032,
            "rating_q975": 1278.9525073711216,
            "rating_q025": 1212.1644870938849
        },
        "minimax-m1": {
            "rating": 1244.7422224731672,
            "rating_q975": 1269.8532900226637,
            "rating_q025": 1219.6311549236707
        },
        "gpt-oss-20b": {
            "rating": 1243.7441174594883,
            "rating_q975": 1283.8159453360518,
            "rating_q025": 1203.6722895829248
        },
        "glm-4-plus": {
            "rating": 1239.1122325148426,
            "rating_q975": 1268.7709513563102,
            "rating_q025": 1209.453513673375
        },
        "grok-2-2024-08-13": {
            "rating": 1235.3717400978544,
            "rating_q975": 1255.0999712521748,
            "rating_q025": 1215.643508943534
        },
        "gpt-4o-2024-05-13": {
            "rating": 1235.1406852594168,
            "rating_q975": 1249.7358947217326,
            "rating_q025": 1220.545475797101
        },
        "gemini-advanced-0514": {
            "rating": 1229.9106222465866,
            "rating_q975": 1248.1808340142502,
            "rating_q025": 1211.640410478923
        },
        "o1-mini": {
            "rating": 1222.6467900302914,
            "rating_q975": 1244.1192297981984,
            "rating_q025": 1201.1743502623845
        },
        "gemini-1.5-pro-001": {
            "rating": 1220.7819360761541,
            "rating_q975": 1237.0671310830216,
            "rating_q025": 1204.4967410692866
        },
        "gemini-1.5-flash-002": {
            "rating": 1219.7200665496073,
            "rating_q975": 1245.5483096472756,
            "rating_q025": 1193.891823451939
        },
        "gpt-4o-2024-08-06": {
            "rating": 1219.7058599876011,
            "rating_q975": 1242.4219525375927,
            "rating_q025": 1196.9897674376095
        },
        "llama-4-scout-17b-16e-instruct": {
            "rating": 1212.539000918713,
            "rating_q975": 1238.324375769225,
            "rating_q025": 1186.7536260682011
        },
        "athene-v2-chat": {
            "rating": 1205.8697486158799,
            "rating_q975": 1237.2386748055428,
            "rating_q025": 1174.500822426217
        },
        "llama-4-maverick-17b-128e-instruct": {
            "rating": 1205.1816565366198,
            "rating_q975": 1227.2990165843762,
            "rating_q025": 1183.0642964888634
        },
        "deepseek-v2.5": {
            "rating": 1204.862904996346,
            "rating_q975": 1235.5256350348907,
            "rating_q025": 1174.2001749578014
        },
        "mistral-large-2411": {
            "rating": 1201.1309408538987,
            "rating_q975": 1228.8654889668962,
            "rating_q025": 1173.396392740901
        },
        "mistral-small-3.1-24b-instruct-2503": {
            "rating": 1199.9343720736583,
            "rating_q975": 1225.403197526678,
            "rating_q025": 1174.4655466206386
        },
        "yi-lightning": {
            "rating": 1199.5620490777037,
            "rating_q975": 1227.977054825782,
            "rating_q025": 1171.1470433296254
        },
        "claude-3-5-sonnet-20241022": {
            "rating": 1198.7283730515505,
            "rating_q975": 1215.9913512224648,
            "rating_q025": 1181.4653948806363
        },
        "gpt-4o-mini-2024-07-18": {
            "rating": 1198.4706763115419,
            "rating_q975": 1216.7969508265317,
            "rating_q025": 1180.144401796552
        },
        "gemini-1.5-flash-001": {
            "rating": 1197.85988436132,
            "rating_q975": 1214.4835634264607,
            "rating_q025": 1181.2362052961792
        },
        "claude-3-5-sonnet-20240620": {
            "rating": 1197.751613869421,
            "rating_q975": 1214.4912331024798,
            "rating_q025": 1181.011994636362
        },
        "grok-2-mini-2024-08-13": {
            "rating": 1196.8062237644385,
            "rating_q975": 1218.03135104126,
            "rating_q025": 1175.581096487617
        },
        "amazon-nova-pro-v1.0": {
            "rating": 1196.373249526615,
            "rating_q975": 1226.7094221257964,
            "rating_q025": 1166.0370769274334
        },
        "qwen2.5-72b-instruct": {
            "rating": 1190.0242152740261,
            "rating_q975": 1215.6346894739352,
            "rating_q025": 1164.413741074117
        },
        "mistral-small-24b-instruct-2501": {
            "rating": 1189.0054469274678,
            "rating_q975": 1227.6467866026655,
            "rating_q025": 1150.36410725227
        },
        "claude-3-opus-20240229": {
            "rating": 1187.074024840333,
            "rating_q975": 1201.0671532241167,
            "rating_q025": 1173.0808964565495
        },
        "gpt-4-turbo-2024-04-09": {
            "rating": 1184.8861028308438,
            "rating_q975": 1200.7448107288574,
            "rating_q025": 1169.0273949328302
        },
        "llama-3.1-405b-instruct-fp8": {
            "rating": 1184.6087506658039,
            "rating_q975": 1204.2667510355777,
            "rating_q025": 1164.95075029603
        },
        "gpt-4-1106-preview": {
            "rating": 1179.8436707855822,
            "rating_q975": 1198.4114804514602,
            "rating_q025": 1161.2758611197041
        },
        "gemma-2-27b-it": {
            "rating": 1172.9204654653008,
            "rating_q975": 1189.6265082413645,
            "rating_q025": 1156.2144226892372
        },
        "gpt-4-0125-preview": {
            "rating": 1172.8589761531782,
            "rating_q975": 1191.235880433253,
            "rating_q025": 1154.4820718731035
        },
        "mistral-large-2407": {
            "rating": 1171.540541101344,
            "rating_q975": 1193.159465560235,
            "rating_q025": 1149.9216166424528
        },
        "llama-3.1-405b-instruct-bf16": {
            "rating": 1170.3142526133454,
            "rating_q975": 1193.873753674775,
            "rating_q025": 1146.754751551916
        },
        "claude-3-5-haiku-20241022": {
            "rating": 1170.058722483768,
            "rating_q975": 1188.625156265354,
            "rating_q025": 1151.492288702182
        },
        "command-r-08-2024": {
            "rating": 1169.139822164654,
            "rating_q975": 1218.1509584078565,
            "rating_q025": 1120.1286859214517
        },
        "amazon-nova-micro-v1.0": {
            "rating": 1158.546540550983,
            "rating_q975": 1193.7786165104123,
            "rating_q025": 1123.3144645915538
        },
        "gemini-1.5-flash-8b-001": {
            "rating": 1157.659306715672,
            "rating_q975": 1183.4479558694657,
            "rating_q025": 1131.8706575618785
        },
        "c4ai-aya-expanse-32b": {
            "rating": 1156.5332346564692,
            "rating_q975": 1185.3211618464459,
            "rating_q025": 1127.7453074664925
        },
        "athene-70b-0725": {
            "rating": 1154.791171965486,
            "rating_q975": 1184.6659634295247,
            "rating_q025": 1124.9163805014473
        },
        "amazon-nova-lite-v1.0": {
            "rating": 1152.6649320008496,
            "rating_q975": 1186.1023742210095,
            "rating_q025": 1119.2274897806897
        },
        "phi-4": {
            "rating": 1149.2870463991908,
            "rating_q975": 1181.237549963565,
            "rating_q025": 1117.3365428348166
        },
        "qwen-max-0919": {
            "rating": 1148.4906741223513,
            "rating_q975": 1182.3562022283666,
            "rating_q025": 1114.625146016336
        },
        "magistral-medium-2506": {
            "rating": 1145.1256139613665,
            "rating_q975": 1193.3609546955076,
            "rating_q025": 1096.8902732272254
        },
        "nemotron-4-340b-instruct": {
            "rating": 1144.984981324605,
            "rating_q975": 1169.7938780821178,
            "rating_q025": 1120.1760845670924
        },
        "llama-3.1-70b-instruct": {
            "rating": 1144.4408663285608,
            "rating_q975": 1164.9190480293441,
            "rating_q025": 1123.9626846277774
        },
        "command-r-plus": {
            "rating": 1137.7265184545013,
            "rating_q975": 1155.2003170292323,
            "rating_q025": 1120.2527198797702
        },
        "gemma-2-9b-it": {
            "rating": 1137.3570311660944,
            "rating_q975": 1156.0803733621187,
            "rating_q025": 1118.6336889700701
        },
        "llama-3.3-70b-instruct": {
            "rating": 1137.2161345709787,
            "rating_q975": 1157.3702828238322,
            "rating_q025": 1117.0619863181253
        },
        "claude-3-sonnet-20240229": {
            "rating": 1129.0495690402424,
            "rating_q975": 1145.7528611670064,
            "rating_q025": 1112.3462769134785
        },
        "claude-3-haiku-20240307": {
            "rating": 1111.7699974045006,
            "rating_q975": 1127.6312056061765,
            "rating_q025": 1095.9087892028247
        },
        "reka-flash-21b-20240226-online": {
            "rating": 1104.5854546081682,
            "rating_q975": 1137.3020721491923,
            "rating_q025": 1071.868837067144
        },
        "deepseek-coder-v2": {
            "rating": 1102.6553219312177,
            "rating_q975": 1132.7203300117674,
            "rating_q025": 1072.590313850668
        },
        "command-r": {
            "rating": 1097.1410449841555,
            "rating_q975": 1116.446064079606,
            "rating_q025": 1077.836025888705
        },
        "gpt-4-0314": {
            "rating": 1094.7521994011997,
            "rating_q975": 1124.2684209554054,
            "rating_q025": 1065.235977846994
        },
        "qwen2-72b-instruct": {
            "rating": 1082.9963849530327,
            "rating_q975": 1102.1067890688596,
            "rating_q025": 1063.8859808372058
        },
        "reka-flash-21b-20240226": {
            "rating": 1073.5469694526432,
            "rating_q975": 1097.8716605493448,
            "rating_q025": 1049.2222783559416
        },
        "gpt-4-0613": {
            "rating": 1061.1051627804811,
            "rating_q975": 1080.9457876240115,
            "rating_q025": 1041.2645379369508
        },
        "mixtral-8x22b-instruct-v0.1": {
            "rating": 1057.9901830559274,
            "rating_q975": 1077.2966604364635,
            "rating_q025": 1038.6837056753914
        },
        "llama-3.1-8b-instruct": {
            "rating": 1057.8053765004113,
            "rating_q975": 1079.4518831415423,
            "rating_q025": 1036.1588698592802
        },
        "gemma-2-2b-it": {
            "rating": 1056.1015395623822,
            "rating_q975": 1079.3761003512966,
            "rating_q025": 1032.8269787734678
        },
        "qwen1.5-72b-chat": {
            "rating": 1050.8105148511165,
            "rating_q975": 1076.746262155231,
            "rating_q025": 1024.874767547002
        },
        "qwen1.5-110b-chat": {
            "rating": 1047.6268192489574,
            "rating_q975": 1066.2934872760968,
            "rating_q025": 1028.960151221818
        },
        "glm-4-0520": {
            "rating": 1043.8701924608165,
            "rating_q975": 1078.3205273852057,
            "rating_q025": 1009.4198575364275
        },
        "mistral-medium": {
            "rating": 1032.2575743379502,
            "rating_q975": 1065.6490632073537,
            "rating_q025": 998.8660854685468
        },
        "gpt-3.5-turbo-0125": {
            "rating": 1024.616691327405,
            "rating_q975": 1044.303667547101,
            "rating_q025": 1004.9297151077092
        },
        "mistral-large-2402": {
            "rating": 1019.4176445183771,
            "rating_q975": 1039.931344531704,
            "rating_q025": 998.90394450505
        },
        "llama-3-70b-instruct": {
            "rating": 1019.2293805714434,
            "rating_q975": 1033.4261601785367,
            "rating_q025": 1005.0326009643499
        },
        "qwen1.5-32b-chat": {
            "rating": 1009.5369869295073,
            "rating_q975": 1038.587368696024,
            "rating_q025": 980.4866051629907
        },
        "yi-1.5-34b-chat": {
            "rating": 1007.8695545576769,
            "rating_q975": 1030.2272681600937,
            "rating_q025": 985.5118409552603
        },
        "llama-3-8b-instruct": {
            "rating": 1006.4764020808616,
            "rating_q975": 1022.8574987865619,
            "rating_q025": 990.0953053751613
        },
        "gemma-1.1-7b-it": {
            "rating": 995.7283681772009,
            "rating_q975": 1018.0758156191278,
            "rating_q025": 973.380920735274
        },
        "dbrx-instruct-preview": {
            "rating": 995.2008975890807,
            "rating_q975": 1024.275536867402,
            "rating_q025": 966.1262583107593
        },
        "mixtral-8x7b-instruct-v0.1": {
            "rating": 975.5784341652734,
            "rating_q975": 998.2863840569792,
            "rating_q025": 952.8704842735676
        },
        "llama-2-70b-chat": {
            "rating": 971.7798876874633,
            "rating_q975": 1009.3225048458368,
            "rating_q025": 934.2372705290899
        },
        "llama-2-13b-chat": {
            "rating": 964.6757102824411,
            "rating_q975": 1011.3195013330227,
            "rating_q025": 918.0319192318594
        },
        "phi-3-medium-4k-instruct": {
            "rating": 962.2982533362363,
            "rating_q975": 984.9857576254832,
            "rating_q025": 939.6107490469893
        },
        "yi-34b-chat": {
            "rating": 961.9292588670544,
            "rating_q975": 1000.7866396760471,
            "rating_q025": 923.0718780580617
        },
        "snowflake-arctic-instruct": {
            "rating": 946.9493074113929,
            "rating_q975": 973.7993092417423,
            "rating_q025": 920.0993055810434
        },
        "phi-3-mini-4k-instruct": {
            "rating": 916.0901566539833,
            "rating_q975": 937.9978992069808,
            "rating_q025": 894.1824141009857
        },
        "phi-3-small-8k-instruct": {
            "rating": 907.9425806632637,
            "rating_q975": 930.5817877230617,
            "rating_q025": 885.3033736034657
        },
        "gemma-1.1-2b-it": {
            "rating": 902.516082599104,
            "rating_q975": 932.7427937502035,
            "rating_q025": 872.2893714480045
        },
        "phi-3-mini-4k-instruct-june-2024": {
            "rating": 888.430399921274,
            "rating_q975": 926.1767653214267,
            "rating_q025": 850.6840345211212
        },
        "phi-3-mini-128k-instruct": {
            "rating": 875.9800015254169,
            "rating_q975": 911.1167840732754,
            "rating_q025": 840.8432189775584
        }
    },
    "long_user": {
        "claude-sonnet-4-5-20250929-thinking-32k": {
            "rating": 1470.7422998702764,
            "rating_q975": 1482.8462554737766,
            "rating_q025": 1458.6383442667761
        },
        "claude-opus-4-1-20250805-thinking-16k": {
            "rating": 1456.751109340319,
            "rating_q975": 1465.305348043258,
            "rating_q025": 1448.1968706373802
        },
        "gemini-2.5-pro": {
            "rating": 1455.5484795019756,
            "rating_q975": 1462.2686429267526,
            "rating_q025": 1448.8283160771987
        },
        "claude-sonnet-4-5-20250929": {
            "rating": 1452.596211395477,
            "rating_q975": 1468.2756836235963,
            "rating_q025": 1436.9167391673577
        },
        "qwen3-max-preview": {
            "rating": 1443.4116471901464,
            "rating_q975": 1452.2977365332256,
            "rating_q025": 1434.5255578470671
        },
        "claude-opus-4-1-20250805": {
            "rating": 1441.5901476819236,
            "rating_q975": 1449.2821225368118,
            "rating_q025": 1433.8981728270353
        },
        "grok-3-preview-02-24": {
            "rating": 1439.8834148539415,
            "rating_q975": 1448.4996384407036,
            "rating_q025": 1431.2671912671794
        },
        "claude-haiku-4-5-20251001": {
            "rating": 1432.3561452488602,
            "rating_q975": 1444.978010313528,
            "rating_q025": 1419.7342801841924
        },
        "glm-4.6": {
            "rating": 1429.5747946903255,
            "rating_q975": 1442.1935570437383,
            "rating_q025": 1416.9560323369126
        },
        "qwen3-235b-a22b-instruct-2507": {
            "rating": 1426.0927989083561,
            "rating_q975": 1433.776918347501,
            "rating_q025": 1418.4086794692114
        },
        "gemini-2.5-flash": {
            "rating": 1424.4029520975673,
            "rating_q975": 1431.0520504576164,
            "rating_q025": 1417.7538537375183
        },
        "deepseek-v3.1-thinking": {
            "rating": 1423.6289518086355,
            "rating_q975": 1435.794345829967,
            "rating_q025": 1411.4635577873041
        },
        "qwen3-vl-235b-a22b-instruct": {
            "rating": 1423.0751933836664,
            "rating_q975": 1436.7518135136208,
            "rating_q025": 1409.398573253712
        },
        "grok-4-fast": {
            "rating": 1421.5239873471246,
            "rating_q975": 1436.928856762798,
            "rating_q025": 1406.1191179314512
        },
        "claude-opus-4-20250514-thinking-16k": {
            "rating": 1419.5004162164755,
            "rating_q975": 1427.4408330038643,
            "rating_q025": 1411.5599994290867
        },
        "deepseek-v3.1-terminus-thinking": {
            "rating": 1418.061027410332,
            "rating_q975": 1440.804575692003,
            "rating_q025": 1395.3174791286608
        },
        "qwen3-max-2025-09-23": {
            "rating": 1417.5447364248585,
            "rating_q975": 1430.5359421289666,
            "rating_q025": 1404.5535307207504
        },
        "glm-4.5": {
            "rating": 1417.5440910572631,
            "rating_q975": 1426.44226010402,
            "rating_q025": 1408.6459220105062
        },
        "chatgpt-4o-latest-20250326": {
            "rating": 1414.7705080647702,
            "rating_q975": 1421.8789127305208,
            "rating_q025": 1407.6621033990195
        },
        "grok-4-0709": {
            "rating": 1414.4728188622066,
            "rating_q975": 1422.0994984636964,
            "rating_q025": 1406.8461392607169
        },
        "gemini-2.5-flash-preview-09-2025": {
            "rating": 1412.5964819145386,
            "rating_q975": 1423.3632008656607,
            "rating_q025": 1401.8297629634164
        },
        "deepseek-v3.2-exp-thinking": {
            "rating": 1411.5671118637938,
            "rating_q975": 1424.7640605474899,
            "rating_q025": 1398.3701631800977
        },
        "qwen3-next-80b-a3b-instruct": {
            "rating": 1408.520289022788,
            "rating_q975": 1418.0090238966716,
            "rating_q025": 1399.0315541489042
        },
        "mistral-medium-2508": {
            "rating": 1407.956932118711,
            "rating_q975": 1416.0241145277164,
            "rating_q025": 1399.8897497097055
        },
        "gpt-4.5-preview-2025-02-27": {
            "rating": 1407.8312992468739,
            "rating_q975": 1421.3546182656141,
            "rating_q025": 1394.3079802281336
        },
        "deepseek-v3.1": {
            "rating": 1406.1146473358413,
            "rating_q975": 1416.7734704982454,
            "rating_q025": 1395.4558241734371
        },
        "gpt-5-chat": {
            "rating": 1403.59852992876,
            "rating_q975": 1411.9213162228414,
            "rating_q025": 1395.2757436346785
        },
        "qwen3-235b-a22b-thinking-2507": {
            "rating": 1401.9839175957939,
            "rating_q975": 1416.311377240078,
            "rating_q025": 1387.6564579515098
        },
        "claude-opus-4-20250514": {
            "rating": 1400.331235154444,
            "rating_q975": 1407.6860708804818,
            "rating_q025": 1392.976399428406
        },
        "deepseek-v3.1-terminus": {
            "rating": 1398.0660935841538,
            "rating_q975": 1418.1817548956815,
            "rating_q025": 1377.9504322726261
        },
        "claude-sonnet-4-20250514-thinking-32k": {
            "rating": 1397.1539659674052,
            "rating_q975": 1405.0510883258162,
            "rating_q025": 1389.2568436089941
        },
        "qwen3-vl-235b-a22b-thinking": {
            "rating": 1393.662660801092,
            "rating_q975": 1407.6529087765448,
            "rating_q025": 1379.6724128256392
        },
        "longcat-flash-chat": {
            "rating": 1393.4310921600634,
            "rating_q975": 1405.7034243250807,
            "rating_q025": 1381.158759995046
        },
        "deepseek-r1-0528": {
            "rating": 1393.2923090742984,
            "rating_q975": 1403.9521714196399,
            "rating_q025": 1382.632446728957
        },
        "gpt-5-high": {
            "rating": 1391.5895565752862,
            "rating_q975": 1399.9975327939233,
            "rating_q025": 1383.1815803566492
        },
        "qwen3-235b-a22b-no-thinking": {
            "rating": 1387.8202353492893,
            "rating_q975": 1395.4867574095106,
            "rating_q025": 1380.153713289068
        },
        "gpt-4.1-2025-04-14": {
            "rating": 1386.5988962363592,
            "rating_q975": 1393.528054716776,
            "rating_q025": 1379.6697377559424
        },
        "gemini-2.5-flash-lite-preview-09-2025-no-thinking": {
            "rating": 1384.401415718731,
            "rating_q975": 1395.157951093983,
            "rating_q025": 1373.644880343479
        },
        "hunyuan-t1-20250711": {
            "rating": 1382.887322027822,
            "rating_q975": 1402.6683692228662,
            "rating_q025": 1363.1062748327777
        },
        "qwen3-30b-a3b-instruct-2507": {
            "rating": 1381.8067134885803,
            "rating_q975": 1390.6512014606042,
            "rating_q025": 1372.9622255165564
        },
        "gemini-2.5-flash-lite-preview-06-17-thinking": {
            "rating": 1379.24775569879,
            "rating_q975": 1387.3018663254127,
            "rating_q025": 1371.193645072167
        },
        "claude-sonnet-4-20250514": {
            "rating": 1379.0575564897936,
            "rating_q975": 1386.5758673051332,
            "rating_q025": 1371.539245674454
        },
        "qwen3-coder-480b-a35b-instruct": {
            "rating": 1378.6677619677566,
            "rating_q975": 1387.7075031865447,
            "rating_q025": 1369.6280207489685
        },
        "o1-2024-12-17": {
            "rating": 1378.4935516988355,
            "rating_q975": 1388.1802235801667,
            "rating_q025": 1368.8068798175043
        },
        "o3-2025-04-16": {
            "rating": 1375.6296429863773,
            "rating_q975": 1382.2774089109034,
            "rating_q025": 1368.9818770618513
        },
        "grok-3-mini-high": {
            "rating": 1375.598274995104,
            "rating_q975": 1386.0027592441506,
            "rating_q025": 1365.1937907460574
        },
        "mai-1-preview": {
            "rating": 1373.096092154139,
            "rating_q975": 1383.2402329666832,
            "rating_q025": 1362.9519513415946
        },
        "claude-3-7-sonnet-20250219-thinking-32k": {
            "rating": 1372.5764060377267,
            "rating_q975": 1380.5668122536254,
            "rating_q025": 1364.585999821828
        },
        "hunyuan-turbos-20250416": {
            "rating": 1367.635183855344,
            "rating_q975": 1382.2865000061722,
            "rating_q025": 1352.9838677045157
        },
        "glm-4.5-air": {
            "rating": 1367.2104245486255,
            "rating_q975": 1375.495401691922,
            "rating_q025": 1358.925447405329
        },
        "gpt-5-mini-high": {
            "rating": 1362.0148473766744,
            "rating_q975": 1371.062321659781,
            "rating_q025": 1352.9673730935679
        },
        "mistral-medium-2505": {
            "rating": 1361.3092390987404,
            "rating_q975": 1369.4428327741728,
            "rating_q025": 1353.175645423308
        },
        "grok-3-mini-beta": {
            "rating": 1361.070291609823,
            "rating_q975": 1370.4072741359305,
            "rating_q025": 1351.7333090837155
        },
        "qwen2.5-max": {
            "rating": 1358.2216527306996,
            "rating_q975": 1366.7013181571292,
            "rating_q025": 1349.74198730427
        },
        "kimi-k2-0905-preview": {
            "rating": 1356.5254237471147,
            "rating_q975": 1369.0750469469515,
            "rating_q025": 1343.975800547278
        },
        "deepseek-r1": {
            "rating": 1355.8507315584516,
            "rating_q975": 1367.6136320913154,
            "rating_q025": 1344.0878310255878
        },
        "qwen3-235b-a22b": {
            "rating": 1355.242299697307,
            "rating_q975": 1364.106269838722,
            "rating_q025": 1346.3783295558922
        },
        "qwen3-next-80b-a3b-thinking": {
            "rating": 1354.3398379614132,
            "rating_q975": 1365.7139368977835,
            "rating_q025": 1342.965739025043
        },
        "deepseek-v3-0324": {
            "rating": 1353.8737259464594,
            "rating_q975": 1360.8178265862086,
            "rating_q025": 1346.9296253067102
        },
        "step-1o-turbo-202506": {
            "rating": 1352.4138783921921,
            "rating_q975": 1368.304897846402,
            "rating_q025": 1336.5228589379824
        },
        "gpt-4.1-mini-2025-04-14": {
            "rating": 1346.0175004078164,
            "rating_q975": 1353.6902556107475,
            "rating_q025": 1338.3447452048854
        },
        "o1-preview": {
            "rating": 1344.6123129971484,
            "rating_q975": 1354.0936736154085,
            "rating_q025": 1335.1309523788882
        },
        "deepseek-v3": {
            "rating": 1343.7117459648468,
            "rating_q975": 1354.0097686415263,
            "rating_q025": 1333.4137232881674
        },
        "o3-mini-high": {
            "rating": 1343.5064866618043,
            "rating_q975": 1355.5995903284293,
            "rating_q025": 1331.4133829951793
        },
        "hunyuan-large-2025-02-10": {
            "rating": 1342.1217143819315,
            "rating_q975": 1370.5349415631772,
            "rating_q025": 1313.7084872006858
        },
        "amazon-nova-experimental-chat-10-09": {
            "rating": 1338.5161323594975,
            "rating_q975": 1355.0832348184601,
            "rating_q025": 1321.949029900535
        },
        "gemma-3-27b-it": {
            "rating": 1336.1100093514112,
            "rating_q975": 1343.5768263001096,
            "rating_q025": 1328.6431924027129
        },
        "command-a-03-2025": {
            "rating": 1335.4656419395128,
            "rating_q975": 1342.0755455238698,
            "rating_q025": 1328.8557383551558
        },
        "minimax-m1": {
            "rating": 1334.2999996221015,
            "rating_q975": 1341.8670429555655,
            "rating_q025": 1326.7329562886375
        },
        "mistral-small-2506": {
            "rating": 1330.551741444571,
            "rating_q975": 1340.7502307761283,
            "rating_q025": 1320.3532521130137
        },
        "step-3": {
            "rating": 1329.9246810607046,
            "rating_q975": 1346.3454545036652,
            "rating_q025": 1313.503907617744
        },
        "qwen3-32b": {
            "rating": 1329.717097025647,
            "rating_q975": 1354.290200230615,
            "rating_q025": 1305.143993820679
        },
        "o3-mini": {
            "rating": 1329.4863263020557,
            "rating_q975": 1335.9845765103162,
            "rating_q025": 1322.9880760937951
        },
        "kimi-k2-0711-preview": {
            "rating": 1329.4007606856703,
            "rating_q975": 1337.9226832068964,
            "rating_q025": 1320.8788381644442
        },
        "ling-flash-2.0": {
            "rating": 1327.2261170628174,
            "rating_q975": 1343.5820774581423,
            "rating_q025": 1310.8701566674924
        },
        "qwen-plus-0125": {
            "rating": 1325.2519935443952,
            "rating_q975": 1346.3931254318788,
            "rating_q025": 1304.1108616569115
        },
        "ring-flash-2.0": {
            "rating": 1323.2991890419642,
            "rating_q975": 1339.3936724694997,
            "rating_q025": 1307.2047056144286
        },
        "gemini-2.0-flash-lite-preview-02-05": {
            "rating": 1321.6133968894078,
            "rating_q975": 1331.8516195462662,
            "rating_q025": 1311.3751742325494
        },
        "hunyuan-turbos-20250226": {
            "rating": 1321.5908817653276,
            "rating_q975": 1354.244643545851,
            "rating_q025": 1288.9371199848042
        },
        "o1-mini": {
            "rating": 1320.8762224569396,
            "rating_q975": 1328.1853136393083,
            "rating_q025": 1313.5671312745708
        },
        "gemma-3-12b-it": {
            "rating": 1320.3000286260285,
            "rating_q975": 1348.8375870288226,
            "rating_q025": 1291.7624702232345
        },
        "o4-mini-2025-04-16": {
            "rating": 1317.7080848378687,
            "rating_q975": 1324.8085471863233,
            "rating_q025": 1310.607622489414
        },
        "glm-4-plus-0111": {
            "rating": 1316.6812287696634,
            "rating_q975": 1337.023968180342,
            "rating_q025": 1296.3384893589848
        },
        "nvidia-llama-3.3-nemotron-super-49b-v1.5": {
            "rating": 1316.1516024478044,
            "rating_q975": 1337.7941963237686,
            "rating_q025": 1294.5090085718402
        },
        "qwen3-30b-a3b": {
            "rating": 1315.3711714896249,
            "rating_q975": 1324.357127938185,
            "rating_q025": 1306.3852150410648
        },
        "gpt-oss-120b": {
            "rating": 1314.886503266685,
            "rating_q975": 1323.4125232765202,
            "rating_q025": 1306.3604832568496
        },
        "gpt-5-nano-high": {
            "rating": 1313.3029359390393,
            "rating_q975": 1328.2191041629026,
            "rating_q025": 1298.3867677151761
        },
        "claude-3-5-sonnet-20241022": {
            "rating": 1312.7794964531772,
            "rating_q975": 1318.1554951732226,
            "rating_q025": 1307.4034977331319
        },
        "hunyuan-turbo-0110": {
            "rating": 1311.3202195108179,
            "rating_q975": 1341.3438491243276,
            "rating_q025": 1281.2965898973082
        },
        "qwq-32b": {
            "rating": 1310.8319828359547,
            "rating_q975": 1320.0800861237485,
            "rating_q025": 1301.583879548161
        },
        "gemini-1.5-pro-002": {
            "rating": 1308.8160678339527,
            "rating_q975": 1315.6573154006621,
            "rating_q025": 1301.9748202672433
        },
        "step-2-16k-exp-202412": {
            "rating": 1307.0717544816102,
            "rating_q975": 1328.2902891304525,
            "rating_q025": 1285.853219832768
        },
        "glm-4.5v": {
            "rating": 1305.6621986116643,
            "rating_q975": 1324.203673835325,
            "rating_q025": 1287.1207233880036
        },
        "mistral-small-3.1-24b-instruct-2503": {
            "rating": 1304.3544747062847,
            "rating_q975": 1312.35691157311,
            "rating_q025": 1296.3520378394594
        },
        "llama-3.1-nemotron-ultra-253b-v1": {
            "rating": 1302.4088611328286,
            "rating_q975": 1332.510117929326,
            "rating_q025": 1272.3076043363312
        },
        "deepseek-v2.5-1210": {
            "rating": 1301.0220222775565,
            "rating_q975": 1318.210783256604,
            "rating_q025": 1283.8332612985091
        },
        "hunyuan-standard-2025-02-10": {
            "rating": 1300.8260561375027,
            "rating_q975": 1328.0235015697986,
            "rating_q025": 1273.628610705207
        },
        "llama-3.3-nemotron-49b-super-v1": {
            "rating": 1299.6966845099673,
            "rating_q975": 1330.5173646680837,
            "rating_q025": 1268.876004351851
        },
        "yi-lightning": {
            "rating": 1297.8234477219903,
            "rating_q975": 1308.1593556660882,
            "rating_q025": 1287.4875397778924
        },
        "magistral-medium-2506": {
            "rating": 1296.5986027395038,
            "rating_q975": 1309.1064349302123,
            "rating_q025": 1284.0907705487953
        },
        "qwen2.5-plus-1127": {
            "rating": 1292.0666917639046,
            "rating_q975": 1306.108933801213,
            "rating_q025": 1278.0244497265962
        },
        "gemini-1.5-pro-001": {
            "rating": 1291.4405653944486,
            "rating_q975": 1299.6004605690277,
            "rating_q025": 1283.2806702198695
        },
        "athene-v2-chat": {
            "rating": 1290.214293840847,
            "rating_q975": 1299.6163290518705,
            "rating_q025": 1280.8122586298234
        },
        "gpt-4o-2024-05-13": {
            "rating": 1289.2299174139162,
            "rating_q975": 1295.8612789048902,
            "rating_q025": 1282.598555922942
        },
        "qwen-max-0919": {
            "rating": 1288.9846782945783,
            "rating_q975": 1300.6629350523756,
            "rating_q025": 1277.306421536781
        },
        "gpt-4o-mini-2024-07-18": {
            "rating": 1288.7966692139448,
            "rating_q975": 1295.5294349949022,
            "rating_q025": 1282.0639034329874
        },
        "glm-4-plus": {
            "rating": 1286.5574526939404,
            "rating_q975": 1296.4217019374557,
            "rating_q025": 1276.693203450425
        },
        "gpt-4.1-nano-2025-04-14": {
            "rating": 1286.53530155938,
            "rating_q975": 1306.6445673790622,
            "rating_q025": 1266.426035739698
        },
        "hunyuan-large-vision": {
            "rating": 1284.7183269539069,
            "rating_q975": 1304.6464331705497,
            "rating_q025": 1264.790220737264
        },
        "gemini-1.5-flash-002": {
            "rating": 1284.6609692844072,
            "rating_q975": 1292.814297839525,
            "rating_q025": 1276.5076407292895
        },
        "llama-4-maverick-17b-128e-instruct": {
            "rating": 1284.5954462313218,
            "rating_q975": 1292.197766639037,
            "rating_q025": 1276.9931258236068
        },
        "gpt-4o-2024-08-06": {
            "rating": 1284.0719071362173,
            "rating_q975": 1292.2294170178814,
            "rating_q025": 1275.9143972545533
        },
        "qwen2.5-72b-instruct": {
            "rating": 1282.4204506859492,
            "rating_q975": 1290.2289865706723,
            "rating_q025": 1274.611914801226
        },
        "gemma-3n-e4b-it": {
            "rating": 1280.8780377154822,
            "rating_q975": 1291.792261010831,
            "rating_q025": 1269.9638144201333
        },
        "gemma-3-4b-it": {
            "rating": 1277.098480898694,
            "rating_q975": 1304.5943981554688,
            "rating_q025": 1249.6025636419195
        },
        "grok-2-2024-08-13": {
            "rating": 1276.9455220668326,
            "rating_q975": 1283.8999565288536,
            "rating_q025": 1269.9910876048116
        },
        "claude-3-5-sonnet-20240620": {
            "rating": 1275.787182906774,
            "rating_q975": 1283.2562515414884,
            "rating_q025": 1268.3181142720596
        },
        "deepseek-v2.5": {
            "rating": 1273.7795015850397,
            "rating_q975": 1283.7229931533723,
            "rating_q025": 1263.8360100167072
        },
        "llama-4-scout-17b-16e-instruct": {
            "rating": 1272.784120153247,
            "rating_q975": 1281.3212821609386,
            "rating_q025": 1264.2469581455553
        },
        "grok-2-mini-2024-08-13": {
            "rating": 1267.021066423444,
            "rating_q975": 1274.451468935862,
            "rating_q025": 1259.5906639110258
        },
        "llama-3.1-405b-instruct-bf16": {
            "rating": 1266.2526052212165,
            "rating_q975": 1273.9883990777364,
            "rating_q025": 1258.5168113646967
        },
        "mistral-large-2411": {
            "rating": 1262.3944056836929,
            "rating_q975": 1271.7231318595027,
            "rating_q025": 1253.065679507883
        },
        "claude-3-5-haiku-20241022": {
            "rating": 1260.57307789497,
            "rating_q975": 1266.5896513591676,
            "rating_q025": 1254.5565044307725
        },
        "llama-3.1-405b-instruct-fp8": {
            "rating": 1260.1619801763654,
            "rating_q975": 1267.4521900546226,
            "rating_q025": 1252.8717702981082
        },
        "claude-3-opus-20240229": {
            "rating": 1259.8283559483566,
            "rating_q975": 1265.9169001732607,
            "rating_q025": 1253.7398117234525
        },
        "mistral-large-2407": {
            "rating": 1258.3148893347166,
            "rating_q975": 1266.7342225626185,
            "rating_q025": 1249.8955561068146
        },
        "gpt-oss-20b": {
            "rating": 1257.4471711972096,
            "rating_q975": 1271.0003371065798,
            "rating_q025": 1243.8940052878395
        },
        "llama-3.3-70b-instruct": {
            "rating": 1257.438565677964,
            "rating_q975": 1263.8942789604437,
            "rating_q025": 1250.9828523954845
        },
        "amazon-nova-pro-v1.0": {
            "rating": 1256.230836712806,
            "rating_q975": 1265.8352960663196,
            "rating_q025": 1246.6263773592923
        },
        "gemini-advanced-0514": {
            "rating": 1254.2055058749174,
            "rating_q975": 1264.4634466722669,
            "rating_q025": 1243.947565077568
        },
        "gpt-4-turbo-2024-04-09": {
            "rating": 1253.855817286968,
            "rating_q975": 1261.5177355807232,
            "rating_q025": 1246.1938989932128
        },
        "gemini-1.5-flash-001": {
            "rating": 1252.4747804240228,
            "rating_q975": 1260.9638244969212,
            "rating_q025": 1243.9857363511244
        },
        "qwen2.5-coder-32b-instruct": {
            "rating": 1250.5285771759786,
            "rating_q975": 1269.2313575484727,
            "rating_q025": 1231.8257968034845
        },
        "mistral-small-24b-instruct-2501": {
            "rating": 1247.323593108767,
            "rating_q975": 1260.7259685311503,
            "rating_q025": 1233.9212176863837
        },
        "gpt-4-0125-preview": {
            "rating": 1244.3078278484647,
            "rating_q975": 1252.6763978623164,
            "rating_q025": 1235.939257834613
        },
        "llama-3.1-70b-instruct": {
            "rating": 1241.6319156348059,
            "rating_q975": 1248.9834656122118,
            "rating_q025": 1234.2803656574
        },
        "llama-3.1-nemotron-70b-instruct": {
            "rating": 1238.9567901815371,
            "rating_q975": 1256.3584067285262,
            "rating_q025": 1221.555173634548
        },
        "gpt-4-1106-preview": {
            "rating": 1236.1552153823673,
            "rating_q975": 1244.421656815528,
            "rating_q025": 1227.8887739492066
        },
        "amazon-nova-lite-v1.0": {
            "rating": 1234.6325199964106,
            "rating_q975": 1245.2215887594489,
            "rating_q025": 1224.0434512333723
        },
        "athene-70b-0725": {
            "rating": 1232.1438877780406,
            "rating_q975": 1244.4330331113845,
            "rating_q025": 1219.8547424446967
        },
        "gemma-2-27b-it": {
            "rating": 1231.3636318282684,
            "rating_q975": 1237.965105351758,
            "rating_q025": 1224.7621583047787
        },
        "command-r-plus-08-2024": {
            "rating": 1230.6804600180544,
            "rating_q975": 1245.9301682817772,
            "rating_q025": 1215.4307517543316
        },
        "c4ai-aya-expanse-32b": {
            "rating": 1228.4931948306657,
            "rating_q975": 1237.6493654200092,
            "rating_q025": 1219.3370242413223
        },
        "gemma-2-9b-it-simpo": {
            "rating": 1226.8574243964897,
            "rating_q975": 1245.9952523759011,
            "rating_q025": 1207.7195964170783
        },
        "llama-3.1-tulu-3-70b": {
            "rating": 1225.4615093060427,
            "rating_q975": 1250.396199262593,
            "rating_q025": 1200.5268193494924
        },
        "hunyuan-standard-256k": {
            "rating": 1225.1608225598852,
            "rating_q975": 1251.7683478396245,
            "rating_q025": 1198.553297280146
        },
        "nemotron-4-340b-instruct": {
            "rating": 1223.7781905785241,
            "rating_q975": 1237.0256265923174,
            "rating_q025": 1210.5307545647308
        },
        "reka-core-20240904": {
            "rating": 1221.1671913758814,
            "rating_q975": 1239.2988338531613,
            "rating_q025": 1203.0355488986015
        },
        "deepseek-coder-v2": {
            "rating": 1219.457333273064,
            "rating_q975": 1233.3207088995052,
            "rating_q025": 1205.5939576466228
        },
        "gemini-1.5-flash-8b-001": {
            "rating": 1219.2040563603605,
            "rating_q975": 1227.4000054167736,
            "rating_q025": 1211.0081073039473
        },
        "phi-4": {
            "rating": 1218.0602025286998,
            "rating_q975": 1228.684622455715,
            "rating_q025": 1207.4357826016847
        },
        "ministral-8b-2410": {
            "rating": 1212.421536991611,
            "rating_q975": 1232.6023043548964,
            "rating_q025": 1192.2407696283256
        },
        "claude-3-sonnet-20240229": {
            "rating": 1211.3636064036696,
            "rating_q975": 1219.8843424861798,
            "rating_q025": 1202.8428703211594
        },
        "jamba-1.5-large": {
            "rating": 1207.3831997441184,
            "rating_q975": 1224.836612622343,
            "rating_q025": 1189.929786865894
        },
        "amazon-nova-micro-v1.0": {
            "rating": 1206.4538621347467,
            "rating_q975": 1217.5524452734091,
            "rating_q025": 1195.3552789960843
        },
        "glm-4-0520": {
            "rating": 1205.8468135770327,
            "rating_q975": 1222.486710739302,
            "rating_q025": 1189.2069164147633
        },
        "llama-3.1-nemotron-51b-instruct": {
            "rating": 1205.4560594813265,
            "rating_q975": 1228.642290087197,
            "rating_q025": 1182.2698288754561
        },
        "command-r-plus": {
            "rating": 1202.8682189893043,
            "rating_q975": 1211.7117637221056,
            "rating_q025": 1194.024674256503
        },
        "command-r-08-2024": {
            "rating": 1198.6922469607007,
            "rating_q975": 1213.440506734692,
            "rating_q025": 1183.9439871867094
        },
        "gemma-2-9b-it": {
            "rating": 1197.7708786419205,
            "rating_q975": 1205.2936024329676,
            "rating_q025": 1190.2481548508733
        },
        "olmo-2-0325-32b-instruct": {
            "rating": 1197.6411290872766,
            "rating_q975": 1232.5387001369113,
            "rating_q025": 1162.7435580376418
        },
        "qwen2-72b-instruct": {
            "rating": 1193.1135993766904,
            "rating_q975": 1203.1526872187153,
            "rating_q025": 1183.0745115346656
        },
        "c4ai-aya-expanse-8b": {
            "rating": 1193.0289131920185,
            "rating_q975": 1207.6594427754787,
            "rating_q025": 1178.3983836085583
        },
        "reka-flash-20240904": {
            "rating": 1192.0148054041783,
            "rating_q975": 1209.6684531263347,
            "rating_q025": 1174.361157682022
        },
        "gpt-4-0314": {
            "rating": 1190.9702491320372,
            "rating_q975": 1202.4640058646075,
            "rating_q025": 1179.476492399467
        },
        "claude-3-haiku-20240307": {
            "rating": 1190.7187816370583,
            "rating_q975": 1198.1629768552825,
            "rating_q025": 1183.2745864188341
        },
        "gpt-4-0613": {
            "rating": 1188.0952603333028,
            "rating_q975": 1197.3149328461263,
            "rating_q025": 1178.8755878204793
        },
        "llama-3.1-8b-instruct": {
            "rating": 1182.2912893462283,
            "rating_q975": 1190.0579033480947,
            "rating_q025": 1174.5246753443619
        },
        "llama-3.1-tulu-3-8b": {
            "rating": 1181.5212376822228,
            "rating_q975": 1207.432533152056,
            "rating_q025": 1155.6099422123896
        },
        "llama-3-70b-instruct": {
            "rating": 1174.744172082192,
            "rating_q975": 1182.194617833066,
            "rating_q025": 1167.293726331318
        },
        "mistral-large-2402": {
            "rating": 1173.4020076633522,
            "rating_q975": 1183.1866459383798,
            "rating_q025": 1163.6173693883245
        },
        "qwq-32b-preview": {
            "rating": 1166.8280599849427,
            "rating_q975": 1193.2255670328263,
            "rating_q025": 1140.430552937059
        },
        "granite-3.1-8b-instruct": {
            "rating": 1163.0908868014853,
            "rating_q975": 1190.3095894844764,
            "rating_q025": 1135.8721841184943
        },
        "command-r": {
            "rating": 1158.482092671377,
            "rating_q975": 1168.3137279170064,
            "rating_q025": 1148.6504574257474
        },
        "qwen1.5-110b-chat": {
            "rating": 1157.8528830530458,
            "rating_q975": 1169.573918897585,
            "rating_q025": 1146.1318472085068
        },
        "qwen1.5-72b-chat": {
            "rating": 1157.4244433648516,
            "rating_q975": 1168.8805724583067,
            "rating_q025": 1145.9683142713966
        },
        "jamba-1.5-mini": {
            "rating": 1156.9916442669619,
            "rating_q975": 1174.5220887053679,
            "rating_q025": 1139.461199828556
        },
        "granite-3.1-2b-instruct": {
            "rating": 1156.166939116964,
            "rating_q975": 1182.5197018304177,
            "rating_q025": 1129.8141764035101
        },
        "mistral-medium": {
            "rating": 1155.247909021755,
            "rating_q975": 1168.0289656063853,
            "rating_q025": 1142.4668524371248
        },
        "internlm2_5-20b-chat": {
            "rating": 1150.5463376769628,
            "rating_q975": 1166.817004225056,
            "rating_q025": 1134.2756711288696
        },
        "qwen1.5-32b-chat": {
            "rating": 1146.9992936830358,
            "rating_q975": 1159.4950109742679,
            "rating_q025": 1134.5035763918038
        },
        "mixtral-8x22b-instruct-v0.1": {
            "rating": 1144.0216914053053,
            "rating_q975": 1153.6444400070304,
            "rating_q025": 1134.3989428035802
        },
        "yi-1.5-34b-chat": {
            "rating": 1143.9402520138706,
            "rating_q975": 1157.2012197557226,
            "rating_q025": 1130.6792842720185
        },
        "reka-flash-21b-20240226": {
            "rating": 1141.6342807581166,
            "rating_q975": 1154.3592185440828,
            "rating_q025": 1128.9093429721504
        },
        "reka-flash-21b-20240226-online": {
            "rating": 1139.984304576259,
            "rating_q975": 1155.6164658497344,
            "rating_q025": 1124.3521433027838
        },
        "gemini-pro-dev-api": {
            "rating": 1131.4300276595172,
            "rating_q975": 1149.1679005811575,
            "rating_q025": 1113.692154737877
        },
        "gemma-2-2b-it": {
            "rating": 1130.8692519305,
            "rating_q975": 1139.1710921351978,
            "rating_q025": 1122.5674117258022
        },
        "llama-3-8b-instruct": {
            "rating": 1128.72791355226,
            "rating_q975": 1137.1591501362175,
            "rating_q025": 1120.2966769683023
        },
        "granite-3.0-8b-instruct": {
            "rating": 1121.949072363061,
            "rating_q975": 1145.8263555795447,
            "rating_q025": 1098.0717891465774
        },
        "phi-3-medium-4k-instruct": {
            "rating": 1121.8716566589392,
            "rating_q975": 1134.728859535394,
            "rating_q025": 1109.0144537824845
        },
        "gpt-3.5-turbo-0125": {
            "rating": 1121.8083504154367,
            "rating_q975": 1130.8691599360236,
            "rating_q025": 1112.7475408948499
        },
        "qwen1.5-14b-chat": {
            "rating": 1113.9888640950146,
            "rating_q975": 1128.7800648418283,
            "rating_q025": 1099.1976633482009
        },
        "dbrx-instruct-preview": {
            "rating": 1112.59987382508,
            "rating_q975": 1124.9906140056898,
            "rating_q025": 1100.2091336444703
        },
        "tulu-2-dpo-70b": {
            "rating": 1106.0670888636273,
            "rating_q975": 1139.967926803799,
            "rating_q025": 1072.1662509234557
        },
        "zephyr-orpo-141b-A35b-v0.1": {
            "rating": 1105.6988829447594,
            "rating_q975": 1134.0801679149117,
            "rating_q025": 1077.317597974607
        },
        "starling-lm-7b-beta": {
            "rating": 1105.3278683217418,
            "rating_q975": 1120.7276096000971,
            "rating_q025": 1089.9281270433864
        },
        "mixtral-8x7b-instruct-v0.1": {
            "rating": 1104.3863906652061,
            "rating_q975": 1113.821574454592,
            "rating_q025": 1094.9512068758202
        },
        "llama-3.2-3b-instruct": {
            "rating": 1101.0444430657099,
            "rating_q975": 1118.9033520703335,
            "rating_q025": 1083.1855340610862
        },
        "wizardlm-70b": {
            "rating": 1099.9764685739428,
            "rating_q975": 1132.2621657690179,
            "rating_q025": 1067.6907713788678
        },
        "openchat-3.5": {
            "rating": 1095.798408744908,
            "rating_q975": 1124.7109603887873,
            "rating_q025": 1066.885857101029
        },
        "yi-34b-chat": {
            "rating": 1095.4591428679896,
            "rating_q975": 1113.4972664016173,
            "rating_q025": 1077.421019334362
        },
        "deepseek-llm-67b-chat": {
            "rating": 1091.3931457089811,
            "rating_q975": 1129.077546672587,
            "rating_q025": 1053.7087447453753
        },
        "qwen1.5-7b-chat": {
            "rating": 1091.006979233223,
            "rating_q975": 1121.709485021867,
            "rating_q025": 1060.3044734445791
        },
        "phi-3-small-8k-instruct": {
            "rating": 1088.583959196651,
            "rating_q975": 1101.6947284009434,
            "rating_q025": 1075.4731899923586
        },
        "openchat-3.5-0106": {
            "rating": 1086.017359985267,
            "rating_q975": 1104.4281805162095,
            "rating_q025": 1067.6065394543243
        },
        "starling-lm-7b-alpha": {
            "rating": 1081.7435573814455,
            "rating_q975": 1104.8299885742028,
            "rating_q025": 1058.6571261886882
        },
        "granite-3.0-2b-instruct": {
            "rating": 1071.604075701789,
            "rating_q975": 1095.8692163763892,
            "rating_q025": 1047.3389350271889
        },
        "gpt-3.5-turbo-1106": {
            "rating": 1068.6999019245877,
            "rating_q975": 1089.9434726624625,
            "rating_q025": 1047.456331186713
        },
        "llama-2-13b-chat": {
            "rating": 1065.2630618846204,
            "rating_q975": 1082.5788630341615,
            "rating_q025": 1047.9472607350792
        },
        "llama-2-70b-chat": {
            "rating": 1063.4554748569403,
            "rating_q975": 1076.1346825574087,
            "rating_q025": 1050.776267156472
        },
        "mistral-7b-instruct-v0.2": {
            "rating": 1060.7055503448682,
            "rating_q975": 1075.7772415169734,
            "rating_q025": 1045.633859172763
        },
        "smollm2-1.7b-instruct": {
            "rating": 1059.739410536963,
            "rating_q975": 1093.2094843795246,
            "rating_q025": 1026.2693366944015
        },
        "gemma-1.1-7b-it": {
            "rating": 1056.9222223324819,
            "rating_q975": 1069.4054810710732,
            "rating_q025": 1044.4389635938905
        },
        "openhermes-2.5-mistral-7b": {
            "rating": 1056.4060130236896,
            "rating_q975": 1090.7510600586488,
            "rating_q025": 1022.0609659887306
        },
        "wizardlm-13b": {
            "rating": 1052.7634013227078,
            "rating_q975": 1094.7696567595538,
            "rating_q025": 1010.7571458858616
        },
        "llama-3.2-1b-instruct": {
            "rating": 1050.0480792312437,
            "rating_q975": 1068.7801614845691,
            "rating_q025": 1031.3159969779183
        },
        "vicuna-13b": {
            "rating": 1048.3384415589426,
            "rating_q975": 1069.906771297557,
            "rating_q025": 1026.770111820328
        },
        "nous-hermes-2-mixtral-8x7b-dpo": {
            "rating": 1045.3868381392895,
            "rating_q975": 1081.6587484025422,
            "rating_q025": 1009.1149278760367
        },
        "zephyr-7b-beta": {
            "rating": 1041.9307011121025,
            "rating_q975": 1069.5363758562803,
            "rating_q025": 1014.3250263679248
        },
        "phi-3-mini-4k-instruct-june-2024": {
            "rating": 1040.2416680986605,
            "rating_q975": 1059.1020217147504,
            "rating_q025": 1021.3813144825706
        },
        "phi-3-mini-4k-instruct": {
            "rating": 1040.21272207456,
            "rating_q975": 1055.2119228595047,
            "rating_q025": 1025.213521289615
        },
        "vicuna-7b": {
            "rating": 1038.9059711397906,
            "rating_q975": 1084.7753340910783,
            "rating_q025": 993.036608188503
        },
        "vicuna-33b": {
            "rating": 1029.171299434404,
            "rating_q975": 1048.372243648635,
            "rating_q025": 1009.9703552201731
        },
        "qwen-14b-chat": {
            "rating": 1027.9570390084282,
            "rating_q975": 1067.6851919762958,
            "rating_q025": 988.2288860405606
        },
        "gemma-7b-it": {
            "rating": 1023.5114406151179,
            "rating_q975": 1046.088621572533,
            "rating_q025": 1000.9342596577027
        },
        "codellama-34b-instruct": {
            "rating": 1014.4259339924606,
            "rating_q975": 1048.022643669866,
            "rating_q025": 980.8292243150551
        },
        "palm-2": {
            "rating": 1007.8305236173326,
            "rating_q975": 1046.1404378604623,
            "rating_q025": 969.5206093742028
        },
        "snowflake-arctic-instruct": {
            "rating": 1002.8008338058244,
            "rating_q975": 1017.0218561563753,
            "rating_q025": 988.5798114552734
        },
        "gemma-1.1-2b-it": {
            "rating": 1002.6785046838163,
            "rating_q975": 1020.5382685106383,
            "rating_q025": 984.8187408569943
        },
        "mistral-7b-instruct": {
            "rating": 1001.2012112919977,
            "rating_q975": 1028.4500313087487,
            "rating_q025": 973.9523912752466
        },
        "llama2-70b-steerlm-chat": {
            "rating": 1000.1202573336936,
            "rating_q975": 1043.1860471168764,
            "rating_q025": 957.0544675505109
        },
        "llama-2-7b-chat": {
            "rating": 999.6090090703676,
            "rating_q975": 1019.7342072343728,
            "rating_q025": 979.4838109063625
        },
        "phi-3-mini-128k-instruct": {
            "rating": 996.8245486232315,
            "rating_q975": 1012.674561221883,
            "rating_q025": 980.9745360245801
        },
        "qwen1.5-4b-chat": {
            "rating": 988.8005724772179,
            "rating_q975": 1012.7438950890763,
            "rating_q025": 964.8572498653594
        },
        "gemma-2b-it": {
            "rating": 982.8904631078909,
            "rating_q975": 1013.4542671742585,
            "rating_q025": 952.3266590415234
        },
        "stripedhyena-nous-7b": {
            "rating": 982.7137743861044,
            "rating_q975": 1015.2097736152766,
            "rating_q025": 950.2177751569322
        },
        "chatglm3-6b": {
            "rating": 952.2683376375985,
            "rating_q975": 994.1573265961831,
            "rating_q025": 910.3793486790139
        }
    },
    "math": {
        "gemini-2.5-pro": {
            "rating": 1463.6611387751332,
            "rating_q975": 1473.8014740709787,
            "rating_q025": 1453.5208034792877
        },
        "claude-sonnet-4-5-20250929-thinking-32k": {
            "rating": 1452.9844286830548,
            "rating_q975": 1475.1308568470392,
            "rating_q025": 1430.8380005190704
        },
        "qwen3-max-preview": {
            "rating": 1452.264325216114,
            "rating_q975": 1468.1309899940147,
            "rating_q025": 1436.3976604382133
        },
        "longcat-flash-chat": {
            "rating": 1450.4801773770373,
            "rating_q975": 1472.5841724987824,
            "rating_q025": 1428.3761822552922
        },
        "qwen3-next-80b-a3b-instruct": {
            "rating": 1443.732993754986,
            "rating_q975": 1461.59996841571,
            "rating_q025": 1425.866019094262
        },
        "qwen3-max-2025-09-23": {
            "rating": 1443.2835682719917,
            "rating_q975": 1466.7850737229783,
            "rating_q025": 1419.7820628210052
        },
        "grok-4-0709": {
            "rating": 1437.3488568047987,
            "rating_q975": 1451.1356676886041,
            "rating_q025": 1423.5620459209933
        },
        "qwen3-235b-a22b-instruct-2507": {
            "rating": 1436.6279883055852,
            "rating_q975": 1449.4938050419967,
            "rating_q025": 1423.7621715691737
        },
        "glm-4.6": {
            "rating": 1433.8478293720223,
            "rating_q975": 1459.1248501155044,
            "rating_q025": 1408.5708086285401
        },
        "claude-opus-4-1-20250805-thinking-16k": {
            "rating": 1433.4987972781046,
            "rating_q975": 1447.7879454659744,
            "rating_q025": 1419.2096490902347
        },
        "glm-4.5": {
            "rating": 1432.1236027955354,
            "rating_q975": 1447.614601918865,
            "rating_q025": 1416.6326036722057
        },
        "gemini-2.5-flash-preview-09-2025": {
            "rating": 1431.8715076617536,
            "rating_q975": 1453.257039633934,
            "rating_q025": 1410.4859756895733
        },
        "o3-2025-04-16": {
            "rating": 1430.9239379522194,
            "rating_q975": 1441.011761154462,
            "rating_q025": 1420.8361147499768
        },
        "claude-opus-4-1-20250805": {
            "rating": 1430.368633093353,
            "rating_q975": 1442.510166128998,
            "rating_q025": 1418.2271000577082
        },
        "qwen3-vl-235b-a22b-instruct": {
            "rating": 1424.228257715005,
            "rating_q975": 1448.9521392503318,
            "rating_q025": 1399.504376179678
        },
        "deepseek-v3.2-exp-thinking": {
            "rating": 1422.948583501843,
            "rating_q975": 1449.6333159595322,
            "rating_q025": 1396.2638510441536
        },
        "deepseek-v3.1": {
            "rating": 1422.350144636124,
            "rating_q975": 1440.6055686798234,
            "rating_q025": 1404.0947205924247
        },
        "qwen3-vl-235b-a22b-thinking": {
            "rating": 1421.567190339715,
            "rating_q975": 1450.0430427182293,
            "rating_q025": 1393.0913379612005
        },
        "deepseek-v3.1-thinking": {
            "rating": 1421.0889359648372,
            "rating_q975": 1443.168225500668,
            "rating_q025": 1399.0096464290064
        },
        "mistral-medium-2508": {
            "rating": 1418.4674360988429,
            "rating_q975": 1432.2325929755575,
            "rating_q025": 1404.7022792221283
        },
        "grok-4-fast": {
            "rating": 1418.351828775417,
            "rating_q975": 1446.9782722217722,
            "rating_q025": 1389.725385329062
        },
        "deepseek-v3.1-terminus-thinking": {
            "rating": 1416.0509468973544,
            "rating_q975": 1457.2856898944517,
            "rating_q025": 1374.816203900257
        },
        "gemini-2.5-flash": {
            "rating": 1415.4362373847632,
            "rating_q975": 1425.0866668484825,
            "rating_q025": 1405.785807921044
        },
        "gpt-4.5-preview-2025-02-27": {
            "rating": 1415.3588310870987,
            "rating_q975": 1430.344448258842,
            "rating_q025": 1400.3732139153553
        },
        "qwen3-235b-a22b-thinking-2507": {
            "rating": 1415.0776099913453,
            "rating_q975": 1439.3126490892569,
            "rating_q025": 1390.8425708934337
        },
        "amazon-nova-experimental-chat-10-09": {
            "rating": 1413.5107056506502,
            "rating_q975": 1447.4056065969548,
            "rating_q025": 1379.6158047043455
        },
        "gpt-5-chat": {
            "rating": 1410.2932548475314,
            "rating_q975": 1424.6619753458378,
            "rating_q025": 1395.924534349225
        },
        "hunyuan-t1-20250711": {
            "rating": 1409.9348647224995,
            "rating_q975": 1448.182539528963,
            "rating_q025": 1371.687189916036
        },
        "claude-sonnet-4-5-20250929": {
            "rating": 1408.3432439676656,
            "rating_q975": 1437.9058460506433,
            "rating_q025": 1378.7806418846878
        },
        "mai-1-preview": {
            "rating": 1407.0528492536628,
            "rating_q975": 1426.2312145401022,
            "rating_q025": 1387.8744839672233
        },
        "gpt-5-high": {
            "rating": 1406.1463498109172,
            "rating_q975": 1420.2102652594974,
            "rating_q025": 1392.082434362337
        },
        "qwen3-next-80b-a3b-thinking": {
            "rating": 1404.0738920654667,
            "rating_q975": 1423.6930671579767,
            "rating_q025": 1384.4547169729567
        },
        "glm-4.5-air": {
            "rating": 1403.7101752624546,
            "rating_q975": 1419.2084996776082,
            "rating_q025": 1388.211850847301
        },
        "qwen3-32b": {
            "rating": 1403.046051548622,
            "rating_q975": 1433.375863267587,
            "rating_q025": 1372.716239829657
        },
        "deepseek-r1-0528": {
            "rating": 1402.9688361681494,
            "rating_q975": 1422.2987593747707,
            "rating_q025": 1383.6389129615281
        },
        "qwen3-235b-a22b": {
            "rating": 1402.4193122746,
            "rating_q975": 1416.2539316603707,
            "rating_q025": 1388.5846928888295
        },
        "qwen3-235b-a22b-no-thinking": {
            "rating": 1400.6603092120938,
            "rating_q975": 1412.4142186602044,
            "rating_q025": 1388.9063997639832
        },
        "chatgpt-4o-latest-20250326": {
            "rating": 1399.3593614933645,
            "rating_q975": 1409.045951821267,
            "rating_q025": 1389.672771165462
        },
        "o3-mini-high": {
            "rating": 1399.0216413535522,
            "rating_q975": 1411.93767123686,
            "rating_q025": 1386.1056114702444
        },
        "qwen3-30b-a3b-instruct-2507": {
            "rating": 1398.858079365363,
            "rating_q975": 1413.789046874338,
            "rating_q025": 1383.927111856388
        },
        "deepseek-v3.1-terminus": {
            "rating": 1398.5856803260247,
            "rating_q975": 1437.2815362943895,
            "rating_q025": 1359.8898243576598
        },
        "kimi-k2-0905-preview": {
            "rating": 1398.1267491423148,
            "rating_q975": 1419.983303505187,
            "rating_q025": 1376.2701947794426
        },
        "nvidia-llama-3.3-nemotron-super-49b-v1.5": {
            "rating": 1397.06285174446,
            "rating_q975": 1434.7674505400885,
            "rating_q025": 1359.3582529488315
        },
        "deepseek-r1": {
            "rating": 1396.1983383916677,
            "rating_q975": 1409.8626098925547,
            "rating_q025": 1382.5340668907807
        },
        "claude-opus-4-20250514-thinking-16k": {
            "rating": 1394.5751398629745,
            "rating_q975": 1406.676991335257,
            "rating_q025": 1382.473288390692
        },
        "minimax-m1": {
            "rating": 1394.2455228524957,
            "rating_q975": 1407.3367049442859,
            "rating_q025": 1381.1543407607055
        },
        "grok-3-preview-02-24": {
            "rating": 1393.573638528009,
            "rating_q975": 1404.2670037658695,
            "rating_q025": 1382.8802732901486
        },
        "o4-mini-2025-04-16": {
            "rating": 1391.3368067789136,
            "rating_q975": 1401.9097005612664,
            "rating_q025": 1380.7639129965607
        },
        "o1-2024-12-17": {
            "rating": 1391.2258438322237,
            "rating_q975": 1401.6142108624647,
            "rating_q025": 1380.8374768019828
        },
        "claude-haiku-4-5-20251001": {
            "rating": 1390.727323161145,
            "rating_q975": 1414.5754605806421,
            "rating_q025": 1366.879185741648
        },
        "gpt-oss-120b": {
            "rating": 1388.998398831487,
            "rating_q975": 1403.6277487791513,
            "rating_q025": 1374.3690488838229
        },
        "grok-3-mini-high": {
            "rating": 1388.990357481735,
            "rating_q975": 1406.7928491856455,
            "rating_q025": 1371.1878657778243
        },
        "gpt-5-mini-high": {
            "rating": 1386.441627775747,
            "rating_q975": 1402.7381005143118,
            "rating_q025": 1370.1451550371823
        },
        "claude-sonnet-4-20250514-thinking-32k": {
            "rating": 1380.198381320265,
            "rating_q975": 1392.8562601908613,
            "rating_q025": 1367.5405024496688
        },
        "deepseek-v3-0324": {
            "rating": 1378.544645321151,
            "rating_q975": 1388.6428588481176,
            "rating_q025": 1368.4464317941843
        },
        "o3-mini": {
            "rating": 1378.4355415736172,
            "rating_q975": 1386.659446125083,
            "rating_q025": 1370.2116370221515
        },
        "gemini-2.5-flash-lite-preview-09-2025-no-thinking": {
            "rating": 1376.6240644472016,
            "rating_q975": 1397.2290214547036,
            "rating_q025": 1356.0191074396996
        },
        "o1-preview": {
            "rating": 1376.4249055192195,
            "rating_q975": 1385.5477690846626,
            "rating_q025": 1367.3020419537763
        },
        "claude-opus-4-20250514": {
            "rating": 1375.1827996373406,
            "rating_q975": 1386.0180410195962,
            "rating_q025": 1364.347558255085
        },
        "step-3": {
            "rating": 1372.8867120768534,
            "rating_q975": 1404.7965718121918,
            "rating_q025": 1340.976852341515
        },
        "qwen2.5-max": {
            "rating": 1372.252641795513,
            "rating_q975": 1381.71063313978,
            "rating_q025": 1362.794650451246
        },
        "kimi-k2-0711-preview": {
            "rating": 1371.6805974141405,
            "rating_q975": 1385.5366071949536,
            "rating_q025": 1357.8245876333274
        },
        "grok-3-mini-beta": {
            "rating": 1371.4444009953584,
            "rating_q975": 1385.3102720042673,
            "rating_q025": 1357.5785299864494
        },
        "ling-flash-2.0": {
            "rating": 1371.1927411322743,
            "rating_q975": 1397.6962111893424,
            "rating_q025": 1344.689271075206
        },
        "qwen3-coder-480b-a35b-instruct": {
            "rating": 1370.9234133241644,
            "rating_q975": 1385.9059742045868,
            "rating_q025": 1355.940852443742
        },
        "gemini-2.5-flash-lite-preview-06-17-thinking": {
            "rating": 1370.1263536064869,
            "rating_q975": 1382.3570871027162,
            "rating_q025": 1357.8956201102576
        },
        "gpt-4.1-2025-04-14": {
            "rating": 1369.8682779852609,
            "rating_q975": 1380.1422174552515,
            "rating_q025": 1359.5943385152702
        },
        "llama-3.1-nemotron-ultra-253b-v1": {
            "rating": 1364.3156413416,
            "rating_q975": 1402.3871037581084,
            "rating_q025": 1326.2441789250915
        },
        "qwen3-30b-a3b": {
            "rating": 1361.6817031685673,
            "rating_q975": 1374.9932673148646,
            "rating_q025": 1348.37013902227
        },
        "o1-mini": {
            "rating": 1361.6600859872412,
            "rating_q975": 1368.813777398388,
            "rating_q025": 1354.5063945760944
        },
        "claude-sonnet-4-20250514": {
            "rating": 1361.6038441492478,
            "rating_q975": 1372.9933039228583,
            "rating_q025": 1350.2143843756373
        },
        "qwq-32b": {
            "rating": 1361.5467780353515,
            "rating_q975": 1374.6799455871014,
            "rating_q025": 1348.4136104836016
        },
        "ring-flash-2.0": {
            "rating": 1360.9915164306944,
            "rating_q975": 1387.9711744041178,
            "rating_q025": 1334.011858457271
        },
        "hunyuan-turbos-20250416": {
            "rating": 1360.9840561010158,
            "rating_q975": 1379.9032927962173,
            "rating_q025": 1342.0648194058142
        },
        "glm-4.5v": {
            "rating": 1356.8542551254125,
            "rating_q975": 1391.489407157785,
            "rating_q025": 1322.2191030930398
        },
        "mistral-medium-2505": {
            "rating": 1355.888578330933,
            "rating_q975": 1367.5516032480305,
            "rating_q025": 1344.2255534138353
        },
        "mistral-small-2506": {
            "rating": 1347.6204070610777,
            "rating_q975": 1364.7350815251637,
            "rating_q025": 1330.5057325969917
        },
        "gpt-4.1-mini-2025-04-14": {
            "rating": 1346.356140826415,
            "rating_q975": 1357.3167639738342,
            "rating_q025": 1335.3955176789957
        },
        "claude-3-7-sonnet-20250219-thinking-32k": {
            "rating": 1342.7210648964108,
            "rating_q975": 1353.5194237075302,
            "rating_q025": 1331.9227060852913
        },
        "qwen-plus-0125": {
            "rating": 1328.619843133564,
            "rating_q975": 1347.6787915594998,
            "rating_q025": 1309.5608947076282
        },
        "gpt-5-nano-high": {
            "rating": 1326.69236246961,
            "rating_q975": 1353.281206474967,
            "rating_q025": 1300.1035184642533
        },
        "step-1o-turbo-202506": {
            "rating": 1322.7694606373716,
            "rating_q975": 1345.0814429142356,
            "rating_q025": 1300.4574783605076
        },
        "gpt-oss-20b": {
            "rating": 1319.0007996610666,
            "rating_q975": 1341.0395888399867,
            "rating_q025": 1296.9620104821465
        },
        "gemini-1.5-pro-002": {
            "rating": 1318.3764054790845,
            "rating_q975": 1325.0052807020068,
            "rating_q025": 1311.7475302561622
        },
        "gemma-3-27b-it": {
            "rating": 1315.8345979210787,
            "rating_q975": 1325.0857733810108,
            "rating_q025": 1306.5834224611467
        },
        "deepseek-v3": {
            "rating": 1314.4175028788893,
            "rating_q975": 1324.6675361272914,
            "rating_q025": 1304.1674696304872
        },
        "gemini-2.0-flash-lite-preview-02-05": {
            "rating": 1313.3436693288613,
            "rating_q975": 1323.251494224053,
            "rating_q025": 1303.4358444336697
        },
        "gemma-3-12b-it": {
            "rating": 1312.5976255625021,
            "rating_q975": 1339.7008819536934,
            "rating_q025": 1285.4943691713108
        },
        "claude-3-5-sonnet-20241022": {
            "rating": 1310.3344888248632,
            "rating_q975": 1316.1935964867225,
            "rating_q025": 1304.475381163004
        },
        "step-2-16k-exp-202412": {
            "rating": 1308.202468900588,
            "rating_q975": 1327.8063573614702,
            "rating_q025": 1288.5985804397058
        },
        "claude-3-5-sonnet-20240620": {
            "rating": 1306.9062753874477,
            "rating_q975": 1313.573722310857,
            "rating_q025": 1300.2388284640385
        },
        "llama-4-maverick-17b-128e-instruct": {
            "rating": 1305.7456305040018,
            "rating_q975": 1316.2909708917052,
            "rating_q025": 1295.2002901162984
        },
        "command-a-03-2025": {
            "rating": 1304.4733444896563,
            "rating_q975": 1313.7231114139922,
            "rating_q025": 1295.2235775653203
        },
        "athene-v2-chat": {
            "rating": 1303.431459823656,
            "rating_q975": 1312.374876178703,
            "rating_q025": 1294.488043468609
        },
        "yi-lightning": {
            "rating": 1303.320901691628,
            "rating_q975": 1312.5649096680224,
            "rating_q025": 1294.0768937152336
        },
        "qwen2.5-plus-1127": {
            "rating": 1301.4678322661307,
            "rating_q975": 1314.8284258524898,
            "rating_q025": 1288.1072386797716
        },
        "hunyuan-turbos-20250226": {
            "rating": 1296.4594766411483,
            "rating_q975": 1327.8230843702233,
            "rating_q025": 1265.0958689120732
        },
        "llama-4-scout-17b-16e-instruct": {
            "rating": 1295.3653244741279,
            "rating_q975": 1308.3397180274037,
            "rating_q025": 1282.390930920852
        },
        "deepseek-v2.5-1210": {
            "rating": 1291.8187474955807,
            "rating_q975": 1308.14890501593,
            "rating_q025": 1275.4885899752314
        },
        "glm-4-plus-0111": {
            "rating": 1290.6865258946189,
            "rating_q975": 1309.7226909103224,
            "rating_q025": 1271.6503608789153
        },
        "gpt-4o-2024-08-06": {
            "rating": 1288.7999730851645,
            "rating_q975": 1296.1522397112708,
            "rating_q025": 1281.4477064590583
        },
        "gpt-4o-2024-05-13": {
            "rating": 1287.908289412681,
            "rating_q975": 1293.9366014913144,
            "rating_q025": 1281.8799773340475
        },
        "grok-2-2024-08-13": {
            "rating": 1286.7600240187078,
            "rating_q975": 1293.2523922692033,
            "rating_q025": 1280.2676557682123
        },
        "qwen2.5-72b-instruct": {
            "rating": 1286.0564171560877,
            "rating_q975": 1293.6184259605716,
            "rating_q025": 1278.4944083516039
        },
        "llama-3.1-405b-instruct-fp8": {
            "rating": 1285.1490978301422,
            "rating_q975": 1291.929701275238,
            "rating_q025": 1278.3684943850465
        },
        "hunyuan-large-2025-02-10": {
            "rating": 1284.2326437555184,
            "rating_q975": 1308.1116967220883,
            "rating_q025": 1260.3535907889486
        },
        "llama-3.1-405b-instruct-bf16": {
            "rating": 1281.3469392038523,
            "rating_q975": 1288.7295238425672,
            "rating_q025": 1273.9643545651375
        },
        "hunyuan-large-vision": {
            "rating": 1280.7797496431785,
            "rating_q975": 1309.634780940522,
            "rating_q025": 1251.9247183458351
        },
        "hunyuan-standard-2025-02-10": {
            "rating": 1278.4015772465705,
            "rating_q975": 1302.2363222759268,
            "rating_q025": 1254.5668322172141
        },
        "qwen-max-0919": {
            "rating": 1278.366461237304,
            "rating_q975": 1289.7911267184252,
            "rating_q025": 1266.941795756183
        },
        "gpt-4.1-nano-2025-04-14": {
            "rating": 1278.067608296273,
            "rating_q975": 1301.2106712188922,
            "rating_q025": 1254.9245453736537
        },
        "glm-4-plus": {
            "rating": 1278.0156309217666,
            "rating_q975": 1287.3992171408918,
            "rating_q025": 1268.6320447026415
        },
        "claude-3-opus-20240229": {
            "rating": 1275.6408794602753,
            "rating_q975": 1281.1613147583107,
            "rating_q025": 1270.12044416224
        },
        "hunyuan-turbo-0110": {
            "rating": 1275.6381987423408,
            "rating_q975": 1306.444050293415,
            "rating_q025": 1244.8323471912665
        },
        "gpt-4-turbo-2024-04-09": {
            "rating": 1275.2079813886876,
            "rating_q975": 1282.0615197870209,
            "rating_q025": 1268.3544429903543
        },
        "gemini-advanced-0514": {
            "rating": 1275.2024079696475,
            "rating_q975": 1284.1041410549528,
            "rating_q025": 1266.3006748843422
        },
        "deepseek-v2.5": {
            "rating": 1274.59262300931,
            "rating_q975": 1283.7827178422833,
            "rating_q025": 1265.4025281763368
        },
        "llama-3.1-nemotron-70b-instruct": {
            "rating": 1274.3965684935101,
            "rating_q975": 1290.9756089485516,
            "rating_q025": 1257.8175280384687
        },
        "gemini-1.5-pro-001": {
            "rating": 1273.4082735017246,
            "rating_q975": 1280.5819044237992,
            "rating_q025": 1266.23464257965
        },
        "gemini-1.5-flash-002": {
            "rating": 1272.924126143579,
            "rating_q975": 1280.8654041410477,
            "rating_q025": 1264.9828481461104
        },
        "gpt-4-1106-preview": {
            "rating": 1272.7744896062259,
            "rating_q975": 1279.8459459057146,
            "rating_q025": 1265.703033306737
        },
        "gpt-4-0125-preview": {
            "rating": 1271.3403471739757,
            "rating_q975": 1278.466673049259,
            "rating_q025": 1264.2140212986924
        },
        "llama-3.3-70b-instruct": {
            "rating": 1271.0508040050095,
            "rating_q975": 1278.2229979963868,
            "rating_q025": 1263.8786100136322
        },
        "gpt-4o-mini-2024-07-18": {
            "rating": 1270.7471932838685,
            "rating_q975": 1276.9273625730884,
            "rating_q025": 1264.5670239946485
        },
        "grok-2-mini-2024-08-13": {
            "rating": 1268.7559126602519,
            "rating_q975": 1275.677093708332,
            "rating_q025": 1261.8347316121717
        },
        "mistral-small-3.1-24b-instruct-2503": {
            "rating": 1266.6646542437911,
            "rating_q975": 1279.4073788288008,
            "rating_q025": 1253.9219296587814
        },
        "mistral-large-2407": {
            "rating": 1265.4713488151317,
            "rating_q975": 1272.8525100630152,
            "rating_q025": 1258.0901875672482
        },
        "mistral-large-2411": {
            "rating": 1264.1096594942794,
            "rating_q975": 1272.9262822905434,
            "rating_q025": 1255.2930366980154
        },
        "gemma-3n-e4b-it": {
            "rating": 1261.5797395705094,
            "rating_q975": 1276.0592434683247,
            "rating_q025": 1247.1002356726942
        },
        "amazon-nova-pro-v1.0": {
            "rating": 1255.0436242425812,
            "rating_q975": 1264.4355859402483,
            "rating_q025": 1245.6516625449142
        },
        "llama-3.1-70b-instruct": {
            "rating": 1254.752646513727,
            "rating_q975": 1261.589849768076,
            "rating_q025": 1247.9154432593782
        },
        "qwen2.5-coder-32b-instruct": {
            "rating": 1254.10958877772,
            "rating_q975": 1273.0663617785008,
            "rating_q025": 1235.1528157769394
        },
        "magistral-medium-2506": {
            "rating": 1253.9752509822913,
            "rating_q975": 1279.1842083854838,
            "rating_q025": 1228.7662935790988
        },
        "phi-4": {
            "rating": 1249.2293669263263,
            "rating_q975": 1259.3359629835,
            "rating_q025": 1239.1227708691526
        },
        "claude-3-5-haiku-20241022": {
            "rating": 1248.6700511193035,
            "rating_q975": 1255.7215902627472,
            "rating_q025": 1241.6185119758597
        },
        "deepseek-coder-v2": {
            "rating": 1244.5163265287094,
            "rating_q975": 1257.6712492487757,
            "rating_q025": 1231.3614038086432
        },
        "gemma-3-4b-it": {
            "rating": 1243.7918823352297,
            "rating_q975": 1272.0212835061395,
            "rating_q025": 1215.56248116432
        },
        "llama-3.1-tulu-3-70b": {
            "rating": 1243.684205899449,
            "rating_q975": 1267.9312077678733,
            "rating_q025": 1219.4372040310245
        },
        "mistral-small-24b-instruct-2501": {
            "rating": 1243.6717058180607,
            "rating_q975": 1256.7310224890384,
            "rating_q025": 1230.612389147083
        },
        "hunyuan-standard-256k": {
            "rating": 1239.0948655310353,
            "rating_q975": 1267.3554643440302,
            "rating_q025": 1210.8342667180405
        },
        "qwen2-72b-instruct": {
            "rating": 1237.9363849898375,
            "rating_q975": 1246.725431844037,
            "rating_q025": 1229.147338135638
        },
        "athene-70b-0725": {
            "rating": 1234.6077991128166,
            "rating_q975": 1244.4833840163658,
            "rating_q025": 1224.7322142092673
        },
        "gpt-4-0314": {
            "rating": 1233.5501429766728,
            "rating_q975": 1242.632010335037,
            "rating_q025": 1224.4682756183086
        },
        "llama-3.1-nemotron-51b-instruct": {
            "rating": 1233.5010804477552,
            "rating_q975": 1255.862712942582,
            "rating_q025": 1211.1394479529283
        },
        "gemini-1.5-flash-001": {
            "rating": 1232.4134875705467,
            "rating_q975": 1239.708782903659,
            "rating_q025": 1225.1181922374344
        },
        "amazon-nova-lite-v1.0": {
            "rating": 1230.2994194738644,
            "rating_q975": 1240.6707933731261,
            "rating_q025": 1219.9280455746027
        },
        "reka-core-20240904": {
            "rating": 1225.7612292516715,
            "rating_q975": 1239.6753385718528,
            "rating_q025": 1211.8471199314902
        },
        "jamba-1.5-large": {
            "rating": 1225.3512391168433,
            "rating_q975": 1240.4077698841077,
            "rating_q025": 1210.294708349579
        },
        "llama-3-70b-instruct": {
            "rating": 1221.8073318079414,
            "rating_q975": 1228.4411780942478,
            "rating_q025": 1215.173485521635
        },
        "glm-4-0520": {
            "rating": 1220.7357282264454,
            "rating_q975": 1235.8578873961526,
            "rating_q025": 1205.6135690567382
        },
        "gpt-4-0613": {
            "rating": 1220.7114269633846,
            "rating_q975": 1228.3879936966619,
            "rating_q025": 1213.0348602301074
        },
        "nemotron-4-340b-instruct": {
            "rating": 1219.8705216559174,
            "rating_q975": 1231.3646782195228,
            "rating_q025": 1208.376365092312
        },
        "qwq-32b-preview": {
            "rating": 1218.215366685406,
            "rating_q975": 1242.4049819760003,
            "rating_q025": 1194.0257513948118
        },
        "claude-3-sonnet-20240229": {
            "rating": 1217.1479841321616,
            "rating_q975": 1224.4627857557043,
            "rating_q025": 1209.8331825086188
        },
        "gemma-2-27b-it": {
            "rating": 1215.891653787789,
            "rating_q975": 1221.9016441796155,
            "rating_q025": 1209.8816633959625
        },
        "olmo-2-0325-32b-instruct": {
            "rating": 1212.230362703427,
            "rating_q975": 1240.597448285575,
            "rating_q025": 1183.8632771212792
        },
        "amazon-nova-micro-v1.0": {
            "rating": 1210.8201060702463,
            "rating_q975": 1221.1405800655227,
            "rating_q025": 1200.49963207497
        },
        "gemini-1.5-flash-8b-001": {
            "rating": 1210.105047772142,
            "rating_q975": 1217.93218684059,
            "rating_q025": 1202.2779087036938
        },
        "mistral-large-2402": {
            "rating": 1203.4039853756963,
            "rating_q975": 1211.7638832370776,
            "rating_q025": 1195.044087514315
        },
        "c4ai-aya-expanse-32b": {
            "rating": 1202.7494075040279,
            "rating_q975": 1211.8170926152716,
            "rating_q025": 1193.6817223927842
        },
        "llama-3.1-tulu-3-8b": {
            "rating": 1199.2302578476529,
            "rating_q975": 1224.2392204949529,
            "rating_q025": 1174.2212952003529
        },
        "reka-flash-20240904": {
            "rating": 1199.145618947287,
            "rating_q975": 1212.7774076750504,
            "rating_q025": 1185.5138302195235
        },
        "claude-3-haiku-20240307": {
            "rating": 1192.0284088139213,
            "rating_q975": 1198.6356568627436,
            "rating_q025": 1185.4211607650989
        },
        "ministral-8b-2410": {
            "rating": 1191.895036244574,
            "rating_q975": 1211.2225206136163,
            "rating_q025": 1172.5675518755315
        },
        "command-r-plus-08-2024": {
            "rating": 1191.8047475179524,
            "rating_q975": 1205.2306717585784,
            "rating_q025": 1178.3788232773263
        },
        "qwen1.5-110b-chat": {
            "rating": 1188.9027800668628,
            "rating_q975": 1199.7092489682307,
            "rating_q025": 1178.0963111654949
        },
        "mixtral-8x22b-instruct-v0.1": {
            "rating": 1187.8498282058958,
            "rating_q975": 1196.126627655965,
            "rating_q025": 1179.5730287558267
        },
        "gemma-2-9b-it": {
            "rating": 1186.986262343245,
            "rating_q975": 1193.8922242865642,
            "rating_q025": 1180.0803003999258
        },
        "yi-1.5-34b-chat": {
            "rating": 1185.3062557718342,
            "rating_q975": 1195.8194586083393,
            "rating_q025": 1174.7930529353291
        },
        "internlm2_5-20b-chat": {
            "rating": 1184.418636074844,
            "rating_q975": 1198.824854721683,
            "rating_q025": 1170.012417428005
        },
        "mistral-medium": {
            "rating": 1183.3347864825328,
            "rating_q975": 1193.5466711461456,
            "rating_q025": 1173.12290181892
        },
        "llama-3.1-8b-instruct": {
            "rating": 1183.1487138590262,
            "rating_q975": 1190.3817912833613,
            "rating_q025": 1175.9156364346911
        },
        "phi-3-medium-4k-instruct": {
            "rating": 1177.4437088672705,
            "rating_q975": 1187.4344331815919,
            "rating_q025": 1167.4529845529491
        },
        "gemma-2-9b-it-simpo": {
            "rating": 1176.4288759543124,
            "rating_q975": 1191.164726950174,
            "rating_q025": 1161.6930249584507
        },
        "reka-flash-21b-20240226-online": {
            "rating": 1172.098228341869,
            "rating_q975": 1185.3795580016472,
            "rating_q025": 1158.8168986820906
        },
        "c4ai-aya-expanse-8b": {
            "rating": 1171.862530359414,
            "rating_q975": 1186.5176501083429,
            "rating_q025": 1157.207410610485
        },
        "command-r-plus": {
            "rating": 1167.9523999849778,
            "rating_q975": 1175.7205467588656,
            "rating_q025": 1160.18425321109
        },
        "qwen1.5-72b-chat": {
            "rating": 1167.5609490875963,
            "rating_q975": 1176.6327318907083,
            "rating_q025": 1158.4891662844843
        },
        "jamba-1.5-mini": {
            "rating": 1164.6854412155692,
            "rating_q975": 1180.3282943848865,
            "rating_q025": 1149.042588046252
        },
        "granite-3.1-2b-instruct": {
            "rating": 1162.292486431515,
            "rating_q975": 1188.2642112796605,
            "rating_q025": 1136.3207615833696
        },
        "reka-flash-21b-20240226": {
            "rating": 1159.643942784058,
            "rating_q975": 1170.499110694491,
            "rating_q025": 1148.788774873625
        },
        "command-r-08-2024": {
            "rating": 1159.006624891028,
            "rating_q975": 1172.1369390251502,
            "rating_q025": 1145.8763107569057
        },
        "qwen1.5-32b-chat": {
            "rating": 1158.9864860162725,
            "rating_q975": 1170.147292490702,
            "rating_q025": 1147.8256795418429
        },
        "granite-3.1-8b-instruct": {
            "rating": 1156.9880288183276,
            "rating_q975": 1184.702716889209,
            "rating_q025": 1129.2733407474464
        },
        "phi-3-mini-4k-instruct-june-2024": {
            "rating": 1155.3790203843334,
            "rating_q975": 1168.5402017857082,
            "rating_q025": 1142.2178389829587
        },
        "llama-3-8b-instruct": {
            "rating": 1155.376456544715,
            "rating_q975": 1162.4718294620423,
            "rating_q025": 1148.2810836273877
        },
        "phi-3-small-8k-instruct": {
            "rating": 1154.2535816161653,
            "rating_q975": 1166.4934097841572,
            "rating_q025": 1142.0137534481735
        },
        "zephyr-orpo-141b-A35b-v0.1": {
            "rating": 1152.2944427639636,
            "rating_q975": 1174.3394263953937,
            "rating_q025": 1130.2494591325335
        },
        "mixtral-8x7b-instruct-v0.1": {
            "rating": 1150.81274329055,
            "rating_q975": 1158.6918144683366,
            "rating_q025": 1142.9336721127636
        },
        "dbrx-instruct-preview": {
            "rating": 1148.7709526534682,
            "rating_q975": 1159.714348039685,
            "rating_q025": 1137.8275572672512
        },
        "granite-3.0-8b-instruct": {
            "rating": 1146.8905123115842,
            "rating_q975": 1165.3185632577631,
            "rating_q025": 1128.4624613654053
        },
        "gpt-3.5-turbo-0125": {
            "rating": 1145.537534622425,
            "rating_q975": 1153.3035487754412,
            "rating_q025": 1137.7715204694089
        },
        "gpt-3.5-turbo-1106": {
            "rating": 1144.918771569723,
            "rating_q975": 1159.6916751278834,
            "rating_q025": 1130.1458680115627
        },
        "gemma-2-2b-it": {
            "rating": 1138.4641313603574,
            "rating_q975": 1145.773885205138,
            "rating_q025": 1131.154377515577
        },
        "gemini-pro-dev-api": {
            "rating": 1135.3422511373647,
            "rating_q975": 1148.7910310736581,
            "rating_q025": 1121.8934712010712
        },
        "gemini-pro": {
            "rating": 1133.4793608521284,
            "rating_q975": 1152.333977827215,
            "rating_q025": 1114.6247438770417
        },
        "llama-3.2-3b-instruct": {
            "rating": 1129.707552348536,
            "rating_q975": 1145.0400521060433,
            "rating_q025": 1114.3750525910286
        },
        "qwen1.5-14b-chat": {
            "rating": 1128.619402219395,
            "rating_q975": 1141.657672923803,
            "rating_q025": 1115.581131514987
        },
        "starling-lm-7b-beta": {
            "rating": 1128.0651197624268,
            "rating_q975": 1141.487024705624,
            "rating_q025": 1114.6432148192296
        },
        "command-r": {
            "rating": 1124.363935479411,
            "rating_q975": 1133.2058625631605,
            "rating_q025": 1115.5220083956617
        },
        "granite-3.0-2b-instruct": {
            "rating": 1121.316140805524,
            "rating_q975": 1139.9606604144742,
            "rating_q025": 1102.6716211965736
        },
        "wizardlm-70b": {
            "rating": 1119.7604284605707,
            "rating_q975": 1138.6798257579394,
            "rating_q025": 1100.841031163202
        },
        "yi-34b-chat": {
            "rating": 1117.2623353536173,
            "rating_q975": 1130.0594562749793,
            "rating_q025": 1104.4652144322554
        },
        "phi-3-mini-4k-instruct": {
            "rating": 1116.0751164797125,
            "rating_q975": 1127.8431412058221,
            "rating_q025": 1104.307091753603
        },
        "snowflake-arctic-instruct": {
            "rating": 1113.049959376442,
            "rating_q975": 1123.7982424452357,
            "rating_q025": 1102.3016763076484
        },
        "deepseek-llm-67b-chat": {
            "rating": 1110.6441991782285,
            "rating_q975": 1133.99002016842,
            "rating_q025": 1087.298378188037
        },
        "tulu-2-dpo-70b": {
            "rating": 1110.5012115509298,
            "rating_q975": 1129.202580251078,
            "rating_q025": 1091.7998428507817
        },
        "gemma-1.1-7b-it": {
            "rating": 1110.4296188670755,
            "rating_q975": 1121.23744059269,
            "rating_q025": 1099.621797141461
        },
        "openchat-3.5-0106": {
            "rating": 1110.0057029786794,
            "rating_q975": 1123.1577894865275,
            "rating_q025": 1096.8536164708314
        },
        "smollm2-1.7b-instruct": {
            "rating": 1108.499098001043,
            "rating_q975": 1141.38419442405,
            "rating_q025": 1075.6140015780359
        },
        "openhermes-2.5-mistral-7b": {
            "rating": 1101.1041233856888,
            "rating_q975": 1120.8956832158335,
            "rating_q025": 1081.312563555544
        },
        "llama-2-70b-chat": {
            "rating": 1094.569743688619,
            "rating_q975": 1104.3030608560573,
            "rating_q025": 1084.8364265211806
        },
        "phi-3-mini-128k-instruct": {
            "rating": 1093.2931436343445,
            "rating_q975": 1106.0179496013066,
            "rating_q025": 1080.5683376673824
        },
        "mistral-7b-instruct-v0.2": {
            "rating": 1089.9035090888742,
            "rating_q975": 1101.5378504416778,
            "rating_q025": 1078.2691677360706
        },
        "llama-3.2-1b-instruct": {
            "rating": 1089.3589540286214,
            "rating_q975": 1105.0779833999836,
            "rating_q025": 1073.6399246572591
        },
        "starling-lm-7b-alpha": {
            "rating": 1085.9256453257813,
            "rating_q975": 1101.21112454488,
            "rating_q025": 1070.6401661066825
        },
        "qwen1.5-7b-chat": {
            "rating": 1083.0222501749522,
            "rating_q975": 1103.226023507825,
            "rating_q025": 1062.8184768420795
        },
        "dolphin-2.2.1-mistral-7b": {
            "rating": 1080.2143991046364,
            "rating_q975": 1113.068075608493,
            "rating_q025": 1047.3607226007798
        },
        "llama2-70b-steerlm-chat": {
            "rating": 1075.3794465054523,
            "rating_q975": 1101.9793661728463,
            "rating_q025": 1048.7795268380582
        },
        "vicuna-33b": {
            "rating": 1074.0645398159445,
            "rating_q975": 1086.1860625449665,
            "rating_q025": 1061.9430170869225
        },
        "openchat-3.5": {
            "rating": 1073.7830756357876,
            "rating_q975": 1091.826638859083,
            "rating_q025": 1055.739512412492
        },
        "qwen-14b-chat": {
            "rating": 1071.6188123597872,
            "rating_q975": 1095.1934899262333,
            "rating_q025": 1048.044134793341
        },
        "gemma-7b-it": {
            "rating": 1070.1412219752947,
            "rating_q975": 1086.2240185274773,
            "rating_q025": 1054.058425423112
        },
        "llama-2-13b-chat": {
            "rating": 1069.0522164697163,
            "rating_q975": 1082.0400751276309,
            "rating_q025": 1056.0643578118018
        },
        "solar-10.7b-instruct-v1.0": {
            "rating": 1067.5240995245686,
            "rating_q975": 1089.0020178530244,
            "rating_q025": 1046.0461811961127
        },
        "nous-hermes-2-mixtral-8x7b-dpo": {
            "rating": 1064.2446093817155,
            "rating_q975": 1085.5113161531215,
            "rating_q025": 1042.9779026103095
        },
        "codellama-34b-instruct": {
            "rating": 1059.8812591947494,
            "rating_q975": 1078.8544752682005,
            "rating_q025": 1040.9080431212983
        },
        "palm-2": {
            "rating": 1052.3516512094507,
            "rating_q975": 1071.6131319584813,
            "rating_q025": 1033.09017046042
        },
        "gemma-1.1-2b-it": {
            "rating": 1052.1041522432038,
            "rating_q975": 1067.6710793397426,
            "rating_q025": 1036.537225146665
        },
        "mpt-30b-chat": {
            "rating": 1049.2537751843975,
            "rating_q975": 1083.5663167318244,
            "rating_q025": 1014.9412336369704
        },
        "llama-2-7b-chat": {
            "rating": 1045.9821828299173,
            "rating_q975": 1059.509688566527,
            "rating_q025": 1032.4546770933075
        },
        "zephyr-7b-beta": {
            "rating": 1043.8731584850998,
            "rating_q975": 1060.5083393641794,
            "rating_q025": 1027.2379776060202
        },
        "stripedhyena-nous-7b": {
            "rating": 1036.784444473938,
            "rating_q975": 1056.8349442739307,
            "rating_q025": 1016.7339446739454
        },
        "guanaco-33b": {
            "rating": 1036.0025438312541,
            "rating_q975": 1068.8801186381586,
            "rating_q025": 1003.1249690243496
        },
        "vicuna-13b": {
            "rating": 1033.723820486522,
            "rating_q975": 1047.0725095867829,
            "rating_q025": 1020.3751313862612
        },
        "mistral-7b-instruct": {
            "rating": 1031.6679597333155,
            "rating_q975": 1050.235994611761,
            "rating_q025": 1013.0999248548699
        },
        "qwen1.5-4b-chat": {
            "rating": 1029.1977938519296,
            "rating_q975": 1046.562149870408,
            "rating_q025": 1011.8334378334513
        },
        "olmo-7b-instruct": {
            "rating": 1021.7618607312072,
            "rating_q975": 1040.4869547596682,
            "rating_q025": 1003.0367667027463
        },
        "wizardlm-13b": {
            "rating": 1020.5624983185155,
            "rating_q975": 1041.0270740570757,
            "rating_q025": 1000.0979225799553
        },
        "gemma-2b-it": {
            "rating": 1013.1639884550988,
            "rating_q975": 1034.976273152211,
            "rating_q025": 991.3517037579866
        },
        "vicuna-7b": {
            "rating": 998.4105114375748,
            "rating_q975": 1019.7820055159581,
            "rating_q025": 977.0390173591915
        },
        "chatglm3-6b": {
            "rating": 992.2636449701879,
            "rating_q975": 1015.5834429364377,
            "rating_q025": 968.9438470039381
        },
        "gpt4all-13b-snoozy": {
            "rating": 944.2467174394576,
            "rating_q975": 982.1859316665009,
            "rating_q025": 906.3075032124143
        },
        "koala-13b": {
            "rating": 935.272595233587,
            "rating_q975": 956.4105575550133,
            "rating_q025": 914.1346329121608
        },
        "chatglm-6b": {
            "rating": 929.0341860091346,
            "rating_q975": 954.4552866752883,
            "rating_q025": 903.6130853429809
        },
        "RWKV-4-Raven-14B": {
            "rating": 925.299511497437,
            "rating_q975": 949.6027465487623,
            "rating_q025": 900.9962764461118
        },
        "mpt-7b-chat": {
            "rating": 922.6374014806095,
            "rating_q975": 948.0731527190183,
            "rating_q025": 897.2016502422007
        },
        "chatglm2-6b": {
            "rating": 917.6571340489635,
            "rating_q975": 952.7441995272992,
            "rating_q025": 882.5700685706278
        },
        "alpaca-13b": {
            "rating": 911.4511104539091,
            "rating_q975": 934.2204994559676,
            "rating_q025": 888.6817214518506
        },
        "oasst-pythia-12b": {
            "rating": 895.1800390101644,
            "rating_q975": 917.1755007306649,
            "rating_q025": 873.1845772896638
        },
        "dolly-v2-12b": {
            "rating": 874.8366096557634,
            "rating_q975": 903.6861980659473,
            "rating_q025": 845.9870212455794
        },
        "fastchat-t5-3b": {
            "rating": 864.9679897611825,
            "rating_q975": 890.9149801126167,
            "rating_q025": 839.0209994097482
        },
        "stablelm-tuned-alpha-7b": {
            "rating": 841.8567861692866,
            "rating_q975": 870.8760705175416,
            "rating_q025": 812.8375018210315
        },
        "llama-13b": {
            "rating": 839.5917884100394,
            "rating_q975": 872.7336803141687,
            "rating_q025": 806.44989650591
        }
    },
    "multiturn": {
        "gemini-2.5-pro": {
            "rating": 1461.256242949733,
            "rating_q975": 1468.36724122759,
            "rating_q025": 1454.1452446718758
        },
        "chatgpt-4o-latest-20250326": {
            "rating": 1454.1773627040402,
            "rating_q975": 1461.5462889722567,
            "rating_q025": 1446.8084364358238
        },
        "claude-sonnet-4-5-20250929": {
            "rating": 1454.0115428023844,
            "rating_q975": 1471.5817935562825,
            "rating_q025": 1436.4412920484863
        },
        "qwen3-max-preview": {
            "rating": 1448.6176935400845,
            "rating_q975": 1458.3134875617784,
            "rating_q025": 1438.9218995183905
        },
        "claude-sonnet-4-5-20250929-thinking-32k": {
            "rating": 1445.8780579354295,
            "rating_q975": 1459.588888803471,
            "rating_q025": 1432.167227067388
        },
        "claude-opus-4-1-20250805-thinking-16k": {
            "rating": 1445.7451580804918,
            "rating_q975": 1454.9137197090567,
            "rating_q025": 1436.576596451927
        },
        "gpt-4.5-preview-2025-02-27": {
            "rating": 1443.101359812478,
            "rating_q975": 1456.4798064219526,
            "rating_q025": 1429.7229132030034
        },
        "claude-opus-4-1-20250805": {
            "rating": 1435.0315223739944,
            "rating_q975": 1443.2203060137347,
            "rating_q025": 1426.8427387342542
        },
        "qwen3-max-2025-09-23": {
            "rating": 1433.9383069632797,
            "rating_q975": 1448.570970272461,
            "rating_q025": 1419.3056436540985
        },
        "qwen3-vl-235b-a22b-instruct": {
            "rating": 1427.9681161726169,
            "rating_q975": 1443.0996974684638,
            "rating_q025": 1412.83653487677
        },
        "qwen3-235b-a22b-instruct-2507": {
            "rating": 1427.3152214317581,
            "rating_q975": 1435.5700404642234,
            "rating_q025": 1419.0604023992928
        },
        "glm-4.6": {
            "rating": 1425.6690419252052,
            "rating_q975": 1440.6393547182013,
            "rating_q025": 1410.698729132209
        },
        "grok-3-preview-02-24": {
            "rating": 1424.3848024307613,
            "rating_q975": 1433.2408656289547,
            "rating_q025": 1415.528739232568
        },
        "mistral-medium-2508": {
            "rating": 1423.3469460639928,
            "rating_q975": 1432.3366981128074,
            "rating_q025": 1414.3571940151783
        },
        "gpt-5-chat": {
            "rating": 1422.5500485522948,
            "rating_q975": 1431.450527530235,
            "rating_q025": 1413.6495695743547
        },
        "grok-4-0709": {
            "rating": 1418.612495611661,
            "rating_q975": 1427.0230958822692,
            "rating_q025": 1410.2018953410527
        },
        "grok-4-fast": {
            "rating": 1418.5418169273862,
            "rating_q975": 1435.4033291965575,
            "rating_q025": 1401.680304658215
        },
        "qwen3-next-80b-a3b-instruct": {
            "rating": 1418.3520680758759,
            "rating_q975": 1428.6911674863854,
            "rating_q025": 1408.0129686653663
        },
        "glm-4.5": {
            "rating": 1417.3486601802474,
            "rating_q975": 1427.1825806195368,
            "rating_q025": 1407.514739740958
        },
        "deepseek-v3.1-terminus-thinking": {
            "rating": 1413.1301633317644,
            "rating_q975": 1437.065276127877,
            "rating_q025": 1389.1950505356517
        },
        "deepseek-v3.2-exp-thinking": {
            "rating": 1413.081152278301,
            "rating_q975": 1428.5041243280637,
            "rating_q025": 1397.6581802285384
        },
        "deepseek-v3.1-thinking": {
            "rating": 1407.6897630840851,
            "rating_q975": 1421.3774669630752,
            "rating_q025": 1394.002059205095
        },
        "qwen3-235b-a22b-thinking-2507": {
            "rating": 1406.8155014893773,
            "rating_q975": 1422.2773854095337,
            "rating_q025": 1391.353617569221
        },
        "o3-2025-04-16": {
            "rating": 1406.5701833203295,
            "rating_q975": 1413.6238320662535,
            "rating_q025": 1399.5165345744056
        },
        "deepseek-r1-0528": {
            "rating": 1405.7097097197798,
            "rating_q975": 1416.520623130877,
            "rating_q025": 1394.8987963086824
        },
        "gemini-2.5-flash": {
            "rating": 1402.5768395867533,
            "rating_q975": 1409.5733283630843,
            "rating_q025": 1395.5803508104223
        },
        "longcat-flash-chat": {
            "rating": 1401.707039666213,
            "rating_q975": 1414.6941850183991,
            "rating_q025": 1388.7198943140268
        },
        "deepseek-v3.1": {
            "rating": 1401.1820800939383,
            "rating_q975": 1412.9357705694279,
            "rating_q025": 1389.4283896184488
        },
        "gpt-5-high": {
            "rating": 1401.0900133202742,
            "rating_q975": 1410.4342769371958,
            "rating_q025": 1391.7457497033527
        },
        "claude-haiku-4-5-20251001": {
            "rating": 1400.7845931890417,
            "rating_q975": 1415.4889031207758,
            "rating_q025": 1386.0802832573077
        },
        "qwen3-235b-a22b-no-thinking": {
            "rating": 1397.7753657007072,
            "rating_q975": 1405.727312807872,
            "rating_q025": 1389.8234185935423
        },
        "gpt-4.1-2025-04-14": {
            "rating": 1396.7758424093288,
            "rating_q975": 1404.0019410283055,
            "rating_q025": 1389.549743790352
        },
        "gemini-2.5-flash-preview-09-2025": {
            "rating": 1394.6649006980983,
            "rating_q975": 1407.0719295626752,
            "rating_q025": 1382.2578718335214
        },
        "claude-opus-4-20250514-thinking-16k": {
            "rating": 1393.0408430602095,
            "rating_q975": 1401.2806357670222,
            "rating_q025": 1384.8010503533967
        },
        "deepseek-r1": {
            "rating": 1389.720649506472,
            "rating_q975": 1401.4634606185405,
            "rating_q025": 1377.9778383944035
        },
        "deepseek-v3.1-terminus": {
            "rating": 1388.7939895604106,
            "rating_q975": 1411.1403806908338,
            "rating_q025": 1366.4475984299875
        },
        "deepseek-v3-0324": {
            "rating": 1386.9358215879872,
            "rating_q975": 1394.2087501901224,
            "rating_q025": 1379.662892985852
        },
        "hunyuan-t1-20250711": {
            "rating": 1386.8362925535944,
            "rating_q975": 1408.6168951207057,
            "rating_q025": 1365.055689986483
        },
        "hunyuan-turbos-20250416": {
            "rating": 1385.2113322188802,
            "rating_q975": 1399.2514292359435,
            "rating_q025": 1371.171235201817
        },
        "qwen3-vl-235b-a22b-thinking": {
            "rating": 1383.659529518451,
            "rating_q975": 1400.2274733824383,
            "rating_q025": 1367.0915856544639
        },
        "claude-opus-4-20250514": {
            "rating": 1383.5382999372216,
            "rating_q975": 1391.2455648684224,
            "rating_q025": 1375.8310350060208
        },
        "mai-1-preview": {
            "rating": 1382.9728673082848,
            "rating_q975": 1394.3885125305558,
            "rating_q025": 1371.5572220860138
        },
        "mistral-medium-2505": {
            "rating": 1382.224691508509,
            "rating_q975": 1390.5245279818282,
            "rating_q025": 1373.92485503519
        },
        "qwen3-30b-a3b-instruct-2507": {
            "rating": 1382.0483116426678,
            "rating_q975": 1391.6293495346245,
            "rating_q025": 1372.4672737507112
        },
        "glm-4.5-air": {
            "rating": 1373.121856258257,
            "rating_q975": 1382.1611299719207,
            "rating_q025": 1364.0825825445932
        },
        "claude-sonnet-4-20250514-thinking-32k": {
            "rating": 1372.3318454675643,
            "rating_q975": 1380.6699503275242,
            "rating_q025": 1363.9937406076044
        },
        "kimi-k2-0711-preview": {
            "rating": 1371.8413497284678,
            "rating_q975": 1380.9948649970636,
            "rating_q025": 1362.687834459872
        },
        "o1-preview": {
            "rating": 1367.6133901671587,
            "rating_q975": 1376.6533523006406,
            "rating_q025": 1358.573428033677
        },
        "kimi-k2-0905-preview": {
            "rating": 1366.938807626849,
            "rating_q975": 1380.7494794894492,
            "rating_q025": 1353.1281357642488
        },
        "gemini-2.5-flash-lite-preview-09-2025-no-thinking": {
            "rating": 1366.3823438353065,
            "rating_q975": 1378.8702622971718,
            "rating_q025": 1353.8944253734412
        },
        "qwen2.5-max": {
            "rating": 1363.7160379763995,
            "rating_q975": 1372.0785878160052,
            "rating_q025": 1355.3534881367939
        },
        "gpt-5-mini-high": {
            "rating": 1363.6466819926156,
            "rating_q975": 1373.516337230454,
            "rating_q025": 1353.7770267547774
        },
        "qwen3-coder-480b-a35b-instruct": {
            "rating": 1363.2962089340517,
            "rating_q975": 1373.1294925395857,
            "rating_q025": 1353.4629253285177
        },
        "qwen3-235b-a22b": {
            "rating": 1361.57879935295,
            "rating_q975": 1370.8152420029398,
            "rating_q025": 1352.3423567029602
        },
        "claude-sonnet-4-20250514": {
            "rating": 1360.7442096785185,
            "rating_q975": 1368.6317595458609,
            "rating_q025": 1352.856659811176
        },
        "gemini-2.5-flash-lite-preview-06-17-thinking": {
            "rating": 1360.1270006045015,
            "rating_q975": 1368.4952432714088,
            "rating_q025": 1351.7587579375943
        },
        "o1-2024-12-17": {
            "rating": 1354.2127435105142,
            "rating_q975": 1363.1689431725895,
            "rating_q025": 1345.256543848439
        },
        "grok-3-mini-high": {
            "rating": 1353.8047342941904,
            "rating_q975": 1364.8919961502843,
            "rating_q025": 1342.7174724380966
        },
        "gpt-4.1-mini-2025-04-14": {
            "rating": 1352.6233954845022,
            "rating_q975": 1360.3002423146556,
            "rating_q025": 1344.9465486543488
        },
        "grok-3-mini-beta": {
            "rating": 1351.356987143298,
            "rating_q975": 1360.9913210295483,
            "rating_q025": 1341.7226532570478
        },
        "o4-mini-2025-04-16": {
            "rating": 1350.0845812793484,
            "rating_q975": 1357.3969538748615,
            "rating_q025": 1342.7722086838353
        },
        "deepseek-v3": {
            "rating": 1348.1680086354406,
            "rating_q975": 1357.7388683467618,
            "rating_q025": 1338.5971489241194
        },
        "gemma-3-27b-it": {
            "rating": 1345.3392859085761,
            "rating_q975": 1352.7467230332204,
            "rating_q025": 1337.9318487839319
        },
        "mistral-small-2506": {
            "rating": 1345.1935638012237,
            "rating_q975": 1355.828707632626,
            "rating_q025": 1334.5584199698214
        },
        "amazon-nova-experimental-chat-10-09": {
            "rating": 1344.4751599812992,
            "rating_q975": 1363.6016521077765,
            "rating_q025": 1325.3486678548218
        },
        "qwen3-next-80b-a3b-thinking": {
            "rating": 1339.618012553127,
            "rating_q975": 1352.3080135992127,
            "rating_q025": 1326.9280115070414
        },
        "command-a-03-2025": {
            "rating": 1339.18935876737,
            "rating_q975": 1346.1172269677452,
            "rating_q025": 1332.261490566995
        },
        "minimax-m1": {
            "rating": 1337.005281032431,
            "rating_q975": 1345.2392272303364,
            "rating_q025": 1328.7713348345255
        },
        "step-1o-turbo-202506": {
            "rating": 1336.2878769891302,
            "rating_q975": 1352.142879011456,
            "rating_q025": 1320.4328749668043
        },
        "claude-3-7-sonnet-20250219-thinking-32k": {
            "rating": 1336.2583092072477,
            "rating_q975": 1344.3107973583399,
            "rating_q025": 1328.2058210561556
        },
        "qwen-plus-0125": {
            "rating": 1336.1321370694209,
            "rating_q975": 1355.201964057583,
            "rating_q025": 1317.0623100812588
        },
        "step-3": {
            "rating": 1335.944048211919,
            "rating_q975": 1353.6231846618311,
            "rating_q025": 1318.2649117620067
        },
        "glm-4.5v": {
            "rating": 1334.1928450321734,
            "rating_q975": 1354.1524789131645,
            "rating_q025": 1314.2332111511823
        },
        "gemma-3-12b-it": {
            "rating": 1333.9618516677278,
            "rating_q975": 1359.9788188837615,
            "rating_q025": 1307.9448844516942
        },
        "gpt-oss-120b": {
            "rating": 1331.1652071081237,
            "rating_q975": 1340.4760830782343,
            "rating_q025": 1321.854331138013
        },
        "qwen3-32b": {
            "rating": 1330.6264818046634,
            "rating_q975": 1353.8836715067932,
            "rating_q025": 1307.3692921025336
        },
        "nvidia-llama-3.3-nemotron-super-49b-v1.5": {
            "rating": 1328.836806944392,
            "rating_q975": 1352.5772219981204,
            "rating_q025": 1305.0963918906637
        },
        "ling-flash-2.0": {
            "rating": 1328.7638113040496,
            "rating_q975": 1345.9464102909785,
            "rating_q025": 1311.5812123171206
        },
        "claude-3-5-sonnet-20241022": {
            "rating": 1325.6769263563124,
            "rating_q975": 1330.9678112903819,
            "rating_q025": 1320.386041422243
        },
        "glm-4-plus-0111": {
            "rating": 1322.9156215048051,
            "rating_q975": 1342.254886885381,
            "rating_q025": 1303.5763561242293
        },
        "o3-mini-high": {
            "rating": 1319.740583164325,
            "rating_q975": 1331.384011561265,
            "rating_q025": 1308.097154767385
        },
        "llama-3.1-nemotron-ultra-253b-v1": {
            "rating": 1316.9109792736067,
            "rating_q975": 1347.3801392048927,
            "rating_q025": 1286.4418193423207
        },
        "hunyuan-turbos-20250226": {
            "rating": 1316.3533003813452,
            "rating_q975": 1349.733787440875,
            "rating_q025": 1282.9728133218155
        },
        "qwq-32b": {
            "rating": 1313.9640382395082,
            "rating_q975": 1323.4362899230557,
            "rating_q025": 1304.4917865559607
        },
        "llama-3.3-nemotron-49b-super-v1": {
            "rating": 1313.4019366655186,
            "rating_q975": 1345.7281948925133,
            "rating_q025": 1281.075678438524
        },
        "gpt-5-nano-high": {
            "rating": 1313.2145232278492,
            "rating_q975": 1328.8193158169627,
            "rating_q025": 1297.6097306387358
        },
        "o1-mini": {
            "rating": 1312.8175005781047,
            "rating_q975": 1319.8158825467808,
            "rating_q025": 1305.8191186094286
        },
        "o3-mini": {
            "rating": 1311.7396677248848,
            "rating_q975": 1318.292600812715,
            "rating_q025": 1305.1867346370548
        },
        "yi-lightning": {
            "rating": 1311.0058125555906,
            "rating_q975": 1320.6198371380963,
            "rating_q025": 1301.391787973085
        },
        "qwen3-30b-a3b": {
            "rating": 1309.0426278797818,
            "rating_q975": 1318.1359515999902,
            "rating_q025": 1299.9493041595733
        },
        "gemini-2.0-flash-lite-preview-02-05": {
            "rating": 1306.7745083169002,
            "rating_q975": 1316.3118827979667,
            "rating_q025": 1297.2371338358337
        },
        "hunyuan-turbo-0110": {
            "rating": 1302.98033038572,
            "rating_q975": 1332.704040453469,
            "rating_q025": 1273.256620317971
        },
        "gpt-4o-2024-05-13": {
            "rating": 1300.8394855991855,
            "rating_q975": 1307.0775044344398,
            "rating_q025": 1294.6014667639313
        },
        "claude-3-5-sonnet-20240620": {
            "rating": 1298.9939639772242,
            "rating_q975": 1305.7596942536989,
            "rating_q025": 1292.2282337007496
        },
        "qwen2.5-plus-1127": {
            "rating": 1297.933049534418,
            "rating_q975": 1311.0350998083543,
            "rating_q025": 1284.8309992604816
        },
        "deepseek-v2.5-1210": {
            "rating": 1296.7509866376154,
            "rating_q975": 1312.9348487177695,
            "rating_q025": 1280.5671245574613
        },
        "llama-3.1-405b-instruct-bf16": {
            "rating": 1296.4083009049386,
            "rating_q975": 1303.7060200261503,
            "rating_q025": 1289.110581783727
        },
        "gemini-1.5-pro-002": {
            "rating": 1295.9257628415157,
            "rating_q975": 1302.4496145467233,
            "rating_q025": 1289.4019111363082
        },
        "step-2-16k-exp-202412": {
            "rating": 1291.8436609145526,
            "rating_q975": 1311.7473794853322,
            "rating_q025": 1271.939942343773
        },
        "grok-2-2024-08-13": {
            "rating": 1289.943219043228,
            "rating_q975": 1296.6378088383851,
            "rating_q025": 1283.248629248071
        },
        "ring-flash-2.0": {
            "rating": 1289.900900152943,
            "rating_q975": 1307.3289733665229,
            "rating_q025": 1272.4728269393631
        },
        "glm-4-plus": {
            "rating": 1288.4665499655896,
            "rating_q975": 1297.624738717534,
            "rating_q025": 1279.3083612136452
        },
        "llama-4-maverick-17b-128e-instruct": {
            "rating": 1287.894076782905,
            "rating_q975": 1295.7639171333915,
            "rating_q025": 1280.0242364324183
        },
        "llama-3.1-405b-instruct-fp8": {
            "rating": 1286.886808735514,
            "rating_q975": 1293.6778445153923,
            "rating_q025": 1280.0957729556358
        },
        "athene-v2-chat": {
            "rating": 1285.0183508152177,
            "rating_q975": 1293.950997504151,
            "rating_q025": 1276.0857041262843
        },
        "gpt-4o-mini-2024-07-18": {
            "rating": 1284.015846074563,
            "rating_q975": 1290.263556026354,
            "rating_q025": 1277.7681361227717
        },
        "hunyuan-large-2025-02-10": {
            "rating": 1283.420233047887,
            "rating_q975": 1308.834921152766,
            "rating_q025": 1258.005544943008
        },
        "llama-4-scout-17b-16e-instruct": {
            "rating": 1282.725441475261,
            "rating_q975": 1291.472167167906,
            "rating_q025": 1273.978715782616
        },
        "llama-3.3-70b-instruct": {
            "rating": 1280.7326761115887,
            "rating_q975": 1287.0910328266941,
            "rating_q025": 1274.3743193964833
        },
        "gpt-4o-2024-08-06": {
            "rating": 1278.4903815959524,
            "rating_q975": 1286.0403620160275,
            "rating_q025": 1270.9404011758772
        },
        "gemma-3n-e4b-it": {
            "rating": 1277.2932714894596,
            "rating_q975": 1287.6401993178272,
            "rating_q025": 1266.946343661092
        },
        "gpt-4.1-nano-2025-04-14": {
            "rating": 1276.964832913682,
            "rating_q975": 1295.11143502646,
            "rating_q025": 1258.8182308009038
        },
        "qwen-max-0919": {
            "rating": 1275.985018641326,
            "rating_q975": 1286.7914599032747,
            "rating_q025": 1265.1785773793772
        },
        "llama-3.1-nemotron-70b-instruct": {
            "rating": 1275.2450469318733,
            "rating_q975": 1291.8340209925666,
            "rating_q025": 1258.65607287118
        },
        "hunyuan-standard-2025-02-10": {
            "rating": 1274.7768031517758,
            "rating_q975": 1298.735002358818,
            "rating_q025": 1250.8186039447335
        },
        "claude-3-opus-20240229": {
            "rating": 1274.7389716648163,
            "rating_q975": 1280.410759293024,
            "rating_q025": 1269.0671840366085
        },
        "magistral-medium-2506": {
            "rating": 1274.4816517886502,
            "rating_q975": 1289.4880345589686,
            "rating_q025": 1259.4752690183318
        },
        "mistral-small-3.1-24b-instruct-2503": {
            "rating": 1271.8299864074152,
            "rating_q975": 1280.5163436953355,
            "rating_q025": 1263.1436291194948
        },
        "qwen2.5-72b-instruct": {
            "rating": 1271.5954778509463,
            "rating_q975": 1279.1228054704943,
            "rating_q025": 1264.0681502313982
        },
        "gemini-advanced-0514": {
            "rating": 1268.7855725310078,
            "rating_q975": 1278.064578517365,
            "rating_q025": 1259.5065665446507
        },
        "gpt-oss-20b": {
            "rating": 1268.6264624542964,
            "rating_q975": 1282.9720084518967,
            "rating_q025": 1254.280916456696
        },
        "gemini-1.5-pro-001": {
            "rating": 1267.0763858441965,
            "rating_q975": 1274.508613512711,
            "rating_q025": 1259.644158175682
        },
        "gpt-4-turbo-2024-04-09": {
            "rating": 1266.4407994696026,
            "rating_q975": 1273.5320439876518,
            "rating_q025": 1259.3495549515533
        },
        "grok-2-mini-2024-08-13": {
            "rating": 1265.2329930116937,
            "rating_q975": 1272.2527865123154,
            "rating_q025": 1258.213199511072
        },
        "claude-3-5-haiku-20241022": {
            "rating": 1264.051635826292,
            "rating_q975": 1270.0615158106195,
            "rating_q025": 1258.0417558419647
        },
        "deepseek-v2.5": {
            "rating": 1260.2516821507902,
            "rating_q975": 1269.6009143466306,
            "rating_q025": 1250.9024499549498
        },
        "mistral-large-2411": {
            "rating": 1259.920987457188,
            "rating_q975": 1268.634555936619,
            "rating_q025": 1251.2074189777568
        },
        "mistral-large-2407": {
            "rating": 1256.8806752955638,
            "rating_q975": 1264.4440987148798,
            "rating_q025": 1249.3172518762478
        },
        "gpt-4-1106-preview": {
            "rating": 1256.2104302696252,
            "rating_q975": 1263.6575253969518,
            "rating_q025": 1248.7633351422987
        },
        "athene-70b-0725": {
            "rating": 1256.1831768276102,
            "rating_q975": 1266.807638839704,
            "rating_q025": 1245.5587148155164
        },
        "llama-3.1-70b-instruct": {
            "rating": 1256.071267612505,
            "rating_q975": 1262.8729235719175,
            "rating_q025": 1249.2696116530924
        },
        "gemma-3-4b-it": {
            "rating": 1254.7764322899093,
            "rating_q975": 1278.4917785248153,
            "rating_q025": 1231.0610860550032
        },
        "gemini-1.5-flash-002": {
            "rating": 1252.2737368575622,
            "rating_q975": 1260.2296839210653,
            "rating_q025": 1244.317789794059
        },
        "hunyuan-large-vision": {
            "rating": 1252.2489309350883,
            "rating_q975": 1272.0318614231483,
            "rating_q025": 1232.4660004470284
        },
        "llama-3.1-tulu-3-70b": {
            "rating": 1251.3632600867145,
            "rating_q975": 1274.637832854994,
            "rating_q025": 1228.088687318435
        },
        "gpt-4-0125-preview": {
            "rating": 1250.320756863018,
            "rating_q975": 1257.816898801293,
            "rating_q025": 1242.824614924743
        },
        "amazon-nova-pro-v1.0": {
            "rating": 1245.5423363530629,
            "rating_q975": 1254.5945682284473,
            "rating_q025": 1236.4901044776784
        },
        "gemini-1.5-flash-001": {
            "rating": 1227.320762175446,
            "rating_q975": 1234.9270808814074,
            "rating_q025": 1219.7144434694844
        },
        "claude-3-sonnet-20240229": {
            "rating": 1226.5908892911043,
            "rating_q975": 1234.2389220633218,
            "rating_q025": 1218.9428565188869
        },
        "llama-3.1-nemotron-51b-instruct": {
            "rating": 1226.1746335806124,
            "rating_q975": 1246.3070426027336,
            "rating_q025": 1206.0422245584912
        },
        "reka-core-20240904": {
            "rating": 1225.8455550384965,
            "rating_q975": 1241.9562148373386,
            "rating_q025": 1209.7348952396544
        },
        "gemma-2-27b-it": {
            "rating": 1223.7716746282363,
            "rating_q975": 1229.8658976601848,
            "rating_q025": 1217.6774515962877
        },
        "llama-3-70b-instruct": {
            "rating": 1222.6307604961657,
            "rating_q975": 1229.6650529654887,
            "rating_q025": 1215.5964680268428
        },
        "olmo-2-0325-32b-instruct": {
            "rating": 1221.55505768194,
            "rating_q975": 1251.0797290056412,
            "rating_q025": 1192.030386358239
        },
        "qwen2.5-coder-32b-instruct": {
            "rating": 1221.3859440925776,
            "rating_q975": 1239.1481912784484,
            "rating_q025": 1203.6236969067068
        },
        "jamba-1.5-large": {
            "rating": 1220.3576772879933,
            "rating_q975": 1234.6527086947483,
            "rating_q025": 1206.0626458812383
        },
        "gemma-2-9b-it-simpo": {
            "rating": 1219.6686112631396,
            "rating_q975": 1234.0089639072146,
            "rating_q025": 1205.3282586190646
        },
        "glm-4-0520": {
            "rating": 1217.3157629712045,
            "rating_q975": 1231.830947191591,
            "rating_q025": 1202.8005787508182
        },
        "mistral-small-24b-instruct-2501": {
            "rating": 1216.8531345831693,
            "rating_q975": 1229.6125224333691,
            "rating_q025": 1204.0937467329695
        },
        "nemotron-4-340b-instruct": {
            "rating": 1214.079694281573,
            "rating_q975": 1225.3221674605545,
            "rating_q025": 1202.8372211025915
        },
        "command-r-plus-08-2024": {
            "rating": 1212.5387197245361,
            "rating_q975": 1225.9918015455148,
            "rating_q025": 1199.0856379035574
        },
        "phi-4": {
            "rating": 1205.4273951242255,
            "rating_q975": 1215.4604253621249,
            "rating_q025": 1195.3943648863262
        },
        "gpt-4-0314": {
            "rating": 1204.45501103278,
            "rating_q975": 1214.0603610791939,
            "rating_q025": 1194.8496609863662
        },
        "amazon-nova-lite-v1.0": {
            "rating": 1198.5613578709206,
            "rating_q975": 1208.9060386539898,
            "rating_q025": 1188.2166770878514
        },
        "qwen2-72b-instruct": {
            "rating": 1194.7988428765548,
            "rating_q975": 1203.696332025879,
            "rating_q025": 1185.9013537272306
        },
        "gemma-2-9b-it": {
            "rating": 1193.25872013578,
            "rating_q975": 1200.1337334506966,
            "rating_q025": 1186.3837068208636
        },
        "command-r-plus": {
            "rating": 1192.0199686282053,
            "rating_q975": 1200.1730466328993,
            "rating_q025": 1183.8668906235114
        },
        "claude-3-haiku-20240307": {
            "rating": 1189.987953083018,
            "rating_q975": 1196.8499160185268,
            "rating_q025": 1183.1259901475094
        },
        "c4ai-aya-expanse-32b": {
            "rating": 1189.4198882662515,
            "rating_q975": 1198.202457285577,
            "rating_q025": 1180.637319246926
        },
        "reka-flash-20240904": {
            "rating": 1188.2043164868744,
            "rating_q975": 1204.0324529051315,
            "rating_q025": 1172.3761800686173
        },
        "gemini-1.5-flash-8b-001": {
            "rating": 1185.2374894147702,
            "rating_q975": 1193.3289416804807,
            "rating_q025": 1177.1460371490596
        },
        "gpt-4-0613": {
            "rating": 1183.6270670421945,
            "rating_q975": 1191.6841918325474,
            "rating_q025": 1175.5699422518417
        },
        "amazon-nova-micro-v1.0": {
            "rating": 1178.9584152572766,
            "rating_q975": 1189.5379477513084,
            "rating_q025": 1168.3788827632447
        },
        "deepseek-coder-v2": {
            "rating": 1176.324414969688,
            "rating_q975": 1188.5817652113647,
            "rating_q025": 1164.0670647280112
        },
        "hunyuan-standard-256k": {
            "rating": 1174.852591525519,
            "rating_q975": 1199.7222434035218,
            "rating_q025": 1149.9829396475163
        },
        "llama-3.1-8b-instruct": {
            "rating": 1171.577123508664,
            "rating_q975": 1178.9152441969377,
            "rating_q025": 1164.2390028203904
        },
        "mistral-large-2402": {
            "rating": 1171.2354018940412,
            "rating_q975": 1180.157194319732,
            "rating_q025": 1162.3136094683503
        },
        "ministral-8b-2410": {
            "rating": 1166.0544723111702,
            "rating_q975": 1184.8461454778483,
            "rating_q025": 1147.2627991444922
        },
        "command-r-08-2024": {
            "rating": 1162.8063306302402,
            "rating_q975": 1176.3006404071728,
            "rating_q025": 1149.3120208533076
        },
        "qwen1.5-110b-chat": {
            "rating": 1160.1319574386248,
            "rating_q975": 1171.3643970222015,
            "rating_q025": 1148.899517855048
        },
        "qwen1.5-72b-chat": {
            "rating": 1159.6650495788872,
            "rating_q975": 1169.742967260655,
            "rating_q025": 1149.5871318971194
        },
        "c4ai-aya-expanse-8b": {
            "rating": 1159.4588304134966,
            "rating_q975": 1173.6885193212267,
            "rating_q025": 1145.2291415057664
        },
        "jamba-1.5-mini": {
            "rating": 1157.3245925599258,
            "rating_q975": 1171.7646230556193,
            "rating_q025": 1142.8845620642323
        },
        "llama-3.1-tulu-3-8b": {
            "rating": 1152.4941155403408,
            "rating_q975": 1177.8969647660601,
            "rating_q025": 1127.0912663146214
        },
        "llama-3-8b-instruct": {
            "rating": 1152.0476360828463,
            "rating_q975": 1159.8293800479707,
            "rating_q025": 1144.265892117722
        },
        "yi-1.5-34b-chat": {
            "rating": 1151.9382394296874,
            "rating_q975": 1162.9672766994918,
            "rating_q025": 1140.909202159883
        },
        "reka-flash-21b-20240226-online": {
            "rating": 1150.8012037337626,
            "rating_q975": 1165.491536282784,
            "rating_q025": 1136.1108711847412
        },
        "command-r": {
            "rating": 1147.9881662224789,
            "rating_q975": 1157.1634943683598,
            "rating_q025": 1138.812838076598
        },
        "mistral-medium": {
            "rating": 1147.1054370277961,
            "rating_q975": 1158.1934015018805,
            "rating_q025": 1136.0174725537117
        },
        "gemini-pro": {
            "rating": 1141.7119136764272,
            "rating_q975": 1166.583703287646,
            "rating_q025": 1116.8401240652086
        },
        "qwq-32b-preview": {
            "rating": 1141.2870259790702,
            "rating_q975": 1168.5255107082799,
            "rating_q025": 1114.0485412498606
        },
        "reka-flash-21b-20240226": {
            "rating": 1141.2274204216428,
            "rating_q975": 1153.0514296875679,
            "rating_q025": 1129.4034111557178
        },
        "qwen1.5-32b-chat": {
            "rating": 1139.6412472749882,
            "rating_q975": 1151.7178319109303,
            "rating_q025": 1127.5646626390462
        },
        "internlm2_5-20b-chat": {
            "rating": 1136.1325171789156,
            "rating_q975": 1150.5458829037975,
            "rating_q025": 1121.7191514540336
        },
        "mixtral-8x22b-instruct-v0.1": {
            "rating": 1128.9489686890065,
            "rating_q975": 1137.643302803978,
            "rating_q025": 1120.254634574035
        },
        "gemini-pro-dev-api": {
            "rating": 1124.145887411241,
            "rating_q975": 1138.5928677139057,
            "rating_q025": 1109.6989071085761
        },
        "gemma-2-2b-it": {
            "rating": 1118.05069261552,
            "rating_q975": 1125.809315703289,
            "rating_q025": 1110.2920695277508
        },
        "gpt-3.5-turbo-0125": {
            "rating": 1117.2405689182388,
            "rating_q975": 1125.5654658018163,
            "rating_q025": 1108.9156720346612
        },
        "mixtral-8x7b-instruct-v0.1": {
            "rating": 1114.8929486360084,
            "rating_q975": 1123.2124112445313,
            "rating_q025": 1106.5734860274856
        },
        "yi-34b-chat": {
            "rating": 1112.7611296711125,
            "rating_q975": 1127.470083686409,
            "rating_q025": 1098.052175655816
        },
        "dbrx-instruct-preview": {
            "rating": 1111.004699591408,
            "rating_q975": 1122.475582254112,
            "rating_q025": 1099.5338169287043
        },
        "starling-lm-7b-beta": {
            "rating": 1110.5382529708922,
            "rating_q975": 1125.4373151519385,
            "rating_q025": 1095.639190789846
        },
        "qwen1.5-14b-chat": {
            "rating": 1109.902778416722,
            "rating_q975": 1124.0107608188234,
            "rating_q025": 1095.7947960146205
        },
        "granite-3.1-8b-instruct": {
            "rating": 1109.5183160630318,
            "rating_q975": 1135.4077392959514,
            "rating_q025": 1083.6288928301121
        },
        "wizardlm-70b": {
            "rating": 1109.0901698952014,
            "rating_q975": 1128.5131547927704,
            "rating_q025": 1089.6671849976324
        },
        "llama-3.2-3b-instruct": {
            "rating": 1105.1279209062832,
            "rating_q975": 1121.9382607409516,
            "rating_q025": 1088.3175810716148
        },
        "zephyr-orpo-141b-A35b-v0.1": {
            "rating": 1100.8836483410528,
            "rating_q975": 1125.034674262921,
            "rating_q025": 1076.7326224191845
        },
        "granite-3.1-2b-instruct": {
            "rating": 1099.9431211321307,
            "rating_q975": 1127.1648548778996,
            "rating_q025": 1072.7213873863618
        },
        "openchat-3.5-0106": {
            "rating": 1090.5158249979943,
            "rating_q975": 1105.4437438979912,
            "rating_q025": 1075.5879060979973
        },
        "llama-2-70b-chat": {
            "rating": 1088.2192421848886,
            "rating_q975": 1098.5042239713123,
            "rating_q025": 1077.9342603984649
        },
        "phi-3-medium-4k-instruct": {
            "rating": 1087.4162734430533,
            "rating_q975": 1098.1308982515059,
            "rating_q025": 1076.7016486346008
        },
        "tulu-2-dpo-70b": {
            "rating": 1086.097161260317,
            "rating_q975": 1107.3939169655341,
            "rating_q025": 1064.8004055551
        },
        "starling-lm-7b-alpha": {
            "rating": 1085.599673597209,
            "rating_q975": 1102.980313628686,
            "rating_q025": 1068.219033565732
        },
        "openchat-3.5": {
            "rating": 1085.3980953211808,
            "rating_q975": 1104.0860169646862,
            "rating_q025": 1066.7101736776754
        },
        "deepseek-llm-67b-chat": {
            "rating": 1081.6478146476766,
            "rating_q975": 1105.8592093271373,
            "rating_q025": 1057.436419968216
        },
        "nous-hermes-2-mixtral-8x7b-dpo": {
            "rating": 1081.172444267776,
            "rating_q975": 1107.2186061671607,
            "rating_q025": 1055.1262823683912
        },
        "vicuna-33b": {
            "rating": 1080.6148089173662,
            "rating_q975": 1093.4457913495617,
            "rating_q025": 1067.7838264851707
        },
        "gpt-3.5-turbo-1106": {
            "rating": 1078.8281821542273,
            "rating_q975": 1094.6034230670268,
            "rating_q025": 1063.0529412414278
        },
        "snowflake-arctic-instruct": {
            "rating": 1072.1613380136173,
            "rating_q975": 1084.5021546404105,
            "rating_q025": 1059.820521386824
        },
        "phi-3-small-8k-instruct": {
            "rating": 1067.2452058116314,
            "rating_q975": 1079.2311870443668,
            "rating_q025": 1055.259224578896
        },
        "openhermes-2.5-mistral-7b": {
            "rating": 1064.3989120190784,
            "rating_q975": 1087.1338036357963,
            "rating_q025": 1041.6640204023604
        },
        "mistral-7b-instruct-v0.2": {
            "rating": 1063.5702607376677,
            "rating_q975": 1076.5548319920242,
            "rating_q025": 1050.5856894833112
        },
        "granite-3.0-8b-instruct": {
            "rating": 1063.5329353363454,
            "rating_q975": 1083.146058342708,
            "rating_q025": 1043.9198123299827
        },
        "qwen1.5-7b-chat": {
            "rating": 1061.4990649792749,
            "rating_q975": 1086.6680538314863,
            "rating_q025": 1036.3300761270634
        },
        "llama2-70b-steerlm-chat": {
            "rating": 1061.1859093123612,
            "rating_q975": 1089.6460631039677,
            "rating_q025": 1032.7257555207548
        },
        "mpt-30b-chat": {
            "rating": 1055.762854034849,
            "rating_q975": 1088.2587316482147,
            "rating_q025": 1023.2669764214832
        },
        "granite-3.0-2b-instruct": {
            "rating": 1054.426060968076,
            "rating_q975": 1073.339138129199,
            "rating_q025": 1035.512983806953
        },
        "llama-2-13b-chat": {
            "rating": 1050.6548085486347,
            "rating_q975": 1064.4196431775665,
            "rating_q025": 1036.889973919703
        },
        "phi-3-mini-4k-instruct-june-2024": {
            "rating": 1047.9157711364555,
            "rating_q975": 1062.4720709008345,
            "rating_q025": 1033.3594713720765
        },
        "solar-10.7b-instruct-v1.0": {
            "rating": 1046.5302305459331,
            "rating_q975": 1071.7259846081363,
            "rating_q025": 1021.33447648373
        },
        "wizardlm-13b": {
            "rating": 1045.5142131988846,
            "rating_q975": 1065.5852540521632,
            "rating_q025": 1025.443172345606
        },
        "gemma-1.1-7b-it": {
            "rating": 1039.8175366275123,
            "rating_q975": 1051.2488621934351,
            "rating_q025": 1028.3862110615894
        },
        "zephyr-7b-beta": {
            "rating": 1037.9503358962502,
            "rating_q975": 1055.5117762382433,
            "rating_q025": 1020.3888955542571
        },
        "vicuna-13b": {
            "rating": 1031.4217253481193,
            "rating_q975": 1045.3946322673792,
            "rating_q025": 1017.4488184288592
        },
        "llama-3.2-1b-instruct": {
            "rating": 1030.9135112223785,
            "rating_q975": 1049.3757695963309,
            "rating_q025": 1012.4512528484262
        },
        "llama-2-7b-chat": {
            "rating": 1028.7289873519574,
            "rating_q975": 1043.7101619752243,
            "rating_q025": 1013.7478127286904
        },
        "dolphin-2.2.1-mistral-7b": {
            "rating": 1020.8713786766589,
            "rating_q975": 1062.8908075506843,
            "rating_q025": 978.8519498026335
        },
        "qwen-14b-chat": {
            "rating": 1020.6316115987863,
            "rating_q975": 1044.0901406124035,
            "rating_q025": 997.173082585169
        },
        "phi-3-mini-4k-instruct": {
            "rating": 1018.6474699147332,
            "rating_q975": 1031.781449151625,
            "rating_q025": 1005.5134906778412
        },
        "codellama-34b-instruct": {
            "rating": 1015.7794720998324,
            "rating_q975": 1034.1803105572942,
            "rating_q025": 997.3786336423707
        },
        "zephyr-7b-alpha": {
            "rating": 1015.7755256207706,
            "rating_q975": 1051.0351309923124,
            "rating_q025": 980.5159202492289
        },
        "falcon-180b-chat": {
            "rating": 1012.8601888030712,
            "rating_q975": 1053.9383747590487,
            "rating_q025": 971.7820028470937
        },
        "mistral-7b-instruct": {
            "rating": 1009.982850448285,
            "rating_q975": 1029.2923278477308,
            "rating_q025": 990.6733730488393
        },
        "stripedhyena-nous-7b": {
            "rating": 1009.6423903943596,
            "rating_q975": 1032.702970055809,
            "rating_q025": 986.5818107329102
        },
        "guanaco-33b": {
            "rating": 1007.7010340898553,
            "rating_q975": 1041.9286700566308,
            "rating_q025": 973.4733981230796
        },
        "olmo-7b-instruct": {
            "rating": 1004.6424638989088,
            "rating_q975": 1032.3800180372182,
            "rating_q025": 976.9049097605995
        },
        "palm-2": {
            "rating": 995.0618967244602,
            "rating_q975": 1014.7395202576998,
            "rating_q025": 975.3842731912206
        },
        "smollm2-1.7b-instruct": {
            "rating": 993.379811301972,
            "rating_q975": 1032.3010679815438,
            "rating_q025": 954.4585546224002
        },
        "phi-3-mini-128k-instruct": {
            "rating": 989.9936734500973,
            "rating_q975": 1005.3695155061873,
            "rating_q025": 974.6178313940072
        },
        "vicuna-7b": {
            "rating": 989.610880483054,
            "rating_q975": 1010.754230275072,
            "rating_q025": 968.4675306910359
        },
        "qwen1.5-4b-chat": {
            "rating": 977.5217340381747,
            "rating_q975": 996.2738406418332,
            "rating_q025": 958.7696274345162
        },
        "gemma-7b-it": {
            "rating": 963.7063046023297,
            "rating_q975": 982.436260752915,
            "rating_q025": 944.9763484517445
        },
        "chatglm3-6b": {
            "rating": 962.0323644969626,
            "rating_q975": 987.9647754115473,
            "rating_q025": 936.0999535823779
        },
        "gemma-1.1-2b-it": {
            "rating": 958.8489043570412,
            "rating_q975": 976.6161947914946,
            "rating_q025": 941.0816139225877
        },
        "gemma-2b-it": {
            "rating": 944.3040319195563,
            "rating_q975": 967.853014897995,
            "rating_q025": 920.7550489411177
        },
        "gpt4all-13b-snoozy": {
            "rating": 924.607278399024,
            "rating_q975": 963.5071377251351,
            "rating_q025": 885.707419072913
        },
        "koala-13b": {
            "rating": 922.379263804999,
            "rating_q975": 946.9774653631479,
            "rating_q025": 897.7810622468502
        },
        "chatglm2-6b": {
            "rating": 904.0287624551269,
            "rating_q975": 936.8036396961246,
            "rating_q025": 871.2538852141291
        },
        "mpt-7b-chat": {
            "rating": 903.023059567164,
            "rating_q975": 932.3734772860873,
            "rating_q025": 873.6726418482406
        },
        "RWKV-4-Raven-14B": {
            "rating": 895.751821713098,
            "rating_q975": 923.4137267704938,
            "rating_q025": 868.0899166557023
        },
        "alpaca-13b": {
            "rating": 886.235234694834,
            "rating_q975": 912.4098278095536,
            "rating_q025": 860.0606415801145
        },
        "oasst-pythia-12b": {
            "rating": 870.3643065031492,
            "rating_q975": 896.0821100874207,
            "rating_q025": 844.6465029188778
        },
        "chatglm-6b": {
            "rating": 856.8536735241034,
            "rating_q975": 886.6011376294932,
            "rating_q025": 827.1062094187137
        },
        "fastchat-t5-3b": {
            "rating": 853.2390103900814,
            "rating_q975": 883.9372738905779,
            "rating_q025": 822.5407468895849
        },
        "stablelm-tuned-alpha-7b": {
            "rating": 822.6151546147073,
            "rating_q975": 857.2605640593896,
            "rating_q025": 787.969745170025
        },
        "llama-13b": {
            "rating": 753.4506477110775,
            "rating_q975": 796.7188551242301,
            "rating_q025": 710.1824402979249
        },
        "dolly-v2-12b": {
            "rating": 740.5746114244658,
            "rating_q975": 776.6641841315031,
            "rating_q025": 704.4850387174286
        }
    },
    "no_refusal": {
        "gemini-2.5-pro": {
            "rating": 1464.694859229565,
            "rating_q975": 1468.6872328584777,
            "rating_q025": 1460.7024856006524
        },
        "glm-4.6": {
            "rating": 1444.9077388751523,
            "rating_q975": 1451.3273596646927,
            "rating_q025": 1438.4881180856119
        },
        "qwen3-max-preview": {
            "rating": 1436.915032862076,
            "rating_q975": 1441.7733514049805,
            "rating_q025": 1432.0567143191715
        },
        "deepseek-v3.2-exp": {
            "rating": 1431.5568721891827,
            "rating_q975": 1458.621641331813,
            "rating_q025": 1404.4921030465525
        },
        "mistral-medium-2508": {
            "rating": 1430.6748762990849,
            "rating_q975": 1435.3280392744532,
            "rating_q025": 1426.0217133237165
        },
        "glm-4.5": {
            "rating": 1427.03857988529,
            "rating_q975": 1431.9406438542896,
            "rating_q025": 1422.1365159162901
        },
        "chatgpt-4o-latest-20250326": {
            "rating": 1426.4226340237506,
            "rating_q975": 1430.2595085092607,
            "rating_q025": 1422.5857595382404
        },
        "claude-sonnet-4-5-20250929-thinking-32k": {
            "rating": 1426.1355582309538,
            "rating_q975": 1432.1084086224844,
            "rating_q025": 1420.1627078394233
        },
        "deepseek-r1-0528": {
            "rating": 1424.4611477978783,
            "rating_q975": 1430.0829130631073,
            "rating_q025": 1418.8393825326493
        },
        "grok-3-preview-02-24": {
            "rating": 1422.8930362299964,
            "rating_q975": 1427.127464720871,
            "rating_q025": 1418.6586077391216
        },
        "longcat-flash-chat": {
            "rating": 1422.1447121803803,
            "rating_q975": 1428.5717411295866,
            "rating_q025": 1415.717683231174
        },
        "qwen3-vl-235b-a22b-instruct": {
            "rating": 1421.4326350077117,
            "rating_q975": 1428.1358965301238,
            "rating_q025": 1414.7293734852997
        },
        "claude-sonnet-4-5-20250929": {
            "rating": 1420.3401088017583,
            "rating_q975": 1427.9028640221868,
            "rating_q025": 1412.7773535813299
        },
        "deepseek-v3.2-exp-thinking": {
            "rating": 1420.2980462976448,
            "rating_q975": 1426.905796171783,
            "rating_q025": 1413.6902964235064
        },
        "qwen3-next-80b-a3b-instruct": {
            "rating": 1419.4052394199432,
            "rating_q975": 1424.599134951528,
            "rating_q025": 1414.2113438883584
        },
        "claude-opus-4-1-20250805-thinking-16k": {
            "rating": 1419.1133211935214,
            "rating_q975": 1423.771467538077,
            "rating_q025": 1414.4551748489657
        },
        "deepseek-v3.1": {
            "rating": 1418.9378040807576,
            "rating_q975": 1424.996219317754,
            "rating_q025": 1412.8793888437613
        },
        "gpt-4.5-preview-2025-02-27": {
            "rating": 1418.6759356743614,
            "rating_q975": 1424.352610690547,
            "rating_q025": 1412.999260658176
        },
        "qwen3-235b-a22b-instruct-2507": {
            "rating": 1417.5393710786973,
            "rating_q975": 1421.9243724354358,
            "rating_q025": 1413.1543697219588
        },
        "deepseek-v3.1-terminus": {
            "rating": 1417.4071634868756,
            "rating_q975": 1427.068683577694,
            "rating_q025": 1407.7456433960572
        },
        "deepseek-v3.1-terminus-thinking": {
            "rating": 1415.8471793278043,
            "rating_q975": 1425.8469190562582,
            "rating_q025": 1405.8474395993503
        },
        "deepseek-v3.1-thinking": {
            "rating": 1415.735856149716,
            "rating_q975": 1422.3567666474921,
            "rating_q025": 1409.11494565194
        },
        "gemini-2.5-flash": {
            "rating": 1413.3911876450813,
            "rating_q975": 1417.2970684847235,
            "rating_q025": 1409.4853068054392
        },
        "qwen3-235b-a22b-thinking-2507": {
            "rating": 1412.9519633653101,
            "rating_q975": 1419.4110647795997,
            "rating_q025": 1406.4928619510206
        },
        "qwen3-max-2025-09-23": {
            "rating": 1412.8916482240877,
            "rating_q975": 1419.3548448383358,
            "rating_q025": 1406.4284516098396
        },
        "grok-4-0709": {
            "rating": 1412.3686091968846,
            "rating_q975": 1416.6821119745628,
            "rating_q025": 1408.0551064192064
        },
        "o3-2025-04-16": {
            "rating": 1411.034446840347,
            "rating_q975": 1414.8170214610975,
            "rating_q025": 1407.2518722195966
        },
        "claude-opus-4-1-20250805": {
            "rating": 1410.3282405072891,
            "rating_q975": 1414.7780287939286,
            "rating_q025": 1405.8784522206497
        },
        "gemini-2.5-flash-preview-09-2025": {
            "rating": 1407.400926927517,
            "rating_q975": 1413.0709107125058,
            "rating_q025": 1401.7309431425283
        },
        "grok-4-fast": {
            "rating": 1406.3354807020091,
            "rating_q975": 1413.9345507562668,
            "rating_q025": 1398.7364106477514
        },
        "gpt-5-high": {
            "rating": 1405.9635477143238,
            "rating_q975": 1410.6886462427985,
            "rating_q025": 1401.238449185849
        },
        "gpt-5-chat": {
            "rating": 1401.9676077728818,
            "rating_q975": 1406.5445198982857,
            "rating_q025": 1397.390695647478
        },
        "qwen3-vl-235b-a22b-thinking": {
            "rating": 1399.054887632305,
            "rating_q975": 1405.9121128809243,
            "rating_q025": 1392.1976623836858
        },
        "hunyuan-t1-20250711": {
            "rating": 1398.4857192378774,
            "rating_q975": 1407.1014897515106,
            "rating_q025": 1389.8699487242443
        },
        "mai-1-preview": {
            "rating": 1392.6018690000005,
            "rating_q975": 1398.0726053124206,
            "rating_q025": 1387.1311326875805
        },
        "qwen3-235b-a22b-no-thinking": {
            "rating": 1391.8489585690402,
            "rating_q975": 1396.3619374473724,
            "rating_q025": 1387.335979690708
        },
        "claude-haiku-4-5-20251001": {
            "rating": 1385.8624872191208,
            "rating_q975": 1392.2822656851324,
            "rating_q025": 1379.4427087531092
        },
        "qwen3-30b-a3b-instruct-2507": {
            "rating": 1384.58084969084,
            "rating_q975": 1389.5007233274298,
            "rating_q025": 1379.6609760542503
        },
        "gpt-4.1-2025-04-14": {
            "rating": 1383.5385860628019,
            "rating_q975": 1387.4427313280078,
            "rating_q025": 1379.634440797596
        },
        "glm-4.5-air": {
            "rating": 1381.6052943687869,
            "rating_q975": 1386.1246751392264,
            "rating_q025": 1377.0859135983474
        },
        "gemini-2.5-flash-lite-preview-09-2025-no-thinking": {
            "rating": 1378.3078532198074,
            "rating_q975": 1383.9504964850714,
            "rating_q025": 1372.6652099545433
        },
        "kimi-k2-0905-preview": {
            "rating": 1378.1077108319892,
            "rating_q975": 1384.9678242443217,
            "rating_q025": 1371.2475974196566
        },
        "hunyuan-turbos-20250416": {
            "rating": 1375.253028179312,
            "rating_q975": 1381.5926182044948,
            "rating_q025": 1368.9134381541292
        },
        "gpt-5-mini-high": {
            "rating": 1374.1603569088772,
            "rating_q975": 1379.0514502084295,
            "rating_q025": 1369.269263609325
        },
        "claude-opus-4-20250514-thinking-16k": {
            "rating": 1374.1016332761244,
            "rating_q975": 1378.5330769964294,
            "rating_q025": 1369.6701895558194
        },
        "deepseek-v3-0324": {
            "rating": 1373.1753943518413,
            "rating_q975": 1377.0484441034316,
            "rating_q025": 1369.302344600251
        },
        "deepseek-r1": {
            "rating": 1371.8175144964403,
            "rating_q975": 1376.593550465908,
            "rating_q025": 1367.0414785269725
        },
        "kimi-k2-0711-preview": {
            "rating": 1369.234811615298,
            "rating_q975": 1374.0881277259623,
            "rating_q025": 1364.3814955046337
        },
        "gemini-2.5-flash-lite-preview-06-17-thinking": {
            "rating": 1368.2689036312609,
            "rating_q975": 1372.7751568253584,
            "rating_q025": 1363.7626504371633
        },
        "mistral-medium-2505": {
            "rating": 1367.4464257995332,
            "rating_q975": 1372.1291806316667,
            "rating_q025": 1362.7636709673998
        },
        "qwen3-next-80b-a3b-thinking": {
            "rating": 1367.0528803831207,
            "rating_q975": 1372.9652332685953,
            "rating_q025": 1361.1405274976462
        },
        "grok-3-mini-high": {
            "rating": 1367.024685461281,
            "rating_q975": 1372.369744454046,
            "rating_q025": 1361.679626468516
        },
        "qwen2.5-max": {
            "rating": 1366.9245549925338,
            "rating_q975": 1370.915509581268,
            "rating_q025": 1362.9336004037996
        },
        "o1-2024-12-17": {
            "rating": 1365.6218118284007,
            "rating_q975": 1370.0032622899323,
            "rating_q025": 1361.2403613668691
        },
        "qwen3-235b-a22b": {
            "rating": 1365.2614751372091,
            "rating_q975": 1369.9750887045418,
            "rating_q025": 1360.5478615698764
        },
        "ling-flash-2.0": {
            "rating": 1363.1213581712927,
            "rating_q975": 1370.3406422901883,
            "rating_q025": 1355.9020740523972
        },
        "claude-opus-4-20250514": {
            "rating": 1362.9966539132295,
            "rating_q975": 1367.3289818808703,
            "rating_q025": 1358.6643259455886
        },
        "gpt-oss-120b": {
            "rating": 1362.1830239025523,
            "rating_q975": 1366.8457117391995,
            "rating_q025": 1357.5203360659052
        },
        "grok-3-mini-beta": {
            "rating": 1362.1559860816449,
            "rating_q975": 1367.1594618609556,
            "rating_q025": 1357.1525103023341
        },
        "amazon-nova-experimental-chat-10-09": {
            "rating": 1359.6844194283194,
            "rating_q975": 1367.3694900920184,
            "rating_q025": 1351.9993487646204
        },
        "o1-preview": {
            "rating": 1358.5207370861322,
            "rating_q975": 1363.5296826478668,
            "rating_q025": 1353.5117915243975
        },
        "gemma-3-27b-it": {
            "rating": 1356.6983375785028,
            "rating_q975": 1360.3416864373248,
            "rating_q025": 1353.0549887196808
        },
        "qwen3-coder-480b-a35b-instruct": {
            "rating": 1355.6997949008862,
            "rating_q975": 1360.7538152295817,
            "rating_q025": 1350.6457745721907
        },
        "o4-mini-2025-04-16": {
            "rating": 1353.1946645267922,
            "rating_q975": 1357.1745942053494,
            "rating_q025": 1349.214734848235
        },
        "claude-sonnet-4-20250514-thinking-32k": {
            "rating": 1348.0838673349333,
            "rating_q975": 1352.5766256239187,
            "rating_q025": 1343.5911090459479
        },
        "step-3": {
            "rating": 1347.750144905002,
            "rating_q975": 1355.1067593137682,
            "rating_q025": 1340.3935304962356
        },
        "minimax-m1": {
            "rating": 1346.2084046591742,
            "rating_q975": 1350.4932344745398,
            "rating_q025": 1341.9235748438086
        },
        "gpt-4.1-mini-2025-04-14": {
            "rating": 1339.829667889304,
            "rating_q975": 1344.1356040730032,
            "rating_q025": 1335.5237317056046
        },
        "qwen3-32b": {
            "rating": 1338.659675690329,
            "rating_q975": 1348.0999379909695,
            "rating_q025": 1329.2194133896887
        },
        "mistral-small-2506": {
            "rating": 1338.3128629159949,
            "rating_q975": 1343.5030157821739,
            "rating_q025": 1333.1227100498159
        },
        "o3-mini-high": {
            "rating": 1338.2476307899362,
            "rating_q975": 1343.480805747381,
            "rating_q025": 1333.0144558324914
        },
        "claude-sonnet-4-20250514": {
            "rating": 1337.3603190050549,
            "rating_q975": 1341.7786728927106,
            "rating_q025": 1332.9419651173991
        },
        "nvidia-llama-3.3-nemotron-super-49b-v1.5": {
            "rating": 1335.4705635718885,
            "rating_q975": 1345.3408067048952,
            "rating_q025": 1325.600320438882
        },
        "step-1o-turbo-202506": {
            "rating": 1335.3431180234634,
            "rating_q975": 1342.0138112148543,
            "rating_q025": 1328.6724248320725
        },
        "gemma-3-12b-it": {
            "rating": 1333.676964229177,
            "rating_q975": 1343.1242910745757,
            "rating_q025": 1324.2296373837783
        },
        "glm-4.5v": {
            "rating": 1332.459434264624,
            "rating_q975": 1340.8942259776193,
            "rating_q025": 1324.0246425516286
        },
        "ring-flash-2.0": {
            "rating": 1331.5603913714765,
            "rating_q975": 1338.758208454028,
            "rating_q025": 1324.362574288925
        },
        "deepseek-v3": {
            "rating": 1330.7611249299075,
            "rating_q975": 1335.4086294667807,
            "rating_q025": 1326.1136203930344
        },
        "glm-4-plus-0111": {
            "rating": 1330.4226474151642,
            "rating_q975": 1338.8532565482647,
            "rating_q025": 1321.9920382820637
        },
        "gemini-2.0-flash-lite-preview-02-05": {
            "rating": 1328.9900571796543,
            "rating_q975": 1333.2061495265873,
            "rating_q025": 1324.7739648327213
        },
        "command-a-03-2025": {
            "rating": 1328.9257179717274,
            "rating_q975": 1332.506155337474,
            "rating_q025": 1325.3452806059809
        },
        "qwq-32b": {
            "rating": 1328.1701596465523,
            "rating_q975": 1332.5637509816559,
            "rating_q025": 1323.7765683114487
        },
        "qwen-plus-0125": {
            "rating": 1325.8238710471016,
            "rating_q975": 1334.2399252867547,
            "rating_q025": 1317.4078168074486
        },
        "o3-mini": {
            "rating": 1321.4215911281644,
            "rating_q975": 1324.9112017064604,
            "rating_q025": 1317.9319805498685
        },
        "step-2-16k-exp-202412": {
            "rating": 1321.156796792923,
            "rating_q975": 1329.759293220651,
            "rating_q025": 1312.5543003651949
        },
        "hunyuan-turbos-20250226": {
            "rating": 1320.6671617694915,
            "rating_q975": 1332.495902657221,
            "rating_q025": 1308.838420881762
        },
        "gpt-5-nano-high": {
            "rating": 1320.0419431694684,
            "rating_q975": 1326.8883261021856,
            "rating_q025": 1313.1955602367511
        },
        "o1-mini": {
            "rating": 1320.0120107075109,
            "rating_q975": 1323.5219065142815,
            "rating_q025": 1316.5021149007403
        },
        "llama-3.1-nemotron-ultra-253b-v1": {
            "rating": 1319.1164246500775,
            "rating_q975": 1330.7959464506046,
            "rating_q025": 1307.4369028495505
        },
        "gemini-1.5-pro-002": {
            "rating": 1318.4330325232881,
            "rating_q975": 1321.652065451787,
            "rating_q025": 1315.2139995947894
        },
        "qwen3-30b-a3b": {
            "rating": 1316.8928190425975,
            "rating_q975": 1321.6055443764515,
            "rating_q025": 1312.1800937087435
        },
        "claude-3-7-sonnet-20250219-thinking-32k": {
            "rating": 1313.6272196166074,
            "rating_q975": 1317.8346009157697,
            "rating_q025": 1309.419838317445
        },
        "hunyuan-turbo-0110": {
            "rating": 1309.7770425337997,
            "rating_q975": 1321.4123315320426,
            "rating_q025": 1298.1417535355567
        },
        "llama-3.3-nemotron-49b-super-v1": {
            "rating": 1308.7955889882292,
            "rating_q975": 1321.0214523567554,
            "rating_q025": 1296.569725619703
        },
        "gemma-3n-e4b-it": {
            "rating": 1306.4848623772505,
            "rating_q975": 1311.6208564439526,
            "rating_q025": 1301.3488683105484
        },
        "grok-2-2024-08-13": {
            "rating": 1303.6056317469854,
            "rating_q975": 1307.131647118922,
            "rating_q025": 1300.0796163750488
        },
        "yi-lightning": {
            "rating": 1300.3537381096635,
            "rating_q975": 1305.169562395487,
            "rating_q025": 1295.53791382384
        },
        "qwen2.5-plus-1127": {
            "rating": 1299.7098059904342,
            "rating_q975": 1306.021492106792,
            "rating_q025": 1293.3981198740764
        },
        "gpt-4o-2024-05-13": {
            "rating": 1299.507630561926,
            "rating_q975": 1302.8191779555457,
            "rating_q025": 1296.1960831683061
        },
        "claude-3-5-sonnet-20241022": {
            "rating": 1298.1309448129637,
            "rating_q975": 1301.145335875722,
            "rating_q025": 1295.1165537502054
        },
        "deepseek-v2.5-1210": {
            "rating": 1294.0175588236048,
            "rating_q975": 1302.2743659448665,
            "rating_q025": 1285.760751702343
        },
        "gemma-3-4b-it": {
            "rating": 1290.1917491678435,
            "rating_q975": 1299.5052595527454,
            "rating_q025": 1280.8782387829415
        },
        "athene-v2-chat": {
            "rating": 1290.0706685246018,
            "rating_q975": 1294.5236896174308,
            "rating_q025": 1285.6176474317729
        },
        "glm-4-plus": {
            "rating": 1289.4179033454052,
            "rating_q975": 1294.263225110451,
            "rating_q025": 1284.5725815803594
        },
        "hunyuan-large-2025-02-10": {
            "rating": 1289.1199760658496,
            "rating_q975": 1299.1466377160239,
            "rating_q025": 1279.0933144156754
        },
        "gpt-oss-20b": {
            "rating": 1287.5944423865558,
            "rating_q975": 1293.9731333865936,
            "rating_q025": 1281.215751386518
        },
        "llama-4-maverick-17b-128e-instruct": {
            "rating": 1287.561317814446,
            "rating_q975": 1291.809738827385,
            "rating_q025": 1283.3128968015071
        },
        "gemini-1.5-flash-002": {
            "rating": 1286.2883993517612,
            "rating_q975": 1290.3690249594026,
            "rating_q025": 1282.2077737441198
        },
        "gpt-4o-mini-2024-07-18": {
            "rating": 1286.0138777983443,
            "rating_q975": 1289.36664083312,
            "rating_q025": 1282.6611147635685
        },
        "gpt-4.1-nano-2025-04-14": {
            "rating": 1285.5306578704372,
            "rating_q975": 1293.2742543281402,
            "rating_q025": 1277.7870614127341
        },
        "claude-3-5-sonnet-20240620": {
            "rating": 1284.0304859432833,
            "rating_q975": 1287.3961581819988,
            "rating_q025": 1280.664813704568
        },
        "gpt-4o-2024-08-06": {
            "rating": 1282.5430908688147,
            "rating_q975": 1286.6349227449946,
            "rating_q025": 1278.4512589926348
        },
        "qwen-max-0919": {
            "rating": 1282.1691329221771,
            "rating_q975": 1287.820523513701,
            "rating_q025": 1276.5177423306534
        },
        "llama-3.1-405b-instruct-bf16": {
            "rating": 1282.0943346819267,
            "rating_q975": 1285.6346756642195,
            "rating_q025": 1278.553993699634
        },
        "llama-3.1-nemotron-70b-instruct": {
            "rating": 1281.3398277557058,
            "rating_q975": 1289.062786713537,
            "rating_q025": 1273.6168687978745
        },
        "llama-4-scout-17b-16e-instruct": {
            "rating": 1281.0020745353027,
            "rating_q975": 1285.7126175575986,
            "rating_q025": 1276.2915315130067
        },
        "llama-3.1-405b-instruct-fp8": {
            "rating": 1280.4861103994613,
            "rating_q975": 1283.9182818541174,
            "rating_q025": 1277.0539389448052
        },
        "grok-2-mini-2024-08-13": {
            "rating": 1280.2169530200922,
            "rating_q975": 1283.7850154641146,
            "rating_q025": 1276.6488905760698
        },
        "mistral-small-3.1-24b-instruct-2503": {
            "rating": 1277.876388848838,
            "rating_q975": 1282.411713123697,
            "rating_q025": 1273.3410645739789
        },
        "gemini-advanced-0514": {
            "rating": 1276.2893509448274,
            "rating_q975": 1281.3774676189223,
            "rating_q025": 1271.2012342707326
        },
        "hunyuan-standard-2025-02-10": {
            "rating": 1275.9560281282138,
            "rating_q975": 1285.7922479996703,
            "rating_q025": 1266.1198082567573
        },
        "llama-3.3-70b-instruct": {
            "rating": 1274.6027112135857,
            "rating_q975": 1277.9517201242427,
            "rating_q025": 1271.2537023029288
        },
        "gemini-1.5-pro-001": {
            "rating": 1274.445149824767,
            "rating_q975": 1278.3460843871294,
            "rating_q025": 1270.5442152624046
        },
        "gpt-4-turbo-2024-04-09": {
            "rating": 1270.8602884515371,
            "rating_q975": 1274.6644542559845,
            "rating_q025": 1267.0561226470898
        },
        "deepseek-v2.5": {
            "rating": 1270.7213844560183,
            "rating_q975": 1275.3453286751546,
            "rating_q025": 1266.097440236882
        },
        "claude-3-opus-20240229": {
            "rating": 1269.5721477862248,
            "rating_q975": 1272.5244558659724,
            "rating_q025": 1266.6198397064773
        },
        "qwen2.5-72b-instruct": {
            "rating": 1268.582718769073,
            "rating_q975": 1272.5261053811173,
            "rating_q025": 1264.6393321570285
        },
        "hunyuan-large-vision": {
            "rating": 1267.7770874567045,
            "rating_q975": 1277.0564606441474,
            "rating_q025": 1258.4977142692617
        },
        "gpt-4-1106-preview": {
            "rating": 1264.9466164688579,
            "rating_q975": 1268.7771795385563,
            "rating_q025": 1261.1160533991595
        },
        "mistral-large-2407": {
            "rating": 1264.819687373781,
            "rating_q975": 1268.6259906754015,
            "rating_q025": 1261.0133840721608
        },
        "mistral-large-2411": {
            "rating": 1264.5849641267992,
            "rating_q975": 1268.908274543539,
            "rating_q025": 1260.2616537100594
        },
        "gpt-4-0125-preview": {
            "rating": 1263.8919595514576,
            "rating_q975": 1267.92839938427,
            "rating_q025": 1259.8555197186452
        },
        "athene-70b-0725": {
            "rating": 1263.2947233771965,
            "rating_q975": 1268.8950521668598,
            "rating_q025": 1257.6943945875332
        },
        "claude-3-5-haiku-20241022": {
            "rating": 1260.6009312054598,
            "rating_q975": 1263.7850366662983,
            "rating_q025": 1257.4168257446213
        },
        "llama-3.1-70b-instruct": {
            "rating": 1259.415610656944,
            "rating_q975": 1262.9834872854958,
            "rating_q025": 1255.847734028392
        },
        "amazon-nova-pro-v1.0": {
            "rating": 1257.7077649364996,
            "rating_q975": 1262.1395609571562,
            "rating_q025": 1253.2759689158431
        },
        "magistral-medium-2506": {
            "rating": 1254.4115163619658,
            "rating_q975": 1260.814900860259,
            "rating_q025": 1248.0081318636726
        },
        "llama-3.1-tulu-3-70b": {
            "rating": 1253.0203575786968,
            "rating_q975": 1263.6293454169747,
            "rating_q025": 1242.4113697404189
        },
        "reka-core-20240904": {
            "rating": 1246.6873461433308,
            "rating_q975": 1253.7954392380122,
            "rating_q025": 1239.5792530486494
        },
        "gemini-1.5-flash-001": {
            "rating": 1239.2187005884357,
            "rating_q975": 1243.6501878413055,
            "rating_q025": 1234.7872133355659
        },
        "jamba-1.5-large": {
            "rating": 1235.7279565258527,
            "rating_q975": 1243.089307019242,
            "rating_q025": 1228.3666060324636
        },
        "mistral-small-24b-instruct-2501": {
            "rating": 1233.997828149409,
            "rating_q975": 1239.8402120683193,
            "rating_q025": 1228.155444230499
        },
        "command-r-plus-08-2024": {
            "rating": 1231.1897362506138,
            "rating_q975": 1237.7966640374286,
            "rating_q025": 1224.582808463799
        },
        "gemma-2-27b-it": {
            "rating": 1231.1575003589915,
            "rating_q975": 1234.378293961058,
            "rating_q025": 1227.9367067569249
        },
        "qwen2.5-coder-32b-instruct": {
            "rating": 1228.7171281026322,
            "rating_q975": 1236.8094939106536,
            "rating_q025": 1220.6247622946107
        },
        "amazon-nova-lite-v1.0": {
            "rating": 1228.4559448177824,
            "rating_q975": 1233.4966383506135,
            "rating_q025": 1223.4152512849514
        },
        "gemini-1.5-flash-8b-001": {
            "rating": 1226.7378542905058,
            "rating_q975": 1230.9013566206693,
            "rating_q025": 1222.5743519603423
        },
        "llama-3.1-nemotron-51b-instruct": {
            "rating": 1226.5578582388707,
            "rating_q975": 1236.6114066724372,
            "rating_q025": 1216.5043098053043
        },
        "gemma-2-9b-it-simpo": {
            "rating": 1225.0312276662357,
            "rating_q975": 1231.9521162781984,
            "rating_q025": 1218.110339054273
        },
        "nemotron-4-340b-instruct": {
            "rating": 1223.7863733098916,
            "rating_q975": 1229.1374753004957,
            "rating_q025": 1218.4352713192875
        },
        "c4ai-aya-expanse-32b": {
            "rating": 1223.7537117074448,
            "rating_q975": 1228.5451604221034,
            "rating_q025": 1218.9622629927862
        },
        "glm-4-0520": {
            "rating": 1223.6217680661362,
            "rating_q975": 1230.625819082448,
            "rating_q025": 1216.6177170498243
        },
        "claude-3-sonnet-20240229": {
            "rating": 1221.0280825136597,
            "rating_q975": 1225.0004785402477,
            "rating_q025": 1217.0556864870716
        },
        "llama-3-70b-instruct": {
            "rating": 1217.8060603178478,
            "rating_q975": 1221.3390157681022,
            "rating_q025": 1214.2731048675935
        },
        "phi-4": {
            "rating": 1216.7988686965753,
            "rating_q975": 1221.3230068806156,
            "rating_q025": 1212.274730512535
        },
        "reka-flash-20240904": {
            "rating": 1216.56930042489,
            "rating_q975": 1223.5189190462615,
            "rating_q025": 1209.6196818035182
        },
        "olmo-2-0325-32b-instruct": {
            "rating": 1216.4843763099952,
            "rating_q975": 1227.3710885186,
            "rating_q025": 1205.5976641013906
        },
        "deepseek-coder-v2": {
            "rating": 1212.3421806218844,
            "rating_q975": 1218.9267652868693,
            "rating_q025": 1205.7575959568994
        },
        "amazon-nova-micro-v1.0": {
            "rating": 1208.6798518324028,
            "rating_q975": 1213.7000200412622,
            "rating_q025": 1203.6596836235435
        },
        "gemma-2-9b-it": {
            "rating": 1206.7044523364318,
            "rating_q975": 1210.3750098376147,
            "rating_q025": 1203.033894835249
        },
        "command-r-plus": {
            "rating": 1204.017974001133,
            "rating_q975": 1208.3168497007623,
            "rating_q025": 1199.719098301504
        },
        "gpt-4-0314": {
            "rating": 1203.5358099774535,
            "rating_q975": 1208.362341031536,
            "rating_q025": 1198.709278923371
        },
        "hunyuan-standard-256k": {
            "rating": 1203.055049911266,
            "rating_q975": 1214.815279482619,
            "rating_q025": 1191.294820339913
        },
        "qwen2-72b-instruct": {
            "rating": 1202.843850440816,
            "rating_q975": 1207.7228639005439,
            "rating_q025": 1197.964836981088
        },
        "claude-3-haiku-20240307": {
            "rating": 1198.846748866304,
            "rating_q975": 1202.5417529730946,
            "rating_q025": 1195.1517447595136
        },
        "llama-3.1-tulu-3-8b": {
            "rating": 1193.7789824691968,
            "rating_q975": 1204.4286186413735,
            "rating_q025": 1183.12934629702
        },
        "ministral-8b-2410": {
            "rating": 1190.0439524071526,
            "rating_q975": 1199.079462000884,
            "rating_q025": 1181.0084428134212
        },
        "command-r-08-2024": {
            "rating": 1188.595552930337,
            "rating_q975": 1195.1563137592914,
            "rating_q025": 1182.0347921013824
        },
        "gpt-4-0613": {
            "rating": 1186.6361490279648,
            "rating_q975": 1190.7167935257191,
            "rating_q025": 1182.5555045302106
        },
        "jamba-1.5-mini": {
            "rating": 1186.3527190749917,
            "rating_q975": 1193.588887408492,
            "rating_q025": 1179.1165507414914
        },
        "llama-3.1-8b-instruct": {
            "rating": 1185.6401358588823,
            "rating_q975": 1189.6208767192948,
            "rating_q025": 1181.65939499847
        },
        "c4ai-aya-expanse-8b": {
            "rating": 1185.5434998359133,
            "rating_q975": 1192.4371454433544,
            "rating_q025": 1178.6498542284721
        },
        "mistral-large-2402": {
            "rating": 1173.6394582153584,
            "rating_q975": 1178.3712177308316,
            "rating_q025": 1168.9076986998853
        },
        "qwen1.5-110b-chat": {
            "rating": 1172.9432008345316,
            "rating_q975": 1178.4965362698508,
            "rating_q025": 1167.3898653992123
        },
        "yi-1.5-34b-chat": {
            "rating": 1170.5887772705403,
            "rating_q975": 1175.637128314645,
            "rating_q025": 1165.5404262264356
        },
        "reka-flash-21b-20240226-online": {
            "rating": 1167.4615724963041,
            "rating_q975": 1174.8672708849963,
            "rating_q025": 1160.055874107612
        },
        "qwq-32b-preview": {
            "rating": 1165.3077012063568,
            "rating_q975": 1176.980623225389,
            "rating_q025": 1153.6347791873245
        },
        "qwen1.5-72b-chat": {
            "rating": 1164.9951676679407,
            "rating_q975": 1170.2723591563906,
            "rating_q025": 1159.7179761794907
        },
        "llama-3-8b-instruct": {
            "rating": 1162.9578537818602,
            "rating_q975": 1166.6387334754618,
            "rating_q025": 1159.2769740882586
        },
        "reka-flash-21b-20240226": {
            "rating": 1162.2432286942906,
            "rating_q975": 1168.2169031711815,
            "rating_q025": 1156.2695542173997
        },
        "command-r": {
            "rating": 1161.5415802356972,
            "rating_q975": 1166.2798241601142,
            "rating_q025": 1156.8033363112802
        },
        "mistral-medium": {
            "rating": 1161.3363729611847,
            "rating_q975": 1166.8850509031504,
            "rating_q025": 1155.787695019219
        },
        "mixtral-8x22b-instruct-v0.1": {
            "rating": 1159.2444858955946,
            "rating_q975": 1163.7535220257582,
            "rating_q025": 1154.735449765431
        },
        "internlm2_5-20b-chat": {
            "rating": 1159.1422279505077,
            "rating_q975": 1166.2653378052453,
            "rating_q025": 1152.0191180957702
        },
        "gemma-2-2b-it": {
            "rating": 1154.9101115478256,
            "rating_q975": 1158.8409844130929,
            "rating_q025": 1150.9792386825584
        },
        "granite-3.1-8b-instruct": {
            "rating": 1150.017913172137,
            "rating_q975": 1161.1301509686305,
            "rating_q025": 1138.9056753756436
        },
        "gemini-pro-dev-api": {
            "rating": 1146.6380005708183,
            "rating_q975": 1154.0635664356996,
            "rating_q025": 1139.212434705937
        },
        "zephyr-orpo-141b-A35b-v0.1": {
            "rating": 1140.8250596257535,
            "rating_q975": 1151.7702743589175,
            "rating_q025": 1129.8798448925895
        },
        "qwen1.5-32b-chat": {
            "rating": 1136.315367135677,
            "rating_q975": 1142.4831780320192,
            "rating_q025": 1130.1475562393348
        },
        "phi-3-medium-4k-instruct": {
            "rating": 1136.1574981247459,
            "rating_q975": 1141.2620644225099,
            "rating_q025": 1131.0529318269819
        },
        "gemini-pro": {
            "rating": 1130.6396896226038,
            "rating_q975": 1142.4855490675923,
            "rating_q025": 1118.7938301776153
        },
        "yi-34b-chat": {
            "rating": 1128.993329671785,
            "rating_q975": 1135.9573168608695,
            "rating_q025": 1122.0293424827005
        },
        "starling-lm-7b-beta": {
            "rating": 1128.924693790186,
            "rating_q975": 1136.322023323013,
            "rating_q025": 1121.527364257359
        },
        "mixtral-8x7b-instruct-v0.1": {
            "rating": 1127.3251517664598,
            "rating_q975": 1131.592080968441,
            "rating_q025": 1123.0582225644787
        },
        "qwen1.5-14b-chat": {
            "rating": 1126.9025419333648,
            "rating_q975": 1134.0923650533916,
            "rating_q025": 1119.712718813338
        },
        "gpt-3.5-turbo-0125": {
            "rating": 1126.2353440739953,
            "rating_q975": 1130.9614174387173,
            "rating_q025": 1121.5092707092733
        },
        "granite-3.1-2b-instruct": {
            "rating": 1126.100611898489,
            "rating_q975": 1137.2989485730977,
            "rating_q025": 1114.9022752238802
        },
        "tulu-2-dpo-70b": {
            "rating": 1117.0234728116031,
            "rating_q975": 1127.1069748501566,
            "rating_q025": 1106.9399707730497
        },
        "dbrx-instruct-preview": {
            "rating": 1116.303408485483,
            "rating_q975": 1122.464552851188,
            "rating_q025": 1110.142264119778
        },
        "wizardlm-70b": {
            "rating": 1113.871887557053,
            "rating_q975": 1123.5462295389093,
            "rating_q025": 1104.1975455751967
        },
        "llama-2-70b-chat": {
            "rating": 1112.444778087088,
            "rating_q975": 1118.0183895165594,
            "rating_q025": 1106.8711666576166
        },
        "phi-3-small-8k-instruct": {
            "rating": 1108.7781423473084,
            "rating_q975": 1114.7465348464884,
            "rating_q025": 1102.8097498481284
        },
        "nous-hermes-2-mixtral-8x7b-dpo": {
            "rating": 1108.7218881924887,
            "rating_q975": 1120.8518575241699,
            "rating_q025": 1096.5919188608075
        },
        "llama-3.2-3b-instruct": {
            "rating": 1107.9406316404002,
            "rating_q975": 1115.5445721612857,
            "rating_q025": 1100.3366911195146
        },
        "gpt-3.5-turbo-1106": {
            "rating": 1105.3706849003408,
            "rating_q975": 1114.5747225031744,
            "rating_q025": 1096.1666472975073
        },
        "openchat-3.5-0106": {
            "rating": 1102.3927682090589,
            "rating_q975": 1110.4457789445942,
            "rating_q025": 1094.3397574735236
        },
        "deepseek-llm-67b-chat": {
            "rating": 1101.5053451880874,
            "rating_q975": 1113.4571402814797,
            "rating_q025": 1089.553550094695
        },
        "starling-lm-7b-alpha": {
            "rating": 1100.0705883662795,
            "rating_q975": 1108.2119872721685,
            "rating_q025": 1091.9291894603905
        },
        "vicuna-33b": {
            "rating": 1098.508775288875,
            "rating_q975": 1104.806382869429,
            "rating_q025": 1092.2111677083212
        },
        "snowflake-arctic-instruct": {
            "rating": 1098.0625242294996,
            "rating_q975": 1104.032708674508,
            "rating_q025": 1092.092339784491
        },
        "granite-3.0-8b-instruct": {
            "rating": 1096.352465069358,
            "rating_q975": 1105.0654659862105,
            "rating_q025": 1087.6394641525055
        },
        "gemma-1.1-7b-it": {
            "rating": 1092.006970660939,
            "rating_q975": 1098.0160311791424,
            "rating_q025": 1085.9979101427357
        },
        "llama2-70b-steerlm-chat": {
            "rating": 1091.5527317932274,
            "rating_q975": 1104.454905337124,
            "rating_q025": 1078.6505582493307
        },
        "openchat-3.5": {
            "rating": 1086.0880034130626,
            "rating_q975": 1096.1330305922017,
            "rating_q025": 1076.0429762339234
        },
        "llama-2-13b-chat": {
            "rating": 1085.6066055532524,
            "rating_q975": 1092.3988282374899,
            "rating_q025": 1078.814382869015
        },
        "mistral-7b-instruct-v0.2": {
            "rating": 1085.3602410852138,
            "rating_q975": 1092.0799204799234,
            "rating_q025": 1078.6405616905042
        },
        "openhermes-2.5-mistral-7b": {
            "rating": 1085.3596935644332,
            "rating_q975": 1096.0305137370826,
            "rating_q025": 1074.6888733917838
        },
        "granite-3.0-2b-instruct": {
            "rating": 1078.3419229843148,
            "rating_q975": 1086.7280885602743,
            "rating_q025": 1069.9557574083553
        },
        "qwen1.5-7b-chat": {
            "rating": 1078.2731420356013,
            "rating_q975": 1088.2376390823986,
            "rating_q025": 1068.308644988804
        },
        "phi-3-mini-4k-instruct-june-2024": {
            "rating": 1077.077188604057,
            "rating_q975": 1083.5331305167729,
            "rating_q025": 1070.6212466913412
        },
        "solar-10.7b-instruct-v1.0": {
            "rating": 1076.5985293091035,
            "rating_q975": 1090.1279739804766,
            "rating_q025": 1063.0690846377304
        },
        "phi-3-mini-4k-instruct": {
            "rating": 1072.4815595762257,
            "rating_q975": 1078.8651931434572,
            "rating_q025": 1066.0979260089941
        },
        "wizardlm-13b": {
            "rating": 1072.4267544990837,
            "rating_q975": 1082.1255966771798,
            "rating_q025": 1062.7279123209876
        },
        "dolphin-2.2.1-mistral-7b": {
            "rating": 1071.8419303824637,
            "rating_q975": 1087.743359259107,
            "rating_q025": 1055.9405015058205
        },
        "codellama-70b-instruct": {
            "rating": 1063.3206383056597,
            "rating_q975": 1082.6023944838869,
            "rating_q025": 1044.0388821274325
        },
        "codellama-34b-instruct": {
            "rating": 1061.8934652552382,
            "rating_q975": 1071.0207717460326,
            "rating_q025": 1052.7661587644438
        },
        "zephyr-7b-beta": {
            "rating": 1061.109558724215,
            "rating_q975": 1070.1463658273049,
            "rating_q025": 1052.0727516211252
        },
        "mpt-30b-chat": {
            "rating": 1058.7922489586556,
            "rating_q975": 1071.5591705985444,
            "rating_q025": 1046.0253273187668
        },
        "llama-2-7b-chat": {
            "rating": 1055.4930892751568,
            "rating_q975": 1062.6984399704866,
            "rating_q025": 1048.287738579827
        },
        "vicuna-13b": {
            "rating": 1055.0444940252187,
            "rating_q975": 1061.869039447776,
            "rating_q025": 1048.2199486026614
        },
        "llama-3.2-1b-instruct": {
            "rating": 1054.6384801301338,
            "rating_q975": 1062.3711458162927,
            "rating_q025": 1046.9058144439748
        },
        "guanaco-33b": {
            "rating": 1053.612815542156,
            "rating_q975": 1066.4957957467045,
            "rating_q025": 1040.7298353376077
        },
        "gemma-7b-it": {
            "rating": 1052.898518192471,
            "rating_q975": 1062.6468626425049,
            "rating_q025": 1043.1501737424373
        },
        "phi-3-mini-128k-instruct": {
            "rating": 1049.124987256513,
            "rating_q975": 1056.46409034991,
            "rating_q025": 1041.7858841631157
        },
        "qwen-14b-chat": {
            "rating": 1047.8235003131977,
            "rating_q975": 1059.2429550916406,
            "rating_q025": 1036.4040455347547
        },
        "smollm2-1.7b-instruct": {
            "rating": 1047.1836400960353,
            "rating_q975": 1061.6924472876929,
            "rating_q025": 1032.6748329043778
        },
        "falcon-180b-chat": {
            "rating": 1047.064531909784,
            "rating_q975": 1065.4164376989925,
            "rating_q025": 1028.7126261205754
        },
        "zephyr-7b-alpha": {
            "rating": 1045.4766208940518,
            "rating_q975": 1061.9844667411144,
            "rating_q025": 1028.9687750469893
        },
        "stripedhyena-nous-7b": {
            "rating": 1033.333433560026,
            "rating_q975": 1044.6980044989164,
            "rating_q025": 1021.9688626211356
        },
        "vicuna-7b": {
            "rating": 1026.618618447888,
            "rating_q975": 1036.1928338492023,
            "rating_q025": 1017.0444030465736
        },
        "olmo-7b-instruct": {
            "rating": 1024.2174221536138,
            "rating_q975": 1035.6583654035599,
            "rating_q025": 1012.7764789036678
        },
        "gemma-1.1-2b-it": {
            "rating": 1021.2025790158698,
            "rating_q975": 1028.9486143009287,
            "rating_q025": 1013.456543730811
        },
        "palm-2": {
            "rating": 1016.0468071095709,
            "rating_q975": 1025.746897747065,
            "rating_q025": 1006.3467164720768
        },
        "mistral-7b-instruct": {
            "rating": 1010.6610218288122,
            "rating_q975": 1020.2020044706389,
            "rating_q025": 1001.1200391869854
        },
        "gemma-2b-it": {
            "rating": 999.2074696046809,
            "rating_q975": 1011.1299195688516,
            "rating_q025": 987.2850196405102
        },
        "qwen1.5-4b-chat": {
            "rating": 992.3826267402211,
            "rating_q975": 1001.9349269675239,
            "rating_q025": 982.8303265129183
        },
        "koala-13b": {
            "rating": 983.9484548631126,
            "rating_q975": 994.6059268770713,
            "rating_q025": 973.2909828491539
        },
        "chatglm3-6b": {
            "rating": 962.1947598287061,
            "rating_q975": 974.5807404197599,
            "rating_q025": 949.8087792376523
        },
        "mpt-7b-chat": {
            "rating": 950.4728320857014,
            "rating_q975": 963.0044496046328,
            "rating_q025": 937.94121456677
        },
        "gpt4all-13b-snoozy": {
            "rating": 948.2501558571623,
            "rating_q975": 964.5377022507226,
            "rating_q025": 931.962609463602
        },
        "RWKV-4-Raven-14B": {
            "rating": 936.146070510499,
            "rating_q975": 948.109621033263,
            "rating_q025": 924.1825199877351
        },
        "chatglm2-6b": {
            "rating": 922.6545830970564,
            "rating_q975": 937.3743154966808,
            "rating_q025": 907.934850697432
        },
        "alpaca-13b": {
            "rating": 916.6945935267124,
            "rating_q975": 928.6796584023436,
            "rating_q025": 904.7095286510812
        },
        "oasst-pythia-12b": {
            "rating": 903.3191362685685,
            "rating_q975": 914.7785398206662,
            "rating_q025": 891.8597327164708
        },
        "chatglm-6b": {
            "rating": 902.5865216155954,
            "rating_q975": 915.8748727185417,
            "rating_q025": 889.2981705126491
        },
        "fastchat-t5-3b": {
            "rating": 878.3992709848923,
            "rating_q975": 891.5307887142332,
            "rating_q025": 865.2677532555514
        },
        "stablelm-tuned-alpha-7b": {
            "rating": 853.1784645671368,
            "rating_q975": 866.9557410679685,
            "rating_q025": 839.401188066305
        },
        "dolly-v2-12b": {
            "rating": 832.2816782629036,
            "rating_q975": 846.3722526584396,
            "rating_q025": 818.1911038673676
        },
        "llama-13b": {
            "rating": 816.8414683631156,
            "rating_q975": 833.4616944481716,
            "rating_q025": 800.2212422780597
        }
    },
    "no_short": {
        "gemini-2.5-pro": {
            "rating": 1466.3569792832081,
            "rating_q975": 1470.3631999592822,
            "rating_q025": 1462.3507586071341
        },
        "glm-4.6": {
            "rating": 1445.5840777164658,
            "rating_q975": 1451.9940634058014,
            "rating_q025": 1439.1740920271302
        },
        "qwen3-max-preview": {
            "rating": 1437.753224896064,
            "rating_q975": 1442.6215746798302,
            "rating_q025": 1432.8848751122978
        },
        "deepseek-v3.2-exp": {
            "rating": 1436.3782408357306,
            "rating_q975": 1463.807787889529,
            "rating_q025": 1408.9486937819322
        },
        "mistral-medium-2508": {
            "rating": 1430.9950196212096,
            "rating_q975": 1435.6576266837756,
            "rating_q025": 1426.3324125586437
        },
        "glm-4.5": {
            "rating": 1428.356549779182,
            "rating_q975": 1433.2754545973996,
            "rating_q025": 1423.4376449609642
        },
        "claude-sonnet-4-5-20250929-thinking-32k": {
            "rating": 1427.0351622261608,
            "rating_q975": 1433.0103375903989,
            "rating_q025": 1421.0599868619227
        },
        "chatgpt-4o-latest-20250326": {
            "rating": 1426.136987384682,
            "rating_q975": 1429.980083369116,
            "rating_q025": 1422.293891400248
        },
        "deepseek-r1-0528": {
            "rating": 1424.5972445386915,
            "rating_q975": 1430.2348298132838,
            "rating_q025": 1418.9596592640992
        },
        "grok-3-preview-02-24": {
            "rating": 1423.7341845422536,
            "rating_q975": 1427.9773645628256,
            "rating_q025": 1419.4910045216816
        },
        "claude-sonnet-4-5-20250929": {
            "rating": 1422.1615957040462,
            "rating_q975": 1429.7425147569857,
            "rating_q025": 1414.5806766511068
        },
        "qwen3-vl-235b-a22b-instruct": {
            "rating": 1421.8769325882274,
            "rating_q975": 1428.5929969163406,
            "rating_q025": 1415.1608682601143
        },
        "longcat-flash-chat": {
            "rating": 1421.7766852861726,
            "rating_q975": 1428.2145090443569,
            "rating_q025": 1415.3388615279882
        },
        "deepseek-v3.2-exp-thinking": {
            "rating": 1420.796590652615,
            "rating_q975": 1427.4154092926985,
            "rating_q025": 1414.1777720125312
        },
        "claude-opus-4-1-20250805-thinking-16k": {
            "rating": 1420.5804007116262,
            "rating_q975": 1425.2449073655353,
            "rating_q025": 1415.9158940577172
        },
        "deepseek-v3.1": {
            "rating": 1420.4243744147848,
            "rating_q975": 1426.4925156036786,
            "rating_q025": 1414.356233225891
        },
        "qwen3-next-80b-a3b-instruct": {
            "rating": 1419.4798953408465,
            "rating_q975": 1424.6699988059993,
            "rating_q025": 1414.2897918756937
        },
        "qwen3-235b-a22b-instruct-2507": {
            "rating": 1417.8187905489551,
            "rating_q975": 1422.2041199280984,
            "rating_q025": 1413.4334611698118
        },
        "gpt-4.5-preview-2025-02-27": {
            "rating": 1417.706507181087,
            "rating_q975": 1423.3795683124702,
            "rating_q025": 1412.033446049704
        },
        "deepseek-v3.1-terminus": {
            "rating": 1417.4150466128583,
            "rating_q975": 1427.0916882754993,
            "rating_q025": 1407.7384049502173
        },
        "deepseek-v3.1-terminus-thinking": {
            "rating": 1417.1333160027884,
            "rating_q975": 1427.1593673435325,
            "rating_q025": 1407.1072646620444
        },
        "deepseek-v3.1-thinking": {
            "rating": 1415.8392005322478,
            "rating_q975": 1422.4945804676888,
            "rating_q025": 1409.1838205968068
        },
        "gemini-2.5-flash": {
            "rating": 1414.1643017851034,
            "rating_q975": 1418.075825293154,
            "rating_q025": 1410.2527782770528
        },
        "qwen3-max-2025-09-23": {
            "rating": 1413.8999447999283,
            "rating_q975": 1420.3922786106675,
            "rating_q025": 1407.4076109891892
        },
        "qwen3-235b-a22b-thinking-2507": {
            "rating": 1412.5878348869858,
            "rating_q975": 1419.0723337799334,
            "rating_q025": 1406.1033359940382
        },
        "claude-opus-4-1-20250805": {
            "rating": 1412.2269371345785,
            "rating_q975": 1416.6897034091105,
            "rating_q025": 1407.7641708600465
        },
        "o3-2025-04-16": {
            "rating": 1411.0567592758978,
            "rating_q975": 1414.8431117131709,
            "rating_q025": 1407.2704068386247
        },
        "grok-4-0709": {
            "rating": 1410.329100161621,
            "rating_q975": 1414.624666977362,
            "rating_q025": 1406.03353334588
        },
        "gemini-2.5-flash-preview-09-2025": {
            "rating": 1408.9582909660628,
            "rating_q975": 1414.6400559991105,
            "rating_q025": 1403.2765259330151
        },
        "grok-4-fast": {
            "rating": 1407.8963504175506,
            "rating_q975": 1415.5318334976669,
            "rating_q025": 1400.2608673374343
        },
        "gpt-5-high": {
            "rating": 1406.8290590056565,
            "rating_q975": 1411.5718930077699,
            "rating_q025": 1402.0862250035432
        },
        "gpt-5-chat": {
            "rating": 1403.8979359274385,
            "rating_q975": 1408.4911617591515,
            "rating_q025": 1399.3047100957256
        },
        "qwen3-vl-235b-a22b-thinking": {
            "rating": 1399.7709253637418,
            "rating_q975": 1406.6310702106364,
            "rating_q025": 1392.9107805168471
        },
        "hunyuan-t1-20250711": {
            "rating": 1397.0154080090022,
            "rating_q975": 1405.6324944108146,
            "rating_q025": 1388.3983216071897
        },
        "mai-1-preview": {
            "rating": 1393.0943258320217,
            "rating_q975": 1398.5805679757098,
            "rating_q025": 1387.6080836883336
        },
        "qwen3-235b-a22b-no-thinking": {
            "rating": 1392.1739285390702,
            "rating_q975": 1396.69408433112,
            "rating_q025": 1387.6537727470204
        },
        "claude-haiku-4-5-20251001": {
            "rating": 1386.16757038178,
            "rating_q975": 1392.600232873202,
            "rating_q025": 1379.734907890358
        },
        "qwen3-30b-a3b-instruct-2507": {
            "rating": 1384.9206743436912,
            "rating_q975": 1389.842940090179,
            "rating_q025": 1379.9984085972035
        },
        "gpt-4.1-2025-04-14": {
            "rating": 1382.9242082557344,
            "rating_q975": 1386.8288116584054,
            "rating_q025": 1379.0196048530634
        },
        "glm-4.5-air": {
            "rating": 1381.8684493741625,
            "rating_q975": 1386.400887376684,
            "rating_q025": 1377.336011371641
        },
        "gemini-2.5-flash-lite-preview-09-2025-no-thinking": {
            "rating": 1379.5188198323992,
            "rating_q975": 1385.164094942535,
            "rating_q025": 1373.8735447222634
        },
        "kimi-k2-0905-preview": {
            "rating": 1379.1794651009523,
            "rating_q975": 1386.0764663509729,
            "rating_q025": 1372.2824638509317
        },
        "hunyuan-turbos-20250416": {
            "rating": 1375.3062737337605,
            "rating_q975": 1381.6601815100423,
            "rating_q025": 1368.9523659574786
        },
        "claude-opus-4-20250514-thinking-16k": {
            "rating": 1374.8642842728532,
            "rating_q975": 1379.3096833053914,
            "rating_q025": 1370.418885240315
        },
        "deepseek-v3-0324": {
            "rating": 1373.1978323675794,
            "rating_q975": 1377.0753401566076,
            "rating_q025": 1369.3203245785512
        },
        "gpt-5-mini-high": {
            "rating": 1372.7888564575853,
            "rating_q975": 1377.6941923792947,
            "rating_q025": 1367.883520535876
        },
        "deepseek-r1": {
            "rating": 1371.734115261612,
            "rating_q975": 1376.5198274372162,
            "rating_q025": 1366.9484030860078
        },
        "kimi-k2-0711-preview": {
            "rating": 1368.9650075594957,
            "rating_q975": 1373.8355229554777,
            "rating_q025": 1364.0944921635137
        },
        "gemini-2.5-flash-lite-preview-06-17-thinking": {
            "rating": 1368.815811875941,
            "rating_q975": 1373.3273286755891,
            "rating_q025": 1364.304295076293
        },
        "mistral-medium-2505": {
            "rating": 1368.0207101180454,
            "rating_q975": 1372.7071174092678,
            "rating_q025": 1363.334302826823
        },
        "grok-3-mini-high": {
            "rating": 1367.2205079870077,
            "rating_q975": 1372.5618459710306,
            "rating_q025": 1361.879170002985
        },
        "qwen3-235b-a22b": {
            "rating": 1366.2851435064954,
            "rating_q975": 1371.0090625954097,
            "rating_q025": 1361.5612244175811
        },
        "qwen3-next-80b-a3b-thinking": {
            "rating": 1365.9340800441198,
            "rating_q975": 1371.8505602544535,
            "rating_q025": 1360.017599833786
        },
        "qwen2.5-max": {
            "rating": 1365.6977196132216,
            "rating_q975": 1369.6798922889152,
            "rating_q025": 1361.715546937528
        },
        "o1-2024-12-17": {
            "rating": 1365.5343051534182,
            "rating_q975": 1369.9137096711913,
            "rating_q025": 1361.1549006356452
        },
        "claude-opus-4-20250514": {
            "rating": 1364.3909436656752,
            "rating_q975": 1368.7307483393436,
            "rating_q025": 1360.0511389920068
        },
        "grok-3-mini-beta": {
            "rating": 1363.027952173236,
            "rating_q975": 1368.029693875511,
            "rating_q025": 1358.026210470961
        },
        "ling-flash-2.0": {
            "rating": 1362.1451692734267,
            "rating_q975": 1369.4014715261685,
            "rating_q025": 1354.888867020685
        },
        "gpt-oss-120b": {
            "rating": 1361.131999526368,
            "rating_q975": 1365.8105045972459,
            "rating_q025": 1356.45349445549
        },
        "amazon-nova-experimental-chat-10-09": {
            "rating": 1360.4869779365483,
            "rating_q975": 1368.1853715497707,
            "rating_q025": 1352.788584323326
        },
        "gemma-3-27b-it": {
            "rating": 1357.015781171655,
            "rating_q975": 1360.6591942987277,
            "rating_q025": 1353.3723680445821
        },
        "qwen3-coder-480b-a35b-instruct": {
            "rating": 1354.751877866638,
            "rating_q975": 1359.8149434568948,
            "rating_q025": 1349.6888122763814
        },
        "o4-mini-2025-04-16": {
            "rating": 1352.6878095681684,
            "rating_q975": 1356.6778274884657,
            "rating_q025": 1348.697791647871
        },
        "o1-preview": {
            "rating": 1351.9457730588874,
            "rating_q975": 1356.8674484284816,
            "rating_q025": 1347.0240976892933
        },
        "claude-sonnet-4-20250514-thinking-32k": {
            "rating": 1348.880424695738,
            "rating_q975": 1353.377646191376,
            "rating_q025": 1344.3832032000998
        },
        "step-3": {
            "rating": 1348.6720464507007,
            "rating_q975": 1356.082531697118,
            "rating_q025": 1341.2615612042835
        },
        "minimax-m1": {
            "rating": 1346.4214032993405,
            "rating_q975": 1350.7059206139118,
            "rating_q025": 1342.1368859847692
        },
        "gpt-4.1-mini-2025-04-14": {
            "rating": 1339.5381020897091,
            "rating_q975": 1343.8556361297137,
            "rating_q025": 1335.2205680497045
        },
        "qwen3-32b": {
            "rating": 1339.3840391209242,
            "rating_q975": 1348.8303322027414,
            "rating_q025": 1329.937746039107
        },
        "claude-sonnet-4-20250514": {
            "rating": 1338.7894783142667,
            "rating_q975": 1343.222243556119,
            "rating_q025": 1334.3567130724143
        },
        "mistral-small-2506": {
            "rating": 1338.3711744721063,
            "rating_q975": 1343.576816184155,
            "rating_q025": 1333.1655327600577
        },
        "o3-mini-high": {
            "rating": 1335.670180955884,
            "rating_q975": 1340.8706161447938,
            "rating_q025": 1330.4697457669743
        },
        "step-1o-turbo-202506": {
            "rating": 1335.5843471204776,
            "rating_q975": 1342.2852034351463,
            "rating_q025": 1328.8834908058088
        },
        "nvidia-llama-3.3-nemotron-super-49b-v1.5": {
            "rating": 1335.1987656145693,
            "rating_q975": 1345.069221290943,
            "rating_q025": 1325.3283099381956
        },
        "gemma-3-12b-it": {
            "rating": 1333.753105091477,
            "rating_q975": 1343.195960765573,
            "rating_q025": 1324.3102494173809
        },
        "glm-4.5v": {
            "rating": 1332.7267868414374,
            "rating_q975": 1341.1974285825352,
            "rating_q025": 1324.2561451003396
        },
        "ring-flash-2.0": {
            "rating": 1332.0294533757917,
            "rating_q975": 1339.2313708469985,
            "rating_q025": 1324.827535904585
        },
        "deepseek-v3": {
            "rating": 1331.7250237587948,
            "rating_q975": 1336.363977125978,
            "rating_q025": 1327.0860703916117
        },
        "glm-4-plus-0111": {
            "rating": 1330.9214773106626,
            "rating_q975": 1339.3266446443295,
            "rating_q025": 1322.5163099769957
        },
        "command-a-03-2025": {
            "rating": 1329.0401071525105,
            "rating_q975": 1332.6247481128057,
            "rating_q025": 1325.4554661922152
        },
        "qwq-32b": {
            "rating": 1328.540497082611,
            "rating_q975": 1332.9364712636736,
            "rating_q025": 1324.1445229015483
        },
        "gemini-2.0-flash-lite-preview-02-05": {
            "rating": 1328.2187343899145,
            "rating_q975": 1332.432956837461,
            "rating_q025": 1324.004511942368
        },
        "qwen-plus-0125": {
            "rating": 1325.5496828533967,
            "rating_q975": 1333.8918841398126,
            "rating_q025": 1317.2074815669807
        },
        "step-2-16k-exp-202412": {
            "rating": 1319.2635819149355,
            "rating_q975": 1327.814797087116,
            "rating_q025": 1310.712366742755
        },
        "llama-3.1-nemotron-ultra-253b-v1": {
            "rating": 1319.111251100387,
            "rating_q975": 1330.7643224981002,
            "rating_q025": 1307.458179702674
        },
        "o3-mini": {
            "rating": 1318.873428819832,
            "rating_q975": 1322.3585634150104,
            "rating_q025": 1315.3882942246537
        },
        "hunyuan-turbos-20250226": {
            "rating": 1318.4968363217445,
            "rating_q975": 1330.2827484068216,
            "rating_q025": 1306.7109242366673
        },
        "gpt-5-nano-high": {
            "rating": 1318.468198390986,
            "rating_q975": 1325.3386044553235,
            "rating_q025": 1311.5977923266482
        },
        "gemini-1.5-pro-002": {
            "rating": 1318.4480356358908,
            "rating_q975": 1321.6598969463378,
            "rating_q025": 1315.236174325444
        },
        "qwen3-30b-a3b": {
            "rating": 1316.7004626038793,
            "rating_q975": 1321.423266835508,
            "rating_q025": 1311.9776583722505
        },
        "o1-mini": {
            "rating": 1316.1758052531682,
            "rating_q975": 1319.6610747203188,
            "rating_q025": 1312.6905357860176
        },
        "claude-3-7-sonnet-20250219-thinking-32k": {
            "rating": 1314.6468671349382,
            "rating_q975": 1318.8595155789365,
            "rating_q025": 1310.43421869094
        },
        "hunyuan-turbo-0110": {
            "rating": 1310.7867080498218,
            "rating_q975": 1322.314097493016,
            "rating_q025": 1299.2593186066274
        },
        "llama-3.3-nemotron-49b-super-v1": {
            "rating": 1309.57229553535,
            "rating_q975": 1321.6943672900964,
            "rating_q025": 1297.4502237806034
        },
        "gemma-3n-e4b-it": {
            "rating": 1305.2206677311444,
            "rating_q975": 1310.3573453052982,
            "rating_q025": 1300.0839901569907
        },
        "grok-2-2024-08-13": {
            "rating": 1304.6412766979395,
            "rating_q975": 1308.1557049453265,
            "rating_q025": 1301.1268484505524
        },
        "yi-lightning": {
            "rating": 1301.6268879549084,
            "rating_q975": 1306.4230980662005,
            "rating_q025": 1296.8306778436163
        },
        "gpt-4o-2024-05-13": {
            "rating": 1300.1698259887316,
            "rating_q975": 1303.4576781706014,
            "rating_q025": 1296.8819738068619
        },
        "qwen2.5-plus-1127": {
            "rating": 1297.7290675240924,
            "rating_q975": 1304.0041466807547,
            "rating_q025": 1291.4539883674302
        },
        "claude-3-5-sonnet-20241022": {
            "rating": 1297.5913404837352,
            "rating_q975": 1300.5920854009848,
            "rating_q025": 1294.5905955664855
        },
        "deepseek-v2.5-1210": {
            "rating": 1292.9738125326912,
            "rating_q975": 1301.1850318487095,
            "rating_q025": 1284.762593216673
        },
        "athene-v2-chat": {
            "rating": 1290.1035536011677,
            "rating_q975": 1294.542238356088,
            "rating_q025": 1285.6648688462474
        },
        "glm-4-plus": {
            "rating": 1288.7144025599487,
            "rating_q975": 1293.5276584229866,
            "rating_q025": 1283.9011466969107
        },
        "gemma-3-4b-it": {
            "rating": 1288.256889808497,
            "rating_q975": 1297.590236333433,
            "rating_q025": 1278.9235432835608
        },
        "hunyuan-large-2025-02-10": {
            "rating": 1287.6984877015627,
            "rating_q975": 1297.588971054575,
            "rating_q025": 1277.8080043485504
        },
        "llama-4-maverick-17b-128e-instruct": {
            "rating": 1287.6034623029284,
            "rating_q975": 1291.8596194180293,
            "rating_q025": 1283.3473051878275
        },
        "gemini-1.5-flash-002": {
            "rating": 1286.5015141080107,
            "rating_q975": 1290.5666253724814,
            "rating_q025": 1282.43640284354
        },
        "gpt-oss-20b": {
            "rating": 1286.499670183235,
            "rating_q975": 1292.9106257882545,
            "rating_q025": 1280.0887145782153
        },
        "gpt-4o-mini-2024-07-18": {
            "rating": 1285.048248937599,
            "rating_q975": 1288.385454449086,
            "rating_q025": 1281.7110434261122
        },
        "gpt-4.1-nano-2025-04-14": {
            "rating": 1284.538283465949,
            "rating_q975": 1292.2773524733718,
            "rating_q025": 1276.7992144585262
        },
        "llama-3.1-405b-instruct-bf16": {
            "rating": 1282.5899857382387,
            "rating_q975": 1286.1275890557993,
            "rating_q025": 1279.0523824206782
        },
        "gpt-4o-2024-08-06": {
            "rating": 1282.2963099101685,
            "rating_q975": 1286.3665358944068,
            "rating_q025": 1278.2260839259302
        },
        "llama-3.1-nemotron-70b-instruct": {
            "rating": 1281.8475858914903,
            "rating_q975": 1289.529326869715,
            "rating_q025": 1274.1658449132656
        },
        "qwen-max-0919": {
            "rating": 1281.8239191634434,
            "rating_q975": 1287.4381796304813,
            "rating_q025": 1276.2096586964055
        },
        "llama-3.1-405b-instruct-fp8": {
            "rating": 1281.196916913405,
            "rating_q975": 1284.6094806360902,
            "rating_q025": 1277.7843531907197
        },
        "grok-2-mini-2024-08-13": {
            "rating": 1280.2953857475447,
            "rating_q975": 1283.8463567601052,
            "rating_q025": 1276.7444147349843
        },
        "claude-3-5-sonnet-20240620": {
            "rating": 1280.2381138042547,
            "rating_q975": 1283.528213227524,
            "rating_q025": 1276.9480143809853
        },
        "llama-4-scout-17b-16e-instruct": {
            "rating": 1279.7202279952194,
            "rating_q975": 1284.4407054762594,
            "rating_q025": 1274.9997505141794
        },
        "gemini-advanced-0514": {
            "rating": 1277.8301936724831,
            "rating_q975": 1282.9010614147398,
            "rating_q025": 1272.7593259302264
        },
        "mistral-small-3.1-24b-instruct-2503": {
            "rating": 1277.682939178146,
            "rating_q975": 1282.2208712970973,
            "rating_q025": 1273.1450070591945
        },
        "llama-3.3-70b-instruct": {
            "rating": 1274.4640078462762,
            "rating_q975": 1277.811231296756,
            "rating_q025": 1271.1167843957965
        },
        "hunyuan-standard-2025-02-10": {
            "rating": 1273.8526718478047,
            "rating_q975": 1283.6557316635717,
            "rating_q025": 1264.0496120320377
        },
        "gemini-1.5-pro-001": {
            "rating": 1272.4274090334634,
            "rating_q975": 1276.2939495036915,
            "rating_q025": 1268.5608685632353
        },
        "gpt-4-turbo-2024-04-09": {
            "rating": 1271.5793391396726,
            "rating_q975": 1275.3666146577011,
            "rating_q025": 1267.792063621644
        },
        "deepseek-v2.5": {
            "rating": 1270.4741188610037,
            "rating_q975": 1275.0582042462177,
            "rating_q025": 1265.8900334757898
        },
        "qwen2.5-72b-instruct": {
            "rating": 1268.6406773152119,
            "rating_q975": 1272.5662960442542,
            "rating_q025": 1264.7150585861696
        },
        "mistral-large-2407": {
            "rating": 1265.520932401114,
            "rating_q975": 1269.293264952097,
            "rating_q025": 1261.7485998501309
        },
        "hunyuan-large-vision": {
            "rating": 1264.9286053791175,
            "rating_q975": 1274.1277826508,
            "rating_q025": 1255.7294281074348
        },
        "mistral-large-2411": {
            "rating": 1264.8527480559894,
            "rating_q975": 1269.1567018507512,
            "rating_q025": 1260.5487942612276
        },
        "athene-70b-0725": {
            "rating": 1263.4818540726317,
            "rating_q975": 1269.051837016231,
            "rating_q025": 1257.9118711290323
        },
        "gpt-4-1106-preview": {
            "rating": 1263.0822097355835,
            "rating_q975": 1266.8603163562698,
            "rating_q025": 1259.3041031148973
        },
        "claude-3-opus-20240229": {
            "rating": 1261.6737790940092,
            "rating_q975": 1264.5434452972395,
            "rating_q025": 1258.804112890779
        },
        "gpt-4-0125-preview": {
            "rating": 1261.372089629286,
            "rating_q975": 1265.3747694518468,
            "rating_q025": 1257.3694098067251
        },
        "llama-3.1-70b-instruct": {
            "rating": 1260.3054116121023,
            "rating_q975": 1263.8600495585972,
            "rating_q025": 1256.7507736656073
        },
        "amazon-nova-pro-v1.0": {
            "rating": 1257.554348184613,
            "rating_q975": 1261.977364103967,
            "rating_q025": 1253.131332265259
        },
        "llama-3.1-tulu-3-70b": {
            "rating": 1255.0413371885327,
            "rating_q975": 1265.523018764917,
            "rating_q025": 1244.5596556121484
        },
        "claude-3-5-haiku-20241022": {
            "rating": 1254.9605227888173,
            "rating_q975": 1258.0838488012703,
            "rating_q025": 1251.8371967763644
        },
        "magistral-medium-2506": {
            "rating": 1254.7092279257697,
            "rating_q975": 1261.1227630535611,
            "rating_q025": 1248.2956927979783
        },
        "reka-core-20240904": {
            "rating": 1246.4454830782738,
            "rating_q975": 1253.5199986776408,
            "rating_q025": 1239.3709674789068
        },
        "gemini-1.5-flash-001": {
            "rating": 1237.9114667935592,
            "rating_q975": 1242.2870952283347,
            "rating_q025": 1233.5358383587836
        },
        "jamba-1.5-large": {
            "rating": 1236.3348532658513,
            "rating_q975": 1243.6334001267492,
            "rating_q025": 1229.0363064049534
        },
        "mistral-small-24b-instruct-2501": {
            "rating": 1232.7041289976146,
            "rating_q975": 1238.527139941969,
            "rating_q025": 1226.8811180532603
        },
        "gemma-2-27b-it": {
            "rating": 1230.6989292117491,
            "rating_q975": 1233.892878563853,
            "rating_q025": 1227.5049798596453
        },
        "command-r-plus-08-2024": {
            "rating": 1228.751027000762,
            "rating_q975": 1235.2548758660118,
            "rating_q025": 1222.247178135512
        },
        "qwen2.5-coder-32b-instruct": {
            "rating": 1228.6140875409717,
            "rating_q975": 1236.6622995160028,
            "rating_q025": 1220.5658755659406
        },
        "amazon-nova-lite-v1.0": {
            "rating": 1227.1502457846163,
            "rating_q975": 1232.175299172706,
            "rating_q025": 1222.1251923965267
        },
        "llama-3.1-nemotron-51b-instruct": {
            "rating": 1226.9223645380025,
            "rating_q975": 1236.8859034101256,
            "rating_q025": 1216.9588256658794
        },
        "gemma-2-9b-it-simpo": {
            "rating": 1226.2518357602162,
            "rating_q975": 1233.1050918589804,
            "rating_q025": 1219.398579661452
        },
        "gemini-1.5-flash-8b-001": {
            "rating": 1225.3536612952153,
            "rating_q975": 1229.4805071325488,
            "rating_q025": 1221.2268154578817
        },
        "glm-4-0520": {
            "rating": 1225.2698322086967,
            "rating_q975": 1232.2155059267598,
            "rating_q025": 1218.3241584906336
        },
        "nemotron-4-340b-instruct": {
            "rating": 1224.3029720577958,
            "rating_q975": 1229.5500252295685,
            "rating_q025": 1219.0559188860232
        },
        "c4ai-aya-expanse-32b": {
            "rating": 1223.7682215952718,
            "rating_q975": 1228.5222831312792,
            "rating_q025": 1219.0141600592644
        },
        "llama-3-70b-instruct": {
            "rating": 1219.728854430406,
            "rating_q975": 1223.2333245026764,
            "rating_q025": 1216.2243843581357
        },
        "claude-3-sonnet-20240229": {
            "rating": 1217.502302670957,
            "rating_q975": 1221.425034124666,
            "rating_q025": 1213.5795712172483
        },
        "reka-flash-20240904": {
            "rating": 1217.3040500250354,
            "rating_q975": 1224.2055471837089,
            "rating_q025": 1210.402552866362
        },
        "olmo-2-0325-32b-instruct": {
            "rating": 1217.010477024033,
            "rating_q975": 1227.832361526054,
            "rating_q025": 1206.188592522012
        },
        "phi-4": {
            "rating": 1215.3201883941917,
            "rating_q975": 1219.8065483917314,
            "rating_q025": 1210.833828396652
        },
        "amazon-nova-micro-v1.0": {
            "rating": 1208.1051777029813,
            "rating_q975": 1213.114166530194,
            "rating_q025": 1203.0961888757686
        },
        "gemma-2-9b-it": {
            "rating": 1206.3468955933754,
            "rating_q975": 1209.9949915659065,
            "rating_q025": 1202.6987996208443
        },
        "gpt-4-0314": {
            "rating": 1205.3914530781826,
            "rating_q975": 1210.1656121506328,
            "rating_q025": 1200.6172940057324
        },
        "command-r-plus": {
            "rating": 1204.5628396069692,
            "rating_q975": 1208.8009710032702,
            "rating_q025": 1200.3247082106682
        },
        "hunyuan-standard-256k": {
            "rating": 1203.9995186429317,
            "rating_q975": 1215.616945939647,
            "rating_q025": 1192.3820913462164
        },
        "qwen2-72b-instruct": {
            "rating": 1202.0217960200011,
            "rating_q975": 1206.86302045566,
            "rating_q025": 1197.1805715843423
        },
        "llama-3.1-tulu-3-8b": {
            "rating": 1194.6353665631514,
            "rating_q975": 1205.1395466043755,
            "rating_q025": 1184.1311865219272
        },
        "claude-3-haiku-20240307": {
            "rating": 1193.7423035580039,
            "rating_q975": 1197.3767777503406,
            "rating_q025": 1190.1078293656672
        },
        "deepseek-coder-v2": {
            "rating": 1190.8961498360466,
            "rating_q975": 1197.2358197316346,
            "rating_q025": 1184.5564799404585
        },
        "ministral-8b-2410": {
            "rating": 1189.6856343472825,
            "rating_q975": 1198.6750330601794,
            "rating_q025": 1180.6962356343856
        },
        "command-r-08-2024": {
            "rating": 1187.301324931822,
            "rating_q975": 1193.786100089581,
            "rating_q025": 1180.8165497740629
        },
        "jamba-1.5-mini": {
            "rating": 1186.1777675652384,
            "rating_q975": 1193.346459022527,
            "rating_q025": 1179.0090761079498
        },
        "llama-3.1-8b-instruct": {
            "rating": 1185.9594610745858,
            "rating_q975": 1189.9212487123502,
            "rating_q025": 1181.9976734368213
        },
        "gpt-4-0613": {
            "rating": 1185.9496733286464,
            "rating_q975": 1189.9569495437443,
            "rating_q025": 1181.9423971135486
        },
        "c4ai-aya-expanse-8b": {
            "rating": 1185.7162641409363,
            "rating_q975": 1192.5760560818994,
            "rating_q025": 1178.8564721999733
        },
        "mistral-large-2402": {
            "rating": 1175.767738398787,
            "rating_q975": 1180.4276048490674,
            "rating_q025": 1171.1078719485067
        },
        "qwen1.5-110b-chat": {
            "rating": 1173.8623737901185,
            "rating_q975": 1179.3828308771958,
            "rating_q025": 1168.341916703041
        },
        "yi-1.5-34b-chat": {
            "rating": 1171.2609374725994,
            "rating_q975": 1176.2464767976396,
            "rating_q025": 1166.2753981475591
        },
        "reka-flash-21b-20240226-online": {
            "rating": 1169.239764719139,
            "rating_q975": 1176.6176004310933,
            "rating_q025": 1161.8619290071847
        },
        "qwen1.5-72b-chat": {
            "rating": 1164.9965721841857,
            "rating_q975": 1170.1919048245386,
            "rating_q025": 1159.8012395438327
        },
        "mistral-medium": {
            "rating": 1164.1399414146185,
            "rating_q975": 1169.5906641676277,
            "rating_q025": 1158.6892186616094
        },
        "llama-3-8b-instruct": {
            "rating": 1163.3958743720361,
            "rating_q975": 1167.0464748992629,
            "rating_q025": 1159.7452738448094
        },
        "reka-flash-21b-20240226": {
            "rating": 1162.9029316843837,
            "rating_q975": 1168.8230948192581,
            "rating_q025": 1156.9827685495093
        },
        "command-r": {
            "rating": 1162.318576565096,
            "rating_q975": 1167.0196331410255,
            "rating_q025": 1157.6175199891666
        },
        "mixtral-8x22b-instruct-v0.1": {
            "rating": 1161.7526485332128,
            "rating_q975": 1166.2095439198483,
            "rating_q025": 1157.2957531465772
        },
        "qwq-32b-preview": {
            "rating": 1161.092820181948,
            "rating_q975": 1172.5539086307253,
            "rating_q025": 1149.6317317331705
        },
        "internlm2_5-20b-chat": {
            "rating": 1158.5342879272453,
            "rating_q975": 1165.5766401755175,
            "rating_q025": 1151.491935678973
        },
        "gemma-2-2b-it": {
            "rating": 1154.4349011710515,
            "rating_q975": 1158.3427129958175,
            "rating_q025": 1150.5270893462855
        },
        "granite-3.1-8b-instruct": {
            "rating": 1148.628983612503,
            "rating_q975": 1159.559292210422,
            "rating_q025": 1137.6986750145838
        },
        "gemini-pro-dev-api": {
            "rating": 1147.561212719405,
            "rating_q975": 1154.8566962314155,
            "rating_q025": 1140.2657292073943
        },
        "zephyr-orpo-141b-A35b-v0.1": {
            "rating": 1144.3767894951284,
            "rating_q975": 1155.2502908870476,
            "rating_q025": 1133.5032881032091
        },
        "qwen1.5-32b-chat": {
            "rating": 1136.6304088921192,
            "rating_q975": 1142.7371310530737,
            "rating_q025": 1130.5236867311648
        },
        "phi-3-medium-4k-instruct": {
            "rating": 1136.273746085431,
            "rating_q975": 1141.3386015122705,
            "rating_q025": 1131.2088906585914
        },
        "mixtral-8x7b-instruct-v0.1": {
            "rating": 1130.909162603561,
            "rating_q975": 1135.111196992601,
            "rating_q025": 1126.7071282145212
        },
        "starling-lm-7b-beta": {
            "rating": 1130.8262068827337,
            "rating_q975": 1138.191675590482,
            "rating_q025": 1123.4607381749854
        },
        "gemini-pro": {
            "rating": 1129.567861243414,
            "rating_q975": 1141.2505855071963,
            "rating_q025": 1117.8851369796316
        },
        "granite-3.1-2b-instruct": {
            "rating": 1128.7054083179348,
            "rating_q975": 1139.7573919231988,
            "rating_q025": 1117.6534247126708
        },
        "yi-34b-chat": {
            "rating": 1127.845654878624,
            "rating_q975": 1134.666229204995,
            "rating_q025": 1121.0250805522528
        },
        "qwen1.5-14b-chat": {
            "rating": 1127.2453050294705,
            "rating_q975": 1134.344536292977,
            "rating_q025": 1120.146073765964
        },
        "gpt-3.5-turbo-0125": {
            "rating": 1123.6414658868678,
            "rating_q975": 1128.2843643982385,
            "rating_q025": 1118.998567375497
        },
        "tulu-2-dpo-70b": {
            "rating": 1120.25491262175,
            "rating_q975": 1130.1339760579167,
            "rating_q025": 1110.3758491855833
        },
        "dbrx-instruct-preview": {
            "rating": 1118.598181259746,
            "rating_q975": 1124.6607331457938,
            "rating_q025": 1112.5356293736984
        },
        "wizardlm-70b": {
            "rating": 1117.1734255402623,
            "rating_q975": 1126.6650323608342,
            "rating_q025": 1107.6818187196905
        },
        "llama-2-70b-chat": {
            "rating": 1114.5560336305514,
            "rating_q975": 1120.0635763770895,
            "rating_q025": 1109.0484908840133
        },
        "nous-hermes-2-mixtral-8x7b-dpo": {
            "rating": 1110.7155489787692,
            "rating_q975": 1122.6561543748908,
            "rating_q025": 1098.7749435826477
        },
        "phi-3-small-8k-instruct": {
            "rating": 1109.078159713621,
            "rating_q975": 1114.9281871679595,
            "rating_q025": 1103.2281322592826
        },
        "llama-3.2-3b-instruct": {
            "rating": 1107.5793864933844,
            "rating_q975": 1115.115960041771,
            "rating_q025": 1100.0428129449979
        },
        "starling-lm-7b-alpha": {
            "rating": 1106.5248847983466,
            "rating_q975": 1114.562268686848,
            "rating_q025": 1098.4875009098453
        },
        "openchat-3.5-0106": {
            "rating": 1104.3802259519173,
            "rating_q975": 1112.3423314755,
            "rating_q025": 1096.4181204283345
        },
        "vicuna-33b": {
            "rating": 1103.565328721496,
            "rating_q975": 1109.7670536958656,
            "rating_q025": 1097.3636037471263
        },
        "deepseek-llm-67b-chat": {
            "rating": 1102.3703749014521,
            "rating_q975": 1114.1371253201064,
            "rating_q025": 1090.6036244827978
        },
        "snowflake-arctic-instruct": {
            "rating": 1098.8254844285752,
            "rating_q975": 1104.755636301071,
            "rating_q025": 1092.8953325560794
        },
        "granite-3.0-8b-instruct": {
            "rating": 1097.798486783344,
            "rating_q975": 1106.348013714816,
            "rating_q025": 1089.248959851872
        },
        "llama2-70b-steerlm-chat": {
            "rating": 1096.790440810255,
            "rating_q975": 1109.4904580085808,
            "rating_q025": 1084.090423611929
        },
        "openchat-3.5": {
            "rating": 1095.0134562885237,
            "rating_q975": 1104.7998058675905,
            "rating_q025": 1085.2271067094568
        },
        "gpt-3.5-turbo-1106": {
            "rating": 1091.855483064368,
            "rating_q975": 1100.7170711392396,
            "rating_q025": 1082.9938949894963
        },
        "openhermes-2.5-mistral-7b": {
            "rating": 1091.6623495492436,
            "rating_q975": 1102.1931841471383,
            "rating_q025": 1081.131514951349
        },
        "gemma-1.1-7b-it": {
            "rating": 1091.560349844733,
            "rating_q975": 1097.5626232775548,
            "rating_q025": 1085.5580764119113
        },
        "mistral-7b-instruct-v0.2": {
            "rating": 1087.5417378051143,
            "rating_q975": 1094.1584068240802,
            "rating_q025": 1080.9250687861484
        },
        "llama-2-13b-chat": {
            "rating": 1083.5425592969896,
            "rating_q975": 1090.259245891013,
            "rating_q025": 1076.825872702966
        },
        "solar-10.7b-instruct-v1.0": {
            "rating": 1083.2174313199348,
            "rating_q975": 1096.54995570221,
            "rating_q025": 1069.8849069376597
        },
        "qwen1.5-7b-chat": {
            "rating": 1081.2569875325883,
            "rating_q975": 1091.0513322303705,
            "rating_q025": 1071.462642834806
        },
        "dolphin-2.2.1-mistral-7b": {
            "rating": 1079.905901859151,
            "rating_q975": 1095.6239795013032,
            "rating_q025": 1064.187824216999
        },
        "granite-3.0-2b-instruct": {
            "rating": 1079.2409715705976,
            "rating_q975": 1087.463698834262,
            "rating_q025": 1071.0182443069332
        },
        "phi-3-mini-4k-instruct-june-2024": {
            "rating": 1078.4188395913548,
            "rating_q975": 1084.7482619912864,
            "rating_q025": 1072.089417191423
        },
        "wizardlm-13b": {
            "rating": 1075.3193644356784,
            "rating_q975": 1084.8080012240523,
            "rating_q025": 1065.8307276473045
        },
        "phi-3-mini-4k-instruct": {
            "rating": 1071.9196250334253,
            "rating_q975": 1078.1858742336444,
            "rating_q025": 1065.6533758332062
        },
        "mpt-30b-chat": {
            "rating": 1066.8351207455498,
            "rating_q975": 1079.2827781183082,
            "rating_q025": 1054.3874633727914
        },
        "zephyr-7b-beta": {
            "rating": 1066.7533804105715,
            "rating_q975": 1075.6225653553622,
            "rating_q025": 1057.8841954657807
        },
        "codellama-34b-instruct": {
            "rating": 1062.937124717214,
            "rating_q975": 1071.8506894915818,
            "rating_q025": 1054.023559942846
        },
        "zephyr-7b-alpha": {
            "rating": 1057.124566974635,
            "rating_q975": 1073.3418831025729,
            "rating_q025": 1040.907250846697
        },
        "vicuna-13b": {
            "rating": 1056.3003829116553,
            "rating_q975": 1062.9848520086043,
            "rating_q025": 1049.6159138147063
        },
        "codellama-70b-instruct": {
            "rating": 1054.793268517638,
            "rating_q975": 1073.3857725423645,
            "rating_q025": 1036.2007644929113
        },
        "falcon-180b-chat": {
            "rating": 1054.3059284973215,
            "rating_q975": 1071.8418844839657,
            "rating_q025": 1036.7699725106772
        },
        "llama-3.2-1b-instruct": {
            "rating": 1053.277216954269,
            "rating_q975": 1060.980142769511,
            "rating_q025": 1045.574291139027
        },
        "gemma-7b-it": {
            "rating": 1053.1687729129153,
            "rating_q975": 1062.8354488245827,
            "rating_q025": 1043.5020970012479
        },
        "guanaco-33b": {
            "rating": 1052.9688291850248,
            "rating_q975": 1065.3024851749146,
            "rating_q025": 1040.635173195135
        },
        "llama-2-7b-chat": {
            "rating": 1051.2410160501104,
            "rating_q975": 1058.2822557912266,
            "rating_q025": 1044.1997763089942
        },
        "qwen-14b-chat": {
            "rating": 1048.8271016934837,
            "rating_q975": 1059.9009220231203,
            "rating_q025": 1037.753281363847
        },
        "phi-3-mini-128k-instruct": {
            "rating": 1048.2556846048938,
            "rating_q975": 1055.5477191929992,
            "rating_q025": 1040.9636500167883
        },
        "smollm2-1.7b-instruct": {
            "rating": 1044.863050607787,
            "rating_q975": 1059.116981284628,
            "rating_q025": 1030.609119930946
        },
        "stripedhyena-nous-7b": {
            "rating": 1036.4709360693003,
            "rating_q975": 1047.5915097549678,
            "rating_q025": 1025.3503623836327
        },
        "vicuna-7b": {
            "rating": 1029.7911411017737,
            "rating_q975": 1039.1498283566768,
            "rating_q025": 1020.4324538468707
        },
        "olmo-7b-instruct": {
            "rating": 1028.660033451706,
            "rating_q975": 1039.9318112600347,
            "rating_q025": 1017.3882556433775
        },
        "palm-2": {
            "rating": 1024.2707027465276,
            "rating_q975": 1033.7676496065847,
            "rating_q025": 1014.7737558864707
        },
        "mistral-7b-instruct": {
            "rating": 1022.0030037692529,
            "rating_q975": 1031.3357921569673,
            "rating_q025": 1012.6702153815387
        },
        "gemma-1.1-2b-it": {
            "rating": 1018.8379714684102,
            "rating_q975": 1026.5846637675693,
            "rating_q025": 1011.091279169251
        },
        "gemma-2b-it": {
            "rating": 999.0717472124643,
            "rating_q975": 1010.86217838963,
            "rating_q025": 987.2813160352986
        },
        "qwen1.5-4b-chat": {
            "rating": 994.4053879257912,
            "rating_q975": 1003.792953270622,
            "rating_q025": 985.0178225809603
        },
        "koala-13b": {
            "rating": 986.4137204575134,
            "rating_q975": 996.571659159526,
            "rating_q025": 976.2557817555007
        },
        "chatglm3-6b": {
            "rating": 969.076896517075,
            "rating_q975": 980.8532853843478,
            "rating_q025": 957.3005076498023
        },
        "gpt4all-13b-snoozy": {
            "rating": 953.8965130636326,
            "rating_q975": 969.5005970876085,
            "rating_q025": 938.2924290396567
        },
        "mpt-7b-chat": {
            "rating": 951.6360196850517,
            "rating_q975": 963.7685744371762,
            "rating_q025": 939.5034649329272
        },
        "RWKV-4-Raven-14B": {
            "rating": 944.9046261812841,
            "rating_q975": 956.5363425999868,
            "rating_q025": 933.2729097625814
        },
        "chatglm2-6b": {
            "rating": 935.1630039961002,
            "rating_q975": 949.0023245040485,
            "rating_q025": 921.3236834881519
        },
        "alpaca-13b": {
            "rating": 926.4242899702526,
            "rating_q975": 938.0791275762667,
            "rating_q025": 914.7694523642385
        },
        "oasst-pythia-12b": {
            "rating": 913.5509392453114,
            "rating_q975": 924.6759344113655,
            "rating_q025": 902.4259440792573
        },
        "chatglm-6b": {
            "rating": 913.4221179452023,
            "rating_q975": 926.2352175706553,
            "rating_q025": 900.6090183197493
        },
        "fastchat-t5-3b": {
            "rating": 890.25061429557,
            "rating_q975": 902.9891983741368,
            "rating_q025": 877.5120302170033
        },
        "stablelm-tuned-alpha-7b": {
            "rating": 862.2370662461446,
            "rating_q975": 875.4325008087538,
            "rating_q025": 849.0416316835355
        },
        "dolly-v2-12b": {
            "rating": 846.5299033329684,
            "rating_q975": 860.3347771108301,
            "rating_q025": 832.7250295551066
        },
        "llama-13b": {
            "rating": 831.1604262540434,
            "rating_q975": 847.3986713594925,
            "rating_q025": 814.9221811485943
        }
    },
    "no_tie": {
        "gemini-2.5-pro": {
            "rating": 1472.3760008933734,
            "rating_q975": 1477.9803724493893,
            "rating_q025": 1466.7716293373576
        },
        "glm-4.6": {
            "rating": 1444.3112519696053,
            "rating_q975": 1453.3378396541234,
            "rating_q025": 1435.2846642850873
        },
        "qwen3-max-preview": {
            "rating": 1434.246055630025,
            "rating_q975": 1441.0189776933478,
            "rating_q025": 1427.4731335667022
        },
        "deepseek-v3.2-exp": {
            "rating": 1428.9938244452537,
            "rating_q975": 1468.0082343909035,
            "rating_q025": 1389.979414499604
        },
        "mistral-medium-2508": {
            "rating": 1424.4339403465015,
            "rating_q975": 1430.9347056103015,
            "rating_q025": 1417.9331750827014
        },
        "glm-4.5": {
            "rating": 1419.7604488887862,
            "rating_q975": 1426.5766177724229,
            "rating_q025": 1412.9442800051495
        },
        "chatgpt-4o-latest-20250326": {
            "rating": 1418.7582485874361,
            "rating_q975": 1424.0928179327348,
            "rating_q025": 1413.4236792421375
        },
        "grok-3-preview-02-24": {
            "rating": 1416.9799270432015,
            "rating_q975": 1422.9570416229476,
            "rating_q025": 1411.0028124634555
        },
        "deepseek-r1-0528": {
            "rating": 1416.9531376595396,
            "rating_q975": 1424.716725022859,
            "rating_q025": 1409.1895502962202
        },
        "claude-sonnet-4-5-20250929-thinking-32k": {
            "rating": 1416.3654035565562,
            "rating_q975": 1424.4767436301383,
            "rating_q025": 1408.254063482974
        },
        "longcat-flash-chat": {
            "rating": 1410.8134742335585,
            "rating_q975": 1419.5675304890633,
            "rating_q025": 1402.0594179780537
        },
        "gpt-4.5-preview-2025-02-27": {
            "rating": 1410.6169626070669,
            "rating_q975": 1419.041644166812,
            "rating_q025": 1402.1922810473218
        },
        "qwen3-vl-235b-a22b-instruct": {
            "rating": 1410.5034636701764,
            "rating_q975": 1419.9883406313395,
            "rating_q025": 1401.0185867090133
        },
        "claude-sonnet-4-5-20250929": {
            "rating": 1409.9133516661561,
            "rating_q975": 1420.1730536917764,
            "rating_q025": 1399.6536496405358
        },
        "deepseek-v3.2-exp-thinking": {
            "rating": 1409.728509448803,
            "rating_q975": 1418.8364768428748,
            "rating_q025": 1400.620542054731
        },
        "claude-opus-4-1-20250805-thinking-16k": {
            "rating": 1407.4941927965376,
            "rating_q975": 1413.818879939547,
            "rating_q025": 1401.1695056535282
        },
        "qwen3-next-80b-a3b-instruct": {
            "rating": 1406.8064846127957,
            "rating_q975": 1413.9030752203707,
            "rating_q025": 1399.7098940052206
        },
        "qwen3-235b-a22b-instruct-2507": {
            "rating": 1405.0944372436168,
            "rating_q975": 1411.184869881694,
            "rating_q025": 1399.0040046055394
        },
        "deepseek-v3.1": {
            "rating": 1404.8043989322184,
            "rating_q975": 1413.084606196886,
            "rating_q025": 1396.524191667551
        },
        "deepseek-v3.1-terminus-thinking": {
            "rating": 1403.5281029040386,
            "rating_q975": 1417.691963584938,
            "rating_q025": 1389.3642422231392
        },
        "deepseek-v3.1-terminus": {
            "rating": 1403.4438014763155,
            "rating_q975": 1417.182959136553,
            "rating_q025": 1389.7046438160778
        },
        "deepseek-v3.1-thinking": {
            "rating": 1402.5901945901296,
            "rating_q975": 1411.528137071562,
            "rating_q025": 1393.6522521086972
        },
        "qwen3-max-2025-09-23": {
            "rating": 1399.8028466373153,
            "rating_q975": 1408.9587130309121,
            "rating_q025": 1390.6469802437184
        },
        "gemini-2.5-flash": {
            "rating": 1399.3762060753963,
            "rating_q975": 1404.727215752887,
            "rating_q025": 1394.0251963979056
        },
        "qwen3-235b-a22b-thinking-2507": {
            "rating": 1398.8215618663573,
            "rating_q975": 1408.0036091409706,
            "rating_q025": 1389.639514591744
        },
        "o3-2025-04-16": {
            "rating": 1395.1298695527412,
            "rating_q975": 1400.3364280520652,
            "rating_q025": 1389.9233110534171
        },
        "claude-opus-4-1-20250805": {
            "rating": 1394.4250928899369,
            "rating_q975": 1400.3716296535633,
            "rating_q025": 1388.4785561263104
        },
        "grok-4-0709": {
            "rating": 1394.2664274180681,
            "rating_q975": 1400.0965385512056,
            "rating_q025": 1388.4363162849306
        },
        "gemini-2.5-flash-preview-09-2025": {
            "rating": 1391.499791975022,
            "rating_q975": 1399.376815551907,
            "rating_q025": 1383.622768398137
        },
        "grok-4-fast": {
            "rating": 1390.5187508672468,
            "rating_q975": 1400.8573194909984,
            "rating_q025": 1380.1801822434952
        },
        "gpt-5-high": {
            "rating": 1388.4962603005777,
            "rating_q975": 1394.8084816418484,
            "rating_q025": 1382.184038959307
        },
        "gpt-5-chat": {
            "rating": 1384.2188327862268,
            "rating_q975": 1390.4850857027607,
            "rating_q025": 1377.952579869693
        },
        "qwen3-vl-235b-a22b-thinking": {
            "rating": 1378.2741027134848,
            "rating_q975": 1387.930996104392,
            "rating_q025": 1368.6172093225775
        },
        "hunyuan-t1-20250711": {
            "rating": 1376.0156582527532,
            "rating_q975": 1388.192332931381,
            "rating_q025": 1363.8389835741252
        },
        "mai-1-preview": {
            "rating": 1372.81980690301,
            "rating_q975": 1380.3590980994813,
            "rating_q025": 1365.2805157065386
        },
        "qwen3-235b-a22b-no-thinking": {
            "rating": 1368.172053161103,
            "rating_q975": 1374.2335001328956,
            "rating_q025": 1362.1106061893101
        },
        "claude-haiku-4-5-20251001": {
            "rating": 1362.7828607761896,
            "rating_q975": 1371.6335456962356,
            "rating_q025": 1353.9321758561437
        },
        "qwen3-30b-a3b-instruct-2507": {
            "rating": 1357.9924784950413,
            "rating_q975": 1364.7560220325645,
            "rating_q025": 1351.228934957518
        },
        "glm-4.5-air": {
            "rating": 1356.1103358334462,
            "rating_q975": 1362.3952046580796,
            "rating_q025": 1349.825467008813
        },
        "gpt-4.1-2025-04-14": {
            "rating": 1355.649526004498,
            "rating_q975": 1360.9714561006995,
            "rating_q025": 1350.3275959082966
        },
        "gemini-2.5-flash-lite-preview-09-2025-no-thinking": {
            "rating": 1351.3718332843732,
            "rating_q975": 1359.2734921164088,
            "rating_q025": 1343.4701744523377
        },
        "kimi-k2-0905-preview": {
            "rating": 1349.2166012872317,
            "rating_q975": 1358.1792870946006,
            "rating_q025": 1340.2539154798628
        },
        "hunyuan-turbos-20250416": {
            "rating": 1346.2142121613272,
            "rating_q975": 1355.0256311447674,
            "rating_q025": 1337.402793177887
        },
        "deepseek-r1": {
            "rating": 1345.3219864763917,
            "rating_q975": 1352.4125169338909,
            "rating_q025": 1338.2314560188925
        },
        "gpt-5-mini-high": {
            "rating": 1344.4248368780916,
            "rating_q975": 1350.9695017752526,
            "rating_q025": 1337.8801719809305
        },
        "deepseek-v3-0324": {
            "rating": 1344.1859795724606,
            "rating_q975": 1349.58252627674,
            "rating_q025": 1338.7894328681812
        },
        "claude-opus-4-20250514-thinking-16k": {
            "rating": 1343.5311278854276,
            "rating_q975": 1349.3922224052096,
            "rating_q025": 1337.6700333656456
        },
        "mistral-medium-2505": {
            "rating": 1337.2515975938436,
            "rating_q975": 1343.655131170016,
            "rating_q025": 1330.8480640176713
        },
        "kimi-k2-0711-preview": {
            "rating": 1336.9907901262384,
            "rating_q975": 1343.4113948177283,
            "rating_q025": 1330.5701854347485
        },
        "qwen2.5-max": {
            "rating": 1336.5362377410881,
            "rating_q975": 1342.36073144497,
            "rating_q025": 1330.7117440372062
        },
        "gemini-2.5-flash-lite-preview-06-17-thinking": {
            "rating": 1335.8390140543281,
            "rating_q975": 1342.0106658199188,
            "rating_q025": 1329.6673622887374
        },
        "o1-2024-12-17": {
            "rating": 1332.741328867059,
            "rating_q975": 1339.0300061352366,
            "rating_q025": 1326.4526515988816
        },
        "qwen3-235b-a22b": {
            "rating": 1332.4261317458097,
            "rating_q975": 1338.9630762143458,
            "rating_q025": 1325.8891872772735
        },
        "grok-3-mini-high": {
            "rating": 1332.3248155677306,
            "rating_q975": 1339.5308301884197,
            "rating_q025": 1325.1188009470416
        },
        "qwen3-next-80b-a3b-thinking": {
            "rating": 1331.6957198077441,
            "rating_q975": 1339.7274143207596,
            "rating_q025": 1323.6640252947286
        },
        "claude-opus-4-20250514": {
            "rating": 1329.7489332231494,
            "rating_q975": 1335.5038728669124,
            "rating_q025": 1323.9939935793864
        },
        "grok-3-mini-beta": {
            "rating": 1327.4900091266302,
            "rating_q975": 1334.3382750787553,
            "rating_q025": 1320.641743174505
        },
        "ling-flash-2.0": {
            "rating": 1326.759055546256,
            "rating_q975": 1336.8980720540108,
            "rating_q025": 1316.620039038501
        },
        "gpt-oss-120b": {
            "rating": 1326.273472969125,
            "rating_q975": 1332.710426003136,
            "rating_q025": 1319.8365199351138
        },
        "amazon-nova-experimental-chat-10-09": {
            "rating": 1324.1739097860686,
            "rating_q975": 1335.1342647836204,
            "rating_q025": 1313.2135547885168
        },
        "gemma-3-27b-it": {
            "rating": 1320.88556994381,
            "rating_q975": 1325.9837320225054,
            "rating_q025": 1315.7874078651146
        },
        "qwen3-coder-480b-a35b-instruct": {
            "rating": 1317.8080659252419,
            "rating_q975": 1324.6385648467804,
            "rating_q025": 1310.9775670037034
        },
        "o4-mini-2025-04-16": {
            "rating": 1315.1478725995164,
            "rating_q975": 1320.6059390388295,
            "rating_q025": 1309.6898061602033
        },
        "o1-preview": {
            "rating": 1313.8136795492176,
            "rating_q975": 1321.0140479931413,
            "rating_q025": 1306.6133111052939
        },
        "step-3": {
            "rating": 1308.6682838002214,
            "rating_q975": 1319.0870776276784,
            "rating_q025": 1298.2494899727644
        },
        "claude-sonnet-4-20250514-thinking-32k": {
            "rating": 1308.6391584245391,
            "rating_q975": 1314.5392313073153,
            "rating_q025": 1302.739085541763
        },
        "minimax-m1": {
            "rating": 1304.7051428104037,
            "rating_q975": 1310.599991821903,
            "rating_q025": 1298.8102937989045
        },
        "gpt-4.1-mini-2025-04-14": {
            "rating": 1295.7864767625636,
            "rating_q975": 1301.6352700628213,
            "rating_q025": 1289.9376834623058
        },
        "qwen3-32b": {
            "rating": 1295.1137763597553,
            "rating_q975": 1309.4460300446299,
            "rating_q025": 1280.7815226748808
        },
        "claude-sonnet-4-20250514": {
            "rating": 1293.5136027596466,
            "rating_q975": 1299.3507701323115,
            "rating_q025": 1287.6764353869817
        },
        "mistral-small-2506": {
            "rating": 1293.093542427114,
            "rating_q975": 1300.340435461136,
            "rating_q025": 1285.846649393092
        },
        "o3-mini-high": {
            "rating": 1290.5033221497938,
            "rating_q975": 1298.0971102482197,
            "rating_q025": 1282.909534051368
        },
        "nvidia-llama-3.3-nemotron-super-49b-v1.5": {
            "rating": 1289.3666662978496,
            "rating_q975": 1303.8097592606948,
            "rating_q025": 1274.9235733350044
        },
        "deepseek-v3": {
            "rating": 1288.938988125702,
            "rating_q975": 1296.1096290518951,
            "rating_q025": 1281.768347199509
        },
        "step-1o-turbo-202506": {
            "rating": 1288.7826299975454,
            "rating_q975": 1298.0815310734806,
            "rating_q025": 1279.4837289216102
        },
        "gemma-3-12b-it": {
            "rating": 1288.1821702452455,
            "rating_q975": 1302.3094786836368,
            "rating_q025": 1274.0548618068542
        },
        "glm-4.5v": {
            "rating": 1284.8395397890924,
            "rating_q975": 1297.005212320696,
            "rating_q025": 1272.6738672574888
        },
        "glm-4-plus-0111": {
            "rating": 1284.501770219751,
            "rating_q975": 1297.0401876317792,
            "rating_q025": 1271.963352807723
        },
        "ring-flash-2.0": {
            "rating": 1283.9279162183059,
            "rating_q975": 1294.066572893859,
            "rating_q025": 1273.7892595427527
        },
        "gemini-2.0-flash-lite-preview-02-05": {
            "rating": 1280.6964232840005,
            "rating_q975": 1287.1791305853678,
            "rating_q025": 1274.2137159826332
        },
        "qwen-plus-0125": {
            "rating": 1279.4731808351694,
            "rating_q975": 1292.2367484354606,
            "rating_q025": 1266.7096132348781
        },
        "command-a-03-2025": {
            "rating": 1279.3059261507847,
            "rating_q975": 1284.4628153198491,
            "rating_q025": 1274.1490369817202
        },
        "qwq-32b": {
            "rating": 1278.7103469982226,
            "rating_q975": 1285.133345373164,
            "rating_q025": 1272.287348623281
        },
        "step-2-16k-exp-202412": {
            "rating": 1272.0919072622899,
            "rating_q975": 1285.8613567784914,
            "rating_q025": 1258.3224577460883
        },
        "gpt-5-nano-high": {
            "rating": 1268.7532231296047,
            "rating_q975": 1278.1983011405896,
            "rating_q025": 1259.30814511862
        },
        "gemini-1.5-pro-002": {
            "rating": 1266.2342169686224,
            "rating_q975": 1271.2326563060574,
            "rating_q025": 1261.2357776311874
        },
        "o3-mini": {
            "rating": 1265.5562369550105,
            "rating_q975": 1270.3765039129232,
            "rating_q025": 1260.7359699970978
        },
        "hunyuan-turbos-20250226": {
            "rating": 1263.589592108312,
            "rating_q975": 1282.6075258130345,
            "rating_q025": 1244.5716584035895
        },
        "llama-3.1-nemotron-ultra-253b-v1": {
            "rating": 1262.82989179389,
            "rating_q975": 1280.1688223139768,
            "rating_q025": 1245.4909612738034
        },
        "o1-mini": {
            "rating": 1262.8049269195765,
            "rating_q975": 1268.0841317675108,
            "rating_q025": 1257.5257220716421
        },
        "claude-3-7-sonnet-20250219-thinking-32k": {
            "rating": 1261.3161561999598,
            "rating_q975": 1266.903769542061,
            "rating_q025": 1255.7285428578587
        },
        "qwen3-30b-a3b": {
            "rating": 1260.8880559994668,
            "rating_q975": 1267.5066461511938,
            "rating_q025": 1254.2694658477399
        },
        "llama-3.3-nemotron-49b-super-v1": {
            "rating": 1252.1730337634826,
            "rating_q975": 1271.1922913734422,
            "rating_q025": 1233.153776153523
        },
        "hunyuan-turbo-0110": {
            "rating": 1247.262036862303,
            "rating_q975": 1266.4060636463041,
            "rating_q025": 1228.1180100783017
        },
        "gemma-3n-e4b-it": {
            "rating": 1246.6630400888107,
            "rating_q975": 1253.7213352172278,
            "rating_q025": 1239.6047449603936
        },
        "grok-2-2024-08-13": {
            "rating": 1244.312762038726,
            "rating_q975": 1249.62030076281,
            "rating_q025": 1239.005223314642
        },
        "yi-lightning": {
            "rating": 1241.8658282638626,
            "rating_q975": 1249.2864662541558,
            "rating_q025": 1234.4451902735693
        },
        "gpt-4o-2024-05-13": {
            "rating": 1238.418765421074,
            "rating_q975": 1243.666728314951,
            "rating_q025": 1233.1708025271973
        },
        "claude-3-5-sonnet-20241022": {
            "rating": 1236.3319880716317,
            "rating_q975": 1240.3881828565325,
            "rating_q025": 1232.275793286731
        },
        "qwen2.5-plus-1127": {
            "rating": 1235.6297494711048,
            "rating_q975": 1245.6057535500902,
            "rating_q025": 1225.6537453921194
        },
        "deepseek-v2.5-1210": {
            "rating": 1228.9322615924834,
            "rating_q975": 1241.9606808991032,
            "rating_q025": 1215.9038422858637
        },
        "athene-v2-chat": {
            "rating": 1223.6897512296214,
            "rating_q975": 1230.5733978326216,
            "rating_q025": 1216.8061046266212
        },
        "gpt-oss-20b": {
            "rating": 1223.5251402002493,
            "rating_q975": 1232.3955216707434,
            "rating_q025": 1214.6547587297553
        },
        "llama-4-maverick-17b-128e-instruct": {
            "rating": 1222.6279754143134,
            "rating_q975": 1228.5903753735963,
            "rating_q025": 1216.6655754550304
        },
        "glm-4-plus": {
            "rating": 1221.4715740554325,
            "rating_q975": 1228.9898380812242,
            "rating_q025": 1213.9533100296408
        },
        "gemma-3-4b-it": {
            "rating": 1220.707618029065,
            "rating_q975": 1234.5748563216198,
            "rating_q025": 1206.8403797365104
        },
        "hunyuan-large-2025-02-10": {
            "rating": 1216.707576410648,
            "rating_q975": 1231.8731416195005,
            "rating_q025": 1201.5420112017955
        },
        "gpt-4o-mini-2024-07-18": {
            "rating": 1216.2937179335888,
            "rating_q975": 1221.2897811901585,
            "rating_q025": 1211.2976546770192
        },
        "gemini-1.5-flash-002": {
            "rating": 1215.893576733344,
            "rating_q975": 1222.1853965347177,
            "rating_q025": 1209.6017569319702
        },
        "llama-3.1-405b-instruct-bf16": {
            "rating": 1213.592870112398,
            "rating_q975": 1218.9513411318474,
            "rating_q025": 1208.2343990929487
        },
        "llama-3.1-nemotron-70b-instruct": {
            "rating": 1211.1959691989798,
            "rating_q975": 1222.5243143277717,
            "rating_q025": 1199.867624070188
        },
        "llama-4-scout-17b-16e-instruct": {
            "rating": 1210.7348827573658,
            "rating_q975": 1217.3403697844587,
            "rating_q025": 1204.1293957302728
        },
        "gpt-4.1-nano-2025-04-14": {
            "rating": 1210.43305356851,
            "rating_q975": 1222.5078148816606,
            "rating_q025": 1198.3582922553596
        },
        "gpt-4o-2024-08-06": {
            "rating": 1209.5147194696926,
            "rating_q975": 1215.8003511828872,
            "rating_q025": 1203.229087756498
        },
        "llama-3.1-405b-instruct-fp8": {
            "rating": 1209.2849823569709,
            "rating_q975": 1214.8067424027504,
            "rating_q025": 1203.7632223111914
        },
        "grok-2-mini-2024-08-13": {
            "rating": 1208.7239241354814,
            "rating_q975": 1214.2789741422105,
            "rating_q025": 1203.1688741287523
        },
        "qwen-max-0919": {
            "rating": 1206.0434971406773,
            "rating_q975": 1214.5240297522184,
            "rating_q025": 1197.5629645291363
        },
        "claude-3-5-sonnet-20240620": {
            "rating": 1205.9644936229433,
            "rating_q975": 1210.9685128764136,
            "rating_q025": 1200.960474369473
        },
        "mistral-small-3.1-24b-instruct-2503": {
            "rating": 1204.5664682155402,
            "rating_q975": 1210.9860085905634,
            "rating_q025": 1198.146927840517
        },
        "gemini-advanced-0514": {
            "rating": 1203.4136258514095,
            "rating_q975": 1210.6457891740497,
            "rating_q025": 1196.1814625287693
        },
        "llama-3.3-70b-instruct": {
            "rating": 1201.3173838505154,
            "rating_q975": 1206.153024996146,
            "rating_q025": 1196.4817427048847
        },
        "hunyuan-standard-2025-02-10": {
            "rating": 1200.2445469338006,
            "rating_q975": 1215.5149761854193,
            "rating_q025": 1184.974117682182
        },
        "gemini-1.5-pro-001": {
            "rating": 1195.3593380114671,
            "rating_q975": 1201.443634788153,
            "rating_q025": 1189.2750412347812
        },
        "deepseek-v2.5": {
            "rating": 1193.1813181504608,
            "rating_q975": 1200.526520732322,
            "rating_q025": 1185.8361155685996
        },
        "hunyuan-large-vision": {
            "rating": 1190.4376802144625,
            "rating_q975": 1203.1459971273025,
            "rating_q025": 1177.7293633016225
        },
        "gpt-4-turbo-2024-04-09": {
            "rating": 1190.4257885629493,
            "rating_q975": 1196.1423345155126,
            "rating_q025": 1184.709242610386
        },
        "qwen2.5-72b-instruct": {
            "rating": 1189.4779074650532,
            "rating_q975": 1195.6838612787121,
            "rating_q025": 1183.2719536513944
        },
        "athene-70b-0725": {
            "rating": 1187.5183074838988,
            "rating_q975": 1196.1815620913537,
            "rating_q025": 1178.8550528764438
        },
        "mistral-large-2407": {
            "rating": 1185.8494674705703,
            "rating_q975": 1191.7857922586425,
            "rating_q025": 1179.9131426824981
        },
        "mistral-large-2411": {
            "rating": 1179.312909545155,
            "rating_q975": 1185.977013870815,
            "rating_q025": 1172.648805219495
        },
        "magistral-medium-2506": {
            "rating": 1177.932324061244,
            "rating_q975": 1186.865523211345,
            "rating_q025": 1168.9991249111429
        },
        "llama-3.1-70b-instruct": {
            "rating": 1177.3007249882896,
            "rating_q975": 1182.9566988446936,
            "rating_q025": 1171.6447511318856
        },
        "claude-3-opus-20240229": {
            "rating": 1174.9137667014543,
            "rating_q975": 1179.399339206204,
            "rating_q025": 1170.4281941967045
        },
        "gpt-4-1106-preview": {
            "rating": 1174.0492148094868,
            "rating_q975": 1179.859108724113,
            "rating_q025": 1168.2393208948606
        },
        "claude-3-5-haiku-20241022": {
            "rating": 1172.2429463955023,
            "rating_q975": 1176.774340190861,
            "rating_q025": 1167.7115526001435
        },
        "gpt-4-0125-preview": {
            "rating": 1171.9263510954847,
            "rating_q975": 1177.9756694084099,
            "rating_q025": 1165.8770327825596
        },
        "amazon-nova-pro-v1.0": {
            "rating": 1169.0881467480158,
            "rating_q975": 1176.0153488318315,
            "rating_q025": 1162.1609446642
        },
        "llama-3.1-tulu-3-70b": {
            "rating": 1168.8992528555477,
            "rating_q975": 1186.4011373445753,
            "rating_q025": 1151.3973683665201
        },
        "reka-core-20240904": {
            "rating": 1155.9671022716525,
            "rating_q975": 1167.5319845288068,
            "rating_q025": 1144.4022200144982
        },
        "gemini-1.5-flash-001": {
            "rating": 1142.291677014374,
            "rating_q975": 1148.8968553236327,
            "rating_q025": 1135.6864987051154
        },
        "jamba-1.5-large": {
            "rating": 1140.1096862967856,
            "rating_q975": 1151.296817625508,
            "rating_q025": 1128.9225549680632
        },
        "mistral-small-24b-instruct-2501": {
            "rating": 1129.4169334134162,
            "rating_q975": 1138.5595751365647,
            "rating_q025": 1120.2742916902678
        },
        "gemma-2-27b-it": {
            "rating": 1129.129013857716,
            "rating_q975": 1134.0848915908985,
            "rating_q025": 1124.1731361245336
        },
        "qwen2.5-coder-32b-instruct": {
            "rating": 1125.6682952845345,
            "rating_q975": 1138.9376752063538,
            "rating_q025": 1112.3989153627151
        },
        "command-r-plus-08-2024": {
            "rating": 1125.6158394770991,
            "rating_q975": 1135.846331455516,
            "rating_q025": 1115.3853474986822
        },
        "glm-4-0520": {
            "rating": 1123.854628790752,
            "rating_q975": 1134.6527533206079,
            "rating_q025": 1113.0565042608962
        },
        "gemma-2-9b-it-simpo": {
            "rating": 1123.159713582679,
            "rating_q975": 1133.808860831089,
            "rating_q025": 1112.5105663342688
        },
        "nemotron-4-340b-instruct": {
            "rating": 1122.3674491428771,
            "rating_q975": 1130.6193499849321,
            "rating_q025": 1114.1155483008222
        },
        "llama-3.1-nemotron-51b-instruct": {
            "rating": 1121.7696765446992,
            "rating_q975": 1137.763618817066,
            "rating_q025": 1105.7757342723326
        },
        "amazon-nova-lite-v1.0": {
            "rating": 1119.9103737561368,
            "rating_q975": 1127.9469496614724,
            "rating_q025": 1111.873797850801
        },
        "gemini-1.5-flash-8b-001": {
            "rating": 1118.921301896322,
            "rating_q975": 1125.5061234591913,
            "rating_q025": 1112.3364803334525
        },
        "llama-3-70b-instruct": {
            "rating": 1115.8186317371064,
            "rating_q975": 1121.2755661308372,
            "rating_q025": 1110.3616973433757
        },
        "c4ai-aya-expanse-32b": {
            "rating": 1115.3334317133363,
            "rating_q975": 1122.9785760344917,
            "rating_q025": 1107.6882873921809
        },
        "claude-3-sonnet-20240229": {
            "rating": 1108.5876866067224,
            "rating_q975": 1114.3490781844007,
            "rating_q025": 1102.826295029044
        },
        "olmo-2-0325-32b-instruct": {
            "rating": 1106.5435314351935,
            "rating_q975": 1123.8214258689,
            "rating_q025": 1089.265637001487
        },
        "reka-flash-20240904": {
            "rating": 1103.2130997122208,
            "rating_q975": 1115.0822052054166,
            "rating_q025": 1091.343994219025
        },
        "phi-4": {
            "rating": 1099.924170988766,
            "rating_q975": 1107.5027117280908,
            "rating_q025": 1092.3456302494412
        },
        "command-r-plus": {
            "rating": 1091.7883811483744,
            "rating_q975": 1098.0187304438311,
            "rating_q025": 1085.5580318529176
        },
        "gemma-2-9b-it": {
            "rating": 1090.571843976973,
            "rating_q975": 1096.2507617983836,
            "rating_q025": 1084.8929261555625
        },
        "qwen2-72b-instruct": {
            "rating": 1086.9014413057619,
            "rating_q975": 1094.1385768660796,
            "rating_q025": 1079.6643057454442
        },
        "amazon-nova-micro-v1.0": {
            "rating": 1085.5700794114068,
            "rating_q975": 1093.8191172645793,
            "rating_q025": 1077.3210415582344
        },
        "gpt-4-0314": {
            "rating": 1085.3113584821258,
            "rating_q975": 1092.3474321384372,
            "rating_q025": 1078.2752848258144
        },
        "hunyuan-standard-256k": {
            "rating": 1080.8307605480945,
            "rating_q975": 1099.1991942415048,
            "rating_q025": 1062.4623268546843
        },
        "claude-3-haiku-20240307": {
            "rating": 1075.7933643833535,
            "rating_q975": 1081.4861037490984,
            "rating_q025": 1070.1006250176085
        },
        "deepseek-coder-v2": {
            "rating": 1070.291664314194,
            "rating_q975": 1079.7434713516316,
            "rating_q025": 1060.8398572767562
        },
        "llama-3.1-tulu-3-8b": {
            "rating": 1061.1712364548441,
            "rating_q975": 1080.1913073228943,
            "rating_q025": 1042.151165586794
        },
        "ministral-8b-2410": {
            "rating": 1060.4914126866483,
            "rating_q975": 1075.4048682464895,
            "rating_q025": 1045.5779571268072
        },
        "gpt-4-0613": {
            "rating": 1058.7938194882877,
            "rating_q975": 1064.6974846655755,
            "rating_q025": 1052.8901543109998
        },
        "jamba-1.5-mini": {
            "rating": 1058.3193086021406,
            "rating_q975": 1070.0167026269883,
            "rating_q025": 1046.621914577293
        },
        "command-r-08-2024": {
            "rating": 1058.09415624473,
            "rating_q975": 1068.6246104303045,
            "rating_q025": 1047.5637020591553
        },
        "llama-3.1-8b-instruct": {
            "rating": 1056.0592845267975,
            "rating_q975": 1062.4588691755632,
            "rating_q025": 1049.6596998780317
        },
        "c4ai-aya-expanse-8b": {
            "rating": 1054.4488163766762,
            "rating_q975": 1065.9832270360941,
            "rating_q025": 1042.9144057172582
        },
        "mistral-large-2402": {
            "rating": 1046.4327831227783,
            "rating_q975": 1053.2707861860017,
            "rating_q025": 1039.594780059555
        },
        "qwen1.5-110b-chat": {
            "rating": 1044.8914049217542,
            "rating_q975": 1053.4644091244602,
            "rating_q025": 1036.3184007190482
        },
        "yi-1.5-34b-chat": {
            "rating": 1042.4310284460987,
            "rating_q975": 1050.5882246233589,
            "rating_q025": 1034.2738322688385
        },
        "reka-flash-21b-20240226-online": {
            "rating": 1040.7009532889133,
            "rating_q975": 1051.6543668302504,
            "rating_q025": 1029.7475397475762
        },
        "qwen1.5-72b-chat": {
            "rating": 1033.231104810388,
            "rating_q975": 1041.0810520779437,
            "rating_q025": 1025.3811575428322
        },
        "reka-flash-21b-20240226": {
            "rating": 1032.3360519504354,
            "rating_q975": 1041.5352310144735,
            "rating_q025": 1023.1368728863972
        },
        "mistral-medium": {
            "rating": 1030.8643242929106,
            "rating_q975": 1038.837335774235,
            "rating_q025": 1022.8913128115863
        },
        "llama-3-8b-instruct": {
            "rating": 1030.6439625418632,
            "rating_q975": 1036.5339589258074,
            "rating_q025": 1024.753966157919
        },
        "command-r": {
            "rating": 1029.0167522976112,
            "rating_q975": 1036.067990694276,
            "rating_q025": 1021.9655139009466
        },
        "qwq-32b-preview": {
            "rating": 1024.5720104073212,
            "rating_q975": 1042.8324686141739,
            "rating_q025": 1006.3115522004684
        },
        "mixtral-8x22b-instruct-v0.1": {
            "rating": 1023.9173436359921,
            "rating_q975": 1030.7986900369888,
            "rating_q025": 1017.0359972349954
        },
        "internlm2_5-20b-chat": {
            "rating": 1012.546076096062,
            "rating_q975": 1024.5607201062523,
            "rating_q025": 1000.5314320858718
        },
        "gemini-pro-dev-api": {
            "rating": 1008.466430342454,
            "rating_q975": 1018.9768439609135,
            "rating_q025": 997.9560167239946
        },
        "gemma-2-2b-it": {
            "rating": 1005.1698771846137,
            "rating_q975": 1011.6484051724319,
            "rating_q025": 998.6913491967955
        },
        "zephyr-orpo-141b-A35b-v0.1": {
            "rating": 999.9004606875923,
            "rating_q975": 1015.6483202108134,
            "rating_q025": 984.1526011643712
        },
        "granite-3.1-8b-instruct": {
            "rating": 994.0354368543394,
            "rating_q975": 1013.6965788106179,
            "rating_q025": 974.374294898061
        },
        "qwen1.5-32b-chat": {
            "rating": 990.3280977804664,
            "rating_q975": 999.7017186453309,
            "rating_q025": 980.9544769156018
        },
        "starling-lm-7b-beta": {
            "rating": 986.9651653089588,
            "rating_q975": 997.7558525433236,
            "rating_q025": 976.174478074594
        },
        "mixtral-8x7b-instruct-v0.1": {
            "rating": 979.1252902098561,
            "rating_q975": 985.5649190337738,
            "rating_q025": 972.6856613859384
        },
        "phi-3-medium-4k-instruct": {
            "rating": 978.8115533067472,
            "rating_q975": 987.2730652724613,
            "rating_q025": 970.3500413410331
        },
        "gemini-pro": {
            "rating": 978.791670018139,
            "rating_q975": 994.9791170273944,
            "rating_q025": 962.6042230088837
        },
        "qwen1.5-14b-chat": {
            "rating": 978.2205132306048,
            "rating_q975": 989.1020589598827,
            "rating_q025": 967.3389675013268
        },
        "yi-34b-chat": {
            "rating": 976.8470545828721,
            "rating_q975": 986.8166750286736,
            "rating_q025": 966.8774341370707
        },
        "gpt-3.5-turbo-0125": {
            "rating": 968.3885966118191,
            "rating_q975": 975.217408960901,
            "rating_q025": 961.5597842627373
        },
        "wizardlm-70b": {
            "rating": 967.2723240716365,
            "rating_q975": 980.4390920572673,
            "rating_q025": 954.1055560860057
        },
        "tulu-2-dpo-70b": {
            "rating": 964.0124482454726,
            "rating_q975": 977.9842101449312,
            "rating_q025": 950.0406863460139
        },
        "dbrx-instruct-preview": {
            "rating": 959.8708250121767,
            "rating_q975": 969.1333215347078,
            "rating_q025": 950.6083284896457
        },
        "llama-2-70b-chat": {
            "rating": 956.0813482467493,
            "rating_q975": 964.1830477187777,
            "rating_q025": 947.9796487747208
        },
        "nous-hermes-2-mixtral-8x7b-dpo": {
            "rating": 952.2576194475259,
            "rating_q975": 969.359472529303,
            "rating_q025": 935.1557663657488
        },
        "granite-3.1-2b-instruct": {
            "rating": 948.2104471786465,
            "rating_q975": 969.363682165172,
            "rating_q025": 927.057212192121
        },
        "vicuna-33b": {
            "rating": 946.0033633585413,
            "rating_q975": 955.190036667119,
            "rating_q025": 936.8166900499635
        },
        "starling-lm-7b-alpha": {
            "rating": 945.9181841881364,
            "rating_q975": 957.5661114494613,
            "rating_q025": 934.2702569268114
        },
        "openchat-3.5-0106": {
            "rating": 944.8652448213152,
            "rating_q975": 956.444202561165,
            "rating_q025": 933.2862870814654
        },
        "deepseek-llm-67b-chat": {
            "rating": 941.8238375796832,
            "rating_q975": 958.7653095922515,
            "rating_q025": 924.8823655671149
        },
        "phi-3-small-8k-instruct": {
            "rating": 936.5763783286516,
            "rating_q975": 946.9117833141647,
            "rating_q025": 926.2409733431384
        },
        "llama-3.2-3b-instruct": {
            "rating": 932.5284776365338,
            "rating_q975": 945.9372331844678,
            "rating_q025": 919.1197220885998
        },
        "llama2-70b-steerlm-chat": {
            "rating": 931.8427031574652,
            "rating_q975": 949.354918013654,
            "rating_q025": 914.3304883012763
        },
        "openchat-3.5": {
            "rating": 929.8042883021446,
            "rating_q975": 943.8946551382461,
            "rating_q025": 915.7139214660432
        },
        "snowflake-arctic-instruct": {
            "rating": 928.4566527746616,
            "rating_q975": 937.9807584603259,
            "rating_q025": 918.9325470889974
        },
        "openhermes-2.5-mistral-7b": {
            "rating": 925.3984519909918,
            "rating_q975": 940.6193573899474,
            "rating_q025": 910.1775465920363
        },
        "gpt-3.5-turbo-1106": {
            "rating": 923.1133881860521,
            "rating_q975": 935.4240280449712,
            "rating_q025": 910.802748327133
        },
        "gemma-1.1-7b-it": {
            "rating": 919.8955299815406,
            "rating_q975": 928.86660739863,
            "rating_q025": 910.9244525644511
        },
        "mistral-7b-instruct-v0.2": {
            "rating": 916.2457228126971,
            "rating_q975": 926.2832231115029,
            "rating_q025": 906.2082225138912
        },
        "granite-3.0-8b-instruct": {
            "rating": 912.6070867439487,
            "rating_q975": 928.4725277976758,
            "rating_q025": 896.7416456902216
        },
        "solar-10.7b-instruct-v1.0": {
            "rating": 910.2789620521678,
            "rating_q975": 929.4294480193437,
            "rating_q025": 891.1284760849919
        },
        "llama-2-13b-chat": {
            "rating": 909.6773281330131,
            "rating_q975": 919.6256692238214,
            "rating_q025": 899.7289870422048
        },
        "qwen1.5-7b-chat": {
            "rating": 907.6907938325577,
            "rating_q975": 922.856521966703,
            "rating_q025": 892.5250656984124
        },
        "dolphin-2.2.1-mistral-7b": {
            "rating": 906.109920290741,
            "rating_q975": 928.6497525932512,
            "rating_q025": 883.5700879882309
        },
        "wizardlm-13b": {
            "rating": 906.0608050816004,
            "rating_q975": 919.5893482622139,
            "rating_q025": 892.5322619009869
        },
        "mpt-30b-chat": {
            "rating": 896.8397887047369,
            "rating_q975": 914.9023336759147,
            "rating_q025": 878.777243733559
        },
        "zephyr-7b-beta": {
            "rating": 889.0708671682744,
            "rating_q975": 901.5313714462263,
            "rating_q025": 876.6103628903224
        },
        "codellama-34b-instruct": {
            "rating": 883.4574735217552,
            "rating_q975": 896.209147879392,
            "rating_q025": 870.7057991641184
        },
        "zephyr-7b-alpha": {
            "rating": 877.6726408343754,
            "rating_q975": 900.576004847971,
            "rating_q025": 854.7692768207799
        },
        "granite-3.0-2b-instruct": {
            "rating": 874.4092874311066,
            "rating_q975": 891.2045900465608,
            "rating_q025": 857.6139848156523
        },
        "guanaco-33b": {
            "rating": 874.0401344188492,
            "rating_q975": 892.1233678494491,
            "rating_q025": 855.9569009882493
        },
        "phi-3-mini-4k-instruct-june-2024": {
            "rating": 873.6161340727964,
            "rating_q975": 885.752587926974,
            "rating_q025": 861.4796802186188
        },
        "codellama-70b-instruct": {
            "rating": 872.8817225800486,
            "rating_q975": 901.0460309506307,
            "rating_q025": 844.7174142094666
        },
        "phi-3-mini-4k-instruct": {
            "rating": 872.2081481828454,
            "rating_q975": 883.4731697640212,
            "rating_q025": 860.9431266016696
        },
        "vicuna-13b": {
            "rating": 869.742472781161,
            "rating_q975": 879.7405283506669,
            "rating_q025": 859.7444172116552
        },
        "falcon-180b-chat": {
            "rating": 869.4059214224601,
            "rating_q975": 893.588832199233,
            "rating_q025": 845.2230106456872
        },
        "qwen-14b-chat": {
            "rating": 866.3970655641248,
            "rating_q975": 882.1870797579888,
            "rating_q025": 850.6070513702607
        },
        "gemma-7b-it": {
            "rating": 864.0924529173035,
            "rating_q975": 878.5134787716518,
            "rating_q025": 849.6714270629552
        },
        "llama-2-7b-chat": {
            "rating": 862.2567113671787,
            "rating_q975": 872.6688006495823,
            "rating_q025": 851.8446220847751
        },
        "phi-3-mini-128k-instruct": {
            "rating": 847.1223582604428,
            "rating_q975": 859.6907035945623,
            "rating_q025": 834.5540129263233
        },
        "vicuna-7b": {
            "rating": 842.6215856930762,
            "rating_q975": 856.1011746584429,
            "rating_q025": 829.1419967277095
        },
        "stripedhyena-nous-7b": {
            "rating": 840.4472495062944,
            "rating_q975": 857.1555525039413,
            "rating_q025": 823.7389465086475
        },
        "palm-2": {
            "rating": 831.3335980021114,
            "rating_q975": 844.3252685781197,
            "rating_q025": 818.3419274261032
        },
        "olmo-7b-instruct": {
            "rating": 826.9209650375694,
            "rating_q975": 844.4318640254862,
            "rating_q025": 809.4100660496526
        },
        "llama-3.2-1b-instruct": {
            "rating": 825.3212518075463,
            "rating_q975": 841.0333138939691,
            "rating_q025": 809.6091897211236
        },
        "mistral-7b-instruct": {
            "rating": 820.8165000700967,
            "rating_q975": 834.4645471668628,
            "rating_q025": 807.1684529733307
        },
        "smollm2-1.7b-instruct": {
            "rating": 806.9428838519993,
            "rating_q975": 838.5513754241624,
            "rating_q025": 775.3343922798363
        },
        "gemma-1.1-2b-it": {
            "rating": 798.259899298045,
            "rating_q975": 811.807813896951,
            "rating_q025": 784.711984699139
        },
        "koala-13b": {
            "rating": 782.8667419607197,
            "rating_q975": 798.3116765598413,
            "rating_q025": 767.421807361598
        },
        "gemma-2b-it": {
            "rating": 780.9959147922548,
            "rating_q975": 799.4063062314607,
            "rating_q025": 762.5855233530489
        },
        "qwen1.5-4b-chat": {
            "rating": 764.6339785812382,
            "rating_q975": 780.4980191235105,
            "rating_q025": 748.769938038966
        },
        "chatglm3-6b": {
            "rating": 742.962118796092,
            "rating_q975": 761.3722019207361,
            "rating_q025": 724.5520356714479
        },
        "mpt-7b-chat": {
            "rating": 728.5994389512707,
            "rating_q975": 746.8329828415797,
            "rating_q025": 710.3658950609617
        },
        "gpt4all-13b-snoozy": {
            "rating": 727.1330916176707,
            "rating_q975": 751.24833655051,
            "rating_q025": 703.0178466848315
        },
        "RWKV-4-Raven-14B": {
            "rating": 723.2851693102938,
            "rating_q975": 740.9187007043373,
            "rating_q025": 705.6516379162503
        },
        "alpaca-13b": {
            "rating": 699.0120326602417,
            "rating_q975": 716.2329595130517,
            "rating_q025": 681.7911058074318
        },
        "chatglm2-6b": {
            "rating": 686.696939940314,
            "rating_q975": 708.6926843078609,
            "rating_q025": 664.7011955727671
        },
        "oasst-pythia-12b": {
            "rating": 673.1766585991534,
            "rating_q975": 689.763425243269,
            "rating_q025": 656.5898919550377
        },
        "chatglm-6b": {
            "rating": 663.1567848781394,
            "rating_q975": 682.600669935481,
            "rating_q025": 643.7128998207978
        },
        "fastchat-t5-3b": {
            "rating": 635.8448371404997,
            "rating_q975": 655.1976150989673,
            "rating_q025": 616.4920591820322
        },
        "stablelm-tuned-alpha-7b": {
            "rating": 584.6310853185291,
            "rating_q975": 606.3589750129894,
            "rating_q025": 562.9031956240689
        },
        "dolly-v2-12b": {
            "rating": 569.2856656203797,
            "rating_q975": 591.4245159737825,
            "rating_q025": 547.146815266977
        },
        "llama-13b": {
            "rating": 533.5360185903645,
            "rating_q975": 559.615908700949,
            "rating_q025": 507.45612847978
        }
    },
    "russian": {
        "gemini-2.5-pro": {
            "rating": 1472.6931286747647,
            "rating_q975": 1483.474355618136,
            "rating_q025": 1461.9119017313933
        },
        "deepseek-v3.1-terminus-thinking": {
            "rating": 1432.5472933937374,
            "rating_q975": 1468.8617493476022,
            "rating_q025": 1396.2328374398726
        },
        "deepseek-v3.1-terminus": {
            "rating": 1431.0532553233008,
            "rating_q975": 1465.5911114169069,
            "rating_q025": 1396.5153992296948
        },
        "claude-sonnet-4-5-20250929": {
            "rating": 1430.0078836745454,
            "rating_q975": 1460.657559240602,
            "rating_q025": 1399.3582081084887
        },
        "qwen3-max-2025-09-23": {
            "rating": 1422.5695841037607,
            "rating_q975": 1446.6718042712666,
            "rating_q025": 1398.4673639362547
        },
        "grok-4-0709": {
            "rating": 1422.1138342207762,
            "rating_q975": 1436.1081898323064,
            "rating_q025": 1408.119478609246
        },
        "deepseek-r1-0528": {
            "rating": 1420.5520691835482,
            "rating_q975": 1436.8516644901456,
            "rating_q025": 1404.2524738769507
        },
        "claude-opus-4-1-20250805": {
            "rating": 1420.4124117471868,
            "rating_q975": 1433.3990190811974,
            "rating_q025": 1407.4258044131761
        },
        "chatgpt-4o-latest-20250326": {
            "rating": 1419.6783476654355,
            "rating_q975": 1430.4788348549157,
            "rating_q025": 1408.8778604759552
        },
        "qwen3-max-preview": {
            "rating": 1419.3470871394868,
            "rating_q975": 1436.547462357299,
            "rating_q025": 1402.1467119216745
        },
        "gemini-2.5-flash": {
            "rating": 1419.221396472382,
            "rating_q975": 1429.3510887148195,
            "rating_q025": 1409.0917042299443
        },
        "gpt-4.5-preview-2025-02-27": {
            "rating": 1417.1790504347346,
            "rating_q975": 1432.3490367837715,
            "rating_q025": 1402.0090640856977
        },
        "grok-3-preview-02-24": {
            "rating": 1416.1141862485795,
            "rating_q975": 1427.6095431971416,
            "rating_q025": 1404.6188293000173
        },
        "gemini-2.5-flash-preview-09-2025": {
            "rating": 1414.0886166463079,
            "rating_q975": 1435.688572173082,
            "rating_q025": 1392.4886611195336
        },
        "mistral-medium-2508": {
            "rating": 1412.868489635411,
            "rating_q975": 1427.9131867767248,
            "rating_q025": 1397.823792494097
        },
        "claude-opus-4-1-20250805-thinking-16k": {
            "rating": 1412.106286148664,
            "rating_q975": 1427.887827408231,
            "rating_q025": 1396.3247448890968
        },
        "glm-4.5": {
            "rating": 1411.9845336510248,
            "rating_q975": 1428.3011722062006,
            "rating_q025": 1395.667895095849
        },
        "deepseek-v3.1": {
            "rating": 1409.479412728497,
            "rating_q975": 1430.5143090985353,
            "rating_q025": 1388.4445163584587
        },
        "qwen3-235b-a22b-instruct-2507": {
            "rating": 1409.3635535404273,
            "rating_q975": 1422.6806235060978,
            "rating_q025": 1396.0464835747568
        },
        "o3-2025-04-16": {
            "rating": 1409.0126802898158,
            "rating_q975": 1419.1482098918025,
            "rating_q025": 1398.877150687829
        },
        "glm-4.6": {
            "rating": 1408.667638894287,
            "rating_q975": 1434.0616947412036,
            "rating_q025": 1383.2735830473703
        },
        "gpt-5-high": {
            "rating": 1407.2842483586426,
            "rating_q975": 1422.9120056364375,
            "rating_q025": 1391.6564910808477
        },
        "qwen3-next-80b-a3b-instruct": {
            "rating": 1405.2661701507718,
            "rating_q975": 1423.4776422086181,
            "rating_q025": 1387.0546980929255
        },
        "qwen3-235b-a22b-thinking-2507": {
            "rating": 1404.5539936351718,
            "rating_q975": 1431.7149309080223,
            "rating_q025": 1377.3930563623212
        },
        "gpt-5-chat": {
            "rating": 1404.4283220300263,
            "rating_q975": 1420.2381622348314,
            "rating_q025": 1388.6184818252211
        },
        "deepseek-v3.2-exp-thinking": {
            "rating": 1402.393625022069,
            "rating_q975": 1427.5184843994425,
            "rating_q025": 1377.2687656446956
        },
        "deepseek-v3.1-thinking": {
            "rating": 1402.2365741813846,
            "rating_q975": 1424.9738001948624,
            "rating_q025": 1379.4993481679069
        },
        "qwen3-vl-235b-a22b-instruct": {
            "rating": 1397.2133936922721,
            "rating_q975": 1422.1220774912506,
            "rating_q025": 1372.3047098932936
        },
        "claude-sonnet-4-5-20250929-thinking-32k": {
            "rating": 1396.509364128101,
            "rating_q975": 1418.661765098832,
            "rating_q025": 1374.35696315737
        },
        "qwen3-235b-a22b-no-thinking": {
            "rating": 1389.039378909648,
            "rating_q975": 1401.0717132007846,
            "rating_q025": 1377.0070446185111
        },
        "hunyuan-t1-20250711": {
            "rating": 1386.7184312991924,
            "rating_q975": 1421.2254305841773,
            "rating_q025": 1352.2114320142075
        },
        "claude-opus-4-20250514-thinking-16k": {
            "rating": 1385.274578793725,
            "rating_q975": 1398.0891585721706,
            "rating_q025": 1372.4599990152792
        },
        "mai-1-preview": {
            "rating": 1384.5255335699298,
            "rating_q975": 1403.0689319140265,
            "rating_q025": 1365.9821352258332
        },
        "longcat-flash-chat": {
            "rating": 1384.5000068133945,
            "rating_q975": 1406.2756802633724,
            "rating_q025": 1362.7243333634167
        },
        "grok-4-fast": {
            "rating": 1383.6463465505642,
            "rating_q975": 1411.6975811069076,
            "rating_q025": 1355.5951119942208
        },
        "claude-opus-4-20250514": {
            "rating": 1379.5947474244197,
            "rating_q975": 1391.073964295062,
            "rating_q025": 1368.1155305537773
        },
        "kimi-k2-0905-preview": {
            "rating": 1376.9122589267038,
            "rating_q975": 1401.1022591857031,
            "rating_q025": 1352.7222586677044
        },
        "glm-4.5-air": {
            "rating": 1376.4516003212223,
            "rating_q975": 1392.3045036374417,
            "rating_q025": 1360.5986970050028
        },
        "gpt-4.1-2025-04-14": {
            "rating": 1372.816666712099,
            "rating_q975": 1383.703615881625,
            "rating_q025": 1361.9297175425731
        },
        "gemini-2.5-flash-lite-preview-09-2025-no-thinking": {
            "rating": 1372.5298412531847,
            "rating_q975": 1394.802728012849,
            "rating_q025": 1350.2569544935204
        },
        "claude-haiku-4-5-20251001": {
            "rating": 1370.6294447115472,
            "rating_q975": 1399.116801012369,
            "rating_q025": 1342.1420884107254
        },
        "qwen3-30b-a3b-instruct-2507": {
            "rating": 1369.4989885828604,
            "rating_q975": 1386.1401003675317,
            "rating_q025": 1352.8578767981892
        },
        "deepseek-v3-0324": {
            "rating": 1369.2256633888032,
            "rating_q975": 1379.6035014788013,
            "rating_q025": 1358.8478252988052
        },
        "hunyuan-turbos-20250416": {
            "rating": 1368.8709629815994,
            "rating_q975": 1387.0611921348177,
            "rating_q025": 1350.680733828381
        },
        "gemini-2.5-flash-lite-preview-06-17-thinking": {
            "rating": 1367.8579530966506,
            "rating_q975": 1381.4661672529135,
            "rating_q025": 1354.2497389403877
        },
        "gpt-5-mini-high": {
            "rating": 1365.6822304472819,
            "rating_q975": 1382.2147685933496,
            "rating_q025": 1349.1496923012141
        },
        "amazon-nova-experimental-chat-10-09": {
            "rating": 1359.757552568503,
            "rating_q975": 1400.1489111748085,
            "rating_q025": 1319.3661939621973
        },
        "claude-sonnet-4-20250514-thinking-32k": {
            "rating": 1356.3558895186327,
            "rating_q975": 1369.8142661581642,
            "rating_q025": 1342.8975128791012
        },
        "qwen3-coder-480b-a35b-instruct": {
            "rating": 1356.3169632129861,
            "rating_q975": 1372.8706865394465,
            "rating_q025": 1339.7632398865258
        },
        "kimi-k2-0711-preview": {
            "rating": 1356.282154037824,
            "rating_q975": 1371.2439442530147,
            "rating_q025": 1341.3203638226335
        },
        "mistral-medium-2505": {
            "rating": 1355.2590585432185,
            "rating_q975": 1367.080596733731,
            "rating_q025": 1343.437520352706
        },
        "qwen3-vl-235b-a22b-thinking": {
            "rating": 1354.3981356244233,
            "rating_q975": 1380.3579267176474,
            "rating_q025": 1328.4383445311992
        },
        "o1-2024-12-17": {
            "rating": 1353.7453237658613,
            "rating_q975": 1363.8209817855711,
            "rating_q025": 1343.6696657461514
        },
        "grok-3-mini-beta": {
            "rating": 1351.8661312763445,
            "rating_q975": 1367.3621828357634,
            "rating_q025": 1336.3700797169256
        },
        "deepseek-r1": {
            "rating": 1351.862531071835,
            "rating_q975": 1364.407619662406,
            "rating_q025": 1339.3174424812642
        },
        "qwen2.5-max": {
            "rating": 1350.788766342844,
            "rating_q975": 1361.229970208829,
            "rating_q025": 1340.347562476859
        },
        "gemma-3-27b-it": {
            "rating": 1349.8876122884567,
            "rating_q975": 1360.2659085733517,
            "rating_q025": 1339.5093160035617
        },
        "grok-3-mini-high": {
            "rating": 1348.9782392031038,
            "rating_q975": 1367.2602116786054,
            "rating_q025": 1330.6962667276023
        },
        "claude-sonnet-4-20250514": {
            "rating": 1342.3333536974853,
            "rating_q975": 1354.1819503921167,
            "rating_q025": 1330.484757002854
        },
        "qwen3-235b-a22b": {
            "rating": 1341.021952979287,
            "rating_q975": 1354.0153370577866,
            "rating_q025": 1328.0285689007876
        },
        "gpt-oss-120b": {
            "rating": 1339.683248033692,
            "rating_q975": 1355.3239102643388,
            "rating_q025": 1324.0425858030453
        },
        "qwen3-next-80b-a3b-thinking": {
            "rating": 1338.7227127674917,
            "rating_q975": 1359.149124599792,
            "rating_q025": 1318.2963009351913
        },
        "gemma-3-12b-it": {
            "rating": 1337.2408108486115,
            "rating_q975": 1368.9700962178833,
            "rating_q025": 1305.5115254793398
        },
        "o4-mini-2025-04-16": {
            "rating": 1333.9652760979984,
            "rating_q975": 1344.8281782038298,
            "rating_q025": 1323.102373992167
        },
        "step-1o-turbo-202506": {
            "rating": 1330.050414664856,
            "rating_q975": 1353.6516844995333,
            "rating_q025": 1306.4491448301785
        },
        "gemini-2.0-flash-lite-preview-02-05": {
            "rating": 1326.8272805074594,
            "rating_q975": 1338.0991545157765,
            "rating_q025": 1315.5554064991422
        },
        "step-2-16k-exp-202412": {
            "rating": 1322.5195751663032,
            "rating_q975": 1344.1726111890055,
            "rating_q025": 1300.866539143601
        },
        "minimax-m1": {
            "rating": 1322.4531744785363,
            "rating_q975": 1335.6906118699526,
            "rating_q025": 1309.21573708712
        },
        "mistral-small-2506": {
            "rating": 1322.3604125260179,
            "rating_q975": 1340.3791436298816,
            "rating_q025": 1304.3416814221541
        },
        "step-3": {
            "rating": 1322.179408035901,
            "rating_q975": 1351.0166879075275,
            "rating_q025": 1293.3421281642743
        },
        "qwen-plus-0125": {
            "rating": 1322.025499736541,
            "rating_q975": 1344.0489369908416,
            "rating_q025": 1300.0020624822403
        },
        "deepseek-v3": {
            "rating": 1321.9531756375895,
            "rating_q975": 1332.9500966118114,
            "rating_q025": 1310.9562546633676
        },
        "gemini-1.5-pro-002": {
            "rating": 1317.9427179937356,
            "rating_q975": 1324.8935064271682,
            "rating_q025": 1310.991929560303
        },
        "gpt-4.1-mini-2025-04-14": {
            "rating": 1317.6940813218368,
            "rating_q975": 1329.2302840312623,
            "rating_q025": 1306.1578786124114
        },
        "o1-preview": {
            "rating": 1315.2717213070362,
            "rating_q975": 1324.3588660115247,
            "rating_q025": 1306.1845766025476
        },
        "command-a-03-2025": {
            "rating": 1313.4232296196144,
            "rating_q975": 1323.2788475909656,
            "rating_q025": 1303.5676116482632
        },
        "glm-4-plus-0111": {
            "rating": 1311.0219833612953,
            "rating_q975": 1332.419547843331,
            "rating_q025": 1289.6244188792596
        },
        "qwen3-32b": {
            "rating": 1309.2572293952383,
            "rating_q975": 1334.817511274763,
            "rating_q025": 1283.6969475157134
        },
        "hunyuan-turbos-20250226": {
            "rating": 1309.1914441957424,
            "rating_q975": 1345.2906752419462,
            "rating_q025": 1273.0922131495386
        },
        "claude-3-7-sonnet-20250219-thinking-32k": {
            "rating": 1308.7046637368285,
            "rating_q975": 1319.548543751853,
            "rating_q025": 1297.860783721804
        },
        "claude-3-5-sonnet-20241022": {
            "rating": 1304.4079339471111,
            "rating_q975": 1310.54437482936,
            "rating_q025": 1298.2714930648622
        },
        "hunyuan-turbo-0110": {
            "rating": 1303.8212675766679,
            "rating_q975": 1336.0580389161532,
            "rating_q025": 1271.5844962371825
        },
        "o3-mini-high": {
            "rating": 1302.9102590034674,
            "rating_q975": 1316.073065622469,
            "rating_q025": 1289.747452384466
        },
        "gpt-5-nano-high": {
            "rating": 1299.0707859830784,
            "rating_q975": 1325.4369814285049,
            "rating_q025": 1272.704590537652
        },
        "ling-flash-2.0": {
            "rating": 1298.4526749434463,
            "rating_q975": 1328.557448580311,
            "rating_q025": 1268.3479013065814
        },
        "o3-mini": {
            "rating": 1297.5772414489102,
            "rating_q975": 1306.1448641518332,
            "rating_q025": 1289.0096187459872
        },
        "glm-4.5v": {
            "rating": 1296.6526493785273,
            "rating_q975": 1327.9512250625667,
            "rating_q025": 1265.3540736944879
        },
        "qwq-32b": {
            "rating": 1295.128479523803,
            "rating_q975": 1308.169534471265,
            "rating_q025": 1282.087424576341
        },
        "gemma-3-4b-it": {
            "rating": 1294.3539819729824,
            "rating_q975": 1325.061332739524,
            "rating_q025": 1263.6466312064408
        },
        "gemma-3n-e4b-it": {
            "rating": 1293.149684507307,
            "rating_q975": 1308.4425422044037,
            "rating_q025": 1277.8568268102104
        },
        "qwen3-30b-a3b": {
            "rating": 1291.4058166196805,
            "rating_q975": 1304.483964866733,
            "rating_q025": 1278.327668372628
        },
        "llama-4-maverick-17b-128e-instruct": {
            "rating": 1290.249601500395,
            "rating_q975": 1301.5536073427475,
            "rating_q025": 1278.9455956580427
        },
        "deepseek-v2.5-1210": {
            "rating": 1286.9976814793413,
            "rating_q975": 1303.8974609340414,
            "rating_q025": 1270.0979020246411
        },
        "gemini-1.5-flash-002": {
            "rating": 1285.8948569217755,
            "rating_q975": 1294.0661222286533,
            "rating_q025": 1277.7235916148977
        },
        "grok-2-2024-08-13": {
            "rating": 1284.385632206074,
            "rating_q975": 1291.2743070044503,
            "rating_q025": 1277.4969574076977
        },
        "gpt-4o-2024-05-13": {
            "rating": 1284.1267237088136,
            "rating_q975": 1290.7213892205825,
            "rating_q025": 1277.5320581970448
        },
        "llama-3.1-nemotron-ultra-253b-v1": {
            "rating": 1283.2692575260858,
            "rating_q975": 1313.148254648237,
            "rating_q025": 1253.3902604039345
        },
        "claude-3-5-sonnet-20240620": {
            "rating": 1281.379684742467,
            "rating_q975": 1288.659321241165,
            "rating_q025": 1274.100048243769
        },
        "o1-mini": {
            "rating": 1280.7404359200477,
            "rating_q975": 1287.9142958885604,
            "rating_q025": 1273.566575951535
        },
        "athene-v2-chat": {
            "rating": 1280.2553877927503,
            "rating_q975": 1289.686415059754,
            "rating_q025": 1270.8243605257467
        },
        "gemini-advanced-0514": {
            "rating": 1279.835421748725,
            "rating_q975": 1289.6804951755012,
            "rating_q025": 1269.9903483219487
        },
        "claude-3-opus-20240229": {
            "rating": 1278.881717421731,
            "rating_q975": 1284.8706477244607,
            "rating_q025": 1272.8927871190015
        },
        "gemini-1.5-pro-001": {
            "rating": 1274.807074034185,
            "rating_q975": 1282.8563211121223,
            "rating_q025": 1266.7578269562478
        },
        "glm-4-plus": {
            "rating": 1274.255372550018,
            "rating_q975": 1283.7763515645013,
            "rating_q025": 1264.7343935355345
        },
        "gpt-4o-mini-2024-07-18": {
            "rating": 1273.917834184013,
            "rating_q975": 1280.580443886311,
            "rating_q025": 1267.2552244817148
        },
        "qwen-max-0919": {
            "rating": 1272.7169771515228,
            "rating_q975": 1284.0449001610261,
            "rating_q025": 1261.3890541420194
        },
        "gpt-4o-2024-08-06": {
            "rating": 1270.4793534524442,
            "rating_q975": 1278.591202202732,
            "rating_q025": 1262.3675047021566
        },
        "qwen2.5-plus-1127": {
            "rating": 1268.9751437150762,
            "rating_q975": 1283.7982388256432,
            "rating_q025": 1254.1520486045092
        },
        "llama-3.3-nemotron-49b-super-v1": {
            "rating": 1268.6652667994395,
            "rating_q975": 1302.844801638892,
            "rating_q025": 1234.4857319599869
        },
        "gpt-oss-20b": {
            "rating": 1268.436773797389,
            "rating_q975": 1292.41273160298,
            "rating_q025": 1244.4608159917977
        },
        "llama-4-scout-17b-16e-instruct": {
            "rating": 1266.8002858423918,
            "rating_q975": 1280.4085595274732,
            "rating_q025": 1253.1920121573103
        },
        "hunyuan-large-2025-02-10": {
            "rating": 1264.1560319806854,
            "rating_q975": 1292.9112408140554,
            "rating_q025": 1235.4008231473154
        },
        "llama-3.1-405b-instruct-fp8": {
            "rating": 1263.9286899122694,
            "rating_q975": 1271.0726569866217,
            "rating_q025": 1256.7847228379171
        },
        "qwen2.5-72b-instruct": {
            "rating": 1262.4544527829441,
            "rating_q975": 1270.2345098084586,
            "rating_q025": 1254.6743957574297
        },
        "mistral-small-3.1-24b-instruct-2503": {
            "rating": 1262.2335324794956,
            "rating_q975": 1275.3691008498386,
            "rating_q025": 1249.0979641091526
        },
        "gpt-4.1-nano-2025-04-14": {
            "rating": 1261.63106899899,
            "rating_q975": 1282.523072407718,
            "rating_q025": 1240.739065590262
        },
        "grok-2-mini-2024-08-13": {
            "rating": 1260.0470264350051,
            "rating_q975": 1267.2635694054488,
            "rating_q025": 1252.8304834645614
        },
        "gpt-4-turbo-2024-04-09": {
            "rating": 1258.2302302380244,
            "rating_q975": 1265.8181648623213,
            "rating_q025": 1250.6422956137276
        },
        "hunyuan-standard-2025-02-10": {
            "rating": 1256.6040461836935,
            "rating_q975": 1283.610895865135,
            "rating_q025": 1229.597196502252
        },
        "mistral-large-2407": {
            "rating": 1255.5775319639658,
            "rating_q975": 1263.645790038311,
            "rating_q025": 1247.5092738896208
        },
        "llama-3.1-405b-instruct-bf16": {
            "rating": 1254.7125973594248,
            "rating_q975": 1262.7401868688169,
            "rating_q025": 1246.6850078500327
        },
        "yi-lightning": {
            "rating": 1253.9857834243662,
            "rating_q975": 1263.3549086354863,
            "rating_q025": 1244.6166582132462
        },
        "claude-3-5-haiku-20241022": {
            "rating": 1252.1500260073021,
            "rating_q975": 1259.4680151940001,
            "rating_q025": 1244.8320368206041
        },
        "deepseek-v2.5": {
            "rating": 1251.2303636821548,
            "rating_q975": 1260.9137558664004,
            "rating_q025": 1241.5469714979092
        },
        "mistral-large-2411": {
            "rating": 1249.9394996267474,
            "rating_q975": 1259.5062528975288,
            "rating_q025": 1240.372746355966
        },
        "gpt-4-1106-preview": {
            "rating": 1248.7765445029063,
            "rating_q975": 1257.2502782172128,
            "rating_q025": 1240.3028107885998
        },
        "athene-70b-0725": {
            "rating": 1248.3708481595095,
            "rating_q975": 1261.1202314432,
            "rating_q025": 1235.621464875819
        },
        "llama-3.3-70b-instruct": {
            "rating": 1248.0269051918679,
            "rating_q975": 1255.6102609971933,
            "rating_q025": 1240.4435493865424
        },
        "reka-core-20240904": {
            "rating": 1247.6156186764774,
            "rating_q975": 1265.1179866222142,
            "rating_q025": 1230.1132507307407
        },
        "hunyuan-large-vision": {
            "rating": 1244.606092355516,
            "rating_q975": 1275.6630428587705,
            "rating_q025": 1213.5491418522615
        },
        "llama-3.1-tulu-3-70b": {
            "rating": 1244.0037051428612,
            "rating_q975": 1271.0447897780357,
            "rating_q025": 1216.9626205076868
        },
        "gpt-4-0125-preview": {
            "rating": 1240.296069179765,
            "rating_q975": 1248.4757129956931,
            "rating_q025": 1232.116425363837
        },
        "amazon-nova-pro-v1.0": {
            "rating": 1238.18420092524,
            "rating_q975": 1248.0579169050727,
            "rating_q025": 1228.3104849454073
        },
        "gemini-1.5-flash-001": {
            "rating": 1238.0539623460309,
            "rating_q975": 1246.4951156076852,
            "rating_q025": 1229.6128090843765
        },
        "gemini-1.5-flash-8b-001": {
            "rating": 1234.274735574716,
            "rating_q975": 1242.3319306214896,
            "rating_q025": 1226.2175405279424
        },
        "gemma-2-27b-it": {
            "rating": 1232.5060209443523,
            "rating_q975": 1238.9043073678506,
            "rating_q025": 1226.107734520854
        },
        "llama-3.1-70b-instruct": {
            "rating": 1232.419432269628,
            "rating_q975": 1239.703321119842,
            "rating_q025": 1225.135543419414
        },
        "command-r-plus-08-2024": {
            "rating": 1226.7965611109942,
            "rating_q975": 1241.4259735517624,
            "rating_q025": 1212.167148670226
        },
        "claude-3-sonnet-20240229": {
            "rating": 1226.0571571069136,
            "rating_q975": 1234.516214059257,
            "rating_q025": 1217.5981001545701
        },
        "qwen2.5-coder-32b-instruct": {
            "rating": 1225.8223900160988,
            "rating_q975": 1244.0575691325707,
            "rating_q025": 1207.5872108996268
        },
        "c4ai-aya-expanse-32b": {
            "rating": 1225.683492113021,
            "rating_q975": 1234.8776078316405,
            "rating_q025": 1216.4893763944015
        },
        "llama-3.1-nemotron-70b-instruct": {
            "rating": 1225.256149674627,
            "rating_q975": 1242.1186510840641,
            "rating_q025": 1208.39364826519
        },
        "ring-flash-2.0": {
            "rating": 1225.2374176834653,
            "rating_q975": 1255.4013444683567,
            "rating_q025": 1195.073490898574
        },
        "gemma-2-9b-it-simpo": {
            "rating": 1223.557856024289,
            "rating_q975": 1240.0966082729044,
            "rating_q025": 1207.0191037756738
        },
        "nemotron-4-340b-instruct": {
            "rating": 1219.501023034782,
            "rating_q975": 1231.5845659547022,
            "rating_q025": 1207.417480114862
        },
        "magistral-medium-2506": {
            "rating": 1217.3807266897081,
            "rating_q975": 1239.1002849815145,
            "rating_q025": 1195.6611683979017
        },
        "mistral-small-24b-instruct-2501": {
            "rating": 1214.9131818753287,
            "rating_q975": 1229.248380111606,
            "rating_q025": 1200.5779836390516
        },
        "amazon-nova-lite-v1.0": {
            "rating": 1214.380405702885,
            "rating_q975": 1225.351727186358,
            "rating_q025": 1203.4090842194119
        },
        "reka-flash-20240904": {
            "rating": 1211.373742236578,
            "rating_q975": 1228.4308378879468,
            "rating_q025": 1194.3166465852091
        },
        "glm-4-0520": {
            "rating": 1211.2356710876288,
            "rating_q975": 1227.119318869769,
            "rating_q025": 1195.3520233054887
        },
        "phi-4": {
            "rating": 1206.2779183663115,
            "rating_q975": 1217.104783706337,
            "rating_q025": 1195.451053026286
        },
        "command-r-plus": {
            "rating": 1204.381083856903,
            "rating_q975": 1213.0842127429191,
            "rating_q025": 1195.6779549708867
        },
        "claude-3-haiku-20240307": {
            "rating": 1203.6288740298742,
            "rating_q975": 1211.0322859707044,
            "rating_q025": 1196.225462089044
        },
        "gemma-2-9b-it": {
            "rating": 1198.8407522913424,
            "rating_q975": 1206.1992716245645,
            "rating_q025": 1191.4822329581202
        },
        "c4ai-aya-expanse-8b": {
            "rating": 1196.6436232639444,
            "rating_q975": 1210.9571467451133,
            "rating_q025": 1182.3300997827755
        },
        "gpt-4-0314": {
            "rating": 1194.5853630539007,
            "rating_q975": 1206.2144599630333,
            "rating_q025": 1182.956266144768
        },
        "ministral-8b-2410": {
            "rating": 1193.3902289256464,
            "rating_q975": 1212.7832034400362,
            "rating_q025": 1173.9972544112566
        },
        "jamba-1.5-large": {
            "rating": 1193.1701159459958,
            "rating_q975": 1210.635672457928,
            "rating_q025": 1175.7045594340636
        },
        "llama-3.1-tulu-3-8b": {
            "rating": 1190.8326598952672,
            "rating_q975": 1215.2212718685832,
            "rating_q025": 1166.444047921951
        },
        "olmo-2-0325-32b-instruct": {
            "rating": 1187.3557380189422,
            "rating_q975": 1220.639083052037,
            "rating_q025": 1154.0723929858475
        },
        "deepseek-coder-v2": {
            "rating": 1186.679433343977,
            "rating_q975": 1200.372859912295,
            "rating_q025": 1172.986006775659
        },
        "llama-3.1-nemotron-51b-instruct": {
            "rating": 1185.5751839070504,
            "rating_q975": 1207.461484995562,
            "rating_q025": 1163.6888828185388
        },
        "gemini-pro-dev-api": {
            "rating": 1185.539852688802,
            "rating_q975": 1205.4193437550068,
            "rating_q025": 1165.6603616225973
        },
        "amazon-nova-micro-v1.0": {
            "rating": 1184.131408981923,
            "rating_q975": 1195.2547710379547,
            "rating_q025": 1173.0080469258912
        },
        "mistral-large-2402": {
            "rating": 1177.3500729888594,
            "rating_q975": 1187.2671971211141,
            "rating_q025": 1167.4329488566048
        },
        "command-r-08-2024": {
            "rating": 1174.734166419076,
            "rating_q975": 1189.9290321270612,
            "rating_q025": 1159.5393007110908
        },
        "gpt-4-0613": {
            "rating": 1171.7306557913653,
            "rating_q975": 1181.1763399434087,
            "rating_q025": 1162.2849716393218
        },
        "qwen2-72b-instruct": {
            "rating": 1167.408390531512,
            "rating_q975": 1177.218772950085,
            "rating_q025": 1157.598008112939
        },
        "mistral-medium": {
            "rating": 1166.3082864444868,
            "rating_q975": 1180.8045814626992,
            "rating_q025": 1151.8119914262745
        },
        "reka-flash-21b-20240226-online": {
            "rating": 1163.2578639529156,
            "rating_q975": 1178.8978474585708,
            "rating_q025": 1147.6178804472604
        },
        "hunyuan-standard-256k": {
            "rating": 1158.484925758177,
            "rating_q975": 1184.4251476473462,
            "rating_q025": 1132.544703869008
        },
        "reka-flash-21b-20240226": {
            "rating": 1158.4758226919944,
            "rating_q975": 1171.1143709620046,
            "rating_q025": 1145.8372744219841
        },
        "llama-3-70b-instruct": {
            "rating": 1158.4148754855396,
            "rating_q975": 1165.994644388364,
            "rating_q025": 1150.8351065827153
        },
        "llama-3.1-8b-instruct": {
            "rating": 1157.9884659864117,
            "rating_q975": 1165.6548486924505,
            "rating_q025": 1150.322083280373
        },
        "command-r": {
            "rating": 1157.0967398848893,
            "rating_q975": 1166.986701350569,
            "rating_q025": 1147.2067784192095
        },
        "jamba-1.5-mini": {
            "rating": 1156.5086565693446,
            "rating_q975": 1173.9798866271851,
            "rating_q025": 1139.037426511504
        },
        "mixtral-8x22b-instruct-v0.1": {
            "rating": 1156.2807837965697,
            "rating_q975": 1165.8199662734157,
            "rating_q025": 1146.7416013197237
        },
        "phi-3-medium-4k-instruct": {
            "rating": 1144.2711038501325,
            "rating_q975": 1155.1673012862764,
            "rating_q025": 1133.3749064139886
        },
        "wizardlm-70b": {
            "rating": 1144.19503065754,
            "rating_q975": 1188.7611415091487,
            "rating_q025": 1099.6289198059312
        },
        "gpt-3.5-turbo-0125": {
            "rating": 1123.0379190793205,
            "rating_q975": 1132.6631672890794,
            "rating_q025": 1113.4126708695617
        },
        "qwen1.5-110b-chat": {
            "rating": 1117.8564433291078,
            "rating_q975": 1129.491746668139,
            "rating_q025": 1106.2211399900766
        },
        "gemma-2-2b-it": {
            "rating": 1117.0090332712912,
            "rating_q975": 1125.116495983046,
            "rating_q025": 1108.9015705595364
        },
        "zephyr-orpo-141b-A35b-v0.1": {
            "rating": 1113.5265941815883,
            "rating_q975": 1140.443095913407,
            "rating_q025": 1086.6100924497696
        },
        "qwq-32b-preview": {
            "rating": 1113.4205843309567,
            "rating_q975": 1139.5108942268764,
            "rating_q025": 1087.330274435037
        },
        "openchat-3.5": {
            "rating": 1111.4594274091073,
            "rating_q975": 1152.2811242723271,
            "rating_q025": 1070.6377305458875
        },
        "llama-3-8b-instruct": {
            "rating": 1110.1885625858818,
            "rating_q975": 1118.4828980494474,
            "rating_q025": 1101.8942271223161
        },
        "phi-3-small-8k-instruct": {
            "rating": 1109.9521678280053,
            "rating_q975": 1122.6100060619451,
            "rating_q025": 1097.2943295940654
        },
        "internlm2_5-20b-chat": {
            "rating": 1105.999993835432,
            "rating_q975": 1121.2841876524312,
            "rating_q025": 1090.7158000184327
        },
        "qwen1.5-72b-chat": {
            "rating": 1104.6229308654515,
            "rating_q975": 1116.8556789347754,
            "rating_q025": 1092.3901827961276
        },
        "snowflake-arctic-instruct": {
            "rating": 1102.8387781829051,
            "rating_q975": 1115.6443959831743,
            "rating_q025": 1090.033160382636
        },
        "starling-lm-7b-beta": {
            "rating": 1102.2489251500692,
            "rating_q975": 1118.1146431173452,
            "rating_q025": 1086.3832071827933
        },
        "starling-lm-7b-alpha": {
            "rating": 1094.4016381652903,
            "rating_q975": 1121.7742112390792,
            "rating_q025": 1067.0290650915013
        },
        "granite-3.1-8b-instruct": {
            "rating": 1092.5836438441327,
            "rating_q975": 1120.4383390988253,
            "rating_q025": 1064.72894858944
        },
        "yi-1.5-34b-chat": {
            "rating": 1091.041419476813,
            "rating_q975": 1102.3837399123431,
            "rating_q025": 1079.6990990412828
        },
        "mixtral-8x7b-instruct-v0.1": {
            "rating": 1089.4133929576865,
            "rating_q975": 1099.3017072201944,
            "rating_q025": 1079.5250786951785
        },
        "openchat-3.5-0106": {
            "rating": 1085.7693908864585,
            "rating_q975": 1106.2988764560616,
            "rating_q025": 1065.2399053168554
        },
        "llama-2-70b-chat": {
            "rating": 1083.6723920304366,
            "rating_q975": 1097.649260157074,
            "rating_q025": 1069.6955239037993
        },
        "vicuna-33b": {
            "rating": 1081.4202012725204,
            "rating_q975": 1102.9229614908,
            "rating_q025": 1059.917441054241
        },
        "dbrx-instruct-preview": {
            "rating": 1077.422722788711,
            "rating_q975": 1089.8669279491187,
            "rating_q025": 1064.9785176283035
        },
        "codellama-34b-instruct": {
            "rating": 1076.2707675096688,
            "rating_q975": 1121.6195228227302,
            "rating_q025": 1030.9220121966073
        },
        "gpt-3.5-turbo-1106": {
            "rating": 1076.107587211246,
            "rating_q975": 1105.1321911063314,
            "rating_q025": 1047.0829833161606
        },
        "qwen1.5-32b-chat": {
            "rating": 1073.3533600545513,
            "rating_q975": 1086.4847252209627,
            "rating_q025": 1060.22199488814
        },
        "granite-3.1-2b-instruct": {
            "rating": 1062.9758665104034,
            "rating_q975": 1090.8583595061236,
            "rating_q025": 1035.0933735146832
        },
        "zephyr-7b-beta": {
            "rating": 1062.970475883193,
            "rating_q975": 1101.6590942616235,
            "rating_q025": 1024.2818575047627
        },
        "granite-3.0-8b-instruct": {
            "rating": 1060.6777295464121,
            "rating_q975": 1079.8687394734677,
            "rating_q025": 1041.4867196193566
        },
        "llama-2-13b-chat": {
            "rating": 1053.1920916561523,
            "rating_q975": 1073.6469877573072,
            "rating_q025": 1032.7371955549975
        },
        "yi-34b-chat": {
            "rating": 1049.5192852289345,
            "rating_q975": 1070.2500407716784,
            "rating_q025": 1028.7885296861905
        },
        "granite-3.0-2b-instruct": {
            "rating": 1047.882016620321,
            "rating_q975": 1066.5770268264303,
            "rating_q025": 1029.187006414212
        },
        "qwen1.5-14b-chat": {
            "rating": 1047.8280095335467,
            "rating_q975": 1062.8602678933253,
            "rating_q025": 1032.7957511737682
        },
        "gemma-1.1-7b-it": {
            "rating": 1045.7466089886516,
            "rating_q975": 1057.789713005612,
            "rating_q025": 1033.7035049716912
        },
        "vicuna-13b": {
            "rating": 1038.8212535057648,
            "rating_q975": 1065.2317823220967,
            "rating_q025": 1012.4107246894329
        },
        "phi-3-mini-4k-instruct": {
            "rating": 1021.9777141516395,
            "rating_q975": 1034.5640025739508,
            "rating_q025": 1009.3914257293283
        },
        "mistral-7b-instruct-v0.2": {
            "rating": 1021.0649692530061,
            "rating_q975": 1037.8954498003986,
            "rating_q025": 1004.2344887056134
        },
        "phi-3-mini-4k-instruct-june-2024": {
            "rating": 1018.6639794854564,
            "rating_q975": 1034.9618659798505,
            "rating_q025": 1002.3660929910624
        },
        "qwen1.5-7b-chat": {
            "rating": 1009.3648073896702,
            "rating_q975": 1043.0232465443028,
            "rating_q025": 975.7063682350375
        },
        "phi-3-mini-128k-instruct": {
            "rating": 1005.0053617904479,
            "rating_q975": 1020.4013404823929,
            "rating_q025": 989.6093830985028
        },
        "mistral-7b-instruct": {
            "rating": 1002.2068402273986,
            "rating_q975": 1043.4652652272682,
            "rating_q025": 960.948415227529
        },
        "llama-2-7b-chat": {
            "rating": 994.4720241982653,
            "rating_q975": 1017.5354345870164,
            "rating_q025": 971.4086138095142
        },
        "gemma-7b-it": {
            "rating": 991.3181360873062,
            "rating_q975": 1014.5451854423088,
            "rating_q025": 968.0910867323037
        },
        "gemma-1.1-2b-it": {
            "rating": 990.9082981467541,
            "rating_q975": 1008.7248409535149,
            "rating_q025": 973.0917553399933
        },
        "smollm2-1.7b-instruct": {
            "rating": 987.0799206130373,
            "rating_q975": 1018.2319170370156,
            "rating_q025": 955.927924189059
        },
        "qwen1.5-4b-chat": {
            "rating": 953.0105834318607,
            "rating_q975": 977.7502974039497,
            "rating_q025": 928.2708694597717
        },
        "llama-3.2-3b-instruct": {
            "rating": 949.4895009781342,
            "rating_q975": 971.6836977615917,
            "rating_q025": 927.2953041946766
        },
        "olmo-7b-instruct": {
            "rating": 947.0022158229813,
            "rating_q975": 974.8329403316828,
            "rating_q025": 919.1714913142797
        },
        "llama-3.2-1b-instruct": {
            "rating": 939.5643831728933,
            "rating_q975": 961.7264105900506,
            "rating_q025": 917.4023557557359
        },
        "gemma-2b-it": {
            "rating": 936.4611524946146,
            "rating_q975": 972.9988951449021,
            "rating_q025": 899.923409844327
        }
    },
    "spanish": {
        "gemini-2.5-pro": {
            "rating": 1478.712808962841,
            "rating_q975": 1499.4481279405352,
            "rating_q025": 1457.977489985147
        },
        "qwen3-max-preview": {
            "rating": 1466.9958702877018,
            "rating_q975": 1493.675954442683,
            "rating_q025": 1440.3157861327206
        },
        "glm-4.5": {
            "rating": 1459.295653678049,
            "rating_q975": 1486.0633879480679,
            "rating_q025": 1432.52791940803
        },
        "glm-4.6": {
            "rating": 1452.8693408454549,
            "rating_q975": 1488.9278741234502,
            "rating_q025": 1416.8108075674595
        },
        "qwen3-next-80b-a3b-instruct": {
            "rating": 1448.738667408026,
            "rating_q975": 1477.4666148949286,
            "rating_q025": 1420.0107199211234
        },
        "claude-opus-4-1-20250805-thinking-16k": {
            "rating": 1446.083044041091,
            "rating_q975": 1472.351884210825,
            "rating_q025": 1419.814203871357
        },
        "longcat-flash-chat": {
            "rating": 1444.1027623279624,
            "rating_q975": 1477.6204529380664,
            "rating_q025": 1410.5850717178585
        },
        "claude-sonnet-4-5-20250929": {
            "rating": 1442.14470307987,
            "rating_q975": 1482.6746802276848,
            "rating_q025": 1401.614725932055
        },
        "mistral-medium-2508": {
            "rating": 1440.508866190562,
            "rating_q975": 1464.7058382683633,
            "rating_q025": 1416.3118941127607
        },
        "claude-sonnet-4-5-20250929-thinking-32k": {
            "rating": 1438.457726088132,
            "rating_q975": 1469.9381378499204,
            "rating_q025": 1406.9773143263435
        },
        "claude-opus-4-1-20250805": {
            "rating": 1434.2486927457624,
            "rating_q975": 1456.20388386314,
            "rating_q025": 1412.2935016283848
        },
        "grok-4-fast": {
            "rating": 1433.1873941455042,
            "rating_q975": 1473.5129167668226,
            "rating_q025": 1392.8618715241857
        },
        "qwen3-235b-a22b-instruct-2507": {
            "rating": 1432.0374529921205,
            "rating_q975": 1455.2833697091717,
            "rating_q025": 1408.7915362750693
        },
        "chatgpt-4o-latest-20250326": {
            "rating": 1428.568057049251,
            "rating_q975": 1452.3955455367577,
            "rating_q025": 1404.740568561744
        },
        "grok-3-preview-02-24": {
            "rating": 1427.11418197713,
            "rating_q975": 1458.962933796658,
            "rating_q025": 1395.2654301576022
        },
        "gemini-2.5-flash": {
            "rating": 1419.520717402278,
            "rating_q975": 1440.3672146467027,
            "rating_q025": 1398.6742201578534
        },
        "deepseek-v3.1-thinking": {
            "rating": 1418.0029506293172,
            "rating_q975": 1452.7321044676567,
            "rating_q025": 1383.2737967909777
        },
        "qwen3-vl-235b-a22b-instruct": {
            "rating": 1417.465982645473,
            "rating_q975": 1451.924491600411,
            "rating_q025": 1383.007473690535
        },
        "grok-4-0709": {
            "rating": 1412.8567029661726,
            "rating_q975": 1436.876616507084,
            "rating_q025": 1388.8367894252613
        },
        "deepseek-v3.1": {
            "rating": 1410.0145455890463,
            "rating_q975": 1444.5212620355428,
            "rating_q025": 1375.5078291425498
        },
        "deepseek-r1-0528": {
            "rating": 1409.2157035832358,
            "rating_q975": 1447.5275650950048,
            "rating_q025": 1370.903842071467
        },
        "gemini-2.5-flash-lite-preview-09-2025-no-thinking": {
            "rating": 1404.8947262264917,
            "rating_q975": 1434.3570284422294,
            "rating_q025": 1375.432424010754
        },
        "qwen3-235b-a22b-no-thinking": {
            "rating": 1403.8081693709594,
            "rating_q975": 1429.4615930649904,
            "rating_q025": 1378.1547456769283
        },
        "deepseek-v3.2-exp-thinking": {
            "rating": 1402.6865407706732,
            "rating_q975": 1439.417883454306,
            "rating_q025": 1365.9551980870403
        },
        "qwen3-max-2025-09-23": {
            "rating": 1401.7509773301279,
            "rating_q975": 1434.0547910771636,
            "rating_q025": 1369.447163583092
        },
        "mai-1-preview": {
            "rating": 1401.3153710124602,
            "rating_q975": 1428.8963365135535,
            "rating_q025": 1373.734405511367
        },
        "ling-flash-2.0": {
            "rating": 1401.2783561753251,
            "rating_q975": 1440.497188870842,
            "rating_q025": 1362.0595234798084
        },
        "grok-3-mini-beta": {
            "rating": 1400.3149843316698,
            "rating_q975": 1431.1533686273863,
            "rating_q025": 1369.4766000359534
        },
        "qwen3-vl-235b-a22b-thinking": {
            "rating": 1398.2649448292123,
            "rating_q975": 1433.4576031783674,
            "rating_q025": 1363.072286480057
        },
        "amazon-nova-experimental-chat-10-09": {
            "rating": 1397.6188678571236,
            "rating_q975": 1451.8476544481268,
            "rating_q025": 1343.3900812661204
        },
        "gemini-2.5-flash-preview-09-2025": {
            "rating": 1395.768737318303,
            "rating_q975": 1425.9518738068418,
            "rating_q025": 1365.5856008297642
        },
        "gpt-5-chat": {
            "rating": 1393.7332760281079,
            "rating_q975": 1419.649334701192,
            "rating_q025": 1367.8172173550238
        },
        "qwen3-30b-a3b-instruct-2507": {
            "rating": 1393.2589524930804,
            "rating_q975": 1419.4017723340169,
            "rating_q025": 1367.116132652144
        },
        "gpt-5-high": {
            "rating": 1392.797151137804,
            "rating_q975": 1417.8668205690594,
            "rating_q025": 1367.7274817065484
        },
        "o3-2025-04-16": {
            "rating": 1391.3839494276806,
            "rating_q975": 1413.7731648944439,
            "rating_q025": 1368.9947339609173
        },
        "gpt-oss-120b": {
            "rating": 1389.4081982135003,
            "rating_q975": 1415.6804268626831,
            "rating_q025": 1363.1359695643175
        },
        "claude-haiku-4-5-20251001": {
            "rating": 1389.0353614680632,
            "rating_q975": 1427.4686683085436,
            "rating_q025": 1350.602054627583
        },
        "step-3": {
            "rating": 1387.0615774387747,
            "rating_q975": 1432.1879252111307,
            "rating_q025": 1341.9352296664188
        },
        "glm-4.5-air": {
            "rating": 1384.0495641403609,
            "rating_q975": 1409.8951639936558,
            "rating_q025": 1358.203964287066
        },
        "kimi-k2-0905-preview": {
            "rating": 1382.516200594909,
            "rating_q975": 1420.3075144655759,
            "rating_q025": 1344.724886724242
        },
        "claude-opus-4-20250514-thinking-16k": {
            "rating": 1382.3536737182023,
            "rating_q975": 1406.43263264832,
            "rating_q025": 1358.2747147880848
        },
        "qwen2.5-max": {
            "rating": 1380.6668425032756,
            "rating_q975": 1416.9705479720662,
            "rating_q025": 1344.363137034485
        },
        "ring-flash-2.0": {
            "rating": 1379.5234781972472,
            "rating_q975": 1417.9987474192396,
            "rating_q025": 1341.0482089752547
        },
        "deepseek-r1": {
            "rating": 1378.397290002717,
            "rating_q975": 1431.150444588003,
            "rating_q025": 1325.644135417431
        },
        "gpt-4.1-2025-04-14": {
            "rating": 1375.2263740560375,
            "rating_q975": 1397.8924124357743,
            "rating_q025": 1352.5603356763006
        },
        "qwen3-235b-a22b": {
            "rating": 1375.2026236937672,
            "rating_q975": 1405.6505166256925,
            "rating_q025": 1344.754730761842
        },
        "gpt-5-nano-high": {
            "rating": 1373.241501393181,
            "rating_q975": 1417.8469524656468,
            "rating_q025": 1328.636050320715
        },
        "mistral-medium-2505": {
            "rating": 1372.0279598893574,
            "rating_q975": 1400.9028662419637,
            "rating_q025": 1343.153053536751
        },
        "gemini-2.5-flash-lite-preview-06-17-thinking": {
            "rating": 1367.9463177501889,
            "rating_q975": 1392.8351961316328,
            "rating_q025": 1343.057439368745
        },
        "grok-3-mini-high": {
            "rating": 1360.2787646834543,
            "rating_q975": 1396.4330604382044,
            "rating_q025": 1324.1244689287041
        },
        "qwen3-coder-480b-a35b-instruct": {
            "rating": 1359.2942152919925,
            "rating_q975": 1388.2210425926246,
            "rating_q025": 1330.3673879913604
        },
        "claude-sonnet-4-20250514": {
            "rating": 1358.0263704655933,
            "rating_q975": 1381.8755698690607,
            "rating_q025": 1334.177171062126
        },
        "qwen3-next-80b-a3b-thinking": {
            "rating": 1357.8163379864823,
            "rating_q975": 1389.0245185713134,
            "rating_q025": 1326.6081574016512
        },
        "mistral-small-2506": {
            "rating": 1355.7849639100818,
            "rating_q975": 1389.0553598454344,
            "rating_q025": 1322.5145679747293
        },
        "deepseek-v3": {
            "rating": 1354.4627389759412,
            "rating_q975": 1402.433417967043,
            "rating_q025": 1306.4920599848394
        },
        "gpt-5-mini-high": {
            "rating": 1353.6646787794853,
            "rating_q975": 1379.4798504578434,
            "rating_q025": 1327.849507101127
        },
        "qwq-32b": {
            "rating": 1352.8893902951202,
            "rating_q975": 1385.5184497323944,
            "rating_q025": 1320.260330857846
        },
        "claude-opus-4-20250514": {
            "rating": 1352.7632009173853,
            "rating_q975": 1375.9548424287304,
            "rating_q025": 1329.5715594060403
        },
        "claude-sonnet-4-20250514-thinking-32k": {
            "rating": 1350.5477485201877,
            "rating_q975": 1375.5362334961587,
            "rating_q025": 1325.5592635442167
        },
        "o4-mini-2025-04-16": {
            "rating": 1349.2727942114143,
            "rating_q975": 1371.9439060393731,
            "rating_q025": 1326.6016823834555
        },
        "minimax-m1": {
            "rating": 1345.296551171536,
            "rating_q975": 1370.1707703840473,
            "rating_q025": 1320.4223319590249
        },
        "o1-2024-12-17": {
            "rating": 1345.021650704596,
            "rating_q975": 1393.1047027929478,
            "rating_q025": 1296.938598616244
        },
        "gemma-3-27b-it": {
            "rating": 1342.839784517481,
            "rating_q975": 1365.8194645072574,
            "rating_q025": 1319.8601045277044
        },
        "deepseek-v3-0324": {
            "rating": 1342.0489046618918,
            "rating_q975": 1364.755978428905,
            "rating_q025": 1319.3418308948785
        },
        "command-a-03-2025": {
            "rating": 1340.7862306157622,
            "rating_q975": 1362.2549739990275,
            "rating_q025": 1319.317487232497
        },
        "glm-4.5v": {
            "rating": 1336.3017217258657,
            "rating_q975": 1384.0707497056917,
            "rating_q025": 1288.5326937460397
        },
        "kimi-k2-0711-preview": {
            "rating": 1331.5084210327364,
            "rating_q975": 1361.1141724734173,
            "rating_q025": 1301.9026695920554
        },
        "o3-mini-high": {
            "rating": 1322.143163923535,
            "rating_q975": 1372.1703820838325,
            "rating_q025": 1272.1159457632375
        },
        "qwen3-30b-a3b": {
            "rating": 1321.9782277354436,
            "rating_q975": 1353.2529775607336,
            "rating_q025": 1290.7034779101537
        },
        "yi-lightning": {
            "rating": 1319.3985801944636,
            "rating_q975": 1349.8478091138657,
            "rating_q025": 1288.9493512750616
        },
        "glm-4-plus": {
            "rating": 1314.231080883746,
            "rating_q975": 1344.6611296159276,
            "rating_q025": 1283.8010321515644
        },
        "gemini-1.5-pro-002": {
            "rating": 1313.6659845861077,
            "rating_q975": 1341.3428823180786,
            "rating_q025": 1285.9890868541368
        },
        "gemini-2.0-flash-lite-preview-02-05": {
            "rating": 1312.0575814094852,
            "rating_q975": 1355.9346556788646,
            "rating_q025": 1268.1805071401059
        },
        "gpt-4.1-mini-2025-04-14": {
            "rating": 1308.35033945892,
            "rating_q975": 1332.5886967583695,
            "rating_q025": 1284.1119821594705
        },
        "claude-3-7-sonnet-20250219-thinking-32k": {
            "rating": 1306.8630691571038,
            "rating_q975": 1334.7679600438667,
            "rating_q025": 1278.958178270341
        },
        "o1-mini": {
            "rating": 1306.17655440214,
            "rating_q975": 1332.4387387464565,
            "rating_q025": 1279.9143700578236
        },
        "o3-mini": {
            "rating": 1305.6280150670232,
            "rating_q975": 1328.3550501192865,
            "rating_q025": 1282.9009800147599
        },
        "o1-preview": {
            "rating": 1305.6277796243098,
            "rating_q975": 1335.4636249646403,
            "rating_q025": 1275.7919342839793
        },
        "gemma-3n-e4b-it": {
            "rating": 1298.300512246075,
            "rating_q975": 1330.0383365897605,
            "rating_q025": 1266.5626879023894
        },
        "gpt-4o-2024-05-13": {
            "rating": 1296.3804503039794,
            "rating_q975": 1313.9105909983875,
            "rating_q025": 1278.8503096095712
        },
        "qwen-max-0919": {
            "rating": 1293.9770221923095,
            "rating_q975": 1331.4897771568933,
            "rating_q025": 1256.4642672277257
        },
        "claude-3-5-sonnet-20240620": {
            "rating": 1293.115138689554,
            "rating_q975": 1313.1355854541325,
            "rating_q025": 1273.0946919249755
        },
        "llama-4-maverick-17b-128e-instruct": {
            "rating": 1291.4561967798115,
            "rating_q975": 1315.7489636962086,
            "rating_q025": 1267.1634298634144
        },
        "claude-3-5-sonnet-20241022": {
            "rating": 1287.5042020876188,
            "rating_q975": 1307.13698132323,
            "rating_q025": 1267.8714228520075
        },
        "grok-2-2024-08-13": {
            "rating": 1285.0727129942677,
            "rating_q975": 1307.5328394292278,
            "rating_q025": 1262.6125865593076
        },
        "gpt-4o-mini-2024-07-18": {
            "rating": 1283.0462864089175,
            "rating_q975": 1304.7207694828976,
            "rating_q025": 1261.3718033349373
        },
        "grok-2-mini-2024-08-13": {
            "rating": 1282.3302562496503,
            "rating_q975": 1305.652305192106,
            "rating_q025": 1259.0082073071947
        },
        "magistral-medium-2506": {
            "rating": 1281.2470768660432,
            "rating_q975": 1324.6785029498599,
            "rating_q025": 1237.8156507822266
        },
        "mistral-small-3.1-24b-instruct-2503": {
            "rating": 1281.2159155326244,
            "rating_q975": 1306.914739563448,
            "rating_q025": 1255.517091501801
        },
        "athene-v2-chat": {
            "rating": 1277.3017698668282,
            "rating_q975": 1316.1723615958517,
            "rating_q025": 1238.4311781378046
        },
        "llama-4-scout-17b-16e-instruct": {
            "rating": 1276.2369852447944,
            "rating_q975": 1303.5077515546275,
            "rating_q025": 1248.9662189349613
        },
        "gpt-4o-2024-08-06": {
            "rating": 1273.7932386743585,
            "rating_q975": 1298.9416352250566,
            "rating_q025": 1248.6448421236603
        },
        "mistral-large-2411": {
            "rating": 1270.081891275233,
            "rating_q975": 1314.3989348640382,
            "rating_q025": 1225.7648476864276
        },
        "llama-3.3-70b-instruct": {
            "rating": 1269.5839652179106,
            "rating_q975": 1295.0124838857662,
            "rating_q025": 1244.155446550055
        },
        "gpt-oss-20b": {
            "rating": 1267.3745173787165,
            "rating_q975": 1309.4001046802414,
            "rating_q025": 1225.3489300771917
        },
        "gpt-4-1106-preview": {
            "rating": 1265.8689995512768,
            "rating_q975": 1285.397076513253,
            "rating_q025": 1246.3409225893006
        },
        "gpt-4-turbo-2024-04-09": {
            "rating": 1263.5568665803328,
            "rating_q975": 1282.229841866684,
            "rating_q025": 1244.8838912939816
        },
        "athene-70b-0725": {
            "rating": 1263.4114378979425,
            "rating_q975": 1297.7568960696335,
            "rating_q025": 1229.0659797262515
        },
        "llama-3.1-405b-instruct-bf16": {
            "rating": 1263.0557787677558,
            "rating_q975": 1291.9654512579693,
            "rating_q025": 1234.1461062775422
        },
        "qwen2.5-72b-instruct": {
            "rating": 1258.9363428721217,
            "rating_q975": 1288.4433594523575,
            "rating_q025": 1229.429326291886
        },
        "claude-3-5-haiku-20241022": {
            "rating": 1257.839084957453,
            "rating_q975": 1279.8708155156269,
            "rating_q025": 1235.8073543992791
        },
        "llama-3.1-70b-instruct": {
            "rating": 1257.1171507002618,
            "rating_q975": 1280.3609890497023,
            "rating_q025": 1233.8733123508214
        },
        "llama-3.1-405b-instruct-fp8": {
            "rating": 1256.688979636639,
            "rating_q975": 1279.911448329606,
            "rating_q025": 1233.4665109436721
        },
        "gpt-4-0125-preview": {
            "rating": 1252.2087334051835,
            "rating_q975": 1272.32173699772,
            "rating_q025": 1232.0957298126468
        },
        "deepseek-v2.5": {
            "rating": 1251.9679907344007,
            "rating_q975": 1284.9146755069742,
            "rating_q025": 1219.0213059618272
        },
        "claude-3-opus-20240229": {
            "rating": 1251.2955250395803,
            "rating_q975": 1267.4407974847054,
            "rating_q025": 1235.1502525944552
        },
        "gemini-1.5-pro-001": {
            "rating": 1246.7224946483734,
            "rating_q975": 1266.3384948250543,
            "rating_q025": 1227.1064944716925
        },
        "gemini-1.5-flash-002": {
            "rating": 1246.06832710902,
            "rating_q975": 1278.4143291012801,
            "rating_q025": 1213.7223251167597
        },
        "llama-3-70b-instruct": {
            "rating": 1245.9360567202568,
            "rating_q975": 1262.7420411812018,
            "rating_q025": 1229.1300722593119
        },
        "gemini-advanced-0514": {
            "rating": 1245.8226979226563,
            "rating_q975": 1268.208875779964,
            "rating_q025": 1223.4365200653485
        },
        "mistral-large-2407": {
            "rating": 1239.7251266026647,
            "rating_q975": 1263.7403204793488,
            "rating_q025": 1215.7099327259805
        },
        "phi-4": {
            "rating": 1235.4389889558681,
            "rating_q975": 1286.5339739437236,
            "rating_q025": 1184.3440039680127
        },
        "gemma-2-27b-it": {
            "rating": 1231.7720763969296,
            "rating_q975": 1252.2913927196569,
            "rating_q025": 1211.2527600742023
        },
        "amazon-nova-micro-v1.0": {
            "rating": 1228.6278242439753,
            "rating_q975": 1273.123851252628,
            "rating_q025": 1184.1317972353227
        },
        "amazon-nova-lite-v1.0": {
            "rating": 1227.8590625615861,
            "rating_q975": 1280.5023071641635,
            "rating_q025": 1175.2158179590087
        },
        "gemini-1.5-flash-001": {
            "rating": 1227.5108887140916,
            "rating_q975": 1247.697407487566,
            "rating_q025": 1207.3243699406173
        },
        "gemini-1.5-flash-8b-001": {
            "rating": 1216.7030889688394,
            "rating_q975": 1246.6193598103746,
            "rating_q025": 1186.7868181273043
        },
        "claude-3-sonnet-20240229": {
            "rating": 1209.3860570304546,
            "rating_q975": 1228.78600975551,
            "rating_q025": 1189.9861043053993
        },
        "gemma-2-9b-it": {
            "rating": 1204.1531978180979,
            "rating_q975": 1228.0287925100035,
            "rating_q025": 1180.2776031261922
        },
        "gpt-4-0314": {
            "rating": 1201.2885400432306,
            "rating_q975": 1226.925870285162,
            "rating_q025": 1175.651209801299
        },
        "nemotron-4-340b-instruct": {
            "rating": 1200.0138807610224,
            "rating_q975": 1230.3120811311376,
            "rating_q025": 1169.7156803909072
        },
        "mistral-large-2402": {
            "rating": 1198.343959240446,
            "rating_q975": 1220.738672204453,
            "rating_q025": 1175.9492462764392
        },
        "c4ai-aya-expanse-32b": {
            "rating": 1196.6455143796147,
            "rating_q975": 1231.38030367667,
            "rating_q025": 1161.9107250825593
        },
        "command-r-plus": {
            "rating": 1191.830606304434,
            "rating_q975": 1212.1935107905767,
            "rating_q025": 1171.4677018182913
        },
        "amazon-nova-pro-v1.0": {
            "rating": 1185.6953190189683,
            "rating_q975": 1234.9624254521304,
            "rating_q025": 1136.4282125858062
        },
        "llama-3-8b-instruct": {
            "rating": 1177.8438181702775,
            "rating_q975": 1196.4364117080202,
            "rating_q025": 1159.2512246325348
        },
        "qwen2-72b-instruct": {
            "rating": 1174.26729966302,
            "rating_q975": 1200.0924125851986,
            "rating_q025": 1148.4421867408412
        },
        "gpt-4-0613": {
            "rating": 1173.92259448822,
            "rating_q975": 1193.862128513744,
            "rating_q025": 1153.9830604626961
        },
        "llama-3.1-8b-instruct": {
            "rating": 1173.4261061350508,
            "rating_q975": 1198.890012856565,
            "rating_q025": 1147.9621994135366
        },
        "claude-3-haiku-20240307": {
            "rating": 1170.2609853729778,
            "rating_q975": 1188.2048231053263,
            "rating_q025": 1152.3171476406292
        },
        "command-r": {
            "rating": 1155.9921477730115,
            "rating_q975": 1180.6191493743615,
            "rating_q025": 1131.3651461716615
        },
        "mixtral-8x22b-instruct-v0.1": {
            "rating": 1154.7930120380854,
            "rating_q975": 1178.0604303947575,
            "rating_q025": 1131.5255936814133
        },
        "deepseek-coder-v2": {
            "rating": 1154.654200647396,
            "rating_q975": 1191.095642797827,
            "rating_q025": 1118.212758496965
        },
        "reka-flash-21b-20240226-online": {
            "rating": 1154.0991638297332,
            "rating_q975": 1193.9422905360889,
            "rating_q025": 1114.2560371233776
        },
        "mistral-medium": {
            "rating": 1148.4167317232746,
            "rating_q975": 1178.7368848124229,
            "rating_q025": 1118.0965786341262
        },
        "qwen1.5-110b-chat": {
            "rating": 1148.2095912264783,
            "rating_q975": 1176.4240110138637,
            "rating_q025": 1119.995171439093
        },
        "llama-2-70b-chat": {
            "rating": 1147.3204623738798,
            "rating_q975": 1174.5788898609019,
            "rating_q025": 1120.0620348868576
        },
        "gemma-2-2b-it": {
            "rating": 1144.8396845785892,
            "rating_q975": 1170.4778067333689,
            "rating_q025": 1119.2015624238095
        },
        "reka-flash-21b-20240226": {
            "rating": 1137.2276510486158,
            "rating_q975": 1167.4880667962793,
            "rating_q025": 1106.9672353009523
        },
        "gemini-pro-dev-api": {
            "rating": 1125.6672491996837,
            "rating_q975": 1166.1972882487905,
            "rating_q025": 1085.137210150577
        },
        "gpt-3.5-turbo-0125": {
            "rating": 1124.6998001770903,
            "rating_q975": 1147.4569494707764,
            "rating_q025": 1101.9426508834042
        },
        "yi-1.5-34b-chat": {
            "rating": 1122.4638914002712,
            "rating_q975": 1151.4218708782207,
            "rating_q025": 1093.5059119223217
        },
        "mixtral-8x7b-instruct-v0.1": {
            "rating": 1117.113894976847,
            "rating_q975": 1138.68896129383,
            "rating_q025": 1095.5388286598638
        },
        "qwen1.5-72b-chat": {
            "rating": 1115.4540870429507,
            "rating_q975": 1143.5022638572777,
            "rating_q025": 1087.4059102286237
        },
        "phi-3-small-8k-instruct": {
            "rating": 1112.1499562370263,
            "rating_q975": 1148.6117318114882,
            "rating_q025": 1075.6881806625645
        },
        "phi-3-medium-4k-instruct": {
            "rating": 1098.2704763292945,
            "rating_q975": 1127.6150316032752,
            "rating_q025": 1068.925921055314
        },
        "gpt-3.5-turbo-1106": {
            "rating": 1097.722710604129,
            "rating_q975": 1137.1153807709263,
            "rating_q025": 1058.3300404373315
        },
        "snowflake-arctic-instruct": {
            "rating": 1094.4088243397503,
            "rating_q975": 1122.8326967107794,
            "rating_q025": 1065.9849519687211
        },
        "qwen1.5-32b-chat": {
            "rating": 1094.0073963191767,
            "rating_q975": 1123.7855610392462,
            "rating_q025": 1064.2292315991072
        },
        "llama-2-13b-chat": {
            "rating": 1093.6465619079459,
            "rating_q975": 1131.8421409505465,
            "rating_q025": 1055.4509828653452
        },
        "phi-3-mini-4k-instruct": {
            "rating": 1090.0619992749266,
            "rating_q975": 1120.7927518089562,
            "rating_q025": 1059.331246740897
        },
        "qwen1.5-14b-chat": {
            "rating": 1089.962520404053,
            "rating_q975": 1124.1878330810916,
            "rating_q025": 1055.7372077270145
        },
        "vicuna-33b": {
            "rating": 1083.185065466479,
            "rating_q975": 1119.9097439205661,
            "rating_q025": 1046.460387012392
        },
        "vicuna-13b": {
            "rating": 1081.9884868370305,
            "rating_q975": 1129.9933465344966,
            "rating_q025": 1033.9836271395643
        },
        "zephyr-7b-beta": {
            "rating": 1079.7572943268901,
            "rating_q975": 1134.6530519062953,
            "rating_q025": 1024.861536747485
        },
        "yi-34b-chat": {
            "rating": 1075.9798282756985,
            "rating_q975": 1116.1118562005763,
            "rating_q025": 1035.8478003508208
        },
        "dbrx-instruct-preview": {
            "rating": 1070.6221722170765,
            "rating_q975": 1101.623589789898,
            "rating_q025": 1039.620754644255
        },
        "phi-3-mini-128k-instruct": {
            "rating": 1062.7347176674634,
            "rating_q975": 1095.5578581496125,
            "rating_q025": 1029.9115771853144
        },
        "gemma-1.1-7b-it": {
            "rating": 1053.6211958839044,
            "rating_q975": 1084.9171307339043,
            "rating_q025": 1022.3252610339046
        },
        "mistral-7b-instruct-v0.2": {
            "rating": 1033.28316535491,
            "rating_q975": 1077.438305333705,
            "rating_q025": 989.1280253761146
        },
        "llama-2-7b-chat": {
            "rating": 1016.6165703080467,
            "rating_q975": 1066.5263237287832,
            "rating_q025": 966.7068168873101
        },
        "gemma-1.1-2b-it": {
            "rating": 986.2596623288434,
            "rating_q975": 1035.3793160171801,
            "rating_q025": 937.1400086405067
        }
    }
}