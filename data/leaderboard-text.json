{
    "chinese": {
        "gemini-3-pro": {
            "rating": 1525.1042120660923,
            "rating_q975": 1545.4822145503822,
            "rating_q025": 1504.7262095818023
        },
        "gemini-2.5-pro": {
            "rating": 1517.2954756980423,
            "rating_q975": 1528.312569434042,
            "rating_q025": 1506.2783819620427
        },
        "ernie-5.0-preview-1103": {
            "rating": 1509.3634753095687,
            "rating_q975": 1541.905948570274,
            "rating_q025": 1476.8210020488634
        },
        "glm-4.6": {
            "rating": 1504.95011367693,
            "rating_q975": 1524.0054496607793,
            "rating_q025": 1485.8947776930806
        },
        "gpt-5.1-high": {
            "rating": 1495.758917634891,
            "rating_q975": 1518.0678957131956,
            "rating_q025": 1473.4499395565865
        },
        "grok-4.1": {
            "rating": 1489.6319706394047,
            "rating_q975": 1509.25818753434,
            "rating_q025": 1470.0057537444693
        },
        "qwen3-max-preview": {
            "rating": 1487.9699347002822,
            "rating_q975": 1504.1570303835774,
            "rating_q025": 1471.782839016987
        },
        "grok-4.1-thinking": {
            "rating": 1475.1369764923788,
            "rating_q975": 1495.353698347822,
            "rating_q025": 1454.9202546369356
        },
        "qwen3-next-80b-a3b-instruct": {
            "rating": 1471.3823048645581,
            "rating_q975": 1489.407517949315,
            "rating_q025": 1453.3570917798013
        },
        "grok-4-fast-chat": {
            "rating": 1469.9413515460203,
            "rating_q975": 1501.7541337853102,
            "rating_q025": 1438.1285693067305
        },
        "deepseek-v3.1-thinking": {
            "rating": 1469.7408030132724,
            "rating_q975": 1490.5641939169407,
            "rating_q025": 1448.9174121096041
        },
        "qwen3-235b-a22b-thinking-2507": {
            "rating": 1468.6582495192501,
            "rating_q975": 1497.5365467246036,
            "rating_q025": 1439.7799523138967
        },
        "gpt-5.1": {
            "rating": 1468.546299335214,
            "rating_q975": 1489.8008401083757,
            "rating_q025": 1447.291758562052
        },
        "deepseek-v3.2-exp": {
            "rating": 1466.7231705053462,
            "rating_q975": 1490.743376135403,
            "rating_q025": 1442.7029648752894
        },
        "glm-4.5": {
            "rating": 1466.3585442034828,
            "rating_q975": 1483.3232241960618,
            "rating_q025": 1449.3938642109038
        },
        "qwen3-vl-235b-a22b-instruct": {
            "rating": 1464.6927777233884,
            "rating_q975": 1495.859957157061,
            "rating_q025": 1433.5255982897158
        },
        "claude-opus-4-5-20251101-thinking-32k": {
            "rating": 1463.0174690816207,
            "rating_q975": 1488.0914454207762,
            "rating_q025": 1437.9434927424652
        },
        "qwen3-235b-a22b-instruct-2507": {
            "rating": 1460.4951318060887,
            "rating_q975": 1472.9965693532706,
            "rating_q025": 1447.9936942589068
        },
        "deepseek-v3.1": {
            "rating": 1460.4092549083475,
            "rating_q975": 1478.6791835240047,
            "rating_q025": 1442.1393262926904
        },
        "claude-opus-4-5-20251101": {
            "rating": 1458.6040300988802,
            "rating_q975": 1485.1060069293646,
            "rating_q025": 1432.1020532683958
        },
        "qwen3-vl-235b-a22b-thinking": {
            "rating": 1457.9524125125868,
            "rating_q975": 1492.9527867200168,
            "rating_q025": 1422.9520383051567
        },
        "deepseek-r1-0528": {
            "rating": 1456.8623238440516,
            "rating_q975": 1476.209834762092,
            "rating_q025": 1437.5148129260112
        },
        "gemini-2.5-flash-preview-09-2025": {
            "rating": 1454.184184829705,
            "rating_q975": 1472.092433511874,
            "rating_q025": 1436.2759361475357
        },
        "claude-sonnet-4-5-20250929": {
            "rating": 1453.717888699869,
            "rating_q975": 1473.4879317650716,
            "rating_q025": 1433.9478456346665
        },
        "chatgpt-4o-latest-20250326": {
            "rating": 1450.4168442527716,
            "rating_q975": 1461.572272910606,
            "rating_q025": 1439.2614155949373
        },
        "deepseek-v3.2-thinking": {
            "rating": 1449.0647136787275,
            "rating_q975": 1481.8393111062667,
            "rating_q025": 1416.2901162511882
        },
        "deepseek-v3.2-exp-thinking": {
            "rating": 1448.6725088869275,
            "rating_q975": 1483.3829013993557,
            "rating_q025": 1413.9621163744994
        },
        "gemini-2.5-flash": {
            "rating": 1447.3232796446705,
            "rating_q975": 1457.8936603094126,
            "rating_q025": 1436.7528989799284
        },
        "deepseek-v3.2": {
            "rating": 1447.2949952077884,
            "rating_q975": 1475.2446429551783,
            "rating_q025": 1419.3453474603984
        },
        "mistral-medium-2508": {
            "rating": 1443.62225501195,
            "rating_q975": 1456.7393228921667,
            "rating_q025": 1430.5051871317335
        },
        "grok-3-preview-02-24": {
            "rating": 1443.0105046617925,
            "rating_q975": 1457.1782233047327,
            "rating_q025": 1428.8427860188524
        },
        "kimi-k2-thinking-turbo": {
            "rating": 1442.4630091615988,
            "rating_q975": 1463.6978308986893,
            "rating_q025": 1421.2281874245084
        },
        "mistral-large-3": {
            "rating": 1438.0748828483584,
            "rating_q975": 1469.8389756535078,
            "rating_q025": 1406.310790043209
        },
        "claude-sonnet-4-5-20250929-thinking-32k": {
            "rating": 1435.4299135768285,
            "rating_q975": 1453.337984497307,
            "rating_q025": 1417.5218426563501
        },
        "o3-2025-04-16": {
            "rating": 1434.1806303124986,
            "rating_q975": 1445.818988213313,
            "rating_q025": 1422.542272411684
        },
        "qwen3-max-2025-09-23": {
            "rating": 1433.401933504562,
            "rating_q975": 1464.3060060158937,
            "rating_q025": 1402.4978609932305
        },
        "qwen3-30b-a3b-instruct-2507": {
            "rating": 1432.3489351475164,
            "rating_q975": 1449.0682119044204,
            "rating_q025": 1415.6296583906123
        },
        "grok-4-0709": {
            "rating": 1431.6129486067296,
            "rating_q975": 1445.535989216969,
            "rating_q025": 1417.68990799649
        },
        "grok-4-fast-reasoning": {
            "rating": 1428.1743522765707,
            "rating_q975": 1451.322270042851,
            "rating_q025": 1405.0264345102905
        },
        "gpt-5-high": {
            "rating": 1427.530513060204,
            "rating_q975": 1443.5223898666104,
            "rating_q025": 1411.5386362537974
        },
        "longcat-flash-chat": {
            "rating": 1426.5405106172004,
            "rating_q975": 1450.2319786512792,
            "rating_q025": 1402.8490425831217
        },
        "glm-4.5-air": {
            "rating": 1426.4928968542688,
            "rating_q975": 1441.733252623988,
            "rating_q025": 1411.2525410845496
        },
        "hunyuan-t1-20250711": {
            "rating": 1425.569034325375,
            "rating_q975": 1463.20055479393,
            "rating_q025": 1387.93751385682
        },
        "qwen3-235b-a22b-no-thinking": {
            "rating": 1425.3700811807191,
            "rating_q975": 1439.04907103167,
            "rating_q025": 1411.6910913297681
        },
        "grok-4-1-fast-reasoning": {
            "rating": 1420.974177358618,
            "rating_q975": 1448.6488653358347,
            "rating_q025": 1393.2994893814011
        },
        "gpt-4.5-preview-2025-02-27": {
            "rating": 1417.0316510377495,
            "rating_q975": 1436.1828045015136,
            "rating_q025": 1397.8804975739854
        },
        "claude-opus-4-1-20250805": {
            "rating": 1416.1361864902572,
            "rating_q975": 1428.2039142426265,
            "rating_q025": 1404.0684587378878
        },
        "gpt-5-chat": {
            "rating": 1414.1832551049765,
            "rating_q975": 1429.4024356087002,
            "rating_q025": 1398.9640746012528
        },
        "qwen3-next-80b-a3b-thinking": {
            "rating": 1412.7703894468993,
            "rating_q975": 1434.6311724009083,
            "rating_q025": 1390.9096064928904
        },
        "hunyuan-turbos-20250416": {
            "rating": 1412.5474659962322,
            "rating_q975": 1439.328742619663,
            "rating_q025": 1385.7661893728014
        },
        "claude-opus-4-1-20250805-thinking-16k": {
            "rating": 1411.2266496474374,
            "rating_q975": 1424.725788789703,
            "rating_q025": 1397.7275105051717
        },
        "claude-haiku-4-5-20251001": {
            "rating": 1409.2612895758825,
            "rating_q975": 1427.1913153393184,
            "rating_q025": 1391.3312638124467
        },
        "ling-flash-2.0": {
            "rating": 1408.0123142776333,
            "rating_q975": 1441.4076735983197,
            "rating_q025": 1374.616954956947
        },
        "kimi-k2-0905-preview": {
            "rating": 1405.6882196548486,
            "rating_q975": 1427.8396043149874,
            "rating_q025": 1383.5368349947098
        },
        "ring-flash-2.0": {
            "rating": 1401.5409933513838,
            "rating_q975": 1433.3585940067462,
            "rating_q025": 1369.7233926960214
        },
        "kimi-k2-0711-preview": {
            "rating": 1399.3873147360166,
            "rating_q975": 1414.892798923075,
            "rating_q025": 1383.8818305489583
        },
        "gemini-2.5-flash-lite-preview-09-2025-no-thinking": {
            "rating": 1399.1623464147813,
            "rating_q975": 1416.5948715300806,
            "rating_q025": 1381.729821299482
        },
        "amazon-nova-experimental-chat-10-20": {
            "rating": 1398.3785676334558,
            "rating_q975": 1427.582174402274,
            "rating_q025": 1369.1749608646376
        },
        "gemini-2.5-flash-lite-preview-06-17-thinking": {
            "rating": 1396.4448758549627,
            "rating_q975": 1410.9908552845243,
            "rating_q025": 1381.898896425401
        },
        "deepseek-r1": {
            "rating": 1396.0731308477898,
            "rating_q975": 1413.6543138865989,
            "rating_q025": 1378.4919478089807
        },
        "o1-2024-12-17": {
            "rating": 1393.0185922428545,
            "rating_q975": 1406.9982530403856,
            "rating_q025": 1379.0389314453234
        },
        "mai-1-preview": {
            "rating": 1392.9369255369368,
            "rating_q975": 1411.5430742782107,
            "rating_q025": 1374.3307767956628
        },
        "step-3": {
            "rating": 1390.677549183797,
            "rating_q975": 1428.2632744151283,
            "rating_q025": 1353.0918239524658
        },
        "gpt-5-mini-high": {
            "rating": 1389.3611916550692,
            "rating_q975": 1406.3117502028713,
            "rating_q025": 1372.4106331072671
        },
        "grok-3-mini-high": {
            "rating": 1388.8271825997815,
            "rating_q975": 1411.0480245655217,
            "rating_q025": 1366.6063406340413
        },
        "minimax-m2": {
            "rating": 1387.8890940317633,
            "rating_q975": 1423.6369446711572,
            "rating_q025": 1352.1412433923695
        },
        "glm-4-plus-0111": {
            "rating": 1386.944214813851,
            "rating_q975": 1416.7303112341467,
            "rating_q025": 1357.1581183935552
        },
        "deepseek-v3-0324": {
            "rating": 1385.470958579778,
            "rating_q975": 1397.651282054766,
            "rating_q025": 1373.29063510479
        },
        "claude-opus-4-20250514-thinking-16k": {
            "rating": 1383.875529057655,
            "rating_q975": 1398.0608389870372,
            "rating_q025": 1369.690219128273
        },
        "claude-opus-4-20250514": {
            "rating": 1382.598810594231,
            "rating_q975": 1395.2211578016622,
            "rating_q025": 1369.9764633867999
        },
        "qwen3-235b-a22b": {
            "rating": 1377.59702693685,
            "rating_q975": 1394.1142952203395,
            "rating_q025": 1361.0797586533604
        },
        "qwen2.5-max": {
            "rating": 1376.1960314521414,
            "rating_q975": 1388.9376568927496,
            "rating_q025": 1363.4544060115331
        },
        "o3-mini-high": {
            "rating": 1375.354505374952,
            "rating_q975": 1392.3081988594606,
            "rating_q025": 1358.4008118904433
        },
        "gemini-2.0-flash-001": {
            "rating": 1375.0572614129073,
            "rating_q975": 1386.906925654369,
            "rating_q025": 1363.2075971714457
        },
        "grok-3-mini-beta": {
            "rating": 1374.467441045392,
            "rating_q975": 1392.3827273277238,
            "rating_q025": 1356.5521547630601
        },
        "qwq-32b": {
            "rating": 1374.1450090928718,
            "rating_q975": 1389.8317502388795,
            "rating_q025": 1358.458267946864
        },
        "mistral-medium-2505": {
            "rating": 1373.7619817139284,
            "rating_q975": 1388.1687708205757,
            "rating_q025": 1359.3551926072812
        },
        "amazon-nova-experimental-chat-10-09": {
            "rating": 1373.3046730679794,
            "rating_q975": 1401.9380616437256,
            "rating_q025": 1344.671284492233
        },
        "gpt-4.1-2025-04-14": {
            "rating": 1372.160252828964,
            "rating_q975": 1384.498828969511,
            "rating_q025": 1359.8216766884173
        },
        "gpt-oss-120b": {
            "rating": 1368.819385974343,
            "rating_q975": 1384.161121154561,
            "rating_q025": 1353.477650794125
        },
        "step-1o-turbo-202506": {
            "rating": 1365.2021353138857,
            "rating_q975": 1391.4378682499848,
            "rating_q025": 1338.9664023777866
        },
        "minimax-m1": {
            "rating": 1358.1292592176862,
            "rating_q975": 1372.2884445958716,
            "rating_q025": 1343.9700738395009
        },
        "qwen3-30b-a3b": {
            "rating": 1355.2439037736954,
            "rating_q975": 1371.7355292537213,
            "rating_q025": 1338.7522782936694
        },
        "qwen3-coder-480b-a35b-instruct": {
            "rating": 1353.1544442299817,
            "rating_q975": 1370.745164333919,
            "rating_q025": 1335.5637241260442
        },
        "qwen3-32b": {
            "rating": 1352.9031704871907,
            "rating_q975": 1390.6801922377315,
            "rating_q025": 1315.1261487366498
        },
        "hunyuan-turbo-0110": {
            "rating": 1352.5286670208518,
            "rating_q975": 1392.1459695156125,
            "rating_q025": 1312.9113645260911
        },
        "gpt-5-nano-high": {
            "rating": 1351.8704328570295,
            "rating_q975": 1381.5587901867857,
            "rating_q025": 1322.1820755272734
        },
        "claude-sonnet-4-20250514-thinking-32k": {
            "rating": 1349.3976212348853,
            "rating_q975": 1363.7361016669988,
            "rating_q025": 1335.0591408027717
        },
        "o4-mini-2025-04-16": {
            "rating": 1348.3331437918969,
            "rating_q975": 1361.0906086727095,
            "rating_q025": 1335.5756789110842
        },
        "qwen-plus-0125": {
            "rating": 1345.0320757048205,
            "rating_q975": 1372.3990054712947,
            "rating_q025": 1317.6651459383463
        },
        "gemma-3-27b-it": {
            "rating": 1342.1951820831382,
            "rating_q975": 1354.7207984922716,
            "rating_q025": 1329.6695656740048
        },
        "hunyuan-large-2025-02-10": {
            "rating": 1341.8598871760603,
            "rating_q975": 1374.3919893296443,
            "rating_q025": 1309.3277850224763
        },
        "claude-sonnet-4-20250514": {
            "rating": 1336.665520369101,
            "rating_q975": 1349.9326772648094,
            "rating_q025": 1323.3983634733925
        },
        "deepseek-v3": {
            "rating": 1335.9942316625109,
            "rating_q975": 1350.934082176624,
            "rating_q025": 1321.0543811483976
        },
        "gemini-2.0-flash-lite-preview-02-05": {
            "rating": 1335.8886884123806,
            "rating_q975": 1350.4143944269806,
            "rating_q025": 1321.3629823977806
        },
        "nova-2-lite": {
            "rating": 1335.39020371813,
            "rating_q975": 1370.1325011130643,
            "rating_q025": 1300.6479063231955
        },
        "mistral-small-2506": {
            "rating": 1335.0071635533175,
            "rating_q975": 1354.5240897590004,
            "rating_q025": 1315.4902373476345
        },
        "gpt-4.1-mini-2025-04-14": {
            "rating": 1330.1500940497938,
            "rating_q975": 1343.674738870209,
            "rating_q025": 1316.6254492293785
        },
        "gemini-1.5-pro-002": {
            "rating": 1328.565570750629,
            "rating_q975": 1337.6950618252179,
            "rating_q025": 1319.43607967604
        },
        "step-2-16k-exp-202412": {
            "rating": 1327.0136856763136,
            "rating_q975": 1359.3319935219652,
            "rating_q025": 1294.695377830662
        },
        "glm-4.5v": {
            "rating": 1325.9386123088354,
            "rating_q975": 1368.894358287521,
            "rating_q025": 1282.9828663301498
        },
        "o3-mini": {
            "rating": 1325.4219821100253,
            "rating_q975": 1335.7519520389556,
            "rating_q025": 1315.092012181095
        },
        "hunyuan-turbos-20250226": {
            "rating": 1324.208817716993,
            "rating_q975": 1363.6462496719644,
            "rating_q025": 1284.7713857620217
        },
        "o1-preview": {
            "rating": 1323.3752254974365,
            "rating_q975": 1335.2399648460266,
            "rating_q025": 1311.5104861488464
        },
        "command-a-03-2025": {
            "rating": 1320.8691727780356,
            "rating_q975": 1332.2477282547468,
            "rating_q025": 1309.4906173013244
        },
        "hunyuan-standard-2025-02-10": {
            "rating": 1317.1972185409104,
            "rating_q975": 1348.200876423042,
            "rating_q025": 1286.1935606587788
        },
        "yi-lightning": {
            "rating": 1315.3131710205316,
            "rating_q975": 1326.9525119821649,
            "rating_q025": 1303.6738300588984
        },
        "deepseek-v2.5-1210": {
            "rating": 1315.119464011822,
            "rating_q975": 1340.877081469716,
            "rating_q025": 1289.361846553928
        },
        "o1-mini": {
            "rating": 1311.5527720733983,
            "rating_q975": 1320.978822255628,
            "rating_q025": 1302.1267218911685
        },
        "gpt-oss-20b": {
            "rating": 1311.1264899195771,
            "rating_q975": 1337.8576703417198,
            "rating_q025": 1284.3953094974345
        },
        "qwen2.5-plus-1127": {
            "rating": 1309.3536779139297,
            "rating_q975": 1331.6036293512461,
            "rating_q025": 1287.1037264766132
        },
        "claude-3-7-sonnet-20250219-thinking-32k": {
            "rating": 1306.3477924873355,
            "rating_q975": 1319.9969218248157,
            "rating_q025": 1292.6986631498553
        },
        "gemma-3n-e4b-it": {
            "rating": 1301.3849452366312,
            "rating_q975": 1318.9782436181176,
            "rating_q025": 1283.7916468551448
        },
        "athene-v2-chat": {
            "rating": 1300.0722763714625,
            "rating_q975": 1313.4916156422616,
            "rating_q025": 1286.6529371006634
        },
        "claude-3-7-sonnet-20250219": {
            "rating": 1297.6450592520114,
            "rating_q975": 1310.3443128406107,
            "rating_q025": 1284.945805663412
        },
        "glm-4-plus": {
            "rating": 1292.040852429055,
            "rating_q975": 1304.3362493690965,
            "rating_q025": 1279.7454554890132
        },
        "gemini-1.5-flash-002": {
            "rating": 1292.0249732594266,
            "rating_q975": 1302.7930869192176,
            "rating_q025": 1281.2568595996356
        },
        "grok-2-2024-08-13": {
            "rating": 1286.8782117470664,
            "rating_q975": 1295.5598910309877,
            "rating_q025": 1278.196532463145
        },
        "olmo-3-32b-think": {
            "rating": 1280.9551379214508,
            "rating_q975": 1338.319668897429,
            "rating_q025": 1223.5906069454727
        },
        "deepseek-v2.5": {
            "rating": 1279.4807682667476,
            "rating_q975": 1291.8942782393212,
            "rating_q025": 1267.067258294174
        },
        "llama-3.3-nemotron-49b-super-v1": {
            "rating": 1277.5815918309959,
            "rating_q975": 1316.7575399425657,
            "rating_q025": 1238.405643719426
        },
        "gpt-4o-2024-05-13": {
            "rating": 1274.899380104524,
            "rating_q975": 1282.6284905904515,
            "rating_q025": 1267.1702696185964
        },
        "llama-4-maverick-17b-128e-instruct": {
            "rating": 1273.7182801747308,
            "rating_q975": 1287.1323621221295,
            "rating_q025": 1260.304198227332
        },
        "gemini-1.5-pro-001": {
            "rating": 1272.3975951463497,
            "rating_q975": 1281.4596833534245,
            "rating_q025": 1263.3355069392749
        },
        "gemini-advanced-0514": {
            "rating": 1272.3802291648103,
            "rating_q975": 1282.8968757849048,
            "rating_q025": 1261.8635825447159
        },
        "qwen2.5-72b-instruct": {
            "rating": 1269.994112426903,
            "rating_q975": 1280.279362380493,
            "rating_q025": 1259.708862473313
        },
        "claude-3-5-sonnet-20241022": {
            "rating": 1269.2795473142846,
            "rating_q975": 1276.905925916319,
            "rating_q025": 1261.6531687122504
        },
        "hunyuan-large-vision": {
            "rating": 1268.4747949139692,
            "rating_q975": 1306.8037576501176,
            "rating_q025": 1230.1458321778207
        },
        "gpt-4.1-nano-2025-04-14": {
            "rating": 1265.2195078068482,
            "rating_q975": 1301.5213931915819,
            "rating_q025": 1228.9176224221146
        },
        "claude-3-5-sonnet-20240620": {
            "rating": 1262.3749532534753,
            "rating_q975": 1270.80950772986,
            "rating_q025": 1253.9403987770906
        },
        "gpt-4o-mini-2024-07-18": {
            "rating": 1261.7148675325643,
            "rating_q975": 1270.0083364161985,
            "rating_q025": 1253.42139864893
        },
        "llama-3.1-nemotron-70b-instruct": {
            "rating": 1260.8512587246034,
            "rating_q975": 1281.7594070076912,
            "rating_q025": 1239.9431104415157
        },
        "grok-2-mini-2024-08-13": {
            "rating": 1259.9102338332095,
            "rating_q975": 1269.1184881644492,
            "rating_q025": 1250.7019795019698
        },
        "gpt-4o-2024-08-06": {
            "rating": 1251.9333275808694,
            "rating_q975": 1261.8914078539838,
            "rating_q025": 1241.9752473077551
        },
        "qwen-max-0919": {
            "rating": 1251.2189869590336,
            "rating_q975": 1266.3236046443183,
            "rating_q025": 1236.114369273749
        },
        "llama-4-scout-17b-16e-instruct": {
            "rating": 1249.1612572298836,
            "rating_q975": 1264.9131837939183,
            "rating_q025": 1233.409330665849
        },
        "mistral-small-3.1-24b-instruct-2503": {
            "rating": 1248.0242064572167,
            "rating_q975": 1263.5058206905608,
            "rating_q025": 1232.5425922238726
        },
        "llama-3.1-tulu-3-70b": {
            "rating": 1246.5934658212218,
            "rating_q975": 1282.461118589798,
            "rating_q025": 1210.7258130526457
        },
        "claude-3-opus-20240229": {
            "rating": 1245.5962992998243,
            "rating_q975": 1252.54886341412,
            "rating_q025": 1238.6437351855286
        },
        "amazon-nova-pro-v1.0": {
            "rating": 1241.7344217322366,
            "rating_q975": 1255.5392749008129,
            "rating_q025": 1227.9295685636603
        },
        "llama-3.1-405b-instruct-bf16": {
            "rating": 1240.3732293307535,
            "rating_q975": 1250.7246190274311,
            "rating_q025": 1230.0218396340758
        },
        "gpt-4-turbo-2024-04-09": {
            "rating": 1240.0477179789746,
            "rating_q975": 1248.6183246993842,
            "rating_q025": 1231.477111258565
        },
        "gpt-4-1106-preview": {
            "rating": 1239.6905123062256,
            "rating_q975": 1248.8414075852731,
            "rating_q025": 1230.539617027178
        },
        "reka-core-20240904": {
            "rating": 1239.5907743372627,
            "rating_q975": 1262.2903277585726,
            "rating_q025": 1216.8912209159528
        },
        "hunyuan-standard-256k": {
            "rating": 1238.158494943767,
            "rating_q975": 1271.9574797873058,
            "rating_q025": 1204.3595101002281
        },
        "mistral-large-2411": {
            "rating": 1238.134773819077,
            "rating_q975": 1251.0591782421102,
            "rating_q025": 1225.210369396044
        },
        "mistral-large-2407": {
            "rating": 1237.978067386543,
            "rating_q975": 1247.8630156110714,
            "rating_q025": 1228.0931191620145
        },
        "qwen2-72b-instruct": {
            "rating": 1236.4412774344903,
            "rating_q975": 1247.296813857664,
            "rating_q025": 1225.5857410113167
        },
        "gpt-4-0125-preview": {
            "rating": 1234.5182716318477,
            "rating_q975": 1243.4609170905978,
            "rating_q025": 1225.5756261730976
        },
        "athene-70b-0725": {
            "rating": 1234.4630083212712,
            "rating_q975": 1248.5571855217668,
            "rating_q025": 1220.3688311207757
        },
        "llama-3.1-405b-instruct-fp8": {
            "rating": 1232.0358365219697,
            "rating_q975": 1240.9090800078543,
            "rating_q025": 1223.1625930360851
        },
        "gemini-1.5-flash-001": {
            "rating": 1231.5277921544102,
            "rating_q975": 1240.9038057622977,
            "rating_q025": 1222.1517785465228
        },
        "gemini-1.5-flash-8b-001": {
            "rating": 1228.943971631197,
            "rating_q975": 1239.92136995896,
            "rating_q025": 1217.966573303434
        },
        "glm-4-0520": {
            "rating": 1227.1562321682104,
            "rating_q975": 1243.6000176913954,
            "rating_q025": 1210.7124466450255
        },
        "command-r-plus-08-2024": {
            "rating": 1224.3254276859375,
            "rating_q975": 1243.5511585541042,
            "rating_q025": 1205.0996968177708
        },
        "gemma-2-9b-it-simpo": {
            "rating": 1223.4179379500067,
            "rating_q975": 1243.9979708537662,
            "rating_q025": 1202.8379050462472
        },
        "amazon-nova-lite-v1.0": {
            "rating": 1223.3478341067264,
            "rating_q975": 1238.9034450613717,
            "rating_q025": 1207.792223152081
        },
        "claude-3-5-haiku-20241022": {
            "rating": 1223.1252068034664,
            "rating_q975": 1232.5890264911964,
            "rating_q025": 1213.6613871157365
        },
        "magistral-medium-2506": {
            "rating": 1222.1519433079416,
            "rating_q975": 1249.8192397613336,
            "rating_q025": 1194.4846468545495
        },
        "gemma-2-27b-it": {
            "rating": 1218.8853182169137,
            "rating_q975": 1226.7807448872602,
            "rating_q025": 1210.9898915465672
        },
        "qwen2.5-coder-32b-instruct": {
            "rating": 1218.4711788466554,
            "rating_q975": 1242.614858743317,
            "rating_q025": 1194.327498949994
        },
        "reka-flash-20240904": {
            "rating": 1217.9290620033128,
            "rating_q975": 1240.829676187347,
            "rating_q025": 1195.0284478192784
        },
        "qwq-32b-preview": {
            "rating": 1216.0951212598225,
            "rating_q975": 1256.7533992107478,
            "rating_q025": 1175.436843308897
        },
        "llama-3.3-70b-instruct": {
            "rating": 1214.9212834546108,
            "rating_q975": 1225.3137331911016,
            "rating_q025": 1204.52883371812
        },
        "llama-3.1-70b-instruct": {
            "rating": 1212.9838244758487,
            "rating_q975": 1222.0133488280894,
            "rating_q025": 1203.954300123608
        },
        "phi-4": {
            "rating": 1210.909861724645,
            "rating_q975": 1225.9631230194175,
            "rating_q025": 1195.8566004298725
        },
        "yi-1.5-34b-chat": {
            "rating": 1210.161738494422,
            "rating_q975": 1222.3723220467125,
            "rating_q025": 1197.9511549421316
        },
        "nemotron-4-340b-instruct": {
            "rating": 1209.84477685279,
            "rating_q975": 1222.4779836767439,
            "rating_q025": 1197.211570028836
        },
        "amazon-nova-micro-v1.0": {
            "rating": 1209.6098380916408,
            "rating_q975": 1225.3315278888088,
            "rating_q025": 1193.8881482944728
        },
        "c4ai-aya-expanse-32b": {
            "rating": 1208.146598422105,
            "rating_q975": 1219.996366782384,
            "rating_q025": 1196.2968300618259
        },
        "qwen1.5-110b-chat": {
            "rating": 1202.4240578052843,
            "rating_q975": 1215.076850411522,
            "rating_q025": 1189.7712651990466
        },
        "mistral-small-24b-instruct-2501": {
            "rating": 1201.9614038016289,
            "rating_q975": 1219.2818945429667,
            "rating_q025": 1184.640913060291
        },
        "jamba-1.5-large": {
            "rating": 1199.9972980056955,
            "rating_q975": 1221.5159574493978,
            "rating_q025": 1178.4786385619932
        },
        "internlm2_5-20b-chat": {
            "rating": 1199.1496373033387,
            "rating_q975": 1217.3617332051235,
            "rating_q025": 1180.937541401554
        },
        "deepseek-coder-v2": {
            "rating": 1198.9931859143944,
            "rating_q975": 1213.5701873711218,
            "rating_q025": 1184.416184457667
        },
        "olmo-2-0325-32b-instruct": {
            "rating": 1192.148241670026,
            "rating_q975": 1227.8310367984875,
            "rating_q025": 1156.4654465415645
        },
        "ministral-8b-2410": {
            "rating": 1191.447090273813,
            "rating_q975": 1216.441314490265,
            "rating_q025": 1166.452866057361
        },
        "command-r-plus": {
            "rating": 1190.3335163425347,
            "rating_q975": 1199.3159505413523,
            "rating_q025": 1181.3510821437171
        },
        "claude-3-sonnet-20240229": {
            "rating": 1186.872827081917,
            "rating_q975": 1195.2842739773614,
            "rating_q025": 1178.4613801864725
        },
        "qwen1.5-72b-chat": {
            "rating": 1184.285317437931,
            "rating_q975": 1195.9089295307142,
            "rating_q025": 1172.661705345148
        },
        "gemma-2-9b-it": {
            "rating": 1182.804845953885,
            "rating_q975": 1191.7355529446966,
            "rating_q025": 1173.8741389630734
        },
        "gpt-4-0314": {
            "rating": 1182.095063647106,
            "rating_q975": 1193.1858743768319,
            "rating_q025": 1171.00425291738
        },
        "command-r-08-2024": {
            "rating": 1180.752229460088,
            "rating_q975": 1200.283115937437,
            "rating_q025": 1161.221342982739
        },
        "c4ai-aya-expanse-8b": {
            "rating": 1178.998089018669,
            "rating_q975": 1201.9494456775126,
            "rating_q025": 1156.0467323598252
        },
        "llama-3.1-nemotron-51b-instruct": {
            "rating": 1178.0096567259634,
            "rating_q975": 1205.6403677584635,
            "rating_q025": 1150.3789456934633
        },
        "qwen1.5-32b-chat": {
            "rating": 1175.511425354282,
            "rating_q975": 1188.1994396568998,
            "rating_q025": 1162.8234110516642
        },
        "yi-34b-chat": {
            "rating": 1174.4101980578926,
            "rating_q975": 1192.0952896928268,
            "rating_q025": 1156.7251064229583
        },
        "llama-3.1-tulu-3-8b": {
            "rating": 1173.4196397140547,
            "rating_q975": 1209.7533461495393,
            "rating_q025": 1137.08593327857
        },
        "claude-3-haiku-20240307": {
            "rating": 1153.4877833790808,
            "rating_q975": 1161.4814221728698,
            "rating_q025": 1145.494144585292
        },
        "llama-3.1-8b-instruct": {
            "rating": 1149.225513212425,
            "rating_q975": 1158.9264830752743,
            "rating_q025": 1139.5245433495759
        },
        "qwen1.5-14b-chat": {
            "rating": 1147.6092370910278,
            "rating_q975": 1160.9417807449734,
            "rating_q025": 1134.2766934370823
        },
        "command-r": {
            "rating": 1145.8660112845432,
            "rating_q975": 1155.8551183157992,
            "rating_q025": 1135.8769042532872
        },
        "granite-3.1-8b-instruct": {
            "rating": 1142.7473136854123,
            "rating_q975": 1181.7642596130352,
            "rating_q025": 1103.7303677577895
        },
        "reka-flash-21b-20240226-online": {
            "rating": 1141.2955286540068,
            "rating_q975": 1155.9998639234038,
            "rating_q025": 1126.5911933846098
        },
        "qwen1.5-7b-chat": {
            "rating": 1136.922746632804,
            "rating_q975": 1165.0585320144692,
            "rating_q025": 1108.786961251139
        },
        "granite-3.1-2b-instruct": {
            "rating": 1136.656398741707,
            "rating_q975": 1174.5841792270649,
            "rating_q025": 1098.7286182563494
        },
        "jamba-1.5-mini": {
            "rating": 1134.1832867900557,
            "rating_q975": 1155.2813625566519,
            "rating_q025": 1113.0852110234596
        },
        "gpt-4-0613": {
            "rating": 1133.7261694981087,
            "rating_q975": 1143.3691465826776,
            "rating_q025": 1124.0831924135398
        },
        "reka-flash-21b-20240226": {
            "rating": 1133.3342871922894,
            "rating_q975": 1146.2555990086314,
            "rating_q025": 1120.4129753759473
        },
        "gemma-2-2b-it": {
            "rating": 1130.7175162420826,
            "rating_q975": 1140.8639356566707,
            "rating_q025": 1120.5710968274946
        },
        "deepseek-llm-67b-chat": {
            "rating": 1128.7238805808263,
            "rating_q975": 1168.647778487115,
            "rating_q025": 1088.7999826745377
        },
        "gemini-pro-dev-api": {
            "rating": 1121.4734865027226,
            "rating_q975": 1138.3525518771023,
            "rating_q025": 1104.594421128343
        },
        "mistral-large-2402": {
            "rating": 1118.2908091890267,
            "rating_q975": 1128.2259598397031,
            "rating_q025": 1108.3556585383503
        },
        "mixtral-8x22b-instruct-v0.1": {
            "rating": 1115.2157091382326,
            "rating_q975": 1125.5862035527541,
            "rating_q025": 1104.845214723711
        },
        "llama-3-70b-instruct": {
            "rating": 1114.0103737684703,
            "rating_q975": 1122.2566368853525,
            "rating_q025": 1105.7641106515882
        },
        "starling-lm-7b-beta": {
            "rating": 1113.1738202006436,
            "rating_q975": 1127.4550922639542,
            "rating_q025": 1098.892548137333
        },
        "mistral-medium": {
            "rating": 1109.2760299866477,
            "rating_q975": 1122.205296468162,
            "rating_q025": 1096.3467635051334
        },
        "phi-3-medium-4k-instruct": {
            "rating": 1106.4072440331242,
            "rating_q975": 1118.6170129277482,
            "rating_q025": 1094.1974751385003
        },
        "gemini-pro": {
            "rating": 1096.000702210445,
            "rating_q975": 1133.5495326002986,
            "rating_q025": 1058.4518718205916
        },
        "zephyr-orpo-141b-A35b-v0.1": {
            "rating": 1082.2393140338615,
            "rating_q975": 1104.9292666448532,
            "rating_q025": 1059.5493614228699
        },
        "openchat-3.5-0106": {
            "rating": 1081.9370326396556,
            "rating_q975": 1098.9195755849187,
            "rating_q025": 1064.9544896943926
        },
        "gpt-3.5-turbo-0125": {
            "rating": 1075.1202737205374,
            "rating_q975": 1084.6988468717009,
            "rating_q025": 1065.541700569374
        },
        "llama-3-8b-instruct": {
            "rating": 1075.0408983822103,
            "rating_q975": 1083.990935003065,
            "rating_q025": 1066.0908617613557
        },
        "qwen-14b-chat": {
            "rating": 1073.9784190220798,
            "rating_q975": 1117.6731311324538,
            "rating_q025": 1030.2837069117058
        },
        "chatglm-6b": {
            "rating": 1072.9450225586918,
            "rating_q975": 1112.321664425607,
            "rating_q025": 1033.5683806917766
        },
        "openchat-3.5": {
            "rating": 1071.248991177729,
            "rating_q975": 1103.203047977168,
            "rating_q025": 1039.2949343782902
        },
        "dbrx-instruct-preview": {
            "rating": 1068.2155093170245,
            "rating_q975": 1080.680370455569,
            "rating_q025": 1055.75064817848
        },
        "granite-3.0-8b-instruct": {
            "rating": 1067.1954532938482,
            "rating_q975": 1089.9754722528592,
            "rating_q025": 1044.4154343348373
        },
        "snowflake-arctic-instruct": {
            "rating": 1066.7624838082195,
            "rating_q975": 1079.8657547136777,
            "rating_q025": 1053.6592129027613
        },
        "granite-3.0-2b-instruct": {
            "rating": 1066.5132250749564,
            "rating_q975": 1088.9820612204967,
            "rating_q025": 1044.044388929416
        },
        "chatglm3-6b": {
            "rating": 1062.4408525157605,
            "rating_q975": 1105.4892733814208,
            "rating_q025": 1019.3924316501003
        },
        "gemma-1.1-7b-it": {
            "rating": 1059.9500268820311,
            "rating_q975": 1071.8095517305267,
            "rating_q025": 1048.0905020335356
        },
        "phi-3-small-8k-instruct": {
            "rating": 1059.8154251884405,
            "rating_q975": 1073.2041292011838,
            "rating_q025": 1046.4267211756971
        },
        "wizardlm-70b": {
            "rating": 1058.174348442849,
            "rating_q975": 1090.3053074709742,
            "rating_q025": 1026.0433894147236
        },
        "mixtral-8x7b-instruct-v0.1": {
            "rating": 1054.8942708944971,
            "rating_q975": 1064.6121082422417,
            "rating_q025": 1045.1764335467526
        },
        "starling-lm-7b-alpha": {
            "rating": 1043.9604814435613,
            "rating_q975": 1065.309734573057,
            "rating_q025": 1022.6112283140654
        },
        "vicuna-13b": {
            "rating": 1037.6920853055349,
            "rating_q975": 1056.6508936621462,
            "rating_q025": 1018.7332769489234
        },
        "gemma-7b-it": {
            "rating": 1036.364076167792,
            "rating_q975": 1055.6543937690872,
            "rating_q025": 1017.0737585664971
        },
        "vicuna-33b": {
            "rating": 1036.0547297662781,
            "rating_q975": 1052.7816204175317,
            "rating_q025": 1019.3278391150246
        },
        "phi-3-mini-4k-instruct-june-2024": {
            "rating": 1032.7486251495995,
            "rating_q975": 1050.1109895965142,
            "rating_q025": 1015.386260702685
        },
        "qwen1.5-4b-chat": {
            "rating": 1022.7951735504618,
            "rating_q975": 1042.2563539739358,
            "rating_q025": 1003.3339931269877
        },
        "wizardlm-13b": {
            "rating": 1022.3618898507273,
            "rating_q975": 1055.2970648018518,
            "rating_q025": 989.4267148996026
        },
        "phi-3-mini-4k-instruct": {
            "rating": 1021.6798075776227,
            "rating_q975": 1035.478492433693,
            "rating_q025": 1007.8811227215524
        },
        "llama-3.2-3b-instruct": {
            "rating": 1019.182200492243,
            "rating_q975": 1043.0523860820285,
            "rating_q025": 995.3120149024576
        },
        "phi-3-mini-128k-instruct": {
            "rating": 1018.0999643932225,
            "rating_q975": 1033.3773106414064,
            "rating_q025": 1002.8226181450386
        },
        "gpt-3.5-turbo-1106": {
            "rating": 1014.8097998118512,
            "rating_q975": 1039.2472709718356,
            "rating_q025": 990.3723286518667
        },
        "olmo-7b-instruct": {
            "rating": 1012.7053914137116,
            "rating_q975": 1035.537459918589,
            "rating_q025": 989.873322908834
        },
        "gemma-1.1-2b-it": {
            "rating": 1012.6103653207215,
            "rating_q975": 1030.0190337599934,
            "rating_q025": 995.2016968814496
        },
        "openhermes-2.5-mistral-7b": {
            "rating": 1011.6820551849614,
            "rating_q975": 1054.195018636074,
            "rating_q025": 969.1690917338486
        },
        "mistral-7b-instruct-v0.2": {
            "rating": 1009.0450215144506,
            "rating_q975": 1023.6381030277047,
            "rating_q025": 994.4519400011965
        },
        "tulu-2-dpo-70b": {
            "rating": 1007.5047993578215,
            "rating_q975": 1043.0843498926988,
            "rating_q025": 971.9252488229441
        },
        "llama-2-13b-chat": {
            "rating": 999.1584232475063,
            "rating_q975": 1017.5368219206063,
            "rating_q025": 980.7800245744064
        },
        "llama-2-70b-chat": {
            "rating": 994.089955849988,
            "rating_q975": 1006.8974952077785,
            "rating_q025": 981.2824164921974
        },
        "gemma-2b-it": {
            "rating": 986.8289191694342,
            "rating_q975": 1011.819404240184,
            "rating_q025": 961.8384340986845
        },
        "vicuna-7b": {
            "rating": 977.8760032607915,
            "rating_q975": 1010.8288340933644,
            "rating_q025": 944.9231724282187
        },
        "codellama-34b-instruct": {
            "rating": 974.1340861895449,
            "rating_q975": 1011.8630539674748,
            "rating_q025": 936.4051184116149
        },
        "llama-2-7b-chat": {
            "rating": 973.7839840037125,
            "rating_q975": 993.0657786536078,
            "rating_q025": 954.5021893538171
        },
        "zephyr-7b-beta": {
            "rating": 962.6836701908177,
            "rating_q975": 993.056764861037,
            "rating_q025": 932.3105755205984
        },
        "mpt-7b-chat": {
            "rating": 959.2295713541168,
            "rating_q975": 1000.7338733455034,
            "rating_q025": 917.7252693627303
        },
        "llama-3.2-1b-instruct": {
            "rating": 958.2704732353718,
            "rating_q975": 984.2917474296173,
            "rating_q025": 932.2491990411263
        },
        "mistral-7b-instruct": {
            "rating": 936.8939029726445,
            "rating_q975": 969.7791202494257,
            "rating_q025": 904.0086856958633
        },
        "RWKV-4-Raven-14B": {
            "rating": 901.6519947522135,
            "rating_q975": 940.7041871467976,
            "rating_q025": 862.5998023576293
        },
        "palm-2": {
            "rating": 887.2936621924417,
            "rating_q975": 924.0049472800022,
            "rating_q025": 850.5823771048813
        },
        "koala-13b": {
            "rating": 874.4967275688493,
            "rating_q975": 906.276784449383,
            "rating_q025": 842.7166706883157
        },
        "dolly-v2-12b": {
            "rating": 829.3295108819101,
            "rating_q975": 874.0300326501563,
            "rating_q025": 784.6289891136639
        },
        "oasst-pythia-12b": {
            "rating": 798.7001539777211,
            "rating_q975": 832.309090173251,
            "rating_q025": 765.0912177821913
        },
        "alpaca-13b": {
            "rating": 779.4835482232385,
            "rating_q975": 818.5521234607795,
            "rating_q025": 740.4149729856974
        },
        "fastchat-t5-3b": {
            "rating": 706.1516342417269,
            "rating_q975": 745.220284614161,
            "rating_q025": 667.0829838692929
        }
    },
    "coding": {
        "claude-opus-4-5-20251101-thinking-32k": {
            "rating": 1515.1020105121383,
            "rating_q975": 1528.848978894912,
            "rating_q025": 1501.3550421293646
        },
        "claude-opus-4-5-20251101": {
            "rating": 1498.0523144292692,
            "rating_q975": 1511.500020724735,
            "rating_q025": 1484.6046081338036
        },
        "claude-sonnet-4-5-20250929-thinking-32k": {
            "rating": 1495.1706246068536,
            "rating_q975": 1503.6243704115427,
            "rating_q025": 1486.7168788021645
        },
        "gemini-3-pro": {
            "rating": 1486.391701071574,
            "rating_q975": 1497.4860970201382,
            "rating_q025": 1475.29730512301
        },
        "claude-opus-4-1-20250805-thinking-16k": {
            "rating": 1483.4104080783227,
            "rating_q975": 1490.5894138445703,
            "rating_q025": 1476.231402312075
        },
        "claude-sonnet-4-5-20250929": {
            "rating": 1475.8191953010912,
            "rating_q975": 1485.1530352815053,
            "rating_q025": 1466.4853553206772
        },
        "claude-opus-4-1-20250805": {
            "rating": 1469.8517648355087,
            "rating_q975": 1476.513880993165,
            "rating_q025": 1463.1896486778523
        },
        "longcat-flash-chat": {
            "rating": 1467.9861029106748,
            "rating_q975": 1480.627608309306,
            "rating_q025": 1455.3445975120437
        },
        "gemini-2.5-pro": {
            "rating": 1459.1819748972932,
            "rating_q975": 1465.189869041161,
            "rating_q025": 1453.1740807534254
        },
        "qwen3-max-preview": {
            "rating": 1457.4394356515975,
            "rating_q975": 1465.966852672486,
            "rating_q025": 1448.9120186307089
        },
        "grok-4.1-thinking": {
            "rating": 1455.7879326038976,
            "rating_q975": 1466.7441774546003,
            "rating_q025": 1444.831687753195
        },
        "glm-4.6": {
            "rating": 1455.2299771928551,
            "rating_q975": 1463.9542000244799,
            "rating_q025": 1446.5057543612304
        },
        "gpt-5.1-high": {
            "rating": 1451.411006974056,
            "rating_q975": 1463.4713152071595,
            "rating_q025": 1439.3506987409523
        },
        "claude-haiku-4-5-20251001": {
            "rating": 1451.012117398801,
            "rating_q975": 1459.5104509959485,
            "rating_q025": 1442.5137838016533
        },
        "ernie-5.0-preview-1103": {
            "rating": 1449.3736090429775,
            "rating_q975": 1467.1293185286072,
            "rating_q025": 1431.6178995573478
        },
        "kimi-k2-thinking-turbo": {
            "rating": 1448.1757142967842,
            "rating_q975": 1459.1806768381389,
            "rating_q025": 1437.1707517554296
        },
        "grok-4.1": {
            "rating": 1444.086862140595,
            "rating_q975": 1454.967847304914,
            "rating_q025": 1433.2058769762762
        },
        "qwen3-235b-a22b-instruct-2507": {
            "rating": 1442.953047534146,
            "rating_q975": 1449.586947981955,
            "rating_q025": 1436.319147086337
        },
        "qwen3-next-80b-a3b-instruct": {
            "rating": 1442.2467211529677,
            "rating_q975": 1451.0575071757776,
            "rating_q025": 1433.4359351301578
        },
        "mistral-large-3": {
            "rating": 1441.8383382554427,
            "rating_q975": 1458.3694722421285,
            "rating_q025": 1425.307204268757
        },
        "qwen3-vl-235b-a22b-instruct": {
            "rating": 1441.4846208830636,
            "rating_q975": 1455.170612509344,
            "rating_q025": 1427.7986292567832
        },
        "claude-opus-4-20250514-thinking-16k": {
            "rating": 1440.7506398578982,
            "rating_q975": 1448.6843196560708,
            "rating_q025": 1432.8169600597257
        },
        "qwen3-max-2025-09-23": {
            "rating": 1440.3189519186665,
            "rating_q975": 1453.258488436,
            "rating_q025": 1427.3794154013328
        },
        "gpt-5-high": {
            "rating": 1439.4388928997698,
            "rating_q975": 1447.4780496169533,
            "rating_q025": 1431.3997361825864
        },
        "gpt-5.1": {
            "rating": 1438.962918874771,
            "rating_q975": 1450.2838114602346,
            "rating_q025": 1427.6420262893075
        },
        "deepseek-v3.2-exp": {
            "rating": 1438.0126527122547,
            "rating_q975": 1449.9138228955028,
            "rating_q025": 1426.1114825290067
        },
        "deepseek-v3.2-thinking": {
            "rating": 1436.3601125523007,
            "rating_q975": 1454.495532131925,
            "rating_q025": 1418.2246929726764
        },
        "deepseek-v3.2": {
            "rating": 1435.9617003093883,
            "rating_q975": 1452.4564008156563,
            "rating_q025": 1419.4669998031204
        },
        "deepseek-v3.2-exp-thinking": {
            "rating": 1435.8246688012064,
            "rating_q975": 1449.21797730415,
            "rating_q025": 1422.4313602982627
        },
        "glm-4.5": {
            "rating": 1434.2606216794684,
            "rating_q975": 1443.1192978935753,
            "rating_q025": 1425.4019454653615
        },
        "grok-3-preview-02-24": {
            "rating": 1431.8030870053929,
            "rating_q975": 1440.0399853508113,
            "rating_q025": 1423.5661886599744
        },
        "mistral-medium-2508": {
            "rating": 1430.7234794838057,
            "rating_q975": 1437.6262009926484,
            "rating_q025": 1423.820757974963
        },
        "qwen3-vl-235b-a22b-thinking": {
            "rating": 1427.1277462150265,
            "rating_q975": 1441.5155687676765,
            "rating_q025": 1412.7399236623764
        },
        "grok-4-fast-chat": {
            "rating": 1426.2641220718258,
            "rating_q975": 1442.6573043372848,
            "rating_q025": 1409.8709398063668
        },
        "deepseek-r1-0528": {
            "rating": 1425.8666668547535,
            "rating_q975": 1437.169800492474,
            "rating_q025": 1414.563533217033
        },
        "deepseek-v3.1-terminus-thinking": {
            "rating": 1424.1996331866578,
            "rating_q975": 1447.8299331056085,
            "rating_q025": 1400.5693332677072
        },
        "qwen3-235b-a22b-thinking-2507": {
            "rating": 1423.4998112467374,
            "rating_q975": 1438.1829991454442,
            "rating_q025": 1408.8166233480306
        },
        "gemini-2.5-flash": {
            "rating": 1422.3006764726706,
            "rating_q975": 1428.27510888213,
            "rating_q025": 1416.326244063211
        },
        "grok-4-fast-reasoning": {
            "rating": 1419.6468126126786,
            "rating_q975": 1429.2111064313356,
            "rating_q025": 1410.0825187940216
        },
        "deepseek-v3.1-thinking": {
            "rating": 1418.6411253292802,
            "rating_q975": 1432.1771229036901,
            "rating_q025": 1405.1051277548702
        },
        "hunyuan-vision-1.5-thinking": {
            "rating": 1416.8325517532348,
            "rating_q975": 1444.4178669109688,
            "rating_q025": 1389.247236595501
        },
        "qwen3-30b-a3b-instruct-2507": {
            "rating": 1416.7823498621358,
            "rating_q975": 1425.688950301308,
            "rating_q025": 1407.8757494229635
        },
        "deepseek-v3.1": {
            "rating": 1415.2294598770318,
            "rating_q975": 1426.760331800524,
            "rating_q025": 1403.6985879535396
        },
        "claude-sonnet-4-20250514-thinking-32k": {
            "rating": 1411.5054076595316,
            "rating_q975": 1419.4670103065207,
            "rating_q025": 1403.5438050125424
        },
        "chatgpt-4o-latest-20250326": {
            "rating": 1410.9987668668805,
            "rating_q975": 1417.043481627338,
            "rating_q025": 1404.954052106423
        },
        "qwen3-coder-480b-a35b-instruct": {
            "rating": 1410.6935938394024,
            "rating_q975": 1419.900385184956,
            "rating_q025": 1401.486802493849
        },
        "grok-4-1-fast-reasoning": {
            "rating": 1410.5893034042688,
            "rating_q975": 1424.4065148393086,
            "rating_q025": 1396.772091969229
        },
        "o3-2025-04-16": {
            "rating": 1408.3078936897332,
            "rating_q975": 1414.5776928558464,
            "rating_q025": 1402.03809452362
        },
        "gpt-5-mini-high": {
            "rating": 1407.5236532716845,
            "rating_q975": 1415.9586410155564,
            "rating_q025": 1399.0886655278125
        },
        "grok-4-0709": {
            "rating": 1407.4112737091393,
            "rating_q975": 1414.4187141287841,
            "rating_q025": 1400.4038332894945
        },
        "amazon-nova-experimental-chat-10-20": {
            "rating": 1407.0280889724022,
            "rating_q975": 1421.4448751372229,
            "rating_q025": 1392.6113028075815
        },
        "deepseek-v3.1-terminus": {
            "rating": 1406.599489858469,
            "rating_q975": 1427.5103583068114,
            "rating_q025": 1385.6886214101266
        },
        "claude-opus-4-20250514": {
            "rating": 1400.909992770625,
            "rating_q975": 1408.2311249883244,
            "rating_q025": 1393.5888605529256
        },
        "kimi-k2-0905-preview": {
            "rating": 1400.0252347175126,
            "rating_q975": 1412.567126419436,
            "rating_q025": 1387.4833430155893
        },
        "nova-2-lite": {
            "rating": 1399.8166170990182,
            "rating_q975": 1416.5926410982602,
            "rating_q025": 1383.0405930997763
        },
        "gemini-2.5-flash-preview-09-2025": {
            "rating": 1398.0742121630415,
            "rating_q975": 1406.2294650269637,
            "rating_q025": 1389.9189592991193
        },
        "qwen3-235b-a22b-no-thinking": {
            "rating": 1397.0692882141477,
            "rating_q975": 1404.640839380142,
            "rating_q025": 1389.4977370481533
        },
        "gpt-5-chat": {
            "rating": 1397.0328196452351,
            "rating_q975": 1405.0504413509218,
            "rating_q025": 1389.0151979395484
        },
        "glm-4.5-air": {
            "rating": 1396.8764343610271,
            "rating_q975": 1404.707236851671,
            "rating_q025": 1389.0456318703832
        },
        "gpt-4.5-preview-2025-02-27": {
            "rating": 1395.9569325717723,
            "rating_q975": 1408.8589973759067,
            "rating_q025": 1383.054867767638
        },
        "mai-1-preview": {
            "rating": 1395.7305189639928,
            "rating_q975": 1406.793272837654,
            "rating_q025": 1384.6677650903316
        },
        "qwen3-next-80b-a3b-thinking": {
            "rating": 1394.0987269980499,
            "rating_q975": 1405.6381874279955,
            "rating_q025": 1382.5592665681042
        },
        "ling-flash-2.0": {
            "rating": 1391.6320261681576,
            "rating_q975": 1406.2664718241472,
            "rating_q025": 1376.997580512168
        },
        "gpt-4.1-2025-04-14": {
            "rating": 1389.4067326658023,
            "rating_q975": 1396.096255220189,
            "rating_q025": 1382.7172101114156
        },
        "hunyuan-t1-20250711": {
            "rating": 1385.5502675748996,
            "rating_q975": 1405.4029042427917,
            "rating_q025": 1365.6976309070076
        },
        "qwen3-235b-a22b": {
            "rating": 1384.737372465757,
            "rating_q975": 1393.7455715516396,
            "rating_q025": 1375.7291733798745
        },
        "mistral-medium-2505": {
            "rating": 1384.1646560959289,
            "rating_q975": 1392.200633636476,
            "rating_q025": 1376.1286785553818
        },
        "intellect-3": {
            "rating": 1383.0269239380602,
            "rating_q975": 1413.302476655347,
            "rating_q025": 1352.7513712207735
        },
        "gpt-oss-120b": {
            "rating": 1379.7890073399637,
            "rating_q975": 1387.6254496634385,
            "rating_q025": 1371.952565016489
        },
        "claude-sonnet-4-20250514": {
            "rating": 1379.4741772499644,
            "rating_q975": 1386.9268770472404,
            "rating_q025": 1372.0214774526885
        },
        "kimi-k2-0711-preview": {
            "rating": 1378.704628461754,
            "rating_q975": 1387.2108443922727,
            "rating_q025": 1370.1984125312354
        },
        "o3-mini-high": {
            "rating": 1377.2852070041306,
            "rating_q975": 1388.812398811725,
            "rating_q025": 1365.7580151965362
        },
        "gemini-2.5-flash-lite-preview-06-17-thinking": {
            "rating": 1374.5849762562302,
            "rating_q975": 1382.503437768143,
            "rating_q025": 1366.6665147443175
        },
        "grok-3-mini-high": {
            "rating": 1373.45165611289,
            "rating_q975": 1383.6393347262936,
            "rating_q025": 1363.2639774994866
        },
        "amazon-nova-experimental-chat-10-09": {
            "rating": 1373.0085330744619,
            "rating_q975": 1386.0675186720955,
            "rating_q025": 1359.9495474768282
        },
        "deepseek-r1": {
            "rating": 1371.4501107366625,
            "rating_q975": 1383.0974153234768,
            "rating_q025": 1359.8028061498483
        },
        "minimax-m2": {
            "rating": 1368.9864347364921,
            "rating_q975": 1383.7401236208061,
            "rating_q025": 1354.2327458521781
        },
        "gpt-4.1-mini-2025-04-14": {
            "rating": 1368.5640682260873,
            "rating_q975": 1376.0620980369306,
            "rating_q025": 1361.066038415244
        },
        "o4-mini-2025-04-16": {
            "rating": 1367.807196294391,
            "rating_q975": 1374.7340630587053,
            "rating_q025": 1360.8803295300766
        },
        "gemini-2.5-flash-lite-preview-09-2025-no-thinking": {
            "rating": 1367.7864631727496,
            "rating_q975": 1375.996239878343,
            "rating_q025": 1359.5766864671562
        },
        "ring-flash-2.0": {
            "rating": 1367.3850787330741,
            "rating_q975": 1382.1285712572776,
            "rating_q025": 1352.6415862088706
        },
        "deepseek-v3-0324": {
            "rating": 1367.0555424505421,
            "rating_q975": 1373.8918795881398,
            "rating_q025": 1360.2192053129445
        },
        "o1-2024-12-17": {
            "rating": 1366.0190570699751,
            "rating_q975": 1375.4288444324636,
            "rating_q025": 1356.6092697074866
        },
        "o1-preview": {
            "rating": 1365.6112044446004,
            "rating_q975": 1374.785821074518,
            "rating_q025": 1356.4365878146828
        },
        "grok-3-mini-beta": {
            "rating": 1364.715760069562,
            "rating_q975": 1373.7732111805537,
            "rating_q025": 1355.6583089585704
        },
        "mistral-small-2506": {
            "rating": 1363.4951392892694,
            "rating_q975": 1373.5893971934734,
            "rating_q025": 1353.4008813850655
        },
        "step-3": {
            "rating": 1362.5514449102448,
            "rating_q975": 1379.0995083436003,
            "rating_q025": 1346.0033814768892
        },
        "claude-3-7-sonnet-20250219-thinking-32k": {
            "rating": 1361.6405940688517,
            "rating_q975": 1369.573405558308,
            "rating_q025": 1353.7077825793954
        },
        "o1-mini": {
            "rating": 1361.3877333885873,
            "rating_q975": 1368.5353397136457,
            "rating_q025": 1354.240127063529
        },
        "o3-mini": {
            "rating": 1361.3306214642694,
            "rating_q975": 1367.7113859436417,
            "rating_q025": 1354.949856984897
        },
        "hunyuan-turbos-20250416": {
            "rating": 1361.3117154823933,
            "rating_q975": 1374.874627746105,
            "rating_q025": 1347.7488032186816
        },
        "minimax-m1": {
            "rating": 1360.6353639928136,
            "rating_q975": 1368.280289839668,
            "rating_q025": 1352.9904381459592
        },
        "qwen2.5-max": {
            "rating": 1357.830703826349,
            "rating_q975": 1365.8385346953394,
            "rating_q025": 1349.8228729573586
        },
        "qwen3-32b": {
            "rating": 1356.9697260368375,
            "rating_q975": 1381.5955633614535,
            "rating_q025": 1332.3438887122215
        },
        "gpt-5-nano-high": {
            "rating": 1350.5880365432708,
            "rating_q975": 1365.2557462898405,
            "rating_q025": 1335.9203267967011
        },
        "gemini-2.0-flash-001": {
            "rating": 1349.3434429967926,
            "rating_q975": 1356.4495297686485,
            "rating_q025": 1342.2373562249368
        },
        "glm-4.5v": {
            "rating": 1349.1429074312268,
            "rating_q975": 1367.786085828406,
            "rating_q025": 1330.4997290340477
        },
        "nvidia-llama-3.3-nemotron-super-49b-v1.5": {
            "rating": 1347.8574715223706,
            "rating_q975": 1369.6595875589533,
            "rating_q025": 1326.055355485788
        },
        "step-1o-turbo-202506": {
            "rating": 1342.1324743491593,
            "rating_q975": 1356.6860377536907,
            "rating_q025": 1327.578910944628
        },
        "hunyuan-turbos-20250226": {
            "rating": 1341.8239076722505,
            "rating_q975": 1373.0927229952551,
            "rating_q025": 1310.5550923492458
        },
        "claude-3-5-sonnet-20241022": {
            "rating": 1341.2425628251508,
            "rating_q975": 1346.4328099289116,
            "rating_q025": 1336.05231572139
        },
        "claude-3-7-sonnet-20250219": {
            "rating": 1338.92971079554,
            "rating_q975": 1346.3152024846302,
            "rating_q025": 1331.5442191064496
        },
        "qwen3-30b-a3b": {
            "rating": 1336.0966427981189,
            "rating_q975": 1344.9087755511018,
            "rating_q025": 1327.284510045136
        },
        "qwq-32b": {
            "rating": 1334.5209833132346,
            "rating_q975": 1343.493865717718,
            "rating_q025": 1325.5481009087512
        },
        "command-a-03-2025": {
            "rating": 1329.7838633234423,
            "rating_q975": 1336.0696280253867,
            "rating_q025": 1323.498098621498
        },
        "qwen-plus-0125": {
            "rating": 1327.2429444041247,
            "rating_q975": 1345.5454890830242,
            "rating_q025": 1308.9403997252252
        },
        "deepseek-v3": {
            "rating": 1324.683170982724,
            "rating_q975": 1334.604666826848,
            "rating_q025": 1314.7616751386001
        },
        "mercury": {
            "rating": 1323.4603402962177,
            "rating_q975": 1352.07407077479,
            "rating_q025": 1294.8466098176455
        },
        "gemma-3-27b-it": {
            "rating": 1323.2138391806973,
            "rating_q975": 1330.0293615646633,
            "rating_q025": 1316.3983167967313
        },
        "gemini-2.0-flash-lite-preview-02-05": {
            "rating": 1321.4401236406925,
            "rating_q975": 1331.042689289867,
            "rating_q025": 1311.837557991518
        },
        "magistral-medium-2506": {
            "rating": 1320.4009445205238,
            "rating_q975": 1332.7617993247684,
            "rating_q025": 1308.0400897162792
        },
        "olmo-3-32b-think": {
            "rating": 1319.4060019395677,
            "rating_q975": 1343.796182956159,
            "rating_q025": 1295.0158209229762
        },
        "hunyuan-turbo-0110": {
            "rating": 1318.1835611034721,
            "rating_q975": 1348.1787263531637,
            "rating_q025": 1288.1883958537805
        },
        "step-2-16k-exp-202412": {
            "rating": 1314.7855536467448,
            "rating_q975": 1334.5173736577635,
            "rating_q025": 1295.053733635726
        },
        "qwen2.5-plus-1127": {
            "rating": 1313.7691088848333,
            "rating_q975": 1327.5534365036,
            "rating_q025": 1299.9847812660664
        },
        "llama-3.1-nemotron-ultra-253b-v1": {
            "rating": 1311.6749141391574,
            "rating_q975": 1341.9644093740574,
            "rating_q025": 1281.3854189042574
        },
        "yi-lightning": {
            "rating": 1311.6289826512261,
            "rating_q975": 1321.1248591754438,
            "rating_q025": 1302.1331061270084
        },
        "athene-v2-chat": {
            "rating": 1311.148251378169,
            "rating_q975": 1320.0441141064664,
            "rating_q025": 1302.2523886498718
        },
        "gpt-oss-20b": {
            "rating": 1310.9187525102925,
            "rating_q975": 1324.1476731888124,
            "rating_q025": 1297.6898318317726
        },
        "hunyuan-large-vision": {
            "rating": 1309.353815684779,
            "rating_q975": 1328.3006097483037,
            "rating_q025": 1290.4070216212542
        },
        "deepseek-v2.5-1210": {
            "rating": 1309.0744109541533,
            "rating_q975": 1325.8286747439363,
            "rating_q025": 1292.3201471643704
        },
        "mistral-small-3.1-24b-instruct-2503": {
            "rating": 1308.48712556998,
            "rating_q975": 1316.4411969178307,
            "rating_q025": 1300.5330542221293
        },
        "hunyuan-large-2025-02-10": {
            "rating": 1305.9793058691416,
            "rating_q975": 1330.5730331548418,
            "rating_q025": 1281.3855785834414
        },
        "gpt-4.1-nano-2025-04-14": {
            "rating": 1305.9637700383919,
            "rating_q975": 1325.4359273365947,
            "rating_q025": 1286.491612740189
        },
        "claude-3-5-sonnet-20240620": {
            "rating": 1305.5743659735147,
            "rating_q975": 1312.4050979834415,
            "rating_q025": 1298.7436339635879
        },
        "llama-4-maverick-17b-128e-instruct": {
            "rating": 1303.1796138954005,
            "rating_q975": 1310.677348366448,
            "rating_q025": 1295.681879424353
        },
        "deepseek-v2.5": {
            "rating": 1300.4505174551332,
            "rating_q975": 1309.6302704121842,
            "rating_q025": 1291.2707644980821
        },
        "gpt-4o-2024-05-13": {
            "rating": 1296.4131977861266,
            "rating_q975": 1302.634592619679,
            "rating_q025": 1290.191802952574
        },
        "llama-3.3-nemotron-49b-super-v1": {
            "rating": 1296.1112682258574,
            "rating_q975": 1327.6279687204633,
            "rating_q025": 1264.5945677312516
        },
        "gemini-1.5-pro-002": {
            "rating": 1293.6355181059562,
            "rating_q975": 1300.2122752064463,
            "rating_q025": 1287.058761005466
        },
        "qwen2.5-72b-instruct": {
            "rating": 1291.9117702060573,
            "rating_q975": 1299.3275068927535,
            "rating_q025": 1284.4960335193612
        },
        "llama-3.1-405b-instruct-bf16": {
            "rating": 1290.986136806619,
            "rating_q975": 1298.2378128183473,
            "rating_q025": 1283.7344607948908
        },
        "glm-4-plus": {
            "rating": 1289.8958026065775,
            "rating_q975": 1299.0603097848918,
            "rating_q025": 1280.7312954282631
        },
        "gpt-4o-mini-2024-07-18": {
            "rating": 1289.137899639909,
            "rating_q975": 1295.3956477356978,
            "rating_q025": 1282.88015154412
        },
        "qwen-max-0919": {
            "rating": 1287.4675391650312,
            "rating_q975": 1298.507960960468,
            "rating_q025": 1276.4271173695945
        },
        "grok-2-2024-08-13": {
            "rating": 1286.99886930821,
            "rating_q975": 1293.6783373324736,
            "rating_q025": 1280.3194012839465
        },
        "llama-4-scout-17b-16e-instruct": {
            "rating": 1286.6438214775444,
            "rating_q975": 1295.2251210264149,
            "rating_q025": 1278.062521928674
        },
        "claude-3-5-haiku-20241022": {
            "rating": 1285.9160459353757,
            "rating_q975": 1291.7444637231422,
            "rating_q025": 1280.0876281476092
        },
        "glm-4-plus-0111": {
            "rating": 1285.6749672169963,
            "rating_q975": 1303.74713866211,
            "rating_q025": 1267.6027957718825
        },
        "llama-3.1-405b-instruct-fp8": {
            "rating": 1283.3433779974137,
            "rating_q975": 1290.2442165958962,
            "rating_q025": 1276.442539398931
        },
        "gpt-4o-2024-08-06": {
            "rating": 1283.1136458080332,
            "rating_q975": 1290.815438968355,
            "rating_q025": 1275.4118526477114
        },
        "gemma-3-12b-it": {
            "rating": 1281.888490707084,
            "rating_q975": 1305.0001119338144,
            "rating_q025": 1258.7768694803535
        },
        "qwen2.5-coder-32b-instruct": {
            "rating": 1275.902767577304,
            "rating_q975": 1294.183553837659,
            "rating_q025": 1257.6219813169491
        },
        "mistral-large-2407": {
            "rating": 1275.5709193934058,
            "rating_q975": 1283.2122826736822,
            "rating_q025": 1267.9295561131294
        },
        "mistral-large-2411": {
            "rating": 1274.8458724938707,
            "rating_q975": 1283.4741932471832,
            "rating_q025": 1266.2175517405583
        },
        "gemma-3n-e4b-it": {
            "rating": 1272.3226377030694,
            "rating_q975": 1282.4466814299224,
            "rating_q025": 1262.1985939762164
        },
        "llama-3.1-nemotron-70b-instruct": {
            "rating": 1271.0332364303513,
            "rating_q975": 1286.2836549297758,
            "rating_q025": 1255.7828179309267
        },
        "amazon-nova-pro-v1.0": {
            "rating": 1269.235702057429,
            "rating_q975": 1278.1102243193786,
            "rating_q025": 1260.3611797954795
        },
        "hunyuan-standard-2025-02-10": {
            "rating": 1268.2591411262638,
            "rating_q975": 1292.1156241704216,
            "rating_q025": 1244.402658082106
        },
        "llama-3.3-70b-instruct": {
            "rating": 1268.2027556178364,
            "rating_q975": 1274.5286144292154,
            "rating_q025": 1261.8768968064574
        },
        "grok-2-mini-2024-08-13": {
            "rating": 1267.701443048385,
            "rating_q975": 1274.6569675205815,
            "rating_q025": 1260.7459185761886
        },
        "gpt-4-turbo-2024-04-09": {
            "rating": 1267.6030219751442,
            "rating_q975": 1274.568004145077,
            "rating_q025": 1260.6380398052113
        },
        "athene-70b-0725": {
            "rating": 1265.8816109907712,
            "rating_q975": 1276.5883355088981,
            "rating_q025": 1255.1748864726442
        },
        "gemini-1.5-pro-001": {
            "rating": 1265.6087585364644,
            "rating_q975": 1272.944360712108,
            "rating_q025": 1258.2731563608208
        },
        "claude-3-opus-20240229": {
            "rating": 1263.1668319802507,
            "rating_q975": 1268.800724726829,
            "rating_q025": 1257.5329392336723
        },
        "gemini-1.5-flash-002": {
            "rating": 1260.7066964784294,
            "rating_q975": 1268.512078571079,
            "rating_q025": 1252.9013143857799
        },
        "llama-3.1-70b-instruct": {
            "rating": 1259.1758817675282,
            "rating_q975": 1266.0808453803588,
            "rating_q025": 1252.2709181546975
        },
        "gemini-advanced-0514": {
            "rating": 1254.578438891739,
            "rating_q975": 1263.4208743049803,
            "rating_q025": 1245.7360034784979
        },
        "gpt-4-1106-preview": {
            "rating": 1253.607524138301,
            "rating_q975": 1260.8703117267519,
            "rating_q025": 1246.34473654985
        },
        "deepseek-coder-v2": {
            "rating": 1250.1335870523974,
            "rating_q975": 1261.9868680706707,
            "rating_q025": 1238.2803060341241
        },
        "gpt-4-0125-preview": {
            "rating": 1248.2496398559038,
            "rating_q975": 1255.7014246335705,
            "rating_q025": 1240.797855078237
        },
        "mistral-small-24b-instruct-2501": {
            "rating": 1245.7803640778443,
            "rating_q975": 1258.1678634632433,
            "rating_q025": 1233.3928646924453
        },
        "amazon-nova-lite-v1.0": {
            "rating": 1238.2101851426523,
            "rating_q975": 1248.267955303492,
            "rating_q025": 1228.1524149818126
        },
        "llama-3.1-tulu-3-70b": {
            "rating": 1234.9719349962072,
            "rating_q975": 1258.9817599804512,
            "rating_q025": 1210.9621100119632
        },
        "gemini-1.5-flash-001": {
            "rating": 1234.9369232493386,
            "rating_q975": 1242.4126664378482,
            "rating_q025": 1227.461180060829
        },
        "phi-4": {
            "rating": 1230.843624823994,
            "rating_q975": 1240.5643214142713,
            "rating_q025": 1221.122928233717
        },
        "gemma-3-4b-it": {
            "rating": 1230.5709157125002,
            "rating_q975": 1254.2605989209653,
            "rating_q025": 1206.881232504035
        },
        "hunyuan-standard-256k": {
            "rating": 1229.373782377455,
            "rating_q975": 1254.0295632507934,
            "rating_q025": 1204.7180015041165
        },
        "reka-core-20240904": {
            "rating": 1229.2376766478706,
            "rating_q975": 1244.6585988253905,
            "rating_q025": 1213.8167544703506
        },
        "jamba-1.5-large": {
            "rating": 1227.030917914592,
            "rating_q975": 1241.426582791883,
            "rating_q025": 1212.635253037301
        },
        "glm-4-0520": {
            "rating": 1226.6022096896613,
            "rating_q975": 1240.499053075639,
            "rating_q025": 1212.7053663036836
        },
        "llama-3.1-nemotron-51b-instruct": {
            "rating": 1222.2233164402573,
            "rating_q975": 1243.6700192210296,
            "rating_q025": 1200.776613659485
        },
        "claude-3-sonnet-20240229": {
            "rating": 1221.8798188270098,
            "rating_q975": 1229.115968246766,
            "rating_q025": 1214.6436694072536
        },
        "amazon-nova-micro-v1.0": {
            "rating": 1216.8934639018125,
            "rating_q975": 1227.0499620643366,
            "rating_q025": 1206.7369657392885
        },
        "gemini-1.5-flash-8b-001": {
            "rating": 1216.819419972192,
            "rating_q975": 1224.6707147689658,
            "rating_q025": 1208.9681251754182
        },
        "gemma-2-27b-it": {
            "rating": 1210.3877502237924,
            "rating_q975": 1216.50300162652,
            "rating_q025": 1204.2724988210648
        },
        "olmo-2-0325-32b-instruct": {
            "rating": 1209.7403930259336,
            "rating_q975": 1237.5208858752142,
            "rating_q025": 1181.959900176653
        },
        "nemotron-4-340b-instruct": {
            "rating": 1208.0843420449949,
            "rating_q975": 1219.3015540389363,
            "rating_q025": 1196.8671300510534
        },
        "gpt-4-0314": {
            "rating": 1207.6021057979547,
            "rating_q975": 1216.9316981969957,
            "rating_q025": 1198.2725133989136
        },
        "llama-3-70b-instruct": {
            "rating": 1205.9274417686993,
            "rating_q975": 1212.756460764839,
            "rating_q025": 1199.0984227725596
        },
        "ministral-8b-2410": {
            "rating": 1200.9604300014894,
            "rating_q975": 1219.6262933852056,
            "rating_q025": 1182.2945666177732
        },
        "claude-3-haiku-20240307": {
            "rating": 1198.4036820807896,
            "rating_q975": 1205.1180636167724,
            "rating_q025": 1191.6893005448069
        },
        "c4ai-aya-expanse-32b": {
            "rating": 1195.8972183021128,
            "rating_q975": 1204.8238496183596,
            "rating_q025": 1186.970586985866
        },
        "qwen2-72b-instruct": {
            "rating": 1194.8359545703638,
            "rating_q975": 1203.652337760892,
            "rating_q025": 1186.0195713798357
        },
        "llama-3.1-8b-instruct": {
            "rating": 1194.523976621822,
            "rating_q975": 1201.7634060291257,
            "rating_q025": 1187.2845472145182
        },
        "gemma-2-9b-it-simpo": {
            "rating": 1191.1331868860448,
            "rating_q975": 1205.896284577009,
            "rating_q025": 1176.3700891950805
        },
        "reka-flash-20240904": {
            "rating": 1189.8666414699298,
            "rating_q975": 1205.0776095765752,
            "rating_q025": 1174.6556733632844
        },
        "command-r-plus-08-2024": {
            "rating": 1186.6970187664492,
            "rating_q975": 1200.4136632097814,
            "rating_q025": 1172.980374323117
        },
        "granite-3.1-8b-instruct": {
            "rating": 1186.6550352594284,
            "rating_q975": 1212.2379362661036,
            "rating_q025": 1161.0721342527531
        },
        "gpt-4-0613": {
            "rating": 1186.4455887308013,
            "rating_q975": 1194.356078844992,
            "rating_q025": 1178.5350986166106
        },
        "qwen1.5-110b-chat": {
            "rating": 1183.132989260714,
            "rating_q975": 1193.3377243687878,
            "rating_q025": 1172.9282541526404
        },
        "llama-3.1-tulu-3-8b": {
            "rating": 1182.8240149018088,
            "rating_q975": 1207.452387388164,
            "rating_q025": 1158.1956424154537
        },
        "mistral-large-2402": {
            "rating": 1182.3032237978746,
            "rating_q975": 1190.7277359982083,
            "rating_q025": 1173.8787115975408
        },
        "jamba-1.5-mini": {
            "rating": 1177.607843102995,
            "rating_q975": 1192.823224437683,
            "rating_q025": 1162.3924617683072
        },
        "gemma-2-9b-it": {
            "rating": 1172.711769140709,
            "rating_q975": 1179.7029443765732,
            "rating_q025": 1165.720593904845
        },
        "command-r-plus": {
            "rating": 1171.3308457087348,
            "rating_q975": 1178.9297418711647,
            "rating_q025": 1163.731949546305
        },
        "command-r-08-2024": {
            "rating": 1168.692340855818,
            "rating_q975": 1182.00968605357,
            "rating_q025": 1155.374995658066
        },
        "yi-1.5-34b-chat": {
            "rating": 1168.2640691254674,
            "rating_q975": 1178.630025716211,
            "rating_q025": 1157.8981125347236
        },
        "mixtral-8x22b-instruct-v0.1": {
            "rating": 1164.975583250433,
            "rating_q975": 1173.447255563093,
            "rating_q025": 1156.5039109377728
        },
        "qwen1.5-72b-chat": {
            "rating": 1164.3511982476543,
            "rating_q975": 1173.89122658933,
            "rating_q025": 1154.8111699059787
        },
        "reka-flash-21b-20240226-online": {
            "rating": 1164.1340652744734,
            "rating_q975": 1176.8259924309673,
            "rating_q025": 1151.4421381179795
        },
        "mistral-medium": {
            "rating": 1161.1052196815908,
            "rating_q975": 1171.486542621007,
            "rating_q025": 1150.7238967421747
        },
        "c4ai-aya-expanse-8b": {
            "rating": 1160.4684544203537,
            "rating_q975": 1174.8598707497779,
            "rating_q025": 1146.0770380909296
        },
        "internlm2_5-20b-chat": {
            "rating": 1159.5826254207896,
            "rating_q975": 1173.6163789379552,
            "rating_q025": 1145.5488719036239
        },
        "qwq-32b-preview": {
            "rating": 1155.3041924525683,
            "rating_q975": 1179.4742083975154,
            "rating_q025": 1131.134176507621
        },
        "qwen1.5-32b-chat": {
            "rating": 1153.6790345559912,
            "rating_q975": 1164.5485013182406,
            "rating_q025": 1142.8095677937417
        },
        "reka-flash-21b-20240226": {
            "rating": 1152.7927887318592,
            "rating_q975": 1163.378981562211,
            "rating_q025": 1142.2065959015074
        },
        "llama-3-8b-instruct": {
            "rating": 1151.176691894757,
            "rating_q975": 1158.612305138808,
            "rating_q025": 1143.7410786507057
        },
        "granite-3.1-2b-instruct": {
            "rating": 1150.8979745622219,
            "rating_q975": 1175.430132291355,
            "rating_q025": 1126.3658168330887
        },
        "starling-lm-7b-beta": {
            "rating": 1142.1933087898626,
            "rating_q975": 1154.8943611164054,
            "rating_q025": 1129.4922564633198
        },
        "qwen1.5-14b-chat": {
            "rating": 1137.0840379008991,
            "rating_q975": 1149.8608457796415,
            "rating_q025": 1124.3072300221568
        },
        "gpt-3.5-turbo-0125": {
            "rating": 1135.7442329767064,
            "rating_q975": 1143.7699344399848,
            "rating_q025": 1127.718531513428
        },
        "dbrx-instruct-preview": {
            "rating": 1131.2659815592856,
            "rating_q975": 1142.1175566657878,
            "rating_q025": 1120.4144064527834
        },
        "phi-3-medium-4k-instruct": {
            "rating": 1129.6122607039556,
            "rating_q975": 1139.721332346849,
            "rating_q025": 1119.5031890610621
        },
        "zephyr-orpo-141b-A35b-v0.1": {
            "rating": 1128.6183948260805,
            "rating_q975": 1149.2665805676454,
            "rating_q025": 1107.9702090845155
        },
        "command-r": {
            "rating": 1127.2623986633773,
            "rating_q975": 1135.8472676110378,
            "rating_q025": 1118.677529715717
        },
        "mixtral-8x7b-instruct-v0.1": {
            "rating": 1125.8866669312556,
            "rating_q975": 1133.906337052448,
            "rating_q025": 1117.8669968100633
        },
        "tulu-2-dpo-70b": {
            "rating": 1115.2166855881464,
            "rating_q975": 1136.5169414482384,
            "rating_q025": 1093.9164297280545
        },
        "gpt-3.5-turbo-1106": {
            "rating": 1114.8847195389487,
            "rating_q975": 1130.6192737966028,
            "rating_q025": 1099.1501652812947
        },
        "gemma-2-2b-it": {
            "rating": 1112.1546426061072,
            "rating_q975": 1119.8650687287272,
            "rating_q025": 1104.4442164834873
        },
        "openchat-3.5-0106": {
            "rating": 1112.0006167412412,
            "rating_q975": 1125.9921439901675,
            "rating_q025": 1098.0090894923148
        },
        "granite-3.0-8b-instruct": {
            "rating": 1111.4101638487384,
            "rating_q975": 1129.3618176420846,
            "rating_q025": 1093.4585100553923
        },
        "yi-34b-chat": {
            "rating": 1110.836735586422,
            "rating_q975": 1123.8567375137045,
            "rating_q025": 1097.8167336591396
        },
        "gemini-pro": {
            "rating": 1106.9776782138179,
            "rating_q975": 1130.5392544008303,
            "rating_q025": 1083.4161020268054
        },
        "qwen1.5-7b-chat": {
            "rating": 1106.6433208025815,
            "rating_q975": 1127.2049531996674,
            "rating_q025": 1086.0816884054955
        },
        "gemini-pro-dev-api": {
            "rating": 1103.514512105261,
            "rating_q975": 1117.3445987893979,
            "rating_q025": 1089.6844254211242
        },
        "phi-3-small-8k-instruct": {
            "rating": 1100.9132346412493,
            "rating_q975": 1112.402009269015,
            "rating_q025": 1089.4244600134837
        },
        "starling-lm-7b-alpha": {
            "rating": 1096.8853507867047,
            "rating_q975": 1113.2395863780037,
            "rating_q025": 1080.5311151954058
        },
        "llama-3.2-3b-instruct": {
            "rating": 1096.8565569869984,
            "rating_q975": 1112.7224940538972,
            "rating_q025": 1080.9906199200996
        },
        "deepseek-llm-67b-chat": {
            "rating": 1095.0878189322884,
            "rating_q975": 1119.0398511741203,
            "rating_q025": 1071.1357866904566
        },
        "phi-3-mini-4k-instruct-june-2024": {
            "rating": 1093.4172989062135,
            "rating_q975": 1107.0988922110616,
            "rating_q025": 1079.7357056013655
        },
        "phi-3-mini-4k-instruct": {
            "rating": 1092.476781631336,
            "rating_q975": 1104.091224748961,
            "rating_q025": 1080.8623385137112
        },
        "granite-3.0-2b-instruct": {
            "rating": 1089.5232136057882,
            "rating_q975": 1106.8897680499936,
            "rating_q025": 1072.1566591615829
        },
        "snowflake-arctic-instruct": {
            "rating": 1088.898509674691,
            "rating_q975": 1100.0702604063626,
            "rating_q025": 1077.7267589430194
        },
        "gemma-1.1-7b-it": {
            "rating": 1083.168966467214,
            "rating_q975": 1093.432484642716,
            "rating_q025": 1072.905448291712
        },
        "mistral-7b-instruct-v0.2": {
            "rating": 1081.2757198573386,
            "rating_q975": 1092.930254194535,
            "rating_q025": 1069.621185520142
        },
        "wizardlm-70b": {
            "rating": 1078.9582735332267,
            "rating_q975": 1098.8274821570878,
            "rating_q025": 1059.0890649093656
        },
        "nous-hermes-2-mixtral-8x7b-dpo": {
            "rating": 1078.5762782939614,
            "rating_q975": 1102.0932174158672,
            "rating_q025": 1055.0593391720556
        },
        "llama-2-70b-chat": {
            "rating": 1077.9484990316255,
            "rating_q975": 1087.8088429279674,
            "rating_q025": 1068.0881551352836
        },
        "vicuna-33b": {
            "rating": 1077.2300558247375,
            "rating_q975": 1089.9248289548852,
            "rating_q025": 1064.5352826945898
        },
        "openchat-3.5": {
            "rating": 1073.5280730019024,
            "rating_q975": 1093.2181927350318,
            "rating_q025": 1053.837953268773
        },
        "llama-3.2-1b-instruct": {
            "rating": 1070.4352166196936,
            "rating_q975": 1086.2764985980398,
            "rating_q025": 1054.5939346413475
        },
        "qwen-14b-chat": {
            "rating": 1069.9912668131583,
            "rating_q975": 1094.1575519205364,
            "rating_q025": 1045.8249817057801
        },
        "solar-10.7b-instruct-v1.0": {
            "rating": 1066.0313051745784,
            "rating_q975": 1093.2090698378402,
            "rating_q025": 1038.8535405113166
        },
        "openhermes-2.5-mistral-7b": {
            "rating": 1063.6308169051488,
            "rating_q975": 1087.2711756451884,
            "rating_q025": 1039.9904581651092
        },
        "llama-2-13b-chat": {
            "rating": 1061.439447003705,
            "rating_q975": 1074.2897701899744,
            "rating_q025": 1048.5891238174356
        },
        "zephyr-7b-alpha": {
            "rating": 1053.7854519205694,
            "rating_q975": 1094.7323908436647,
            "rating_q025": 1012.8385129974741
        },
        "gemma-7b-it": {
            "rating": 1047.8209964782707,
            "rating_q975": 1064.3746102925477,
            "rating_q025": 1031.2673826639937
        },
        "smollm2-1.7b-instruct": {
            "rating": 1047.1698340389435,
            "rating_q975": 1080.0909267081822,
            "rating_q025": 1014.2487413697046
        },
        "codellama-34b-instruct": {
            "rating": 1044.9975754773545,
            "rating_q975": 1065.4152443778348,
            "rating_q025": 1024.5799065768742
        },
        "zephyr-7b-beta": {
            "rating": 1043.094738919427,
            "rating_q975": 1061.403052748346,
            "rating_q025": 1024.7864250905081
        },
        "vicuna-13b": {
            "rating": 1039.6988895357904,
            "rating_q975": 1053.5697039356264,
            "rating_q025": 1025.8280751359544
        },
        "phi-3-mini-128k-instruct": {
            "rating": 1039.5010497118135,
            "rating_q975": 1052.3524107858864,
            "rating_q025": 1026.6496886377406
        },
        "mpt-30b-chat": {
            "rating": 1037.346239378925,
            "rating_q975": 1073.3390375757267,
            "rating_q025": 1001.3534411821233
        },
        "wizardlm-13b": {
            "rating": 1033.4349159910907,
            "rating_q975": 1055.6828628135672,
            "rating_q025": 1011.1869691686143
        },
        "gemma-1.1-2b-it": {
            "rating": 1033.3073778225464,
            "rating_q975": 1047.2433980312974,
            "rating_q025": 1019.3713576137955
        },
        "llama2-70b-steerlm-chat": {
            "rating": 1023.9058902016593,
            "rating_q975": 1052.6235221332902,
            "rating_q025": 995.1882582700283
        },
        "mistral-7b-instruct": {
            "rating": 1018.1833810843252,
            "rating_q975": 1037.9977799132535,
            "rating_q025": 998.368982255397
        },
        "olmo-7b-instruct": {
            "rating": 1015.3329779238086,
            "rating_q975": 1037.308821001107,
            "rating_q025": 993.3571348465102
        },
        "vicuna-7b": {
            "rating": 1008.4812630175443,
            "rating_q975": 1031.401149239373,
            "rating_q025": 985.5613767957158
        },
        "gemma-2b-it": {
            "rating": 1008.2986422525314,
            "rating_q975": 1030.390765858458,
            "rating_q025": 986.2065186466048
        },
        "llama-2-7b-chat": {
            "rating": 1001.3252202017218,
            "rating_q975": 1015.4201210412741,
            "rating_q025": 987.2303193621694
        },
        "stripedhyena-nous-7b": {
            "rating": 998.6493144000028,
            "rating_q975": 1021.078620154415,
            "rating_q025": 976.2200086455906
        },
        "qwen1.5-4b-chat": {
            "rating": 997.0609143244603,
            "rating_q975": 1014.4225842500958,
            "rating_q025": 979.6992443988248
        },
        "guanaco-33b": {
            "rating": 995.065431798884,
            "rating_q975": 1030.9936773199645,
            "rating_q025": 959.1371862778036
        },
        "palm-2": {
            "rating": 993.1366683256251,
            "rating_q975": 1014.2246359956299,
            "rating_q025": 972.0487006556203
        },
        "chatglm3-6b": {
            "rating": 962.4463701321635,
            "rating_q975": 989.1794848441874,
            "rating_q025": 935.7132554201395
        },
        "koala-13b": {
            "rating": 943.0352487499125,
            "rating_q975": 967.5826233008725,
            "rating_q025": 918.4878741989526
        },
        "RWKV-4-Raven-14B": {
            "rating": 926.0371670337377,
            "rating_q975": 953.6853482391411,
            "rating_q025": 898.3889858283342
        },
        "chatglm-6b": {
            "rating": 917.2817675675074,
            "rating_q975": 944.5954245242925,
            "rating_q025": 889.9681106107222
        },
        "mpt-7b-chat": {
            "rating": 911.6898002452497,
            "rating_q975": 944.0185050185173,
            "rating_q025": 879.361095471982
        },
        "chatglm2-6b": {
            "rating": 900.7053383168833,
            "rating_q975": 936.471375993696,
            "rating_q025": 864.9393006400705
        },
        "oasst-pythia-12b": {
            "rating": 898.7436842040215,
            "rating_q975": 924.3748619011925,
            "rating_q025": 873.1125065068505
        },
        "stablelm-tuned-alpha-7b": {
            "rating": 884.1773701057982,
            "rating_q975": 917.8223424194848,
            "rating_q025": 850.5323977921116
        },
        "alpaca-13b": {
            "rating": 796.9203372361106,
            "rating_q975": 824.9036857906315,
            "rating_q025": 768.9369886815898
        },
        "dolly-v2-12b": {
            "rating": 774.8988460225859,
            "rating_q975": 809.1498643310397,
            "rating_q025": 740.6478277141321
        },
        "fastchat-t5-3b": {
            "rating": 762.2611368155837,
            "rating_q975": 793.3568207807837,
            "rating_q025": 731.1654528503836
        },
        "llama-13b": {
            "rating": 679.4992209788337,
            "rating_q975": 720.0901407291318,
            "rating_q025": 638.9083012285356
        }
    },
    "creative_writing": {
        "gemini-3-pro": {
            "rating": 1491.2925136549422,
            "rating_q975": 1505.118650263685,
            "rating_q025": 1477.4663770461996
        },
        "gemini-2.5-pro": {
            "rating": 1462.9818743057708,
            "rating_q975": 1470.0219842999936,
            "rating_q025": 1455.941764311548
        },
        "claude-opus-4-5-20251101": {
            "rating": 1434.818577846634,
            "rating_q975": 1451.6332708024847,
            "rating_q025": 1418.0038848907834
        },
        "gpt-5.1-high": {
            "rating": 1433.833137446875,
            "rating_q975": 1448.4618262360598,
            "rating_q025": 1419.2044486576904
        },
        "claude-opus-4-5-20251101-thinking-32k": {
            "rating": 1430.5270795253082,
            "rating_q975": 1447.761395523898,
            "rating_q025": 1413.2927635267183
        },
        "grok-4.1-thinking": {
            "rating": 1425.659701897884,
            "rating_q975": 1439.1353165848743,
            "rating_q025": 1412.1840872108935
        },
        "ernie-5.0-preview-1103": {
            "rating": 1424.559938521689,
            "rating_q975": 1446.1086190527474,
            "rating_q025": 1403.0112579906306
        },
        "claude-sonnet-4-5-20250929": {
            "rating": 1423.8313673712894,
            "rating_q975": 1435.1420357490435,
            "rating_q025": 1412.5206989935352
        },
        "claude-sonnet-4-5-20250929-thinking-32k": {
            "rating": 1413.9656795401759,
            "rating_q975": 1424.475533584141,
            "rating_q025": 1403.4558254962108
        },
        "grok-3-preview-02-24": {
            "rating": 1413.1925857762108,
            "rating_q975": 1421.9777088970397,
            "rating_q025": 1404.4074626553818
        },
        "glm-4.6": {
            "rating": 1408.7932426778286,
            "rating_q975": 1419.7509169315883,
            "rating_q025": 1397.835568424069
        },
        "grok-4.1": {
            "rating": 1408.1555857077724,
            "rating_q975": 1421.7676393513352,
            "rating_q025": 1394.5435320642096
        },
        "deepseek-v3.2-thinking": {
            "rating": 1406.5405194642528,
            "rating_q975": 1428.085787363801,
            "rating_q025": 1384.9952515647046
        },
        "claude-opus-4-1-20250805-thinking-16k": {
            "rating": 1406.2431487220686,
            "rating_q975": 1414.835114099345,
            "rating_q025": 1397.6511833447921
        },
        "deepseek-v3.1-terminus": {
            "rating": 1405.5363409015079,
            "rating_q975": 1433.0283276974324,
            "rating_q025": 1378.0443541055834
        },
        "deepseek-r1-0528": {
            "rating": 1404.4086090825547,
            "rating_q975": 1416.4319533190637,
            "rating_q025": 1392.3852648460456
        },
        "chatgpt-4o-latest-20250326": {
            "rating": 1403.7622993953778,
            "rating_q975": 1410.7097035775766,
            "rating_q025": 1396.814895213179
        },
        "gemini-2.5-flash": {
            "rating": 1403.2821026419756,
            "rating_q975": 1410.1354929105637,
            "rating_q025": 1396.4287123733875
        },
        "claude-opus-4-1-20250805": {
            "rating": 1403.1900137272414,
            "rating_q975": 1410.9214077113625,
            "rating_q025": 1395.4586197431204
        },
        "deepseek-v3.1-thinking": {
            "rating": 1402.736689204275,
            "rating_q975": 1417.1727793858315,
            "rating_q025": 1388.3005990227186
        },
        "qwen3-max-preview": {
            "rating": 1402.3559166626173,
            "rating_q975": 1412.3846612880586,
            "rating_q025": 1392.327172037176
        },
        "gpt-5.1": {
            "rating": 1400.3109561180386,
            "rating_q975": 1414.3788890523365,
            "rating_q025": 1386.2430231837407
        },
        "deepseek-v3.2-exp": {
            "rating": 1398.1002927849468,
            "rating_q975": 1413.3895445546352,
            "rating_q025": 1382.8110410152583
        },
        "grok-4-0709": {
            "rating": 1396.2855710727122,
            "rating_q975": 1404.6561546036778,
            "rating_q025": 1387.9149875417465
        },
        "glm-4.5": {
            "rating": 1395.7480564487562,
            "rating_q975": 1406.4688306274056,
            "rating_q025": 1385.0272822701068
        },
        "hunyuan-t1-20250711": {
            "rating": 1395.1098586833666,
            "rating_q975": 1419.0128961673943,
            "rating_q025": 1371.206821199339
        },
        "mistral-medium-2508": {
            "rating": 1394.4358036013032,
            "rating_q975": 1402.7237113258318,
            "rating_q025": 1386.1478958767746
        },
        "gpt-4.5-preview-2025-02-27": {
            "rating": 1394.0625468319015,
            "rating_q975": 1405.8470077773459,
            "rating_q025": 1382.2780858864571
        },
        "deepseek-v3.2-exp-thinking": {
            "rating": 1392.3923685684772,
            "rating_q975": 1409.7185527898096,
            "rating_q025": 1375.0661843471448
        },
        "deepseek-v3.1": {
            "rating": 1392.2772393030484,
            "rating_q975": 1405.5076727276842,
            "rating_q025": 1379.0468058784127
        },
        "deepseek-v3.2": {
            "rating": 1390.884443386144,
            "rating_q975": 1412.1419705297606,
            "rating_q025": 1369.6269162425276
        },
        "mistral-large-3": {
            "rating": 1387.541497929786,
            "rating_q975": 1407.6117470872834,
            "rating_q025": 1367.4712487722884
        },
        "grok-4-1-fast-reasoning": {
            "rating": 1387.2844768181048,
            "rating_q975": 1404.716311398702,
            "rating_q025": 1369.8526422375078
        },
        "grok-4-fast-chat": {
            "rating": 1386.6223576832506,
            "rating_q975": 1405.681248516468,
            "rating_q025": 1367.5634668500331
        },
        "gemini-2.5-flash-preview-09-2025": {
            "rating": 1385.5065231584422,
            "rating_q975": 1395.518356105425,
            "rating_q025": 1375.4946902114593
        },
        "qwen3-235b-a22b-thinking-2507": {
            "rating": 1385.2026446280513,
            "rating_q975": 1402.5103917200563,
            "rating_q025": 1367.8948975360463
        },
        "kimi-k2-thinking-turbo": {
            "rating": 1384.3903739496063,
            "rating_q975": 1397.8967678863212,
            "rating_q025": 1370.8839800128915
        },
        "qwen3-max-2025-09-23": {
            "rating": 1382.9847264060647,
            "rating_q975": 1400.0489636618852,
            "rating_q025": 1365.9204891502443
        },
        "deepseek-v3.1-terminus-thinking": {
            "rating": 1382.3087987487866,
            "rating_q975": 1410.4629254337685,
            "rating_q025": 1354.1546720638046
        },
        "claude-opus-4-20250514-thinking-16k": {
            "rating": 1377.8773977838414,
            "rating_q975": 1387.066773712445,
            "rating_q025": 1368.6880218552378
        },
        "qwen3-235b-a22b-instruct-2507": {
            "rating": 1375.881991473675,
            "rating_q975": 1383.6812933676179,
            "rating_q025": 1368.0826895797322
        },
        "hunyuan-vision-1.5-thinking": {
            "rating": 1375.1889499732097,
            "rating_q975": 1412.2555825201075,
            "rating_q025": 1338.1223174263118
        },
        "claude-opus-4-20250514": {
            "rating": 1371.489843142761,
            "rating_q975": 1379.9705767231453,
            "rating_q025": 1363.0091095623766
        },
        "gpt-5-high": {
            "rating": 1370.9983513237648,
            "rating_q975": 1380.4773909796213,
            "rating_q025": 1361.5193116679084
        },
        "grok-4-fast-reasoning": {
            "rating": 1370.866247402355,
            "rating_q975": 1383.0260357848458,
            "rating_q025": 1358.706459019864
        },
        "qwen3-vl-235b-a22b-instruct": {
            "rating": 1369.89795176505,
            "rating_q975": 1387.5410460263781,
            "rating_q025": 1352.254857503722
        },
        "gpt-5-chat": {
            "rating": 1366.1888882549615,
            "rating_q975": 1375.7760383056789,
            "rating_q025": 1356.6017382042442
        },
        "deepseek-v3-0324": {
            "rating": 1365.6262951767005,
            "rating_q975": 1373.500612536911,
            "rating_q025": 1357.7519778164901
        },
        "gemini-2.5-flash-lite-preview-06-17-thinking": {
            "rating": 1364.6318466158307,
            "rating_q975": 1373.802873483876,
            "rating_q025": 1355.4608197477853
        },
        "gpt-4.1-2025-04-14": {
            "rating": 1363.6128492179732,
            "rating_q975": 1371.230067266723,
            "rating_q025": 1355.9956311692235
        },
        "hunyuan-turbos-20250416": {
            "rating": 1360.8308047430362,
            "rating_q975": 1375.703968120896,
            "rating_q025": 1345.9576413651764
        },
        "o3-2025-04-16": {
            "rating": 1360.5882856167027,
            "rating_q975": 1367.866491637887,
            "rating_q025": 1353.3100795955183
        },
        "claude-haiku-4-5-20251001": {
            "rating": 1360.5810178924664,
            "rating_q975": 1371.2356256559694,
            "rating_q025": 1349.9264101289634
        },
        "gemini-2.5-flash-lite-preview-09-2025-no-thinking": {
            "rating": 1360.3298966142795,
            "rating_q975": 1370.3393190236013,
            "rating_q025": 1350.3204742049577
        },
        "qwen3-235b-a22b-no-thinking": {
            "rating": 1357.258548770604,
            "rating_q975": 1366.176079521931,
            "rating_q025": 1348.341018019277
        },
        "mai-1-preview": {
            "rating": 1356.856844789525,
            "rating_q975": 1369.5619454232858,
            "rating_q025": 1344.1517441557642
        },
        "deepseek-r1": {
            "rating": 1354.4869624234236,
            "rating_q975": 1364.554439684729,
            "rating_q025": 1344.4194851621182
        },
        "kimi-k2-0905-preview": {
            "rating": 1349.6974494992849,
            "rating_q975": 1365.0683922538972,
            "rating_q025": 1334.3265067446725
        },
        "qwen3-vl-235b-a22b-thinking": {
            "rating": 1349.3370004009648,
            "rating_q975": 1367.8383835632078,
            "rating_q025": 1330.8356172387219
        },
        "o1-2024-12-17": {
            "rating": 1347.770344018775,
            "rating_q975": 1356.5690917772338,
            "rating_q025": 1338.9715962603161
        },
        "longcat-flash-chat": {
            "rating": 1347.1623956845192,
            "rating_q975": 1362.8747967542108,
            "rating_q025": 1331.4499946148276
        },
        "claude-sonnet-4-20250514-thinking-32k": {
            "rating": 1345.2338774020081,
            "rating_q975": 1354.5265924491887,
            "rating_q025": 1335.9411623548276
        },
        "gemma-3-27b-it": {
            "rating": 1344.618262552649,
            "rating_q975": 1352.0556222683103,
            "rating_q025": 1337.1809028369876
        },
        "glm-4.5-air": {
            "rating": 1342.7703743087025,
            "rating_q975": 1352.2259380112241,
            "rating_q025": 1333.3148106061808
        },
        "mistral-medium-2505": {
            "rating": 1341.5685609396564,
            "rating_q975": 1350.7646637729129,
            "rating_q025": 1332.3724581064
        },
        "grok-3-mini-beta": {
            "rating": 1340.8277402927772,
            "rating_q975": 1351.654064800078,
            "rating_q025": 1330.0014157854764
        },
        "gemini-2.0-flash-001": {
            "rating": 1340.2579614216352,
            "rating_q975": 1347.6852291512569,
            "rating_q025": 1332.8306936920135
        },
        "qwen2.5-max": {
            "rating": 1338.709050310422,
            "rating_q975": 1346.9769721971786,
            "rating_q025": 1330.4411284236655
        },
        "claude-sonnet-4-20250514": {
            "rating": 1337.480022930589,
            "rating_q975": 1346.220531337688,
            "rating_q025": 1328.73951452349
        },
        "qwen3-next-80b-a3b-instruct": {
            "rating": 1336.0517423540834,
            "rating_q975": 1347.078083052993,
            "rating_q025": 1325.025401655174
        },
        "gemini-1.5-pro-002": {
            "rating": 1333.7529527143483,
            "rating_q975": 1340.7781076773963,
            "rating_q025": 1326.7277977513004
        },
        "grok-3-mini-high": {
            "rating": 1333.326593482049,
            "rating_q975": 1346.149610006491,
            "rating_q025": 1320.503576957607
        },
        "qwen3-coder-480b-a35b-instruct": {
            "rating": 1332.9559040530892,
            "rating_q975": 1343.5714503973234,
            "rating_q025": 1322.340357708855
        },
        "gpt-5-mini-high": {
            "rating": 1331.3037929420689,
            "rating_q975": 1341.6263951282187,
            "rating_q025": 1320.981190755919
        },
        "claude-3-7-sonnet-20250219-thinking-32k": {
            "rating": 1330.2443140434018,
            "rating_q975": 1338.6706920065435,
            "rating_q025": 1321.81793608026
        },
        "gemma-3-12b-it": {
            "rating": 1330.0340944704335,
            "rating_q975": 1352.983363944421,
            "rating_q025": 1307.084824996446
        },
        "deepseek-v3": {
            "rating": 1329.8814921340586,
            "rating_q975": 1339.68145937364,
            "rating_q025": 1320.081524894477
        },
        "step-2-16k-exp-202412": {
            "rating": 1327.4839753283281,
            "rating_q975": 1348.1218231279393,
            "rating_q025": 1306.846127528717
        },
        "kimi-k2-0711-preview": {
            "rating": 1327.4129577583665,
            "rating_q975": 1337.4263064689226,
            "rating_q025": 1317.3996090478104
        },
        "qwen3-30b-a3b-instruct-2507": {
            "rating": 1322.2052729156514,
            "rating_q975": 1333.0239493172749,
            "rating_q025": 1311.386596514028
        },
        "qwen3-235b-a22b": {
            "rating": 1321.8167673370192,
            "rating_q975": 1331.6844877719286,
            "rating_q025": 1311.9490469021098
        },
        "gemini-2.0-flash-lite-preview-02-05": {
            "rating": 1320.1268466940064,
            "rating_q975": 1329.0709377199319,
            "rating_q025": 1311.182755668081
        },
        "o1-preview": {
            "rating": 1319.440492317686,
            "rating_q975": 1329.1532484902104,
            "rating_q025": 1309.7277361451615
        },
        "command-a-03-2025": {
            "rating": 1318.2749723755464,
            "rating_q975": 1325.3613080264852,
            "rating_q025": 1311.1886367246077
        },
        "step-3": {
            "rating": 1317.687543567661,
            "rating_q975": 1338.2473413560801,
            "rating_q025": 1297.1277457792416
        },
        "amazon-nova-experimental-chat-10-20": {
            "rating": 1317.6614904475925,
            "rating_q975": 1336.3474462976617,
            "rating_q025": 1298.9755345975234
        },
        "claude-3-7-sonnet-20250219": {
            "rating": 1316.607630262994,
            "rating_q975": 1324.478149561277,
            "rating_q025": 1308.737110964711
        },
        "llama-3.1-nemotron-ultra-253b-v1": {
            "rating": 1316.0915081746462,
            "rating_q975": 1342.5539338412962,
            "rating_q025": 1289.6290825079961
        },
        "glm-4-plus-0111": {
            "rating": 1312.1293079385737,
            "rating_q975": 1331.0326865937477,
            "rating_q025": 1293.2259292833996
        },
        "qwen3-next-80b-a3b-thinking": {
            "rating": 1310.4486975241116,
            "rating_q975": 1324.7097164283164,
            "rating_q025": 1296.1876786199068
        },
        "amazon-nova-experimental-chat-10-09": {
            "rating": 1310.1961856904095,
            "rating_q975": 1326.9025757734335,
            "rating_q025": 1293.4897956073855
        },
        "nvidia-llama-3.3-nemotron-super-49b-v1.5": {
            "rating": 1306.5452993534934,
            "rating_q975": 1334.6223393626797,
            "rating_q025": 1278.4682593443072
        },
        "mistral-small-2506": {
            "rating": 1306.1396469505166,
            "rating_q975": 1318.3060610284022,
            "rating_q025": 1293.9732328726311
        },
        "minimax-m1": {
            "rating": 1302.9089807593166,
            "rating_q975": 1311.7778674250367,
            "rating_q025": 1294.0400940935965
        },
        "step-1o-turbo-202506": {
            "rating": 1301.4199335220205,
            "rating_q975": 1319.346175818078,
            "rating_q025": 1283.493691225963
        },
        "o4-mini-2025-04-16": {
            "rating": 1300.2310118634039,
            "rating_q975": 1308.2752403094598,
            "rating_q025": 1292.186783417348
        },
        "gpt-4.1-mini-2025-04-14": {
            "rating": 1299.5226170652313,
            "rating_q975": 1308.0886779838218,
            "rating_q025": 1290.9565561466409
        },
        "qwen3-32b": {
            "rating": 1298.2701338240468,
            "rating_q975": 1320.7401253005394,
            "rating_q025": 1275.8001423475541
        },
        "glm-4.5v": {
            "rating": 1294.604235851089,
            "rating_q975": 1317.5034700311944,
            "rating_q025": 1271.7050016709836
        },
        "claude-3-5-sonnet-20241022": {
            "rating": 1293.7853960975306,
            "rating_q975": 1299.6635176673383,
            "rating_q025": 1287.9072745277228
        },
        "qwen-plus-0125": {
            "rating": 1292.8133576358744,
            "rating_q975": 1311.055598258674,
            "rating_q025": 1274.5711170130746
        },
        "gpt-4o-2024-05-13": {
            "rating": 1292.4189379851618,
            "rating_q975": 1299.2378371697466,
            "rating_q025": 1285.600038800577
        },
        "nova-2-lite": {
            "rating": 1291.7822333010024,
            "rating_q975": 1315.8785807679135,
            "rating_q025": 1267.6858858340913
        },
        "minimax-m2": {
            "rating": 1290.0597861231167,
            "rating_q975": 1310.3849188803006,
            "rating_q025": 1269.734653365933
        },
        "ling-flash-2.0": {
            "rating": 1289.267528588591,
            "rating_q975": 1309.648597699012,
            "rating_q025": 1268.8864594781699
        },
        "qwq-32b": {
            "rating": 1289.0250801903335,
            "rating_q975": 1298.558266305104,
            "rating_q025": 1279.4918940755629
        },
        "llama-3.3-nemotron-49b-super-v1": {
            "rating": 1286.5443382179678,
            "rating_q975": 1313.5717721141475,
            "rating_q025": 1259.5169043217882
        },
        "gemini-1.5-flash-002": {
            "rating": 1286.3894988871161,
            "rating_q975": 1294.9945666188326,
            "rating_q025": 1277.7844311553997
        },
        "intellect-3": {
            "rating": 1286.3510770673336,
            "rating_q975": 1321.714344193198,
            "rating_q025": 1250.987809941469
        },
        "o3-mini-high": {
            "rating": 1286.0349553471176,
            "rating_q975": 1296.5784482201927,
            "rating_q025": 1275.4914624740425
        },
        "gemma-3n-e4b-it": {
            "rating": 1285.9731847395606,
            "rating_q975": 1296.821768872828,
            "rating_q025": 1275.1246006062931
        },
        "grok-2-2024-08-13": {
            "rating": 1285.559659699606,
            "rating_q975": 1292.6625470711729,
            "rating_q025": 1278.4567723280393
        },
        "gemini-advanced-0514": {
            "rating": 1285.267316258668,
            "rating_q975": 1294.9125775468706,
            "rating_q025": 1275.6220549704653
        },
        "deepseek-v2.5-1210": {
            "rating": 1284.8481552235637,
            "rating_q975": 1301.9952227914553,
            "rating_q025": 1267.7010876556722
        },
        "yi-lightning": {
            "rating": 1281.5915594326127,
            "rating_q975": 1291.7766777009863,
            "rating_q025": 1271.4064411642391
        },
        "gpt-oss-120b": {
            "rating": 1279.4098330033012,
            "rating_q975": 1289.1382716300457,
            "rating_q025": 1269.6813943765567
        },
        "o3-mini": {
            "rating": 1275.1476931549819,
            "rating_q975": 1281.8805264314863,
            "rating_q025": 1268.4148598784775
        },
        "gpt-4o-2024-08-06": {
            "rating": 1274.8626744827905,
            "rating_q975": 1283.0606546550412,
            "rating_q025": 1266.6646943105397
        },
        "qwen3-30b-a3b": {
            "rating": 1274.1234558624476,
            "rating_q975": 1284.18767415961,
            "rating_q025": 1264.0592375652852
        },
        "gemini-1.5-pro-001": {
            "rating": 1273.5233080798143,
            "rating_q975": 1281.3995850246326,
            "rating_q025": 1265.647031134996
        },
        "gemma-3-4b-it": {
            "rating": 1272.192566087048,
            "rating_q975": 1293.8670721385622,
            "rating_q025": 1250.5180600355336
        },
        "hunyuan-turbos-20250226": {
            "rating": 1271.0359806750473,
            "rating_q975": 1296.9608145022328,
            "rating_q025": 1245.1111468478618
        },
        "ring-flash-2.0": {
            "rating": 1270.8727298894498,
            "rating_q975": 1290.6849567161685,
            "rating_q025": 1251.0605030627312
        },
        "gpt-4-turbo-2024-04-09": {
            "rating": 1270.1545914252047,
            "rating_q975": 1277.6481443219695,
            "rating_q025": 1262.6610385284398
        },
        "llama-3.1-nemotron-70b-instruct": {
            "rating": 1269.5998466964722,
            "rating_q975": 1288.2347782412082,
            "rating_q025": 1250.9649151517362
        },
        "gpt-4o-mini-2024-07-18": {
            "rating": 1269.0535265722547,
            "rating_q975": 1275.6234262616335,
            "rating_q025": 1262.4836268828758
        },
        "hunyuan-turbo-0110": {
            "rating": 1268.4956911705403,
            "rating_q975": 1293.5569551779954,
            "rating_q025": 1243.4344271630853
        },
        "llama-4-maverick-17b-128e-instruct": {
            "rating": 1268.3997230870325,
            "rating_q975": 1276.8094700214263,
            "rating_q025": 1259.9899761526387
        },
        "glm-4-plus": {
            "rating": 1264.1240243238906,
            "rating_q975": 1274.1278855838152,
            "rating_q025": 1254.120163063966
        },
        "hunyuan-large-2025-02-10": {
            "rating": 1263.9844107084373,
            "rating_q975": 1287.7913617699824,
            "rating_q025": 1240.1774596468922
        },
        "llama-3.1-405b-instruct-fp8": {
            "rating": 1263.2751574370443,
            "rating_q975": 1270.6444810370974,
            "rating_q025": 1255.9058338369912
        },
        "qwen2.5-plus-1127": {
            "rating": 1262.646958406693,
            "rating_q975": 1276.886117734344,
            "rating_q025": 1248.4077990790422
        },
        "gpt-4.1-nano-2025-04-14": {
            "rating": 1261.9462142050888,
            "rating_q975": 1280.1624672131338,
            "rating_q025": 1243.7299611970438
        },
        "llama-3.1-405b-instruct-bf16": {
            "rating": 1261.000150683547,
            "rating_q975": 1268.3195459591407,
            "rating_q025": 1253.6807554079533
        },
        "olmo-3-32b-think": {
            "rating": 1259.5118186458294,
            "rating_q975": 1288.2865962484075,
            "rating_q025": 1230.7370410432513
        },
        "hunyuan-large-vision": {
            "rating": 1258.8201308964171,
            "rating_q975": 1282.3457477049278,
            "rating_q025": 1235.2945140879065
        },
        "gpt-5-nano-high": {
            "rating": 1256.8298158969174,
            "rating_q975": 1276.7954534533865,
            "rating_q025": 1236.8641783404482
        },
        "mistral-small-3.1-24b-instruct-2503": {
            "rating": 1254.335991303617,
            "rating_q975": 1263.6423465638456,
            "rating_q025": 1245.0296360433883
        },
        "magistral-medium-2506": {
            "rating": 1253.621630373446,
            "rating_q975": 1269.5551096437393,
            "rating_q025": 1237.6881511031524
        },
        "llama-4-scout-17b-16e-instruct": {
            "rating": 1253.0145635738395,
            "rating_q975": 1262.8727038460975,
            "rating_q025": 1243.1564233015815
        },
        "llama-3.3-70b-instruct": {
            "rating": 1252.5058077933838,
            "rating_q975": 1259.1703863153755,
            "rating_q025": 1245.8412292713922
        },
        "qwen-max-0919": {
            "rating": 1249.7079029715933,
            "rating_q975": 1261.5497617396666,
            "rating_q025": 1237.86604420352
        },
        "o1-mini": {
            "rating": 1245.6274547645526,
            "rating_q975": 1252.933101274326,
            "rating_q025": 1238.3218082547792
        },
        "gpt-4-1106-preview": {
            "rating": 1245.3088895124288,
            "rating_q975": 1253.0306080093942,
            "rating_q025": 1237.5871710154634
        },
        "mistral-large-2407": {
            "rating": 1244.173706053993,
            "rating_q975": 1252.4712494976523,
            "rating_q025": 1235.876162610334
        },
        "grok-2-mini-2024-08-13": {
            "rating": 1243.2493915585546,
            "rating_q975": 1250.6489034955448,
            "rating_q025": 1235.8498796215645
        },
        "gemma-2-27b-it": {
            "rating": 1242.3066186572619,
            "rating_q975": 1248.7979490323478,
            "rating_q025": 1235.815288282176
        },
        "mistral-large-2411": {
            "rating": 1242.2110999956153,
            "rating_q975": 1250.9371591663153,
            "rating_q025": 1233.4850408249154
        },
        "hunyuan-standard-2025-02-10": {
            "rating": 1241.6779709183832,
            "rating_q975": 1265.2387125301598,
            "rating_q025": 1218.1172293066065
        },
        "gemma-2-9b-it-simpo": {
            "rating": 1240.6431690896318,
            "rating_q975": 1255.124221566257,
            "rating_q025": 1226.1621166130067
        },
        "claude-3-5-sonnet-20240620": {
            "rating": 1239.1511149631774,
            "rating_q975": 1246.517681232309,
            "rating_q025": 1231.7845486940457
        },
        "athene-70b-0725": {
            "rating": 1238.7915668680375,
            "rating_q975": 1249.8807523465725,
            "rating_q025": 1227.7023813895025
        },
        "deepseek-v2.5": {
            "rating": 1238.3002323162223,
            "rating_q975": 1248.5852012912621,
            "rating_q025": 1228.0152633411824
        },
        "command-r-plus-08-2024": {
            "rating": 1236.0933428996118,
            "rating_q975": 1250.990834240843,
            "rating_q025": 1221.1958515583806
        },
        "reka-core-20240904": {
            "rating": 1236.0883212259944,
            "rating_q975": 1254.0391549219073,
            "rating_q025": 1218.1374875300814
        },
        "claude-3-opus-20240229": {
            "rating": 1236.0443943206374,
            "rating_q975": 1242.2164239087585,
            "rating_q025": 1229.8723647325162
        },
        "athene-v2-chat": {
            "rating": 1234.340046818177,
            "rating_q975": 1243.8354066863826,
            "rating_q025": 1224.8446869499712
        },
        "llama-3.1-70b-instruct": {
            "rating": 1233.9391479149526,
            "rating_q975": 1241.4110346541252,
            "rating_q025": 1226.46726117578
        },
        "gpt-4-0125-preview": {
            "rating": 1233.6696616321497,
            "rating_q975": 1241.5664728301529,
            "rating_q025": 1225.7728504341464
        },
        "llama-3.1-tulu-3-70b": {
            "rating": 1233.26365757491,
            "rating_q975": 1257.849977667362,
            "rating_q025": 1208.677337482458
        },
        "claude-3-5-haiku-20241022": {
            "rating": 1231.7522309230092,
            "rating_q975": 1237.9423653708209,
            "rating_q025": 1225.5620964751974
        },
        "gemini-1.5-flash-001": {
            "rating": 1224.2107358778146,
            "rating_q975": 1232.3644688396707,
            "rating_q025": 1216.0570029159585
        },
        "qwen2.5-72b-instruct": {
            "rating": 1222.407379998724,
            "rating_q975": 1230.5451757228923,
            "rating_q025": 1214.2695842745559
        },
        "gemini-1.5-flash-8b-001": {
            "rating": 1219.0833054345585,
            "rating_q975": 1227.6339038716105,
            "rating_q025": 1210.5327069975065
        },
        "llama-3.1-nemotron-51b-instruct": {
            "rating": 1213.9092091839784,
            "rating_q975": 1239.476766655153,
            "rating_q025": 1188.341651712804
        },
        "jamba-1.5-large": {
            "rating": 1213.2103632165513,
            "rating_q975": 1229.101982186141,
            "rating_q025": 1197.3187442469616
        },
        "amazon-nova-pro-v1.0": {
            "rating": 1212.7191488641338,
            "rating_q975": 1221.9389893362945,
            "rating_q025": 1203.499308391973
        },
        "llama-3-70b-instruct": {
            "rating": 1211.7838119467324,
            "rating_q975": 1219.1251844318897,
            "rating_q025": 1204.442439461575
        },
        "gemma-2-9b-it": {
            "rating": 1207.0117114550821,
            "rating_q975": 1214.1599878560778,
            "rating_q025": 1199.8634350540865
        },
        "mercury": {
            "rating": 1206.0432795294046,
            "rating_q975": 1246.0496133188199,
            "rating_q025": 1166.0369457399893
        },
        "nemotron-4-340b-instruct": {
            "rating": 1203.7983803805564,
            "rating_q975": 1215.2555113536635,
            "rating_q025": 1192.3412494074494
        },
        "reka-flash-20240904": {
            "rating": 1203.0812813425398,
            "rating_q975": 1220.5084355439956,
            "rating_q025": 1185.654127141084
        },
        "gpt-oss-20b": {
            "rating": 1202.4877682911742,
            "rating_q975": 1219.9243277887022,
            "rating_q025": 1185.0512087936463
        },
        "command-r-plus": {
            "rating": 1202.1753649259838,
            "rating_q975": 1210.5725405260268,
            "rating_q025": 1193.7781893259407
        },
        "c4ai-aya-expanse-32b": {
            "rating": 1201.2096933205064,
            "rating_q975": 1210.8913968535508,
            "rating_q025": 1191.527989787462
        },
        "olmo-2-0325-32b-instruct": {
            "rating": 1200.205087186846,
            "rating_q975": 1224.7689003701103,
            "rating_q025": 1175.6412740035817
        },
        "glm-4-0520": {
            "rating": 1199.7641718212635,
            "rating_q975": 1214.7917212980512,
            "rating_q025": 1184.7366223444758
        },
        "amazon-nova-lite-v1.0": {
            "rating": 1197.5039074577999,
            "rating_q975": 1207.7376181021016,
            "rating_q025": 1187.2701968134982
        },
        "mistral-small-24b-instruct-2501": {
            "rating": 1195.9760945941744,
            "rating_q975": 1207.875233396032,
            "rating_q025": 1184.0769557923168
        },
        "gpt-4-0613": {
            "rating": 1192.4414848451083,
            "rating_q975": 1200.583189482995,
            "rating_q025": 1184.2997802072216
        },
        "gpt-4-0314": {
            "rating": 1191.5099171421239,
            "rating_q975": 1201.3105068190746,
            "rating_q025": 1181.7093274651731
        },
        "claude-3-sonnet-20240229": {
            "rating": 1187.6379870507355,
            "rating_q975": 1195.7086581178078,
            "rating_q025": 1179.5673159836633
        },
        "qwen2-72b-instruct": {
            "rating": 1182.8970553914942,
            "rating_q975": 1192.195182743654,
            "rating_q025": 1173.5989280393344
        },
        "phi-4": {
            "rating": 1182.6273220965877,
            "rating_q975": 1192.031244513147,
            "rating_q025": 1173.2233996800285
        },
        "llama-3.1-tulu-3-8b": {
            "rating": 1180.4291023730104,
            "rating_q975": 1205.8108505623843,
            "rating_q025": 1155.0473541836366
        },
        "ministral-8b-2410": {
            "rating": 1175.246902513392,
            "rating_q975": 1196.7755219280912,
            "rating_q025": 1153.7182830986926
        },
        "amazon-nova-micro-v1.0": {
            "rating": 1173.6875710827803,
            "rating_q975": 1184.1482923774004,
            "rating_q025": 1163.2268497881603
        },
        "qwen2.5-coder-32b-instruct": {
            "rating": 1172.2835196975104,
            "rating_q975": 1191.3576477959468,
            "rating_q025": 1153.209391599074
        },
        "command-r-08-2024": {
            "rating": 1172.1821409669742,
            "rating_q975": 1187.395266572028,
            "rating_q025": 1156.9690153619204
        },
        "c4ai-aya-expanse-8b": {
            "rating": 1170.3442582801986,
            "rating_q975": 1185.090530229256,
            "rating_q025": 1155.597986331141
        },
        "hunyuan-standard-256k": {
            "rating": 1168.5980863978575,
            "rating_q975": 1197.4849042931783,
            "rating_q025": 1139.7112685025368
        },
        "jamba-1.5-mini": {
            "rating": 1165.2857553069402,
            "rating_q975": 1180.7646698507492,
            "rating_q025": 1149.8068407631313
        },
        "mistral-large-2402": {
            "rating": 1162.7521960018507,
            "rating_q975": 1171.9533201246322,
            "rating_q025": 1153.5510718790692
        },
        "mistral-medium": {
            "rating": 1160.0425190569165,
            "rating_q975": 1170.7454885528227,
            "rating_q025": 1149.3395495610102
        },
        "claude-3-haiku-20240307": {
            "rating": 1159.1771179279826,
            "rating_q975": 1166.4951427047995,
            "rating_q025": 1151.8590931511658
        },
        "command-r": {
            "rating": 1156.530409469201,
            "rating_q975": 1166.083754968937,
            "rating_q025": 1146.977063969465
        },
        "llama-3.1-8b-instruct": {
            "rating": 1156.36030270851,
            "rating_q975": 1164.3830702897703,
            "rating_q025": 1148.3375351272498
        },
        "llama-3-8b-instruct": {
            "rating": 1151.8457852031013,
            "rating_q975": 1159.7583763489367,
            "rating_q025": 1143.9331940572658
        },
        "wizardlm-70b": {
            "rating": 1151.2302972749824,
            "rating_q975": 1168.0807027402975,
            "rating_q025": 1134.3798918096672
        },
        "qwen1.5-110b-chat": {
            "rating": 1149.9440692656788,
            "rating_q975": 1161.3501819494165,
            "rating_q025": 1138.537956581941
        },
        "gemma-2-2b-it": {
            "rating": 1148.5400026400612,
            "rating_q975": 1156.3927976819878,
            "rating_q025": 1140.6872075981346
        },
        "mixtral-8x22b-instruct-v0.1": {
            "rating": 1142.7072887862246,
            "rating_q975": 1151.7762530197435,
            "rating_q025": 1133.6383245527056
        },
        "qwen1.5-72b-chat": {
            "rating": 1138.2904721558448,
            "rating_q975": 1148.1958375264205,
            "rating_q025": 1128.385106785269
        },
        "yi-1.5-34b-chat": {
            "rating": 1135.957380574957,
            "rating_q975": 1146.8625109469183,
            "rating_q025": 1125.0522502029955
        },
        "qwq-32b-preview": {
            "rating": 1134.3810991170956,
            "rating_q975": 1162.8751306068825,
            "rating_q025": 1105.8870676273086
        },
        "reka-flash-21b-20240226-online": {
            "rating": 1132.8041866074027,
            "rating_q975": 1147.0848151704333,
            "rating_q025": 1118.523558044372
        },
        "gemini-pro-dev-api": {
            "rating": 1132.3668825189584,
            "rating_q975": 1146.1674559834005,
            "rating_q025": 1118.5663090545163
        },
        "granite-3.1-8b-instruct": {
            "rating": 1129.6197358158472,
            "rating_q975": 1156.2289934595913,
            "rating_q025": 1103.0104781721031
        },
        "vicuna-33b": {
            "rating": 1127.7369421099534,
            "rating_q975": 1139.6195972009155,
            "rating_q025": 1115.8542870189913
        },
        "openchat-3.5": {
            "rating": 1127.4129561883392,
            "rating_q975": 1145.5133605152616,
            "rating_q025": 1109.3125518614168
        },
        "reka-flash-21b-20240226": {
            "rating": 1126.7113969192942,
            "rating_q975": 1138.724105545228,
            "rating_q025": 1114.6986882933604
        },
        "internlm2_5-20b-chat": {
            "rating": 1123.6363866982156,
            "rating_q975": 1139.4108834463573,
            "rating_q025": 1107.8618899500739
        },
        "deepseek-coder-v2": {
            "rating": 1122.5500331423873,
            "rating_q975": 1135.8089866866874,
            "rating_q025": 1109.2910795980872
        },
        "granite-3.1-2b-instruct": {
            "rating": 1119.2644746684052,
            "rating_q975": 1148.3261455639959,
            "rating_q025": 1090.2028037728146
        },
        "zephyr-orpo-141b-A35b-v0.1": {
            "rating": 1113.6172592859211,
            "rating_q975": 1136.7614448472727,
            "rating_q025": 1090.4730737245695
        },
        "yi-34b-chat": {
            "rating": 1110.672155334305,
            "rating_q975": 1124.2693433883555,
            "rating_q025": 1097.0749672802544
        },
        "mixtral-8x7b-instruct-v0.1": {
            "rating": 1110.529509868258,
            "rating_q975": 1118.9795486285245,
            "rating_q025": 1102.0794711079914
        },
        "phi-3-medium-4k-instruct": {
            "rating": 1107.825533042266,
            "rating_q975": 1118.4459946969996,
            "rating_q025": 1097.2050713875324
        },
        "dbrx-instruct-preview": {
            "rating": 1107.0649653425448,
            "rating_q975": 1118.5117228694833,
            "rating_q025": 1095.6182078156064
        },
        "tulu-2-dpo-70b": {
            "rating": 1107.003341146342,
            "rating_q975": 1126.3328637219954,
            "rating_q025": 1087.6738185706888
        },
        "gemini-pro": {
            "rating": 1105.150479624067,
            "rating_q975": 1126.1458343800864,
            "rating_q025": 1084.1551248680476
        },
        "nous-hermes-2-mixtral-8x7b-dpo": {
            "rating": 1103.7925863329765,
            "rating_q975": 1127.2576151693213,
            "rating_q025": 1080.3275574966317
        },
        "zephyr-7b-beta": {
            "rating": 1103.4708692060622,
            "rating_q975": 1119.4713537716584,
            "rating_q025": 1087.470384640466
        },
        "starling-lm-7b-alpha": {
            "rating": 1100.4645844818906,
            "rating_q975": 1115.8249061693004,
            "rating_q025": 1085.1042627944807
        },
        "openhermes-2.5-mistral-7b": {
            "rating": 1099.2664361976408,
            "rating_q975": 1121.0996421426548,
            "rating_q025": 1077.4332302526268
        },
        "starling-lm-7b-beta": {
            "rating": 1098.4371024546133,
            "rating_q975": 1112.7653203675693,
            "rating_q025": 1084.1088845416573
        },
        "llama-3.2-3b-instruct": {
            "rating": 1095.2417646821018,
            "rating_q975": 1114.0862316133991,
            "rating_q025": 1076.3972977508045
        },
        "gpt-3.5-turbo-0125": {
            "rating": 1094.2210721221822,
            "rating_q975": 1102.8777473426553,
            "rating_q025": 1085.5643969017092
        },
        "openchat-3.5-0106": {
            "rating": 1093.99544474349,
            "rating_q975": 1108.8134638603683,
            "rating_q025": 1079.1774256266117
        },
        "solar-10.7b-instruct-v1.0": {
            "rating": 1093.3633294506803,
            "rating_q975": 1117.6816196751904,
            "rating_q025": 1069.0450392261703
        },
        "qwen1.5-14b-chat": {
            "rating": 1092.9975299917867,
            "rating_q975": 1107.0146473867055,
            "rating_q025": 1078.9804125968678
        },
        "llama2-70b-steerlm-chat": {
            "rating": 1092.430349504753,
            "rating_q975": 1117.0999714391558,
            "rating_q025": 1067.7607275703501
        },
        "wizardlm-13b": {
            "rating": 1091.8549020397245,
            "rating_q975": 1109.8268419102212,
            "rating_q025": 1073.8829621692278
        },
        "falcon-180b-chat": {
            "rating": 1090.7768655073473,
            "rating_q975": 1128.4438729062142,
            "rating_q025": 1053.1098581084805
        },
        "dolphin-2.2.1-mistral-7b": {
            "rating": 1087.6867170603946,
            "rating_q975": 1121.7646784477245,
            "rating_q025": 1053.6087556730647
        },
        "qwen1.5-32b-chat": {
            "rating": 1086.0537073969224,
            "rating_q975": 1098.2329814730158,
            "rating_q025": 1073.874433320829
        },
        "phi-3-small-8k-instruct": {
            "rating": 1085.0506617849105,
            "rating_q975": 1097.8679370409227,
            "rating_q025": 1072.2333865288983
        },
        "snowflake-arctic-instruct": {
            "rating": 1083.7882827757842,
            "rating_q975": 1095.6755030492209,
            "rating_q025": 1071.9010625023475
        },
        "guanaco-33b": {
            "rating": 1080.895078418257,
            "rating_q975": 1108.6334332094768,
            "rating_q025": 1053.1567236270373
        },
        "llama-2-70b-chat": {
            "rating": 1077.3375739889239,
            "rating_q975": 1087.3448062430737,
            "rating_q025": 1067.330341734774
        },
        "mpt-30b-chat": {
            "rating": 1077.064829826805,
            "rating_q975": 1106.2017685290593,
            "rating_q025": 1047.9278911245506
        },
        "granite-3.0-8b-instruct": {
            "rating": 1073.9377338211316,
            "rating_q975": 1094.3545260942142,
            "rating_q025": 1053.520941548049
        },
        "zephyr-7b-alpha": {
            "rating": 1072.0274510124773,
            "rating_q975": 1102.6375839000414,
            "rating_q025": 1041.4173181249132
        },
        "mistral-7b-instruct-v0.2": {
            "rating": 1070.4649418201184,
            "rating_q975": 1082.9391825544026,
            "rating_q025": 1057.9907010858342
        },
        "deepseek-llm-67b-chat": {
            "rating": 1067.169236145529,
            "rating_q975": 1089.2579265444183,
            "rating_q025": 1045.08054574664
        },
        "gemma-1.1-7b-it": {
            "rating": 1062.8801489274233,
            "rating_q975": 1074.3959843340233,
            "rating_q025": 1051.3643135208233
        },
        "vicuna-13b": {
            "rating": 1059.2987341376245,
            "rating_q975": 1071.9552986451704,
            "rating_q025": 1046.6421696300786
        },
        "llama-2-13b-chat": {
            "rating": 1049.4074570045404,
            "rating_q975": 1061.8683666572795,
            "rating_q025": 1036.9465473518014
        },
        "granite-3.0-2b-instruct": {
            "rating": 1047.7164163565926,
            "rating_q975": 1068.51232426977,
            "rating_q025": 1026.9205084434152
        },
        "phi-3-mini-4k-instruct-june-2024": {
            "rating": 1044.8465516592837,
            "rating_q975": 1059.2216081221618,
            "rating_q025": 1030.4714951964056
        },
        "phi-3-mini-4k-instruct": {
            "rating": 1037.1601762808364,
            "rating_q975": 1049.6709997466835,
            "rating_q025": 1024.6493528149892
        },
        "llama-3.2-1b-instruct": {
            "rating": 1036.333817038798,
            "rating_q975": 1055.9558933236353,
            "rating_q025": 1016.7117407539608
        },
        "gpt-3.5-turbo-1106": {
            "rating": 1036.2377334970868,
            "rating_q975": 1051.576230188664,
            "rating_q025": 1020.8992368055094
        },
        "llama-2-7b-chat": {
            "rating": 1035.8611203518917,
            "rating_q975": 1049.4309311427746,
            "rating_q025": 1022.2913095610087
        },
        "qwen1.5-7b-chat": {
            "rating": 1034.8765619779665,
            "rating_q975": 1057.477443641383,
            "rating_q025": 1012.2756803145502
        },
        "smollm2-1.7b-instruct": {
            "rating": 1033.1902600634485,
            "rating_q975": 1068.3087778322817,
            "rating_q025": 998.0717422946151
        },
        "stripedhyena-nous-7b": {
            "rating": 1033.0488400144864,
            "rating_q975": 1053.9041568765738,
            "rating_q025": 1012.1935231523989
        },
        "codellama-34b-instruct": {
            "rating": 1032.7695146287522,
            "rating_q975": 1049.4426914033065,
            "rating_q025": 1016.0963378541979
        },
        "mistral-7b-instruct": {
            "rating": 1032.5137030658086,
            "rating_q975": 1049.4761558624532,
            "rating_q025": 1015.551250269164
        },
        "qwen-14b-chat": {
            "rating": 1029.9096390698537,
            "rating_q975": 1050.7526262239921,
            "rating_q025": 1009.0666519157153
        },
        "phi-3-mini-128k-instruct": {
            "rating": 1027.901363883911,
            "rating_q975": 1041.7394127382279,
            "rating_q025": 1014.0633150295943
        },
        "gemma-7b-it": {
            "rating": 1025.8211139529321,
            "rating_q975": 1043.4722611761274,
            "rating_q025": 1008.169966729737
        },
        "vicuna-7b": {
            "rating": 1023.7352127641941,
            "rating_q975": 1041.7625813552734,
            "rating_q025": 1005.7078441731148
        },
        "gemma-1.1-2b-it": {
            "rating": 999.8514594549368,
            "rating_q975": 1016.5938664879827,
            "rating_q025": 983.109052421891
        },
        "palm-2": {
            "rating": 994.216560100931,
            "rating_q975": 1011.6265211585289,
            "rating_q025": 976.8065990433331
        },
        "olmo-7b-instruct": {
            "rating": 993.2748001769658,
            "rating_q975": 1013.5244420185679,
            "rating_q025": 973.0251583353636
        },
        "gemma-2b-it": {
            "rating": 988.132661320931,
            "rating_q975": 1011.5129045196568,
            "rating_q025": 964.7524181222052
        },
        "gpt4all-13b-snoozy": {
            "rating": 974.4656281170184,
            "rating_q975": 1012.63742391645,
            "rating_q025": 936.2938323175867
        },
        "koala-13b": {
            "rating": 974.1809987976455,
            "rating_q975": 994.9029137196725,
            "rating_q025": 953.4590838756186
        },
        "chatglm3-6b": {
            "rating": 972.6848517808628,
            "rating_q975": 995.851992140135,
            "rating_q025": 949.5177114215905
        },
        "alpaca-13b": {
            "rating": 970.7931230072395,
            "rating_q975": 993.2420496713927,
            "rating_q025": 948.3441963430863
        },
        "qwen1.5-4b-chat": {
            "rating": 970.6569303005656,
            "rating_q975": 989.4736165040301,
            "rating_q025": 951.840244097101
        },
        "mpt-7b-chat": {
            "rating": 958.3146380576152,
            "rating_q975": 982.378664033611,
            "rating_q025": 934.2506120816194
        },
        "chatglm2-6b": {
            "rating": 944.6228054454077,
            "rating_q975": 971.1603489835832,
            "rating_q025": 918.0852619072323
        },
        "RWKV-4-Raven-14B": {
            "rating": 935.7815887371542,
            "rating_q975": 958.3793590598337,
            "rating_q025": 913.1838184144746
        },
        "oasst-pythia-12b": {
            "rating": 924.5891926433875,
            "rating_q975": 944.9376140636523,
            "rating_q025": 904.2407712231227
        },
        "fastchat-t5-3b": {
            "rating": 902.3080792974386,
            "rating_q975": 926.053178635226,
            "rating_q025": 878.5629799596511
        },
        "chatglm-6b": {
            "rating": 901.99319481867,
            "rating_q975": 926.412993370868,
            "rating_q025": 877.573396266472
        },
        "stablelm-tuned-alpha-7b": {
            "rating": 868.7644600668737,
            "rating_q975": 896.8311119045632,
            "rating_q025": 840.6978082291841
        },
        "dolly-v2-12b": {
            "rating": 865.385733775821,
            "rating_q975": 892.998599870482,
            "rating_q025": 837.7728676811599
        },
        "llama-13b": {
            "rating": 797.0721217945741,
            "rating_q975": 829.9168345217877,
            "rating_q025": 764.2274090673604
        }
    },
    "english": {
        "gemini-3-pro": {
            "rating": 1484.479849183445,
            "rating_q975": 1492.8338151501398,
            "rating_q025": 1476.12588321675
        },
        "gemini-2.5-pro": {
            "rating": 1463.5344306385014,
            "rating_q975": 1467.93124877742,
            "rating_q025": 1459.1376124995827
        },
        "claude-opus-4-5-20251101-thinking-32k": {
            "rating": 1457.2209207073606,
            "rating_q975": 1467.0263698884573,
            "rating_q025": 1447.415471526264
        },
        "grok-4.1": {
            "rating": 1455.8262662218995,
            "rating_q975": 1463.9317516891276,
            "rating_q025": 1447.7207807546713
        },
        "grok-4.1-thinking": {
            "rating": 1453.6913145186045,
            "rating_q975": 1461.7519700871435,
            "rating_q025": 1445.6306589500655
        },
        "claude-opus-4-5-20251101": {
            "rating": 1452.2631072392878,
            "rating_q975": 1461.8982148746345,
            "rating_q025": 1442.6279996039411
        },
        "gpt-5.1-high": {
            "rating": 1451.5676710523087,
            "rating_q975": 1460.2430511396387,
            "rating_q025": 1442.8922909649787
        },
        "glm-4.6": {
            "rating": 1450.4824831991561,
            "rating_q975": 1456.6784172283294,
            "rating_q025": 1444.286549169983
        },
        "ernie-5.0-preview-1103": {
            "rating": 1450.2072354519419,
            "rating_q975": 1462.0221647955216,
            "rating_q025": 1438.3923061083622
        },
        "claude-sonnet-4-5-20250929-thinking-32k": {
            "rating": 1445.1971243006249,
            "rating_q975": 1451.2390599116625,
            "rating_q025": 1439.1551886895872
        },
        "mistral-large-3": {
            "rating": 1443.9633124373465,
            "rating_q975": 1454.8748579401156,
            "rating_q025": 1433.0517669345775
        },
        "longcat-flash-chat": {
            "rating": 1442.7213521847239,
            "rating_q975": 1451.0205744941277,
            "rating_q025": 1434.42212987532
        },
        "qwen3-max-preview": {
            "rating": 1440.9694464844126,
            "rating_q975": 1446.912535190628,
            "rating_q025": 1435.0263577781973
        },
        "mistral-medium-2508": {
            "rating": 1440.579377416704,
            "rating_q975": 1445.6032643014603,
            "rating_q025": 1435.5554905319475
        },
        "claude-sonnet-4-5-20250929": {
            "rating": 1440.5530040324427,
            "rating_q975": 1447.1300677708566,
            "rating_q025": 1433.9759402940288
        },
        "deepseek-v3.2-exp": {
            "rating": 1439.8801048707137,
            "rating_q975": 1448.4669718104087,
            "rating_q025": 1431.2932379310187
        },
        "deepseek-v3.2": {
            "rating": 1439.5250072139818,
            "rating_q975": 1450.601581313284,
            "rating_q025": 1428.4484331146796
        },
        "deepseek-v3.2-exp-thinking": {
            "rating": 1437.9554245725308,
            "rating_q975": 1446.998386908341,
            "rating_q025": 1428.9124622367206
        },
        "deepseek-v3.2-thinking": {
            "rating": 1437.4851516327685,
            "rating_q975": 1448.5846159337893,
            "rating_q025": 1426.3856873317477
        },
        "claude-opus-4-1-20250805-thinking-16k": {
            "rating": 1436.500397298112,
            "rating_q975": 1441.57018518011,
            "rating_q025": 1431.4306094161138
        },
        "grok-3-preview-02-24": {
            "rating": 1436.3119943576653,
            "rating_q975": 1441.5137763500613,
            "rating_q025": 1431.1102123652693
        },
        "deepseek-r1-0528": {
            "rating": 1432.7051238795455,
            "rating_q975": 1439.7585514742104,
            "rating_q025": 1425.6516962848805
        },
        "glm-4.5": {
            "rating": 1432.6332100972593,
            "rating_q975": 1438.9281486914672,
            "rating_q025": 1426.3382715030514
        },
        "deepseek-v3.1-thinking": {
            "rating": 1432.3044930095457,
            "rating_q975": 1440.8806096082435,
            "rating_q025": 1423.7283764108479
        },
        "chatgpt-4o-latest-20250326": {
            "rating": 1431.935438827822,
            "rating_q975": 1436.1578994458469,
            "rating_q025": 1427.7129782097973
        },
        "qwen3-vl-235b-a22b-instruct": {
            "rating": 1431.6938700466012,
            "rating_q975": 1440.7568618047596,
            "rating_q025": 1422.6308782884428
        },
        "deepseek-v3.1": {
            "rating": 1431.4585971001902,
            "rating_q975": 1439.237850807393,
            "rating_q025": 1423.6793433929874
        },
        "deepseek-v3.1-terminus-thinking": {
            "rating": 1427.4025506335718,
            "rating_q975": 1441.7160376211345,
            "rating_q025": 1413.089063646009
        },
        "qwen3-235b-a22b-thinking-2507": {
            "rating": 1426.6117400901621,
            "rating_q975": 1435.4695139750997,
            "rating_q025": 1417.7539662052245
        },
        "kimi-k2-thinking-turbo": {
            "rating": 1425.4127175126398,
            "rating_q975": 1433.2615395173734,
            "rating_q025": 1417.5638955079062
        },
        "deepseek-v3.1-terminus": {
            "rating": 1424.8120248799216,
            "rating_q975": 1438.5984079476523,
            "rating_q025": 1411.025641812191
        },
        "gpt-5.1": {
            "rating": 1424.737884861423,
            "rating_q975": 1432.9780752649706,
            "rating_q025": 1416.4976944578755
        },
        "claude-opus-4-1-20250805": {
            "rating": 1423.9991039585725,
            "rating_q975": 1428.780784094148,
            "rating_q025": 1419.217423822997
        },
        "qwen3-235b-a22b-instruct-2507": {
            "rating": 1423.6872241205033,
            "rating_q975": 1428.464451487259,
            "rating_q025": 1418.9099967537475
        },
        "qwen3-next-80b-a3b-instruct": {
            "rating": 1423.5187028703085,
            "rating_q975": 1429.739072837493,
            "rating_q025": 1417.298332903124
        },
        "grok-4-1-fast-reasoning": {
            "rating": 1422.4802869873488,
            "rating_q975": 1431.8851627205086,
            "rating_q025": 1413.075411254189
        },
        "qwen3-max-2025-09-23": {
            "rating": 1419.6457311870672,
            "rating_q975": 1428.3615268997787,
            "rating_q025": 1410.9299354743557
        },
        "gpt-4.5-preview-2025-02-27": {
            "rating": 1419.4222219688531,
            "rating_q975": 1426.4247796738575,
            "rating_q025": 1412.4196642638487
        },
        "amazon-nova-experimental-chat-10-20": {
            "rating": 1418.4451128173969,
            "rating_q975": 1428.1447793857913,
            "rating_q025": 1408.7454462490025
        },
        "grok-4-0709": {
            "rating": 1418.0192876861333,
            "rating_q975": 1423.0337161121524,
            "rating_q025": 1413.0048592601142
        },
        "gemini-2.5-flash": {
            "rating": 1416.5966814865728,
            "rating_q975": 1420.8761876480266,
            "rating_q025": 1412.317175325119
        },
        "o3-2025-04-16": {
            "rating": 1416.500049119868,
            "rating_q975": 1421.0574896329122,
            "rating_q025": 1411.9426086068238
        },
        "qwen3-vl-235b-a22b-thinking": {
            "rating": 1416.2303179007442,
            "rating_q975": 1425.6903162259905,
            "rating_q025": 1406.770319575498
        },
        "grok-4-fast-chat": {
            "rating": 1415.1532255160112,
            "rating_q975": 1425.4630647283443,
            "rating_q025": 1404.843386303678
        },
        "hunyuan-vision-1.5-thinking": {
            "rating": 1413.3164165800292,
            "rating_q975": 1430.869534530188,
            "rating_q025": 1395.7632986298704
        },
        "gemini-2.5-flash-preview-09-2025": {
            "rating": 1412.7824900931662,
            "rating_q975": 1418.5886274677368,
            "rating_q025": 1406.9763527185955
        },
        "gpt-5-high": {
            "rating": 1410.9501760569633,
            "rating_q975": 1416.6452522001337,
            "rating_q025": 1405.255099913793
        },
        "gpt-5-chat": {
            "rating": 1408.2308053098432,
            "rating_q975": 1413.8413098240123,
            "rating_q025": 1402.620300795674
        },
        "grok-4-fast-reasoning": {
            "rating": 1406.0708588381858,
            "rating_q975": 1412.7511401176714,
            "rating_q025": 1399.3905775587002
        },
        "claude-haiku-4-5-20251001": {
            "rating": 1406.0307824944998,
            "rating_q975": 1412.1780168146936,
            "rating_q025": 1399.883548174306
        },
        "mai-1-preview": {
            "rating": 1404.5349941253203,
            "rating_q975": 1411.575795409519,
            "rating_q025": 1397.4941928411215
        },
        "hunyuan-t1-20250711": {
            "rating": 1396.1185510245864,
            "rating_q975": 1408.6745556370108,
            "rating_q025": 1383.562546412162
        },
        "glm-4.5-air": {
            "rating": 1394.8802790949283,
            "rating_q975": 1400.4060596598913,
            "rating_q025": 1389.3544985299652
        },
        "qwen3-235b-a22b-no-thinking": {
            "rating": 1393.9887432135447,
            "rating_q975": 1399.4402369552706,
            "rating_q025": 1388.5372494718188
        },
        "qwen3-next-80b-a3b-thinking": {
            "rating": 1392.0425844304918,
            "rating_q975": 1399.6673775285265,
            "rating_q025": 1384.4177913324572
        },
        "qwen3-30b-a3b-instruct-2507": {
            "rating": 1391.995540675749,
            "rating_q975": 1398.3170636127209,
            "rating_q025": 1385.6740177387771
        },
        "gpt-4.1-2025-04-14": {
            "rating": 1391.9121207199348,
            "rating_q975": 1396.579092123504,
            "rating_q025": 1387.2451493163655
        },
        "ling-flash-2.0": {
            "rating": 1389.0782056526273,
            "rating_q975": 1398.9956512801016,
            "rating_q025": 1379.160760025153
        },
        "nova-2-lite": {
            "rating": 1387.4787125577466,
            "rating_q975": 1398.990358825073,
            "rating_q025": 1375.9670662904202
        },
        "claude-opus-4-20250514-thinking-16k": {
            "rating": 1386.5258142421371,
            "rating_q975": 1392.0832392717225,
            "rating_q025": 1380.9683892125518
        },
        "deepseek-v3-0324": {
            "rating": 1386.1297663749451,
            "rating_q975": 1390.9350593271122,
            "rating_q025": 1381.324473422778
        },
        "deepseek-r1": {
            "rating": 1384.4596375472076,
            "rating_q975": 1390.4258619947657,
            "rating_q025": 1378.4934130996496
        },
        "hunyuan-turbos-20250416": {
            "rating": 1384.2434020294154,
            "rating_q975": 1392.275233654216,
            "rating_q025": 1376.2115704046148
        },
        "gemini-2.5-flash-lite-preview-09-2025-no-thinking": {
            "rating": 1383.7409141808346,
            "rating_q975": 1389.4726600760341,
            "rating_q025": 1378.009168285635
        },
        "kimi-k2-0905-preview": {
            "rating": 1383.0990792545635,
            "rating_q975": 1391.5164253661699,
            "rating_q025": 1374.6817331429572
        },
        "gpt-5-mini-high": {
            "rating": 1382.649877947663,
            "rating_q975": 1388.6528978378824,
            "rating_q025": 1376.6468580574438
        },
        "o1-preview": {
            "rating": 1382.0441813002117,
            "rating_q975": 1388.2041831861243,
            "rating_q025": 1375.884179414299
        },
        "mistral-medium-2505": {
            "rating": 1381.1056450493982,
            "rating_q975": 1386.7791660558119,
            "rating_q025": 1375.4321240429845
        },
        "qwen3-235b-a22b": {
            "rating": 1377.8048495719931,
            "rating_q975": 1383.633349909529,
            "rating_q025": 1371.9763492344573
        },
        "grok-3-mini-high": {
            "rating": 1377.2542291133764,
            "rating_q975": 1384.0282541860931,
            "rating_q025": 1370.4802040406596
        },
        "kimi-k2-0711-preview": {
            "rating": 1376.4612394266594,
            "rating_q975": 1382.5005588621898,
            "rating_q025": 1370.421919991129
        },
        "qwen2.5-max": {
            "rating": 1375.2789213854878,
            "rating_q975": 1380.173671275099,
            "rating_q025": 1370.3841714958767
        },
        "gpt-oss-120b": {
            "rating": 1375.1820250443143,
            "rating_q975": 1380.8761089736952,
            "rating_q025": 1369.4879411149334
        },
        "claude-opus-4-20250514": {
            "rating": 1375.1187768780107,
            "rating_q975": 1380.456535944018,
            "rating_q025": 1369.7810178120035
        },
        "gemini-2.5-flash-lite-preview-06-17-thinking": {
            "rating": 1373.878160778078,
            "rating_q975": 1379.4548646687094,
            "rating_q025": 1368.3014568874464
        },
        "gemma-3-27b-it": {
            "rating": 1373.259163240757,
            "rating_q975": 1377.7357885119236,
            "rating_q025": 1368.7825379695905
        },
        "amazon-nova-experimental-chat-10-09": {
            "rating": 1373.170042342969,
            "rating_q975": 1381.8461183779496,
            "rating_q025": 1364.4939663079886
        },
        "grok-3-mini-beta": {
            "rating": 1372.6906248810653,
            "rating_q975": 1378.8645643561883,
            "rating_q025": 1366.5166854059423
        },
        "intellect-3": {
            "rating": 1372.4476416376092,
            "rating_q975": 1389.7943291827607,
            "rating_q025": 1355.1009540924576
        },
        "step-3": {
            "rating": 1371.8108042337312,
            "rating_q975": 1382.1482357298519,
            "rating_q025": 1361.4733727376106
        },
        "o1-2024-12-17": {
            "rating": 1371.6323064164544,
            "rating_q975": 1377.0220513416402,
            "rating_q025": 1366.2425614912686
        },
        "minimax-m1": {
            "rating": 1370.548346086025,
            "rating_q975": 1375.866960401566,
            "rating_q025": 1365.229731770484
        },
        "o4-mini-2025-04-16": {
            "rating": 1367.5945151099347,
            "rating_q975": 1372.4903120638658,
            "rating_q025": 1362.6987181560037
        },
        "claude-sonnet-4-20250514-thinking-32k": {
            "rating": 1366.745196544117,
            "rating_q975": 1372.3283488939894,
            "rating_q025": 1361.1620441942448
        },
        "ring-flash-2.0": {
            "rating": 1365.7144528341062,
            "rating_q975": 1375.588173619649,
            "rating_q025": 1355.8407320485633
        },
        "gemini-2.0-flash-001": {
            "rating": 1365.1213217188913,
            "rating_q975": 1369.5853009961857,
            "rating_q025": 1360.657342441597
        },
        "qwen3-coder-480b-a35b-instruct": {
            "rating": 1364.205709866429,
            "rating_q975": 1370.5355741507542,
            "rating_q025": 1357.875845582104
        },
        "minimax-m2": {
            "rating": 1363.5955160583426,
            "rating_q975": 1373.8590629362486,
            "rating_q025": 1353.3319691804365
        },
        "mistral-small-2506": {
            "rating": 1362.1470171304154,
            "rating_q975": 1368.8052068972747,
            "rating_q025": 1355.488827363556
        },
        "glm-4.5v": {
            "rating": 1359.8112632847199,
            "rating_q975": 1371.8299910244455,
            "rating_q025": 1347.7925355449943
        },
        "nvidia-llama-3.3-nemotron-super-49b-v1.5": {
            "rating": 1359.2661397852364,
            "rating_q975": 1373.3702040741193,
            "rating_q025": 1345.1620754963535
        },
        "qwen3-32b": {
            "rating": 1358.6261300364715,
            "rating_q975": 1370.931202057344,
            "rating_q025": 1346.321058015599
        },
        "gpt-4.1-mini-2025-04-14": {
            "rating": 1357.1129862483806,
            "rating_q975": 1362.3609584593185,
            "rating_q025": 1351.8650140374427
        },
        "llama-3.3-nemotron-49b-super-v1": {
            "rating": 1353.296619405536,
            "rating_q975": 1368.8752220706347,
            "rating_q025": 1337.7180167404372
        },
        "step-1o-turbo-202506": {
            "rating": 1353.2137096415988,
            "rating_q975": 1362.1501847191696,
            "rating_q025": 1344.277234564028
        },
        "olmo-3-32b-think": {
            "rating": 1351.3814228420883,
            "rating_q975": 1366.0817797066725,
            "rating_q025": 1336.6810659775042
        },
        "o3-mini-high": {
            "rating": 1350.2564013290548,
            "rating_q975": 1356.6464990421787,
            "rating_q025": 1343.866303615931
        },
        "qwq-32b": {
            "rating": 1349.0927073954908,
            "rating_q975": 1354.5782408050648,
            "rating_q025": 1343.607173985917
        },
        "claude-sonnet-4-20250514": {
            "rating": 1348.083631051708,
            "rating_q975": 1353.5079839142556,
            "rating_q025": 1342.6592781891602
        },
        "gemma-3-12b-it": {
            "rating": 1347.7727725531818,
            "rating_q975": 1359.537087925056,
            "rating_q025": 1336.0084571813074
        },
        "deepseek-v3": {
            "rating": 1346.162561801846,
            "rating_q975": 1351.9311720635392,
            "rating_q025": 1340.393951540153
        },
        "step-2-16k-exp-202412": {
            "rating": 1344.422225585889,
            "rating_q975": 1355.1115773036229,
            "rating_q025": 1333.7328738681551
        },
        "llama-3.1-nemotron-ultra-253b-v1": {
            "rating": 1344.3183358720771,
            "rating_q975": 1359.1066765395415,
            "rating_q025": 1329.5299952046128
        },
        "command-a-03-2025": {
            "rating": 1342.1102261067551,
            "rating_q975": 1346.4300526956622,
            "rating_q025": 1337.790399517848
        },
        "glm-4-plus-0111": {
            "rating": 1341.029768335186,
            "rating_q975": 1351.259518682662,
            "rating_q025": 1330.80001798771
        },
        "o1-mini": {
            "rating": 1340.4485812004464,
            "rating_q975": 1345.0174708538952,
            "rating_q025": 1335.8796915469975
        },
        "qwen-plus-0125": {
            "rating": 1338.4524969263916,
            "rating_q975": 1348.8156051113515,
            "rating_q025": 1328.0893887414318
        },
        "qwen3-30b-a3b": {
            "rating": 1335.5116649065599,
            "rating_q975": 1341.3988044543448,
            "rating_q025": 1329.624525358775
        },
        "o3-mini": {
            "rating": 1334.531677815101,
            "rating_q975": 1338.7426151881298,
            "rating_q025": 1330.320740442072
        },
        "gemini-2.0-flash-lite-preview-02-05": {
            "rating": 1333.08614077651,
            "rating_q975": 1338.3568976638603,
            "rating_q025": 1327.8153838891599
        },
        "hunyuan-turbos-20250226": {
            "rating": 1332.1154263462145,
            "rating_q975": 1347.0030211407654,
            "rating_q025": 1317.2278315516635
        },
        "yi-lightning": {
            "rating": 1330.3427322252405,
            "rating_q975": 1336.7452719511489,
            "rating_q025": 1323.9401924993322
        },
        "claude-3-7-sonnet-20250219-thinking-32k": {
            "rating": 1328.2862646438175,
            "rating_q975": 1333.418414399078,
            "rating_q025": 1323.154114888557
        },
        "hunyuan-turbo-0110": {
            "rating": 1328.1719061613196,
            "rating_q975": 1342.487449212638,
            "rating_q025": 1313.8563631100012
        },
        "gpt-5-nano-high": {
            "rating": 1326.8278748874359,
            "rating_q975": 1336.2246496971661,
            "rating_q025": 1317.4311000777057
        },
        "gemini-1.5-pro-002": {
            "rating": 1322.8887532729686,
            "rating_q975": 1327.1079654637424,
            "rating_q025": 1318.6695410821949
        },
        "qwen2.5-plus-1127": {
            "rating": 1322.202302289102,
            "rating_q975": 1329.9550758396485,
            "rating_q025": 1314.4495287385553
        },
        "grok-2-2024-08-13": {
            "rating": 1321.2867423915259,
            "rating_q975": 1325.6492728012747,
            "rating_q025": 1316.924211981777
        },
        "gemma-3n-e4b-it": {
            "rating": 1321.0200725679856,
            "rating_q975": 1327.3939801694014,
            "rating_q025": 1314.6461649665698
        },
        "llama-3.1-nemotron-70b-instruct": {
            "rating": 1315.1258675927168,
            "rating_q975": 1324.9706746999361,
            "rating_q025": 1305.2810604854974
        },
        "gpt-4o-2024-05-13": {
            "rating": 1312.7004564596732,
            "rating_q975": 1317.1146288231564,
            "rating_q025": 1308.28628409619
        },
        "llama-3.1-405b-instruct-bf16": {
            "rating": 1312.1982537655595,
            "rating_q975": 1316.5819496800598,
            "rating_q025": 1307.8145578510591
        },
        "claude-3-7-sonnet-20250219": {
            "rating": 1310.2861916490197,
            "rating_q975": 1315.0901660655943,
            "rating_q025": 1305.482217232445
        },
        "deepseek-v2.5-1210": {
            "rating": 1309.9235287547815,
            "rating_q975": 1320.1695659119675,
            "rating_q025": 1299.6774915975955
        },
        "mercury": {
            "rating": 1308.476067040611,
            "rating_q975": 1328.324212377677,
            "rating_q025": 1288.627921703545
        },
        "llama-3.1-405b-instruct-fp8": {
            "rating": 1308.303766870918,
            "rating_q975": 1312.8700744555713,
            "rating_q025": 1303.7374592862648
        },
        "claude-3-5-sonnet-20241022": {
            "rating": 1308.1530576266273,
            "rating_q975": 1311.7937770297303,
            "rating_q025": 1304.5123382235242
        },
        "athene-v2-chat": {
            "rating": 1306.9213178492923,
            "rating_q975": 1312.4727204622527,
            "rating_q025": 1301.369915236332
        },
        "hunyuan-large-2025-02-10": {
            "rating": 1305.7389403132208,
            "rating_q975": 1318.0380994241268,
            "rating_q025": 1293.4397812023149
        },
        "llama-3.3-70b-instruct": {
            "rating": 1304.7683807998824,
            "rating_q975": 1308.8343831088926,
            "rating_q025": 1300.7023784908722
        },
        "llama-4-maverick-17b-128e-instruct": {
            "rating": 1304.1789347557578,
            "rating_q975": 1309.3492917804952,
            "rating_q025": 1299.0085777310205
        },
        "gpt-oss-20b": {
            "rating": 1304.0303149789215,
            "rating_q975": 1312.6310542130682,
            "rating_q025": 1295.4295757447749
        },
        "gpt-4.1-nano-2025-04-14": {
            "rating": 1303.4866710293516,
            "rating_q975": 1313.275441279825,
            "rating_q025": 1293.6979007788782
        },
        "llama-4-scout-17b-16e-instruct": {
            "rating": 1303.103921446278,
            "rating_q975": 1308.9197120322465,
            "rating_q025": 1297.2881308603096
        },
        "gpt-4o-mini-2024-07-18": {
            "rating": 1300.829743914098,
            "rating_q975": 1304.8878023595928,
            "rating_q025": 1296.771685468603
        },
        "gemma-3-4b-it": {
            "rating": 1300.239985336236,
            "rating_q975": 1311.7952504908533,
            "rating_q025": 1288.6847201816188
        },
        "mistral-small-3.1-24b-instruct-2503": {
            "rating": 1299.552042860012,
            "rating_q975": 1305.1529707661582,
            "rating_q025": 1293.951114953866
        },
        "grok-2-mini-2024-08-13": {
            "rating": 1298.5949070967017,
            "rating_q975": 1303.2361556895146,
            "rating_q025": 1293.9536585038888
        },
        "gpt-4o-2024-08-06": {
            "rating": 1297.8411927121633,
            "rating_q975": 1303.018177310797,
            "rating_q025": 1292.6642081135296
        },
        "glm-4-plus": {
            "rating": 1296.911873217975,
            "rating_q975": 1303.1724005194278,
            "rating_q025": 1290.6513459165221
        },
        "llama-3.1-70b-instruct": {
            "rating": 1294.2427354644758,
            "rating_q975": 1298.8695848145028,
            "rating_q025": 1289.6158861144488
        },
        "qwen-max-0919": {
            "rating": 1293.139256430914,
            "rating_q975": 1300.337355521525,
            "rating_q025": 1285.9411573403029
        },
        "gpt-4-turbo-2024-04-09": {
            "rating": 1291.7591890918984,
            "rating_q975": 1296.5020297169817,
            "rating_q025": 1287.016348466815
        },
        "gemini-1.5-flash-002": {
            "rating": 1289.5727053523729,
            "rating_q975": 1294.8109601554156,
            "rating_q025": 1284.33445054933
        },
        "mistral-large-2407": {
            "rating": 1289.3081011861739,
            "rating_q975": 1294.2332537823668,
            "rating_q025": 1284.382948589981
        },
        "athene-70b-0725": {
            "rating": 1287.9153037613787,
            "rating_q975": 1294.7506458724192,
            "rating_q025": 1281.0799616503382
        },
        "claude-3-5-sonnet-20240620": {
            "rating": 1287.6179314859953,
            "rating_q975": 1291.9425233062093,
            "rating_q025": 1283.2933396657813
        },
        "hunyuan-large-vision": {
            "rating": 1285.614650301125,
            "rating_q975": 1297.322812905649,
            "rating_q025": 1273.906487696601
        },
        "deepseek-v2.5": {
            "rating": 1284.8634760175687,
            "rating_q975": 1290.8820368362428,
            "rating_q025": 1278.8449151988946
        },
        "mistral-large-2411": {
            "rating": 1284.1107791908585,
            "rating_q975": 1289.333785922677,
            "rating_q025": 1278.88777245904
        },
        "qwen2.5-72b-instruct": {
            "rating": 1283.1215596619945,
            "rating_q975": 1288.0870585788916,
            "rating_q025": 1278.1560607450974
        },
        "hunyuan-standard-2025-02-10": {
            "rating": 1282.3420397570285,
            "rating_q975": 1294.7774291683709,
            "rating_q025": 1269.906650345686
        },
        "gemini-advanced-0514": {
            "rating": 1282.0688815942203,
            "rating_q975": 1288.0141598165915,
            "rating_q025": 1276.1236033718492
        },
        "gemini-1.5-pro-001": {
            "rating": 1279.830589860669,
            "rating_q975": 1284.8015294159093,
            "rating_q025": 1274.8596503054289
        },
        "llama-3-70b-instruct": {
            "rating": 1277.5561376986948,
            "rating_q975": 1282.0889528234302,
            "rating_q025": 1273.0233225739594
        },
        "gpt-4-1106-preview": {
            "rating": 1277.4980820490484,
            "rating_q975": 1282.266022096529,
            "rating_q025": 1272.7301420015679
        },
        "magistral-medium-2506": {
            "rating": 1277.0984988987711,
            "rating_q975": 1285.931351446881,
            "rating_q025": 1268.2656463506612
        },
        "gpt-4-0125-preview": {
            "rating": 1276.6449077826946,
            "rating_q975": 1281.6263793722972,
            "rating_q025": 1271.6634361930921
        },
        "amazon-nova-pro-v1.0": {
            "rating": 1275.8745117524172,
            "rating_q975": 1281.1979332665987,
            "rating_q025": 1270.5510902382357
        },
        "llama-3.1-tulu-3-70b": {
            "rating": 1272.25648418723,
            "rating_q975": 1285.5109765954055,
            "rating_q025": 1259.0019917790544
        },
        "claude-3-5-haiku-20241022": {
            "rating": 1269.6628939968978,
            "rating_q975": 1273.5141638530308,
            "rating_q025": 1265.8116241407647
        },
        "jamba-1.5-large": {
            "rating": 1267.5165352608828,
            "rating_q975": 1276.651802296055,
            "rating_q025": 1258.3812682257108
        },
        "llama-3.1-nemotron-51b-instruct": {
            "rating": 1266.9631893963813,
            "rating_q975": 1280.5240960895355,
            "rating_q025": 1253.402282703227
        },
        "claude-3-opus-20240229": {
            "rating": 1263.0579261278635,
            "rating_q975": 1266.8421162606203,
            "rating_q025": 1259.2737359951068
        },
        "mistral-small-24b-instruct-2501": {
            "rating": 1256.533980023331,
            "rating_q975": 1263.442402139343,
            "rating_q025": 1249.625557907319
        },
        "reka-core-20240904": {
            "rating": 1255.9240471937078,
            "rating_q975": 1265.1313769154365,
            "rating_q025": 1246.716717471979
        },
        "olmo-2-0325-32b-instruct": {
            "rating": 1255.7738303087099,
            "rating_q975": 1268.728122883347,
            "rating_q025": 1242.8195377340728
        },
        "qwen2.5-coder-32b-instruct": {
            "rating": 1247.946361660976,
            "rating_q975": 1259.0391983625805,
            "rating_q025": 1236.8535249593715
        },
        "gemini-1.5-flash-001": {
            "rating": 1244.050240445055,
            "rating_q975": 1249.281852241181,
            "rating_q025": 1238.8186286489288
        },
        "gemma-2-9b-it-simpo": {
            "rating": 1243.0746464193398,
            "rating_q975": 1251.7203569660319,
            "rating_q025": 1234.4289358726478
        },
        "amazon-nova-lite-v1.0": {
            "rating": 1243.0620713558878,
            "rating_q975": 1249.2000649387312,
            "rating_q025": 1236.9240777730445
        },
        "gemma-2-27b-it": {
            "rating": 1242.5288799738228,
            "rating_q975": 1246.6057895990668,
            "rating_q025": 1238.4519703485787
        },
        "glm-4-0520": {
            "rating": 1241.8760429097338,
            "rating_q975": 1250.970435133214,
            "rating_q025": 1232.7816506862534
        },
        "command-r-plus-08-2024": {
            "rating": 1238.4059672650144,
            "rating_q975": 1246.6407861437772,
            "rating_q025": 1230.1711483862516
        },
        "nemotron-4-340b-instruct": {
            "rating": 1237.139422642764,
            "rating_q975": 1244.2537639136356,
            "rating_q025": 1230.0250813718924
        },
        "gemini-1.5-flash-8b-001": {
            "rating": 1232.205173666737,
            "rating_q975": 1237.5605035244141,
            "rating_q025": 1226.8498438090598
        },
        "phi-4": {
            "rating": 1231.5094557117507,
            "rating_q975": 1237.1107998171315,
            "rating_q025": 1225.9081116063699
        },
        "c4ai-aya-expanse-32b": {
            "rating": 1229.454683805092,
            "rating_q975": 1235.422939207329,
            "rating_q025": 1223.486428402855
        },
        "claude-3-sonnet-20240229": {
            "rating": 1226.6526564723972,
            "rating_q975": 1231.4634229094786,
            "rating_q025": 1221.8418900353158
        },
        "jamba-1.5-mini": {
            "rating": 1225.4134317496337,
            "rating_q975": 1234.3495622318767,
            "rating_q025": 1216.4773012673907
        },
        "amazon-nova-micro-v1.0": {
            "rating": 1224.9716661268124,
            "rating_q975": 1231.0573954720326,
            "rating_q025": 1218.8859367815921
        },
        "reka-flash-20240904": {
            "rating": 1223.5659433154492,
            "rating_q975": 1232.6060413566759,
            "rating_q025": 1214.5258452742225
        },
        "qwen2-72b-instruct": {
            "rating": 1222.655118546834,
            "rating_q975": 1228.563999626406,
            "rating_q025": 1216.746237467262
        },
        "gemma-2-9b-it": {
            "rating": 1220.4466611454263,
            "rating_q975": 1225.0061242936101,
            "rating_q025": 1215.8871979972425
        },
        "gpt-4-0314": {
            "rating": 1219.8678530320708,
            "rating_q975": 1225.613882733679,
            "rating_q025": 1214.1218233304626
        },
        "llama-3.1-8b-instruct": {
            "rating": 1218.5944428179628,
            "rating_q975": 1223.5627178105497,
            "rating_q025": 1213.626167825376
        },
        "hunyuan-standard-256k": {
            "rating": 1216.7172400477214,
            "rating_q975": 1232.8621331672925,
            "rating_q025": 1200.5723469281502
        },
        "llama-3.1-tulu-3-8b": {
            "rating": 1215.5625354863946,
            "rating_q975": 1229.1106441773666,
            "rating_q025": 1202.0144267954227
        },
        "yi-1.5-34b-chat": {
            "rating": 1215.0959258517241,
            "rating_q975": 1221.852699671398,
            "rating_q025": 1208.3391520320502
        },
        "llama-3-8b-instruct": {
            "rating": 1213.858965506546,
            "rating_q975": 1218.6170686321693,
            "rating_q025": 1209.1008623809225
        },
        "command-r-plus": {
            "rating": 1213.8276274618875,
            "rating_q975": 1219.0260822078149,
            "rating_q025": 1208.62917271596
        },
        "ministral-8b-2410": {
            "rating": 1212.8557272603884,
            "rating_q975": 1224.706175036947,
            "rating_q025": 1201.00527948383
        },
        "claude-3-haiku-20240307": {
            "rating": 1206.7569370113772,
            "rating_q975": 1211.4700105719555,
            "rating_q025": 1202.0438634507989
        },
        "gpt-4-0613": {
            "rating": 1205.9177518989077,
            "rating_q975": 1210.8644916621056,
            "rating_q025": 1200.9710121357098
        },
        "internlm2_5-20b-chat": {
            "rating": 1205.0007368677366,
            "rating_q975": 1214.1520465513124,
            "rating_q025": 1195.8494271841607
        },
        "mistral-large-2402": {
            "rating": 1200.2236534641552,
            "rating_q975": 1205.9572656212397,
            "rating_q025": 1194.4900413070707
        },
        "command-r-08-2024": {
            "rating": 1198.919110069518,
            "rating_q975": 1207.1531100600505,
            "rating_q025": 1190.6851100789854
        },
        "qwen1.5-110b-chat": {
            "rating": 1198.6560260142344,
            "rating_q975": 1205.8561174359945,
            "rating_q025": 1191.4559345924743
        },
        "deepseek-coder-v2": {
            "rating": 1195.095554218552,
            "rating_q975": 1203.0985371249847,
            "rating_q025": 1187.0925713121194
        },
        "c4ai-aya-expanse-8b": {
            "rating": 1192.5629763003215,
            "rating_q975": 1201.1431311209342,
            "rating_q025": 1183.9828214797087
        },
        "mistral-medium": {
            "rating": 1191.4066316848935,
            "rating_q975": 1197.804645268434,
            "rating_q025": 1185.008618101353
        },
        "granite-3.1-8b-instruct": {
            "rating": 1191.3784741342567,
            "rating_q975": 1205.212477374318,
            "rating_q025": 1177.5444708941955
        },
        "mixtral-8x22b-instruct-v0.1": {
            "rating": 1187.5763842904269,
            "rating_q975": 1193.1096462294122,
            "rating_q025": 1182.0431223514415
        },
        "qwen1.5-72b-chat": {
            "rating": 1187.3931040775856,
            "rating_q975": 1193.5871951707811,
            "rating_q025": 1181.19901298439
        },
        "qwq-32b-preview": {
            "rating": 1185.0748036668924,
            "rating_q975": 1199.6423529755864,
            "rating_q025": 1170.5072543581985
        },
        "gemma-2-2b-it": {
            "rating": 1182.446068450708,
            "rating_q975": 1187.2597714579952,
            "rating_q025": 1177.632365443421
        },
        "reka-flash-21b-20240226-online": {
            "rating": 1181.7269328034479,
            "rating_q975": 1190.7195359223642,
            "rating_q025": 1172.7343296845315
        },
        "llama-3.2-3b-instruct": {
            "rating": 1180.3949217766303,
            "rating_q975": 1189.9200495951443,
            "rating_q025": 1170.8697939581164
        },
        "reka-flash-21b-20240226": {
            "rating": 1179.7529798961732,
            "rating_q975": 1187.0688299785202,
            "rating_q025": 1172.4371298138262
        },
        "zephyr-orpo-141b-A35b-v0.1": {
            "rating": 1175.4532601221272,
            "rating_q975": 1188.6609892726788,
            "rating_q025": 1162.2455309715756
        },
        "command-r": {
            "rating": 1175.2245359258445,
            "rating_q975": 1181.06878609603,
            "rating_q025": 1169.380285755659
        },
        "granite-3.1-2b-instruct": {
            "rating": 1174.3443736829024,
            "rating_q975": 1188.5430762061083,
            "rating_q025": 1160.1456711596966
        },
        "phi-3-medium-4k-instruct": {
            "rating": 1169.6617588113086,
            "rating_q975": 1176.164181403254,
            "rating_q025": 1163.1593362193632
        },
        "mixtral-8x7b-instruct-v0.1": {
            "rating": 1168.4882617192516,
            "rating_q975": 1173.6599428018746,
            "rating_q025": 1163.3165806366285
        },
        "starling-lm-7b-beta": {
            "rating": 1163.2040376679481,
            "rating_q975": 1172.0502119392097,
            "rating_q025": 1154.3578633966865
        },
        "gemini-pro-dev-api": {
            "rating": 1162.6898643625411,
            "rating_q975": 1171.0918004645641,
            "rating_q025": 1154.2879282605181
        },
        "qwen1.5-32b-chat": {
            "rating": 1160.7831643311729,
            "rating_q975": 1168.405134504651,
            "rating_q025": 1153.1611941576948
        },
        "yi-34b-chat": {
            "rating": 1159.7627111027034,
            "rating_q975": 1167.6508617300362,
            "rating_q025": 1151.8745604753706
        },
        "llama-2-70b-chat": {
            "rating": 1157.008313021118,
            "rating_q975": 1163.4354088154232,
            "rating_q025": 1150.581217226813
        },
        "dbrx-instruct-preview": {
            "rating": 1155.8865644799666,
            "rating_q975": 1163.4078128247556,
            "rating_q025": 1148.3653161351776
        },
        "gemini-pro": {
            "rating": 1154.5544135368277,
            "rating_q975": 1167.2703026442468,
            "rating_q025": 1141.8385244294086
        },
        "phi-3-small-8k-instruct": {
            "rating": 1151.6501064190352,
            "rating_q975": 1159.473686318573,
            "rating_q025": 1143.8265265194973
        },
        "tulu-2-dpo-70b": {
            "rating": 1151.458738718528,
            "rating_q975": 1162.2647770665085,
            "rating_q025": 1140.6527003705473
        },
        "wizardlm-70b": {
            "rating": 1151.1671281514455,
            "rating_q975": 1161.4512156762746,
            "rating_q025": 1140.8830406266163
        },
        "granite-3.0-8b-instruct": {
            "rating": 1150.193583704232,
            "rating_q975": 1161.5860472962286,
            "rating_q025": 1138.8011201122354
        },
        "qwen1.5-14b-chat": {
            "rating": 1149.387286293675,
            "rating_q975": 1158.232786331261,
            "rating_q025": 1140.5417862560892
        },
        "nous-hermes-2-mixtral-8x7b-dpo": {
            "rating": 1140.7948352368899,
            "rating_q975": 1153.6871848604112,
            "rating_q025": 1127.9024856133685
        },
        "gpt-3.5-turbo-0125": {
            "rating": 1140.4222498947124,
            "rating_q975": 1145.9248902345207,
            "rating_q025": 1134.9196095549041
        },
        "starling-lm-7b-alpha": {
            "rating": 1139.840360440328,
            "rating_q975": 1148.851611681719,
            "rating_q025": 1130.8291091989367
        },
        "vicuna-33b": {
            "rating": 1134.7704368934076,
            "rating_q975": 1142.0368334836487,
            "rating_q025": 1127.5040403031664
        },
        "mistral-7b-instruct-v0.2": {
            "rating": 1134.7298342378344,
            "rating_q975": 1142.4058049606474,
            "rating_q025": 1127.0538635150215
        },
        "openchat-3.5-0106": {
            "rating": 1132.121844479316,
            "rating_q975": 1140.9133397927028,
            "rating_q025": 1123.3303491659292
        },
        "phi-3-mini-4k-instruct-june-2024": {
            "rating": 1128.8394197322705,
            "rating_q975": 1137.005918267411,
            "rating_q025": 1120.6729211971299
        },
        "openhermes-2.5-mistral-7b": {
            "rating": 1127.4610447707748,
            "rating_q975": 1139.0156749103521,
            "rating_q025": 1115.9064146311975
        },
        "deepseek-llm-67b-chat": {
            "rating": 1127.1777967454932,
            "rating_q975": 1140.070246065286,
            "rating_q025": 1114.2853474257004
        },
        "gemma-1.1-7b-it": {
            "rating": 1126.0777942665677,
            "rating_q975": 1133.182610994244,
            "rating_q025": 1118.9729775388914
        },
        "snowflake-arctic-instruct": {
            "rating": 1122.6363344955714,
            "rating_q975": 1130.065869472341,
            "rating_q025": 1115.2067995188017
        },
        "llama-2-13b-chat": {
            "rating": 1121.492426165953,
            "rating_q975": 1129.186295627239,
            "rating_q025": 1113.7985567046671
        },
        "llama2-70b-steerlm-chat": {
            "rating": 1121.1877949170525,
            "rating_q975": 1135.0349083129845,
            "rating_q025": 1107.3406815211206
        },
        "granite-3.0-2b-instruct": {
            "rating": 1120.4324603603477,
            "rating_q975": 1131.7892932817094,
            "rating_q025": 1109.075627438986
        },
        "llama-3.2-1b-instruct": {
            "rating": 1119.2628086628633,
            "rating_q975": 1128.8925537462276,
            "rating_q025": 1109.633063579499
        },
        "solar-10.7b-instruct-v1.0": {
            "rating": 1119.229370337103,
            "rating_q975": 1133.782100362656,
            "rating_q025": 1104.6766403115503
        },
        "openchat-3.5": {
            "rating": 1118.1571251356354,
            "rating_q975": 1128.865124467374,
            "rating_q025": 1107.4491258038968
        },
        "phi-3-mini-4k-instruct": {
            "rating": 1117.2322550238819,
            "rating_q975": 1125.2760560953213,
            "rating_q025": 1109.1884539524424
        },
        "gpt-3.5-turbo-1106": {
            "rating": 1113.7745737305972,
            "rating_q975": 1123.4480763647175,
            "rating_q025": 1104.101071096477
        },
        "dolphin-2.2.1-mistral-7b": {
            "rating": 1112.8381265657315,
            "rating_q975": 1129.8520044609097,
            "rating_q025": 1095.8242486705533
        },
        "zephyr-7b-beta": {
            "rating": 1108.1743774474946,
            "rating_q975": 1117.8018885800968,
            "rating_q025": 1098.5468663148924
        },
        "qwen1.5-7b-chat": {
            "rating": 1105.8380781258588,
            "rating_q975": 1117.0568023330188,
            "rating_q025": 1094.6193539186988
        },
        "mpt-30b-chat": {
            "rating": 1102.9937939699053,
            "rating_q975": 1116.815809299533,
            "rating_q025": 1089.1717786402776
        },
        "wizardlm-13b": {
            "rating": 1102.6769926847728,
            "rating_q975": 1113.1908245342092,
            "rating_q025": 1092.1631608353364
        },
        "smollm2-1.7b-instruct": {
            "rating": 1098.1050122882625,
            "rating_q975": 1116.8824255318289,
            "rating_q025": 1079.3275990446962
        },
        "llama-2-7b-chat": {
            "rating": 1096.6695809870591,
            "rating_q975": 1104.5946507305898,
            "rating_q025": 1088.7445112435284
        },
        "codellama-70b-instruct": {
            "rating": 1096.167104133605,
            "rating_q975": 1118.4515060709755,
            "rating_q025": 1073.8827021962347
        },
        "zephyr-7b-alpha": {
            "rating": 1093.9440473673612,
            "rating_q975": 1111.600745425392,
            "rating_q025": 1076.2873493093305
        },
        "codellama-34b-instruct": {
            "rating": 1092.862784831042,
            "rating_q975": 1102.5743460498386,
            "rating_q025": 1083.1512236122455
        },
        "gemma-7b-it": {
            "rating": 1090.7426781230647,
            "rating_q975": 1101.8928031665062,
            "rating_q025": 1079.5925530796233
        },
        "guanaco-33b": {
            "rating": 1086.778888847255,
            "rating_q975": 1100.3691786357645,
            "rating_q025": 1073.1885990587457
        },
        "phi-3-mini-128k-instruct": {
            "rating": 1084.5435981713345,
            "rating_q975": 1093.4644370377086,
            "rating_q025": 1075.6227593049603
        },
        "vicuna-13b": {
            "rating": 1082.058325202408,
            "rating_q975": 1089.5670784553138,
            "rating_q025": 1074.5495719495023
        },
        "falcon-180b-chat": {
            "rating": 1082.0272936704162,
            "rating_q975": 1101.0156781767441,
            "rating_q025": 1063.0389091640882
        },
        "stripedhyena-nous-7b": {
            "rating": 1071.2655600015619,
            "rating_q975": 1083.2810149986321,
            "rating_q025": 1059.2501050044916
        },
        "qwen-14b-chat": {
            "rating": 1069.3826972301604,
            "rating_q975": 1081.332354213543,
            "rating_q025": 1057.4330402467776
        },
        "olmo-7b-instruct": {
            "rating": 1068.144274800657,
            "rating_q975": 1081.1224820711882,
            "rating_q025": 1055.166067530126
        },
        "palm-2": {
            "rating": 1064.5988870218484,
            "rating_q975": 1074.6894260748581,
            "rating_q025": 1054.5083479688387
        },
        "mistral-7b-instruct": {
            "rating": 1060.7487761644754,
            "rating_q975": 1070.9385426870474,
            "rating_q025": 1050.5590096419035
        },
        "vicuna-7b": {
            "rating": 1052.9907383369055,
            "rating_q975": 1063.0386298954556,
            "rating_q025": 1042.9428467783553
        },
        "gemma-1.1-2b-it": {
            "rating": 1051.825958440457,
            "rating_q975": 1061.5401261948023,
            "rating_q025": 1042.1117906861118
        },
        "gemma-2b-it": {
            "rating": 1033.551690505223,
            "rating_q975": 1046.9476324397951,
            "rating_q025": 1020.1557485706508
        },
        "koala-13b": {
            "rating": 1023.0320037318138,
            "rating_q975": 1034.3476394866213,
            "rating_q025": 1011.7163679770064
        },
        "qwen1.5-4b-chat": {
            "rating": 1016.0258832136809,
            "rating_q975": 1026.9214587271244,
            "rating_q025": 1005.1303077002374
        },
        "chatglm3-6b": {
            "rating": 1004.3753704060083,
            "rating_q975": 1017.2058205336325,
            "rating_q025": 991.5449202783841
        },
        "gpt4all-13b-snoozy": {
            "rating": 989.5808418898794,
            "rating_q975": 1006.7887957371452,
            "rating_q025": 972.3728880426136
        },
        "mpt-7b-chat": {
            "rating": 982.1358443021127,
            "rating_q975": 995.2619296866086,
            "rating_q025": 969.0097589176168
        },
        "chatglm2-6b": {
            "rating": 975.5261890244012,
            "rating_q975": 990.6213234516771,
            "rating_q025": 960.4310545971254
        },
        "RWKV-4-Raven-14B": {
            "rating": 969.7465560294145,
            "rating_q975": 982.5541829249308,
            "rating_q025": 956.9389291338981
        },
        "alpaca-13b": {
            "rating": 959.1708181247661,
            "rating_q975": 971.7152321821087,
            "rating_q025": 946.6264040674236
        },
        "oasst-pythia-12b": {
            "rating": 947.0036787175479,
            "rating_q975": 959.0009971788189,
            "rating_q025": 935.0063602562769
        },
        "chatglm-6b": {
            "rating": 939.9516435726179,
            "rating_q975": 953.6704748181248,
            "rating_q025": 926.2328123271109
        },
        "fastchat-t5-3b": {
            "rating": 936.5882498618598,
            "rating_q975": 950.1738385155118,
            "rating_q025": 923.0026612082079
        },
        "stablelm-tuned-alpha-7b": {
            "rating": 891.9806298298731,
            "rating_q975": 906.2936114666095,
            "rating_q025": 877.6676481931368
        },
        "dolly-v2-12b": {
            "rating": 869.2079896707002,
            "rating_q975": 884.2792112982593,
            "rating_q025": 854.136768043141
        },
        "llama-13b": {
            "rating": 847.0950639980717,
            "rating_q975": 864.5250817936368,
            "rating_q025": 829.6650462025067
        }
    },
    "expert": {
        "claude-opus-4-5-20251101": {
            "rating": 1531.5010799991023,
            "rating_q975": 1558.7453043304415,
            "rating_q025": 1504.2568556677631
        },
        "claude-sonnet-4-5-20250929-thinking-32k": {
            "rating": 1484.1859940209972,
            "rating_q975": 1501.076804950818,
            "rating_q025": 1467.2951830911763
        },
        "claude-opus-4-5-20251101-thinking-32k": {
            "rating": 1478.350292131722,
            "rating_q975": 1505.597098441574,
            "rating_q025": 1451.10348582187
        },
        "gemini-3-pro": {
            "rating": 1475.2475557967539,
            "rating_q975": 1495.8177031756195,
            "rating_q025": 1454.6774084178883
        },
        "gpt-5.1-high": {
            "rating": 1467.6858622509594,
            "rating_q975": 1491.3814626855208,
            "rating_q025": 1443.990261816398
        },
        "claude-sonnet-4-5-20250929": {
            "rating": 1465.161977782422,
            "rating_q975": 1483.5802827013697,
            "rating_q025": 1446.743672863474
        },
        "gemini-2.5-pro": {
            "rating": 1460.324709274125,
            "rating_q975": 1470.912363633455,
            "rating_q025": 1449.7370549147952
        },
        "qwen3-max-preview": {
            "rating": 1456.6448967012832,
            "rating_q975": 1473.686763463669,
            "rating_q025": 1439.6030299388974
        },
        "qwen3-235b-a22b-thinking-2507": {
            "rating": 1453.7467361244617,
            "rating_q975": 1481.9085118559985,
            "rating_q025": 1425.5849603929248
        },
        "gpt-5.1": {
            "rating": 1444.79249215822,
            "rating_q975": 1466.118821716586,
            "rating_q025": 1423.4661625998542
        },
        "qwen3-235b-a22b-instruct-2507": {
            "rating": 1443.4179728831004,
            "rating_q975": 1456.1375519870192,
            "rating_q025": 1430.6983937791817
        },
        "qwen3-vl-235b-a22b-instruct": {
            "rating": 1437.3547150736288,
            "rating_q975": 1464.4092772691404,
            "rating_q025": 1410.3001528781172
        },
        "grok-4.1-thinking": {
            "rating": 1437.059571056744,
            "rating_q975": 1457.9112663518158,
            "rating_q025": 1416.2078757616723
        },
        "claude-opus-4-1-20250805-thinking-16k": {
            "rating": 1435.818363867176,
            "rating_q975": 1449.8559649017707,
            "rating_q025": 1421.7807628325813
        },
        "longcat-flash-chat": {
            "rating": 1433.8253344330126,
            "rating_q975": 1459.743078133682,
            "rating_q025": 1407.9075907323431
        },
        "gemini-2.5-flash": {
            "rating": 1431.5265499319269,
            "rating_q975": 1441.7606743629017,
            "rating_q025": 1421.292425500952
        },
        "glm-4.6": {
            "rating": 1429.6786491390787,
            "rating_q975": 1447.3835441564145,
            "rating_q025": 1411.973754121743
        },
        "gemini-2.5-flash-preview-09-2025": {
            "rating": 1427.2269954783633,
            "rating_q975": 1443.5349991948192,
            "rating_q025": 1410.9189917619074
        },
        "glm-4.5": {
            "rating": 1426.9725808923706,
            "rating_q975": 1444.7617382726883,
            "rating_q025": 1409.183423512053
        },
        "qwen3-vl-235b-a22b-thinking": {
            "rating": 1425.2076929644722,
            "rating_q975": 1455.3530689313127,
            "rating_q025": 1395.0623169976318
        },
        "claude-haiku-4-5-20251001": {
            "rating": 1421.4266312155887,
            "rating_q975": 1438.1224191475767,
            "rating_q025": 1404.7308432836007
        },
        "kimi-k2-thinking-turbo": {
            "rating": 1419.9961647105413,
            "rating_q975": 1441.6044794961617,
            "rating_q025": 1398.3878499249208
        },
        "gpt-5-high": {
            "rating": 1419.574133837832,
            "rating_q975": 1435.078290464126,
            "rating_q025": 1404.0699772115381
        },
        "grok-3-preview-02-24": {
            "rating": 1417.1606383687213,
            "rating_q975": 1432.0293120156748,
            "rating_q025": 1402.2919647217677
        },
        "grok-4-0709": {
            "rating": 1415.7024165680739,
            "rating_q975": 1429.2583713975598,
            "rating_q025": 1402.146461738588
        },
        "claude-opus-4-1-20250805": {
            "rating": 1415.1877006487666,
            "rating_q975": 1427.6625162688779,
            "rating_q025": 1402.7128850286554
        },
        "ernie-5.0-preview-1103": {
            "rating": 1412.5107312362525,
            "rating_q975": 1444.116282154073,
            "rating_q025": 1380.905180318432
        },
        "qwen3-next-80b-a3b-instruct": {
            "rating": 1411.3935567680153,
            "rating_q975": 1429.912821823587,
            "rating_q025": 1392.8742917124437
        },
        "grok-4.1": {
            "rating": 1409.58111098644,
            "rating_q975": 1429.5988226506481,
            "rating_q025": 1389.563399322232
        },
        "grok-4-1-fast-reasoning": {
            "rating": 1408.9871435705322,
            "rating_q975": 1439.018083114964,
            "rating_q025": 1378.9562040261005
        },
        "deepseek-v3.2-exp-thinking": {
            "rating": 1406.0376849222341,
            "rating_q975": 1435.417664724236,
            "rating_q025": 1376.6577051202323
        },
        "deepseek-v3.1": {
            "rating": 1406.0342400445168,
            "rating_q975": 1428.1276092710266,
            "rating_q025": 1383.940870818007
        },
        "grok-4-fast-chat": {
            "rating": 1405.5775198346294,
            "rating_q975": 1439.2531666871407,
            "rating_q025": 1371.901872982118
        },
        "qwen3-max-2025-09-23": {
            "rating": 1405.3496806596636,
            "rating_q975": 1432.2487932618071,
            "rating_q025": 1378.45056805752
        },
        "gpt-5-chat": {
            "rating": 1403.4611977727432,
            "rating_q975": 1419.0655667398287,
            "rating_q025": 1387.8568288056576
        },
        "deepseek-v3.1-thinking": {
            "rating": 1403.3866855763308,
            "rating_q975": 1428.3972487683554,
            "rating_q025": 1378.3761223843062
        },
        "deepseek-v3.2-exp": {
            "rating": 1402.2216863767655,
            "rating_q975": 1426.147175807676,
            "rating_q025": 1378.2961969458552
        },
        "deepseek-v3.2": {
            "rating": 1402.120065555759,
            "rating_q975": 1435.835092967147,
            "rating_q025": 1368.4050381443712
        },
        "grok-4-fast-reasoning": {
            "rating": 1401.370908260277,
            "rating_q975": 1421.5121825675556,
            "rating_q025": 1381.2296339529985
        },
        "mistral-medium-2508": {
            "rating": 1400.351122389437,
            "rating_q975": 1413.5429116823354,
            "rating_q025": 1387.1593330965386
        },
        "o3-2025-04-16": {
            "rating": 1398.6336599832916,
            "rating_q975": 1410.1190504637275,
            "rating_q025": 1387.1482695028558
        },
        "chatgpt-4o-latest-20250326": {
            "rating": 1395.1821423564872,
            "rating_q975": 1406.2148661828799,
            "rating_q025": 1384.1494185300946
        },
        "deepseek-v3.2-thinking": {
            "rating": 1393.217937014366,
            "rating_q975": 1428.1050757808403,
            "rating_q025": 1358.3307982478918
        },
        "gpt-4.5-preview-2025-02-27": {
            "rating": 1392.078422371018,
            "rating_q975": 1415.3278578258803,
            "rating_q025": 1368.8289869161556
        },
        "mistral-large-3": {
            "rating": 1390.8968034326538,
            "rating_q975": 1422.3945955889055,
            "rating_q025": 1359.399011276402
        },
        "deepseek-r1-0528": {
            "rating": 1389.3123017393796,
            "rating_q975": 1408.5489783280727,
            "rating_q025": 1370.0756251506864
        },
        "grok-3-mini-high": {
            "rating": 1386.3509518796445,
            "rating_q975": 1404.949907817468,
            "rating_q025": 1367.751995941821
        },
        "hunyuan-t1-20250711": {
            "rating": 1386.1820245988708,
            "rating_q975": 1424.9856549172341,
            "rating_q025": 1347.3783942805076
        },
        "qwen3-30b-a3b-instruct-2507": {
            "rating": 1386.016125194767,
            "rating_q975": 1403.1631463162184,
            "rating_q025": 1368.8691040733156
        },
        "mai-1-preview": {
            "rating": 1381.1848892275334,
            "rating_q975": 1402.0176647953278,
            "rating_q025": 1360.352113659739
        },
        "claude-opus-4-20250514-thinking-16k": {
            "rating": 1380.3602919819675,
            "rating_q975": 1394.8393532241455,
            "rating_q025": 1365.8812307397895
        },
        "gpt-5-mini-high": {
            "rating": 1379.1726564305873,
            "rating_q975": 1397.3371081371029,
            "rating_q025": 1361.0082047240717
        },
        "amazon-nova-experimental-chat-10-20": {
            "rating": 1375.6067444765342,
            "rating_q975": 1403.6232355613884,
            "rating_q025": 1347.59025339168
        },
        "gemini-2.5-flash-lite-preview-09-2025-no-thinking": {
            "rating": 1374.127583093042,
            "rating_q975": 1390.1386099663137,
            "rating_q025": 1358.1165562197702
        },
        "claude-sonnet-4-20250514-thinking-32k": {
            "rating": 1372.1383046901324,
            "rating_q975": 1386.6931361524814,
            "rating_q025": 1357.5834732277833
        },
        "nova-2-lite": {
            "rating": 1370.1447429532493,
            "rating_q975": 1403.3563512509832,
            "rating_q025": 1336.9331346555155
        },
        "kimi-k2-0905-preview": {
            "rating": 1369.0283790709714,
            "rating_q975": 1394.4584838221117,
            "rating_q025": 1343.598274319831
        },
        "qwen3-next-80b-a3b-thinking": {
            "rating": 1368.774860171728,
            "rating_q975": 1392.658058796618,
            "rating_q025": 1344.8916615468381
        },
        "qwen3-235b-a22b-no-thinking": {
            "rating": 1368.4356604695477,
            "rating_q975": 1382.1897976735488,
            "rating_q025": 1354.6815232655465
        },
        "glm-4.5-air": {
            "rating": 1368.3154983466006,
            "rating_q975": 1384.2199262970873,
            "rating_q025": 1352.411070396114
        },
        "claude-opus-4-20250514": {
            "rating": 1364.740717594686,
            "rating_q975": 1377.3224091555417,
            "rating_q025": 1352.1590260338303
        },
        "gemini-2.5-flash-lite-preview-06-17-thinking": {
            "rating": 1364.396988857147,
            "rating_q975": 1378.9922479991315,
            "rating_q025": 1349.8017297151628
        },
        "o3-mini-high": {
            "rating": 1360.921400830486,
            "rating_q975": 1380.9898078509382,
            "rating_q025": 1340.8529938100337
        },
        "qwen3-32b": {
            "rating": 1360.91689163696,
            "rating_q975": 1397.9291039352324,
            "rating_q025": 1323.9046793386874
        },
        "glm-4.5v": {
            "rating": 1360.5150122284185,
            "rating_q975": 1402.4706842678017,
            "rating_q025": 1318.5593401890353
        },
        "gpt-4.1-2025-04-14": {
            "rating": 1360.1912179661301,
            "rating_q975": 1372.0862865058004,
            "rating_q025": 1348.2961494264598
        },
        "o1-2024-12-17": {
            "rating": 1359.5993657620752,
            "rating_q975": 1376.051999607741,
            "rating_q025": 1343.1467319164094
        },
        "amazon-nova-experimental-chat-10-09": {
            "rating": 1359.492976670073,
            "rating_q975": 1388.6353779050498,
            "rating_q025": 1330.350575435096
        },
        "grok-3-mini-beta": {
            "rating": 1358.5680245670237,
            "rating_q975": 1375.3380448283967,
            "rating_q025": 1341.7980043056507
        },
        "gpt-oss-120b": {
            "rating": 1356.370488292347,
            "rating_q975": 1372.8284057614353,
            "rating_q025": 1339.9125708232589
        },
        "ling-flash-2.0": {
            "rating": 1353.5960862150596,
            "rating_q975": 1383.3552567051277,
            "rating_q025": 1323.8369157249915
        },
        "deepseek-v3-0324": {
            "rating": 1347.2717189064167,
            "rating_q975": 1359.6743944262137,
            "rating_q025": 1334.8690433866198
        },
        "qwen3-235b-a22b": {
            "rating": 1346.149244387532,
            "rating_q975": 1362.0427207927585,
            "rating_q025": 1330.2557679823055
        },
        "o4-mini-2025-04-16": {
            "rating": 1344.958862336576,
            "rating_q975": 1357.4779124873844,
            "rating_q025": 1332.4398121857676
        },
        "kimi-k2-0711-preview": {
            "rating": 1343.4155334131278,
            "rating_q975": 1358.958192075481,
            "rating_q025": 1327.8728747507746
        },
        "mistral-medium-2505": {
            "rating": 1342.2639514815053,
            "rating_q975": 1355.7652984594824,
            "rating_q025": 1328.762604503528
        },
        "hunyuan-turbos-20250416": {
            "rating": 1339.4316935091922,
            "rating_q975": 1362.6823436696743,
            "rating_q025": 1316.18104334871
        },
        "ring-flash-2.0": {
            "rating": 1337.6385967966319,
            "rating_q975": 1369.035198856332,
            "rating_q025": 1306.2419947369317
        },
        "gpt-4.1-mini-2025-04-14": {
            "rating": 1337.148850170397,
            "rating_q975": 1350.1941897704353,
            "rating_q025": 1324.1035105703588
        },
        "gemini-2.0-flash-001": {
            "rating": 1336.8668500395247,
            "rating_q975": 1349.091469661227,
            "rating_q025": 1324.6422304178225
        },
        "qwen3-coder-480b-a35b-instruct": {
            "rating": 1336.045530670026,
            "rating_q975": 1352.5807204260996,
            "rating_q025": 1319.5103409139524
        },
        "o1-preview": {
            "rating": 1335.4118254319733,
            "rating_q975": 1349.2956648998354,
            "rating_q025": 1321.5279859641112
        },
        "deepseek-r1": {
            "rating": 1334.409691444196,
            "rating_q975": 1353.7049739061895,
            "rating_q025": 1315.1144089822023
        },
        "claude-sonnet-4-20250514": {
            "rating": 1333.5294043209271,
            "rating_q975": 1346.774788357002,
            "rating_q025": 1320.2840202848522
        },
        "qwen2.5-max": {
            "rating": 1333.318210979978,
            "rating_q975": 1346.7113348448845,
            "rating_q025": 1319.9250871150714
        },
        "step-3": {
            "rating": 1329.0685714551041,
            "rating_q975": 1364.4268492726092,
            "rating_q025": 1293.710293637599
        },
        "o3-mini": {
            "rating": 1328.9667400827104,
            "rating_q975": 1340.0909350347981,
            "rating_q025": 1317.8425451306227
        },
        "nvidia-llama-3.3-nemotron-super-49b-v1.5": {
            "rating": 1326.4971945103734,
            "rating_q975": 1365.404965308788,
            "rating_q025": 1287.589423711959
        },
        "qwen-plus-0125": {
            "rating": 1325.4684189648958,
            "rating_q975": 1355.0154046021607,
            "rating_q025": 1295.921433327631
        },
        "gpt-5-nano-high": {
            "rating": 1323.671475120482,
            "rating_q975": 1357.102151829052,
            "rating_q025": 1290.240798411912
        },
        "minimax-m1": {
            "rating": 1323.6269985881859,
            "rating_q975": 1338.1276130531671,
            "rating_q025": 1309.1263841232046
        },
        "qwq-32b": {
            "rating": 1322.6047098821593,
            "rating_q975": 1339.0858035350554,
            "rating_q025": 1306.1236162292632
        },
        "claude-3-7-sonnet-20250219-thinking-32k": {
            "rating": 1318.66892476463,
            "rating_q975": 1332.482557390413,
            "rating_q025": 1304.855292138847
        },
        "o1-mini": {
            "rating": 1313.5330813049518,
            "rating_q975": 1324.3695341740797,
            "rating_q025": 1302.6966284358239
        },
        "minimax-m2": {
            "rating": 1313.4234533172455,
            "rating_q975": 1349.5497868495067,
            "rating_q025": 1277.2971197849843
        },
        "qwen3-30b-a3b": {
            "rating": 1312.9919002522895,
            "rating_q975": 1329.0735670859845,
            "rating_q025": 1296.9102334185945
        },
        "deepseek-v3": {
            "rating": 1302.5120601825429,
            "rating_q975": 1318.5073504648549,
            "rating_q025": 1286.5167699002309
        },
        "step-1o-turbo-202506": {
            "rating": 1302.4356826854653,
            "rating_q975": 1328.6664339691629,
            "rating_q025": 1276.2049314017677
        },
        "gemini-2.0-flash-lite-preview-02-05": {
            "rating": 1302.404440392733,
            "rating_q975": 1318.391598123616,
            "rating_q025": 1286.41728266185
        },
        "gemma-3-27b-it": {
            "rating": 1300.87138964456,
            "rating_q975": 1313.325693011005,
            "rating_q025": 1288.417086278115
        },
        "claude-3-7-sonnet-20250219": {
            "rating": 1296.9158137401525,
            "rating_q975": 1309.7897417258087,
            "rating_q025": 1284.0418857544964
        },
        "command-a-03-2025": {
            "rating": 1290.452594256522,
            "rating_q975": 1301.7917631457087,
            "rating_q025": 1279.1134253673351
        },
        "mistral-small-2506": {
            "rating": 1289.3150366632237,
            "rating_q975": 1308.5992410471804,
            "rating_q025": 1270.030832279267
        },
        "qwen2.5-plus-1127": {
            "rating": 1286.8814325429262,
            "rating_q975": 1307.5299998141513,
            "rating_q025": 1266.232865271701
        },
        "yi-lightning": {
            "rating": 1282.736770147268,
            "rating_q975": 1296.7333598207044,
            "rating_q025": 1268.7401804738317
        },
        "glm-4-plus-0111": {
            "rating": 1277.4215351616526,
            "rating_q975": 1306.6420052682497,
            "rating_q025": 1248.2010650550556
        },
        "gemini-1.5-pro-002": {
            "rating": 1276.0860415408633,
            "rating_q975": 1286.2374222287442,
            "rating_q025": 1265.9346608529825
        },
        "step-2-16k-exp-202412": {
            "rating": 1276.0308880979967,
            "rating_q975": 1306.8663006217337,
            "rating_q025": 1245.1954755742597
        },
        "hunyuan-large-2025-02-10": {
            "rating": 1273.2350337285934,
            "rating_q975": 1309.523734048491,
            "rating_q025": 1236.9463334086959
        },
        "gpt-4.1-nano-2025-04-14": {
            "rating": 1269.8883196915308,
            "rating_q975": 1300.3676110343874,
            "rating_q025": 1239.4090283486742
        },
        "athene-v2-chat": {
            "rating": 1265.577372687354,
            "rating_q975": 1279.9422333284635,
            "rating_q025": 1251.2125120462445
        },
        "deepseek-v2.5-1210": {
            "rating": 1263.8990455914409,
            "rating_q975": 1289.760629353554,
            "rating_q025": 1238.0374618293279
        },
        "claude-3-5-sonnet-20241022": {
            "rating": 1263.523718611894,
            "rating_q975": 1271.856959737063,
            "rating_q025": 1255.190477486725
        },
        "mistral-small-3.1-24b-instruct-2503": {
            "rating": 1263.2251033872928,
            "rating_q975": 1278.2542995214626,
            "rating_q025": 1248.195907253123
        },
        "gpt-oss-20b": {
            "rating": 1260.5642892485675,
            "rating_q975": 1288.2639877405131,
            "rating_q025": 1232.864590756622
        },
        "llama-4-maverick-17b-128e-instruct": {
            "rating": 1260.2494245690586,
            "rating_q975": 1273.5575801358764,
            "rating_q025": 1246.941269002241
        },
        "hunyuan-large-vision": {
            "rating": 1257.779442775737,
            "rating_q975": 1291.4811783774774,
            "rating_q025": 1224.0777071739965
        },
        "grok-2-2024-08-13": {
            "rating": 1251.3047969355268,
            "rating_q975": 1261.314210510837,
            "rating_q025": 1241.2953833602166
        },
        "glm-4-plus": {
            "rating": 1250.0695242502538,
            "rating_q975": 1264.1582705375688,
            "rating_q025": 1235.9807779629389
        },
        "gemma-3n-e4b-it": {
            "rating": 1247.8314572830743,
            "rating_q975": 1265.5967379858655,
            "rating_q025": 1230.0661765802831
        },
        "gpt-4o-2024-05-13": {
            "rating": 1247.4620384058135,
            "rating_q975": 1256.6877004601763,
            "rating_q025": 1238.2363763514506
        },
        "gemma-3-12b-it": {
            "rating": 1246.2486103785327,
            "rating_q975": 1287.5327104897408,
            "rating_q025": 1204.9645102673246
        },
        "qwen-max-0919": {
            "rating": 1245.6743161857526,
            "rating_q975": 1263.2353476802925,
            "rating_q025": 1228.1132846912126
        },
        "hunyuan-standard-2025-02-10": {
            "rating": 1245.3041529660168,
            "rating_q975": 1284.637282898398,
            "rating_q025": 1205.9710230336354
        },
        "claude-3-5-sonnet-20240620": {
            "rating": 1244.9251078215477,
            "rating_q975": 1255.1484974147982,
            "rating_q025": 1234.7017182282973
        },
        "qwen2.5-72b-instruct": {
            "rating": 1243.140003710524,
            "rating_q975": 1254.5099534600952,
            "rating_q025": 1231.770053960953
        },
        "gemini-1.5-pro-001": {
            "rating": 1242.4043928086971,
            "rating_q975": 1253.6381121957866,
            "rating_q025": 1231.1706734216077
        },
        "llama-3.1-405b-instruct-fp8": {
            "rating": 1240.571099348498,
            "rating_q975": 1251.1254328949506,
            "rating_q025": 1230.0167658020453
        },
        "llama-3.1-nemotron-70b-instruct": {
            "rating": 1239.9928282543215,
            "rating_q975": 1266.70693575824,
            "rating_q025": 1213.278720750403
        },
        "gpt-4o-2024-08-06": {
            "rating": 1238.1666198057603,
            "rating_q975": 1250.0872358045033,
            "rating_q025": 1226.2460038070174
        },
        "deepseek-v2.5": {
            "rating": 1237.6191151221237,
            "rating_q975": 1251.7369021605616,
            "rating_q025": 1223.5013280836858
        },
        "grok-2-mini-2024-08-13": {
            "rating": 1235.4498173413758,
            "rating_q975": 1246.3367279753488,
            "rating_q025": 1224.5629067074028
        },
        "llama-4-scout-17b-16e-instruct": {
            "rating": 1235.2203146105117,
            "rating_q975": 1250.842460130724,
            "rating_q025": 1219.5981690902993
        },
        "gpt-4o-mini-2024-07-18": {
            "rating": 1231.2690102345375,
            "rating_q975": 1241.1519437753236,
            "rating_q025": 1221.3860766937514
        },
        "gemini-1.5-flash-002": {
            "rating": 1230.7238454794765,
            "rating_q975": 1243.0916294369963,
            "rating_q025": 1218.3560615219567
        },
        "mistral-large-2407": {
            "rating": 1229.5618758304988,
            "rating_q975": 1241.3373103793754,
            "rating_q025": 1217.7864412816223
        },
        "llama-3.1-405b-instruct-bf16": {
            "rating": 1226.6401934614091,
            "rating_q975": 1238.8323552567908,
            "rating_q025": 1214.4480316660274
        },
        "athene-70b-0725": {
            "rating": 1225.6642310950579,
            "rating_q975": 1244.5602440781083,
            "rating_q025": 1206.7682181120074
        },
        "llama-3.3-70b-instruct": {
            "rating": 1222.4879704068626,
            "rating_q975": 1233.0304978577353,
            "rating_q025": 1211.9454429559898
        },
        "magistral-medium-2506": {
            "rating": 1221.7546443995311,
            "rating_q975": 1248.2111546343144,
            "rating_q025": 1195.2981341647478
        },
        "gpt-4-turbo-2024-04-09": {
            "rating": 1221.4980427178725,
            "rating_q975": 1231.7211576982425,
            "rating_q025": 1211.2749277375026
        },
        "gemma-3-4b-it": {
            "rating": 1220.9296540518724,
            "rating_q975": 1262.7062653261914,
            "rating_q025": 1179.1530427775533
        },
        "claude-3-opus-20240229": {
            "rating": 1220.3512347211415,
            "rating_q975": 1228.6130310654903,
            "rating_q025": 1212.0894383767927
        },
        "qwen2.5-coder-32b-instruct": {
            "rating": 1218.5905461495058,
            "rating_q975": 1251.304973702807,
            "rating_q025": 1185.8761185962046
        },
        "jamba-1.5-large": {
            "rating": 1215.3589517689581,
            "rating_q975": 1244.3111096171413,
            "rating_q025": 1186.406793920775
        },
        "gemini-advanced-0514": {
            "rating": 1212.3751783592184,
            "rating_q975": 1226.1133620869098,
            "rating_q025": 1198.636994631527
        },
        "reka-core-20240904": {
            "rating": 1210.6003044250645,
            "rating_q975": 1235.1003682123674,
            "rating_q025": 1186.1002406377615
        },
        "gpt-4-1106-preview": {
            "rating": 1208.7838577231678,
            "rating_q975": 1219.943844200989,
            "rating_q025": 1197.6238712453467
        },
        "amazon-nova-pro-v1.0": {
            "rating": 1208.5926824612625,
            "rating_q975": 1223.8529668132376,
            "rating_q025": 1193.3323981092874
        },
        "llama-3.1-70b-instruct": {
            "rating": 1206.161964585509,
            "rating_q975": 1216.838706799603,
            "rating_q025": 1195.485222371415
        },
        "mistral-large-2411": {
            "rating": 1205.6977126238567,
            "rating_q975": 1220.0529839182411,
            "rating_q025": 1191.3424413294722
        },
        "claude-3-5-haiku-20241022": {
            "rating": 1204.9070274436167,
            "rating_q975": 1215.0265986224547,
            "rating_q025": 1194.7874562647787
        },
        "gpt-4-0125-preview": {
            "rating": 1203.330087225338,
            "rating_q975": 1214.508783211819,
            "rating_q025": 1192.151391238857
        },
        "phi-4": {
            "rating": 1200.785146166667,
            "rating_q975": 1217.6030868534888,
            "rating_q025": 1183.967205479845
        },
        "amazon-nova-lite-v1.0": {
            "rating": 1199.2106552710504,
            "rating_q975": 1215.4314077831016,
            "rating_q025": 1182.9899027589993
        },
        "mistral-small-24b-instruct-2501": {
            "rating": 1198.9405423716084,
            "rating_q975": 1219.23883452102,
            "rating_q025": 1178.642250222197
        },
        "gemini-1.5-flash-001": {
            "rating": 1196.95052212181,
            "rating_q975": 1208.5343202742467,
            "rating_q025": 1185.3667239693734
        },
        "gemini-1.5-flash-8b-001": {
            "rating": 1182.9993174714891,
            "rating_q975": 1195.3287877233297,
            "rating_q025": 1170.6698472196485
        },
        "amazon-nova-micro-v1.0": {
            "rating": 1180.9949410060265,
            "rating_q975": 1197.7983115089567,
            "rating_q025": 1164.1915705030963
        },
        "c4ai-aya-expanse-32b": {
            "rating": 1179.756076342474,
            "rating_q975": 1192.9784574597738,
            "rating_q025": 1166.5336952251741
        },
        "deepseek-coder-v2": {
            "rating": 1179.6742928615759,
            "rating_q975": 1200.6692939347397,
            "rating_q025": 1158.679291788412
        },
        "reka-flash-20240904": {
            "rating": 1179.5795739921498,
            "rating_q975": 1202.4740040494469,
            "rating_q025": 1156.6851439348527
        },
        "glm-4-0520": {
            "rating": 1176.1622395259901,
            "rating_q975": 1200.5042013942366,
            "rating_q025": 1151.8202776577436
        },
        "command-r-plus-08-2024": {
            "rating": 1171.2431261928218,
            "rating_q975": 1195.331938090589,
            "rating_q025": 1147.1543142950547
        },
        "claude-3-sonnet-20240229": {
            "rating": 1169.742628879922,
            "rating_q975": 1180.782524117927,
            "rating_q025": 1158.702733641917
        },
        "qwen2-72b-instruct": {
            "rating": 1168.8085365747343,
            "rating_q975": 1182.845335470078,
            "rating_q025": 1154.7717376793905
        },
        "gemma-2-27b-it": {
            "rating": 1168.6830267168575,
            "rating_q975": 1178.224717580978,
            "rating_q025": 1159.141335852737
        },
        "nemotron-4-340b-instruct": {
            "rating": 1168.1264482500112,
            "rating_q975": 1186.39382984591,
            "rating_q025": 1149.8590666541124
        },
        "ministral-8b-2410": {
            "rating": 1167.504531703811,
            "rating_q975": 1197.176310966315,
            "rating_q025": 1137.8327524413069
        },
        "llama-3.1-nemotron-51b-instruct": {
            "rating": 1164.7031893046064,
            "rating_q975": 1197.7305807696637,
            "rating_q025": 1131.6757978395492
        },
        "gemma-2-9b-it-simpo": {
            "rating": 1152.616892087581,
            "rating_q975": 1181.939279163306,
            "rating_q025": 1123.2945050118558
        },
        "c4ai-aya-expanse-8b": {
            "rating": 1151.1444616196309,
            "rating_q975": 1174.301828863356,
            "rating_q025": 1127.9870943759058
        },
        "command-r-plus": {
            "rating": 1150.915919900117,
            "rating_q975": 1162.5572574785244,
            "rating_q025": 1139.2745823217094
        },
        "internlm2_5-20b-chat": {
            "rating": 1148.2407161388228,
            "rating_q975": 1169.9006676618808,
            "rating_q025": 1126.5807646157648
        },
        "llama-3-70b-instruct": {
            "rating": 1147.0976170380327,
            "rating_q975": 1157.0591239008222,
            "rating_q025": 1137.1361101752432
        },
        "gpt-4-0314": {
            "rating": 1146.4641889787717,
            "rating_q975": 1161.2206832895827,
            "rating_q025": 1131.7076946679608
        },
        "claude-3-haiku-20240307": {
            "rating": 1145.2800822661418,
            "rating_q975": 1155.2242256341294,
            "rating_q025": 1135.3359388981542
        },
        "gemma-2-9b-it": {
            "rating": 1144.5733127152694,
            "rating_q975": 1155.6061517512635,
            "rating_q025": 1133.5404736792752
        },
        "qwen1.5-110b-chat": {
            "rating": 1141.73975148276,
            "rating_q975": 1157.6784162421739,
            "rating_q025": 1125.8010867233463
        },
        "llama-3.1-8b-instruct": {
            "rating": 1141.506201426582,
            "rating_q975": 1152.9461187629367,
            "rating_q025": 1130.0662840902273
        },
        "yi-1.5-34b-chat": {
            "rating": 1140.8694285295128,
            "rating_q975": 1158.801823204072,
            "rating_q025": 1122.9370338549536
        },
        "granite-3.1-8b-instruct": {
            "rating": 1139.715607303313,
            "rating_q975": 1174.970169477953,
            "rating_q025": 1104.4610451286728
        },
        "command-r-08-2024": {
            "rating": 1136.6630810727304,
            "rating_q975": 1158.2095793311435,
            "rating_q025": 1115.1165828143173
        },
        "qwen1.5-72b-chat": {
            "rating": 1133.9827195454297,
            "rating_q975": 1148.6192730408866,
            "rating_q025": 1119.346166049973
        },
        "jamba-1.5-mini": {
            "rating": 1133.3077211260475,
            "rating_q975": 1164.0471989541497,
            "rating_q025": 1102.5682432979452
        },
        "qwq-32b-preview": {
            "rating": 1132.2409989195228,
            "rating_q975": 1168.4000272120174,
            "rating_q025": 1096.081970627028
        },
        "granite-3.1-2b-instruct": {
            "rating": 1129.4932545452225,
            "rating_q975": 1164.4930943923318,
            "rating_q025": 1094.4934146981132
        },
        "gpt-4-0613": {
            "rating": 1126.0198313600285,
            "rating_q975": 1138.073077619984,
            "rating_q025": 1113.9665851000732
        },
        "qwen1.5-32b-chat": {
            "rating": 1123.9456313920646,
            "rating_q975": 1141.6642020484528,
            "rating_q025": 1106.2270607356763
        },
        "mistral-medium": {
            "rating": 1123.2402989040033,
            "rating_q975": 1139.8343127348967,
            "rating_q025": 1106.64628507311
        },
        "mistral-large-2402": {
            "rating": 1119.9258248107653,
            "rating_q975": 1132.863830230425,
            "rating_q025": 1106.9878193911056
        },
        "reka-flash-21b-20240226-online": {
            "rating": 1114.554177604418,
            "rating_q975": 1135.4765627290722,
            "rating_q025": 1093.631792479764
        },
        "llama-3-8b-instruct": {
            "rating": 1111.3507573003562,
            "rating_q975": 1122.2997987609567,
            "rating_q025": 1100.4017158397558
        },
        "mixtral-8x22b-instruct-v0.1": {
            "rating": 1111.1722879441768,
            "rating_q975": 1124.184502654405,
            "rating_q025": 1098.1600732339487
        },
        "command-r": {
            "rating": 1105.42302699004,
            "rating_q975": 1118.551952287415,
            "rating_q025": 1092.294101692665
        },
        "phi-3-medium-4k-instruct": {
            "rating": 1105.3234382407577,
            "rating_q975": 1122.634719740855,
            "rating_q025": 1088.0121567406604
        },
        "reka-flash-21b-20240226": {
            "rating": 1104.5474024159012,
            "rating_q975": 1121.1999703512367,
            "rating_q025": 1087.8948344805656
        },
        "gemma-2-2b-it": {
            "rating": 1094.2868695151928,
            "rating_q975": 1106.1053970869566,
            "rating_q025": 1082.468341943429
        },
        "qwen1.5-14b-chat": {
            "rating": 1092.1033769475355,
            "rating_q975": 1111.650050620358,
            "rating_q025": 1072.556703274713
        },
        "llama-3.2-3b-instruct": {
            "rating": 1087.429883176736,
            "rating_q975": 1111.521800592254,
            "rating_q025": 1063.337965761218
        },
        "granite-3.0-8b-instruct": {
            "rating": 1084.5996644559186,
            "rating_q975": 1115.5731074894404,
            "rating_q025": 1053.6262214223968
        },
        "mixtral-8x7b-instruct-v0.1": {
            "rating": 1084.1581202739935,
            "rating_q975": 1096.4348201430964,
            "rating_q025": 1071.8814204048906
        },
        "starling-lm-7b-beta": {
            "rating": 1082.2706770014638,
            "rating_q975": 1101.6006948729305,
            "rating_q025": 1062.9406591299971
        },
        "dbrx-instruct-preview": {
            "rating": 1072.8902690919344,
            "rating_q975": 1088.5620920630229,
            "rating_q025": 1057.218446120846
        },
        "gpt-3.5-turbo-1106": {
            "rating": 1067.2781945120985,
            "rating_q975": 1095.3031055409435,
            "rating_q025": 1039.2532834832534
        },
        "phi-3-small-8k-instruct": {
            "rating": 1064.411311100434,
            "rating_q975": 1083.1003503217712,
            "rating_q025": 1045.7222718790968
        },
        "gpt-3.5-turbo-0125": {
            "rating": 1063.6162023599295,
            "rating_q975": 1075.706142432468,
            "rating_q025": 1051.526262287391
        },
        "granite-3.0-2b-instruct": {
            "rating": 1061.5691543309642,
            "rating_q975": 1089.7601697564326,
            "rating_q025": 1033.378138905496
        },
        "zephyr-orpo-141b-A35b-v0.1": {
            "rating": 1061.4497836379462,
            "rating_q975": 1101.7811054142255,
            "rating_q025": 1021.118461861667
        },
        "yi-34b-chat": {
            "rating": 1059.1128015218796,
            "rating_q975": 1083.7369166116705,
            "rating_q025": 1034.4886864320888
        },
        "gemini-pro-dev-api": {
            "rating": 1058.270098655679,
            "rating_q975": 1081.1123825990358,
            "rating_q025": 1035.4278147123223
        },
        "qwen1.5-7b-chat": {
            "rating": 1052.7380855591987,
            "rating_q975": 1089.268210670588,
            "rating_q025": 1016.2079604478093
        },
        "phi-3-mini-4k-instruct-june-2024": {
            "rating": 1049.7814364785568,
            "rating_q975": 1075.6588824459525,
            "rating_q025": 1023.9039905111612
        },
        "openchat-3.5-0106": {
            "rating": 1046.9475412902523,
            "rating_q975": 1069.5409932734724,
            "rating_q025": 1024.3540893070322
        },
        "phi-3-mini-4k-instruct": {
            "rating": 1044.2677062104462,
            "rating_q975": 1063.229485732892,
            "rating_q025": 1025.3059266880005
        },
        "openchat-3.5": {
            "rating": 1039.7028485773249,
            "rating_q975": 1081.1000513733418,
            "rating_q025": 998.3056457813079
        },
        "gemma-1.1-7b-it": {
            "rating": 1037.2704753865105,
            "rating_q975": 1054.3755058629033,
            "rating_q025": 1020.1654449101178
        },
        "llama-2-70b-chat": {
            "rating": 1036.8410394276439,
            "rating_q975": 1053.6020136752434,
            "rating_q025": 1020.0800651800445
        },
        "mistral-7b-instruct-v0.2": {
            "rating": 1034.102365796206,
            "rating_q975": 1054.2013689149906,
            "rating_q025": 1014.0033626774214
        },
        "llama-2-7b-chat": {
            "rating": 1032.377693284816,
            "rating_q975": 1059.887810575377,
            "rating_q025": 1004.8675759942547
        },
        "starling-lm-7b-alpha": {
            "rating": 1032.098260347616,
            "rating_q975": 1062.8213655827446,
            "rating_q025": 1001.3751551124872
        },
        "llama-2-13b-chat": {
            "rating": 1028.6744479229924,
            "rating_q975": 1053.7284112500458,
            "rating_q025": 1003.6204845959389
        },
        "vicuna-33b": {
            "rating": 1027.7715228862817,
            "rating_q975": 1054.2404896222492,
            "rating_q025": 1001.302556150314
        },
        "snowflake-arctic-instruct": {
            "rating": 1026.0219007552632,
            "rating_q975": 1042.7014582215056,
            "rating_q025": 1009.3423432890208
        },
        "olmo-7b-instruct": {
            "rating": 1024.9155157782602,
            "rating_q975": 1063.568719007333,
            "rating_q025": 986.2623125491876
        },
        "llama-3.2-1b-instruct": {
            "rating": 1004.2931038106117,
            "rating_q975": 1031.3364536102342,
            "rating_q025": 977.2497540109891
        },
        "zephyr-7b-beta": {
            "rating": 1003.7211275740569,
            "rating_q975": 1041.915417547428,
            "rating_q025": 965.5268376006858
        },
        "gemma-7b-it": {
            "rating": 1000.7540419082177,
            "rating_q975": 1031.0712657974925,
            "rating_q025": 970.436818018943
        },
        "vicuna-13b": {
            "rating": 991.9208247281372,
            "rating_q975": 1023.2420048111177,
            "rating_q025": 960.5996446451567
        },
        "phi-3-mini-128k-instruct": {
            "rating": 982.74980308559,
            "rating_q975": 1002.6271772244233,
            "rating_q025": 962.8724289467566
        },
        "qwen1.5-4b-chat": {
            "rating": 976.5131331801047,
            "rating_q975": 1007.7743209097621,
            "rating_q025": 945.2519454504472
        },
        "gemma-1.1-2b-it": {
            "rating": 967.9668549780786,
            "rating_q975": 993.5052701495969,
            "rating_q025": 942.4284398065603
        },
        "mistral-7b-instruct": {
            "rating": 951.6494339230178,
            "rating_q975": 991.4026397209715,
            "rating_q025": 911.8962281250641
        }
    },
    "french": {
        "gemini-3-pro": {
            "rating": 1502.3282140081558,
            "rating_q975": 1535.6087514676758,
            "rating_q025": 1469.0476765486358
        },
        "grok-4.1-thinking": {
            "rating": 1483.969817831951,
            "rating_q975": 1517.7868884856077,
            "rating_q025": 1450.1527471782945
        },
        "glm-4.6": {
            "rating": 1482.7604304260494,
            "rating_q975": 1516.1881629555096,
            "rating_q025": 1449.3326978965893
        },
        "gemini-2.5-pro": {
            "rating": 1481.6334347675506,
            "rating_q975": 1503.2195259684854,
            "rating_q025": 1460.0473435666158
        },
        "mistral-medium-2508": {
            "rating": 1480.0353832892356,
            "rating_q975": 1505.3980270838044,
            "rating_q025": 1454.6727394946668
        },
        "gpt-5.1-high": {
            "rating": 1469.839206437723,
            "rating_q975": 1506.9675613879417,
            "rating_q025": 1432.7108514875044
        },
        "claude-opus-4-5-20251101": {
            "rating": 1469.7696642301562,
            "rating_q975": 1515.30833648286,
            "rating_q025": 1424.2309919774523
        },
        "qwen3-max-preview": {
            "rating": 1469.3665698560633,
            "rating_q975": 1500.8207067970711,
            "rating_q025": 1437.9124329150554
        },
        "grok-3-preview-02-24": {
            "rating": 1468.6035561874796,
            "rating_q975": 1500.8866291341328,
            "rating_q025": 1436.3204832408264
        },
        "longcat-flash-chat": {
            "rating": 1463.794168049759,
            "rating_q975": 1513.3725329482863,
            "rating_q025": 1414.2158031512317
        },
        "qwen3-235b-a22b-instruct-2507": {
            "rating": 1463.2469238788738,
            "rating_q975": 1487.2325382854995,
            "rating_q025": 1439.261309472248
        },
        "claude-opus-4-5-20251101-thinking-32k": {
            "rating": 1463.2296117587537,
            "rating_q975": 1512.3034324255834,
            "rating_q025": 1414.155791091924
        },
        "deepseek-v3.1": {
            "rating": 1461.9814965065939,
            "rating_q975": 1500.929054500313,
            "rating_q025": 1423.0339385128748
        },
        "grok-4.1": {
            "rating": 1458.6684972688759,
            "rating_q975": 1494.265004315183,
            "rating_q025": 1423.0719902225687
        },
        "gemini-2.5-flash-preview-09-2025": {
            "rating": 1458.6265880817493,
            "rating_q975": 1489.2137873494564,
            "rating_q025": 1428.0393888140422
        },
        "chatgpt-4o-latest-20250326": {
            "rating": 1447.2338877664984,
            "rating_q975": 1470.393419707708,
            "rating_q025": 1424.0743558252886
        },
        "gpt-5.1": {
            "rating": 1446.1385837322766,
            "rating_q975": 1486.003465046232,
            "rating_q025": 1406.2737024183214
        },
        "o3-2025-04-16": {
            "rating": 1445.6987394530765,
            "rating_q975": 1470.1363206970761,
            "rating_q025": 1421.261158209077
        },
        "kimi-k2-thinking-turbo": {
            "rating": 1443.3299830907415,
            "rating_q975": 1480.5026725837563,
            "rating_q025": 1406.1572935977267
        },
        "claude-opus-4-1-20250805-thinking-16k": {
            "rating": 1442.611038544064,
            "rating_q975": 1468.8827657481759,
            "rating_q025": 1416.3393113399522
        },
        "glm-4.5": {
            "rating": 1442.451851817634,
            "rating_q975": 1477.14966452845,
            "rating_q025": 1407.7540391068178
        },
        "claude-opus-4-1-20250805": {
            "rating": 1441.9815786394997,
            "rating_q975": 1465.549717701871,
            "rating_q025": 1418.4134395771284
        },
        "claude-sonnet-4-5-20250929": {
            "rating": 1438.5992236584211,
            "rating_q975": 1472.6600895123443,
            "rating_q025": 1404.538357804498
        },
        "mai-1-preview": {
            "rating": 1436.543344197834,
            "rating_q975": 1473.2457612889157,
            "rating_q025": 1399.8409271067521
        },
        "amazon-nova-experimental-chat-10-20": {
            "rating": 1435.4161733728079,
            "rating_q975": 1487.8315526184754,
            "rating_q025": 1383.0007941271404
        },
        "deepseek-v3.2-exp": {
            "rating": 1434.9141647855647,
            "rating_q975": 1480.5315487767714,
            "rating_q025": 1389.296780794358
        },
        "claude-sonnet-4-5-20250929-thinking-32k": {
            "rating": 1432.8961681453363,
            "rating_q975": 1464.021298993605,
            "rating_q025": 1401.7710372970678
        },
        "gemini-2.5-flash": {
            "rating": 1432.1751236810728,
            "rating_q975": 1453.5713945926057,
            "rating_q025": 1410.77885276954
        },
        "grok-4-fast-reasoning": {
            "rating": 1431.9211154965558,
            "rating_q975": 1470.2553485918747,
            "rating_q025": 1393.5868824012368
        },
        "deepseek-r1-0528": {
            "rating": 1430.62891727858,
            "rating_q975": 1470.0814403477386,
            "rating_q025": 1391.1763942094215
        },
        "qwen3-next-80b-a3b-instruct": {
            "rating": 1430.3654805877054,
            "rating_q975": 1463.773903251159,
            "rating_q025": 1396.9570579242518
        },
        "grok-4-0709": {
            "rating": 1427.9051543870964,
            "rating_q975": 1455.4692560879207,
            "rating_q025": 1400.3410526862722
        },
        "gpt-4.5-preview-2025-02-27": {
            "rating": 1425.2364268235217,
            "rating_q975": 1481.4689367260723,
            "rating_q025": 1369.003916920971
        },
        "deepseek-v3.2": {
            "rating": 1422.4189005351498,
            "rating_q975": 1476.090943960172,
            "rating_q025": 1368.7468571101276
        },
        "qwen3-coder-480b-a35b-instruct": {
            "rating": 1422.0490587157904,
            "rating_q975": 1458.4753668604008,
            "rating_q025": 1385.62275057118
        },
        "gpt-5-chat": {
            "rating": 1421.690806729173,
            "rating_q975": 1452.8926224698507,
            "rating_q025": 1390.488990988495
        },
        "grok-4-1-fast-reasoning": {
            "rating": 1419.5104479872314,
            "rating_q975": 1471.1227826597478,
            "rating_q025": 1367.898113314715
        },
        "glm-4.5-air": {
            "rating": 1418.0369215935762,
            "rating_q975": 1447.710679216234,
            "rating_q025": 1388.3631639709183
        },
        "deepseek-v3.2-exp-thinking": {
            "rating": 1417.0792942807602,
            "rating_q975": 1466.8900408783675,
            "rating_q025": 1367.268547683153
        },
        "qwen3-30b-a3b-instruct-2507": {
            "rating": 1416.1971966435717,
            "rating_q975": 1450.8280671518546,
            "rating_q025": 1381.5663261352888
        },
        "gpt-5-high": {
            "rating": 1403.2768748851347,
            "rating_q975": 1434.2849146399967,
            "rating_q025": 1372.2688351302727
        },
        "qwen2.5-max": {
            "rating": 1401.7479119598543,
            "rating_q975": 1434.4941812231525,
            "rating_q025": 1369.001642696556
        },
        "claude-opus-4-20250514-thinking-16k": {
            "rating": 1399.1553449219134,
            "rating_q975": 1428.5579574224748,
            "rating_q025": 1369.752732421352
        },
        "gemini-2.0-flash-001": {
            "rating": 1397.5730801868488,
            "rating_q975": 1424.069746369087,
            "rating_q025": 1371.0764140046106
        },
        "deepseek-v3-0324": {
            "rating": 1395.1639116225408,
            "rating_q975": 1421.9443139133105,
            "rating_q025": 1368.3835093317712
        },
        "gpt-4.1-2025-04-14": {
            "rating": 1395.1215068036186,
            "rating_q975": 1420.0823618158727,
            "rating_q025": 1370.1606517913644
        },
        "gemini-2.5-flash-lite-preview-06-17-thinking": {
            "rating": 1394.8986721162507,
            "rating_q975": 1426.2077069826073,
            "rating_q025": 1363.5896372498942
        },
        "kimi-k2-0905-preview": {
            "rating": 1393.8212181214662,
            "rating_q975": 1438.8145723522487,
            "rating_q025": 1348.8278638906838
        },
        "gemini-2.5-flash-lite-preview-09-2025-no-thinking": {
            "rating": 1392.8917455424028,
            "rating_q975": 1423.8355974082872,
            "rating_q025": 1361.9478936765183
        },
        "claude-haiku-4-5-20251001": {
            "rating": 1392.4858514891534,
            "rating_q975": 1425.3763335321844,
            "rating_q025": 1359.5953694461225
        },
        "gpt-5-mini-high": {
            "rating": 1388.8169235572184,
            "rating_q975": 1422.2870694078674,
            "rating_q025": 1355.3467777065694
        },
        "qwen3-next-80b-a3b-thinking": {
            "rating": 1386.1818723650601,
            "rating_q975": 1428.1418247397994,
            "rating_q025": 1344.2219199903209
        },
        "qwen3-235b-a22b-no-thinking": {
            "rating": 1385.2273463026754,
            "rating_q975": 1413.6846746694594,
            "rating_q025": 1356.7700179358915
        },
        "minimax-m1": {
            "rating": 1384.319627489162,
            "rating_q975": 1414.2027060548705,
            "rating_q025": 1354.4365489234535
        },
        "amazon-nova-experimental-chat-10-09": {
            "rating": 1384.1764442669914,
            "rating_q975": 1439.9779286697901,
            "rating_q025": 1328.3749598641928
        },
        "mistral-medium-2505": {
            "rating": 1381.1751446644184,
            "rating_q975": 1409.8645203999808,
            "rating_q025": 1352.485768928856
        },
        "hunyuan-turbos-20250416": {
            "rating": 1381.1642209556558,
            "rating_q975": 1430.0993994635887,
            "rating_q025": 1332.2290424477228
        },
        "gemma-3-27b-it": {
            "rating": 1379.6417676546166,
            "rating_q975": 1404.8937855153572,
            "rating_q025": 1354.389749793876
        },
        "kimi-k2-0711-preview": {
            "rating": 1376.339657302935,
            "rating_q975": 1408.7083952955581,
            "rating_q025": 1343.9709193103117
        },
        "claude-sonnet-4-20250514": {
            "rating": 1373.4105234448782,
            "rating_q975": 1401.0348195050678,
            "rating_q025": 1345.7862273846886
        },
        "deepseek-r1": {
            "rating": 1373.2800428958503,
            "rating_q975": 1415.6774658166246,
            "rating_q025": 1330.882619975076
        },
        "claude-sonnet-4-20250514-thinking-32k": {
            "rating": 1371.791469211016,
            "rating_q975": 1400.8562562679267,
            "rating_q025": 1342.7266821541052
        },
        "gpt-oss-120b": {
            "rating": 1370.8984674766732,
            "rating_q975": 1401.731084721657,
            "rating_q025": 1340.0658502316894
        },
        "qwen3-235b-a22b": {
            "rating": 1369.639315636709,
            "rating_q975": 1402.640271942399,
            "rating_q025": 1336.6383593310188
        },
        "grok-3-mini-beta": {
            "rating": 1368.3160936709091,
            "rating_q975": 1406.0072463135816,
            "rating_q025": 1330.6249410282367
        },
        "qwen3-30b-a3b": {
            "rating": 1366.6824268110176,
            "rating_q975": 1399.4045421315975,
            "rating_q025": 1333.9603114904378
        },
        "o4-mini-2025-04-16": {
            "rating": 1366.1658214933414,
            "rating_q975": 1392.7717453809314,
            "rating_q025": 1339.5598976057513
        },
        "command-a-03-2025": {
            "rating": 1362.0401031438512,
            "rating_q975": 1386.665989352579,
            "rating_q025": 1337.4142169351235
        },
        "gpt-4.1-mini-2025-04-14": {
            "rating": 1360.729529151145,
            "rating_q975": 1388.3788607819056,
            "rating_q025": 1333.0801975203844
        },
        "claude-opus-4-20250514": {
            "rating": 1360.5903503713591,
            "rating_q975": 1387.636198935198,
            "rating_q025": 1333.5445018075202
        },
        "gemini-2.0-flash-lite-preview-02-05": {
            "rating": 1355.2917650882066,
            "rating_q975": 1393.2696612540797,
            "rating_q025": 1317.3138689223335
        },
        "o1-preview": {
            "rating": 1352.3621926980404,
            "rating_q975": 1386.09699550285,
            "rating_q025": 1318.6273898932309
        },
        "grok-3-mini-high": {
            "rating": 1351.6902714553469,
            "rating_q975": 1396.310351319225,
            "rating_q025": 1307.0701915914688
        },
        "o1-2024-12-17": {
            "rating": 1351.383643106033,
            "rating_q975": 1387.928906815075,
            "rating_q025": 1314.8383793969913
        },
        "qwq-32b": {
            "rating": 1349.5677554993922,
            "rating_q975": 1383.8982004896488,
            "rating_q025": 1315.2373105091356
        },
        "deepseek-v3": {
            "rating": 1349.482058984527,
            "rating_q975": 1386.3115133736783,
            "rating_q025": 1312.6526045953756
        },
        "mistral-small-2506": {
            "rating": 1344.870669696987,
            "rating_q975": 1385.8850663123542,
            "rating_q025": 1303.85627308162
        },
        "o3-mini-high": {
            "rating": 1341.4760551688778,
            "rating_q975": 1385.6429526429356,
            "rating_q025": 1297.30915769482
        },
        "athene-v2-chat": {
            "rating": 1340.378730693874,
            "rating_q975": 1376.7929965638002,
            "rating_q025": 1303.964464823948
        },
        "qwen-max-0919": {
            "rating": 1337.2903237296673,
            "rating_q975": 1377.6286471542344,
            "rating_q025": 1296.9520003051002
        },
        "gemma-3n-e4b-it": {
            "rating": 1334.5347521523436,
            "rating_q975": 1369.2735828948742,
            "rating_q025": 1299.795921409813
        },
        "mistral-large-2411": {
            "rating": 1332.3422348613442,
            "rating_q975": 1372.8080325620233,
            "rating_q025": 1291.876437160665
        },
        "o3-mini": {
            "rating": 1332.2157285111361,
            "rating_q975": 1356.280624006036,
            "rating_q025": 1308.1508330162362
        },
        "grok-2-2024-08-13": {
            "rating": 1325.003398526847,
            "rating_q975": 1349.5882456025802,
            "rating_q025": 1300.4185514511137
        },
        "glm-4-plus": {
            "rating": 1315.4061406328713,
            "rating_q975": 1350.848963109996,
            "rating_q025": 1279.9633181557465
        },
        "gemini-advanced-0514": {
            "rating": 1314.2314199124953,
            "rating_q975": 1338.3296455366542,
            "rating_q025": 1290.1331942883364
        },
        "gpt-4o-2024-05-13": {
            "rating": 1312.7161773085395,
            "rating_q975": 1331.4187198029967,
            "rating_q025": 1294.0136348140823
        },
        "yi-lightning": {
            "rating": 1312.1912142687852,
            "rating_q975": 1347.7502975452717,
            "rating_q025": 1276.6321309922987
        },
        "claude-3-7-sonnet-20250219": {
            "rating": 1309.741100048585,
            "rating_q975": 1337.7279642262433,
            "rating_q025": 1281.7542358709265
        },
        "gemini-1.5-pro-002": {
            "rating": 1308.7671300367726,
            "rating_q975": 1335.9084758189306,
            "rating_q025": 1281.6257842546147
        },
        "claude-3-5-sonnet-20241022": {
            "rating": 1308.113545453418,
            "rating_q975": 1328.8347026846534,
            "rating_q025": 1287.3923882221827
        },
        "gpt-4o-mini-2024-07-18": {
            "rating": 1304.1537156823686,
            "rating_q975": 1326.8271439553198,
            "rating_q025": 1281.4802874094173
        },
        "claude-3-5-sonnet-20240620": {
            "rating": 1301.1520995155731,
            "rating_q975": 1322.5456447001761,
            "rating_q025": 1279.7585543309701
        },
        "o1-mini": {
            "rating": 1300.293728444412,
            "rating_q975": 1328.8878369188699,
            "rating_q025": 1271.699619969954
        },
        "llama-4-scout-17b-16e-instruct": {
            "rating": 1297.7166600704222,
            "rating_q975": 1329.202623365313,
            "rating_q025": 1266.2306967755314
        },
        "deepseek-v2.5": {
            "rating": 1294.381824033676,
            "rating_q975": 1331.8126418126033,
            "rating_q025": 1256.9510062547486
        },
        "athene-70b-0725": {
            "rating": 1293.763680030239,
            "rating_q975": 1335.0721746388901,
            "rating_q025": 1252.4551854215877
        },
        "grok-2-mini-2024-08-13": {
            "rating": 1293.5521751468464,
            "rating_q975": 1320.829321605921,
            "rating_q025": 1266.2750286877717
        },
        "llama-3.3-70b-instruct": {
            "rating": 1290.7627390439106,
            "rating_q975": 1316.3180387024006,
            "rating_q025": 1265.2074393854207
        },
        "gpt-4-1106-preview": {
            "rating": 1289.9658572519825,
            "rating_q975": 1308.857422917013,
            "rating_q025": 1271.0742915869519
        },
        "gpt-4-0125-preview": {
            "rating": 1288.6266702336538,
            "rating_q975": 1308.4120119613308,
            "rating_q025": 1268.841328505977
        },
        "qwen2.5-72b-instruct": {
            "rating": 1285.7135638499037,
            "rating_q975": 1317.0411199795278,
            "rating_q025": 1254.3860077202796
        },
        "claude-3-7-sonnet-20250219-thinking-32k": {
            "rating": 1285.4204253173734,
            "rating_q975": 1315.0110326651793,
            "rating_q025": 1255.8298179695676
        },
        "llama-3.1-405b-instruct-bf16": {
            "rating": 1284.989392844885,
            "rating_q975": 1314.6572855454294,
            "rating_q025": 1255.3215001443407
        },
        "gpt-4-turbo-2024-04-09": {
            "rating": 1283.20737996879,
            "rating_q975": 1302.7039010389726,
            "rating_q025": 1263.7108588986075
        },
        "claude-3-opus-20240229": {
            "rating": 1282.1090891790686,
            "rating_q975": 1298.1556111248656,
            "rating_q025": 1266.0625672332717
        },
        "amazon-nova-pro-v1.0": {
            "rating": 1281.615001971867,
            "rating_q975": 1319.4973267677356,
            "rating_q025": 1243.7326771759986
        },
        "mistral-large-2407": {
            "rating": 1280.1688713671379,
            "rating_q975": 1308.2747096134206,
            "rating_q025": 1252.0630331208552
        },
        "llama-3.1-405b-instruct-fp8": {
            "rating": 1280.0349126308486,
            "rating_q975": 1305.9361836344933,
            "rating_q025": 1254.1336416272038
        },
        "gemini-1.5-pro-001": {
            "rating": 1279.9054887883126,
            "rating_q975": 1300.5507705849836,
            "rating_q025": 1259.2602069916416
        },
        "gpt-4o-2024-08-06": {
            "rating": 1269.7382201466196,
            "rating_q975": 1296.4668806027144,
            "rating_q025": 1243.0095596905248
        },
        "llama-3.1-70b-instruct": {
            "rating": 1268.6509145304722,
            "rating_q975": 1295.7342407132558,
            "rating_q025": 1241.5675883476886
        },
        "claude-3-5-haiku-20241022": {
            "rating": 1267.160501152889,
            "rating_q975": 1290.2237393361397,
            "rating_q025": 1244.0972629696385
        },
        "mistral-small-3.1-24b-instruct-2503": {
            "rating": 1267.1260204893756,
            "rating_q975": 1299.2749541880407,
            "rating_q025": 1234.9770867907105
        },
        "gemini-1.5-flash-002": {
            "rating": 1265.4410484649566,
            "rating_q975": 1298.5456891203537,
            "rating_q025": 1232.3364078095594
        },
        "magistral-medium-2506": {
            "rating": 1262.340937571765,
            "rating_q975": 1312.7325674559977,
            "rating_q025": 1211.9493076875322
        },
        "llama-4-maverick-17b-128e-instruct": {
            "rating": 1261.8914476560933,
            "rating_q975": 1288.896494897826,
            "rating_q025": 1234.8864004143607
        },
        "c4ai-aya-expanse-32b": {
            "rating": 1255.0831356617332,
            "rating_q975": 1288.6622271211063,
            "rating_q025": 1221.50404420236
        },
        "gemma-2-27b-it": {
            "rating": 1254.4297147133116,
            "rating_q975": 1275.6954365755864,
            "rating_q025": 1233.1639928510367
        },
        "gemini-1.5-flash-001": {
            "rating": 1247.8886959713036,
            "rating_q975": 1269.971650887928,
            "rating_q025": 1225.8057410546792
        },
        "amazon-nova-micro-v1.0": {
            "rating": 1246.2560078829524,
            "rating_q975": 1290.5177718038876,
            "rating_q025": 1201.9942439620172
        },
        "amazon-nova-lite-v1.0": {
            "rating": 1242.1355434683137,
            "rating_q975": 1286.3765639465696,
            "rating_q025": 1197.8945229900578
        },
        "gemini-1.5-flash-8b-001": {
            "rating": 1242.0741459448022,
            "rating_q975": 1273.7674664038288,
            "rating_q025": 1210.3808254857756
        },
        "llama-3-70b-instruct": {
            "rating": 1239.8386170148804,
            "rating_q975": 1256.967491943501,
            "rating_q025": 1222.7097420862597
        },
        "claude-3-sonnet-20240229": {
            "rating": 1236.5315237324085,
            "rating_q975": 1255.0382257882993,
            "rating_q025": 1218.0248216765176
        },
        "phi-4": {
            "rating": 1231.915115877398,
            "rating_q975": 1271.164701443694,
            "rating_q025": 1192.665530311102
        },
        "gpt-4-0314": {
            "rating": 1226.707800632707,
            "rating_q975": 1250.7306609035872,
            "rating_q025": 1202.6849403618266
        },
        "mistral-large-2402": {
            "rating": 1217.0304259146078,
            "rating_q975": 1238.7477008211463,
            "rating_q025": 1195.3131510080693
        },
        "command-r-plus": {
            "rating": 1215.7477359245756,
            "rating_q975": 1236.3834944769396,
            "rating_q025": 1195.1119773722116
        },
        "mistral-small-24b-instruct-2501": {
            "rating": 1210.3856146173848,
            "rating_q975": 1260.093810349042,
            "rating_q025": 1160.6774188857275
        },
        "nemotron-4-340b-instruct": {
            "rating": 1207.2210284747714,
            "rating_q975": 1240.0966351553975,
            "rating_q025": 1174.3454217941453
        },
        "claude-3-haiku-20240307": {
            "rating": 1201.5395482345439,
            "rating_q975": 1219.8525180884712,
            "rating_q025": 1183.2265783806165
        },
        "gemma-2-9b-it": {
            "rating": 1197.9114011904317,
            "rating_q975": 1222.39269342444,
            "rating_q025": 1173.4301089564233
        },
        "deepseek-coder-v2": {
            "rating": 1190.805683470536,
            "rating_q975": 1231.4418455250047,
            "rating_q025": 1150.1695214160673
        },
        "mistral-medium": {
            "rating": 1187.220423443654,
            "rating_q975": 1212.6783961393296,
            "rating_q025": 1161.7624507479784
        },
        "llama-3.1-8b-instruct": {
            "rating": 1186.5291377893864,
            "rating_q975": 1214.5713584246275,
            "rating_q025": 1158.4869171541452
        },
        "reka-flash-21b-20240226": {
            "rating": 1183.1823098980349,
            "rating_q975": 1213.0505284983424,
            "rating_q025": 1153.3140912977274
        },
        "qwen2-72b-instruct": {
            "rating": 1177.8211123275983,
            "rating_q975": 1202.5667426792095,
            "rating_q025": 1153.075481975987
        },
        "gpt-4-0613": {
            "rating": 1177.703426014688,
            "rating_q975": 1197.4606093167945,
            "rating_q025": 1157.9462427125814
        },
        "mixtral-8x7b-instruct-v0.1": {
            "rating": 1173.5457791788913,
            "rating_q975": 1194.0605848010225,
            "rating_q025": 1153.03097355676
        },
        "mixtral-8x22b-instruct-v0.1": {
            "rating": 1173.2412131727092,
            "rating_q975": 1197.160407527389,
            "rating_q025": 1149.3220188180294
        },
        "command-r": {
            "rating": 1169.36165946974,
            "rating_q975": 1192.7710154600777,
            "rating_q025": 1145.9523034794024
        },
        "reka-flash-21b-20240226-online": {
            "rating": 1168.759306476012,
            "rating_q975": 1208.6703862928482,
            "rating_q025": 1128.8482266591757
        },
        "llama-3-8b-instruct": {
            "rating": 1167.48430704793,
            "rating_q975": 1186.8021828358053,
            "rating_q025": 1148.1664312600549
        },
        "qwen1.5-72b-chat": {
            "rating": 1166.9884862055317,
            "rating_q975": 1190.1731570903164,
            "rating_q025": 1143.803815320747
        },
        "gemma-2-2b-it": {
            "rating": 1164.5957993153233,
            "rating_q975": 1193.4978113595514,
            "rating_q025": 1135.6937872710953
        },
        "yi-1.5-34b-chat": {
            "rating": 1162.6692587201007,
            "rating_q975": 1193.3543767369654,
            "rating_q025": 1131.984140703236
        },
        "qwen1.5-110b-chat": {
            "rating": 1160.3056157298388,
            "rating_q975": 1191.8588903469495,
            "rating_q025": 1128.7523411127281
        },
        "gemini-pro-dev-api": {
            "rating": 1152.630521232194,
            "rating_q975": 1183.7660061089966,
            "rating_q025": 1121.4950363553914
        },
        "phi-3-small-8k-instruct": {
            "rating": 1142.6665198232795,
            "rating_q975": 1177.5580710802728,
            "rating_q025": 1107.7749685662861
        },
        "snowflake-arctic-instruct": {
            "rating": 1141.179423692773,
            "rating_q975": 1170.062570208312,
            "rating_q025": 1112.296277177234
        },
        "gpt-3.5-turbo-0125": {
            "rating": 1125.6132446647998,
            "rating_q975": 1146.4606842146402,
            "rating_q025": 1104.7658051149594
        },
        "qwen1.5-14b-chat": {
            "rating": 1124.3565117220523,
            "rating_q975": 1162.185583924554,
            "rating_q025": 1086.5274395195506
        },
        "starling-lm-7b-beta": {
            "rating": 1123.6024134727822,
            "rating_q975": 1161.8027290373652,
            "rating_q025": 1085.4020979081993
        },
        "phi-3-medium-4k-instruct": {
            "rating": 1121.9172930961631,
            "rating_q975": 1154.750138149133,
            "rating_q025": 1089.0844480431933
        },
        "qwen1.5-32b-chat": {
            "rating": 1107.0926153361045,
            "rating_q975": 1141.412227247251,
            "rating_q025": 1072.773003424958
        },
        "dbrx-instruct-preview": {
            "rating": 1103.8523788395107,
            "rating_q975": 1132.5266985169878,
            "rating_q025": 1075.1780591620336
        },
        "openchat-3.5-0106": {
            "rating": 1099.4970322142235,
            "rating_q975": 1141.7472524574964,
            "rating_q025": 1057.2468119709506
        },
        "llama-2-70b-chat": {
            "rating": 1097.611170575325,
            "rating_q975": 1123.8577298666874,
            "rating_q025": 1071.3646112839629
        },
        "vicuna-33b": {
            "rating": 1093.432890438431,
            "rating_q975": 1130.351756645316,
            "rating_q025": 1056.514024231546
        },
        "starling-lm-7b-alpha": {
            "rating": 1092.7076259011137,
            "rating_q975": 1135.099776692439,
            "rating_q025": 1050.3154751097884
        },
        "yi-34b-chat": {
            "rating": 1088.5955867701134,
            "rating_q975": 1128.7291275346627,
            "rating_q025": 1048.4620460055642
        },
        "phi-3-mini-4k-instruct": {
            "rating": 1085.6514448670107,
            "rating_q975": 1120.5235463760876,
            "rating_q025": 1050.7793433579338
        },
        "gemma-1.1-7b-it": {
            "rating": 1074.319353697902,
            "rating_q975": 1105.3164786495897,
            "rating_q025": 1043.3222287462143
        },
        "gpt-3.5-turbo-1106": {
            "rating": 1073.72036988844,
            "rating_q975": 1112.0063899872862,
            "rating_q025": 1035.4343497895939
        },
        "llama-2-13b-chat": {
            "rating": 1053.0669375811262,
            "rating_q975": 1091.5970560530684,
            "rating_q025": 1014.5368191091841
        },
        "phi-3-mini-128k-instruct": {
            "rating": 1046.9231696435868,
            "rating_q975": 1080.7015701746102,
            "rating_q025": 1013.1447691125633
        },
        "mistral-7b-instruct-v0.2": {
            "rating": 1043.3102584975106,
            "rating_q975": 1074.280483374489,
            "rating_q025": 1012.3400336205324
        },
        "zephyr-7b-beta": {
            "rating": 1039.7401419053922,
            "rating_q975": 1087.8497560528808,
            "rating_q025": 991.6305277579036
        },
        "stripedhyena-nous-7b": {
            "rating": 1038.6251969787759,
            "rating_q975": 1087.5665388873392,
            "rating_q025": 989.6838550702126
        },
        "gemma-7b-it": {
            "rating": 1030.4001779686241,
            "rating_q975": 1077.5865211248192,
            "rating_q025": 983.2138348124289
        },
        "vicuna-13b": {
            "rating": 1029.038483086556,
            "rating_q975": 1073.3490025662377,
            "rating_q025": 984.7279636068741
        },
        "llama-2-7b-chat": {
            "rating": 980.4744768859266,
            "rating_q975": 1022.7358500526171,
            "rating_q025": 938.2131037192361
        },
        "mistral-7b-instruct": {
            "rating": 954.0992039931182,
            "rating_q975": 1001.9618237342595,
            "rating_q025": 906.2365842519769
        }
    },
    "full": {
        "gemini-3-pro": {
            "rating": 1486.6027120272704,
            "rating_q975": 1492.8027344568852,
            "rating_q025": 1480.4026895976556
        },
        "gemini-2.5-pro": {
            "rating": 1464.461788215414,
            "rating_q975": 1467.9021455827035,
            "rating_q025": 1461.0214308481243
        },
        "grok-4.1-thinking": {
            "rating": 1451.2104783024167,
            "rating_q975": 1457.2996361058304,
            "rating_q025": 1445.121320499003
        },
        "claude-opus-4-5-20251101": {
            "rating": 1446.431063509376,
            "rating_q975": 1453.4583334383456,
            "rating_q025": 1439.4037935804063
        },
        "gpt-5.1-high": {
            "rating": 1445.9302909868388,
            "rating_q975": 1452.3338696577464,
            "rating_q025": 1439.5267123159313
        },
        "ernie-5.0-preview-1103": {
            "rating": 1445.8127576476008,
            "rating_q975": 1454.6449927633748,
            "rating_q025": 1436.9805225318269
        },
        "grok-4.1": {
            "rating": 1443.437196930874,
            "rating_q975": 1449.4684955814605,
            "rating_q025": 1437.4058982802876
        },
        "claude-opus-4-5-20251101-thinking-32k": {
            "rating": 1442.2437083563004,
            "rating_q975": 1449.3931379129579,
            "rating_q025": 1435.094278799643
        },
        "glm-4.6": {
            "rating": 1441.1577248695578,
            "rating_q975": 1445.8838608218377,
            "rating_q025": 1436.4315889172778
        },
        "qwen3-max-preview": {
            "rating": 1437.9507529033654,
            "rating_q975": 1442.5029167394764,
            "rating_q025": 1433.3985890672543
        },
        "mistral-large-3": {
            "rating": 1431.739545542449,
            "rating_q975": 1440.040953251129,
            "rating_q025": 1423.438137833769
        },
        "mistral-medium-2508": {
            "rating": 1430.4438390729767,
            "rating_q975": 1434.2862512721354,
            "rating_q025": 1426.6014268738181
        },
        "glm-4.5": {
            "rating": 1428.1237745813262,
            "rating_q975": 1432.984542230227,
            "rating_q025": 1423.2630069324255
        },
        "chatgpt-4o-latest-20250326": {
            "rating": 1427.4844746679514,
            "rating_q975": 1430.8024629236756,
            "rating_q025": 1424.1664864122272
        },
        "claude-sonnet-4-5-20250929-thinking-32k": {
            "rating": 1426.9636632815746,
            "rating_q975": 1431.489225243666,
            "rating_q025": 1422.4381013194832
        },
        "claude-sonnet-4-5-20250929": {
            "rating": 1426.6103157511056,
            "rating_q975": 1431.6689362314228,
            "rating_q025": 1421.5516952707885
        },
        "deepseek-r1-0528": {
            "rating": 1425.6379784647631,
            "rating_q975": 1431.2193778839528,
            "rating_q025": 1420.0565790455735
        },
        "grok-3-preview-02-24": {
            "rating": 1424.440849503837,
            "rating_q975": 1428.6501762081316,
            "rating_q025": 1420.2315227995423
        },
        "deepseek-v3.2-exp": {
            "rating": 1424.2361069765134,
            "rating_q975": 1430.7418898904114,
            "rating_q025": 1417.7303240626154
        },
        "longcat-flash-chat": {
            "rating": 1422.7198357772845,
            "rating_q975": 1429.092790191526,
            "rating_q025": 1416.346881363043
        },
        "qwen3-vl-235b-a22b-instruct": {
            "rating": 1422.2668846053548,
            "rating_q975": 1428.9255522933563,
            "rating_q025": 1415.6082169173533
        },
        "deepseek-v3.2-exp-thinking": {
            "rating": 1421.6457341205987,
            "rating_q975": 1428.2012133521587,
            "rating_q025": 1415.0902548890388
        },
        "gpt-5.1": {
            "rating": 1420.8144085943575,
            "rating_q975": 1427.01763807393,
            "rating_q025": 1414.611179114785
        },
        "claude-opus-4-1-20250805-thinking-16k": {
            "rating": 1419.7375098398104,
            "rating_q975": 1423.5844390596492,
            "rating_q025": 1415.8905806199716
        },
        "deepseek-v3.1": {
            "rating": 1419.4775767205822,
            "rating_q975": 1425.4849831172623,
            "rating_q025": 1413.470170323902
        },
        "deepseek-v3.1-terminus": {
            "rating": 1418.6645171484156,
            "rating_q975": 1428.2824450115093,
            "rating_q025": 1409.046589285322
        },
        "qwen3-235b-a22b-instruct-2507": {
            "rating": 1418.5279372202156,
            "rating_q975": 1422.2068407761324,
            "rating_q025": 1414.8490336642988
        },
        "qwen3-next-80b-a3b-instruct": {
            "rating": 1418.115145264465,
            "rating_q975": 1422.912318979872,
            "rating_q025": 1413.3179715490578
        },
        "gpt-4.5-preview-2025-02-27": {
            "rating": 1417.448902009419,
            "rating_q975": 1423.0780219553474,
            "rating_q025": 1411.8197820634907
        },
        "deepseek-v3.1-terminus-thinking": {
            "rating": 1417.2818316580751,
            "rating_q975": 1427.2058988218257,
            "rating_q025": 1407.3577644943246
        },
        "deepseek-v3.2-thinking": {
            "rating": 1417.2666702236502,
            "rating_q975": 1425.7285543313938,
            "rating_q025": 1408.8047861159066
        },
        "deepseek-v3.2": {
            "rating": 1416.8274464930687,
            "rating_q975": 1425.096268414959,
            "rating_q025": 1408.5586245711784
        },
        "deepseek-v3.1-thinking": {
            "rating": 1416.600556383553,
            "rating_q975": 1423.182522266318,
            "rating_q025": 1410.0185905007882
        },
        "gemini-2.5-flash": {
            "rating": 1415.132949651076,
            "rating_q975": 1418.5043725334017,
            "rating_q025": 1411.7615267687502
        },
        "qwen3-max-2025-09-23": {
            "rating": 1413.8383684853623,
            "rating_q975": 1420.2590560668514,
            "rating_q025": 1407.4176809038731
        },
        "qwen3-235b-a22b-thinking-2507": {
            "rating": 1413.0547177174508,
            "rating_q975": 1419.4751717528002,
            "rating_q025": 1406.6342636821014
        },
        "claude-opus-4-1-20250805": {
            "rating": 1412.9733311826228,
            "rating_q975": 1416.6975254020194,
            "rating_q025": 1409.2491369632262
        },
        "o3-2025-04-16": {
            "rating": 1410.7688477691415,
            "rating_q975": 1414.370634124769,
            "rating_q025": 1407.1670614135141
        },
        "kimi-k2-thinking-turbo": {
            "rating": 1409.5324051919436,
            "rating_q975": 1415.332300587029,
            "rating_q025": 1403.732509796858
        },
        "grok-4-1-fast-reasoning": {
            "rating": 1409.3591576720682,
            "rating_q975": 1416.2784878987661,
            "rating_q025": 1402.4398274453704
        },
        "grok-4-0709": {
            "rating": 1408.8869985523272,
            "rating_q975": 1412.8043802880436,
            "rating_q025": 1404.9696168166108
        },
        "grok-4-fast-chat": {
            "rating": 1407.691860938449,
            "rating_q975": 1415.244800315766,
            "rating_q025": 1400.138921561132
        },
        "gpt-5-high": {
            "rating": 1407.2867738055795,
            "rating_q975": 1411.748244504682,
            "rating_q025": 1402.8253031064771
        },
        "gemini-2.5-flash-preview-09-2025": {
            "rating": 1407.2684808029132,
            "rating_q975": 1411.6294975025994,
            "rating_q025": 1402.907464103227
        },
        "hunyuan-vision-1.5-thinking": {
            "rating": 1403.6070471776122,
            "rating_q975": 1415.9831438020447,
            "rating_q025": 1391.2309505531798
        },
        "gpt-5-chat": {
            "rating": 1403.085965423863,
            "rating_q975": 1407.3786376818857,
            "rating_q025": 1398.7932931658402
        },
        "qwen3-vl-235b-a22b-thinking": {
            "rating": 1400.6190430719814,
            "rating_q975": 1407.4264930220268,
            "rating_q025": 1393.811593121936
        },
        "hunyuan-t1-20250711": {
            "rating": 1398.305877913168,
            "rating_q975": 1406.8246083133783,
            "rating_q025": 1389.7871475129575
        },
        "amazon-nova-experimental-chat-10-20": {
            "rating": 1397.4441523983678,
            "rating_q975": 1404.7091571906947,
            "rating_q025": 1390.179147606041
        },
        "grok-4-fast-reasoning": {
            "rating": 1395.920520019026,
            "rating_q975": 1400.9980570251182,
            "rating_q025": 1390.842983012934
        },
        "mai-1-preview": {
            "rating": 1393.4219766507413,
            "rating_q975": 1398.8522932943747,
            "rating_q025": 1387.9916600071078
        },
        "qwen3-235b-a22b-no-thinking": {
            "rating": 1392.1521062305358,
            "rating_q975": 1396.6227167774791,
            "rating_q025": 1387.6814956835924
        },
        "claude-haiku-4-5-20251001": {
            "rating": 1384.2321106477507,
            "rating_q975": 1388.8227891921258,
            "rating_q025": 1379.6414321033756
        },
        "qwen3-30b-a3b-instruct-2507": {
            "rating": 1383.7095089609613,
            "rating_q975": 1388.5768345458814,
            "rating_q025": 1378.8421833760412
        },
        "gpt-4.1-2025-04-14": {
            "rating": 1382.406997436761,
            "rating_q975": 1386.1029576694277,
            "rating_q025": 1378.7110372040943
        },
        "glm-4.5-air": {
            "rating": 1382.1690875937147,
            "rating_q975": 1386.4219499745514,
            "rating_q025": 1377.916225212878
        },
        "kimi-k2-0905-preview": {
            "rating": 1379.9640308426424,
            "rating_q975": 1386.5159880978483,
            "rating_q025": 1373.4120735874365
        },
        "gemini-2.5-flash-lite-preview-09-2025-no-thinking": {
            "rating": 1378.7871639395005,
            "rating_q975": 1383.123294784635,
            "rating_q025": 1374.451033094366
        },
        "hunyuan-turbos-20250416": {
            "rating": 1375.6505582997158,
            "rating_q975": 1381.9443082236653,
            "rating_q025": 1369.3568083757664
        },
        "gpt-5-mini-high": {
            "rating": 1375.2324445346037,
            "rating_q975": 1379.8144570545578,
            "rating_q025": 1370.6504320146496
        },
        "claude-opus-4-20250514-thinking-16k": {
            "rating": 1374.763032123607,
            "rating_q975": 1379.1460046503778,
            "rating_q025": 1370.3800595968362
        },
        "deepseek-v3-0324": {
            "rating": 1374.0903388977772,
            "rating_q975": 1377.9211363970642,
            "rating_q025": 1370.2595413984902
        },
        "deepseek-r1": {
            "rating": 1372.6003155773453,
            "rating_q975": 1377.3569795850572,
            "rating_q025": 1367.8436515696335
        },
        "kimi-k2-0711-preview": {
            "rating": 1371.632267009305,
            "rating_q975": 1376.445139066675,
            "rating_q025": 1366.819394951935
        },
        "gemini-2.5-flash-lite-preview-06-17-thinking": {
            "rating": 1368.8765810225013,
            "rating_q975": 1373.3347910636066,
            "rating_q025": 1364.418370981396
        },
        "mistral-medium-2505": {
            "rating": 1368.5979135669802,
            "rating_q975": 1373.2417823165752,
            "rating_q025": 1363.9540448173852
        },
        "grok-3-mini-high": {
            "rating": 1367.5123012925912,
            "rating_q975": 1372.791821047068,
            "rating_q025": 1362.2327815381145
        },
        "qwen3-next-80b-a3b-thinking": {
            "rating": 1367.0222252285862,
            "rating_q975": 1372.8856803456977,
            "rating_q025": 1361.1587701114747
        },
        "qwen3-235b-a22b": {
            "rating": 1366.9210591249519,
            "rating_q975": 1371.5900665214583,
            "rating_q025": 1362.2520517284454
        },
        "qwen2.5-max": {
            "rating": 1366.7546958296205,
            "rating_q975": 1370.712166377767,
            "rating_q025": 1362.7972252814739
        },
        "o1-2024-12-17": {
            "rating": 1365.571634356339,
            "rating_q975": 1369.9355432461568,
            "rating_q025": 1361.2077254665212
        },
        "gpt-oss-120b": {
            "rating": 1365.1673237680434,
            "rating_q975": 1369.5428130962277,
            "rating_q025": 1360.791834439859
        },
        "claude-opus-4-20250514": {
            "rating": 1364.4931599270662,
            "rating_q975": 1368.7742641854231,
            "rating_q025": 1360.2120556687094
        },
        "ling-flash-2.0": {
            "rating": 1364.29371072206,
            "rating_q975": 1371.4695514733462,
            "rating_q025": 1357.1178699707739
        },
        "nova-2-lite": {
            "rating": 1363.195173287168,
            "rating_q975": 1371.7748838478499,
            "rating_q025": 1354.6154627264862
        },
        "grok-3-mini-beta": {
            "rating": 1362.8974492913667,
            "rating_q975": 1367.8472236444898,
            "rating_q025": 1357.9476749382436
        },
        "gemma-3-27b-it": {
            "rating": 1357.7682543265646,
            "rating_q975": 1361.3669495713425,
            "rating_q025": 1354.1695590817867
        },
        "amazon-nova-experimental-chat-10-09": {
            "rating": 1357.750649762494,
            "rating_q975": 1364.2676669132052,
            "rating_q025": 1351.233632611783
        },
        "qwen3-coder-480b-a35b-instruct": {
            "rating": 1356.4096607772142,
            "rating_q975": 1361.4208673353394,
            "rating_q025": 1351.398454219089
        },
        "gemini-2.0-flash-001": {
            "rating": 1354.3325550858472,
            "rating_q975": 1357.975636495553,
            "rating_q025": 1350.6894736761412
        },
        "o4-mini-2025-04-16": {
            "rating": 1353.9587747052537,
            "rating_q975": 1357.890979896635,
            "rating_q025": 1350.0265695138726
        },
        "o1-preview": {
            "rating": 1352.9667391718453,
            "rating_q975": 1357.90200810853,
            "rating_q025": 1348.0314702351607
        },
        "step-3": {
            "rating": 1349.7145298222201,
            "rating_q975": 1357.0404625767187,
            "rating_q025": 1342.3885970677215
        },
        "claude-sonnet-4-20250514-thinking-32k": {
            "rating": 1349.2078682339547,
            "rating_q975": 1353.6538644694967,
            "rating_q025": 1344.7618719984127
        },
        "intellect-3": {
            "rating": 1347.1348200071839,
            "rating_q975": 1359.7127848323835,
            "rating_q025": 1334.5568551819842
        },
        "minimax-m1": {
            "rating": 1346.4070143526078,
            "rating_q975": 1350.6442469405863,
            "rating_q025": 1342.1697817646293
        },
        "minimax-m2": {
            "rating": 1342.7556542208415,
            "rating_q975": 1350.4214010540675,
            "rating_q025": 1335.0899073876155
        },
        "gpt-4.1-mini-2025-04-14": {
            "rating": 1340.5029515431297,
            "rating_q975": 1344.7676208215307,
            "rating_q025": 1336.2382822647287
        },
        "qwen3-32b": {
            "rating": 1339.781679202713,
            "rating_q975": 1349.1568093780384,
            "rating_q025": 1330.4065490273874
        },
        "mistral-small-2506": {
            "rating": 1339.4246828609662,
            "rating_q975": 1344.575301359509,
            "rating_q025": 1334.2740643624234
        },
        "claude-sonnet-4-20250514": {
            "rating": 1338.3080269109098,
            "rating_q975": 1342.684509834341,
            "rating_q025": 1333.9315439874786
        },
        "nvidia-llama-3.3-nemotron-super-49b-v1.5": {
            "rating": 1336.7227974386237,
            "rating_q975": 1346.524289501865,
            "rating_q025": 1326.9213053753824
        },
        "o3-mini-high": {
            "rating": 1336.3618634881489,
            "rating_q975": 1341.5345877534655,
            "rating_q025": 1331.1891392228322
        },
        "step-1o-turbo-202506": {
            "rating": 1336.2704456550991,
            "rating_q975": 1342.9012788422433,
            "rating_q025": 1329.639612467955
        },
        "gemma-3-12b-it": {
            "rating": 1333.9747666301,
            "rating_q975": 1343.3587844008268,
            "rating_q025": 1324.5907488593732
        },
        "glm-4.5v": {
            "rating": 1333.8708932663303,
            "rating_q975": 1342.2550745832627,
            "rating_q025": 1325.4867119493979
        },
        "deepseek-v3": {
            "rating": 1333.1272167677535,
            "rating_q975": 1337.7563441201007,
            "rating_q025": 1328.4980894154062
        },
        "ring-flash-2.0": {
            "rating": 1332.5813917082087,
            "rating_q975": 1339.7274125506208,
            "rating_q025": 1325.4353708657966
        },
        "glm-4-plus-0111": {
            "rating": 1331.8672536047795,
            "rating_q975": 1340.2373913456547,
            "rating_q025": 1323.4971158639044
        },
        "command-a-03-2025": {
            "rating": 1331.1308136474913,
            "rating_q975": 1334.554885220037,
            "rating_q025": 1327.7067420749456
        },
        "gemini-2.0-flash-lite-preview-02-05": {
            "rating": 1329.8731743056992,
            "rating_q975": 1334.0716094328102,
            "rating_q025": 1325.6747391785882
        },
        "qwq-32b": {
            "rating": 1329.1396890967967,
            "rating_q975": 1333.4970010827092,
            "rating_q025": 1324.7823771108842
        },
        "qwen-plus-0125": {
            "rating": 1326.5349965760993,
            "rating_q975": 1334.8427745106464,
            "rating_q025": 1318.227218641552
        },
        "step-2-16k-exp-202412": {
            "rating": 1321.1742656846586,
            "rating_q975": 1329.691300698513,
            "rating_q025": 1312.6572306708042
        },
        "gpt-5-nano-high": {
            "rating": 1320.7102259638534,
            "rating_q975": 1327.5247979474368,
            "rating_q025": 1313.89565398027
        },
        "o3-mini": {
            "rating": 1320.0165755444852,
            "rating_q975": 1323.468869206717,
            "rating_q025": 1316.5642818822535
        },
        "gemini-1.5-pro-002": {
            "rating": 1319.8321447207713,
            "rating_q975": 1323.0668861228598,
            "rating_q025": 1316.5974033186828
        },
        "llama-3.1-nemotron-ultra-253b-v1": {
            "rating": 1319.7037572168676,
            "rating_q975": 1331.302652273996,
            "rating_q025": 1308.1048621597392
        },
        "hunyuan-turbos-20250226": {
            "rating": 1318.9688587687247,
            "rating_q975": 1330.7098479641156,
            "rating_q025": 1307.2278695733337
        },
        "qwen3-30b-a3b": {
            "rating": 1317.9079935190666,
            "rating_q975": 1322.5759906462804,
            "rating_q025": 1313.2399963918529
        },
        "o1-mini": {
            "rating": 1317.7494171243916,
            "rating_q975": 1321.2602713110034,
            "rating_q025": 1314.2385629377798
        },
        "claude-3-7-sonnet-20250219-thinking-32k": {
            "rating": 1315.2144383988812,
            "rating_q975": 1319.3844375625754,
            "rating_q025": 1311.044439235187
        },
        "hunyuan-turbo-0110": {
            "rating": 1311.2269765804228,
            "rating_q975": 1322.7020056828762,
            "rating_q025": 1299.7519474779695
        },
        "llama-3.3-nemotron-49b-super-v1": {
            "rating": 1308.9437563271563,
            "rating_q975": 1321.0187378038634,
            "rating_q025": 1296.8687748504492
        },
        "gemma-3n-e4b-it": {
            "rating": 1307.2348039769472,
            "rating_q975": 1312.3196102610493,
            "rating_q025": 1302.149997692845
        },
        "olmo-3-32b-think": {
            "rating": 1305.5016217093785,
            "rating_q975": 1316.0555247321238,
            "rating_q025": 1294.9477186866332
        },
        "grok-2-2024-08-13": {
            "rating": 1305.389529495964,
            "rating_q975": 1308.9346453742319,
            "rating_q025": 1301.8444136176963
        },
        "yi-lightning": {
            "rating": 1302.507872982448,
            "rating_q975": 1307.3341489507984,
            "rating_q025": 1297.6815970140974
        },
        "gpt-4o-2024-05-13": {
            "rating": 1301.1368441320633,
            "rating_q975": 1304.470918025407,
            "rating_q025": 1297.8027702387196
        },
        "claude-3-7-sonnet-20250219": {
            "rating": 1299.8749520773308,
            "rating_q975": 1303.7638118247623,
            "rating_q025": 1295.9860923298993
        },
        "qwen2.5-plus-1127": {
            "rating": 1299.4679745540197,
            "rating_q975": 1305.7373579377331,
            "rating_q025": 1293.1985911703064
        },
        "claude-3-5-sonnet-20241022": {
            "rating": 1298.4713263412832,
            "rating_q975": 1301.480915101158,
            "rating_q025": 1295.4617375814084
        },
        "deepseek-v2.5-1210": {
            "rating": 1294.5329992798097,
            "rating_q975": 1302.7280591058454,
            "rating_q025": 1286.337939453774
        },
        "athene-v2-chat": {
            "rating": 1291.9591659865957,
            "rating_q975": 1296.4052549339494,
            "rating_q025": 1287.513077039242
        },
        "gemma-3-4b-it": {
            "rating": 1291.1931951999613,
            "rating_q975": 1300.445230374579,
            "rating_q025": 1281.9411600253436
        },
        "glm-4-plus": {
            "rating": 1290.346385860114,
            "rating_q975": 1295.1780121115817,
            "rating_q025": 1285.5147596086463
        },
        "gpt-oss-20b": {
            "rating": 1288.9449999317371,
            "rating_q975": 1295.2802722413799,
            "rating_q025": 1282.6097276220944
        },
        "llama-4-maverick-17b-128e-instruct": {
            "rating": 1288.6930455673798,
            "rating_q975": 1292.902378554259,
            "rating_q025": 1284.4837125805007
        },
        "hunyuan-large-2025-02-10": {
            "rating": 1288.4020829561427,
            "rating_q975": 1298.1952480189384,
            "rating_q025": 1278.608917893347
        },
        "gemini-1.5-flash-002": {
            "rating": 1287.5990569060639,
            "rating_q975": 1291.684058474116,
            "rating_q025": 1283.5140553380118
        },
        "gpt-4o-mini-2024-07-18": {
            "rating": 1287.222118494587,
            "rating_q975": 1290.5916953805854,
            "rating_q025": 1283.8525416085886
        },
        "mercury": {
            "rating": 1286.6653666159314,
            "rating_q975": 1300.4081350807473,
            "rating_q025": 1272.9225981511154
        },
        "gpt-4.1-nano-2025-04-14": {
            "rating": 1285.358684658697,
            "rating_q975": 1293.0191048408565,
            "rating_q025": 1277.6982644765376
        },
        "llama-3.1-405b-instruct-bf16": {
            "rating": 1284.4486549030921,
            "rating_q975": 1287.9980155390558,
            "rating_q025": 1280.8992942671284
        },
        "gpt-4o-2024-08-06": {
            "rating": 1283.465895957351,
            "rating_q975": 1287.5644284513282,
            "rating_q025": 1279.3673634633737
        },
        "llama-3.1-nemotron-70b-instruct": {
            "rating": 1283.4353095508864,
            "rating_q975": 1291.1227560021096,
            "rating_q025": 1275.7478630996632
        },
        "qwen-max-0919": {
            "rating": 1282.7265235189411,
            "rating_q975": 1288.3412826380743,
            "rating_q025": 1277.111764399808
        },
        "llama-3.1-405b-instruct-fp8": {
            "rating": 1282.6119325014117,
            "rating_q975": 1286.0593840227966,
            "rating_q025": 1279.1644809800268
        },
        "grok-2-mini-2024-08-13": {
            "rating": 1281.654322491533,
            "rating_q975": 1285.243710798558,
            "rating_q025": 1278.0649341845083
        },
        "claude-3-5-sonnet-20240620": {
            "rating": 1281.6114695219708,
            "rating_q975": 1284.9386392534288,
            "rating_q025": 1278.2842997905127
        },
        "llama-4-scout-17b-16e-instruct": {
            "rating": 1281.6097312663687,
            "rating_q975": 1286.2761547623613,
            "rating_q025": 1276.9433077703761
        },
        "gemini-advanced-0514": {
            "rating": 1279.2038686914245,
            "rating_q975": 1284.2958797290032,
            "rating_q025": 1274.1118576538458
        },
        "mistral-small-3.1-24b-instruct-2503": {
            "rating": 1278.9827160868144,
            "rating_q975": 1283.4625087090424,
            "rating_q025": 1274.5029234645865
        },
        "llama-3.3-70b-instruct": {
            "rating": 1276.2328254995527,
            "rating_q975": 1279.571417905368,
            "rating_q025": 1272.8942330937375
        },
        "hunyuan-standard-2025-02-10": {
            "rating": 1274.8668846886194,
            "rating_q975": 1284.580181284992,
            "rating_q025": 1265.1535880922468
        },
        "gemini-1.5-pro-001": {
            "rating": 1274.219013293281,
            "rating_q975": 1278.1222795323815,
            "rating_q025": 1270.3157470541805
        },
        "gpt-4-turbo-2024-04-09": {
            "rating": 1272.4849059553674,
            "rating_q975": 1276.3121898891727,
            "rating_q025": 1268.657622021562
        },
        "deepseek-v2.5": {
            "rating": 1272.2107995472365,
            "rating_q975": 1276.817231259176,
            "rating_q025": 1267.6043678352971
        },
        "qwen2.5-72b-instruct": {
            "rating": 1269.8407462704797,
            "rating_q975": 1273.7939615769342,
            "rating_q025": 1265.8875309640252
        },
        "mistral-large-2407": {
            "rating": 1266.835107740695,
            "rating_q975": 1270.645709807967,
            "rating_q025": 1263.0245056734232
        },
        "hunyuan-large-vision": {
            "rating": 1266.3808443254375,
            "rating_q975": 1275.5242466480993,
            "rating_q025": 1257.2374420027757
        },
        "mistral-large-2411": {
            "rating": 1266.0672092135883,
            "rating_q975": 1270.373559848832,
            "rating_q025": 1261.7608585783446
        },
        "athene-70b-0725": {
            "rating": 1265.4425703304735,
            "rating_q975": 1271.0383165968542,
            "rating_q025": 1259.8468240640927
        },
        "gpt-4-1106-preview": {
            "rating": 1264.1461991220626,
            "rating_q975": 1267.9563049255328,
            "rating_q025": 1260.3360933185925
        },
        "gpt-4-0125-preview": {
            "rating": 1263.0252050381882,
            "rating_q975": 1267.0491843803704,
            "rating_q025": 1259.001225696006
        },
        "claude-3-opus-20240229": {
            "rating": 1262.7447476717662,
            "rating_q975": 1265.6678026806755,
            "rating_q025": 1259.8216926628568
        },
        "llama-3.1-70b-instruct": {
            "rating": 1262.0171474707217,
            "rating_q975": 1265.6036971288352,
            "rating_q025": 1258.4305978126083
        },
        "amazon-nova-pro-v1.0": {
            "rating": 1258.917722692385,
            "rating_q975": 1263.336214959691,
            "rating_q025": 1254.499230425079
        },
        "claude-3-5-haiku-20241022": {
            "rating": 1256.5179869410274,
            "rating_q975": 1259.6233511278756,
            "rating_q025": 1253.4126227541792
        },
        "llama-3.1-tulu-3-70b": {
            "rating": 1255.9164164990277,
            "rating_q975": 1266.3735000373267,
            "rating_q025": 1245.4593329607287
        },
        "magistral-medium-2506": {
            "rating": 1255.6380587233475,
            "rating_q975": 1262.0060252187047,
            "rating_q025": 1249.2700922279903
        },
        "reka-core-20240904": {
            "rating": 1248.864627848479,
            "rating_q975": 1255.9250167546547,
            "rating_q025": 1241.804238942303
        },
        "gemini-1.5-flash-001": {
            "rating": 1239.8690760343827,
            "rating_q975": 1244.2846762415425,
            "rating_q025": 1235.453475827223
        },
        "jamba-1.5-large": {
            "rating": 1238.2156107126489,
            "rating_q975": 1245.4977675305765,
            "rating_q025": 1230.9334538947212
        },
        "mistral-small-24b-instruct-2501": {
            "rating": 1234.407437803111,
            "rating_q975": 1240.19794057358,
            "rating_q025": 1228.616935032642
        },
        "gemma-2-27b-it": {
            "rating": 1232.371897671649,
            "rating_q975": 1235.6035625330608,
            "rating_q025": 1229.1402328102374
        },
        "qwen2.5-coder-32b-instruct": {
            "rating": 1230.3315560026542,
            "rating_q975": 1238.3688024538667,
            "rating_q025": 1222.2943095514418
        },
        "command-r-plus-08-2024": {
            "rating": 1229.9647160961345,
            "rating_q975": 1236.4767855532332,
            "rating_q025": 1223.4526466390357
        },
        "amazon-nova-lite-v1.0": {
            "rating": 1229.2386400795217,
            "rating_q975": 1234.2585619367555,
            "rating_q025": 1224.2187182222879
        },
        "llama-3.1-nemotron-51b-instruct": {
            "rating": 1228.358790445147,
            "rating_q975": 1238.3041509379264,
            "rating_q025": 1218.4134299523676
        },
        "gemma-2-9b-it-simpo": {
            "rating": 1228.1964655471031,
            "rating_q975": 1235.0395151905582,
            "rating_q025": 1221.353415903648
        },
        "gemini-1.5-flash-8b-001": {
            "rating": 1227.2703841706439,
            "rating_q975": 1231.4345067350314,
            "rating_q025": 1223.1062616062563
        },
        "glm-4-0520": {
            "rating": 1226.5961565178263,
            "rating_q975": 1233.5441440066213,
            "rating_q025": 1219.6481690290314
        },
        "nemotron-4-340b-instruct": {
            "rating": 1225.6810931942882,
            "rating_q975": 1230.9395435090055,
            "rating_q025": 1220.422642879571
        },
        "c4ai-aya-expanse-32b": {
            "rating": 1224.9895901108187,
            "rating_q975": 1229.7479620477127,
            "rating_q025": 1220.2312181739246
        },
        "llama-3-70b-instruct": {
            "rating": 1221.7492444378413,
            "rating_q975": 1225.2930195819943,
            "rating_q025": 1218.2054692936883
        },
        "reka-flash-20240904": {
            "rating": 1219.209563594065,
            "rating_q975": 1226.1162036726073,
            "rating_q025": 1212.3029235155227
        },
        "claude-3-sonnet-20240229": {
            "rating": 1219.013357356419,
            "rating_q975": 1222.9698370806457,
            "rating_q025": 1215.0568776321923
        },
        "olmo-2-0325-32b-instruct": {
            "rating": 1218.9279379461916,
            "rating_q975": 1229.7040710960787,
            "rating_q025": 1208.1518047963045
        },
        "phi-4": {
            "rating": 1217.3525401899383,
            "rating_q975": 1221.8277063736696,
            "rating_q025": 1212.877374006207
        },
        "amazon-nova-micro-v1.0": {
            "rating": 1210.3576108192153,
            "rating_q975": 1215.3642648956154,
            "rating_q025": 1205.3509567428152
        },
        "gemma-2-9b-it": {
            "rating": 1208.3954831126453,
            "rating_q975": 1212.0731683455379,
            "rating_q025": 1204.7177978797527
        },
        "gpt-4-0314": {
            "rating": 1206.3665648137417,
            "rating_q975": 1211.1512516266232,
            "rating_q025": 1201.5818780008601
        },
        "command-r-plus": {
            "rating": 1205.2888585271346,
            "rating_q975": 1209.571851364648,
            "rating_q025": 1201.0058656896213
        },
        "qwen2-72b-instruct": {
            "rating": 1203.8237203585563,
            "rating_q975": 1208.6904481334452,
            "rating_q025": 1198.9569925836674
        },
        "hunyuan-standard-256k": {
            "rating": 1203.6050907723056,
            "rating_q975": 1215.201401126784,
            "rating_q025": 1192.0087804178272
        },
        "claude-3-haiku-20240307": {
            "rating": 1195.8927634801485,
            "rating_q975": 1199.570025943733,
            "rating_q025": 1192.2155010165638
        },
        "llama-3.1-tulu-3-8b": {
            "rating": 1195.303760853913,
            "rating_q975": 1205.8013482858437,
            "rating_q025": 1184.8061734219823
        },
        "ministral-8b-2410": {
            "rating": 1192.0700223624037,
            "rating_q975": 1201.0374988278927,
            "rating_q025": 1183.1025458969148
        },
        "deepseek-coder-v2": {
            "rating": 1191.9873639450511,
            "rating_q975": 1198.3351893998286,
            "rating_q025": 1185.6395384902737
        },
        "command-r-08-2024": {
            "rating": 1189.0923038204314,
            "rating_q975": 1195.5792663199297,
            "rating_q025": 1182.6053413209331
        },
        "jamba-1.5-mini": {
            "rating": 1188.171548096541,
            "rating_q975": 1195.323238282253,
            "rating_q025": 1181.0198579108292
        },
        "llama-3.1-8b-instruct": {
            "rating": 1188.0787505146068,
            "rating_q975": 1192.0670669178444,
            "rating_q025": 1184.0904341113692
        },
        "c4ai-aya-expanse-8b": {
            "rating": 1187.1663746979966,
            "rating_q975": 1194.0133609632096,
            "rating_q025": 1180.3193884327836
        },
        "gpt-4-0613": {
            "rating": 1186.9807727794368,
            "rating_q975": 1191.0190606302199,
            "rating_q025": 1182.9424849286538
        },
        "mistral-large-2402": {
            "rating": 1177.0230977611216,
            "rating_q975": 1181.7088685332137,
            "rating_q025": 1172.3373269890294
        },
        "qwen1.5-110b-chat": {
            "rating": 1175.6935459549504,
            "rating_q975": 1181.1853783392437,
            "rating_q025": 1170.2017135706571
        },
        "yi-1.5-34b-chat": {
            "rating": 1173.5540223325465,
            "rating_q975": 1178.5464334060446,
            "rating_q025": 1168.5616112590485
        },
        "reka-flash-21b-20240226-online": {
            "rating": 1171.5430968403793,
            "rating_q975": 1178.8727361122785,
            "rating_q025": 1164.2134575684802
        },
        "qwen1.5-72b-chat": {
            "rating": 1167.5567554527488,
            "rating_q975": 1172.7655753144634,
            "rating_q025": 1162.3479355910342
        },
        "llama-3-8b-instruct": {
            "rating": 1166.7879561547106,
            "rating_q975": 1170.4676690975573,
            "rating_q025": 1163.108243211864
        },
        "mistral-medium": {
            "rating": 1166.2969750920724,
            "rating_q975": 1171.7462087794422,
            "rating_q025": 1160.8477414047027
        },
        "reka-flash-21b-20240226": {
            "rating": 1166.0860724703632,
            "rating_q975": 1171.9969268378575,
            "rating_q025": 1160.175218102869
        },
        "command-r": {
            "rating": 1164.7855029148168,
            "rating_q975": 1169.5124976189136,
            "rating_q025": 1160.05850821072
        },
        "qwq-32b-preview": {
            "rating": 1163.4974507674783,
            "rating_q975": 1174.9274244004498,
            "rating_q025": 1152.0674771345068
        },
        "mixtral-8x22b-instruct-v0.1": {
            "rating": 1162.9351816147805,
            "rating_q975": 1167.4129723263206,
            "rating_q025": 1158.4573909032404
        },
        "internlm2_5-20b-chat": {
            "rating": 1160.554672696817,
            "rating_q975": 1167.5872048559256,
            "rating_q025": 1153.5221405377085
        },
        "gemma-2-2b-it": {
            "rating": 1157.079505102217,
            "rating_q975": 1161.009534611209,
            "rating_q025": 1153.149475593225
        },
        "granite-3.1-8b-instruct": {
            "rating": 1151.9567853016792,
            "rating_q975": 1162.8308308951964,
            "rating_q025": 1141.082739708162
        },
        "gemini-pro-dev-api": {
            "rating": 1150.1065635040134,
            "rating_q975": 1157.367945516045,
            "rating_q025": 1142.8451814919817
        },
        "zephyr-orpo-141b-A35b-v0.1": {
            "rating": 1145.5312568534266,
            "rating_q975": 1156.3086053209174,
            "rating_q025": 1134.7539083859358
        },
        "qwen1.5-32b-chat": {
            "rating": 1139.2593867557189,
            "rating_q975": 1145.3390792292669,
            "rating_q025": 1133.1796942821709
        },
        "phi-3-medium-4k-instruct": {
            "rating": 1138.5776398589096,
            "rating_q975": 1143.6663610821747,
            "rating_q025": 1133.4889186356445
        },
        "starling-lm-7b-beta": {
            "rating": 1133.76768485358,
            "rating_q975": 1141.101405092872,
            "rating_q025": 1126.433964614288
        },
        "mixtral-8x7b-instruct-v0.1": {
            "rating": 1132.926093038598,
            "rating_q975": 1137.1642174598562,
            "rating_q025": 1128.68796861734
        },
        "gemini-pro": {
            "rating": 1132.28045979213,
            "rating_q975": 1143.8729438161708,
            "rating_q025": 1120.687975768089
        },
        "granite-3.1-2b-instruct": {
            "rating": 1130.2090550850344,
            "rating_q975": 1141.2378801173234,
            "rating_q025": 1119.1802300527454
        },
        "qwen1.5-14b-chat": {
            "rating": 1130.0734008099955,
            "rating_q975": 1137.1359186983693,
            "rating_q025": 1123.0108829216217
        },
        "yi-34b-chat": {
            "rating": 1129.6045160335404,
            "rating_q975": 1136.4111501485804,
            "rating_q025": 1122.7978819185005
        },
        "gpt-3.5-turbo-0125": {
            "rating": 1126.4993039253668,
            "rating_q975": 1131.1607745961837,
            "rating_q025": 1121.8378332545499
        },
        "tulu-2-dpo-70b": {
            "rating": 1122.54447365326,
            "rating_q975": 1132.3407160888964,
            "rating_q025": 1112.7482312176235
        },
        "wizardlm-70b": {
            "rating": 1120.852501362238,
            "rating_q975": 1130.3105272789687,
            "rating_q025": 1111.3944754455072
        },
        "dbrx-instruct-preview": {
            "rating": 1120.4818996656895,
            "rating_q975": 1126.5199322500844,
            "rating_q025": 1114.4438670812947
        },
        "llama-2-70b-chat": {
            "rating": 1116.689577433045,
            "rating_q975": 1122.197208953742,
            "rating_q025": 1111.1819459123483
        },
        "nous-hermes-2-mixtral-8x7b-dpo": {
            "rating": 1113.6527384402498,
            "rating_q975": 1125.5701931574313,
            "rating_q025": 1101.7352837230683
        },
        "phi-3-small-8k-instruct": {
            "rating": 1111.2792832525406,
            "rating_q975": 1117.1329490307257,
            "rating_q025": 1105.4256174743555
        },
        "llama-3.2-3b-instruct": {
            "rating": 1110.3757639801177,
            "rating_q975": 1117.9072954294325,
            "rating_q025": 1102.8442325308029
        },
        "starling-lm-7b-alpha": {
            "rating": 1109.0652231165498,
            "rating_q975": 1117.0630291021603,
            "rating_q025": 1101.0674171309392
        },
        "openchat-3.5-0106": {
            "rating": 1108.0886463772806,
            "rating_q975": 1116.0667721538387,
            "rating_q025": 1100.1105206007226
        },
        "vicuna-33b": {
            "rating": 1106.8943739949032,
            "rating_q975": 1113.0877186569796,
            "rating_q025": 1100.7010293328267
        },
        "deepseek-llm-67b-chat": {
            "rating": 1105.5744002831148,
            "rating_q975": 1117.2737515186875,
            "rating_q025": 1093.875049047542
        },
        "snowflake-arctic-instruct": {
            "rating": 1102.6496525991379,
            "rating_q975": 1108.5386782100572,
            "rating_q025": 1096.7606269882185
        },
        "llama2-70b-steerlm-chat": {
            "rating": 1099.8898724989454,
            "rating_q975": 1112.5138093233563,
            "rating_q025": 1087.2659356745344
        },
        "granite-3.0-8b-instruct": {
            "rating": 1099.1146493144456,
            "rating_q975": 1107.6497491709338,
            "rating_q025": 1090.5795494579575
        },
        "openchat-3.5": {
            "rating": 1098.1378719541383,
            "rating_q975": 1107.8880399530851,
            "rating_q025": 1088.3877039551915
        },
        "gemma-1.1-7b-it": {
            "rating": 1096.303706561759,
            "rating_q975": 1102.2971513719547,
            "rating_q025": 1090.3102617515635
        },
        "gpt-3.5-turbo-1106": {
            "rating": 1095.0634244719743,
            "rating_q975": 1103.884490784933,
            "rating_q025": 1086.2423581590156
        },
        "openhermes-2.5-mistral-7b": {
            "rating": 1094.7881504392003,
            "rating_q975": 1105.2512377673734,
            "rating_q025": 1084.3250631110272
        },
        "mistral-7b-instruct-v0.2": {
            "rating": 1091.328663758201,
            "rating_q975": 1097.905322216542,
            "rating_q025": 1084.75200529986
        },
        "llama-2-13b-chat": {
            "rating": 1086.351782554101,
            "rating_q975": 1093.0499747194183,
            "rating_q025": 1079.6535903887836
        },
        "solar-10.7b-instruct-v1.0": {
            "rating": 1085.4847952293794,
            "rating_q975": 1098.7602255699317,
            "rating_q025": 1072.2093648888272
        },
        "qwen1.5-7b-chat": {
            "rating": 1084.5742754877322,
            "rating_q975": 1094.3232459874098,
            "rating_q025": 1074.8253049880545
        },
        "dolphin-2.2.1-mistral-7b": {
            "rating": 1081.7690489513425,
            "rating_q975": 1097.4178857710579,
            "rating_q025": 1066.120212131627
        },
        "granite-3.0-2b-instruct": {
            "rating": 1081.7086877113884,
            "rating_q975": 1089.9142661754033,
            "rating_q025": 1073.5031092473735
        },
        "phi-3-mini-4k-instruct-june-2024": {
            "rating": 1080.6225504172826,
            "rating_q975": 1086.951379010683,
            "rating_q025": 1074.2937218238822
        },
        "wizardlm-13b": {
            "rating": 1078.533141364942,
            "rating_q975": 1087.957572346008,
            "rating_q025": 1069.1087103838759
        },
        "phi-3-mini-4k-instruct": {
            "rating": 1074.9653340706677,
            "rating_q975": 1081.2155383855018,
            "rating_q025": 1068.7151297558337
        },
        "zephyr-7b-beta": {
            "rating": 1070.9500295522298,
            "rating_q975": 1079.7725995302953,
            "rating_q025": 1062.1274595741643
        },
        "mpt-30b-chat": {
            "rating": 1070.416738595858,
            "rating_q975": 1082.7271653334517,
            "rating_q025": 1058.1063118582645
        },
        "codellama-34b-instruct": {
            "rating": 1066.7975878723855,
            "rating_q975": 1075.6597777828802,
            "rating_q025": 1057.9353979618909
        },
        "zephyr-7b-alpha": {
            "rating": 1060.5911468924228,
            "rating_q975": 1076.6104852428648,
            "rating_q025": 1044.5718085419808
        },
        "vicuna-13b": {
            "rating": 1059.5502742665296,
            "rating_q975": 1066.233220317497,
            "rating_q025": 1052.8673282155623
        },
        "codellama-70b-instruct": {
            "rating": 1058.435559453538,
            "rating_q975": 1076.7835803550513,
            "rating_q025": 1040.0875385520246
        },
        "gemma-7b-it": {
            "rating": 1057.2311465326059,
            "rating_q975": 1066.861385973237,
            "rating_q025": 1047.6009070919747
        },
        "llama-3.2-1b-instruct": {
            "rating": 1056.7603555394726,
            "rating_q975": 1064.4361748776075,
            "rating_q025": 1049.0845362013376
        },
        "falcon-180b-chat": {
            "rating": 1056.0033662046126,
            "rating_q975": 1073.3469590511547,
            "rating_q025": 1038.6597733580704
        },
        "guanaco-33b": {
            "rating": 1055.533056697398,
            "rating_q975": 1067.8034962374588,
            "rating_q025": 1043.2626171573372
        },
        "llama-2-7b-chat": {
            "rating": 1054.8090182301753,
            "rating_q975": 1061.8342962533643,
            "rating_q025": 1047.7837402069863
        },
        "phi-3-mini-128k-instruct": {
            "rating": 1053.1174320723885,
            "rating_q975": 1060.3317194330643,
            "rating_q025": 1045.9031447117127
        },
        "qwen-14b-chat": {
            "rating": 1052.6451325001558,
            "rating_q975": 1063.651077742421,
            "rating_q025": 1041.6391872578906
        },
        "smollm2-1.7b-instruct": {
            "rating": 1048.4328974334783,
            "rating_q975": 1062.6060949725543,
            "rating_q025": 1034.2596998944023
        },
        "stripedhyena-nous-7b": {
            "rating": 1039.4082801428176,
            "rating_q975": 1050.5109375132424,
            "rating_q025": 1028.3056227723928
        },
        "vicuna-7b": {
            "rating": 1032.781195481517,
            "rating_q975": 1042.086973510623,
            "rating_q025": 1023.4754174524111
        },
        "olmo-7b-instruct": {
            "rating": 1032.4502599315338,
            "rating_q975": 1043.6334248248622,
            "rating_q025": 1021.2670950382052
        },
        "palm-2": {
            "rating": 1028.8366164414456,
            "rating_q975": 1038.2352603592726,
            "rating_q025": 1019.4379725236187
        },
        "mistral-7b-instruct": {
            "rating": 1025.7109549272598,
            "rating_q975": 1035.0024700160823,
            "rating_q025": 1016.4194398384373
        },
        "gemma-1.1-2b-it": {
            "rating": 1024.833345900753,
            "rating_q975": 1032.5035276969304,
            "rating_q025": 1017.1631641045759
        },
        "gemma-2b-it": {
            "rating": 1003.9228950051552,
            "rating_q975": 1015.5958186059489,
            "rating_q025": 992.2499714043614
        },
        "qwen1.5-4b-chat": {
            "rating": 999.1539653751704,
            "rating_q975": 1008.4658869251082,
            "rating_q025": 989.8420438252326
        },
        "koala-13b": {
            "rating": 991.13939565738,
            "rating_q975": 1001.2186217429004,
            "rating_q025": 981.0601695718595
        },
        "chatglm3-6b": {
            "rating": 973.7733154688622,
            "rating_q975": 985.4837873586853,
            "rating_q025": 962.062843579039
        },
        "gpt4all-13b-snoozy": {
            "rating": 957.3943208251899,
            "rating_q975": 972.7989569173021,
            "rating_q025": 941.9896847330776
        },
        "mpt-7b-chat": {
            "rating": 957.0965517368717,
            "rating_q975": 969.1640458354559,
            "rating_q025": 945.0290576382874
        },
        "RWKV-4-Raven-14B": {
            "rating": 950.594911325315,
            "rating_q975": 962.2258528118234,
            "rating_q025": 938.9639698388066
        },
        "chatglm2-6b": {
            "rating": 940.957484715635,
            "rating_q975": 954.6412046291842,
            "rating_q025": 927.2737648020858
        },
        "alpaca-13b": {
            "rating": 934.6869823866326,
            "rating_q975": 946.3159457958766,
            "rating_q025": 923.0580189773887
        },
        "chatglm-6b": {
            "rating": 920.2360755305735,
            "rating_q975": 932.8485873518744,
            "rating_q025": 907.6235637092727
        },
        "oasst-pythia-12b": {
            "rating": 917.9271463221045,
            "rating_q975": 929.0186506921667,
            "rating_q025": 906.8356419520422
        },
        "fastchat-t5-3b": {
            "rating": 895.8909982605364,
            "rating_q975": 908.462848166005,
            "rating_q025": 883.3191483550679
        },
        "stablelm-tuned-alpha-7b": {
            "rating": 868.4704047619023,
            "rating_q975": 881.5742189957253,
            "rating_q025": 855.3665905280792
        },
        "dolly-v2-12b": {
            "rating": 852.9771440606016,
            "rating_q975": 866.732124787124,
            "rating_q025": 839.2221633340793
        },
        "llama-13b": {
            "rating": 834.7658126127217,
            "rating_q975": 850.9752120170061,
            "rating_q025": 818.5564132084372
        }
    },
    "german": {
        "gemini-3-pro": {
            "rating": 1521.3925542201719,
            "rating_q975": 1554.3834554769078,
            "rating_q025": 1488.401652963436
        },
        "gemini-2.5-pro": {
            "rating": 1484.8382798237358,
            "rating_q975": 1501.0186281168585,
            "rating_q025": 1468.657931530613
        },
        "qwen3-max-preview": {
            "rating": 1457.8291465241316,
            "rating_q975": 1484.2326037930577,
            "rating_q025": 1431.4256892552055
        },
        "glm-4.6": {
            "rating": 1453.3927801724533,
            "rating_q975": 1482.3443605203995,
            "rating_q025": 1424.441199824507
        },
        "gpt-4.5-preview-2025-02-27": {
            "rating": 1453.2738801492865,
            "rating_q975": 1485.740504412024,
            "rating_q025": 1420.807255886549
        },
        "grok-4.1": {
            "rating": 1440.6856297702514,
            "rating_q975": 1472.9882030824012,
            "rating_q025": 1408.3830564581015
        },
        "claude-opus-4-5-20251101": {
            "rating": 1437.9718221408,
            "rating_q975": 1477.9208252829205,
            "rating_q025": 1398.0228189986794
        },
        "gpt-5.1-high": {
            "rating": 1435.7704394095842,
            "rating_q975": 1472.4540585536845,
            "rating_q025": 1399.086820265484
        },
        "grok-4.1-thinking": {
            "rating": 1433.3426689555902,
            "rating_q975": 1466.824485018172,
            "rating_q025": 1399.8608528930083
        },
        "mistral-medium-2508": {
            "rating": 1429.865422574863,
            "rating_q975": 1451.2898659271832,
            "rating_q025": 1408.4409792225429
        },
        "qwen3-max-2025-09-23": {
            "rating": 1428.363994675322,
            "rating_q975": 1469.5316001616316,
            "rating_q025": 1387.1963891890123
        },
        "deepseek-v3.2-exp-thinking": {
            "rating": 1427.6019344767974,
            "rating_q975": 1471.6854703391632,
            "rating_q025": 1383.5183986144316
        },
        "claude-opus-4-5-20251101-thinking-32k": {
            "rating": 1425.382946747462,
            "rating_q975": 1465.8654657065435,
            "rating_q025": 1384.9004277883805
        },
        "claude-sonnet-4-5-20250929": {
            "rating": 1425.0493413108227,
            "rating_q975": 1454.6632330262073,
            "rating_q025": 1395.435449595438
        },
        "qwen3-235b-a22b-instruct-2507": {
            "rating": 1424.55134153982,
            "rating_q975": 1444.0889237905062,
            "rating_q025": 1405.0137592891338
        },
        "gpt-5.1": {
            "rating": 1423.1193048799523,
            "rating_q975": 1459.4606921390475,
            "rating_q025": 1386.7779176208571
        },
        "qwen3-next-80b-a3b-instruct": {
            "rating": 1422.6359379388668,
            "rating_q975": 1450.4498260790651,
            "rating_q025": 1394.8220497986686
        },
        "grok-4-0709": {
            "rating": 1422.1677173147655,
            "rating_q975": 1443.2407259374806,
            "rating_q025": 1401.0947086920503
        },
        "claude-opus-4-1-20250805-thinking-16k": {
            "rating": 1421.3607148754515,
            "rating_q975": 1442.3032819447542,
            "rating_q025": 1400.418147806149
        },
        "deepseek-v3.2-exp": {
            "rating": 1421.297742030374,
            "rating_q975": 1460.9975540725657,
            "rating_q025": 1381.5979299881822
        },
        "qwen3-vl-235b-a22b-thinking": {
            "rating": 1420.7393316290006,
            "rating_q975": 1466.3315466399247,
            "rating_q025": 1375.1471166180766
        },
        "chatgpt-4o-latest-20250326": {
            "rating": 1420.2255511242415,
            "rating_q975": 1437.2816363067288,
            "rating_q025": 1403.1694659417542
        },
        "grok-3-preview-02-24": {
            "rating": 1419.370294958154,
            "rating_q975": 1440.925002975267,
            "rating_q025": 1397.8155869410411
        },
        "longcat-flash-chat": {
            "rating": 1417.312504270017,
            "rating_q975": 1454.459572355759,
            "rating_q025": 1380.1654361842748
        },
        "claude-sonnet-4-5-20250929-thinking-32k": {
            "rating": 1416.4134991509018,
            "rating_q975": 1443.11548973483,
            "rating_q025": 1389.7115085669736
        },
        "o3-2025-04-16": {
            "rating": 1415.6337589213795,
            "rating_q975": 1432.3575361524204,
            "rating_q025": 1398.9099816903386
        },
        "gemini-2.5-flash-preview-09-2025": {
            "rating": 1413.577544185868,
            "rating_q975": 1440.3268969214014,
            "rating_q025": 1386.8281914503345
        },
        "gemini-2.5-flash": {
            "rating": 1411.7139309407808,
            "rating_q975": 1426.9601459208677,
            "rating_q025": 1396.4677159606938
        },
        "gpt-5-high": {
            "rating": 1411.5424461395228,
            "rating_q975": 1435.0896614600917,
            "rating_q025": 1387.9952308189538
        },
        "deepseek-v3.1": {
            "rating": 1410.1106617420644,
            "rating_q975": 1440.5831068980463,
            "rating_q025": 1379.6382165860825
        },
        "deepseek-v3.2-thinking": {
            "rating": 1405.9422348062044,
            "rating_q975": 1454.40022008646,
            "rating_q025": 1357.4842495259488
        },
        "gpt-5-chat": {
            "rating": 1405.6622672811934,
            "rating_q975": 1429.8341204938877,
            "rating_q025": 1381.4904140684991
        },
        "mai-1-preview": {
            "rating": 1404.0152893542297,
            "rating_q975": 1433.8795546415033,
            "rating_q025": 1374.151024066956
        },
        "deepseek-v3.1-thinking": {
            "rating": 1402.290469873467,
            "rating_q975": 1435.4625246036276,
            "rating_q025": 1369.1184151433063
        },
        "qwen3-vl-235b-a22b-instruct": {
            "rating": 1401.4755591796438,
            "rating_q975": 1443.658160747063,
            "rating_q025": 1359.2929576122247
        },
        "qwen3-235b-a22b-thinking-2507": {
            "rating": 1401.0042337038742,
            "rating_q975": 1441.4554089669937,
            "rating_q025": 1360.5530584407547
        },
        "glm-4.5": {
            "rating": 1400.4575608337484,
            "rating_q975": 1426.5758042102916,
            "rating_q025": 1374.3393174572052
        },
        "claude-opus-4-1-20250805": {
            "rating": 1398.0475321802417,
            "rating_q975": 1416.8881865852952,
            "rating_q025": 1379.206877775188
        },
        "deepseek-r1-0528": {
            "rating": 1394.2597863948963,
            "rating_q975": 1419.8655155781953,
            "rating_q025": 1368.6540572115973
        },
        "kimi-k2-0905-preview": {
            "rating": 1391.2523699427957,
            "rating_q975": 1427.915868083554,
            "rating_q025": 1354.5888718020374
        },
        "gemini-2.5-flash-lite-preview-09-2025-no-thinking": {
            "rating": 1391.0637829299278,
            "rating_q975": 1417.8155166052086,
            "rating_q025": 1364.312049254647
        },
        "kimi-k2-thinking-turbo": {
            "rating": 1386.8957962660788,
            "rating_q975": 1421.2816581008165,
            "rating_q025": 1352.5099344313412
        },
        "grok-4-1-fast-reasoning": {
            "rating": 1385.4115250243995,
            "rating_q975": 1438.0270203834098,
            "rating_q025": 1332.7960296653891
        },
        "qwen3-235b-a22b-no-thinking": {
            "rating": 1384.0426456408463,
            "rating_q975": 1403.0820231085436,
            "rating_q025": 1365.003268173149
        },
        "qwen3-235b-a22b": {
            "rating": 1382.7091066655373,
            "rating_q975": 1404.5810373752488,
            "rating_q025": 1360.8371759558258
        },
        "grok-4-fast-reasoning": {
            "rating": 1382.68627126062,
            "rating_q975": 1414.8634961512678,
            "rating_q025": 1350.5090463699723
        },
        "deepseek-r1": {
            "rating": 1379.6065192668286,
            "rating_q975": 1407.1077165288111,
            "rating_q025": 1352.1053220048461
        },
        "claude-opus-4-20250514-thinking-16k": {
            "rating": 1377.6548656025834,
            "rating_q975": 1398.1218302135753,
            "rating_q025": 1357.1879009915915
        },
        "mistral-medium-2505": {
            "rating": 1376.7826609790177,
            "rating_q975": 1395.6992164149083,
            "rating_q025": 1357.866105543127
        },
        "gpt-4.1-2025-04-14": {
            "rating": 1375.4372472722346,
            "rating_q975": 1392.6809677172841,
            "rating_q025": 1358.193526827185
        },
        "deepseek-v3-0324": {
            "rating": 1374.0423155262233,
            "rating_q975": 1392.1873585907204,
            "rating_q025": 1355.8972724617263
        },
        "amazon-nova-experimental-chat-10-20": {
            "rating": 1371.9145918762856,
            "rating_q975": 1413.6226141020506,
            "rating_q025": 1330.2065696505206
        },
        "gemma-3-12b-it": {
            "rating": 1370.3779861129512,
            "rating_q975": 1412.5904517114682,
            "rating_q025": 1328.1655205144343
        },
        "glm-4.5-air": {
            "rating": 1369.7521627877659,
            "rating_q975": 1392.8474428809222,
            "rating_q025": 1346.6568826946095
        },
        "step-3": {
            "rating": 1368.58553902742,
            "rating_q975": 1415.5502989436875,
            "rating_q025": 1321.6207791111526
        },
        "gpt-5-mini-high": {
            "rating": 1368.0943558698198,
            "rating_q975": 1393.704235844595,
            "rating_q025": 1342.4844758950446
        },
        "claude-opus-4-20250514": {
            "rating": 1367.0306680303217,
            "rating_q975": 1384.8664517961024,
            "rating_q025": 1349.194884264541
        },
        "gemini-2.5-flash-lite-preview-06-17-thinking": {
            "rating": 1366.816903359621,
            "rating_q975": 1388.0289787641964,
            "rating_q025": 1345.6048279550455
        },
        "kimi-k2-0711-preview": {
            "rating": 1365.3304551874921,
            "rating_q975": 1388.9869764059981,
            "rating_q025": 1341.6739339689861
        },
        "qwen3-30b-a3b-instruct-2507": {
            "rating": 1364.0220072678962,
            "rating_q975": 1390.9061241222878,
            "rating_q025": 1337.1378904135047
        },
        "deepseek-v3.2": {
            "rating": 1361.6879148816286,
            "rating_q975": 1407.8780461519984,
            "rating_q025": 1315.4977836112587
        },
        "claude-haiku-4-5-20251001": {
            "rating": 1359.6967597311916,
            "rating_q975": 1387.4641415300189,
            "rating_q025": 1331.9293779323643
        },
        "gemma-3-27b-it": {
            "rating": 1356.6714975447135,
            "rating_q975": 1374.3620759989794,
            "rating_q025": 1338.9809190904475
        },
        "qwen3-next-80b-a3b-thinking": {
            "rating": 1355.96478871931,
            "rating_q975": 1390.187142093586,
            "rating_q025": 1321.742435345034
        },
        "grok-3-mini-high": {
            "rating": 1350.3878821834483,
            "rating_q975": 1379.3581738539667,
            "rating_q025": 1321.4175905129298
        },
        "minimax-m2": {
            "rating": 1349.050555960699,
            "rating_q975": 1403.2310605839289,
            "rating_q025": 1294.8700513374692
        },
        "amazon-nova-experimental-chat-10-09": {
            "rating": 1348.9810497217695,
            "rating_q975": 1400.8689596752959,
            "rating_q025": 1297.0931397682432
        },
        "gemini-2.0-flash-001": {
            "rating": 1348.811628627185,
            "rating_q975": 1366.4765326085712,
            "rating_q025": 1331.1467246457987
        },
        "gpt-oss-120b": {
            "rating": 1348.7781766386188,
            "rating_q975": 1373.3160648640132,
            "rating_q025": 1324.2402884132243
        },
        "hunyuan-turbos-20250416": {
            "rating": 1344.680013720854,
            "rating_q975": 1377.0638934526987,
            "rating_q025": 1312.2961339890094
        },
        "mistral-small-2506": {
            "rating": 1343.3437183249534,
            "rating_q975": 1372.58475422401,
            "rating_q025": 1314.1026824258968
        },
        "qwen2.5-max": {
            "rating": 1343.3038053179123,
            "rating_q975": 1364.1665646431557,
            "rating_q025": 1322.441045992669
        },
        "minimax-m1": {
            "rating": 1342.9429747563765,
            "rating_q975": 1363.693584069098,
            "rating_q025": 1322.192365443655
        },
        "gpt-4.1-mini-2025-04-14": {
            "rating": 1342.7027861835827,
            "rating_q975": 1361.5271530784244,
            "rating_q025": 1323.878419288741
        },
        "command-a-03-2025": {
            "rating": 1339.2366262068606,
            "rating_q975": 1356.0035461401787,
            "rating_q025": 1322.4697062735424
        },
        "glm-4-plus-0111": {
            "rating": 1337.8949043975392,
            "rating_q975": 1376.936601773254,
            "rating_q025": 1298.8532070218243
        },
        "qwen3-32b": {
            "rating": 1335.8013449367802,
            "rating_q975": 1376.5268309645246,
            "rating_q025": 1295.0758589090358
        },
        "nova-2-lite": {
            "rating": 1335.1915535841615,
            "rating_q975": 1380.9539306559618,
            "rating_q025": 1289.4291765123612
        },
        "grok-3-mini-beta": {
            "rating": 1334.394345526783,
            "rating_q975": 1358.9577620948544,
            "rating_q025": 1309.8309289587114
        },
        "o4-mini-2025-04-16": {
            "rating": 1332.2700184407718,
            "rating_q975": 1350.3911252003709,
            "rating_q025": 1314.1489116811726
        },
        "o1-2024-12-17": {
            "rating": 1331.8378336857936,
            "rating_q975": 1355.3584993866589,
            "rating_q025": 1308.3171679849283
        },
        "claude-sonnet-4-20250514": {
            "rating": 1329.6225896899161,
            "rating_q975": 1349.0150444295305,
            "rating_q025": 1310.2301349503018
        },
        "gpt-5-nano-high": {
            "rating": 1325.4559992037646,
            "rating_q975": 1366.81111991707,
            "rating_q025": 1284.100878490459
        },
        "qwen3-coder-480b-a35b-instruct": {
            "rating": 1325.3635322720525,
            "rating_q975": 1353.491870514912,
            "rating_q025": 1297.2351940291928
        },
        "deepseek-v3": {
            "rating": 1319.2293638263573,
            "rating_q975": 1343.6769509644985,
            "rating_q025": 1294.781776688216
        },
        "claude-sonnet-4-20250514-thinking-32k": {
            "rating": 1315.6380732423163,
            "rating_q975": 1337.1379541752267,
            "rating_q025": 1294.138192309406
        },
        "qwq-32b": {
            "rating": 1308.0052363966327,
            "rating_q975": 1330.6860398496885,
            "rating_q025": 1285.3244329435768
        },
        "gemma-3n-e4b-it": {
            "rating": 1307.6990275703988,
            "rating_q975": 1329.8952393890056,
            "rating_q025": 1285.502815751792
        },
        "step-1o-turbo-202506": {
            "rating": 1306.5311191750877,
            "rating_q975": 1338.2659342738505,
            "rating_q025": 1274.796304076325
        },
        "o1-preview": {
            "rating": 1305.8077661122597,
            "rating_q975": 1326.6912107023484,
            "rating_q025": 1284.924321522171
        },
        "qwen3-30b-a3b": {
            "rating": 1304.9579813437053,
            "rating_q975": 1326.6444437574726,
            "rating_q025": 1283.271518929938
        },
        "gemini-2.0-flash-lite-preview-02-05": {
            "rating": 1301.1185433902717,
            "rating_q975": 1323.2000857906307,
            "rating_q025": 1279.0370009899127
        },
        "o3-mini-high": {
            "rating": 1300.1402428899069,
            "rating_q975": 1329.4390824084014,
            "rating_q025": 1270.8414033714123
        },
        "o3-mini": {
            "rating": 1300.0279140234877,
            "rating_q975": 1316.5622020024205,
            "rating_q025": 1283.493626044555
        },
        "claude-3-7-sonnet-20250219-thinking-32k": {
            "rating": 1295.2090046456858,
            "rating_q975": 1314.8282509642922,
            "rating_q025": 1275.5897583270794
        },
        "claude-3-5-sonnet-20241022": {
            "rating": 1293.106947671634,
            "rating_q975": 1305.92724280015,
            "rating_q025": 1280.2866525431182
        },
        "llama-4-maverick-17b-128e-instruct": {
            "rating": 1290.4659482850934,
            "rating_q975": 1309.8683099297596,
            "rating_q025": 1271.0635866404273
        },
        "gpt-4.1-nano-2025-04-14": {
            "rating": 1283.6596875934338,
            "rating_q975": 1320.4140761661147,
            "rating_q025": 1246.9052990207529
        },
        "grok-2-2024-08-13": {
            "rating": 1283.4917513683667,
            "rating_q975": 1298.2735161625974,
            "rating_q025": 1268.709986574136
        },
        "gemini-1.5-pro-002": {
            "rating": 1282.9351920049326,
            "rating_q975": 1298.8287154583102,
            "rating_q025": 1267.041668551555
        },
        "claude-3-7-sonnet-20250219": {
            "rating": 1279.3960864223557,
            "rating_q975": 1298.6523350559944,
            "rating_q025": 1260.139837788717
        },
        "gpt-4o-2024-05-13": {
            "rating": 1278.7097648447211,
            "rating_q975": 1290.780824224713,
            "rating_q025": 1266.6387054647294
        },
        "o1-mini": {
            "rating": 1275.0210294742233,
            "rating_q975": 1292.094837006107,
            "rating_q025": 1257.9472219423396
        },
        "glm-4-plus": {
            "rating": 1274.9869616500591,
            "rating_q975": 1297.1355393872043,
            "rating_q025": 1252.838383912914
        },
        "gemma-3-4b-it": {
            "rating": 1274.4799281148407,
            "rating_q975": 1316.222219317238,
            "rating_q025": 1232.7376369124436
        },
        "gemini-advanced-0514": {
            "rating": 1270.620853220454,
            "rating_q975": 1286.908850934223,
            "rating_q025": 1254.3328555066848
        },
        "grok-2-mini-2024-08-13": {
            "rating": 1269.9887701968298,
            "rating_q975": 1286.085450674334,
            "rating_q025": 1253.8920897193257
        },
        "gpt-4o-mini-2024-07-18": {
            "rating": 1267.863793735928,
            "rating_q975": 1282.003328095256,
            "rating_q025": 1253.7242593766002
        },
        "claude-3-5-sonnet-20240620": {
            "rating": 1267.189154522404,
            "rating_q975": 1280.5607677747917,
            "rating_q025": 1253.8175412700161
        },
        "llama-4-scout-17b-16e-instruct": {
            "rating": 1264.0205304848264,
            "rating_q975": 1286.1813256937976,
            "rating_q025": 1241.8597352758552
        },
        "yi-lightning": {
            "rating": 1263.2704759381136,
            "rating_q975": 1284.3147371792807,
            "rating_q025": 1242.2262146969465
        },
        "gemini-1.5-flash-002": {
            "rating": 1259.5931047472986,
            "rating_q975": 1280.2034589306922,
            "rating_q025": 1238.982750563905
        },
        "athene-v2-chat": {
            "rating": 1258.1975358374189,
            "rating_q975": 1280.026010693629,
            "rating_q025": 1236.3690609812088
        },
        "mistral-small-3.1-24b-instruct-2503": {
            "rating": 1256.987481179366,
            "rating_q975": 1278.6727400351554,
            "rating_q025": 1235.3022223235764
        },
        "gpt-4-turbo-2024-04-09": {
            "rating": 1255.4098008237147,
            "rating_q975": 1268.3541425913438,
            "rating_q025": 1242.4654590560856
        },
        "claude-3-opus-20240229": {
            "rating": 1254.8827432291475,
            "rating_q975": 1265.8827834646686,
            "rating_q025": 1243.8827029936265
        },
        "deepseek-v2.5-1210": {
            "rating": 1254.7648349462738,
            "rating_q975": 1300.4586312203778,
            "rating_q025": 1209.0710386721698
        },
        "gpt-4o-2024-08-06": {
            "rating": 1253.7916801652125,
            "rating_q975": 1270.3009313318707,
            "rating_q025": 1237.2824289985542
        },
        "gpt-oss-20b": {
            "rating": 1251.2803231658386,
            "rating_q975": 1292.1000707205774,
            "rating_q025": 1210.4605756110998
        },
        "qwen-max-0919": {
            "rating": 1250.4183351619445,
            "rating_q975": 1275.954158415598,
            "rating_q025": 1224.882511908291
        },
        "mistral-large-2407": {
            "rating": 1250.0982000168337,
            "rating_q975": 1266.7558531617722,
            "rating_q025": 1233.4405468718953
        },
        "llama-3.1-405b-instruct-bf16": {
            "rating": 1248.8214026173346,
            "rating_q975": 1267.481781703854,
            "rating_q025": 1230.161023530815
        },
        "llama-3.3-70b-instruct": {
            "rating": 1248.7391659242526,
            "rating_q975": 1265.528387426109,
            "rating_q025": 1231.9499444223961
        },
        "athene-70b-0725": {
            "rating": 1247.640714877074,
            "rating_q975": 1270.6854304227295,
            "rating_q025": 1224.5959993314186
        },
        "gpt-4-1106-preview": {
            "rating": 1246.6180675325604,
            "rating_q975": 1260.7165024249964,
            "rating_q025": 1232.5196326401244
        },
        "llama-3.1-405b-instruct-fp8": {
            "rating": 1246.2520876627207,
            "rating_q975": 1261.2840530982273,
            "rating_q025": 1231.220122227214
        },
        "gemini-1.5-pro-001": {
            "rating": 1245.6208836553988,
            "rating_q975": 1259.2254448572694,
            "rating_q025": 1232.0163224535281
        },
        "gpt-4-0125-preview": {
            "rating": 1241.1538735986478,
            "rating_q975": 1255.0003208080445,
            "rating_q025": 1227.307426389251
        },
        "mistral-large-2411": {
            "rating": 1240.1283725038447,
            "rating_q975": 1262.2754594583482,
            "rating_q025": 1217.9812855493412
        },
        "reka-core-20240904": {
            "rating": 1239.7335667275865,
            "rating_q975": 1279.9175199413492,
            "rating_q025": 1199.549613513824
        },
        "magistral-medium-2506": {
            "rating": 1239.0142760434585,
            "rating_q975": 1272.1570901126695,
            "rating_q025": 1205.8714619742475
        },
        "claude-3-5-haiku-20241022": {
            "rating": 1236.3745140760668,
            "rating_q975": 1251.1856458533434,
            "rating_q025": 1221.5633822987902
        },
        "amazon-nova-pro-v1.0": {
            "rating": 1235.7094678160051,
            "rating_q975": 1258.421829983587,
            "rating_q025": 1212.9971056484233
        },
        "qwen2.5-72b-instruct": {
            "rating": 1230.489593436061,
            "rating_q975": 1248.8049706246572,
            "rating_q025": 1212.174216247465
        },
        "qwen2.5-plus-1127": {
            "rating": 1226.592918912795,
            "rating_q975": 1261.732926672423,
            "rating_q025": 1191.4529111531672
        },
        "amazon-nova-lite-v1.0": {
            "rating": 1224.3291152037673,
            "rating_q975": 1250.214670684103,
            "rating_q025": 1198.4435597234315
        },
        "deepseek-v2.5": {
            "rating": 1222.98548761544,
            "rating_q975": 1246.7532569198427,
            "rating_q025": 1199.2177183110373
        },
        "phi-4": {
            "rating": 1218.972260971494,
            "rating_q975": 1244.0031755653276,
            "rating_q025": 1193.9413463776605
        },
        "llama-3.1-70b-instruct": {
            "rating": 1218.4843836410569,
            "rating_q975": 1234.358698498434,
            "rating_q025": 1202.6100687836797
        },
        "gemma-2-9b-it-simpo": {
            "rating": 1216.1098763209677,
            "rating_q975": 1246.7165600671394,
            "rating_q025": 1185.503192574796
        },
        "gemini-1.5-flash-001": {
            "rating": 1213.02953988036,
            "rating_q975": 1227.2450266378098,
            "rating_q025": 1198.8140531229103
        },
        "command-r-plus-08-2024": {
            "rating": 1212.4041217207086,
            "rating_q975": 1245.4154074628182,
            "rating_q025": 1179.3928359785991
        },
        "mistral-small-24b-instruct-2501": {
            "rating": 1208.2373394882388,
            "rating_q975": 1241.5354871609434,
            "rating_q025": 1174.9391918155343
        },
        "gemma-2-27b-it": {
            "rating": 1205.4646955746696,
            "rating_q975": 1218.667533702861,
            "rating_q025": 1192.2618574464782
        },
        "gemini-1.5-flash-8b-001": {
            "rating": 1201.9477263235203,
            "rating_q975": 1222.1349884405986,
            "rating_q025": 1181.760464206442
        },
        "claude-3-sonnet-20240229": {
            "rating": 1200.1607145562662,
            "rating_q975": 1213.8532756454215,
            "rating_q025": 1186.4681534671108
        },
        "c4ai-aya-expanse-32b": {
            "rating": 1195.5523600970143,
            "rating_q975": 1218.559626891781,
            "rating_q025": 1172.5450933022478
        },
        "gpt-4-0314": {
            "rating": 1194.4292100476807,
            "rating_q975": 1212.5499961585356,
            "rating_q025": 1176.3084239368259
        },
        "jamba-1.5-large": {
            "rating": 1194.40946408863,
            "rating_q975": 1230.8361241470157,
            "rating_q025": 1157.9828040302446
        },
        "command-r-plus": {
            "rating": 1191.3673639620868,
            "rating_q975": 1205.2414608816061,
            "rating_q025": 1177.4932670425674
        },
        "amazon-nova-micro-v1.0": {
            "rating": 1190.0642481457742,
            "rating_q975": 1216.5154433019006,
            "rating_q025": 1163.6130529896477
        },
        "nemotron-4-340b-instruct": {
            "rating": 1188.252416403381,
            "rating_q975": 1210.564084432171,
            "rating_q025": 1165.9407483745908
        },
        "c4ai-aya-expanse-8b": {
            "rating": 1185.499124235058,
            "rating_q975": 1221.9394079419194,
            "rating_q025": 1149.0588405281965
        },
        "gemma-2-9b-it": {
            "rating": 1182.28373645198,
            "rating_q975": 1197.336894614252,
            "rating_q025": 1167.230578289708
        },
        "glm-4-0520": {
            "rating": 1180.168742045923,
            "rating_q975": 1209.574124001054,
            "rating_q025": 1150.7633600907918
        },
        "mistral-large-2402": {
            "rating": 1175.3820923221117,
            "rating_q975": 1191.3263511918296,
            "rating_q025": 1159.4378334523938
        },
        "reka-flash-20240904": {
            "rating": 1174.8525475165063,
            "rating_q975": 1213.1691347813996,
            "rating_q025": 1136.535960251613
        },
        "command-r-08-2024": {
            "rating": 1172.6214243159727,
            "rating_q975": 1205.0343155586195,
            "rating_q025": 1140.208533073326
        },
        "claude-3-haiku-20240307": {
            "rating": 1169.7924359883111,
            "rating_q975": 1182.417433289946,
            "rating_q025": 1157.1674386866762
        },
        "llama-3-70b-instruct": {
            "rating": 1165.6669011448266,
            "rating_q975": 1177.8434063827804,
            "rating_q025": 1153.490395906873
        },
        "jamba-1.5-mini": {
            "rating": 1160.4762072894744,
            "rating_q975": 1198.080455462659,
            "rating_q025": 1122.8719591162896
        },
        "deepseek-coder-v2": {
            "rating": 1160.0230643722907,
            "rating_q975": 1185.5972005176418,
            "rating_q025": 1134.4489282269396
        },
        "gpt-4-0613": {
            "rating": 1157.6565473855499,
            "rating_q975": 1172.457802647897,
            "rating_q025": 1142.8552921232026
        },
        "mistral-medium": {
            "rating": 1152.4684361247314,
            "rating_q975": 1173.9561580758618,
            "rating_q025": 1130.980714173601
        },
        "reka-flash-21b-20240226": {
            "rating": 1149.3218546106139,
            "rating_q975": 1170.0467110111117,
            "rating_q025": 1128.596998210116
        },
        "reka-flash-21b-20240226-online": {
            "rating": 1148.0208195398127,
            "rating_q975": 1173.9535714892556,
            "rating_q025": 1122.0880675903697
        },
        "qwen2-72b-instruct": {
            "rating": 1146.9390985171076,
            "rating_q975": 1163.7092201457601,
            "rating_q025": 1130.168976888455
        },
        "llama-3.1-8b-instruct": {
            "rating": 1141.1593210906194,
            "rating_q975": 1157.9276440002402,
            "rating_q025": 1124.3909981809986
        },
        "mixtral-8x22b-instruct-v0.1": {
            "rating": 1137.0640190469223,
            "rating_q975": 1153.1426350064114,
            "rating_q025": 1120.9854030874333
        },
        "gemini-pro-dev-api": {
            "rating": 1122.325899520216,
            "rating_q975": 1151.2331618657024,
            "rating_q025": 1093.4186371747294
        },
        "command-r": {
            "rating": 1122.2334732970899,
            "rating_q975": 1139.7184382103626,
            "rating_q025": 1104.7485083838171
        },
        "qwen1.5-110b-chat": {
            "rating": 1120.1447257789855,
            "rating_q975": 1140.1185007528836,
            "rating_q025": 1100.1709508050874
        },
        "gemma-2-2b-it": {
            "rating": 1111.6428983363567,
            "rating_q975": 1129.4883356113128,
            "rating_q025": 1093.7974610614006
        },
        "mixtral-8x7b-instruct-v0.1": {
            "rating": 1110.5696151735585,
            "rating_q975": 1125.7645317911188,
            "rating_q025": 1095.3746985559983
        },
        "yi-1.5-34b-chat": {
            "rating": 1107.9750454915215,
            "rating_q975": 1127.7430651596321,
            "rating_q025": 1088.207025823411
        },
        "llama-3-8b-instruct": {
            "rating": 1101.8299265227363,
            "rating_q975": 1115.1579064768898,
            "rating_q025": 1088.5019465685828
        },
        "phi-3-medium-4k-instruct": {
            "rating": 1099.2231719537258,
            "rating_q975": 1119.5404211503778,
            "rating_q025": 1078.9059227570738
        },
        "gpt-3.5-turbo-0125": {
            "rating": 1086.854009333477,
            "rating_q975": 1102.7530476930135,
            "rating_q025": 1070.9549709739406
        },
        "qwen1.5-72b-chat": {
            "rating": 1081.0446374364326,
            "rating_q975": 1099.9808687637149,
            "rating_q025": 1062.1084061091503
        },
        "wizardlm-70b": {
            "rating": 1079.8348831317526,
            "rating_q975": 1124.1188662107795,
            "rating_q025": 1035.5509000527256
        },
        "starling-lm-7b-beta": {
            "rating": 1077.8653516833033,
            "rating_q975": 1107.9206781602309,
            "rating_q025": 1047.8100252063757
        },
        "phi-3-small-8k-instruct": {
            "rating": 1076.2481435830023,
            "rating_q975": 1099.8613324532275,
            "rating_q025": 1052.634954712777
        },
        "snowflake-arctic-instruct": {
            "rating": 1070.531808953951,
            "rating_q975": 1092.0727634828247,
            "rating_q025": 1048.9908544250773
        },
        "openchat-3.5-0106": {
            "rating": 1061.2532918212974,
            "rating_q975": 1094.4597112886852,
            "rating_q025": 1028.0468723539095
        },
        "internlm2_5-20b-chat": {
            "rating": 1059.271349718501,
            "rating_q975": 1096.135448922279,
            "rating_q025": 1022.4072505147227
        },
        "vicuna-33b": {
            "rating": 1057.9234329526303,
            "rating_q975": 1086.7089280259502,
            "rating_q025": 1029.1379378793104
        },
        "gpt-3.5-turbo-1106": {
            "rating": 1055.759192802177,
            "rating_q975": 1090.2735439843873,
            "rating_q025": 1021.2448416199668
        },
        "qwen1.5-32b-chat": {
            "rating": 1054.525649582541,
            "rating_q975": 1076.3259530294717,
            "rating_q025": 1032.7253461356104
        },
        "dbrx-instruct-preview": {
            "rating": 1053.4449917332558,
            "rating_q975": 1075.7824320100062,
            "rating_q025": 1031.1075514565055
        },
        "llama-3.2-3b-instruct": {
            "rating": 1052.676883702086,
            "rating_q975": 1092.872048334452,
            "rating_q025": 1012.4817190697196
        },
        "gemma-1.1-7b-it": {
            "rating": 1051.0628811045674,
            "rating_q975": 1072.0400499443851,
            "rating_q025": 1030.0857122647496
        },
        "phi-3-mini-4k-instruct": {
            "rating": 1039.890987446764,
            "rating_q975": 1062.9657582920242,
            "rating_q025": 1016.8162166015037
        },
        "qwen1.5-14b-chat": {
            "rating": 1039.132809574733,
            "rating_q975": 1064.2746045113124,
            "rating_q025": 1013.9910146381537
        },
        "yi-34b-chat": {
            "rating": 1038.7527476644236,
            "rating_q975": 1070.1170983314823,
            "rating_q025": 1007.388396997365
        },
        "llama-2-70b-chat": {
            "rating": 1037.580358371882,
            "rating_q975": 1058.8933217470494,
            "rating_q025": 1016.2673949967148
        },
        "phi-3-mini-4k-instruct-june-2024": {
            "rating": 1027.8596586909127,
            "rating_q975": 1059.4682327863695,
            "rating_q025": 996.251084595456
        },
        "starling-lm-7b-alpha": {
            "rating": 1023.4671576542421,
            "rating_q975": 1065.390138968691,
            "rating_q025": 981.5441763397932
        },
        "llama-3.2-1b-instruct": {
            "rating": 1010.2210241064956,
            "rating_q975": 1049.7045738150562,
            "rating_q025": 970.7374743979351
        },
        "llama-2-13b-chat": {
            "rating": 1003.7202516141413,
            "rating_q975": 1033.1070879160302,
            "rating_q025": 974.3334153122524
        },
        "phi-3-mini-128k-instruct": {
            "rating": 1002.8781854042747,
            "rating_q975": 1026.6366738746692,
            "rating_q025": 979.1196969338803
        },
        "zephyr-7b-beta": {
            "rating": 989.0312558526052,
            "rating_q975": 1036.7950007796967,
            "rating_q025": 941.2675109255138
        },
        "vicuna-13b": {
            "rating": 988.4335028027252,
            "rating_q975": 1024.2578818415468,
            "rating_q025": 952.6091237639035
        },
        "mistral-7b-instruct-v0.2": {
            "rating": 981.7119480958897,
            "rating_q975": 1008.3138476706841,
            "rating_q025": 955.1100485210953
        },
        "gemma-7b-it": {
            "rating": 979.6799933388322,
            "rating_q975": 1023.6835071971891,
            "rating_q025": 935.6764794804753
        },
        "llama-2-7b-chat": {
            "rating": 973.5602068610967,
            "rating_q975": 1007.5956702035546,
            "rating_q025": 939.5247435186388
        },
        "gemma-1.1-2b-it": {
            "rating": 941.7498038776123,
            "rating_q975": 975.777179217677,
            "rating_q025": 907.7224285375476
        },
        "mistral-7b-instruct": {
            "rating": 928.0191504885997,
            "rating_q975": 973.3858223488817,
            "rating_q025": 882.6524786283178
        },
        "qwen1.5-4b-chat": {
            "rating": 899.4593823356049,
            "rating_q975": 938.0330889812233,
            "rating_q025": 860.8856756899866
        }
    },
    "hard_6": {
        "gemini-3-pro": {
            "rating": 1482.8577422781843,
            "rating_q975": 1490.8229729002824,
            "rating_q025": 1474.8925116560863
        },
        "claude-opus-4-5-20251101": {
            "rating": 1472.9825335384044,
            "rating_q975": 1482.280130601098,
            "rating_q025": 1463.6849364757106
        },
        "claude-opus-4-5-20251101-thinking-32k": {
            "rating": 1470.6972741621519,
            "rating_q975": 1480.10785353234,
            "rating_q025": 1461.2866947919638
        },
        "gemini-2.5-pro": {
            "rating": 1461.0299442552807,
            "rating_q975": 1465.555584348275,
            "rating_q025": 1456.5043041622864
        },
        "claude-sonnet-4-5-20250929-thinking-32k": {
            "rating": 1456.6835001895054,
            "rating_q975": 1462.6398765996112,
            "rating_q025": 1450.7271237793996
        },
        "gpt-5.1-high": {
            "rating": 1454.6574780546766,
            "rating_q975": 1463.0920287035633,
            "rating_q025": 1446.22292740579
        },
        "grok-4.1-thinking": {
            "rating": 1449.4282932565304,
            "rating_q975": 1457.2794710346323,
            "rating_q025": 1441.5771154784286
        },
        "claude-sonnet-4-5-20250929": {
            "rating": 1448.9071957668316,
            "rating_q975": 1455.3759387941818,
            "rating_q025": 1442.4384527394814
        },
        "qwen3-max-preview": {
            "rating": 1447.3282453973663,
            "rating_q975": 1453.3286371462557,
            "rating_q025": 1441.327853648477
        },
        "claude-opus-4-1-20250805-thinking-16k": {
            "rating": 1443.6447295964028,
            "rating_q975": 1448.7747347316274,
            "rating_q025": 1438.5147244611783
        },
        "glm-4.6": {
            "rating": 1441.962275103018,
            "rating_q975": 1448.068900484892,
            "rating_q025": 1435.8556497211441
        },
        "ernie-5.0-preview-1103": {
            "rating": 1440.4932228638113,
            "rating_q975": 1451.8252514592061,
            "rating_q025": 1429.1611942684165
        },
        "grok-4.1": {
            "rating": 1439.6431407021762,
            "rating_q975": 1447.4755214010163,
            "rating_q025": 1431.810760003336
        },
        "mistral-large-3": {
            "rating": 1437.4671537478723,
            "rating_q975": 1448.0032472754726,
            "rating_q025": 1426.931060220272
        },
        "claude-opus-4-1-20250805": {
            "rating": 1436.6940514587304,
            "rating_q975": 1441.6189255470758,
            "rating_q025": 1431.769177370385
        },
        "qwen3-235b-a22b-instruct-2507": {
            "rating": 1435.4585336707162,
            "rating_q975": 1440.342418620746,
            "rating_q025": 1430.5746487206864
        },
        "gpt-5.1": {
            "rating": 1432.334406401985,
            "rating_q975": 1440.188323352982,
            "rating_q025": 1424.480489450988
        },
        "longcat-flash-chat": {
            "rating": 1431.822453359245,
            "rating_q975": 1440.1004788494208,
            "rating_q025": 1423.544427869069
        },
        "mistral-medium-2508": {
            "rating": 1431.4844497127665,
            "rating_q975": 1436.5862382546186,
            "rating_q025": 1426.3826611709144
        },
        "grok-3-preview-02-24": {
            "rating": 1431.1575954710586,
            "rating_q975": 1437.4723070572106,
            "rating_q025": 1424.8428838849065
        },
        "qwen3-vl-235b-a22b-instruct": {
            "rating": 1430.353029507346,
            "rating_q975": 1439.3094658435118,
            "rating_q025": 1421.3965931711803
        },
        "deepseek-v3.2-exp": {
            "rating": 1429.7589100939301,
            "rating_q975": 1437.9862200485356,
            "rating_q025": 1421.5316001393246
        },
        "qwen3-next-80b-a3b-instruct": {
            "rating": 1429.5883311456587,
            "rating_q975": 1435.797880386581,
            "rating_q025": 1423.3787819047363
        },
        "glm-4.5": {
            "rating": 1428.1384419083674,
            "rating_q975": 1434.5951548334172,
            "rating_q025": 1421.6817289833177
        },
        "deepseek-v3.2": {
            "rating": 1424.9825336932936,
            "rating_q975": 1435.4607133009533,
            "rating_q025": 1414.5043540856338
        },
        "qwen3-max-2025-09-23": {
            "rating": 1423.7674448350274,
            "rating_q975": 1432.3194614872707,
            "rating_q025": 1415.215428182784
        },
        "deepseek-v3.1-terminus-thinking": {
            "rating": 1423.2286495573276,
            "rating_q975": 1437.639727908104,
            "rating_q025": 1408.817571206551
        },
        "deepseek-v3.2-exp-thinking": {
            "rating": 1423.130135062975,
            "rating_q975": 1431.8415501389622,
            "rating_q025": 1414.4187199869875
        },
        "kimi-k2-thinking-turbo": {
            "rating": 1422.5226685169994,
            "rating_q975": 1430.0761751064879,
            "rating_q025": 1414.9691619275109
        },
        "chatgpt-4o-latest-20250326": {
            "rating": 1421.154837504826,
            "rating_q975": 1425.6800603266397,
            "rating_q025": 1416.6296146830123
        },
        "gemini-2.5-flash": {
            "rating": 1418.0359490429305,
            "rating_q975": 1422.510249440154,
            "rating_q025": 1413.561648645707
        },
        "gpt-5-high": {
            "rating": 1416.775142768985,
            "rating_q975": 1422.6729971663885,
            "rating_q025": 1410.8772883715815
        },
        "qwen3-235b-a22b-thinking-2507": {
            "rating": 1416.2589443960112,
            "rating_q975": 1425.736621663329,
            "rating_q025": 1406.7812671286933
        },
        "deepseek-v3.1-thinking": {
            "rating": 1416.1672074268865,
            "rating_q975": 1424.8914983422424,
            "rating_q025": 1407.4429165115307
        },
        "deepseek-v3.2-thinking": {
            "rating": 1416.057530999331,
            "rating_q975": 1427.026383411429,
            "rating_q025": 1405.088678587233
        },
        "deepseek-r1-0528": {
            "rating": 1415.2958251815862,
            "rating_q975": 1422.9941652487298,
            "rating_q025": 1407.5974851144426
        },
        "deepseek-v3.1": {
            "rating": 1414.512304494824,
            "rating_q975": 1422.3772422983725,
            "rating_q025": 1406.6473666912757
        },
        "hunyuan-vision-1.5-thinking": {
            "rating": 1413.7863930874787,
            "rating_q975": 1431.2826867161998,
            "rating_q025": 1396.2900994587576
        },
        "claude-haiku-4-5-20251001": {
            "rating": 1412.8070920611194,
            "rating_q975": 1418.8346179360456,
            "rating_q025": 1406.7795661861933
        },
        "grok-4-fast-chat": {
            "rating": 1411.007225803022,
            "rating_q975": 1421.5938139497514,
            "rating_q025": 1400.4206376562927
        },
        "grok-4-1-fast-reasoning": {
            "rating": 1408.8061331782812,
            "rating_q975": 1417.8824064493767,
            "rating_q025": 1399.7298599071858
        },
        "gemini-2.5-flash-preview-09-2025": {
            "rating": 1407.7274638279353,
            "rating_q975": 1413.442886941978,
            "rating_q025": 1402.0120407138925
        },
        "qwen3-vl-235b-a22b-thinking": {
            "rating": 1407.011789496389,
            "rating_q975": 1416.2683933541466,
            "rating_q025": 1397.7551856386312
        },
        "grok-4-0709": {
            "rating": 1406.4997101334725,
            "rating_q975": 1411.6350709164153,
            "rating_q025": 1401.3643493505297
        },
        "deepseek-v3.1-terminus": {
            "rating": 1405.5649140075668,
            "rating_q975": 1418.8539359845672,
            "rating_q025": 1392.2758920305664
        },
        "gpt-5-chat": {
            "rating": 1404.1302135477965,
            "rating_q975": 1409.8278819494396,
            "rating_q025": 1398.4325451461534
        },
        "gpt-4.5-preview-2025-02-27": {
            "rating": 1402.0761030561303,
            "rating_q975": 1412.0193829581747,
            "rating_q025": 1392.1328231540858
        },
        "o3-2025-04-16": {
            "rating": 1402.0520984090165,
            "rating_q975": 1406.9371996076331,
            "rating_q025": 1397.1669972103998
        },
        "grok-4-fast-reasoning": {
            "rating": 1401.8628338822673,
            "rating_q975": 1408.4581480708919,
            "rating_q025": 1395.2675196936427
        },
        "amazon-nova-experimental-chat-10-20": {
            "rating": 1398.4784539875634,
            "rating_q975": 1407.9511991334787,
            "rating_q025": 1389.0057088416481
        },
        "hunyuan-t1-20250711": {
            "rating": 1397.6044002019478,
            "rating_q975": 1410.755848101254,
            "rating_q025": 1384.4529523026415
        },
        "qwen3-30b-a3b-instruct-2507": {
            "rating": 1397.4909564825566,
            "rating_q975": 1403.8882604502005,
            "rating_q025": 1391.0936525149127
        },
        "claude-opus-4-20250514-thinking-16k": {
            "rating": 1396.6642302877813,
            "rating_q975": 1402.4238232237935,
            "rating_q025": 1390.904637351769
        },
        "qwen3-235b-a22b-no-thinking": {
            "rating": 1391.2337092494422,
            "rating_q975": 1396.943943082241,
            "rating_q025": 1385.5234754166434
        },
        "mai-1-preview": {
            "rating": 1385.7957438391925,
            "rating_q975": 1392.9990051777168,
            "rating_q025": 1378.5924825006682
        },
        "gpt-4.1-2025-04-14": {
            "rating": 1381.9091333478084,
            "rating_q975": 1386.9007100662384,
            "rating_q025": 1376.9175566293784
        },
        "gpt-5-mini-high": {
            "rating": 1381.2761789943183,
            "rating_q975": 1387.3985098502383,
            "rating_q025": 1375.1538481383984
        },
        "kimi-k2-0905-preview": {
            "rating": 1380.5268923907665,
            "rating_q975": 1388.9853492792372,
            "rating_q025": 1372.0684355022959
        },
        "gemini-2.5-flash-lite-preview-09-2025-no-thinking": {
            "rating": 1378.2641475012929,
            "rating_q975": 1383.9893650754962,
            "rating_q025": 1372.5389299270896
        },
        "glm-4.5-air": {
            "rating": 1377.6298912883556,
            "rating_q975": 1383.2726638254144,
            "rating_q025": 1371.9871187512967
        },
        "claude-opus-4-20250514": {
            "rating": 1374.6098711223974,
            "rating_q975": 1380.1386319907808,
            "rating_q025": 1369.081110254014
        },
        "gemini-2.5-flash-lite-preview-06-17-thinking": {
            "rating": 1373.206563758707,
            "rating_q975": 1379.0665955710256,
            "rating_q025": 1367.3465319463885
        },
        "grok-3-mini-high": {
            "rating": 1371.9292066229343,
            "rating_q975": 1379.081495661938,
            "rating_q025": 1364.7769175839305
        },
        "hunyuan-turbos-20250416": {
            "rating": 1371.1047127605855,
            "rating_q975": 1380.524775966445,
            "rating_q025": 1361.6846495547259
        },
        "nova-2-lite": {
            "rating": 1371.0276104097018,
            "rating_q975": 1382.0732302159377,
            "rating_q025": 1359.9819906034659
        },
        "claude-sonnet-4-20250514-thinking-32k": {
            "rating": 1370.5106606964705,
            "rating_q975": 1376.3139014828816,
            "rating_q025": 1364.7074199100593
        },
        "qwen3-coder-480b-a35b-instruct": {
            "rating": 1370.510520570077,
            "rating_q975": 1377.0924300661104,
            "rating_q025": 1363.9286110740436
        },
        "o1-2024-12-17": {
            "rating": 1370.1266594855701,
            "rating_q975": 1377.6914053599032,
            "rating_q025": 1362.561913611237
        },
        "qwen3-next-80b-a3b-thinking": {
            "rating": 1370.0317864709468,
            "rating_q975": 1377.6745772102438,
            "rating_q025": 1362.3889957316499
        },
        "kimi-k2-0711-preview": {
            "rating": 1366.4101093605507,
            "rating_q975": 1372.7513931185963,
            "rating_q025": 1360.068825602505
        },
        "o3-mini-high": {
            "rating": 1363.680339562229,
            "rating_q975": 1372.7163638465543,
            "rating_q025": 1354.6443152779036
        },
        "ling-flash-2.0": {
            "rating": 1363.4948373506688,
            "rating_q975": 1373.3970243099793,
            "rating_q025": 1353.5926503913583
        },
        "deepseek-v3-0324": {
            "rating": 1363.2003361036398,
            "rating_q975": 1368.4738023199493,
            "rating_q025": 1357.9268698873302
        },
        "grok-3-mini-beta": {
            "rating": 1362.8196411823578,
            "rating_q975": 1369.4429087605447,
            "rating_q025": 1356.196373604171
        },
        "mistral-medium-2505": {
            "rating": 1362.3769042015626,
            "rating_q975": 1368.3828466655275,
            "rating_q025": 1356.3709617375978
        },
        "qwen3-235b-a22b": {
            "rating": 1361.776114835763,
            "rating_q975": 1368.1209241968506,
            "rating_q025": 1355.4313054746756
        },
        "gpt-oss-120b": {
            "rating": 1361.7753097618067,
            "rating_q975": 1367.570864495279,
            "rating_q025": 1355.9797550283345
        },
        "deepseek-r1": {
            "rating": 1359.9556153667274,
            "rating_q975": 1368.8002944969,
            "rating_q025": 1351.1109362365548
        },
        "qwen2.5-max": {
            "rating": 1357.4424347723784,
            "rating_q975": 1363.588080416909,
            "rating_q025": 1351.296789127848
        },
        "minimax-m2": {
            "rating": 1356.650187654924,
            "rating_q975": 1366.5154456973694,
            "rating_q025": 1346.7849296124784
        },
        "amazon-nova-experimental-chat-10-09": {
            "rating": 1355.1294370541234,
            "rating_q975": 1363.5998232581235,
            "rating_q025": 1346.6590508501233
        },
        "step-3": {
            "rating": 1353.0884000219412,
            "rating_q975": 1363.7986698826073,
            "rating_q025": 1342.378130161275
        },
        "o1-preview": {
            "rating": 1352.9247855730653,
            "rating_q975": 1360.5044807626614,
            "rating_q025": 1345.3450903834691
        },
        "claude-sonnet-4-20250514": {
            "rating": 1352.6177423734282,
            "rating_q975": 1358.2834672296103,
            "rating_q025": 1346.952017517246
        },
        "o4-mini-2025-04-16": {
            "rating": 1350.4490131622101,
            "rating_q975": 1355.6756902271798,
            "rating_q025": 1345.2223360972405
        },
        "gpt-4.1-mini-2025-04-14": {
            "rating": 1347.566659884088,
            "rating_q975": 1353.276394433713,
            "rating_q025": 1341.856925334463
        },
        "intellect-3": {
            "rating": 1345.6602924602923,
            "rating_q975": 1362.7718214030788,
            "rating_q025": 1328.548763517506
        },
        "gemini-2.0-flash-001": {
            "rating": 1344.6669668162983,
            "rating_q975": 1350.0426621744148,
            "rating_q025": 1339.2912714581819
        },
        "ring-flash-2.0": {
            "rating": 1344.4305790010872,
            "rating_q975": 1354.2433043696285,
            "rating_q025": 1334.6178536325458
        },
        "minimax-m1": {
            "rating": 1341.51638003081,
            "rating_q975": 1347.0780649416272,
            "rating_q025": 1335.954695119993
        },
        "gemma-3-27b-it": {
            "rating": 1338.5339593573158,
            "rating_q975": 1343.7039598502624,
            "rating_q025": 1333.3639588643691
        },
        "mistral-small-2506": {
            "rating": 1335.1605775671403,
            "rating_q975": 1342.1093679315413,
            "rating_q025": 1328.2117872027393
        },
        "step-1o-turbo-202506": {
            "rating": 1334.0461566370357,
            "rating_q975": 1343.7835561721784,
            "rating_q025": 1324.308757101893
        },
        "qwen3-32b": {
            "rating": 1332.3326783123148,
            "rating_q975": 1348.435735543001,
            "rating_q025": 1316.2296210816285
        },
        "glm-4.5v": {
            "rating": 1332.3082757871912,
            "rating_q975": 1344.4213064159821,
            "rating_q025": 1320.1952451584002
        },
        "claude-3-7-sonnet-20250219-thinking-32k": {
            "rating": 1331.918880257171,
            "rating_q975": 1337.8722710460702,
            "rating_q025": 1325.9654894682717
        },
        "o3-mini": {
            "rating": 1331.8977044815251,
            "rating_q975": 1336.7922578965827,
            "rating_q025": 1327.0031510664676
        },
        "o1-mini": {
            "rating": 1331.8712382592614,
            "rating_q975": 1337.7050708558352,
            "rating_q025": 1326.0374056626877
        },
        "nvidia-llama-3.3-nemotron-super-49b-v1.5": {
            "rating": 1330.899858340361,
            "rating_q975": 1345.7881347454659,
            "rating_q025": 1316.0115819352563
        },
        "gpt-5-nano-high": {
            "rating": 1326.630216580085,
            "rating_q975": 1336.4146254026602,
            "rating_q025": 1316.8458077575099
        },
        "qwq-32b": {
            "rating": 1325.2519964947533,
            "rating_q975": 1331.7332380631508,
            "rating_q025": 1318.7707549263557
        },
        "command-a-03-2025": {
            "rating": 1324.860541977113,
            "rating_q975": 1329.6122250516585,
            "rating_q025": 1320.1088589025674
        },
        "gemini-2.0-flash-lite-preview-02-05": {
            "rating": 1323.408070977447,
            "rating_q975": 1330.6978181297316,
            "rating_q025": 1316.1183238251626
        },
        "hunyuan-turbos-20250226": {
            "rating": 1322.4585160445286,
            "rating_q975": 1345.4809175329262,
            "rating_q025": 1299.4361145561309
        },
        "qwen-plus-0125": {
            "rating": 1315.449443844079,
            "rating_q975": 1329.6945333203942,
            "rating_q025": 1301.204354367764
        },
        "qwen3-30b-a3b": {
            "rating": 1314.386416876081,
            "rating_q975": 1320.7702562576405,
            "rating_q025": 1308.0025774945216
        },
        "llama-3.1-nemotron-ultra-253b-v1": {
            "rating": 1313.8450128911054,
            "rating_q975": 1335.2228207534108,
            "rating_q025": 1292.4672050288
        },
        "claude-3-7-sonnet-20250219": {
            "rating": 1313.449223332806,
            "rating_q975": 1319.0595707204636,
            "rating_q025": 1307.8388759451484
        },
        "deepseek-v3": {
            "rating": 1310.9933821008185,
            "rating_q975": 1318.948763766563,
            "rating_q025": 1303.038000435074
        },
        "llama-3.3-nemotron-49b-super-v1": {
            "rating": 1310.0469037640169,
            "rating_q975": 1334.551982769073,
            "rating_q025": 1285.5418247589607
        },
        "gemma-3-12b-it": {
            "rating": 1308.672104368514,
            "rating_q975": 1326.4752100895105,
            "rating_q025": 1290.8689986475176
        },
        "hunyuan-turbo-0110": {
            "rating": 1305.7614054986684,
            "rating_q975": 1329.4393454877084,
            "rating_q025": 1282.0834655096285
        },
        "olmo-3-32b-think": {
            "rating": 1304.9425744061953,
            "rating_q975": 1319.6192165091325,
            "rating_q025": 1290.265932303258
        },
        "claude-3-5-sonnet-20241022": {
            "rating": 1304.847233474814,
            "rating_q975": 1308.9890220424188,
            "rating_q025": 1300.705444907209
        },
        "yi-lightning": {
            "rating": 1301.0476781351313,
            "rating_q975": 1308.9225695318376,
            "rating_q025": 1293.172786738425
        },
        "qwen2.5-plus-1127": {
            "rating": 1298.6451861765956,
            "rating_q975": 1309.1922116407775,
            "rating_q025": 1288.0981607124138
        },
        "step-2-16k-exp-202412": {
            "rating": 1297.1862006220879,
            "rating_q975": 1312.5328795424919,
            "rating_q025": 1281.839521701684
        },
        "gemini-1.5-pro-002": {
            "rating": 1295.4543086961598,
            "rating_q975": 1300.8554181130658,
            "rating_q025": 1290.053199279254
        },
        "glm-4-plus-0111": {
            "rating": 1292.933463334583,
            "rating_q975": 1307.26423929056,
            "rating_q025": 1278.6026873786059
        },
        "athene-v2-chat": {
            "rating": 1291.3208667473764,
            "rating_q975": 1298.5613683864653,
            "rating_q025": 1284.0803651082874
        },
        "mercury": {
            "rating": 1289.0568094664927,
            "rating_q975": 1307.607000498727,
            "rating_q025": 1270.5066184342584
        },
        "deepseek-v2.5-1210": {
            "rating": 1288.934276541183,
            "rating_q975": 1302.2280420100026,
            "rating_q025": 1275.6405110723633
        },
        "hunyuan-large-2025-02-10": {
            "rating": 1285.2920093520188,
            "rating_q975": 1304.2165489415406,
            "rating_q025": 1266.367469762497
        },
        "gemma-3n-e4b-it": {
            "rating": 1284.8943130611626,
            "rating_q975": 1291.9980708909536,
            "rating_q025": 1277.7905552313716
        },
        "gpt-4.1-nano-2025-04-14": {
            "rating": 1284.2904979514674,
            "rating_q975": 1297.916167155373,
            "rating_q025": 1270.6648287475618
        },
        "llama-4-maverick-17b-128e-instruct": {
            "rating": 1281.72952628259,
            "rating_q975": 1287.50349816794,
            "rating_q025": 1275.9555543972401
        },
        "gpt-4o-2024-05-13": {
            "rating": 1279.8020603022358,
            "rating_q975": 1285.0621618348732,
            "rating_q025": 1274.5419587695983
        },
        "mistral-small-3.1-24b-instruct-2503": {
            "rating": 1277.930252815327,
            "rating_q975": 1283.8650769826756,
            "rating_q025": 1271.9954286479785
        },
        "gpt-oss-20b": {
            "rating": 1275.3708119750163,
            "rating_q975": 1284.3810097511346,
            "rating_q025": 1266.360614198898
        },
        "claude-3-5-sonnet-20240620": {
            "rating": 1274.465498273868,
            "rating_q975": 1279.9635165297082,
            "rating_q025": 1268.9674800180278
        },
        "glm-4-plus": {
            "rating": 1271.725325803715,
            "rating_q975": 1279.3460711888363,
            "rating_q025": 1264.1045804185935
        },
        "grok-2-2024-08-13": {
            "rating": 1271.1575168318261,
            "rating_q975": 1276.5838178855163,
            "rating_q025": 1265.731215778136
        },
        "deepseek-v2.5": {
            "rating": 1269.7038716242446,
            "rating_q975": 1277.1644870724067,
            "rating_q025": 1262.2432561760825
        },
        "qwen2.5-72b-instruct": {
            "rating": 1269.6371316485079,
            "rating_q975": 1275.8695157644895,
            "rating_q025": 1263.4047475325262
        },
        "qwen-max-0919": {
            "rating": 1268.4957815125908,
            "rating_q975": 1277.6798317180394,
            "rating_q025": 1259.3117313071423
        },
        "llama-3.1-405b-instruct-bf16": {
            "rating": 1268.3208753305912,
            "rating_q975": 1274.1114342445935,
            "rating_q025": 1262.530316416589
        },
        "magistral-medium-2506": {
            "rating": 1267.6603877538996,
            "rating_q975": 1276.0317513500231,
            "rating_q025": 1259.289024157776
        },
        "llama-4-scout-17b-16e-instruct": {
            "rating": 1266.5334953174133,
            "rating_q975": 1272.7546120879545,
            "rating_q025": 1260.3123785468722
        },
        "gpt-4o-mini-2024-07-18": {
            "rating": 1266.1367970352921,
            "rating_q975": 1271.2537242382323,
            "rating_q025": 1261.019869832352
        },
        "llama-3.1-nemotron-70b-instruct": {
            "rating": 1265.2395585683225,
            "rating_q975": 1277.9923351195362,
            "rating_q025": 1252.486782017109
        },
        "hunyuan-standard-2025-02-10": {
            "rating": 1264.179916739005,
            "rating_q975": 1283.0154573729217,
            "rating_q025": 1245.3443761050883
        },
        "gpt-4o-2024-08-06": {
            "rating": 1263.1344730118515,
            "rating_q975": 1269.4481905769576,
            "rating_q025": 1256.8207554467454
        },
        "llama-3.1-405b-instruct-fp8": {
            "rating": 1262.814257913024,
            "rating_q975": 1268.5090404753782,
            "rating_q025": 1257.1194753506697
        },
        "llama-3.3-70b-instruct": {
            "rating": 1257.594000408988,
            "rating_q975": 1262.4331853404126,
            "rating_q025": 1252.7548154775634
        },
        "hunyuan-large-vision": {
            "rating": 1257.072790785237,
            "rating_q975": 1270.3506440485753,
            "rating_q025": 1243.7949375218986
        },
        "gemini-1.5-flash-002": {
            "rating": 1256.040294047915,
            "rating_q975": 1262.58405036177,
            "rating_q025": 1249.49653773406
        },
        "mistral-large-2411": {
            "rating": 1255.7478483641848,
            "rating_q975": 1262.622629471214,
            "rating_q025": 1248.8730672571558
        },
        "mistral-large-2407": {
            "rating": 1255.733133295875,
            "rating_q975": 1261.937353656158,
            "rating_q025": 1249.528912935592
        },
        "grok-2-mini-2024-08-13": {
            "rating": 1253.920560035434,
            "rating_q975": 1259.6483942622096,
            "rating_q025": 1248.1927258086582
        },
        "gemini-1.5-pro-001": {
            "rating": 1253.8849392742131,
            "rating_q975": 1259.9433883086963,
            "rating_q025": 1247.82649023973
        },
        "gemma-3-4b-it": {
            "rating": 1251.5671788966997,
            "rating_q975": 1268.9016361259287,
            "rating_q025": 1234.2327216674707
        },
        "qwen2.5-coder-32b-instruct": {
            "rating": 1250.7186058806133,
            "rating_q975": 1265.1373625849517,
            "rating_q025": 1236.2998491762748
        },
        "gpt-4-turbo-2024-04-09": {
            "rating": 1249.953532421941,
            "rating_q975": 1255.7795508735123,
            "rating_q025": 1244.1275139703696
        },
        "claude-3-5-haiku-20241022": {
            "rating": 1249.7413287376185,
            "rating_q975": 1254.2628530829716,
            "rating_q025": 1245.2198043922654
        },
        "gemini-advanced-0514": {
            "rating": 1247.564797883689,
            "rating_q975": 1254.791836537589,
            "rating_q025": 1240.3377592297888
        },
        "claude-3-opus-20240229": {
            "rating": 1244.2421532094377,
            "rating_q975": 1248.938005556543,
            "rating_q025": 1239.5463008623324
        },
        "amazon-nova-pro-v1.0": {
            "rating": 1244.0050859778808,
            "rating_q975": 1251.1581506203336,
            "rating_q025": 1236.852021335428
        },
        "athene-70b-0725": {
            "rating": 1242.0995065428442,
            "rating_q975": 1250.6448829898018,
            "rating_q025": 1233.5541300958866
        },
        "llama-3.1-70b-instruct": {
            "rating": 1240.2173382192523,
            "rating_q975": 1245.926632782368,
            "rating_q025": 1234.5080436561366
        },
        "gpt-4-1106-preview": {
            "rating": 1240.1763799455546,
            "rating_q975": 1246.159754713648,
            "rating_q025": 1234.1930051774611
        },
        "gpt-4-0125-preview": {
            "rating": 1237.6082500725088,
            "rating_q975": 1243.7091697345645,
            "rating_q025": 1231.507330410453
        },
        "mistral-small-24b-instruct-2501": {
            "rating": 1231.6233511683627,
            "rating_q975": 1241.1547816044997,
            "rating_q025": 1222.0919207322256
        },
        "amazon-nova-lite-v1.0": {
            "rating": 1219.1438237670004,
            "rating_q975": 1227.3506673351346,
            "rating_q025": 1210.9369801988662
        },
        "llama-3.1-tulu-3-70b": {
            "rating": 1219.1091768154845,
            "rating_q975": 1237.8313304227834,
            "rating_q025": 1200.3870232081856
        },
        "phi-4": {
            "rating": 1218.795147544768,
            "rating_q975": 1226.476504735427,
            "rating_q025": 1211.1137903541091
        },
        "gemini-1.5-flash-001": {
            "rating": 1218.6156188865339,
            "rating_q975": 1224.7942140408359,
            "rating_q025": 1212.4370237322319
        },
        "jamba-1.5-large": {
            "rating": 1217.209071524103,
            "rating_q975": 1228.8214487975094,
            "rating_q025": 1205.5966942506964
        },
        "hunyuan-standard-256k": {
            "rating": 1216.8311046571575,
            "rating_q975": 1237.4362007259967,
            "rating_q025": 1196.2260085883183
        },
        "glm-4-0520": {
            "rating": 1210.5182236683827,
            "rating_q975": 1221.64436850176,
            "rating_q025": 1199.3920788350053
        },
        "reka-core-20240904": {
            "rating": 1210.1257492641312,
            "rating_q975": 1221.6430162939912,
            "rating_q025": 1198.6084822342712
        },
        "gemini-1.5-flash-8b-001": {
            "rating": 1208.1414882151885,
            "rating_q975": 1214.6785896971169,
            "rating_q025": 1201.60438673326
        },
        "olmo-2-0325-32b-instruct": {
            "rating": 1208.0443831997618,
            "rating_q975": 1228.0487892925723,
            "rating_q025": 1188.0399771069513
        },
        "deepseek-coder-v2": {
            "rating": 1205.5864868550161,
            "rating_q975": 1215.4183344025894,
            "rating_q025": 1195.7546393074429
        },
        "llama-3.1-nemotron-51b-instruct": {
            "rating": 1202.6224406705076,
            "rating_q975": 1220.0127800990663,
            "rating_q025": 1185.2321012419488
        },
        "nemotron-4-340b-instruct": {
            "rating": 1200.5061146397143,
            "rating_q975": 1209.4221432318736,
            "rating_q025": 1191.590086047555
        },
        "gpt-4-0314": {
            "rating": 1198.5780269974432,
            "rating_q975": 1206.3462889109305,
            "rating_q025": 1190.8097650839559
        },
        "gemma-2-27b-it": {
            "rating": 1197.443075854624,
            "rating_q975": 1202.4853128968937,
            "rating_q025": 1192.4008388123546
        },
        "claude-3-sonnet-20240229": {
            "rating": 1195.8108679421196,
            "rating_q975": 1201.7647314178182,
            "rating_q025": 1189.857004466421
        },
        "gemma-2-9b-it-simpo": {
            "rating": 1195.636389265577,
            "rating_q975": 1206.9870615552823,
            "rating_q025": 1184.2857169758718
        },
        "llama-3-70b-instruct": {
            "rating": 1194.1293284576223,
            "rating_q975": 1199.6951507622598,
            "rating_q025": 1188.5635061529847
        },
        "c4ai-aya-expanse-32b": {
            "rating": 1192.1690320467292,
            "rating_q975": 1199.5925737926675,
            "rating_q025": 1184.7454903007908
        },
        "amazon-nova-micro-v1.0": {
            "rating": 1190.5764092184172,
            "rating_q975": 1198.7365589218382,
            "rating_q025": 1182.4162595149962
        },
        "ministral-8b-2410": {
            "rating": 1190.2009065391521,
            "rating_q975": 1205.3651721966285,
            "rating_q025": 1175.0366408816758
        },
        "qwen2-72b-instruct": {
            "rating": 1189.375351095071,
            "rating_q975": 1196.6421082614909,
            "rating_q025": 1182.108593928651
        },
        "command-r-plus-08-2024": {
            "rating": 1185.015020881754,
            "rating_q975": 1195.4920870697679,
            "rating_q025": 1174.5379546937402
        },
        "reka-flash-20240904": {
            "rating": 1180.9499220995879,
            "rating_q975": 1192.1346064631025,
            "rating_q025": 1169.7652377360732
        },
        "llama-3.1-8b-instruct": {
            "rating": 1174.0985853363995,
            "rating_q975": 1180.1132269924362,
            "rating_q025": 1168.0839436803628
        },
        "llama-3.1-tulu-3-8b": {
            "rating": 1173.5709875863315,
            "rating_q975": 1193.5214631508406,
            "rating_q025": 1153.6205120218224
        },
        "gpt-4-0613": {
            "rating": 1173.3419089313863,
            "rating_q975": 1179.821540100117,
            "rating_q025": 1166.8622777626556
        },
        "claude-3-haiku-20240307": {
            "rating": 1173.0173806689581,
            "rating_q975": 1178.6261963700765,
            "rating_q025": 1167.4085649678398
        },
        "gemma-2-9b-it": {
            "rating": 1170.6314039464696,
            "rating_q975": 1176.3745668938352,
            "rating_q025": 1164.888240999104
        },
        "qwen1.5-110b-chat": {
            "rating": 1167.182573376911,
            "rating_q975": 1175.9575996109588,
            "rating_q025": 1158.4075471428632
        },
        "jamba-1.5-mini": {
            "rating": 1166.1133965591252,
            "rating_q975": 1177.9445493167773,
            "rating_q025": 1154.2822438014732
        },
        "mistral-large-2402": {
            "rating": 1166.0618021084806,
            "rating_q975": 1173.0244935806006,
            "rating_q025": 1159.0991106363606
        },
        "command-r-plus": {
            "rating": 1165.4791371416368,
            "rating_q975": 1171.8502860465856,
            "rating_q025": 1159.107988236688
        },
        "command-r-08-2024": {
            "rating": 1163.7658853453963,
            "rating_q975": 1174.0304794556835,
            "rating_q025": 1153.5012912351092
        },
        "qwq-32b-preview": {
            "rating": 1161.6542471699622,
            "rating_q975": 1181.084320180344,
            "rating_q025": 1142.2241741595803
        },
        "yi-1.5-34b-chat": {
            "rating": 1158.5452657725486,
            "rating_q975": 1166.859988733649,
            "rating_q025": 1150.2305428114482
        },
        "internlm2_5-20b-chat": {
            "rating": 1157.6334768499787,
            "rating_q975": 1169.00112154331,
            "rating_q025": 1146.2658321566473
        },
        "c4ai-aya-expanse-8b": {
            "rating": 1156.0003856563383,
            "rating_q975": 1167.2342489570058,
            "rating_q025": 1144.7665223556708
        },
        "mixtral-8x22b-instruct-v0.1": {
            "rating": 1148.8252516175917,
            "rating_q975": 1155.7473492836405,
            "rating_q025": 1141.903153951543
        },
        "mistral-medium": {
            "rating": 1148.1744440515574,
            "rating_q975": 1156.888532643279,
            "rating_q025": 1139.460355459836
        },
        "qwen1.5-72b-chat": {
            "rating": 1146.872275086098,
            "rating_q975": 1154.7252614097429,
            "rating_q025": 1139.019288762453
        },
        "granite-3.1-8b-instruct": {
            "rating": 1145.6077950370218,
            "rating_q975": 1165.3766280247035,
            "rating_q025": 1125.8389620493401
        },
        "granite-3.1-2b-instruct": {
            "rating": 1136.8163997273898,
            "rating_q975": 1156.0304871959743,
            "rating_q025": 1117.6023122588053
        },
        "reka-flash-21b-20240226-online": {
            "rating": 1136.5352826307471,
            "rating_q975": 1147.3184385186391,
            "rating_q025": 1125.7521267428551
        },
        "reka-flash-21b-20240226": {
            "rating": 1135.5750845617222,
            "rating_q975": 1144.4451530208491,
            "rating_q025": 1126.7050161025952
        },
        "llama-3-8b-instruct": {
            "rating": 1132.6208223285291,
            "rating_q975": 1138.6969165580836,
            "rating_q025": 1126.5447280989747
        },
        "qwen1.5-32b-chat": {
            "rating": 1129.7063471391211,
            "rating_q975": 1139.0144321851512,
            "rating_q025": 1120.398262093091
        },
        "phi-3-medium-4k-instruct": {
            "rating": 1125.6340817418172,
            "rating_q975": 1133.6872671711305,
            "rating_q025": 1117.580896312504
        },
        "starling-lm-7b-beta": {
            "rating": 1117.7392062918816,
            "rating_q975": 1128.499375534286,
            "rating_q025": 1106.9790370494773
        },
        "zephyr-orpo-141b-A35b-v0.1": {
            "rating": 1115.8536906858944,
            "rating_q975": 1132.6926993497912,
            "rating_q025": 1099.0146820219977
        },
        "command-r": {
            "rating": 1113.9734340988443,
            "rating_q975": 1121.1732011242234,
            "rating_q025": 1106.7736670734653
        },
        "mixtral-8x7b-instruct-v0.1": {
            "rating": 1113.8279973077047,
            "rating_q975": 1120.5442896398627,
            "rating_q025": 1107.1117049755467
        },
        "qwen1.5-14b-chat": {
            "rating": 1112.7103300257722,
            "rating_q975": 1123.3475130233096,
            "rating_q025": 1102.0731470282349
        },
        "dbrx-instruct-preview": {
            "rating": 1112.3301593180668,
            "rating_q975": 1121.3853649026125,
            "rating_q025": 1103.274953733521
        },
        "gemma-2-2b-it": {
            "rating": 1112.136202484952,
            "rating_q975": 1118.344252860251,
            "rating_q025": 1105.9281521096532
        },
        "gemini-pro-dev-api": {
            "rating": 1108.3893877234636,
            "rating_q975": 1119.696499308095,
            "rating_q025": 1097.0822761388322
        },
        "gpt-3.5-turbo-0125": {
            "rating": 1107.0474538952126,
            "rating_q975": 1113.7232887028001,
            "rating_q025": 1100.371619087625
        },
        "tulu-2-dpo-70b": {
            "rating": 1103.6123351229767,
            "rating_q975": 1120.0156273578316,
            "rating_q025": 1087.2090428881218
        },
        "yi-34b-chat": {
            "rating": 1102.720601129425,
            "rating_q975": 1113.3428329678882,
            "rating_q025": 1092.0983692909617
        },
        "phi-3-small-8k-instruct": {
            "rating": 1098.9996972040276,
            "rating_q975": 1108.4952649254244,
            "rating_q025": 1089.5041294826308
        },
        "gpt-3.5-turbo-1106": {
            "rating": 1097.4809547596687,
            "rating_q975": 1110.443727283123,
            "rating_q025": 1084.5181822362144
        },
        "llama-3.2-3b-instruct": {
            "rating": 1094.5709453543902,
            "rating_q975": 1106.7507602405249,
            "rating_q025": 1082.3911304682556
        },
        "gemini-pro": {
            "rating": 1092.5457699898077,
            "rating_q975": 1110.3965846597903,
            "rating_q025": 1074.694955319825
        },
        "granite-3.0-8b-instruct": {
            "rating": 1091.302401804951,
            "rating_q975": 1106.0334021237945,
            "rating_q025": 1076.5714014861073
        },
        "phi-3-mini-4k-instruct-june-2024": {
            "rating": 1086.6104135119936,
            "rating_q975": 1097.381824639192,
            "rating_q025": 1075.839002384795
        },
        "openchat-3.5-0106": {
            "rating": 1083.8465785660092,
            "rating_q975": 1095.0408610441877,
            "rating_q025": 1072.6522960878306
        },
        "wizardlm-70b": {
            "rating": 1078.6037601285716,
            "rating_q975": 1093.99567691611,
            "rating_q025": 1063.2118433410333
        },
        "starling-lm-7b-alpha": {
            "rating": 1074.8702056919044,
            "rating_q975": 1087.5494080408662,
            "rating_q025": 1062.1910033429426
        },
        "granite-3.0-2b-instruct": {
            "rating": 1072.4564567500852,
            "rating_q975": 1087.0193231140418,
            "rating_q025": 1057.8935903861286
        },
        "llama-2-70b-chat": {
            "rating": 1072.2057842476424,
            "rating_q975": 1080.4597226480432,
            "rating_q025": 1063.9518458472417
        },
        "snowflake-arctic-instruct": {
            "rating": 1071.6085036703073,
            "rating_q975": 1080.7708197714762,
            "rating_q025": 1062.4461875691384
        },
        "openhermes-2.5-mistral-7b": {
            "rating": 1070.4791883163791,
            "rating_q975": 1087.6108352131737,
            "rating_q025": 1053.3475414195846
        },
        "phi-3-mini-4k-instruct": {
            "rating": 1070.2501133356275,
            "rating_q975": 1079.752581860694,
            "rating_q025": 1060.747644810561
        },
        "gemma-1.1-7b-it": {
            "rating": 1069.8452833691467,
            "rating_q975": 1078.386001505706,
            "rating_q025": 1061.3045652325875
        },
        "deepseek-llm-67b-chat": {
            "rating": 1069.0321828583287,
            "rating_q975": 1087.8718129944407,
            "rating_q025": 1050.1925527222168
        },
        "mistral-7b-instruct-v0.2": {
            "rating": 1066.7952063057073,
            "rating_q975": 1076.497097122133,
            "rating_q025": 1057.0933154892816
        },
        "vicuna-33b": {
            "rating": 1065.6241533904258,
            "rating_q975": 1075.6940175155928,
            "rating_q025": 1055.5542892652588
        },
        "qwen1.5-7b-chat": {
            "rating": 1064.4887522496856,
            "rating_q975": 1080.0927405757066,
            "rating_q025": 1048.8847639236647
        },
        "openchat-3.5": {
            "rating": 1064.350922285969,
            "rating_q975": 1080.094843539838,
            "rating_q025": 1048.6070010321002
        },
        "solar-10.7b-instruct-v1.0": {
            "rating": 1061.8286474796391,
            "rating_q975": 1081.6381039799992,
            "rating_q025": 1042.019190979279
        },
        "smollm2-1.7b-instruct": {
            "rating": 1055.3612613082923,
            "rating_q975": 1080.1976627152221,
            "rating_q025": 1030.5248599013626
        },
        "dolphin-2.2.1-mistral-7b": {
            "rating": 1053.5026768334653,
            "rating_q975": 1081.8761729685637,
            "rating_q025": 1025.129180698367
        },
        "nous-hermes-2-mixtral-8x7b-dpo": {
            "rating": 1052.4104566482192,
            "rating_q975": 1070.1070790085464,
            "rating_q025": 1034.713834287892
        },
        "llama-2-13b-chat": {
            "rating": 1050.343899125292,
            "rating_q975": 1060.6666324854264,
            "rating_q025": 1040.0211657651575
        },
        "mpt-30b-chat": {
            "rating": 1049.5653297655354,
            "rating_q975": 1077.2419074043546,
            "rating_q025": 1021.8887521267161
        },
        "codellama-70b-instruct": {
            "rating": 1049.3179196737483,
            "rating_q975": 1081.5919548190263,
            "rating_q025": 1017.0438845284701
        },
        "llama2-70b-steerlm-chat": {
            "rating": 1045.9625994706425,
            "rating_q975": 1066.9253229046944,
            "rating_q025": 1024.9998760365906
        },
        "llama-3.2-1b-instruct": {
            "rating": 1043.4698012233353,
            "rating_q975": 1056.0672182762899,
            "rating_q025": 1030.8723841703807
        },
        "gemma-7b-it": {
            "rating": 1040.7849523070804,
            "rating_q975": 1054.3651822139564,
            "rating_q025": 1027.2047224002044
        },
        "codellama-34b-instruct": {
            "rating": 1030.7668139528594,
            "rating_q975": 1045.595231948033,
            "rating_q025": 1015.9383959576857
        },
        "phi-3-mini-128k-instruct": {
            "rating": 1027.543386767109,
            "rating_q975": 1038.3735583779871,
            "rating_q025": 1016.713215156231
        },
        "qwen-14b-chat": {
            "rating": 1025.4896374734742,
            "rating_q975": 1044.7670855582387,
            "rating_q025": 1006.2121893887098
        },
        "zephyr-7b-beta": {
            "rating": 1025.3103540442753,
            "rating_q975": 1039.8387357529518,
            "rating_q025": 1010.7819723355987
        },
        "zephyr-7b-alpha": {
            "rating": 1023.9388376874007,
            "rating_q975": 1054.202265568986,
            "rating_q025": 993.6754098058154
        },
        "vicuna-13b": {
            "rating": 1022.2836097959614,
            "rating_q975": 1033.0673536509516,
            "rating_q025": 1011.4998659409711
        },
        "wizardlm-13b": {
            "rating": 1016.2171199851541,
            "rating_q975": 1032.9787765372548,
            "rating_q025": 999.4554634330534
        },
        "llama-2-7b-chat": {
            "rating": 1008.1523304132513,
            "rating_q975": 1019.1198801190801,
            "rating_q025": 997.1847807074225
        },
        "falcon-180b-chat": {
            "rating": 1006.1006077974216,
            "rating_q975": 1042.1567513171242,
            "rating_q025": 970.0444642777189
        },
        "gemma-1.1-2b-it": {
            "rating": 1003.8629318912278,
            "rating_q975": 1015.7221806230323,
            "rating_q025": 992.0036831594234
        },
        "palm-2": {
            "rating": 1003.3480296803302,
            "rating_q975": 1019.1871387542877,
            "rating_q025": 987.5089206063727
        },
        "guanaco-33b": {
            "rating": 1002.6532043030594,
            "rating_q975": 1028.32934346679,
            "rating_q025": 976.9770651393287
        },
        "mistral-7b-instruct": {
            "rating": 1000.6983903789242,
            "rating_q975": 1016.1255014742983,
            "rating_q025": 985.27127928355
        },
        "stripedhyena-nous-7b": {
            "rating": 997.2827990936502,
            "rating_q975": 1014.3894333325085,
            "rating_q025": 980.1761648547919
        },
        "vicuna-7b": {
            "rating": 993.5888591012281,
            "rating_q975": 1010.7223482696107,
            "rating_q025": 976.4553699328454
        },
        "olmo-7b-instruct": {
            "rating": 992.6397162309871,
            "rating_q975": 1009.6195947956443,
            "rating_q025": 975.65983766633
        },
        "gemma-2b-it": {
            "rating": 987.5336919983475,
            "rating_q975": 1005.2426581044118,
            "rating_q025": 969.8247258922833
        },
        "qwen1.5-4b-chat": {
            "rating": 974.7481015168116,
            "rating_q975": 988.8704436523503,
            "rating_q025": 960.6257593812729
        },
        "chatglm3-6b": {
            "rating": 951.6916889328114,
            "rating_q975": 972.080875548672,
            "rating_q025": 931.3025023169508
        },
        "gpt4all-13b-snoozy": {
            "rating": 934.6010017469853,
            "rating_q975": 965.8685158625339,
            "rating_q025": 903.3334876314367
        },
        "koala-13b": {
            "rating": 927.9374201313128,
            "rating_q975": 946.6211992580619,
            "rating_q025": 909.2536410045637
        },
        "chatglm2-6b": {
            "rating": 914.8301964181604,
            "rating_q975": 942.0660715443129,
            "rating_q025": 887.594321292008
        },
        "chatglm-6b": {
            "rating": 899.1618247632425,
            "rating_q975": 921.1333258986893,
            "rating_q025": 877.1903236277957
        },
        "RWKV-4-Raven-14B": {
            "rating": 893.8640511510823,
            "rating_q975": 914.8086395394266,
            "rating_q025": 872.919462762738
        },
        "mpt-7b-chat": {
            "rating": 893.6878533529032,
            "rating_q975": 916.4113718321734,
            "rating_q025": 870.964334873633
        },
        "oasst-pythia-12b": {
            "rating": 882.6671474965381,
            "rating_q975": 902.2395765708603,
            "rating_q025": 863.0947184222158
        },
        "stablelm-tuned-alpha-7b": {
            "rating": 832.8775667286313,
            "rating_q975": 858.3199672118059,
            "rating_q025": 807.4351662454568
        },
        "alpaca-13b": {
            "rating": 823.5567851133868,
            "rating_q975": 843.7865677150761,
            "rating_q025": 803.3270025116975
        },
        "fastchat-t5-3b": {
            "rating": 812.2434748575115,
            "rating_q975": 834.1252033847904,
            "rating_q025": 790.3617463302326
        },
        "dolly-v2-12b": {
            "rating": 801.5707383475376,
            "rating_q975": 826.6308080860795,
            "rating_q025": 776.5106686089957
        },
        "llama-13b": {
            "rating": 725.6161281328772,
            "rating_q975": 756.9460975109296,
            "rating_q025": 694.2861587548248
        }
    },
    "hard_english_6": {
        "claude-opus-4-5-20251101-thinking-32k": {
            "rating": 1488.5753923364318,
            "rating_q975": 1501.0368824304485,
            "rating_q025": 1476.1139022424152
        },
        "claude-opus-4-5-20251101": {
            "rating": 1476.0169260771486,
            "rating_q975": 1488.1095058687147,
            "rating_q025": 1463.9243462855825
        },
        "gemini-3-pro": {
            "rating": 1475.5307058338049,
            "rating_q975": 1485.7754551604914,
            "rating_q025": 1465.2859565071183
        },
        "claude-sonnet-4-5-20250929-thinking-32k": {
            "rating": 1471.359457609515,
            "rating_q975": 1479.126123234701,
            "rating_q025": 1463.5927919843289
        },
        "claude-sonnet-4-5-20250929": {
            "rating": 1458.201905214872,
            "rating_q975": 1466.6459536265731,
            "rating_q025": 1449.757856803171
        },
        "claude-opus-4-1-20250805-thinking-16k": {
            "rating": 1456.901172021209,
            "rating_q975": 1463.4619083467105,
            "rating_q025": 1450.3404356957076
        },
        "gemini-2.5-pro": {
            "rating": 1456.8637616375188,
            "rating_q975": 1462.4638149017335,
            "rating_q025": 1451.263708373304
        },
        "gpt-5.1-high": {
            "rating": 1454.9021343687782,
            "rating_q975": 1465.8863234993644,
            "rating_q025": 1443.917945238192
        },
        "glm-4.6": {
            "rating": 1449.0039470601025,
            "rating_q975": 1456.963619843196,
            "rating_q025": 1441.044274277009
        },
        "grok-4.1-thinking": {
            "rating": 1448.7455566348362,
            "rating_q975": 1458.719162760749,
            "rating_q025": 1438.7719505089235
        },
        "grok-4.1": {
            "rating": 1446.950437501339,
            "rating_q975": 1456.9947356489395,
            "rating_q025": 1436.9061393537384
        },
        "qwen3-max-preview": {
            "rating": 1445.830781351305,
            "rating_q975": 1453.5773602583947,
            "rating_q025": 1438.0842024442152
        },
        "claude-opus-4-1-20250805": {
            "rating": 1445.3429311649904,
            "rating_q975": 1451.4890088961283,
            "rating_q025": 1439.1968534338525
        },
        "longcat-flash-chat": {
            "rating": 1443.8632143931304,
            "rating_q975": 1455.0466848167227,
            "rating_q025": 1432.679743969538
        },
        "qwen3-vl-235b-a22b-instruct": {
            "rating": 1442.3485411379406,
            "rating_q975": 1454.8316705524082,
            "rating_q025": 1429.865411723473
        },
        "ernie-5.0-preview-1103": {
            "rating": 1441.8909936215668,
            "rating_q975": 1457.1044298820677,
            "rating_q025": 1426.677557361066
        },
        "deepseek-v3.2-exp-thinking": {
            "rating": 1441.4417996489167,
            "rating_q975": 1453.667510489109,
            "rating_q025": 1429.2160888087244
        },
        "grok-3-preview-02-24": {
            "rating": 1441.380848663778,
            "rating_q975": 1449.2179484340397,
            "rating_q025": 1433.543748893516
        },
        "mistral-large-3": {
            "rating": 1440.4882237410468,
            "rating_q975": 1454.7400037501807,
            "rating_q025": 1426.236443731913
        },
        "deepseek-v3.2": {
            "rating": 1439.7516597403896,
            "rating_q975": 1454.3603921814124,
            "rating_q025": 1425.1429272993669
        },
        "deepseek-v3.2-exp": {
            "rating": 1439.3972878863547,
            "rating_q975": 1450.1694129216594,
            "rating_q025": 1428.62516285105
        },
        "qwen3-235b-a22b-instruct-2507": {
            "rating": 1437.4840311126807,
            "rating_q975": 1443.6665223896277,
            "rating_q025": 1431.3015398357336
        },
        "gpt-5.1": {
            "rating": 1436.3577085241222,
            "rating_q975": 1446.6860509601813,
            "rating_q025": 1426.0293660880632
        },
        "kimi-k2-thinking-turbo": {
            "rating": 1436.1923797084971,
            "rating_q975": 1446.050844232729,
            "rating_q025": 1426.3339151842652
        },
        "deepseek-v3.2-thinking": {
            "rating": 1435.2236220730947,
            "rating_q975": 1450.4738549304702,
            "rating_q025": 1419.9733892157192
        },
        "mistral-medium-2508": {
            "rating": 1434.9473425443598,
            "rating_q975": 1441.3598470905106,
            "rating_q025": 1428.534837998209
        },
        "qwen3-next-80b-a3b-instruct": {
            "rating": 1433.8848309294513,
            "rating_q975": 1441.921191377888,
            "rating_q025": 1425.8484704810146
        },
        "claude-haiku-4-5-20251001": {
            "rating": 1431.4967049354123,
            "rating_q975": 1439.299550524852,
            "rating_q025": 1423.6938593459724
        },
        "qwen3-235b-a22b-thinking-2507": {
            "rating": 1430.6587896029432,
            "rating_q975": 1443.779490552486,
            "rating_q025": 1417.5380886534003
        },
        "qwen3-max-2025-09-23": {
            "rating": 1429.5041489521623,
            "rating_q975": 1441.3063287225323,
            "rating_q025": 1417.7019691817923
        },
        "deepseek-v3.1-thinking": {
            "rating": 1427.5059462833299,
            "rating_q975": 1439.5938943357496,
            "rating_q025": 1415.4179982309101
        },
        "deepseek-v3.1-terminus-thinking": {
            "rating": 1425.6757134027268,
            "rating_q975": 1445.9036243800442,
            "rating_q025": 1405.4478024254095
        },
        "glm-4.5": {
            "rating": 1425.2488800829017,
            "rating_q975": 1433.5790241269744,
            "rating_q025": 1416.918736038829
        },
        "gpt-5-high": {
            "rating": 1422.9703349817862,
            "rating_q975": 1430.440510248321,
            "rating_q025": 1415.5001597152514
        },
        "chatgpt-4o-latest-20250326": {
            "rating": 1422.3622677516983,
            "rating_q975": 1428.0030856273747,
            "rating_q025": 1416.7214498760218
        },
        "grok-4-fast-chat": {
            "rating": 1421.3394285077293,
            "rating_q975": 1436.3712187154138,
            "rating_q025": 1406.3076383000448
        },
        "hunyuan-vision-1.5-thinking": {
            "rating": 1420.538771825169,
            "rating_q975": 1444.2944589440406,
            "rating_q025": 1396.7830847062976
        },
        "deepseek-r1-0528": {
            "rating": 1419.745464735686,
            "rating_q975": 1429.9347549623346,
            "rating_q025": 1409.5561745090374
        },
        "amazon-nova-experimental-chat-10-20": {
            "rating": 1419.312378194658,
            "rating_q975": 1432.204934863669,
            "rating_q025": 1406.4198215256472
        },
        "deepseek-v3.1": {
            "rating": 1418.3159679062003,
            "rating_q975": 1428.7756626992486,
            "rating_q025": 1407.856273113152
        },
        "gemini-2.5-flash": {
            "rating": 1418.1037851227884,
            "rating_q975": 1423.6258068183665,
            "rating_q025": 1412.5817634272103
        },
        "grok-4-1-fast-reasoning": {
            "rating": 1416.74696960387,
            "rating_q975": 1429.074808860075,
            "rating_q025": 1404.4191303476648
        },
        "qwen3-vl-235b-a22b-thinking": {
            "rating": 1414.1425639605347,
            "rating_q975": 1426.958882543473,
            "rating_q025": 1401.3262453775965
        },
        "grok-4-fast-reasoning": {
            "rating": 1413.4638531692285,
            "rating_q975": 1422.1267084461463,
            "rating_q025": 1404.8009978923108
        },
        "deepseek-v3.1-terminus": {
            "rating": 1411.022393843023,
            "rating_q975": 1429.4957377385972,
            "rating_q025": 1392.549049947449
        },
        "grok-4-0709": {
            "rating": 1410.8661744352985,
            "rating_q975": 1417.3650542979735,
            "rating_q025": 1404.3672945726235
        },
        "o3-2025-04-16": {
            "rating": 1408.1059797370683,
            "rating_q975": 1414.085498153949,
            "rating_q025": 1402.1264613201877
        },
        "claude-opus-4-20250514-thinking-16k": {
            "rating": 1407.6243832663795,
            "rating_q975": 1414.882618095503,
            "rating_q025": 1400.366148437256
        },
        "qwen3-30b-a3b-instruct-2507": {
            "rating": 1406.7087174426083,
            "rating_q975": 1415.019459025413,
            "rating_q025": 1398.3979758598036
        },
        "gemini-2.5-flash-preview-09-2025": {
            "rating": 1406.633838090553,
            "rating_q975": 1414.100281950491,
            "rating_q025": 1399.1673942306147
        },
        "gpt-4.5-preview-2025-02-27": {
            "rating": 1406.6206897111122,
            "rating_q975": 1418.812979274305,
            "rating_q025": 1394.4284001479193
        },
        "gpt-5-chat": {
            "rating": 1403.9336378149699,
            "rating_q975": 1411.2350278417446,
            "rating_q025": 1396.6322477881952
        },
        "mai-1-preview": {
            "rating": 1394.9420382541684,
            "rating_q975": 1404.5118928584252,
            "rating_q025": 1385.3721836499117
        },
        "hunyuan-t1-20250711": {
            "rating": 1393.2610545936393,
            "rating_q975": 1412.4029179638558,
            "rating_q025": 1374.1191912234228
        },
        "gpt-4.1-2025-04-14": {
            "rating": 1390.549232532834,
            "rating_q975": 1396.6946148679767,
            "rating_q025": 1384.403850197691
        },
        "nova-2-lite": {
            "rating": 1389.934574371508,
            "rating_q975": 1405.1587499182988,
            "rating_q025": 1374.7103988247172
        },
        "qwen3-235b-a22b-no-thinking": {
            "rating": 1389.5010125591436,
            "rating_q975": 1396.5955954646154,
            "rating_q025": 1382.406429653672
        },
        "claude-sonnet-4-20250514-thinking-32k": {
            "rating": 1389.2185951644854,
            "rating_q975": 1396.519194003391,
            "rating_q025": 1381.9179963255797
        },
        "gpt-5-mini-high": {
            "rating": 1388.6876077386523,
            "rating_q975": 1396.6234640860207,
            "rating_q025": 1380.751751391284
        },
        "ling-flash-2.0": {
            "rating": 1388.4929515557042,
            "rating_q975": 1401.9805101587415,
            "rating_q025": 1375.0053929526669
        },
        "glm-4.5-air": {
            "rating": 1387.1405626674166,
            "rating_q975": 1394.3622148000397,
            "rating_q025": 1379.9189105347934
        },
        "qwen3-next-80b-a3b-thinking": {
            "rating": 1385.883694391427,
            "rating_q975": 1396.0956226124483,
            "rating_q025": 1375.6717661704058
        },
        "gemini-2.5-flash-lite-preview-09-2025-no-thinking": {
            "rating": 1384.9158140633124,
            "rating_q975": 1392.2969177182936,
            "rating_q025": 1377.5347104083312
        },
        "qwen3-coder-480b-a35b-instruct": {
            "rating": 1383.493495489245,
            "rating_q975": 1391.9289185289235,
            "rating_q025": 1375.0580724495667
        },
        "claude-opus-4-20250514": {
            "rating": 1381.6590446023179,
            "rating_q975": 1388.4692635664678,
            "rating_q025": 1374.848825638168
        },
        "kimi-k2-0905-preview": {
            "rating": 1381.1683078973026,
            "rating_q975": 1392.6393810950683,
            "rating_q025": 1369.697234699537
        },
        "grok-3-mini-high": {
            "rating": 1377.5737758307391,
            "rating_q975": 1387.0259073927218,
            "rating_q025": 1368.1216442687564
        },
        "o1-preview": {
            "rating": 1376.584803364695,
            "rating_q975": 1385.8753224611335,
            "rating_q025": 1367.2942842682567
        },
        "deepseek-v3-0324": {
            "rating": 1376.1394070860674,
            "rating_q975": 1382.5946320499752,
            "rating_q025": 1369.6841821221597
        },
        "step-3": {
            "rating": 1375.2272155590124,
            "rating_q975": 1390.2144070377897,
            "rating_q025": 1360.2400240802351
        },
        "gemini-2.5-flash-lite-preview-06-17-thinking": {
            "rating": 1375.2203908630472,
            "rating_q975": 1382.562725832056,
            "rating_q025": 1367.8780558940384
        },
        "deepseek-r1": {
            "rating": 1374.9715238024114,
            "rating_q975": 1385.9755815431586,
            "rating_q025": 1363.9674660616643
        },
        "ring-flash-2.0": {
            "rating": 1374.9418781178622,
            "rating_q975": 1388.5042159574407,
            "rating_q025": 1361.3795402782837
        },
        "o3-mini-high": {
            "rating": 1374.6843021538791,
            "rating_q975": 1385.517865027665,
            "rating_q025": 1363.8507392800932
        },
        "grok-3-mini-beta": {
            "rating": 1373.789580680284,
            "rating_q975": 1382.1308815056743,
            "rating_q025": 1365.4482798548936
        },
        "amazon-nova-experimental-chat-10-09": {
            "rating": 1372.7293983843938,
            "rating_q975": 1384.2047559641428,
            "rating_q025": 1361.2540408046448
        },
        "mistral-medium-2505": {
            "rating": 1372.6079754409973,
            "rating_q975": 1380.043319116907,
            "rating_q025": 1365.1726317650875
        },
        "qwen3-235b-a22b": {
            "rating": 1372.387340206703,
            "rating_q975": 1380.3974279776128,
            "rating_q025": 1364.377252435793
        },
        "hunyuan-turbos-20250416": {
            "rating": 1372.2751288707616,
            "rating_q975": 1384.6691533052087,
            "rating_q025": 1359.8811044363144
        },
        "o1-2024-12-17": {
            "rating": 1372.1419636877888,
            "rating_q975": 1381.3459370138053,
            "rating_q025": 1362.9379903617723
        },
        "intellect-3": {
            "rating": 1371.8832571119158,
            "rating_q975": 1395.285010125313,
            "rating_q025": 1348.4815040985186
        },
        "minimax-m2": {
            "rating": 1371.1002065335206,
            "rating_q975": 1384.5897947598587,
            "rating_q025": 1357.6106183071824
        },
        "gpt-oss-120b": {
            "rating": 1368.4691029200255,
            "rating_q975": 1375.8666509742488,
            "rating_q025": 1361.0715548658022
        },
        "kimi-k2-0711-preview": {
            "rating": 1368.0569007073552,
            "rating_q975": 1376.0460596891123,
            "rating_q025": 1360.0677417255981
        },
        "o4-mini-2025-04-16": {
            "rating": 1365.8578174758125,
            "rating_q975": 1372.3023038967965,
            "rating_q025": 1359.4133310548284
        },
        "gpt-4.1-mini-2025-04-14": {
            "rating": 1362.3266781732964,
            "rating_q975": 1369.3002370971242,
            "rating_q025": 1355.3531192494686
        },
        "claude-sonnet-4-20250514": {
            "rating": 1361.98897024036,
            "rating_q975": 1368.9700196682682,
            "rating_q025": 1355.0079208124519
        },
        "qwen2.5-max": {
            "rating": 1361.8429251977893,
            "rating_q975": 1369.377139987585,
            "rating_q025": 1354.3087104079937
        },
        "mistral-small-2506": {
            "rating": 1358.5650534312983,
            "rating_q975": 1367.7547225172618,
            "rating_q025": 1349.3753843453349
        },
        "minimax-m1": {
            "rating": 1356.4097550517529,
            "rating_q975": 1363.4209760548094,
            "rating_q025": 1349.3985340486963
        },
        "glm-4.5v": {
            "rating": 1355.0185468247769,
            "rating_q975": 1371.8543448498585,
            "rating_q025": 1338.1827487996952
        },
        "gemini-2.0-flash-001": {
            "rating": 1354.6865275395967,
            "rating_q975": 1361.275536750894,
            "rating_q025": 1348.0975183282994
        },
        "o1-mini": {
            "rating": 1351.864034367411,
            "rating_q975": 1358.9902705304473,
            "rating_q025": 1344.7377982043747
        },
        "step-1o-turbo-202506": {
            "rating": 1351.40580074705,
            "rating_q975": 1364.554984862368,
            "rating_q025": 1338.2566166317322
        },
        "qwen3-32b": {
            "rating": 1348.7554381586963,
            "rating_q975": 1369.5564154753538,
            "rating_q025": 1327.9544608420388
        },
        "gemma-3-27b-it": {
            "rating": 1347.266529378516,
            "rating_q975": 1353.6169630121617,
            "rating_q025": 1340.9160957448703
        },
        "claude-3-7-sonnet-20250219-thinking-32k": {
            "rating": 1344.371249150885,
            "rating_q975": 1351.7025462296558,
            "rating_q025": 1337.0399520721141
        },
        "nvidia-llama-3.3-nemotron-super-49b-v1.5": {
            "rating": 1344.1555921666475,
            "rating_q975": 1365.015355560622,
            "rating_q025": 1323.2958287726728
        },
        "o3-mini": {
            "rating": 1344.030067478606,
            "rating_q975": 1350.016829988747,
            "rating_q025": 1338.043304968465
        },
        "olmo-3-32b-think": {
            "rating": 1340.520116489931,
            "rating_q975": 1361.2163187867714,
            "rating_q025": 1319.8239141930908
        },
        "qwq-32b": {
            "rating": 1340.2871361855744,
            "rating_q975": 1348.4535922999976,
            "rating_q025": 1332.1206800711511
        },
        "gpt-5-nano-high": {
            "rating": 1339.513063459951,
            "rating_q975": 1353.09023784545,
            "rating_q025": 1325.9358890744518
        },
        "llama-3.3-nemotron-49b-super-v1": {
            "rating": 1337.6562045571836,
            "rating_q975": 1367.1649523482183,
            "rating_q025": 1308.147456766149
        },
        "hunyuan-turbos-20250226": {
            "rating": 1335.586774422883,
            "rating_q975": 1363.790047086801,
            "rating_q025": 1307.3835017589652
        },
        "llama-3.1-nemotron-ultra-253b-v1": {
            "rating": 1335.1366581656785,
            "rating_q975": 1362.0729480563534,
            "rating_q025": 1308.2003682750035
        },
        "command-a-03-2025": {
            "rating": 1333.9181316343302,
            "rating_q975": 1339.8104471529025,
            "rating_q025": 1328.0258161157578
        },
        "qwen-plus-0125": {
            "rating": 1333.6536385166023,
            "rating_q975": 1351.0158018514808,
            "rating_q025": 1316.2914751817239
        },
        "qwen3-30b-a3b": {
            "rating": 1331.0634484582301,
            "rating_q975": 1339.1905907556354,
            "rating_q025": 1322.9363061608249
        },
        "gemini-2.0-flash-lite-preview-02-05": {
            "rating": 1330.0455360991016,
            "rating_q975": 1338.8268539268963,
            "rating_q025": 1321.2642182713068
        },
        "hunyuan-turbo-0110": {
            "rating": 1325.009168204897,
            "rating_q975": 1352.8539918149484,
            "rating_q025": 1297.1643445948455
        },
        "deepseek-v3": {
            "rating": 1323.9201132599883,
            "rating_q975": 1333.368450953417,
            "rating_q025": 1314.4717755665595
        },
        "yi-lightning": {
            "rating": 1322.8243182114682,
            "rating_q975": 1332.479352686577,
            "rating_q025": 1313.1692837363594
        },
        "mercury": {
            "rating": 1321.6556473910537,
            "rating_q975": 1347.643923650347,
            "rating_q025": 1295.6673711317603
        },
        "claude-3-7-sonnet-20250219": {
            "rating": 1319.2884314461148,
            "rating_q975": 1326.1630129061032,
            "rating_q025": 1312.4138499861265
        },
        "qwen2.5-plus-1127": {
            "rating": 1318.925275801239,
            "rating_q975": 1331.8132289114026,
            "rating_q025": 1306.0373226910754
        },
        "gemma-3-12b-it": {
            "rating": 1317.9812042043354,
            "rating_q975": 1338.7543298331768,
            "rating_q025": 1297.208078575494
        },
        "claude-3-5-sonnet-20241022": {
            "rating": 1313.9554187494155,
            "rating_q975": 1318.9818312842594,
            "rating_q025": 1308.9290062145715
        },
        "step-2-16k-exp-202412": {
            "rating": 1308.7449227196428,
            "rating_q975": 1327.3658575163904,
            "rating_q025": 1290.1239879228951
        },
        "athene-v2-chat": {
            "rating": 1304.4735352253492,
            "rating_q975": 1313.3541978067522,
            "rating_q025": 1295.5928726439463
        },
        "deepseek-v2.5-1210": {
            "rating": 1300.5984731107387,
            "rating_q975": 1316.902954754816,
            "rating_q025": 1284.2939914666615
        },
        "gemini-1.5-pro-002": {
            "rating": 1299.7512808072695,
            "rating_q975": 1306.236109801343,
            "rating_q025": 1293.266451813196
        },
        "llama-4-maverick-17b-128e-instruct": {
            "rating": 1298.1340409978707,
            "rating_q975": 1305.1642348303608,
            "rating_q025": 1291.1038471653806
        },
        "mistral-small-3.1-24b-instruct-2503": {
            "rating": 1296.2643687871434,
            "rating_q975": 1303.6504756299398,
            "rating_q025": 1288.878261944347
        },
        "hunyuan-large-2025-02-10": {
            "rating": 1295.1377920604423,
            "rating_q975": 1317.8511452990144,
            "rating_q025": 1272.4244388218701
        },
        "gpt-oss-20b": {
            "rating": 1295.0835572551844,
            "rating_q975": 1307.5989014908166,
            "rating_q025": 1282.568213019552
        },
        "gemma-3n-e4b-it": {
            "rating": 1293.4164529071604,
            "rating_q975": 1302.4933402432814,
            "rating_q025": 1284.3395655710394
        },
        "gpt-4o-2024-05-13": {
            "rating": 1293.387832046609,
            "rating_q975": 1299.566952744993,
            "rating_q025": 1287.208711348225
        },
        "glm-4-plus-0111": {
            "rating": 1292.5188542140281,
            "rating_q975": 1310.069602078313,
            "rating_q025": 1274.9681063497433
        },
        "gpt-4.1-nano-2025-04-14": {
            "rating": 1291.9667062223193,
            "rating_q975": 1309.1170965298268,
            "rating_q025": 1274.8163159148119
        },
        "llama-3.1-405b-instruct-bf16": {
            "rating": 1291.9474728038756,
            "rating_q975": 1298.9679590356714,
            "rating_q025": 1284.9269865720798
        },
        "llama-4-scout-17b-16e-instruct": {
            "rating": 1290.9398111974438,
            "rating_q975": 1298.7533927194274,
            "rating_q025": 1283.12622967546
        },
        "magistral-medium-2506": {
            "rating": 1287.7279954739856,
            "rating_q975": 1299.4268774345467,
            "rating_q025": 1276.0291135134246
        },
        "llama-3.1-405b-instruct-fp8": {
            "rating": 1284.2838692114037,
            "rating_q975": 1291.113414934075,
            "rating_q025": 1277.4543234887324
        },
        "claude-3-5-sonnet-20240620": {
            "rating": 1283.4231526903022,
            "rating_q975": 1290.0535119663398,
            "rating_q025": 1276.7927934142647
        },
        "llama-3.1-nemotron-70b-instruct": {
            "rating": 1283.189885629939,
            "rating_q975": 1299.7988069785335,
            "rating_q025": 1266.5809642813444
        },
        "qwen-max-0919": {
            "rating": 1281.608473096409,
            "rating_q975": 1292.7965624527187,
            "rating_q025": 1270.4203837400992
        },
        "deepseek-v2.5": {
            "rating": 1280.8373011916142,
            "rating_q975": 1289.9639216302699,
            "rating_q025": 1271.7106807529585
        },
        "grok-2-2024-08-13": {
            "rating": 1280.7968656383007,
            "rating_q975": 1287.3309087389705,
            "rating_q025": 1274.2628225376309
        },
        "glm-4-plus": {
            "rating": 1280.3014007911822,
            "rating_q975": 1289.7100747660884,
            "rating_q025": 1270.892726816276
        },
        "qwen2.5-72b-instruct": {
            "rating": 1280.287551339025,
            "rating_q975": 1287.8494651483743,
            "rating_q025": 1272.7256375296756
        },
        "hunyuan-large-vision": {
            "rating": 1279.3069807840893,
            "rating_q975": 1296.3326227411205,
            "rating_q025": 1262.281338827058
        },
        "gpt-4o-mini-2024-07-18": {
            "rating": 1278.9753766066865,
            "rating_q975": 1285.0825679509621,
            "rating_q025": 1272.8681852624109
        },
        "llama-3.3-70b-instruct": {
            "rating": 1278.2254722056746,
            "rating_q975": 1284.1413001945034,
            "rating_q025": 1272.3096442168458
        },
        "gpt-4o-2024-08-06": {
            "rating": 1277.7915607414989,
            "rating_q975": 1285.2916074124291,
            "rating_q025": 1270.2915140705686
        },
        "hunyuan-standard-2025-02-10": {
            "rating": 1275.8415229691645,
            "rating_q975": 1299.2609839317727,
            "rating_q025": 1252.4220620065564
        },
        "mistral-large-2407": {
            "rating": 1270.5578363690151,
            "rating_q975": 1278.0322357670082,
            "rating_q025": 1263.0834369710221
        },
        "qwen2.5-coder-32b-instruct": {
            "rating": 1270.1153251067121,
            "rating_q975": 1289.6213540664698,
            "rating_q025": 1250.6092961469544
        },
        "mistral-large-2411": {
            "rating": 1268.5527446154301,
            "rating_q975": 1276.939297306182,
            "rating_q025": 1260.1661919246783
        },
        "grok-2-mini-2024-08-13": {
            "rating": 1268.3405652050062,
            "rating_q975": 1275.2108480908976,
            "rating_q025": 1261.4702823191149
        },
        "gpt-4-turbo-2024-04-09": {
            "rating": 1267.1011024385907,
            "rating_q975": 1273.915988513088,
            "rating_q025": 1260.2862163640934
        },
        "claude-3-5-haiku-20241022": {
            "rating": 1266.6647795101749,
            "rating_q975": 1272.2302836614717,
            "rating_q025": 1261.099275358878
        },
        "gemini-1.5-flash-002": {
            "rating": 1265.6465109216624,
            "rating_q975": 1273.6188643212959,
            "rating_q025": 1257.674157522029
        },
        "llama-3.1-70b-instruct": {
            "rating": 1262.1992421566358,
            "rating_q975": 1269.0979147934383,
            "rating_q025": 1255.3005695198333
        },
        "gemini-1.5-pro-001": {
            "rating": 1259.4983896365038,
            "rating_q975": 1266.560197994909,
            "rating_q025": 1252.4365812780986
        },
        "amazon-nova-pro-v1.0": {
            "rating": 1258.8607243143356,
            "rating_q975": 1267.5066537145165,
            "rating_q025": 1250.2147949141547
        },
        "athene-70b-0725": {
            "rating": 1255.620684437024,
            "rating_q975": 1265.5814970946374,
            "rating_q025": 1245.6598717794107
        },
        "gpt-4-1106-preview": {
            "rating": 1254.8140383373318,
            "rating_q975": 1261.7812320058233,
            "rating_q025": 1247.8468446688403
        },
        "gemma-3-4b-it": {
            "rating": 1252.4685185561445,
            "rating_q975": 1273.0736609282246,
            "rating_q025": 1231.8633761840645
        },
        "gpt-4-0125-preview": {
            "rating": 1252.2444138419557,
            "rating_q975": 1259.359918471559,
            "rating_q025": 1245.1289092123525
        },
        "gemini-advanced-0514": {
            "rating": 1250.880257307991,
            "rating_q975": 1259.4898822696875,
            "rating_q025": 1242.2706323462946
        },
        "olmo-2-0325-32b-instruct": {
            "rating": 1244.992514664115,
            "rating_q975": 1268.9477332326408,
            "rating_q025": 1221.0372960955895
        },
        "claude-3-opus-20240229": {
            "rating": 1243.9938605521493,
            "rating_q975": 1249.5557516337374,
            "rating_q025": 1238.4319694705612
        },
        "mistral-small-24b-instruct-2501": {
            "rating": 1242.7751827966185,
            "rating_q975": 1254.433816181314,
            "rating_q025": 1231.1165494119232
        },
        "llama-3.1-tulu-3-70b": {
            "rating": 1237.6022720453057,
            "rating_q975": 1261.215865059458,
            "rating_q025": 1213.9886790311532
        },
        "jamba-1.5-large": {
            "rating": 1232.6108704128872,
            "rating_q975": 1246.4685436803145,
            "rating_q025": 1218.7531971454598
        },
        "llama-3-70b-instruct": {
            "rating": 1231.4900653736252,
            "rating_q975": 1238.0740427487146,
            "rating_q025": 1224.9060879985357
        },
        "phi-4": {
            "rating": 1230.7961951472878,
            "rating_q975": 1240.0354010282922,
            "rating_q025": 1221.5569892662834
        },
        "hunyuan-standard-256k": {
            "rating": 1229.1065614938734,
            "rating_q975": 1257.5197182431743,
            "rating_q025": 1200.6934047445725
        },
        "amazon-nova-lite-v1.0": {
            "rating": 1226.3384918741494,
            "rating_q975": 1236.3921777820892,
            "rating_q025": 1216.2848059662097
        },
        "gemini-1.5-flash-001": {
            "rating": 1225.5448079852965,
            "rating_q975": 1232.7736254742465,
            "rating_q025": 1218.3159904963466
        },
        "glm-4-0520": {
            "rating": 1218.8277244300716,
            "rating_q975": 1232.3301229610206,
            "rating_q025": 1205.3253258991226
        },
        "deepseek-coder-v2": {
            "rating": 1218.0624329882658,
            "rating_q975": 1229.9401127583244,
            "rating_q025": 1206.184753218207
        },
        "reka-core-20240904": {
            "rating": 1216.3462047739533,
            "rating_q975": 1230.523457776719,
            "rating_q025": 1202.1689517711877
        },
        "gemini-1.5-flash-8b-001": {
            "rating": 1215.0526215055625,
            "rating_q975": 1223.0655743583948,
            "rating_q025": 1207.0396686527301
        },
        "gpt-4-0314": {
            "rating": 1209.1423784948852,
            "rating_q975": 1217.9512409107379,
            "rating_q025": 1200.3335160790325
        },
        "ministral-8b-2410": {
            "rating": 1207.2373085293661,
            "rating_q975": 1227.4287047054404,
            "rating_q025": 1187.045912353292
        },
        "gemma-2-27b-it": {
            "rating": 1206.7706120595838,
            "rating_q975": 1212.8097442437074,
            "rating_q025": 1200.73147987546
        },
        "qwen2-72b-instruct": {
            "rating": 1206.5212597112325,
            "rating_q975": 1215.1076612682873,
            "rating_q025": 1197.9348581541776
        },
        "llama-3.1-nemotron-51b-instruct": {
            "rating": 1206.0706845753566,
            "rating_q975": 1228.6158996084619,
            "rating_q025": 1183.5254695422514
        },
        "amazon-nova-micro-v1.0": {
            "rating": 1204.6670607066267,
            "rating_q975": 1214.6240153438712,
            "rating_q025": 1194.7101060693822
        },
        "claude-3-sonnet-20240229": {
            "rating": 1203.189490430428,
            "rating_q975": 1210.325211560847,
            "rating_q025": 1196.0537693000088
        },
        "nemotron-4-340b-instruct": {
            "rating": 1202.75955807479,
            "rating_q975": 1213.7026109010242,
            "rating_q025": 1191.8165052485558
        },
        "gemma-2-9b-it-simpo": {
            "rating": 1202.1956007989838,
            "rating_q975": 1215.9008898024706,
            "rating_q025": 1188.490311795497
        },
        "llama-3.1-8b-instruct": {
            "rating": 1196.7948964733741,
            "rating_q975": 1204.1097057846755,
            "rating_q025": 1189.4800871620728
        },
        "c4ai-aya-expanse-32b": {
            "rating": 1196.7215931691078,
            "rating_q975": 1205.7937883265463,
            "rating_q025": 1187.6493980116693
        },
        "command-r-plus-08-2024": {
            "rating": 1195.6888083809743,
            "rating_q975": 1208.8321344431774,
            "rating_q025": 1182.545482318771
        },
        "internlm2_5-20b-chat": {
            "rating": 1190.3060724449215,
            "rating_q975": 1204.7308035823169,
            "rating_q025": 1175.881341307526
        },
        "gpt-4-0613": {
            "rating": 1189.2537984625474,
            "rating_q975": 1196.7543112884614,
            "rating_q025": 1181.7532856366333
        },
        "reka-flash-20240904": {
            "rating": 1186.96391945981,
            "rating_q975": 1200.8084244177771,
            "rating_q025": 1173.119414501843
        },
        "qwen1.5-110b-chat": {
            "rating": 1185.9220167025696,
            "rating_q975": 1196.2799993091235,
            "rating_q025": 1175.5640340960158
        },
        "jamba-1.5-mini": {
            "rating": 1182.84229695403,
            "rating_q975": 1197.0637887745647,
            "rating_q025": 1168.6208051334952
        },
        "claude-3-haiku-20240307": {
            "rating": 1182.348793919818,
            "rating_q975": 1188.8854623993655,
            "rating_q025": 1175.8121254402706
        },
        "yi-1.5-34b-chat": {
            "rating": 1180.3016961316885,
            "rating_q975": 1190.2878278555568,
            "rating_q025": 1170.3155644078201
        },
        "llama-3.1-tulu-3-8b": {
            "rating": 1179.3284207902961,
            "rating_q975": 1205.0061658667917,
            "rating_q025": 1153.6506757138006
        },
        "mistral-large-2402": {
            "rating": 1179.1516747409537,
            "rating_q975": 1187.3503457411732,
            "rating_q025": 1170.9530037407342
        },
        "gemma-2-9b-it": {
            "rating": 1178.5639684304747,
            "rating_q975": 1185.4747382685161,
            "rating_q025": 1171.6531985924332
        },
        "command-r-08-2024": {
            "rating": 1172.6106404286672,
            "rating_q975": 1185.4014024374633,
            "rating_q025": 1159.8198784198712
        },
        "command-r-plus": {
            "rating": 1172.398777018622,
            "rating_q975": 1179.9210527626526,
            "rating_q025": 1164.8765012745914
        },
        "qwq-32b-preview": {
            "rating": 1171.6751388268917,
            "rating_q975": 1196.5105127985512,
            "rating_q025": 1146.8397648552323
        },
        "granite-3.1-8b-instruct": {
            "rating": 1166.1960850162527,
            "rating_q975": 1190.2487652359255,
            "rating_q025": 1142.14340479658
        },
        "llama-3-8b-instruct": {
            "rating": 1164.732196708284,
            "rating_q975": 1171.8080909205555,
            "rating_q025": 1157.6563024960124
        },
        "mixtral-8x22b-instruct-v0.1": {
            "rating": 1164.1302549887707,
            "rating_q975": 1172.2845283729562,
            "rating_q025": 1155.9759816045853
        },
        "qwen1.5-72b-chat": {
            "rating": 1163.3705792452433,
            "rating_q975": 1172.2412139363794,
            "rating_q025": 1154.4999445541073
        },
        "mistral-medium": {
            "rating": 1159.11516232859,
            "rating_q975": 1168.8647894503342,
            "rating_q025": 1149.3655352068458
        },
        "granite-3.1-2b-instruct": {
            "rating": 1156.8267000174956,
            "rating_q975": 1181.4765903722653,
            "rating_q025": 1132.1768096627259
        },
        "c4ai-aya-expanse-8b": {
            "rating": 1155.6745943187047,
            "rating_q975": 1169.9545968981363,
            "rating_q025": 1141.3945917392732
        },
        "reka-flash-21b-20240226-online": {
            "rating": 1148.514363375494,
            "rating_q975": 1161.0562905138447,
            "rating_q025": 1135.9724362371433
        },
        "qwen1.5-32b-chat": {
            "rating": 1147.9226247275897,
            "rating_q975": 1158.938205722804,
            "rating_q025": 1136.9070437323753
        },
        "reka-flash-21b-20240226": {
            "rating": 1145.4620615996598,
            "rating_q975": 1155.8783091992832,
            "rating_q025": 1135.0458140000364
        },
        "phi-3-medium-4k-instruct": {
            "rating": 1143.384715004504,
            "rating_q975": 1153.0998490428963,
            "rating_q025": 1133.6695809661117
        },
        "llama-3.2-3b-instruct": {
            "rating": 1142.4765208921444,
            "rating_q975": 1157.4030369080406,
            "rating_q025": 1127.5500048762483
        },
        "dbrx-instruct-preview": {
            "rating": 1138.954072243928,
            "rating_q975": 1149.6507035261122,
            "rating_q025": 1128.257440961744
        },
        "mixtral-8x7b-instruct-v0.1": {
            "rating": 1136.0692289466622,
            "rating_q975": 1143.7464616930613,
            "rating_q025": 1128.391996200263
        },
        "zephyr-orpo-141b-A35b-v0.1": {
            "rating": 1134.8924912403463,
            "rating_q975": 1155.3042907828105,
            "rating_q025": 1114.480691697882
        },
        "starling-lm-7b-beta": {
            "rating": 1131.9400021153672,
            "rating_q975": 1144.5733805519012,
            "rating_q025": 1119.3066236788331
        },
        "gemma-2-2b-it": {
            "rating": 1128.878441801639,
            "rating_q975": 1136.4004470224204,
            "rating_q025": 1121.3564365808575
        },
        "phi-3-small-8k-instruct": {
            "rating": 1126.2425959272987,
            "rating_q975": 1137.7784846292352,
            "rating_q025": 1114.7067072253622
        },
        "tulu-2-dpo-70b": {
            "rating": 1125.5212428615528,
            "rating_q975": 1143.0999068165613,
            "rating_q025": 1107.9425789065442
        },
        "qwen1.5-14b-chat": {
            "rating": 1124.7454244121527,
            "rating_q975": 1137.3531779937057,
            "rating_q025": 1112.1376708305997
        },
        "command-r": {
            "rating": 1123.6017788613133,
            "rating_q975": 1132.1568109812413,
            "rating_q025": 1115.0467467413853
        },
        "granite-3.0-8b-instruct": {
            "rating": 1123.1305660308942,
            "rating_q975": 1142.6725583942143,
            "rating_q025": 1103.588573667574
        },
        "gpt-3.5-turbo-0125": {
            "rating": 1122.891231973536,
            "rating_q975": 1130.5383784014684,
            "rating_q025": 1115.2440855456034
        },
        "yi-34b-chat": {
            "rating": 1120.8623102728627,
            "rating_q975": 1132.8666865792488,
            "rating_q025": 1108.8579339664766
        },
        "gemini-pro-dev-api": {
            "rating": 1117.919831119198,
            "rating_q975": 1130.5099886826677,
            "rating_q025": 1105.3296735557285
        },
        "phi-3-mini-4k-instruct-june-2024": {
            "rating": 1115.333724974181,
            "rating_q975": 1128.206500056169,
            "rating_q025": 1102.460949892193
        },
        "gpt-3.5-turbo-1106": {
            "rating": 1114.9800050025651,
            "rating_q975": 1128.9075134354819,
            "rating_q025": 1101.0524965696484
        },
        "gemini-pro": {
            "rating": 1111.540845994184,
            "rating_q975": 1130.6204959539198,
            "rating_q025": 1092.4611960344484
        },
        "wizardlm-70b": {
            "rating": 1097.1517266111437,
            "rating_q975": 1113.6195319791989,
            "rating_q025": 1080.6839212430884
        },
        "phi-3-mini-4k-instruct": {
            "rating": 1096.3341571574942,
            "rating_q975": 1107.7995907850493,
            "rating_q025": 1084.8687235299392
        },
        "starling-lm-7b-alpha": {
            "rating": 1096.2902078149837,
            "rating_q975": 1110.4300817025362,
            "rating_q025": 1082.1503339274311
        },
        "openchat-3.5-0106": {
            "rating": 1095.9800915767576,
            "rating_q975": 1108.3794193423205,
            "rating_q025": 1083.5807638111946
        },
        "llama-2-70b-chat": {
            "rating": 1092.4544036546868,
            "rating_q975": 1101.6589736388812,
            "rating_q025": 1083.2498336704923
        },
        "gemma-1.1-7b-it": {
            "rating": 1091.8269145573938,
            "rating_q975": 1102.086428777345,
            "rating_q025": 1081.5674003374427
        },
        "mistral-7b-instruct-v0.2": {
            "rating": 1090.7777955635565,
            "rating_q975": 1101.793323152357,
            "rating_q025": 1079.762267974756
        },
        "snowflake-arctic-instruct": {
            "rating": 1089.687058715038,
            "rating_q975": 1100.4385718331243,
            "rating_q025": 1078.9355455969514
        },
        "granite-3.0-2b-instruct": {
            "rating": 1088.0736227780374,
            "rating_q975": 1107.4186458084507,
            "rating_q025": 1068.728599747624
        },
        "llama-3.2-1b-instruct": {
            "rating": 1087.689851087031,
            "rating_q975": 1102.6458198760572,
            "rating_q025": 1072.7338822980048
        },
        "openhermes-2.5-mistral-7b": {
            "rating": 1087.5968116076026,
            "rating_q975": 1106.356659194027,
            "rating_q025": 1068.8369640211781
        },
        "deepseek-llm-67b-chat": {
            "rating": 1086.6424920008722,
            "rating_q975": 1106.8423495055556,
            "rating_q025": 1066.4426344961887
        },
        "mpt-30b-chat": {
            "rating": 1082.455960054685,
            "rating_q975": 1112.9555331007132,
            "rating_q025": 1051.9563870086567
        },
        "vicuna-33b": {
            "rating": 1080.5327788190139,
            "rating_q975": 1091.806732818714,
            "rating_q025": 1069.2588248193138
        },
        "solar-10.7b-instruct-v1.0": {
            "rating": 1077.2856712971711,
            "rating_q975": 1098.9911903382072,
            "rating_q025": 1055.580152256135
        },
        "qwen1.5-7b-chat": {
            "rating": 1076.2886019869204,
            "rating_q975": 1093.8260857713665,
            "rating_q025": 1058.7511182024743
        },
        "codellama-70b-instruct": {
            "rating": 1076.2547086558095,
            "rating_q975": 1114.2348373514512,
            "rating_q025": 1038.2745799601678
        },
        "smollm2-1.7b-instruct": {
            "rating": 1074.072975901383,
            "rating_q975": 1106.647974118588,
            "rating_q025": 1041.4979776841778
        },
        "llama-2-13b-chat": {
            "rating": 1073.9134723338957,
            "rating_q975": 1085.7912228657142,
            "rating_q025": 1062.0357218020772
        },
        "openchat-3.5": {
            "rating": 1072.0540480328996,
            "rating_q975": 1088.939933100398,
            "rating_q025": 1055.168162965401
        },
        "dolphin-2.2.1-mistral-7b": {
            "rating": 1069.2634031404352,
            "rating_q975": 1101.2983040080014,
            "rating_q025": 1037.228502272869
        },
        "nous-hermes-2-mixtral-8x7b-dpo": {
            "rating": 1067.4243817884496,
            "rating_q975": 1086.1009954111973,
            "rating_q025": 1048.747768165702
        },
        "gemma-7b-it": {
            "rating": 1061.7801070462183,
            "rating_q975": 1077.0656421181468,
            "rating_q025": 1046.4945719742898
        },
        "llama2-70b-steerlm-chat": {
            "rating": 1057.4532970212776,
            "rating_q975": 1080.6094623620818,
            "rating_q025": 1034.2971316804735
        },
        "phi-3-mini-128k-instruct": {
            "rating": 1052.2808486070426,
            "rating_q975": 1064.6982865675777,
            "rating_q025": 1039.8634106465074
        },
        "zephyr-7b-beta": {
            "rating": 1048.437578976643,
            "rating_q975": 1063.990890419649,
            "rating_q025": 1032.8842675336368
        },
        "codellama-34b-instruct": {
            "rating": 1047.6357896953616,
            "rating_q975": 1063.7677170861004,
            "rating_q025": 1031.5038623046228
        },
        "zephyr-7b-alpha": {
            "rating": 1044.4222430174564,
            "rating_q975": 1078.0528325350986,
            "rating_q025": 1010.7916534998141
        },
        "qwen-14b-chat": {
            "rating": 1041.4574062189276,
            "rating_q975": 1062.1219243423566,
            "rating_q025": 1020.7928880954986
        },
        "vicuna-13b": {
            "rating": 1036.5311902819647,
            "rating_q975": 1048.6087356063472,
            "rating_q025": 1024.4536449575821
        },
        "palm-2": {
            "rating": 1035.840148499058,
            "rating_q975": 1052.5975666977672,
            "rating_q025": 1019.0827303003485
        },
        "wizardlm-13b": {
            "rating": 1034.6317546797827,
            "rating_q975": 1053.1104261747143,
            "rating_q025": 1016.153083184851
        },
        "llama-2-7b-chat": {
            "rating": 1032.5838009297536,
            "rating_q975": 1045.0286635525845,
            "rating_q025": 1020.1389383069226
        },
        "gemma-1.1-2b-it": {
            "rating": 1026.5337003731356,
            "rating_q975": 1040.913458219298,
            "rating_q025": 1012.1539425269731
        },
        "mistral-7b-instruct": {
            "rating": 1022.892865034704,
            "rating_q975": 1039.4596685513407,
            "rating_q025": 1006.3260615180673
        },
        "guanaco-33b": {
            "rating": 1019.9131794538516,
            "rating_q975": 1048.3462092283812,
            "rating_q025": 991.480149679322
        },
        "stripedhyena-nous-7b": {
            "rating": 1016.1372663656568,
            "rating_q975": 1034.3881215043486,
            "rating_q025": 997.8864112269649
        },
        "olmo-7b-instruct": {
            "rating": 1012.2175649664435,
            "rating_q975": 1031.001000478562,
            "rating_q025": 993.4341294543251
        },
        "vicuna-7b": {
            "rating": 1004.8686794474902,
            "rating_q975": 1023.5927363307545,
            "rating_q025": 986.1446225642259
        },
        "gemma-2b-it": {
            "rating": 997.4274561499211,
            "rating_q975": 1017.6844008649263,
            "rating_q025": 977.170511434916
        },
        "qwen1.5-4b-chat": {
            "rating": 983.8367072555685,
            "rating_q975": 999.9608353957007,
            "rating_q025": 967.7125791154364
        },
        "chatglm3-6b": {
            "rating": 977.6994251530117,
            "rating_q975": 999.3635134337975,
            "rating_q025": 956.0353368722259
        },
        "gpt4all-13b-snoozy": {
            "rating": 955.9457929764658,
            "rating_q975": 990.2504935784153,
            "rating_q025": 921.6410923745162
        },
        "koala-13b": {
            "rating": 943.4852006898964,
            "rating_q975": 963.4710236088342,
            "rating_q025": 923.4993777709585
        },
        "chatglm2-6b": {
            "rating": 938.5997261291802,
            "rating_q975": 968.116490972759,
            "rating_q025": 909.0829612856014
        },
        "mpt-7b-chat": {
            "rating": 908.7751035330165,
            "rating_q975": 933.3580330427453,
            "rating_q025": 884.1921740232876
        },
        "RWKV-4-Raven-14B": {
            "rating": 901.3569784647557,
            "rating_q975": 923.8838312638107,
            "rating_q025": 878.8301256657006
        },
        "oasst-pythia-12b": {
            "rating": 897.8864716624723,
            "rating_q975": 918.8889428864313,
            "rating_q025": 876.8840004385133
        },
        "chatglm-6b": {
            "rating": 896.6444414944256,
            "rating_q975": 920.3961541833401,
            "rating_q025": 872.8927288055111
        },
        "stablelm-tuned-alpha-7b": {
            "rating": 849.4998259618956,
            "rating_q975": 877.2293353431679,
            "rating_q025": 821.7703165806232
        },
        "alpaca-13b": {
            "rating": 839.625618574488,
            "rating_q975": 861.5534017327556,
            "rating_q025": 817.6978354162205
        },
        "fastchat-t5-3b": {
            "rating": 830.0499650346231,
            "rating_q975": 853.5513623641574,
            "rating_q025": 806.5485677050889
        },
        "dolly-v2-12b": {
            "rating": 809.4780583049135,
            "rating_q975": 836.7461651645445,
            "rating_q025": 782.2099514452824
        },
        "llama-13b": {
            "rating": 734.7116600619045,
            "rating_q975": 769.0324147741162,
            "rating_q025": 700.3909053496927
        }
    },
    "if": {
        "claude-opus-4-5-20251101": {
            "rating": 1475.0829476943616,
            "rating_q975": 1487.0557152014392,
            "rating_q025": 1463.110180187284
        },
        "claude-opus-4-5-20251101-thinking-32k": {
            "rating": 1465.9451235995332,
            "rating_q975": 1478.172495222857,
            "rating_q025": 1453.7177519762095
        },
        "gemini-3-pro": {
            "rating": 1460.3740506335034,
            "rating_q975": 1470.296423369856,
            "rating_q025": 1450.4516778971508
        },
        "claude-sonnet-4-5-20250929-thinking-32k": {
            "rating": 1450.8790224336167,
            "rating_q975": 1458.4471243615828,
            "rating_q025": 1443.3109205056505
        },
        "claude-sonnet-4-5-20250929": {
            "rating": 1444.8352413951623,
            "rating_q975": 1453.1013126003206,
            "rating_q025": 1436.569170190004
        },
        "gemini-2.5-pro": {
            "rating": 1442.1832957094152,
            "rating_q975": 1447.5415526144257,
            "rating_q025": 1436.8250388044048
        },
        "gpt-5.1-high": {
            "rating": 1437.2475181436844,
            "rating_q975": 1447.7765156067933,
            "rating_q025": 1426.7185206805755
        },
        "claude-opus-4-1-20250805-thinking-16k": {
            "rating": 1435.548519535737,
            "rating_q975": 1441.8489021433265,
            "rating_q025": 1429.2481369281472
        },
        "claude-opus-4-1-20250805": {
            "rating": 1429.0678038570404,
            "rating_q975": 1434.9689110469071,
            "rating_q025": 1423.1666966671737
        },
        "qwen3-max-preview": {
            "rating": 1418.971305322972,
            "rating_q975": 1426.36508887211,
            "rating_q025": 1411.5775217738342
        },
        "gpt-5.1": {
            "rating": 1415.0045850483916,
            "rating_q975": 1425.0267325832378,
            "rating_q025": 1404.9824375135454
        },
        "glm-4.6": {
            "rating": 1413.5125896578304,
            "rating_q975": 1421.1443833300552,
            "rating_q025": 1405.8807959856056
        },
        "grok-4.1-thinking": {
            "rating": 1410.4232457759135,
            "rating_q975": 1420.2492753116424,
            "rating_q025": 1400.5972162401847
        },
        "qwen3-vl-235b-a22b-instruct": {
            "rating": 1407.3836905562607,
            "rating_q975": 1419.1887675417242,
            "rating_q025": 1395.5786135707972
        },
        "grok-3-preview-02-24": {
            "rating": 1407.3225091425195,
            "rating_q975": 1413.7576745532126,
            "rating_q025": 1400.8873437318264
        },
        "qwen3-235b-a22b-instruct-2507": {
            "rating": 1407.0756689544346,
            "rating_q975": 1412.934968810588,
            "rating_q025": 1401.2163690982811
        },
        "claude-haiku-4-5-20251001": {
            "rating": 1406.5951754300818,
            "rating_q975": 1414.1927473734236,
            "rating_q025": 1398.99760348674
        },
        "mistral-large-3": {
            "rating": 1406.0022130966897,
            "rating_q975": 1419.789593533919,
            "rating_q025": 1392.2148326594604
        },
        "gemini-2.5-flash": {
            "rating": 1405.3425786178314,
            "rating_q975": 1410.5644753973859,
            "rating_q025": 1400.1206818382768
        },
        "claude-opus-4-20250514-thinking-16k": {
            "rating": 1404.1413420409017,
            "rating_q975": 1411.052018030753,
            "rating_q025": 1397.2306660510503
        },
        "glm-4.5": {
            "rating": 1403.129705054895,
            "rating_q975": 1411.029908359222,
            "rating_q025": 1395.2295017505683
        },
        "gpt-4.5-preview-2025-02-27": {
            "rating": 1401.8459790208335,
            "rating_q975": 1410.0217178077567,
            "rating_q025": 1393.6702402339104
        },
        "mistral-medium-2508": {
            "rating": 1400.8247698444065,
            "rating_q975": 1406.9574877726352,
            "rating_q025": 1394.692051916178
        },
        "deepseek-v3.2": {
            "rating": 1400.7493740455996,
            "rating_q975": 1414.915412073604,
            "rating_q025": 1386.583336017595
        },
        "deepseek-v3.1-thinking": {
            "rating": 1400.3859848248578,
            "rating_q975": 1411.5555460386602,
            "rating_q025": 1389.2164236110555
        },
        "deepseek-v3.2-exp": {
            "rating": 1399.6068442336018,
            "rating_q975": 1410.0837139917755,
            "rating_q025": 1389.129974475428
        },
        "grok-4.1": {
            "rating": 1398.8206674226258,
            "rating_q975": 1408.64736609189,
            "rating_q025": 1388.9939687533615
        },
        "deepseek-v3.2-exp-thinking": {
            "rating": 1398.6505811430097,
            "rating_q975": 1410.1994706184494,
            "rating_q025": 1387.10169166757
        },
        "chatgpt-4o-latest-20250326": {
            "rating": 1397.7242632460677,
            "rating_q975": 1402.7888716320622,
            "rating_q025": 1392.6596548600733
        },
        "deepseek-v3.1-terminus-thinking": {
            "rating": 1397.7104870718258,
            "rating_q975": 1417.8276587595124,
            "rating_q025": 1377.5933153841393
        },
        "kimi-k2-thinking-turbo": {
            "rating": 1397.6021014110793,
            "rating_q975": 1407.1589909568147,
            "rating_q025": 1388.0452118653438
        },
        "deepseek-v3.2-thinking": {
            "rating": 1396.9274115998226,
            "rating_q975": 1411.7042450351,
            "rating_q025": 1382.150578164545
        },
        "qwen3-max-2025-09-23": {
            "rating": 1396.6049073884112,
            "rating_q975": 1407.9770410170934,
            "rating_q025": 1385.232773759729
        },
        "longcat-flash-chat": {
            "rating": 1395.2957560454743,
            "rating_q975": 1406.0462544111172,
            "rating_q025": 1384.5452576798314
        },
        "gemini-2.5-flash-preview-09-2025": {
            "rating": 1394.520271796925,
            "rating_q975": 1401.6385432528432,
            "rating_q025": 1387.402000341007
        },
        "grok-4-fast-chat": {
            "rating": 1391.357848475371,
            "rating_q975": 1405.8062151151732,
            "rating_q025": 1376.9094818355686
        },
        "ernie-5.0-preview-1103": {
            "rating": 1390.7056927560654,
            "rating_q975": 1405.7238950479052,
            "rating_q025": 1375.6874904642257
        },
        "qwen3-next-80b-a3b-instruct": {
            "rating": 1389.7376390604381,
            "rating_q975": 1397.4282293543947,
            "rating_q025": 1382.0470487664816
        },
        "gpt-5-high": {
            "rating": 1389.3496179679064,
            "rating_q975": 1396.4736345514586,
            "rating_q025": 1382.2256013843541
        },
        "deepseek-v3.1": {
            "rating": 1387.758056728721,
            "rating_q975": 1397.5989110594644,
            "rating_q025": 1377.9172023979775
        },
        "qwen3-235b-a22b-thinking-2507": {
            "rating": 1387.209595847782,
            "rating_q975": 1399.6395614445062,
            "rating_q025": 1374.779630251058
        },
        "hunyuan-vision-1.5-thinking": {
            "rating": 1387.1028481659148,
            "rating_q975": 1410.0258572568541,
            "rating_q025": 1364.1798390749755
        },
        "grok-4-0709": {
            "rating": 1384.7829951264803,
            "rating_q975": 1390.9761916043356,
            "rating_q025": 1378.589798648625
        },
        "gpt-5-chat": {
            "rating": 1381.2377234273645,
            "rating_q975": 1388.2189049297558,
            "rating_q025": 1374.2565419249731
        },
        "deepseek-r1-0528": {
            "rating": 1379.082175618106,
            "rating_q975": 1388.497431832185,
            "rating_q025": 1369.666919404027
        },
        "deepseek-v3.1-terminus": {
            "rating": 1378.9386165151668,
            "rating_q975": 1396.996623536598,
            "rating_q025": 1360.8806094937356
        },
        "grok-4-fast-reasoning": {
            "rating": 1377.929618314823,
            "rating_q975": 1386.299546336798,
            "rating_q025": 1369.5596902928482
        },
        "hunyuan-t1-20250711": {
            "rating": 1375.4067538535453,
            "rating_q975": 1393.0014786223112,
            "rating_q025": 1357.8120290847794
        },
        "claude-sonnet-4-20250514-thinking-32k": {
            "rating": 1373.949214841928,
            "rating_q975": 1380.9524484326475,
            "rating_q025": 1366.9459812512087
        },
        "grok-4-1-fast-reasoning": {
            "rating": 1372.5660926863718,
            "rating_q975": 1384.4173964556492,
            "rating_q025": 1360.7147889170944
        },
        "qwen3-vl-235b-a22b-thinking": {
            "rating": 1371.3604902117409,
            "rating_q975": 1383.7910676942606,
            "rating_q025": 1358.929912729221
        },
        "claude-opus-4-20250514": {
            "rating": 1370.640305820868,
            "rating_q975": 1377.1397552448102,
            "rating_q025": 1364.1408563969258
        },
        "o3-2025-04-16": {
            "rating": 1366.76031183999,
            "rating_q975": 1372.311838323619,
            "rating_q025": 1361.208785356361
        },
        "gemini-2.5-flash-lite-preview-06-17-thinking": {
            "rating": 1365.1857954653067,
            "rating_q975": 1372.1354871723406,
            "rating_q025": 1358.2361037582727
        },
        "o1-2024-12-17": {
            "rating": 1364.3683264223234,
            "rating_q975": 1370.7004731291279,
            "rating_q025": 1358.036179715519
        },
        "gpt-4.1-2025-04-14": {
            "rating": 1363.0831921134989,
            "rating_q975": 1368.8063225498088,
            "rating_q025": 1357.360061677189
        },
        "amazon-nova-experimental-chat-10-20": {
            "rating": 1361.157296246693,
            "rating_q975": 1373.5979751249342,
            "rating_q025": 1348.7166173684518
        },
        "qwen3-30b-a3b-instruct-2507": {
            "rating": 1361.083410281936,
            "rating_q975": 1369.004905109686,
            "rating_q025": 1353.161915454186
        },
        "qwen3-235b-a22b-no-thinking": {
            "rating": 1358.6643851837678,
            "rating_q975": 1365.4106332300505,
            "rating_q025": 1351.918137137485
        },
        "gpt-5-mini-high": {
            "rating": 1357.3442737634978,
            "rating_q975": 1364.893145629953,
            "rating_q025": 1349.7954018970424
        },
        "mai-1-preview": {
            "rating": 1355.9741132742508,
            "rating_q975": 1365.1750263584827,
            "rating_q025": 1346.773200190019
        },
        "deepseek-r1": {
            "rating": 1354.9720020078612,
            "rating_q975": 1362.2734413551377,
            "rating_q025": 1347.6705626605847
        },
        "qwen3-coder-480b-a35b-instruct": {
            "rating": 1353.8263222519497,
            "rating_q975": 1361.790506083051,
            "rating_q025": 1345.8621384208484
        },
        "grok-3-mini-high": {
            "rating": 1353.406436008936,
            "rating_q975": 1362.4049395021075,
            "rating_q025": 1344.4079325157645
        },
        "gemini-2.5-flash-lite-preview-09-2025-no-thinking": {
            "rating": 1353.3170339253218,
            "rating_q975": 1360.3904214960191,
            "rating_q025": 1346.2436463546244
        },
        "glm-4.5-air": {
            "rating": 1352.7819523977332,
            "rating_q975": 1359.6989983581923,
            "rating_q025": 1345.8649064372742
        },
        "claude-3-7-sonnet-20250219-thinking-32k": {
            "rating": 1349.2584100414092,
            "rating_q975": 1355.6054562696775,
            "rating_q025": 1342.911363813141
        },
        "claude-sonnet-4-20250514": {
            "rating": 1347.1247234095001,
            "rating_q975": 1353.7483620037035,
            "rating_q025": 1340.5010848152967
        },
        "grok-3-mini-beta": {
            "rating": 1345.2710255328554,
            "rating_q975": 1353.208127469035,
            "rating_q025": 1337.333923596676
        },
        "deepseek-v3-0324": {
            "rating": 1342.8496962933837,
            "rating_q975": 1348.6772961252175,
            "rating_q025": 1337.0220964615498
        },
        "kimi-k2-0905-preview": {
            "rating": 1341.7373427633636,
            "rating_q975": 1352.8626817598345,
            "rating_q025": 1330.6120037668927
        },
        "qwen3-next-80b-a3b-thinking": {
            "rating": 1341.6736270615859,
            "rating_q975": 1351.6332141475975,
            "rating_q025": 1331.7140399755742
        },
        "o1-preview": {
            "rating": 1339.8903048558743,
            "rating_q975": 1346.6027080791935,
            "rating_q025": 1333.1779016325552
        },
        "hunyuan-turbos-20250416": {
            "rating": 1339.7782485222438,
            "rating_q975": 1351.2765385016578,
            "rating_q025": 1328.2799585428297
        },
        "mistral-medium-2505": {
            "rating": 1335.3554759255185,
            "rating_q975": 1342.402752805915,
            "rating_q025": 1328.308199045122
        },
        "amazon-nova-experimental-chat-10-09": {
            "rating": 1335.1828783650105,
            "rating_q975": 1346.5281505394578,
            "rating_q025": 1323.8376061905633
        },
        "o3-mini-high": {
            "rating": 1334.563850210042,
            "rating_q975": 1342.0854036972883,
            "rating_q025": 1327.0422967227955
        },
        "gemini-2.0-flash-001": {
            "rating": 1333.2981228943422,
            "rating_q975": 1338.664537725629,
            "rating_q025": 1327.9317080630553
        },
        "qwen3-235b-a22b": {
            "rating": 1333.2299840265164,
            "rating_q975": 1340.9035405862098,
            "rating_q025": 1325.556427466823
        },
        "qwen2.5-max": {
            "rating": 1332.073905538525,
            "rating_q975": 1337.8925862775602,
            "rating_q025": 1326.2552247994897
        },
        "nova-2-lite": {
            "rating": 1330.4737098485994,
            "rating_q975": 1345.3230147972927,
            "rating_q025": 1315.624404899906
        },
        "gpt-4.1-mini-2025-04-14": {
            "rating": 1330.2143165124571,
            "rating_q975": 1336.6382978423376,
            "rating_q025": 1323.7903351825767
        },
        "step-3": {
            "rating": 1328.794098810582,
            "rating_q975": 1343.2466774904995,
            "rating_q025": 1314.3415201306645
        },
        "minimax-m2": {
            "rating": 1327.4596380941653,
            "rating_q975": 1340.4658225320213,
            "rating_q025": 1314.4534536563092
        },
        "kimi-k2-0711-preview": {
            "rating": 1322.116533185514,
            "rating_q975": 1329.7224045300227,
            "rating_q025": 1314.5106618410055
        },
        "claude-3-7-sonnet-20250219": {
            "rating": 1321.6824183005672,
            "rating_q975": 1327.4715379945635,
            "rating_q025": 1315.8932986065709
        },
        "o4-mini-2025-04-16": {
            "rating": 1321.4847001354203,
            "rating_q975": 1327.4870536473106,
            "rating_q025": 1315.48234662353
        },
        "gemma-3-27b-it": {
            "rating": 1319.2736072945113,
            "rating_q975": 1324.8367471489755,
            "rating_q025": 1313.710467440047
        },
        "ling-flash-2.0": {
            "rating": 1316.8100845960012,
            "rating_q975": 1330.279920666401,
            "rating_q025": 1303.3402485256013
        },
        "gpt-oss-120b": {
            "rating": 1316.2548080321494,
            "rating_q975": 1323.3733064213031,
            "rating_q025": 1309.1363096429957
        },
        "o3-mini": {
            "rating": 1313.6774890665274,
            "rating_q975": 1318.6651886772067,
            "rating_q025": 1308.689789455848
        },
        "minimax-m1": {
            "rating": 1313.2210422664314,
            "rating_q975": 1319.858905950054,
            "rating_q025": 1306.5831785828088
        },
        "deepseek-v3": {
            "rating": 1313.0605542275725,
            "rating_q975": 1319.7289621860186,
            "rating_q025": 1306.3921462691264
        },
        "hunyuan-turbos-20250226": {
            "rating": 1312.0610089239344,
            "rating_q975": 1330.0462570860304,
            "rating_q025": 1294.0757607618384
        },
        "intellect-3": {
            "rating": 1311.1690988368387,
            "rating_q975": 1335.3622287037795,
            "rating_q025": 1286.9759689698978
        },
        "ring-flash-2.0": {
            "rating": 1311.116943611121,
            "rating_q975": 1324.618460465529,
            "rating_q025": 1297.615426756713
        },
        "step-1o-turbo-202506": {
            "rating": 1310.5844341265263,
            "rating_q975": 1322.9465114205407,
            "rating_q025": 1298.2223568325119
        },
        "mistral-small-2506": {
            "rating": 1309.4305273674795,
            "rating_q975": 1318.2047497433953,
            "rating_q025": 1300.6563049915637
        },
        "glm-4.5v": {
            "rating": 1309.391625746539,
            "rating_q975": 1325.4564773403836,
            "rating_q025": 1293.3267741526943
        },
        "command-a-03-2025": {
            "rating": 1306.6905658011779,
            "rating_q975": 1311.9473871004593,
            "rating_q025": 1301.4337445018964
        },
        "llama-3.1-nemotron-ultra-253b-v1": {
            "rating": 1306.0933048701704,
            "rating_q975": 1327.2856618944884,
            "rating_q025": 1284.9009478458524
        },
        "gemini-2.0-flash-lite-preview-02-05": {
            "rating": 1303.134793770441,
            "rating_q975": 1309.2827732490896,
            "rating_q025": 1296.9868142917926
        },
        "o1-mini": {
            "rating": 1302.3654990651848,
            "rating_q975": 1307.394842012961,
            "rating_q025": 1297.3361561174088
        },
        "qwen3-32b": {
            "rating": 1302.3302214144423,
            "rating_q975": 1321.1673999725012,
            "rating_q025": 1283.4930428563835
        },
        "gpt-5-nano-high": {
            "rating": 1301.96172008438,
            "rating_q975": 1315.174972926517,
            "rating_q025": 1288.748467242243
        },
        "qwen-plus-0125": {
            "rating": 1301.3334459924336,
            "rating_q975": 1313.352150242148,
            "rating_q025": 1289.3147417427192
        },
        "gemma-3-12b-it": {
            "rating": 1297.4697975074494,
            "rating_q975": 1313.599023735748,
            "rating_q025": 1281.3405712791507
        },
        "qwq-32b": {
            "rating": 1297.3810760970732,
            "rating_q975": 1304.2838472206968,
            "rating_q025": 1290.4783049734497
        },
        "nvidia-llama-3.3-nemotron-super-49b-v1.5": {
            "rating": 1297.2949871240655,
            "rating_q975": 1316.9038696572509,
            "rating_q025": 1277.6861045908802
        },
        "claude-3-5-sonnet-20241022": {
            "rating": 1295.9819674294195,
            "rating_q975": 1300.1219777410497,
            "rating_q025": 1291.8419571177892
        },
        "gemini-1.5-pro-002": {
            "rating": 1295.56783355577,
            "rating_q975": 1300.301342968273,
            "rating_q025": 1290.834324143267
        },
        "glm-4-plus-0111": {
            "rating": 1291.9265859900133,
            "rating_q975": 1304.2924062593163,
            "rating_q025": 1279.5607657207104
        },
        "llama-3.3-nemotron-49b-super-v1": {
            "rating": 1291.8325507218522,
            "rating_q975": 1311.2928653667493,
            "rating_q025": 1272.372236076955
        },
        "step-2-16k-exp-202412": {
            "rating": 1284.5593256946354,
            "rating_q975": 1297.0069433929818,
            "rating_q025": 1272.111707996289
        },
        "qwen3-30b-a3b": {
            "rating": 1284.1633366789931,
            "rating_q975": 1291.9000624042392,
            "rating_q025": 1276.426610953747
        },
        "deepseek-v2.5-1210": {
            "rating": 1278.3516269810348,
            "rating_q975": 1289.4347889396818,
            "rating_q025": 1267.2684650223878
        },
        "yi-lightning": {
            "rating": 1277.5039693447925,
            "rating_q975": 1284.2493453521397,
            "rating_q025": 1270.7585933374453
        },
        "hunyuan-turbo-0110": {
            "rating": 1276.9530104305666,
            "rating_q975": 1294.9691638944646,
            "rating_q025": 1258.9368569666685
        },
        "gpt-4o-2024-05-13": {
            "rating": 1276.3117308410701,
            "rating_q975": 1281.0962305888431,
            "rating_q025": 1271.5272310932971
        },
        "olmo-3-32b-think": {
            "rating": 1275.8366386086986,
            "rating_q975": 1296.9890629225956,
            "rating_q025": 1254.6842142948017
        },
        "hunyuan-large-2025-02-10": {
            "rating": 1275.1995256285218,
            "rating_q975": 1290.6981568695212,
            "rating_q025": 1259.7008943875223
        },
        "qwen2.5-plus-1127": {
            "rating": 1273.1140091843981,
            "rating_q975": 1282.0079073959319,
            "rating_q025": 1264.2201109728644
        },
        "athene-v2-chat": {
            "rating": 1269.25171900106,
            "rating_q975": 1275.3848039773336,
            "rating_q025": 1263.1186340247866
        },
        "grok-2-2024-08-13": {
            "rating": 1268.6483106594176,
            "rating_q975": 1273.4118607017965,
            "rating_q025": 1263.8847606170386
        },
        "claude-3-5-sonnet-20240620": {
            "rating": 1268.1955251808017,
            "rating_q975": 1273.0969089258492,
            "rating_q025": 1263.2941414357542
        },
        "llama-4-maverick-17b-128e-instruct": {
            "rating": 1267.3699549255994,
            "rating_q975": 1273.7827334232047,
            "rating_q025": 1260.957176427994
        },
        "gpt-4o-2024-08-06": {
            "rating": 1265.532967540813,
            "rating_q975": 1271.1388578036976,
            "rating_q025": 1259.9270772779282
        },
        "gpt-4.1-nano-2025-04-14": {
            "rating": 1265.2681578333459,
            "rating_q975": 1277.6469679773927,
            "rating_q025": 1252.889347689299
        },
        "mistral-small-3.1-24b-instruct-2503": {
            "rating": 1263.9588324702784,
            "rating_q975": 1271.0466929402887,
            "rating_q025": 1256.870972000268
        },
        "glm-4-plus": {
            "rating": 1262.7136002140132,
            "rating_q975": 1269.4344117775634,
            "rating_q025": 1255.9927886504631
        },
        "qwen-max-0919": {
            "rating": 1260.7281328192462,
            "rating_q975": 1268.5324066800674,
            "rating_q025": 1252.923858958425
        },
        "llama-3.1-405b-instruct-bf16": {
            "rating": 1257.7881220191043,
            "rating_q975": 1262.7842048099449,
            "rating_q025": 1252.7920392282638
        },
        "magistral-medium-2506": {
            "rating": 1257.490495005385,
            "rating_q975": 1268.2874377046603,
            "rating_q025": 1246.6935523061095
        },
        "llama-3.1-405b-instruct-fp8": {
            "rating": 1257.3360306040877,
            "rating_q975": 1262.382023866244,
            "rating_q025": 1252.2900373419313
        },
        "gpt-4o-mini-2024-07-18": {
            "rating": 1256.9575810244867,
            "rating_q975": 1261.5079015232354,
            "rating_q025": 1252.407260525738
        },
        "gemini-1.5-flash-002": {
            "rating": 1256.4654060950243,
            "rating_q975": 1262.1274080581363,
            "rating_q025": 1250.8034041319122
        },
        "gemma-3n-e4b-it": {
            "rating": 1255.352469015816,
            "rating_q975": 1263.7791768687616,
            "rating_q025": 1246.9257611628705
        },
        "qwen2.5-72b-instruct": {
            "rating": 1252.7758602247663,
            "rating_q975": 1258.2081373236551,
            "rating_q025": 1247.3435831258776
        },
        "gemini-advanced-0514": {
            "rating": 1252.2379017354124,
            "rating_q975": 1258.8365069648269,
            "rating_q025": 1245.639296505998
        },
        "gemini-1.5-pro-001": {
            "rating": 1252.1692913651332,
            "rating_q975": 1257.7839874176855,
            "rating_q025": 1246.554595312581
        },
        "hunyuan-large-vision": {
            "rating": 1251.422472294687,
            "rating_q975": 1268.1808377349446,
            "rating_q025": 1234.6641068544293
        },
        "llama-3.1-nemotron-70b-instruct": {
            "rating": 1250.7936449901442,
            "rating_q975": 1261.5181706068759,
            "rating_q025": 1240.0691193734126
        },
        "llama-4-scout-17b-16e-instruct": {
            "rating": 1249.2305747421883,
            "rating_q975": 1256.510910681698,
            "rating_q025": 1241.9502388026785
        },
        "gpt-4-turbo-2024-04-09": {
            "rating": 1248.2291238288612,
            "rating_q975": 1253.5586505683796,
            "rating_q025": 1242.899597089343
        },
        "deepseek-v2.5": {
            "rating": 1248.184484145422,
            "rating_q975": 1254.7014837747392,
            "rating_q025": 1241.6674845161047
        },
        "mistral-large-2411": {
            "rating": 1247.4217842679263,
            "rating_q975": 1253.2565648825375,
            "rating_q025": 1241.5870036533152
        },
        "claude-3-opus-20240229": {
            "rating": 1246.7209321829505,
            "rating_q975": 1250.9641701484954,
            "rating_q025": 1242.4776942174055
        },
        "mistral-large-2407": {
            "rating": 1246.6170288128787,
            "rating_q975": 1252.075122858938,
            "rating_q025": 1241.1589347668196
        },
        "hunyuan-standard-2025-02-10": {
            "rating": 1243.9357254381753,
            "rating_q975": 1259.079831614568,
            "rating_q025": 1228.7916192617824
        },
        "grok-2-mini-2024-08-13": {
            "rating": 1243.5373008077636,
            "rating_q975": 1248.5898097268564,
            "rating_q025": 1238.4847918886708
        },
        "mercury": {
            "rating": 1242.0762839159108,
            "rating_q975": 1267.407078429917,
            "rating_q025": 1216.7454894019047
        },
        "llama-3.3-70b-instruct": {
            "rating": 1240.9237115583562,
            "rating_q975": 1245.7043880711285,
            "rating_q025": 1236.143035045584
        },
        "gpt-4-1106-preview": {
            "rating": 1238.9949131193403,
            "rating_q975": 1244.4578406759933,
            "rating_q025": 1233.5319855626872
        },
        "claude-3-5-haiku-20241022": {
            "rating": 1238.39520979881,
            "rating_q975": 1242.8555299995694,
            "rating_q025": 1233.9348895980504
        },
        "gemma-3-4b-it": {
            "rating": 1237.7735143352415,
            "rating_q975": 1254.005646050999,
            "rating_q025": 1221.541382619484
        },
        "gpt-oss-20b": {
            "rating": 1237.1011813131813,
            "rating_q975": 1249.3213404807402,
            "rating_q025": 1224.8810221456224
        },
        "amazon-nova-pro-v1.0": {
            "rating": 1233.7336365915714,
            "rating_q975": 1239.8138414893942,
            "rating_q025": 1227.6534316937486
        },
        "gpt-4-0125-preview": {
            "rating": 1233.564755103379,
            "rating_q975": 1239.1663015009296,
            "rating_q025": 1227.9632087058283
        },
        "llama-3.1-tulu-3-70b": {
            "rating": 1231.631715403498,
            "rating_q975": 1247.0318524008583,
            "rating_q025": 1216.2315784061377
        },
        "llama-3.1-70b-instruct": {
            "rating": 1230.3275224421104,
            "rating_q975": 1235.4014753552826,
            "rating_q025": 1225.2535695289382
        },
        "athene-70b-0725": {
            "rating": 1224.9378172885617,
            "rating_q975": 1232.510086937239,
            "rating_q025": 1217.3655476398844
        },
        "qwen2.5-coder-32b-instruct": {
            "rating": 1220.7656066637298,
            "rating_q975": 1232.4986205980467,
            "rating_q025": 1209.032592729413
        },
        "mistral-small-24b-instruct-2501": {
            "rating": 1212.2802648765726,
            "rating_q975": 1220.2877474688155,
            "rating_q025": 1204.2727822843297
        },
        "jamba-1.5-large": {
            "rating": 1211.542263723465,
            "rating_q975": 1222.1439686799733,
            "rating_q025": 1200.9405587669569
        },
        "gemini-1.5-flash-001": {
            "rating": 1210.5746341194154,
            "rating_q975": 1216.3711477129445,
            "rating_q025": 1204.7781205258862
        },
        "reka-core-20240904": {
            "rating": 1210.3748666151932,
            "rating_q975": 1220.3127014623703,
            "rating_q025": 1200.4370317680161
        },
        "gemma-2-27b-it": {
            "rating": 1204.872447372548,
            "rating_q975": 1209.3641744689623,
            "rating_q025": 1200.3807202761338
        },
        "amazon-nova-lite-v1.0": {
            "rating": 1203.963707063571,
            "rating_q975": 1210.8149512310338,
            "rating_q025": 1197.1124628961084
        },
        "nemotron-4-340b-instruct": {
            "rating": 1201.9707016685243,
            "rating_q975": 1209.9894552651758,
            "rating_q025": 1193.9519480718727
        },
        "glm-4-0520": {
            "rating": 1201.1953388636302,
            "rating_q975": 1211.3408032372924,
            "rating_q025": 1191.049874489968
        },
        "phi-4": {
            "rating": 1199.8379943764849,
            "rating_q975": 1206.260861602667,
            "rating_q025": 1193.4151271503026
        },
        "hunyuan-standard-256k": {
            "rating": 1199.766946387757,
            "rating_q975": 1216.5342148423144,
            "rating_q025": 1182.9996779331993
        },
        "gpt-4-0314": {
            "rating": 1199.1909967254642,
            "rating_q975": 1206.3507118505167,
            "rating_q025": 1192.0312816004116
        },
        "llama-3.1-nemotron-51b-instruct": {
            "rating": 1198.7678113446293,
            "rating_q975": 1213.2734522278804,
            "rating_q025": 1184.2621704613782
        },
        "claude-3-sonnet-20240229": {
            "rating": 1197.9190580038817,
            "rating_q975": 1203.4205636587278,
            "rating_q025": 1192.4175523490355
        },
        "gemini-1.5-flash-8b-001": {
            "rating": 1197.726319138405,
            "rating_q975": 1203.4467562327725,
            "rating_q025": 1192.0058820440374
        },
        "command-r-plus-08-2024": {
            "rating": 1195.2291493534917,
            "rating_q975": 1204.4058416640512,
            "rating_q025": 1186.0524570429322
        },
        "c4ai-aya-expanse-32b": {
            "rating": 1195.0550515707369,
            "rating_q975": 1201.5364769864866,
            "rating_q025": 1188.573626154987
        },
        "llama-3-70b-instruct": {
            "rating": 1193.2902138154009,
            "rating_q975": 1198.4500414577592,
            "rating_q025": 1188.1303861730426
        },
        "gemma-2-9b-it-simpo": {
            "rating": 1189.9352881684822,
            "rating_q975": 1199.8424449830493,
            "rating_q025": 1180.0281313539151
        },
        "gpt-4-0613": {
            "rating": 1187.1490412155467,
            "rating_q975": 1193.0440794202493,
            "rating_q025": 1181.2540030108441
        },
        "olmo-2-0325-32b-instruct": {
            "rating": 1186.2306847402888,
            "rating_q975": 1203.4329828275274,
            "rating_q025": 1169.0283866530501
        },
        "reka-flash-20240904": {
            "rating": 1184.0893755389693,
            "rating_q975": 1193.9894860680065,
            "rating_q025": 1174.1892650099321
        },
        "qwen2-72b-instruct": {
            "rating": 1179.844288785198,
            "rating_q975": 1186.4875980834547,
            "rating_q025": 1173.2009794869412
        },
        "deepseek-coder-v2": {
            "rating": 1178.7605478769262,
            "rating_q975": 1187.7700091485365,
            "rating_q025": 1169.751086605316
        },
        "command-r-plus": {
            "rating": 1178.5697039872023,
            "rating_q975": 1184.5106704368488,
            "rating_q025": 1172.6287375375557
        },
        "gemma-2-9b-it": {
            "rating": 1177.2715040023968,
            "rating_q975": 1182.2940056708476,
            "rating_q025": 1172.249002333946
        },
        "amazon-nova-micro-v1.0": {
            "rating": 1174.180051176269,
            "rating_q975": 1181.033553405049,
            "rating_q025": 1167.326548947489
        },
        "llama-3.1-tulu-3-8b": {
            "rating": 1173.781038308876,
            "rating_q975": 1189.1808841646578,
            "rating_q025": 1158.3811924530944
        },
        "claude-3-haiku-20240307": {
            "rating": 1172.3421924827055,
            "rating_q975": 1177.460641728355,
            "rating_q025": 1167.223743237056
        },
        "mistral-large-2402": {
            "rating": 1168.0670903296805,
            "rating_q975": 1174.556565315446,
            "rating_q025": 1161.5776153439149
        },
        "command-r-08-2024": {
            "rating": 1166.2482165663814,
            "rating_q975": 1175.2763002518398,
            "rating_q025": 1157.220132880923
        },
        "ministral-8b-2410": {
            "rating": 1159.8470889443497,
            "rating_q975": 1172.4594225535814,
            "rating_q025": 1147.234755335118
        },
        "llama-3.1-8b-instruct": {
            "rating": 1158.495704948159,
            "rating_q975": 1163.8109373590669,
            "rating_q025": 1153.1804725372513
        },
        "qwen1.5-110b-chat": {
            "rating": 1156.6239613676717,
            "rating_q975": 1164.5998284153957,
            "rating_q025": 1148.6480943199476
        },
        "qwq-32b-preview": {
            "rating": 1156.4895170972652,
            "rating_q975": 1172.4012539906469,
            "rating_q025": 1140.5777802038835
        },
        "c4ai-aya-expanse-8b": {
            "rating": 1154.0991324257966,
            "rating_q975": 1163.5049621476958,
            "rating_q025": 1144.6933027038974
        },
        "mistral-medium": {
            "rating": 1150.6758621195322,
            "rating_q975": 1158.725313584264,
            "rating_q025": 1142.6264106548003
        },
        "jamba-1.5-mini": {
            "rating": 1147.1530001743201,
            "rating_q975": 1157.613075776771,
            "rating_q025": 1136.6929245718693
        },
        "mixtral-8x22b-instruct-v0.1": {
            "rating": 1145.830347163279,
            "rating_q975": 1152.1834660633658,
            "rating_q025": 1139.477228263192
        },
        "qwen1.5-72b-chat": {
            "rating": 1140.3287800941193,
            "rating_q975": 1147.5854950681698,
            "rating_q025": 1133.0720651200688
        },
        "yi-1.5-34b-chat": {
            "rating": 1137.786290216045,
            "rating_q975": 1145.3658126042717,
            "rating_q025": 1130.2067678278183
        },
        "internlm2_5-20b-chat": {
            "rating": 1135.0006007365773,
            "rating_q975": 1144.8796150776836,
            "rating_q025": 1125.121586395471
        },
        "granite-3.1-8b-instruct": {
            "rating": 1131.971880120645,
            "rating_q975": 1148.1598713620638,
            "rating_q025": 1115.7838888792262
        },
        "reka-flash-21b-20240226-online": {
            "rating": 1128.381551681941,
            "rating_q975": 1138.5214532106859,
            "rating_q025": 1118.241650153196
        },
        "llama-3-8b-instruct": {
            "rating": 1126.1589173093935,
            "rating_q975": 1131.6812817587404,
            "rating_q025": 1120.6365528600465
        },
        "command-r": {
            "rating": 1123.8734308023593,
            "rating_q975": 1130.5145465240423,
            "rating_q025": 1117.2323150806762
        },
        "reka-flash-21b-20240226": {
            "rating": 1120.1861580837915,
            "rating_q975": 1128.5237274682231,
            "rating_q025": 1111.8485886993599
        },
        "gpt-3.5-turbo-0125": {
            "rating": 1117.504590576525,
            "rating_q975": 1123.7592170007795,
            "rating_q025": 1111.2499641522706
        },
        "gemma-2-2b-it": {
            "rating": 1116.7046779219736,
            "rating_q975": 1122.0391949295256,
            "rating_q025": 1111.3701609144216
        },
        "zephyr-orpo-141b-A35b-v0.1": {
            "rating": 1116.4320293115125,
            "rating_q975": 1131.9111097240054,
            "rating_q025": 1100.9529488990195
        },
        "granite-3.1-2b-instruct": {
            "rating": 1115.0757052508507,
            "rating_q975": 1131.1937705007,
            "rating_q025": 1098.9576400010012
        },
        "qwen1.5-32b-chat": {
            "rating": 1114.9824096504612,
            "rating_q975": 1123.4474813083393,
            "rating_q025": 1106.5173379925832
        },
        "gemini-pro-dev-api": {
            "rating": 1113.0256264254926,
            "rating_q975": 1123.5045189679768,
            "rating_q025": 1102.5467338830085
        },
        "phi-3-medium-4k-instruct": {
            "rating": 1112.5682009764737,
            "rating_q975": 1119.7851510104254,
            "rating_q025": 1105.351250942522
        },
        "dbrx-instruct-preview": {
            "rating": 1110.5368227694307,
            "rating_q975": 1118.9113317911854,
            "rating_q025": 1102.162313747676
        },
        "gemini-pro": {
            "rating": 1109.4165212407402,
            "rating_q975": 1125.9336710630132,
            "rating_q025": 1092.8993714184671
        },
        "tulu-2-dpo-70b": {
            "rating": 1109.119196606779,
            "rating_q975": 1123.7945482722328,
            "rating_q025": 1094.4438449413253
        },
        "mixtral-8x7b-instruct-v0.1": {
            "rating": 1107.9542156541288,
            "rating_q975": 1114.127282361096,
            "rating_q025": 1101.7811489471617
        },
        "qwen1.5-14b-chat": {
            "rating": 1100.7302185651506,
            "rating_q975": 1110.60025001168,
            "rating_q025": 1090.8601871186213
        },
        "starling-lm-7b-beta": {
            "rating": 1095.431650377331,
            "rating_q975": 1105.376306162589,
            "rating_q025": 1085.486994592073
        },
        "wizardlm-70b": {
            "rating": 1091.9479389331286,
            "rating_q975": 1105.3345373165093,
            "rating_q025": 1078.561340549748
        },
        "gpt-3.5-turbo-1106": {
            "rating": 1090.8400411078894,
            "rating_q975": 1103.0593646224888,
            "rating_q025": 1078.62071759329
        },
        "yi-34b-chat": {
            "rating": 1089.799074885229,
            "rating_q975": 1099.456844690857,
            "rating_q025": 1080.141305079601
        },
        "llama-3.2-3b-instruct": {
            "rating": 1088.2489636856455,
            "rating_q975": 1098.9020653228774,
            "rating_q025": 1077.5958620484137
        },
        "granite-3.0-8b-instruct": {
            "rating": 1087.3151589911663,
            "rating_q975": 1099.3851110086832,
            "rating_q025": 1075.2452069736494
        },
        "phi-3-small-8k-instruct": {
            "rating": 1085.4427823272167,
            "rating_q975": 1093.9922656321128,
            "rating_q025": 1076.8932990223207
        },
        "deepseek-llm-67b-chat": {
            "rating": 1077.6068909975343,
            "rating_q975": 1094.6305702103728,
            "rating_q025": 1060.5832117846958
        },
        "openchat-3.5-0106": {
            "rating": 1075.1388318096301,
            "rating_q975": 1085.5533452396235,
            "rating_q025": 1064.7243183796368
        },
        "llama-2-70b-chat": {
            "rating": 1070.3480520323035,
            "rating_q975": 1077.947727105877,
            "rating_q025": 1062.74837695873
        },
        "starling-lm-7b-alpha": {
            "rating": 1069.2538037472486,
            "rating_q975": 1080.5788730147085,
            "rating_q025": 1057.9287344797888
        },
        "openhermes-2.5-mistral-7b": {
            "rating": 1069.1988327661802,
            "rating_q975": 1084.570218740723,
            "rating_q025": 1053.8274467916374
        },
        "openchat-3.5": {
            "rating": 1068.6725455102405,
            "rating_q975": 1082.7810610629417,
            "rating_q025": 1054.5640299575393
        },
        "snowflake-arctic-instruct": {
            "rating": 1065.5036818913525,
            "rating_q975": 1073.8956376403387,
            "rating_q025": 1057.1117261423663
        },
        "vicuna-33b": {
            "rating": 1063.452660291192,
            "rating_q975": 1072.3671976843511,
            "rating_q025": 1054.5381228980327
        },
        "llama2-70b-steerlm-chat": {
            "rating": 1060.2183271360366,
            "rating_q975": 1078.4093558256059,
            "rating_q025": 1042.0272984464673
        },
        "mistral-7b-instruct-v0.2": {
            "rating": 1058.8040618742516,
            "rating_q975": 1067.7106510259737,
            "rating_q025": 1049.8974727225295
        },
        "qwen1.5-7b-chat": {
            "rating": 1056.7732648297067,
            "rating_q975": 1070.7142459142417,
            "rating_q025": 1042.8322837451717
        },
        "phi-3-mini-4k-instruct-june-2024": {
            "rating": 1056.4775404578775,
            "rating_q975": 1066.0073611529817,
            "rating_q025": 1046.9477197627732
        },
        "gemma-1.1-7b-it": {
            "rating": 1056.3010779014978,
            "rating_q975": 1064.1520247893231,
            "rating_q025": 1048.4501310136725
        },
        "nous-hermes-2-mixtral-8x7b-dpo": {
            "rating": 1055.381161247199,
            "rating_q975": 1071.652951762233,
            "rating_q025": 1039.1093707321652
        },
        "granite-3.0-2b-instruct": {
            "rating": 1054.922705501575,
            "rating_q975": 1067.1104032999026,
            "rating_q025": 1042.7350077032472
        },
        "mpt-30b-chat": {
            "rating": 1052.6569741970834,
            "rating_q975": 1074.1588524205656,
            "rating_q025": 1031.1550959736012
        },
        "dolphin-2.2.1-mistral-7b": {
            "rating": 1051.3602407928636,
            "rating_q975": 1076.2559041358013,
            "rating_q025": 1026.4645774499259
        },
        "phi-3-mini-4k-instruct": {
            "rating": 1051.0046906018667,
            "rating_q975": 1059.6795024637975,
            "rating_q025": 1042.329878739936
        },
        "wizardlm-13b": {
            "rating": 1047.0510882364572,
            "rating_q975": 1061.0301600462578,
            "rating_q025": 1033.0720164266565
        },
        "solar-10.7b-instruct-v1.0": {
            "rating": 1046.4489383661212,
            "rating_q975": 1064.8587897867865,
            "rating_q025": 1028.039086945456
        },
        "falcon-180b-chat": {
            "rating": 1045.5630374610105,
            "rating_q975": 1074.4273142572845,
            "rating_q025": 1016.6987606647366
        },
        "llama-2-13b-chat": {
            "rating": 1044.2029347259777,
            "rating_q975": 1053.466333866052,
            "rating_q025": 1034.9395355859033
        },
        "vicuna-13b": {
            "rating": 1034.1353971225717,
            "rating_q975": 1043.6567855430771,
            "rating_q025": 1024.6140087020663
        },
        "zephyr-7b-alpha": {
            "rating": 1033.814043148104,
            "rating_q975": 1058.8019326354515,
            "rating_q025": 1008.8261536607566
        },
        "smollm2-1.7b-instruct": {
            "rating": 1031.6059001545482,
            "rating_q975": 1052.691763382182,
            "rating_q025": 1010.5200369269145
        },
        "llama-3.2-1b-instruct": {
            "rating": 1031.0402681029539,
            "rating_q975": 1042.0478985015845,
            "rating_q025": 1020.0326377043232
        },
        "zephyr-7b-beta": {
            "rating": 1030.175244974054,
            "rating_q975": 1042.9381745019484,
            "rating_q025": 1017.4123154461596
        },
        "qwen-14b-chat": {
            "rating": 1029.7703195540164,
            "rating_q975": 1046.3226273910807,
            "rating_q025": 1013.218011716952
        },
        "codellama-34b-instruct": {
            "rating": 1027.0174555149317,
            "rating_q975": 1039.88727906864,
            "rating_q025": 1014.1476319612235
        },
        "phi-3-mini-128k-instruct": {
            "rating": 1022.5386175932188,
            "rating_q975": 1032.624620472939,
            "rating_q025": 1012.4526147134986
        },
        "codellama-70b-instruct": {
            "rating": 1022.1422328276049,
            "rating_q975": 1052.7624504717528,
            "rating_q025": 991.5220151834569
        },
        "gemma-7b-it": {
            "rating": 1015.7804498848159,
            "rating_q975": 1028.594800065042,
            "rating_q025": 1002.9660997045899
        },
        "stripedhyena-nous-7b": {
            "rating": 1009.0774493083653,
            "rating_q975": 1024.384110755279,
            "rating_q025": 993.7707878614518
        },
        "palm-2": {
            "rating": 1008.7784215130364,
            "rating_q975": 1022.259675939422,
            "rating_q025": 995.2971670866508
        },
        "llama-2-7b-chat": {
            "rating": 1004.5139684634999,
            "rating_q975": 1014.3136541342209,
            "rating_q025": 994.7142827927788
        },
        "mistral-7b-instruct": {
            "rating": 1002.7584179939456,
            "rating_q975": 1016.3625768917417,
            "rating_q025": 989.1542590961495
        },
        "vicuna-7b": {
            "rating": 993.769420120899,
            "rating_q975": 1007.8746028119523,
            "rating_q025": 979.6642374298457
        },
        "gemma-1.1-2b-it": {
            "rating": 990.7660533411183,
            "rating_q975": 1001.6233878318262,
            "rating_q025": 979.9087188504104
        },
        "guanaco-33b": {
            "rating": 990.4247426636148,
            "rating_q975": 1011.5168546597293,
            "rating_q025": 969.3326306675002
        },
        "olmo-7b-instruct": {
            "rating": 978.7476266238978,
            "rating_q975": 994.5750502655978,
            "rating_q025": 962.9202029821977
        },
        "qwen1.5-4b-chat": {
            "rating": 977.3255916619826,
            "rating_q975": 990.2243332834776,
            "rating_q025": 964.4268500404876
        },
        "gemma-2b-it": {
            "rating": 969.7136486174529,
            "rating_q975": 985.9096835165631,
            "rating_q025": 953.5176137183428
        },
        "chatglm3-6b": {
            "rating": 954.0258605456133,
            "rating_q975": 971.8294783776432,
            "rating_q025": 936.2222427135835
        },
        "gpt4all-13b-snoozy": {
            "rating": 946.1220209904915,
            "rating_q975": 971.2453364022942,
            "rating_q025": 920.9987055786887
        },
        "koala-13b": {
            "rating": 943.5225682124021,
            "rating_q975": 958.9059485380249,
            "rating_q025": 928.1391878867794
        },
        "mpt-7b-chat": {
            "rating": 908.2381813194768,
            "rating_q975": 926.6695360597564,
            "rating_q025": 889.8068265791971
        },
        "chatglm-6b": {
            "rating": 901.8409709792339,
            "rating_q975": 919.7074898781024,
            "rating_q025": 883.9744520803655
        },
        "chatglm2-6b": {
            "rating": 900.9882903756422,
            "rating_q975": 923.7791717192079,
            "rating_q025": 878.1974090320766
        },
        "alpaca-13b": {
            "rating": 891.4361420368414,
            "rating_q975": 907.969679459581,
            "rating_q025": 874.9026046141017
        },
        "oasst-pythia-12b": {
            "rating": 886.5293274346641,
            "rating_q975": 902.5122562856311,
            "rating_q025": 870.546398583697
        },
        "RWKV-4-Raven-14B": {
            "rating": 882.0793857235658,
            "rating_q975": 898.9828568350799,
            "rating_q025": 865.1759146120517
        },
        "fastchat-t5-3b": {
            "rating": 857.0664303752847,
            "rating_q975": 875.783834345228,
            "rating_q025": 838.3490264053413
        },
        "stablelm-tuned-alpha-7b": {
            "rating": 831.3969843284665,
            "rating_q975": 851.9471613434482,
            "rating_q025": 810.8468073134848
        },
        "dolly-v2-12b": {
            "rating": 814.185903959691,
            "rating_q975": 835.4655809547751,
            "rating_q025": 792.906226964607
        },
        "llama-13b": {
            "rating": 779.9420647348118,
            "rating_q975": 805.0232083769962,
            "rating_q025": 754.8609210926273
        }
    },
    "industry_business_and_management_and_financial_operations": {
        "gemini-3-pro": {
            "rating": 1464.5287112676185,
            "rating_q975": 1476.3089438159952,
            "rating_q025": 1452.7484787192418
        },
        "claude-opus-4-5-20251101": {
            "rating": 1446.0562270647395,
            "rating_q975": 1459.6301311314407,
            "rating_q025": 1432.4823229980382
        },
        "gemini-2.5-pro": {
            "rating": 1445.5446267657653,
            "rating_q975": 1451.9883801758235,
            "rating_q025": 1439.100873355707
        },
        "qwen3-max-preview": {
            "rating": 1436.139756848159,
            "rating_q975": 1444.9634463785,
            "rating_q025": 1427.3160673178181
        },
        "grok-4.1-thinking": {
            "rating": 1433.5701477870348,
            "rating_q975": 1444.880830886832,
            "rating_q025": 1422.2594646872376
        },
        "grok-4.1": {
            "rating": 1433.1596288582007,
            "rating_q975": 1444.5333300102732,
            "rating_q025": 1421.7859277061282
        },
        "qwen3-vl-235b-a22b-instruct": {
            "rating": 1432.7038531857997,
            "rating_q975": 1447.284254996312,
            "rating_q025": 1418.1234513752875
        },
        "gpt-5.1-high": {
            "rating": 1430.881716304997,
            "rating_q975": 1443.2669108235746,
            "rating_q025": 1418.4965217864196
        },
        "ernie-5.0-preview-1103": {
            "rating": 1430.3586272347598,
            "rating_q975": 1448.1290407637543,
            "rating_q025": 1412.5882137057652
        },
        "mistral-medium-2508": {
            "rating": 1430.1806762019305,
            "rating_q975": 1437.6552563251805,
            "rating_q025": 1422.7060960786805
        },
        "longcat-flash-chat": {
            "rating": 1428.1111412217895,
            "rating_q975": 1441.0375442139996,
            "rating_q025": 1415.1847382295794
        },
        "mistral-large-3": {
            "rating": 1426.1227182295556,
            "rating_q975": 1442.8202556306899,
            "rating_q025": 1409.4251808284214
        },
        "claude-sonnet-4-5-20250929": {
            "rating": 1424.9523387870545,
            "rating_q975": 1434.5346141562832,
            "rating_q025": 1415.3700634178258
        },
        "chatgpt-4o-latest-20250326": {
            "rating": 1424.1835865500934,
            "rating_q975": 1430.9483710907161,
            "rating_q025": 1417.4188020094707
        },
        "qwen3-next-80b-a3b-instruct": {
            "rating": 1422.5928490713131,
            "rating_q975": 1432.1512084289807,
            "rating_q025": 1413.0344897136456
        },
        "claude-opus-4-5-20251101-thinking-32k": {
            "rating": 1422.461802908835,
            "rating_q975": 1436.5969889284263,
            "rating_q025": 1408.3266168892435
        },
        "glm-4.5": {
            "rating": 1421.4166987980245,
            "rating_q975": 1430.9054289748449,
            "rating_q025": 1411.9279686212042
        },
        "qwen3-235b-a22b-instruct-2507": {
            "rating": 1419.1208455358633,
            "rating_q975": 1426.1698351248797,
            "rating_q025": 1412.0718559468469
        },
        "gpt-5.1": {
            "rating": 1419.005990333014,
            "rating_q975": 1430.7295217202818,
            "rating_q025": 1407.2824589457464
        },
        "glm-4.6": {
            "rating": 1413.3698887385228,
            "rating_q975": 1422.677877664888,
            "rating_q025": 1404.0618998121577
        },
        "deepseek-v3.1-terminus-thinking": {
            "rating": 1412.924116654333,
            "rating_q975": 1435.3056427537265,
            "rating_q025": 1390.5425905549394
        },
        "qwen3-235b-a22b-thinking-2507": {
            "rating": 1412.9044501604117,
            "rating_q975": 1427.8680479783015,
            "rating_q025": 1397.9408523425218
        },
        "hunyuan-vision-1.5-thinking": {
            "rating": 1411.4192579921455,
            "rating_q975": 1438.7653714792618,
            "rating_q025": 1384.0731445050292
        },
        "claude-sonnet-4-5-20250929-thinking-32k": {
            "rating": 1411.382898249819,
            "rating_q975": 1420.337579551022,
            "rating_q025": 1402.428216948616
        },
        "deepseek-v3.1-thinking": {
            "rating": 1407.6391720624054,
            "rating_q975": 1421.2041797483585,
            "rating_q025": 1394.0741643764522
        },
        "deepseek-v3.1": {
            "rating": 1407.4849573346974,
            "rating_q975": 1419.5463215605023,
            "rating_q025": 1395.4235931088924
        },
        "grok-3-preview-02-24": {
            "rating": 1406.2164496268776,
            "rating_q975": 1415.8364712282578,
            "rating_q025": 1396.5964280254975
        },
        "deepseek-v3.2-exp": {
            "rating": 1405.0061427798937,
            "rating_q975": 1417.8321410118565,
            "rating_q025": 1392.180144547931
        },
        "claude-opus-4-1-20250805-thinking-16k": {
            "rating": 1404.8921253936626,
            "rating_q975": 1412.3207430906416,
            "rating_q025": 1397.4635076966836
        },
        "deepseek-v3.2": {
            "rating": 1404.7566696487384,
            "rating_q975": 1421.285973215881,
            "rating_q025": 1388.2273660815956
        },
        "amazon-nova-experimental-chat-10-20": {
            "rating": 1403.5595410422393,
            "rating_q975": 1418.6375420784843,
            "rating_q025": 1388.4815400059942
        },
        "gemini-2.5-flash": {
            "rating": 1400.0973808811873,
            "rating_q975": 1406.4465991292693,
            "rating_q025": 1393.7481626331053
        },
        "claude-opus-4-1-20250805": {
            "rating": 1399.4061497209752,
            "rating_q975": 1406.4230536985408,
            "rating_q025": 1392.3892457434097
        },
        "deepseek-v3.2-thinking": {
            "rating": 1399.3878239165826,
            "rating_q975": 1416.5432386667546,
            "rating_q025": 1382.2324091664107
        },
        "deepseek-r1-0528": {
            "rating": 1398.593775743694,
            "rating_q975": 1409.846926251409,
            "rating_q025": 1387.3406252359791
        },
        "gpt-5-chat": {
            "rating": 1398.4618266331959,
            "rating_q975": 1406.9511897078942,
            "rating_q025": 1389.9724635584976
        },
        "gemini-2.5-flash-preview-09-2025": {
            "rating": 1396.7092684771667,
            "rating_q975": 1405.3448566760687,
            "rating_q025": 1388.0736802782646
        },
        "qwen3-max-2025-09-23": {
            "rating": 1395.358197473643,
            "rating_q975": 1409.2452089027763,
            "rating_q025": 1381.4711860445097
        },
        "deepseek-v3.2-exp-thinking": {
            "rating": 1393.712572710776,
            "rating_q975": 1407.6646485785577,
            "rating_q025": 1379.7604968429941
        },
        "kimi-k2-thinking-turbo": {
            "rating": 1392.9064235554067,
            "rating_q975": 1404.1324108396984,
            "rating_q025": 1381.680436271115
        },
        "o3-2025-04-16": {
            "rating": 1392.1203496513076,
            "rating_q975": 1399.138987944757,
            "rating_q025": 1385.1017113578582
        },
        "qwen3-235b-a22b-no-thinking": {
            "rating": 1390.2432840146835,
            "rating_q975": 1398.4155294261088,
            "rating_q025": 1382.071038603258
        },
        "qwen3-30b-a3b-instruct-2507": {
            "rating": 1390.0677755630409,
            "rating_q975": 1399.5946639047554,
            "rating_q025": 1380.5408872213263
        },
        "grok-4-fast-reasoning": {
            "rating": 1389.4885851217614,
            "rating_q975": 1399.6366746375948,
            "rating_q025": 1379.340495605928
        },
        "qwen3-vl-235b-a22b-thinking": {
            "rating": 1389.3953138510149,
            "rating_q975": 1404.102983687316,
            "rating_q025": 1374.6876440147137
        },
        "grok-4-1-fast-reasoning": {
            "rating": 1387.6195359686221,
            "rating_q975": 1402.103650914093,
            "rating_q025": 1373.1354210231514
        },
        "deepseek-v3.1-terminus": {
            "rating": 1387.33813278657,
            "rating_q975": 1409.0014314373764,
            "rating_q025": 1365.6748341357636
        },
        "grok-4-0709": {
            "rating": 1386.7258897245022,
            "rating_q975": 1394.2727281162147,
            "rating_q025": 1379.1790513327896
        },
        "gpt-4.5-preview-2025-02-27": {
            "rating": 1384.467524346893,
            "rating_q975": 1400.1208617682776,
            "rating_q025": 1368.8141869255085
        },
        "grok-4-fast-chat": {
            "rating": 1383.881338349521,
            "rating_q975": 1400.8508859182054,
            "rating_q025": 1366.9117907808366
        },
        "hunyuan-turbos-20250416": {
            "rating": 1383.6188897495247,
            "rating_q975": 1399.458409615531,
            "rating_q025": 1367.7793698835183
        },
        "claude-haiku-4-5-20251001": {
            "rating": 1382.5392580327104,
            "rating_q975": 1391.6868950722223,
            "rating_q025": 1373.3916209931986
        },
        "gpt-5-high": {
            "rating": 1379.079822895409,
            "rating_q975": 1387.7092481475331,
            "rating_q025": 1370.450397643285
        },
        "gemma-3-12b-it": {
            "rating": 1374.6083721351583,
            "rating_q975": 1404.958657526182,
            "rating_q025": 1344.2580867441347
        },
        "hunyuan-t1-20250711": {
            "rating": 1372.8436614340108,
            "rating_q975": 1394.2463606396614,
            "rating_q025": 1351.4409622283601
        },
        "mai-1-preview": {
            "rating": 1370.888822633551,
            "rating_q975": 1381.2645050096744,
            "rating_q025": 1360.5131402574275
        },
        "glm-4.5-air": {
            "rating": 1369.8165070903985,
            "rating_q975": 1378.2116828419878,
            "rating_q025": 1361.4213313388093
        },
        "gpt-4.1-2025-04-14": {
            "rating": 1367.86027979751,
            "rating_q975": 1375.10567971102,
            "rating_q025": 1360.614879884
        },
        "gemini-2.5-flash-lite-preview-09-2025-no-thinking": {
            "rating": 1367.5286071958378,
            "rating_q975": 1376.0927305317155,
            "rating_q025": 1358.9644838599602
        },
        "nova-2-lite": {
            "rating": 1364.7112006255115,
            "rating_q975": 1382.1432803268217,
            "rating_q025": 1347.2791209242014
        },
        "qwen3-next-80b-a3b-thinking": {
            "rating": 1362.2248885383112,
            "rating_q975": 1374.2228695743693,
            "rating_q025": 1350.2269075022532
        },
        "gemma-3-27b-it": {
            "rating": 1360.0211510952236,
            "rating_q975": 1367.685241238895,
            "rating_q025": 1352.357060951552
        },
        "gpt-5-mini-high": {
            "rating": 1358.5996690589654,
            "rating_q975": 1367.665913584023,
            "rating_q025": 1349.533424533908
        },
        "gpt-oss-120b": {
            "rating": 1356.3990255328292,
            "rating_q975": 1365.0187066541891,
            "rating_q025": 1347.7793444114693
        },
        "ling-flash-2.0": {
            "rating": 1356.3371253960963,
            "rating_q975": 1372.451486678054,
            "rating_q025": 1340.2227641141387
        },
        "gemini-2.5-flash-lite-preview-06-17-thinking": {
            "rating": 1354.5270989974028,
            "rating_q975": 1363.0628195414956,
            "rating_q025": 1345.99137845331
        },
        "kimi-k2-0905-preview": {
            "rating": 1353.3485840950134,
            "rating_q975": 1366.718893382379,
            "rating_q025": 1339.9782748076477
        },
        "mistral-medium-2505": {
            "rating": 1351.8191891275737,
            "rating_q975": 1360.6338010548618,
            "rating_q025": 1343.0045772002857
        },
        "qwen2.5-max": {
            "rating": 1349.732492701397,
            "rating_q975": 1359.5071585286055,
            "rating_q025": 1339.9578268741884
        },
        "deepseek-v3-0324": {
            "rating": 1349.2805703773045,
            "rating_q975": 1356.9606016021683,
            "rating_q025": 1341.6005391524407
        },
        "qwen3-235b-a22b": {
            "rating": 1348.8853945827739,
            "rating_q975": 1358.4796505071204,
            "rating_q025": 1339.2911386584274
        },
        "deepseek-r1": {
            "rating": 1346.747502417529,
            "rating_q975": 1360.528512689699,
            "rating_q025": 1332.9664921453589
        },
        "qwen3-coder-480b-a35b-instruct": {
            "rating": 1344.8775169383857,
            "rating_q975": 1354.7775496130284,
            "rating_q025": 1334.977484263743
        },
        "amazon-nova-experimental-chat-10-09": {
            "rating": 1344.2112908434947,
            "rating_q975": 1358.609221465969,
            "rating_q025": 1329.8133602210203
        },
        "step-3": {
            "rating": 1343.0069588321837,
            "rating_q975": 1359.8869009551781,
            "rating_q025": 1326.1270167091893
        },
        "kimi-k2-0711-preview": {
            "rating": 1342.858003971126,
            "rating_q975": 1352.1226568630664,
            "rating_q025": 1333.5933510791856
        },
        "grok-3-mini-beta": {
            "rating": 1342.5783692567604,
            "rating_q975": 1352.6954497636343,
            "rating_q025": 1332.4612887498865
        },
        "grok-3-mini-high": {
            "rating": 1342.042247038182,
            "rating_q975": 1353.426860580494,
            "rating_q025": 1330.6576334958702
        },
        "claude-opus-4-20250514-thinking-16k": {
            "rating": 1341.9224334479425,
            "rating_q975": 1350.2617947705662,
            "rating_q025": 1333.5830721253187
        },
        "minimax-m2": {
            "rating": 1339.0043866818685,
            "rating_q975": 1355.4121143078792,
            "rating_q025": 1322.5966590558578
        },
        "intellect-3": {
            "rating": 1337.5294032679676,
            "rating_q975": 1366.3404452417253,
            "rating_q025": 1308.71836129421
        },
        "gemini-2.0-flash-001": {
            "rating": 1336.1188360639314,
            "rating_q975": 1344.413998712452,
            "rating_q025": 1327.823673415411
        },
        "claude-opus-4-20250514": {
            "rating": 1335.537590732808,
            "rating_q975": 1343.451905684416,
            "rating_q025": 1327.6232757812
        },
        "gemini-2.0-flash-lite-preview-02-05": {
            "rating": 1333.38460134188,
            "rating_q975": 1345.04500963217,
            "rating_q025": 1321.72419305159
        },
        "ring-flash-2.0": {
            "rating": 1327.65483024254,
            "rating_q975": 1343.7482297909446,
            "rating_q025": 1311.5614306941352
        },
        "mistral-small-2506": {
            "rating": 1327.305143262643,
            "rating_q975": 1338.3662169459133,
            "rating_q025": 1316.2440695793728
        },
        "o1-2024-12-17": {
            "rating": 1326.6473665696242,
            "rating_q975": 1338.0933695326096,
            "rating_q025": 1315.2013636066388
        },
        "glm-4-plus-0111": {
            "rating": 1326.1675809965798,
            "rating_q975": 1349.8753730641465,
            "rating_q025": 1302.459788929013
        },
        "step-1o-turbo-202506": {
            "rating": 1325.742211272571,
            "rating_q975": 1341.3584051482153,
            "rating_q025": 1310.1260173969267
        },
        "o4-mini-2025-04-16": {
            "rating": 1324.5753178516095,
            "rating_q975": 1332.1930429838956,
            "rating_q025": 1316.9575927193234
        },
        "hunyuan-turbos-20250226": {
            "rating": 1323.2748003436227,
            "rating_q975": 1356.3703432526415,
            "rating_q025": 1290.1792574346039
        },
        "gpt-4.1-mini-2025-04-14": {
            "rating": 1322.085542038312,
            "rating_q975": 1330.310517551,
            "rating_q025": 1313.860566525624
        },
        "qwq-32b": {
            "rating": 1320.4946163270808,
            "rating_q975": 1330.3562864326611,
            "rating_q025": 1310.6329462215006
        },
        "minimax-m1": {
            "rating": 1319.1836273475915,
            "rating_q975": 1327.2189995208905,
            "rating_q025": 1311.1482551742924
        },
        "qwen3-32b": {
            "rating": 1317.696708489135,
            "rating_q975": 1344.2068144271182,
            "rating_q025": 1291.186602551152
        },
        "claude-sonnet-4-20250514": {
            "rating": 1315.4132569274668,
            "rating_q975": 1323.5582289286988,
            "rating_q025": 1307.2682849262349
        },
        "claude-sonnet-4-20250514-thinking-32k": {
            "rating": 1313.9803819942358,
            "rating_q975": 1322.482405239267,
            "rating_q025": 1305.4783587492045
        },
        "command-a-03-2025": {
            "rating": 1312.3858250812154,
            "rating_q975": 1319.375359755589,
            "rating_q025": 1305.396290406842
        },
        "o3-mini-high": {
            "rating": 1311.615836881051,
            "rating_q975": 1325.2258851150486,
            "rating_q025": 1298.0057886470536
        },
        "gemma-3-4b-it": {
            "rating": 1310.5756343805035,
            "rating_q975": 1341.1695028928111,
            "rating_q025": 1279.981765868196
        },
        "nvidia-llama-3.3-nemotron-super-49b-v1.5": {
            "rating": 1308.8140960721778,
            "rating_q975": 1331.7828374167711,
            "rating_q025": 1285.8453547275844
        },
        "qwen3-30b-a3b": {
            "rating": 1308.400179699497,
            "rating_q975": 1317.928719282216,
            "rating_q025": 1298.8716401167778
        },
        "gpt-5-nano-high": {
            "rating": 1308.2823283729017,
            "rating_q975": 1323.8987651895911,
            "rating_q025": 1292.6658915562123
        },
        "hunyuan-turbo-0110": {
            "rating": 1307.7428655653912,
            "rating_q975": 1342.3102765893675,
            "rating_q025": 1273.1754545414149
        },
        "deepseek-v3": {
            "rating": 1305.6379499672835,
            "rating_q975": 1317.8782997369372,
            "rating_q025": 1293.3976001976298
        },
        "glm-4.5v": {
            "rating": 1305.1350850272365,
            "rating_q975": 1324.59651360324,
            "rating_q025": 1285.673656451233
        },
        "o1-preview": {
            "rating": 1303.1031933533195,
            "rating_q975": 1313.500945401171,
            "rating_q025": 1292.705441305468
        },
        "qwen-plus-0125": {
            "rating": 1302.8422629073502,
            "rating_q975": 1326.113653864706,
            "rating_q025": 1279.5708719499944
        },
        "llama-3.1-nemotron-ultra-253b-v1": {
            "rating": 1301.7631073878479,
            "rating_q975": 1335.9627818707106,
            "rating_q025": 1267.5634329049851
        },
        "olmo-3-32b-think": {
            "rating": 1297.9867282425107,
            "rating_q975": 1321.7135611990213,
            "rating_q025": 1274.259895286
        },
        "gemma-3n-e4b-it": {
            "rating": 1297.4463469043767,
            "rating_q975": 1307.9815520977243,
            "rating_q025": 1286.9111417110291
        },
        "mercury": {
            "rating": 1290.7719927755438,
            "rating_q975": 1322.8230339851727,
            "rating_q025": 1258.720951565915
        },
        "o3-mini": {
            "rating": 1287.806829562253,
            "rating_q975": 1294.9450656800561,
            "rating_q025": 1280.6685934444497
        },
        "qwen2.5-plus-1127": {
            "rating": 1287.5917701967778,
            "rating_q975": 1304.972792796389,
            "rating_q025": 1270.2107475971666
        },
        "o1-mini": {
            "rating": 1285.5849978165215,
            "rating_q975": 1293.8903987607016,
            "rating_q025": 1277.2795968723415
        },
        "llama-3.3-nemotron-49b-super-v1": {
            "rating": 1285.4790052670974,
            "rating_q975": 1320.7021989157527,
            "rating_q025": 1250.255811618442
        },
        "gemini-1.5-pro-002": {
            "rating": 1284.5714934925954,
            "rating_q975": 1292.5338174780265,
            "rating_q025": 1276.6091695071643
        },
        "gpt-oss-20b": {
            "rating": 1282.7058368250728,
            "rating_q975": 1296.9109987756956,
            "rating_q025": 1268.50067487445
        },
        "step-2-16k-exp-202412": {
            "rating": 1281.7766948644196,
            "rating_q975": 1306.714199914333,
            "rating_q025": 1256.8391898145062
        },
        "athene-v2-chat": {
            "rating": 1272.7628514516282,
            "rating_q975": 1283.8228478215622,
            "rating_q025": 1261.7028550816942
        },
        "claude-3-7-sonnet-20250219": {
            "rating": 1272.291642463497,
            "rating_q975": 1280.7191709660187,
            "rating_q025": 1263.8641139609754
        },
        "glm-4-plus": {
            "rating": 1271.5281237440067,
            "rating_q975": 1282.549620063333,
            "rating_q025": 1260.5066274246806
        },
        "yi-lightning": {
            "rating": 1269.8558513550956,
            "rating_q975": 1280.7675348443954,
            "rating_q025": 1258.9441678657959
        },
        "claude-3-7-sonnet-20250219-thinking-32k": {
            "rating": 1267.8778748766467,
            "rating_q975": 1276.5053179417494,
            "rating_q025": 1259.250431811544
        },
        "gpt-4.1-nano-2025-04-14": {
            "rating": 1266.4563899420932,
            "rating_q975": 1288.562787591145,
            "rating_q025": 1244.3499922930414
        },
        "grok-2-2024-08-13": {
            "rating": 1263.843220263038,
            "rating_q975": 1271.7035956501823,
            "rating_q025": 1255.9828448758935
        },
        "gpt-4o-mini-2024-07-18": {
            "rating": 1263.4253990388634,
            "rating_q975": 1270.9267551807245,
            "rating_q025": 1255.9240428970022
        },
        "gemini-1.5-flash-002": {
            "rating": 1263.0694542648566,
            "rating_q975": 1272.544519566998,
            "rating_q025": 1253.5943889627154
        },
        "llama-4-maverick-17b-128e-instruct": {
            "rating": 1261.1881887246036,
            "rating_q975": 1269.3917867700368,
            "rating_q025": 1252.9845906791704
        },
        "llama-3.1-nemotron-70b-instruct": {
            "rating": 1260.778809293408,
            "rating_q975": 1279.865710273818,
            "rating_q025": 1241.6919083129978
        },
        "gpt-4o-2024-05-13": {
            "rating": 1260.2653147994647,
            "rating_q975": 1267.6208063427225,
            "rating_q025": 1252.909823256207
        },
        "llama-4-scout-17b-16e-instruct": {
            "rating": 1260.1542992706773,
            "rating_q975": 1269.2750042079363,
            "rating_q025": 1251.0335943334183
        },
        "deepseek-v2.5-1210": {
            "rating": 1257.9544948199398,
            "rating_q975": 1279.4630716326337,
            "rating_q025": 1236.4459180072458
        },
        "mistral-small-3.1-24b-instruct-2503": {
            "rating": 1257.3600760213262,
            "rating_q975": 1266.1599081018378,
            "rating_q025": 1248.5602439408146
        },
        "qwen-max-0919": {
            "rating": 1254.753297216345,
            "rating_q975": 1267.4266144359653,
            "rating_q025": 1242.0799799967244
        },
        "hunyuan-standard-2025-02-10": {
            "rating": 1253.957926439362,
            "rating_q975": 1283.2870359610665,
            "rating_q025": 1224.6288169176573
        },
        "claude-3-5-sonnet-20241022": {
            "rating": 1253.345038416075,
            "rating_q975": 1259.375743007168,
            "rating_q025": 1247.3143338249822
        },
        "grok-2-mini-2024-08-13": {
            "rating": 1252.2977601026894,
            "rating_q975": 1260.5211686237542,
            "rating_q025": 1244.0743515816246
        },
        "qwen2.5-72b-instruct": {
            "rating": 1251.6034192651546,
            "rating_q975": 1260.6888884225696,
            "rating_q025": 1242.5179501077396
        },
        "gemini-1.5-pro-001": {
            "rating": 1247.0289322027024,
            "rating_q975": 1255.7427189254283,
            "rating_q025": 1238.3151454799765
        },
        "deepseek-v2.5": {
            "rating": 1246.9612298731065,
            "rating_q975": 1258.3096036074787,
            "rating_q025": 1235.6128561387343
        },
        "llama-3.1-405b-instruct-fp8": {
            "rating": 1246.239453727688,
            "rating_q975": 1254.5083114680194,
            "rating_q025": 1237.9705959873565
        },
        "gemini-advanced-0514": {
            "rating": 1244.7536753994978,
            "rating_q975": 1255.188764282553,
            "rating_q025": 1234.3185865164426
        },
        "athene-70b-0725": {
            "rating": 1244.5032445084264,
            "rating_q975": 1257.805652686626,
            "rating_q025": 1231.2008363302268
        },
        "llama-3.1-405b-instruct-bf16": {
            "rating": 1243.4868501481437,
            "rating_q975": 1252.3729097730438,
            "rating_q025": 1234.6007905232436
        },
        "llama-3.3-70b-instruct": {
            "rating": 1242.1155601732798,
            "rating_q975": 1249.4939555644114,
            "rating_q025": 1234.7371647821483
        },
        "hunyuan-large-2025-02-10": {
            "rating": 1240.4597894540987,
            "rating_q975": 1271.9261546062064,
            "rating_q025": 1208.993424301991
        },
        "mistral-large-2411": {
            "rating": 1237.5125574164188,
            "rating_q975": 1248.0321460842274,
            "rating_q025": 1226.99296874861
        },
        "llama-3.1-70b-instruct": {
            "rating": 1233.7524572073416,
            "rating_q975": 1242.0524137003101,
            "rating_q025": 1225.4525007143732
        },
        "claude-3-5-sonnet-20240620": {
            "rating": 1233.6818748295855,
            "rating_q975": 1241.6906603738018,
            "rating_q025": 1225.673089285369
        },
        "hunyuan-large-vision": {
            "rating": 1230.8814293805594,
            "rating_q975": 1252.8860602165569,
            "rating_q025": 1208.876798544562
        },
        "gpt-4o-2024-08-06": {
            "rating": 1230.4109956058383,
            "rating_q975": 1239.371270515892,
            "rating_q025": 1221.4507206957844
        },
        "amazon-nova-pro-v1.0": {
            "rating": 1227.4666118706705,
            "rating_q975": 1238.6362205730034,
            "rating_q025": 1216.2970031683376
        },
        "llama-3.1-tulu-3-70b": {
            "rating": 1225.1624207165742,
            "rating_q975": 1258.0042696470207,
            "rating_q025": 1192.3205717861276
        },
        "mistral-large-2407": {
            "rating": 1224.6522978489975,
            "rating_q975": 1233.8362206309657,
            "rating_q025": 1215.4683750670292
        },
        "gemini-1.5-flash-001": {
            "rating": 1224.1286779347106,
            "rating_q975": 1233.3031439271851,
            "rating_q025": 1214.954211942236
        },
        "qwen2.5-coder-32b-instruct": {
            "rating": 1222.3861406314793,
            "rating_q975": 1244.3859726599978,
            "rating_q025": 1200.3863086029608
        },
        "magistral-medium-2506": {
            "rating": 1221.3934771525232,
            "rating_q975": 1234.9882624268373,
            "rating_q025": 1207.7986918782092
        },
        "claude-3-5-haiku-20241022": {
            "rating": 1220.9820502525827,
            "rating_q975": 1227.7430586173032,
            "rating_q025": 1214.2210418878622
        },
        "gemma-2-9b-it-simpo": {
            "rating": 1220.9498271329853,
            "rating_q975": 1238.155793567938,
            "rating_q025": 1203.7438606980327
        },
        "claude-3-opus-20240229": {
            "rating": 1220.7829832806988,
            "rating_q975": 1227.52016250918,
            "rating_q025": 1214.0458040522176
        },
        "gpt-4-turbo-2024-04-09": {
            "rating": 1220.6153663688278,
            "rating_q975": 1228.9256778585795,
            "rating_q025": 1212.3050548790761
        },
        "amazon-nova-lite-v1.0": {
            "rating": 1217.3976206210468,
            "rating_q975": 1230.1528759290159,
            "rating_q025": 1204.6423653130778
        },
        "reka-core-20240904": {
            "rating": 1216.2657985972014,
            "rating_q975": 1235.8723159553676,
            "rating_q025": 1196.6592812390352
        },
        "gpt-4-0125-preview": {
            "rating": 1215.4915394978452,
            "rating_q975": 1224.2172172530643,
            "rating_q025": 1206.7658617426262
        },
        "llama-3.1-nemotron-51b-instruct": {
            "rating": 1214.1113335706646,
            "rating_q975": 1241.273617915721,
            "rating_q025": 1186.9490492256082
        },
        "command-r-plus-08-2024": {
            "rating": 1213.802400079254,
            "rating_q975": 1230.9455487685698,
            "rating_q025": 1196.6592513899384
        },
        "gemini-1.5-flash-8b-001": {
            "rating": 1209.4334340315454,
            "rating_q975": 1218.9436573242551,
            "rating_q025": 1199.9232107388357
        },
        "gpt-4-1106-preview": {
            "rating": 1209.2996734661888,
            "rating_q975": 1217.9532134888555,
            "rating_q025": 1200.646133443522
        },
        "c4ai-aya-expanse-32b": {
            "rating": 1208.7354981140006,
            "rating_q975": 1219.560739735439,
            "rating_q025": 1197.9102564925622
        },
        "gemma-2-27b-it": {
            "rating": 1206.5058923128336,
            "rating_q975": 1213.8771094843428,
            "rating_q025": 1199.1346751413244
        },
        "mistral-small-24b-instruct-2501": {
            "rating": 1205.9951234845298,
            "rating_q975": 1221.506545206961,
            "rating_q025": 1190.4837017620987
        },
        "phi-4": {
            "rating": 1197.4736492950651,
            "rating_q975": 1209.3964921730949,
            "rating_q025": 1185.5508064170353
        },
        "llama-3.1-tulu-3-8b": {
            "rating": 1195.2005624129754,
            "rating_q975": 1227.6545913038901,
            "rating_q025": 1162.7465335220606
        },
        "jamba-1.5-large": {
            "rating": 1195.096614895717,
            "rating_q975": 1213.5190207052028,
            "rating_q025": 1176.6742090862313
        },
        "reka-flash-20240904": {
            "rating": 1189.9290786025877,
            "rating_q975": 1208.53119758532,
            "rating_q025": 1171.3269596198554
        },
        "command-r-plus": {
            "rating": 1189.018494325751,
            "rating_q975": 1198.3603810728684,
            "rating_q025": 1179.6766075786334
        },
        "gemma-2-9b-it": {
            "rating": 1188.5009399552723,
            "rating_q975": 1196.8452900644627,
            "rating_q025": 1180.156589846082
        },
        "nemotron-4-340b-instruct": {
            "rating": 1183.5401363960889,
            "rating_q975": 1196.7389890138281,
            "rating_q025": 1170.3412837783496
        },
        "amazon-nova-micro-v1.0": {
            "rating": 1180.876876170737,
            "rating_q975": 1193.8983641243096,
            "rating_q025": 1167.8553882171643
        },
        "olmo-2-0325-32b-instruct": {
            "rating": 1178.6367423590907,
            "rating_q975": 1211.6352275733816,
            "rating_q025": 1145.6382571447998
        },
        "hunyuan-standard-256k": {
            "rating": 1176.369629265629,
            "rating_q975": 1208.1430706532406,
            "rating_q025": 1144.5961878780176
        },
        "c4ai-aya-expanse-8b": {
            "rating": 1175.0340898708223,
            "rating_q975": 1192.974018014138,
            "rating_q025": 1157.0941617275066
        },
        "glm-4-0520": {
            "rating": 1174.2516963710589,
            "rating_q975": 1191.5607343891584,
            "rating_q025": 1156.9426583529594
        },
        "claude-3-sonnet-20240229": {
            "rating": 1172.5057575830242,
            "rating_q975": 1181.4032359323637,
            "rating_q025": 1163.6082792336847
        },
        "ministral-8b-2410": {
            "rating": 1171.3736482952945,
            "rating_q975": 1194.9139450022308,
            "rating_q025": 1147.8333515883583
        },
        "llama-3-70b-instruct": {
            "rating": 1170.9822937163108,
            "rating_q975": 1178.9920371651287,
            "rating_q025": 1162.9725502674928
        },
        "llama-3.1-8b-instruct": {
            "rating": 1164.637830436502,
            "rating_q975": 1173.4158591214375,
            "rating_q025": 1155.8598017515667
        },
        "claude-3-haiku-20240307": {
            "rating": 1156.3005699966873,
            "rating_q975": 1164.3383017247436,
            "rating_q025": 1148.262838268631
        },
        "jamba-1.5-mini": {
            "rating": 1155.8332029236471,
            "rating_q975": 1174.0811108353034,
            "rating_q025": 1137.5852950119909
        },
        "command-r-08-2024": {
            "rating": 1155.5796156030024,
            "rating_q975": 1172.935812607017,
            "rating_q025": 1138.2234185989878
        },
        "deepseek-coder-v2": {
            "rating": 1153.5982142705193,
            "rating_q975": 1168.1012875788654,
            "rating_q025": 1139.0951409621732
        },
        "qwen2-72b-instruct": {
            "rating": 1145.0276720503095,
            "rating_q975": 1155.6310901756708,
            "rating_q025": 1134.4242539249483
        },
        "gpt-4-0314": {
            "rating": 1143.5330997502126,
            "rating_q975": 1154.6533361059187,
            "rating_q025": 1132.4128633945065
        },
        "granite-3.1-8b-instruct": {
            "rating": 1141.493796775359,
            "rating_q975": 1175.198091241837,
            "rating_q025": 1107.789502308881
        },
        "command-r": {
            "rating": 1139.959210763544,
            "rating_q975": 1150.4004958980024,
            "rating_q025": 1129.5179256290855
        },
        "qwen1.5-110b-chat": {
            "rating": 1138.8708939642045,
            "rating_q975": 1151.2404612379287,
            "rating_q025": 1126.5013266904803
        },
        "granite-3.1-2b-instruct": {
            "rating": 1137.8834702820673,
            "rating_q975": 1167.381455254167,
            "rating_q025": 1108.3854853099676
        },
        "reka-flash-21b-20240226-online": {
            "rating": 1133.8774039382452,
            "rating_q975": 1149.5246819352935,
            "rating_q025": 1118.2301259411968
        },
        "yi-1.5-34b-chat": {
            "rating": 1133.2249926327536,
            "rating_q975": 1145.433399067636,
            "rating_q025": 1121.0165861978712
        },
        "gemini-pro-dev-api": {
            "rating": 1129.3616618955589,
            "rating_q975": 1146.5270655523677,
            "rating_q025": 1112.19625823875
        },
        "mistral-large-2402": {
            "rating": 1128.95159126825,
            "rating_q975": 1139.0964670536766,
            "rating_q025": 1118.8067154828234
        },
        "llama-3-8b-instruct": {
            "rating": 1125.7323065439825,
            "rating_q975": 1134.6662855707991,
            "rating_q025": 1116.798327517166
        },
        "reka-flash-21b-20240226": {
            "rating": 1125.5494082824225,
            "rating_q975": 1138.6998103506485,
            "rating_q025": 1112.3990062141966
        },
        "gemma-2-2b-it": {
            "rating": 1124.477196263555,
            "rating_q975": 1133.571805868325,
            "rating_q025": 1115.382586658785
        },
        "gpt-4-0613": {
            "rating": 1120.4571032667766,
            "rating_q975": 1129.770546274103,
            "rating_q025": 1111.1436602594501
        },
        "mistral-medium": {
            "rating": 1118.1214687370339,
            "rating_q975": 1130.783811547998,
            "rating_q025": 1105.4591259260696
        },
        "mixtral-8x22b-instruct-v0.1": {
            "rating": 1117.2749855019704,
            "rating_q975": 1127.312982654267,
            "rating_q025": 1107.2369883496738
        },
        "qwen1.5-72b-chat": {
            "rating": 1115.5067913663615,
            "rating_q975": 1127.0814799788966,
            "rating_q025": 1103.9321027538265
        },
        "internlm2_5-20b-chat": {
            "rating": 1113.720057052427,
            "rating_q975": 1130.5411971064227,
            "rating_q025": 1096.898916998431
        },
        "starling-lm-7b-beta": {
            "rating": 1102.7668999003727,
            "rating_q975": 1119.0575676762069,
            "rating_q025": 1086.4762321245385
        },
        "phi-3-medium-4k-instruct": {
            "rating": 1097.7575109818165,
            "rating_q975": 1109.8536689988575,
            "rating_q025": 1085.6613529647755
        },
        "qwq-32b-preview": {
            "rating": 1096.3491681622613,
            "rating_q975": 1128.593008359552,
            "rating_q025": 1064.1053279649707
        },
        "qwen1.5-32b-chat": {
            "rating": 1092.7677642818346,
            "rating_q975": 1106.4266685617488,
            "rating_q025": 1079.1088600019204
        },
        "yi-34b-chat": {
            "rating": 1087.0496692230045,
            "rating_q975": 1103.8055958146408,
            "rating_q025": 1070.293742631368
        },
        "zephyr-orpo-141b-A35b-v0.1": {
            "rating": 1086.9327066889118,
            "rating_q975": 1114.9765555005165,
            "rating_q025": 1058.8888578773071
        },
        "mixtral-8x7b-instruct-v0.1": {
            "rating": 1082.2461299210695,
            "rating_q975": 1092.1032826879627,
            "rating_q025": 1072.3889771541762
        },
        "qwen1.5-14b-chat": {
            "rating": 1081.9122442150056,
            "rating_q975": 1097.419107705879,
            "rating_q025": 1066.405380724132
        },
        "llama-2-70b-chat": {
            "rating": 1081.096359963973,
            "rating_q975": 1093.1458560205433,
            "rating_q025": 1069.046863907403
        },
        "gemini-pro": {
            "rating": 1080.9554477205002,
            "rating_q975": 1111.1225554078007,
            "rating_q025": 1050.7883400331996
        },
        "llama2-70b-steerlm-chat": {
            "rating": 1076.6351921516316,
            "rating_q975": 1112.8736501324,
            "rating_q025": 1040.3967341708633
        },
        "wizardlm-70b": {
            "rating": 1076.2836702406175,
            "rating_q975": 1100.4105335674046,
            "rating_q025": 1052.1568069138305
        },
        "tulu-2-dpo-70b": {
            "rating": 1075.7426952442827,
            "rating_q975": 1101.4479620124994,
            "rating_q025": 1050.037428476066
        },
        "phi-3-small-8k-instruct": {
            "rating": 1075.7362877839394,
            "rating_q975": 1089.3811798511144,
            "rating_q025": 1062.0913957167643
        },
        "gpt-3.5-turbo-0125": {
            "rating": 1074.4774385524454,
            "rating_q975": 1084.1355230002755,
            "rating_q025": 1064.8193541046153
        },
        "openchat-3.5-0106": {
            "rating": 1072.7133886722036,
            "rating_q975": 1090.8036710434862,
            "rating_q025": 1054.6231063009209
        },
        "llama-3.2-3b-instruct": {
            "rating": 1072.1426149477224,
            "rating_q975": 1091.897795910648,
            "rating_q025": 1052.3874339847969
        },
        "starling-lm-7b-alpha": {
            "rating": 1071.4669800598424,
            "rating_q975": 1092.0243779023338,
            "rating_q025": 1050.909582217351
        },
        "dbrx-instruct-preview": {
            "rating": 1070.7735793251427,
            "rating_q975": 1084.0692847706146,
            "rating_q025": 1057.4778738796708
        },
        "nous-hermes-2-mixtral-8x7b-dpo": {
            "rating": 1069.6793596845314,
            "rating_q975": 1105.1809310053777,
            "rating_q025": 1034.177788363685
        },
        "qwen1.5-7b-chat": {
            "rating": 1062.930034104717,
            "rating_q975": 1091.0487708703283,
            "rating_q025": 1034.8112973391055
        },
        "gemma-1.1-7b-it": {
            "rating": 1061.4176831790753,
            "rating_q975": 1074.2953086409245,
            "rating_q025": 1048.540057717226
        },
        "llama-2-13b-chat": {
            "rating": 1054.1647452923926,
            "rating_q975": 1070.3109373619711,
            "rating_q025": 1038.018553222814
        },
        "vicuna-33b": {
            "rating": 1052.4486691124969,
            "rating_q975": 1068.0625516181206,
            "rating_q025": 1036.8347866068732
        },
        "deepseek-llm-67b-chat": {
            "rating": 1046.0675299311026,
            "rating_q975": 1074.9366321968132,
            "rating_q025": 1017.1984276653922
        },
        "granite-3.0-8b-instruct": {
            "rating": 1039.2001136611075,
            "rating_q975": 1061.7308571017759,
            "rating_q025": 1016.6693702204391
        },
        "mistral-7b-instruct-v0.2": {
            "rating": 1036.49587832635,
            "rating_q975": 1052.1215936352614,
            "rating_q025": 1020.8701630174387
        },
        "openchat-3.5": {
            "rating": 1034.7243858859006,
            "rating_q975": 1059.0992734815557,
            "rating_q025": 1010.3494982902455
        },
        "granite-3.0-2b-instruct": {
            "rating": 1033.638239305215,
            "rating_q975": 1055.2001095190215,
            "rating_q025": 1012.0763690914084
        },
        "codellama-34b-instruct": {
            "rating": 1032.0008413547773,
            "rating_q975": 1056.838247671845,
            "rating_q025": 1007.1634350377097
        },
        "phi-3-mini-4k-instruct": {
            "rating": 1031.0970582439938,
            "rating_q975": 1044.5913799109012,
            "rating_q025": 1017.6027365770866
        },
        "snowflake-arctic-instruct": {
            "rating": 1030.0022726440247,
            "rating_q975": 1043.4674518949569,
            "rating_q025": 1016.5370933930925
        },
        "llama-2-7b-chat": {
            "rating": 1026.4330869271657,
            "rating_q975": 1044.5368927607415,
            "rating_q025": 1008.32928109359
        },
        "gemma-7b-it": {
            "rating": 1024.2088284749752,
            "rating_q975": 1045.9100699456283,
            "rating_q025": 1002.5075870043222
        },
        "openhermes-2.5-mistral-7b": {
            "rating": 1022.839126854627,
            "rating_q975": 1052.9313018211299,
            "rating_q025": 992.7469518881242
        },
        "phi-3-mini-4k-instruct-june-2024": {
            "rating": 1021.0846863071151,
            "rating_q975": 1037.9366976299582,
            "rating_q025": 1004.232674984272
        },
        "solar-10.7b-instruct-v1.0": {
            "rating": 1019.5834504603167,
            "rating_q975": 1054.3996358797867,
            "rating_q025": 984.7672650408468
        },
        "gpt-3.5-turbo-1106": {
            "rating": 1018.0588394569378,
            "rating_q975": 1037.4316248812827,
            "rating_q025": 998.6860540325929
        },
        "olmo-7b-instruct": {
            "rating": 1017.3038175916398,
            "rating_q975": 1043.6791477376332,
            "rating_q025": 990.9284874456463
        },
        "mpt-30b-chat": {
            "rating": 1006.7148561633026,
            "rating_q975": 1046.3791296360898,
            "rating_q025": 967.0505826905154
        },
        "wizardlm-13b": {
            "rating": 1004.6220394864722,
            "rating_q975": 1029.4660056767302,
            "rating_q025": 979.7780732962141
        },
        "vicuna-13b": {
            "rating": 1004.034516989736,
            "rating_q975": 1021.404044320334,
            "rating_q025": 986.6649896591379
        },
        "qwen-14b-chat": {
            "rating": 998.9994117685073,
            "rating_q975": 1028.1850960041697,
            "rating_q025": 969.813727532845
        },
        "zephyr-7b-beta": {
            "rating": 998.8561801325313,
            "rating_q975": 1019.4920378196847,
            "rating_q025": 978.220322445378
        },
        "llama-3.2-1b-instruct": {
            "rating": 998.3969492489371,
            "rating_q975": 1019.0030847341878,
            "rating_q025": 977.7908137636863
        },
        "gemma-2b-it": {
            "rating": 997.2701182245187,
            "rating_q975": 1025.5728230101365,
            "rating_q025": 968.9674134389008
        },
        "phi-3-mini-128k-instruct": {
            "rating": 989.3135927390556,
            "rating_q975": 1005.2443945862195,
            "rating_q025": 973.3827908918917
        },
        "gemma-1.1-2b-it": {
            "rating": 979.5774270888064,
            "rating_q975": 998.7733441294035,
            "rating_q025": 960.3815100482093
        },
        "vicuna-7b": {
            "rating": 970.8629053747768,
            "rating_q975": 998.9244024131891,
            "rating_q025": 942.8014083363645
        },
        "guanaco-33b": {
            "rating": 969.5680047527641,
            "rating_q975": 1009.8884072120636,
            "rating_q025": 929.2476022934645
        },
        "smollm2-1.7b-instruct": {
            "rating": 969.0365380633275,
            "rating_q975": 1014.6130197537118,
            "rating_q025": 923.4600563729432
        },
        "stripedhyena-nous-7b": {
            "rating": 968.6356489089703,
            "rating_q975": 998.5732899983125,
            "rating_q025": 938.6980078196282
        },
        "qwen1.5-4b-chat": {
            "rating": 964.0463156062028,
            "rating_q975": 987.6564685630558,
            "rating_q025": 940.4361626493499
        },
        "palm-2": {
            "rating": 957.2964221282789,
            "rating_q975": 981.9133455852743,
            "rating_q025": 932.6794986712835
        },
        "mistral-7b-instruct": {
            "rating": 950.8073186264285,
            "rating_q975": 974.8598853363804,
            "rating_q025": 926.7547519164765
        },
        "koala-13b": {
            "rating": 934.5455708045492,
            "rating_q975": 965.0077662834648,
            "rating_q025": 904.0833753256337
        },
        "chatglm3-6b": {
            "rating": 930.0578394541631,
            "rating_q975": 962.5766153556846,
            "rating_q025": 897.5390635526416
        },
        "RWKV-4-Raven-14B": {
            "rating": 886.2236689420008,
            "rating_q975": 921.4099825793834,
            "rating_q025": 851.0373553046182
        },
        "chatglm2-6b": {
            "rating": 885.2888039422313,
            "rating_q975": 928.2958191359638,
            "rating_q025": 842.2817887484988
        },
        "fastchat-t5-3b": {
            "rating": 865.784589548244,
            "rating_q975": 905.775437749902,
            "rating_q025": 825.7937413465859
        },
        "mpt-7b-chat": {
            "rating": 862.8002533193758,
            "rating_q975": 900.3707424096772,
            "rating_q025": 825.2297642290744
        },
        "chatglm-6b": {
            "rating": 843.6682595486823,
            "rating_q975": 882.8485174582606,
            "rating_q025": 804.4880016391039
        },
        "oasst-pythia-12b": {
            "rating": 820.216743328984,
            "rating_q975": 851.6746018609115,
            "rating_q025": 788.7588847970565
        },
        "alpaca-13b": {
            "rating": 810.6908730491641,
            "rating_q975": 845.9006200146682,
            "rating_q025": 775.48112608366
        },
        "stablelm-tuned-alpha-7b": {
            "rating": 784.2058590253487,
            "rating_q975": 827.2088775673935,
            "rating_q025": 741.2028404833038
        },
        "dolly-v2-12b": {
            "rating": 732.0635945073047,
            "rating_q975": 778.9385898654834,
            "rating_q025": 685.188599149126
        }
    },
    "industry_entertainment_and_sports_and_media": {
        "gemini-3-pro": {
            "rating": 1478.1874558499758,
            "rating_q975": 1490.145949023967,
            "rating_q025": 1466.2289626759846
        },
        "gemini-2.5-pro": {
            "rating": 1450.9340717510856,
            "rating_q975": 1457.167515830928,
            "rating_q025": 1444.7006276712432
        },
        "gpt-5.1-high": {
            "rating": 1428.5313941466452,
            "rating_q975": 1440.986539255883,
            "rating_q025": 1416.0762490374075
        },
        "grok-4.1-thinking": {
            "rating": 1427.545784840379,
            "rating_q975": 1439.1566835917079,
            "rating_q025": 1415.93488608905
        },
        "claude-opus-4-5-20251101-thinking-32k": {
            "rating": 1427.4554659395678,
            "rating_q975": 1441.887913110927,
            "rating_q025": 1413.0230187682087
        },
        "claude-opus-4-5-20251101": {
            "rating": 1421.236762223301,
            "rating_q975": 1435.6703342289654,
            "rating_q025": 1406.8031902176365
        },
        "grok-4.1": {
            "rating": 1414.895075428071,
            "rating_q975": 1426.241093211853,
            "rating_q025": 1403.5490576442892
        },
        "grok-3-preview-02-24": {
            "rating": 1414.785484712267,
            "rating_q975": 1422.874006636075,
            "rating_q025": 1406.696962788459
        },
        "chatgpt-4o-latest-20250326": {
            "rating": 1409.875915265924,
            "rating_q975": 1416.0706488749618,
            "rating_q025": 1403.6811816568863
        },
        "glm-4.6": {
            "rating": 1409.2594453540216,
            "rating_q975": 1418.5432456091569,
            "rating_q025": 1399.9756450988864
        },
        "claude-sonnet-4-5-20250929-thinking-32k": {
            "rating": 1407.5044929408623,
            "rating_q975": 1416.468687888229,
            "rating_q025": 1398.5402979934956
        },
        "claude-sonnet-4-5-20250929": {
            "rating": 1407.4928840304765,
            "rating_q975": 1417.3284195910983,
            "rating_q025": 1397.6573484698547
        },
        "ernie-5.0-preview-1103": {
            "rating": 1405.498658839197,
            "rating_q975": 1424.059282823968,
            "rating_q025": 1386.9380348544262
        },
        "glm-4.5": {
            "rating": 1404.3478217226466,
            "rating_q975": 1413.4650701198027,
            "rating_q025": 1395.2305733254905
        },
        "qwen3-max-preview": {
            "rating": 1403.1247271757313,
            "rating_q975": 1411.8375280775817,
            "rating_q025": 1394.411926273881
        },
        "deepseek-v3.2-exp": {
            "rating": 1402.0519640956268,
            "rating_q975": 1414.9139702746272,
            "rating_q025": 1389.1899579166263
        },
        "gpt-4.5-preview-2025-02-27": {
            "rating": 1398.959163833946,
            "rating_q975": 1410.684067702208,
            "rating_q025": 1387.2342599656838
        },
        "deepseek-r1-0528": {
            "rating": 1398.4494368867647,
            "rating_q975": 1408.8620295225326,
            "rating_q025": 1388.0368442509969
        },
        "gpt-5.1": {
            "rating": 1397.0272455471243,
            "rating_q975": 1409.0265609758019,
            "rating_q025": 1385.0279301184466
        },
        "gemini-2.5-flash": {
            "rating": 1395.072763582333,
            "rating_q975": 1401.062667750767,
            "rating_q025": 1389.0828594138989
        },
        "deepseek-v3.1-thinking": {
            "rating": 1392.623789583284,
            "rating_q975": 1405.031628742659,
            "rating_q025": 1380.215950423909
        },
        "grok-4-0709": {
            "rating": 1392.0844107265766,
            "rating_q975": 1399.3096415687046,
            "rating_q025": 1384.8591798844486
        },
        "claude-opus-4-1-20250805-thinking-16k": {
            "rating": 1391.2640363614914,
            "rating_q975": 1398.5854565334007,
            "rating_q025": 1383.9426161895822
        },
        "mistral-large-3": {
            "rating": 1390.906139320133,
            "rating_q975": 1407.8819480967109,
            "rating_q025": 1373.930330543555
        },
        "claude-opus-4-1-20250805": {
            "rating": 1390.693426455708,
            "rating_q975": 1397.465501080923,
            "rating_q025": 1383.921351830493
        },
        "deepseek-v3.2": {
            "rating": 1389.3991283378066,
            "rating_q975": 1406.9587329921271,
            "rating_q025": 1371.839523683486
        },
        "mistral-medium-2508": {
            "rating": 1389.0629089822107,
            "rating_q975": 1396.2803948278147,
            "rating_q025": 1381.8454231366068
        },
        "deepseek-v3.2-exp-thinking": {
            "rating": 1387.3607387045759,
            "rating_q975": 1401.7577584863277,
            "rating_q025": 1372.963718922824
        },
        "gemini-2.5-flash-preview-09-2025": {
            "rating": 1386.1751080607924,
            "rating_q975": 1394.7577211859948,
            "rating_q025": 1377.59249493559
        },
        "grok-4-1-fast-reasoning": {
            "rating": 1385.8430208782747,
            "rating_q975": 1400.5369724389457,
            "rating_q025": 1371.1490693176038
        },
        "deepseek-v3.2-thinking": {
            "rating": 1385.1771172236286,
            "rating_q975": 1403.3582479398613,
            "rating_q025": 1366.9959865073959
        },
        "deepseek-v3.1-terminus-thinking": {
            "rating": 1383.4137776131226,
            "rating_q975": 1407.2054175891087,
            "rating_q025": 1359.6221376371366
        },
        "deepseek-v3.1-terminus": {
            "rating": 1382.0801199210086,
            "rating_q975": 1405.4653736333387,
            "rating_q025": 1358.6948662086786
        },
        "gpt-5-high": {
            "rating": 1381.6142403904344,
            "rating_q975": 1389.7841271602128,
            "rating_q025": 1373.4443536206559
        },
        "deepseek-v3.1": {
            "rating": 1381.1939354814745,
            "rating_q975": 1392.448851841095,
            "rating_q025": 1369.939019121854
        },
        "qwen3-max-2025-09-23": {
            "rating": 1381.1376932778294,
            "rating_q975": 1395.3434167522682,
            "rating_q025": 1366.9319698033905
        },
        "grok-4-fast-chat": {
            "rating": 1379.4294098356136,
            "rating_q975": 1395.529525627465,
            "rating_q025": 1363.329294043762
        },
        "hunyuan-vision-1.5-thinking": {
            "rating": 1378.4920579089403,
            "rating_q975": 1407.954342519033,
            "rating_q025": 1349.0297732988477
        },
        "kimi-k2-thinking-turbo": {
            "rating": 1377.8444898482362,
            "rating_q975": 1389.406519508011,
            "rating_q025": 1366.2824601884615
        },
        "o3-2025-04-16": {
            "rating": 1374.7458501493848,
            "rating_q975": 1381.2261367887897,
            "rating_q025": 1368.2655635099798
        },
        "qwen3-235b-a22b-instruct-2507": {
            "rating": 1373.8108333999307,
            "rating_q975": 1380.6200968398853,
            "rating_q025": 1367.0015699599762
        },
        "qwen3-vl-235b-a22b-thinking": {
            "rating": 1371.9438529105887,
            "rating_q975": 1387.3243257303004,
            "rating_q025": 1356.563380090877
        },
        "qwen3-vl-235b-a22b-instruct": {
            "rating": 1368.4675604311233,
            "rating_q975": 1383.604328192043,
            "rating_q025": 1353.3307926702034
        },
        "grok-4-fast-reasoning": {
            "rating": 1364.7110726459903,
            "rating_q975": 1375.0455153223184,
            "rating_q025": 1354.3766299696622
        },
        "gpt-5-chat": {
            "rating": 1364.1435268471407,
            "rating_q975": 1372.3066243256283,
            "rating_q025": 1355.9804293686532
        },
        "claude-opus-4-20250514-thinking-16k": {
            "rating": 1363.8883085386299,
            "rating_q975": 1371.8243476007362,
            "rating_q025": 1355.9522694765235
        },
        "qwen3-235b-a22b-thinking-2507": {
            "rating": 1363.8414251324832,
            "rating_q975": 1378.2240383357453,
            "rating_q025": 1349.4588119292212
        },
        "gpt-4.1-2025-04-14": {
            "rating": 1363.599370640161,
            "rating_q975": 1370.3076934608591,
            "rating_q025": 1356.8910478194628
        },
        "longcat-flash-chat": {
            "rating": 1362.0208422899457,
            "rating_q975": 1375.0784478683377,
            "rating_q025": 1348.9632367115537
        },
        "o1-2024-12-17": {
            "rating": 1358.183909693886,
            "rating_q975": 1366.5567134189,
            "rating_q025": 1349.8111059688722
        },
        "deepseek-v3-0324": {
            "rating": 1355.7767023593535,
            "rating_q975": 1362.659873643456,
            "rating_q025": 1348.893531075251
        },
        "hunyuan-t1-20250711": {
            "rating": 1355.0949126249493,
            "rating_q975": 1374.1864183947027,
            "rating_q025": 1336.0034068551959
        },
        "mai-1-preview": {
            "rating": 1354.5685103200226,
            "rating_q975": 1365.1870319733346,
            "rating_q025": 1343.9499886667106
        },
        "gemini-2.5-flash-lite-preview-06-17-thinking": {
            "rating": 1354.2637910129613,
            "rating_q975": 1362.2333381088056,
            "rating_q025": 1346.294243917117
        },
        "claude-haiku-4-5-20251001": {
            "rating": 1351.6431781061945,
            "rating_q975": 1360.7906680359736,
            "rating_q025": 1342.4956881764153
        },
        "qwen3-next-80b-a3b-instruct": {
            "rating": 1351.3970599119632,
            "rating_q975": 1360.6852336783156,
            "rating_q025": 1342.1088861456108
        },
        "qwen3-235b-a22b-no-thinking": {
            "rating": 1348.8905889404093,
            "rating_q975": 1356.5084578096912,
            "rating_q025": 1341.2727200711274
        },
        "claude-opus-4-20250514": {
            "rating": 1348.516485440513,
            "rating_q975": 1355.8982064662925,
            "rating_q025": 1341.1347644147334
        },
        "gemini-2.5-flash-lite-preview-09-2025-no-thinking": {
            "rating": 1347.074855679206,
            "rating_q975": 1355.6334887523365,
            "rating_q025": 1338.5162226060754
        },
        "deepseek-r1": {
            "rating": 1346.949987958734,
            "rating_q975": 1356.6127615947903,
            "rating_q025": 1337.2872143226778
        },
        "kimi-k2-0905-preview": {
            "rating": 1344.0812615656985,
            "rating_q975": 1356.9039450590476,
            "rating_q025": 1331.2585780723493
        },
        "gpt-5-mini-high": {
            "rating": 1343.9566211025146,
            "rating_q975": 1352.8607780240754,
            "rating_q025": 1335.0524641809538
        },
        "glm-4.5-air": {
            "rating": 1339.6101490688711,
            "rating_q975": 1347.5960952931594,
            "rating_q025": 1331.624202844583
        },
        "qwen3-30b-a3b-instruct-2507": {
            "rating": 1335.289470130398,
            "rating_q975": 1344.465370044043,
            "rating_q025": 1326.113570216753
        },
        "amazon-nova-experimental-chat-10-20": {
            "rating": 1334.9774827372491,
            "rating_q975": 1351.0292488089008,
            "rating_q025": 1318.9257166655975
        },
        "hunyuan-turbos-20250416": {
            "rating": 1334.5016159785378,
            "rating_q975": 1347.5846795952205,
            "rating_q025": 1321.418552361855
        },
        "kimi-k2-0711-preview": {
            "rating": 1333.9752280477046,
            "rating_q975": 1342.5578426283219,
            "rating_q025": 1325.3926134670874
        },
        "mistral-medium-2505": {
            "rating": 1333.569349994912,
            "rating_q975": 1341.5901002287792,
            "rating_q025": 1325.548599761045
        },
        "gemini-2.0-flash-001": {
            "rating": 1333.3641203706018,
            "rating_q975": 1340.1316532014348,
            "rating_q025": 1326.5965875397687
        },
        "o1-preview": {
            "rating": 1331.385752233985,
            "rating_q975": 1340.8633244035796,
            "rating_q025": 1321.9081800643903
        },
        "grok-3-mini-high": {
            "rating": 1330.8113394913335,
            "rating_q975": 1341.4190154196594,
            "rating_q025": 1320.2036635630075
        },
        "claude-sonnet-4-20250514-thinking-32k": {
            "rating": 1330.0114857908043,
            "rating_q975": 1338.0168321517306,
            "rating_q025": 1322.006139429878
        },
        "step-3": {
            "rating": 1328.3407012201392,
            "rating_q975": 1345.397799229507,
            "rating_q025": 1311.2836032107714
        },
        "qwen2.5-max": {
            "rating": 1326.5329253219898,
            "rating_q975": 1334.0291752168287,
            "rating_q025": 1319.0366754271508
        },
        "grok-3-mini-beta": {
            "rating": 1326.085015222003,
            "rating_q975": 1335.3817339162192,
            "rating_q025": 1316.7882965277868
        },
        "deepseek-v3": {
            "rating": 1324.1903830458002,
            "rating_q975": 1333.2950819963876,
            "rating_q025": 1315.0856840952129
        },
        "amazon-nova-experimental-chat-10-09": {
            "rating": 1321.1640418795942,
            "rating_q975": 1335.1219224621968,
            "rating_q025": 1307.2061612969915
        },
        "gemma-3-27b-it": {
            "rating": 1320.2512924083233,
            "rating_q975": 1326.9383910242611,
            "rating_q025": 1313.5641937923854
        },
        "claude-sonnet-4-20250514": {
            "rating": 1318.0716235060477,
            "rating_q975": 1325.7867799943008,
            "rating_q025": 1310.3564670177946
        },
        "nova-2-lite": {
            "rating": 1317.5293863190336,
            "rating_q975": 1337.0513930343193,
            "rating_q025": 1298.007379603748
        },
        "qwen3-235b-a22b": {
            "rating": 1316.45233140997,
            "rating_q975": 1324.931418592612,
            "rating_q025": 1307.9732442273278
        },
        "qwen3-coder-480b-a35b-instruct": {
            "rating": 1316.2863342738844,
            "rating_q975": 1325.4004379730886,
            "rating_q025": 1307.1722305746803
        },
        "o4-mini-2025-04-16": {
            "rating": 1312.3896877208783,
            "rating_q975": 1319.3740072664443,
            "rating_q025": 1305.4053681753123
        },
        "claude-3-7-sonnet-20250219-thinking-32k": {
            "rating": 1311.2408993698612,
            "rating_q975": 1318.8749946493822,
            "rating_q025": 1303.6068040903401
        },
        "qwen3-next-80b-a3b-thinking": {
            "rating": 1307.7742909083381,
            "rating_q975": 1319.7099540862494,
            "rating_q025": 1295.8386277304269
        },
        "command-a-03-2025": {
            "rating": 1306.7696226433584,
            "rating_q975": 1313.0295837515362,
            "rating_q025": 1300.5096615351806
        },
        "minimax-m1": {
            "rating": 1306.1917023267515,
            "rating_q975": 1313.7813356129052,
            "rating_q025": 1298.6020690405978
        },
        "gemini-1.5-pro-002": {
            "rating": 1305.8436462157658,
            "rating_q975": 1312.3525447732527,
            "rating_q025": 1299.334747658279
        },
        "mistral-small-2506": {
            "rating": 1305.2681563584956,
            "rating_q975": 1315.274437076061,
            "rating_q025": 1295.2618756409302
        },
        "glm-4.5v": {
            "rating": 1303.16673383881,
            "rating_q975": 1322.0729564270016,
            "rating_q025": 1284.2605112506183
        },
        "minimax-m2": {
            "rating": 1303.034268464619,
            "rating_q975": 1319.8051187767658,
            "rating_q025": 1286.263418152472
        },
        "claude-3-7-sonnet-20250219": {
            "rating": 1300.312594758297,
            "rating_q975": 1307.5062801625381,
            "rating_q025": 1293.118909354056
        },
        "gpt-4.1-mini-2025-04-14": {
            "rating": 1300.114992381698,
            "rating_q975": 1307.6238846854365,
            "rating_q025": 1292.6061000779594
        },
        "gemma-3-12b-it": {
            "rating": 1297.7668916767157,
            "rating_q975": 1318.967369009355,
            "rating_q025": 1276.5664143440763
        },
        "gemini-2.0-flash-lite-preview-02-05": {
            "rating": 1297.1768244992506,
            "rating_q975": 1305.6585468396001,
            "rating_q025": 1288.6951021589011
        },
        "ling-flash-2.0": {
            "rating": 1296.7141168824774,
            "rating_q975": 1313.5378258680553,
            "rating_q025": 1279.8904078968994
        },
        "gpt-oss-120b": {
            "rating": 1293.1174481775809,
            "rating_q975": 1301.307065905298,
            "rating_q025": 1284.9278304498637
        },
        "step-1o-turbo-202506": {
            "rating": 1292.492366266912,
            "rating_q975": 1307.010461044965,
            "rating_q025": 1277.9742714888591
        },
        "step-2-16k-exp-202412": {
            "rating": 1291.6358348345561,
            "rating_q975": 1310.008568850013,
            "rating_q025": 1273.2631008190992
        },
        "glm-4-plus-0111": {
            "rating": 1291.407068564888,
            "rating_q975": 1308.6984824622307,
            "rating_q025": 1274.1156546675454
        },
        "gpt-4o-2024-05-13": {
            "rating": 1290.0001282952355,
            "rating_q975": 1296.5961620709334,
            "rating_q025": 1283.4040945195377
        },
        "intellect-3": {
            "rating": 1288.4320891369148,
            "rating_q975": 1318.4807406924263,
            "rating_q025": 1258.3834375814033
        },
        "llama-3.3-nemotron-49b-super-v1": {
            "rating": 1287.695627410371,
            "rating_q975": 1314.910999789697,
            "rating_q025": 1260.4802550310449
        },
        "ring-flash-2.0": {
            "rating": 1286.3043986518592,
            "rating_q975": 1302.6633292587528,
            "rating_q025": 1269.9454680449655
        },
        "o3-mini-high": {
            "rating": 1283.3810678600175,
            "rating_q975": 1293.5809993123523,
            "rating_q025": 1273.1811364076827
        },
        "grok-2-2024-08-13": {
            "rating": 1282.67880003475,
            "rating_q975": 1289.4152923403117,
            "rating_q025": 1275.9423077291885
        },
        "nvidia-llama-3.3-nemotron-super-49b-v1.5": {
            "rating": 1281.3632620431702,
            "rating_q975": 1303.8569327334021,
            "rating_q025": 1258.8695913529382
        },
        "claude-3-5-sonnet-20241022": {
            "rating": 1279.904197822313,
            "rating_q975": 1285.2621834697036,
            "rating_q025": 1274.5462121749226
        },
        "qwen3-32b": {
            "rating": 1279.84705045494,
            "rating_q975": 1300.5592924153043,
            "rating_q025": 1259.1348084945757
        },
        "qwq-32b": {
            "rating": 1278.405836699528,
            "rating_q975": 1286.992413944277,
            "rating_q025": 1269.819259454779
        },
        "llama-3.1-nemotron-ultra-253b-v1": {
            "rating": 1276.9071772269717,
            "rating_q975": 1300.495927077707,
            "rating_q025": 1253.3184273762365
        },
        "deepseek-v2.5-1210": {
            "rating": 1275.7078170040859,
            "rating_q975": 1291.6658376304279,
            "rating_q025": 1259.749796377744
        },
        "o3-mini": {
            "rating": 1273.7200112346459,
            "rating_q975": 1279.8180040306313,
            "rating_q025": 1267.6220184386605
        },
        "olmo-3-32b-think": {
            "rating": 1272.9785206538063,
            "rating_q975": 1298.1952021206769,
            "rating_q025": 1247.7618391869357
        },
        "yi-lightning": {
            "rating": 1272.7209738497297,
            "rating_q975": 1282.6967044356106,
            "rating_q025": 1262.7452432638488
        },
        "gpt-5-nano-high": {
            "rating": 1272.3842774979003,
            "rating_q975": 1288.6210296456056,
            "rating_q025": 1256.1475253501949
        },
        "gemini-advanced-0514": {
            "rating": 1271.1932526802998,
            "rating_q975": 1280.5729832220973,
            "rating_q025": 1261.8135221385023
        },
        "qwen-plus-0125": {
            "rating": 1270.365500847574,
            "rating_q975": 1287.0683750126354,
            "rating_q025": 1253.6626266825124
        },
        "gpt-4o-2024-08-06": {
            "rating": 1267.9089314585394,
            "rating_q975": 1275.9347280149354,
            "rating_q025": 1259.8831349021434
        },
        "hunyuan-turbo-0110": {
            "rating": 1266.860486117856,
            "rating_q975": 1291.978456110905,
            "rating_q025": 1241.742516124807
        },
        "gemma-3n-e4b-it": {
            "rating": 1262.678023138786,
            "rating_q975": 1272.0056227289683,
            "rating_q025": 1253.3504235486039
        },
        "hunyuan-large-2025-02-10": {
            "rating": 1262.3234869504527,
            "rating_q975": 1284.480328422383,
            "rating_q025": 1240.1666454785222
        },
        "qwen3-30b-a3b": {
            "rating": 1259.4962043173164,
            "rating_q975": 1268.2042493542613,
            "rating_q025": 1250.7881592803715
        },
        "gpt-4-turbo-2024-04-09": {
            "rating": 1258.4695466639669,
            "rating_q975": 1265.73131882972,
            "rating_q025": 1251.2077744982137
        },
        "o1-mini": {
            "rating": 1257.0107309035761,
            "rating_q975": 1263.939453471595,
            "rating_q025": 1250.0820083355572
        },
        "gpt-4o-mini-2024-07-18": {
            "rating": 1253.717654241787,
            "rating_q975": 1259.9558353245134,
            "rating_q025": 1247.4794731590605
        },
        "hunyuan-turbos-20250226": {
            "rating": 1253.3918023467295,
            "rating_q975": 1279.032937418765,
            "rating_q025": 1227.750667274694
        },
        "llama-4-maverick-17b-128e-instruct": {
            "rating": 1252.7643588497565,
            "rating_q975": 1260.249476523482,
            "rating_q025": 1245.279241176031
        },
        "gemini-1.5-pro-001": {
            "rating": 1251.851040802917,
            "rating_q975": 1259.4305787013752,
            "rating_q025": 1244.2715029044587
        },
        "gemini-1.5-flash-002": {
            "rating": 1251.6829417666233,
            "rating_q975": 1259.651484085673,
            "rating_q025": 1243.7143994475737
        },
        "mistral-small-3.1-24b-instruct-2503": {
            "rating": 1251.3837559126198,
            "rating_q975": 1259.406038117388,
            "rating_q025": 1243.3614737078515
        },
        "llama-3.1-405b-instruct-fp8": {
            "rating": 1250.3391151246465,
            "rating_q975": 1257.4020660562194,
            "rating_q025": 1243.2761641930736
        },
        "glm-4-plus": {
            "rating": 1250.2711112025036,
            "rating_q975": 1260.1510924629695,
            "rating_q025": 1240.3911299420377
        },
        "llama-3.1-nemotron-70b-instruct": {
            "rating": 1249.4250191185497,
            "rating_q975": 1268.0865182082368,
            "rating_q025": 1230.7635200288626
        },
        "llama-4-scout-17b-16e-instruct": {
            "rating": 1246.199870777246,
            "rating_q975": 1254.6320602927372,
            "rating_q025": 1237.7676812617547
        },
        "magistral-medium-2506": {
            "rating": 1245.3911030723439,
            "rating_q975": 1258.6777146224827,
            "rating_q025": 1232.104491522205
        },
        "qwen2.5-plus-1127": {
            "rating": 1244.8072530649447,
            "rating_q975": 1257.7011473902521,
            "rating_q025": 1231.9133587396373
        },
        "gpt-4.1-nano-2025-04-14": {
            "rating": 1244.0487813202421,
            "rating_q975": 1261.3459539279818,
            "rating_q025": 1226.7516087125025
        },
        "gpt-4-1106-preview": {
            "rating": 1243.0706905423035,
            "rating_q975": 1250.6591743648798,
            "rating_q025": 1235.4822067197272
        },
        "mistral-large-2407": {
            "rating": 1242.2291239078893,
            "rating_q975": 1250.246074612735,
            "rating_q025": 1234.2121732030437
        },
        "llama-3.3-70b-instruct": {
            "rating": 1242.0463801823503,
            "rating_q975": 1248.0828200366648,
            "rating_q025": 1236.0099403280358
        },
        "llama-3.1-405b-instruct-bf16": {
            "rating": 1241.174860942872,
            "rating_q975": 1248.2273796529475,
            "rating_q025": 1234.1223422327967
        },
        "llama-3.1-tulu-3-70b": {
            "rating": 1240.7018557675883,
            "rating_q975": 1263.180996764625,
            "rating_q025": 1218.2227147705516
        },
        "qwen-max-0919": {
            "rating": 1240.5146682867694,
            "rating_q975": 1252.1781056843292,
            "rating_q025": 1228.8512308892095
        },
        "claude-3-5-sonnet-20240620": {
            "rating": 1239.1862758554912,
            "rating_q975": 1246.2547473030995,
            "rating_q025": 1232.1178044078829
        },
        "gpt-4-0125-preview": {
            "rating": 1237.5096241793678,
            "rating_q975": 1245.271243177147,
            "rating_q025": 1229.7480051815887
        },
        "gemma-3-4b-it": {
            "rating": 1233.603771207344,
            "rating_q975": 1254.102735377426,
            "rating_q025": 1213.104807037262
        },
        "grok-2-mini-2024-08-13": {
            "rating": 1233.259454408666,
            "rating_q975": 1240.305945558171,
            "rating_q025": 1226.212963259161
        },
        "athene-70b-0725": {
            "rating": 1232.7060721737214,
            "rating_q975": 1243.1421057181446,
            "rating_q025": 1222.2700386292981
        },
        "mistral-large-2411": {
            "rating": 1230.7174509352317,
            "rating_q975": 1238.8375385459995,
            "rating_q025": 1222.597363324464
        },
        "deepseek-v2.5": {
            "rating": 1230.53457941841,
            "rating_q975": 1240.3961136752218,
            "rating_q025": 1220.673045161598
        },
        "llama-3.1-70b-instruct": {
            "rating": 1230.4579364480705,
            "rating_q975": 1237.5821085031928,
            "rating_q025": 1223.3337643929483
        },
        "athene-v2-chat": {
            "rating": 1228.8465628615677,
            "rating_q975": 1237.629165901304,
            "rating_q025": 1220.0639598218313
        },
        "mercury": {
            "rating": 1225.415521333356,
            "rating_q975": 1257.8757174092864,
            "rating_q025": 1192.9553252574258
        },
        "olmo-2-0325-32b-instruct": {
            "rating": 1224.1351530643033,
            "rating_q975": 1247.5179369611324,
            "rating_q025": 1200.7523691674742
        },
        "command-r-plus-08-2024": {
            "rating": 1223.388317100159,
            "rating_q975": 1237.9594247901825,
            "rating_q025": 1208.8172094101353
        },
        "hunyuan-large-vision": {
            "rating": 1223.2834391589358,
            "rating_q975": 1243.155952521619,
            "rating_q025": 1203.4109257962527
        },
        "hunyuan-standard-2025-02-10": {
            "rating": 1222.6958106458505,
            "rating_q975": 1244.6341904155188,
            "rating_q025": 1200.7574308761823
        },
        "claude-3-5-haiku-20241022": {
            "rating": 1222.4669940059007,
            "rating_q975": 1228.089374477995,
            "rating_q025": 1216.8446135338063
        },
        "claude-3-opus-20240229": {
            "rating": 1220.4375949193995,
            "rating_q975": 1226.2500345558847,
            "rating_q025": 1214.6251552829144
        },
        "gpt-oss-20b": {
            "rating": 1219.926632367884,
            "rating_q975": 1234.4946480936899,
            "rating_q025": 1205.358616642078
        },
        "jamba-1.5-large": {
            "rating": 1218.5023378087753,
            "rating_q975": 1233.8633280884264,
            "rating_q025": 1203.1413475291242
        },
        "gemma-2-9b-it-simpo": {
            "rating": 1215.012995871195,
            "rating_q975": 1229.0895840276435,
            "rating_q025": 1200.9364077147466
        },
        "gemma-2-27b-it": {
            "rating": 1213.0247735224384,
            "rating_q975": 1219.1873851542853,
            "rating_q025": 1206.8621618905916
        },
        "qwen2.5-72b-instruct": {
            "rating": 1211.5922029930375,
            "rating_q975": 1219.4048882565748,
            "rating_q025": 1203.7795177295002
        },
        "amazon-nova-pro-v1.0": {
            "rating": 1210.0107742885662,
            "rating_q975": 1218.4411345090598,
            "rating_q025": 1201.5804140680725
        },
        "gemini-1.5-flash-001": {
            "rating": 1208.2530539319382,
            "rating_q975": 1216.040465497329,
            "rating_q025": 1200.4656423665474
        },
        "nemotron-4-340b-instruct": {
            "rating": 1208.0816352921647,
            "rating_q975": 1219.4089561774267,
            "rating_q025": 1196.7543144069027
        },
        "reka-core-20240904": {
            "rating": 1207.4282424468524,
            "rating_q975": 1224.385150684486,
            "rating_q025": 1190.4713342092189
        },
        "llama-3-70b-instruct": {
            "rating": 1195.6748029104667,
            "rating_q975": 1202.70871056257,
            "rating_q025": 1188.6408952583633
        },
        "llama-3.1-nemotron-51b-instruct": {
            "rating": 1190.8623810111656,
            "rating_q975": 1214.8212403274351,
            "rating_q025": 1166.903521694896
        },
        "command-r-plus": {
            "rating": 1189.9748582890986,
            "rating_q975": 1198.130780823099,
            "rating_q025": 1181.8189357550982
        },
        "glm-4-0520": {
            "rating": 1185.9034248858288,
            "rating_q975": 1200.3425030172111,
            "rating_q025": 1171.4643467544465
        },
        "gemini-1.5-flash-8b-001": {
            "rating": 1185.4516157101773,
            "rating_q975": 1193.6741890687524,
            "rating_q025": 1177.2290423516022
        },
        "gemma-2-9b-it": {
            "rating": 1185.3260795873907,
            "rating_q975": 1192.097378339919,
            "rating_q025": 1178.5547808348624
        },
        "gpt-4-0314": {
            "rating": 1184.8438169403134,
            "rating_q975": 1194.4697977931758,
            "rating_q025": 1175.2178360874511
        },
        "mistral-small-24b-instruct-2501": {
            "rating": 1184.4047877400712,
            "rating_q975": 1195.7341975663846,
            "rating_q025": 1173.0753779137578
        },
        "c4ai-aya-expanse-32b": {
            "rating": 1183.9953343460656,
            "rating_q975": 1193.0195378141755,
            "rating_q025": 1174.9711308779558
        },
        "gpt-4-0613": {
            "rating": 1180.566264080353,
            "rating_q975": 1188.5689060553318,
            "rating_q025": 1172.5636221053742
        },
        "reka-flash-20240904": {
            "rating": 1177.3993271738864,
            "rating_q975": 1194.0379944718934,
            "rating_q025": 1160.7606598758794
        },
        "amazon-nova-lite-v1.0": {
            "rating": 1176.327961411504,
            "rating_q975": 1186.174282450722,
            "rating_q025": 1166.481640372286
        },
        "claude-3-sonnet-20240229": {
            "rating": 1171.6935005803716,
            "rating_q975": 1179.4384153419817,
            "rating_q025": 1163.9485858187616
        },
        "qwen2-72b-instruct": {
            "rating": 1166.0199352134084,
            "rating_q975": 1175.0356820688617,
            "rating_q025": 1157.0041883579552
        },
        "amazon-nova-micro-v1.0": {
            "rating": 1163.4856392777642,
            "rating_q975": 1173.4381011903363,
            "rating_q025": 1153.5331773651922
        },
        "command-r-08-2024": {
            "rating": 1162.8478917621928,
            "rating_q975": 1176.965322391972,
            "rating_q025": 1148.7304611324137
        },
        "phi-4": {
            "rating": 1162.1141334784884,
            "rating_q975": 1170.9692547199618,
            "rating_q025": 1153.259012237015
        },
        "llama-3.1-tulu-3-8b": {
            "rating": 1161.1170148817714,
            "rating_q975": 1184.1030491710694,
            "rating_q025": 1138.1309805924734
        },
        "jamba-1.5-mini": {
            "rating": 1158.4253299683087,
            "rating_q975": 1173.5450991954233,
            "rating_q025": 1143.305560741194
        },
        "hunyuan-standard-256k": {
            "rating": 1153.4067893302363,
            "rating_q975": 1182.4920056862495,
            "rating_q025": 1124.321572974223
        },
        "claude-3-haiku-20240307": {
            "rating": 1152.2256857563023,
            "rating_q975": 1159.2930944406926,
            "rating_q025": 1145.158277071912
        },
        "mistral-large-2402": {
            "rating": 1151.2740611578597,
            "rating_q975": 1160.1282183652772,
            "rating_q025": 1142.4199039504422
        },
        "c4ai-aya-expanse-8b": {
            "rating": 1150.7208294106206,
            "rating_q975": 1164.3047742112994,
            "rating_q025": 1137.1368846099417
        },
        "qwen2.5-coder-32b-instruct": {
            "rating": 1150.607093182216,
            "rating_q975": 1169.17124695621,
            "rating_q025": 1132.0429394082219
        },
        "llama-3.1-8b-instruct": {
            "rating": 1145.2961597136755,
            "rating_q975": 1152.9685468668672,
            "rating_q025": 1137.6237725604838
        },
        "command-r": {
            "rating": 1142.660560667256,
            "rating_q975": 1151.7787755714824,
            "rating_q025": 1133.5423457630297
        },
        "ministral-8b-2410": {
            "rating": 1141.2988418183604,
            "rating_q975": 1161.6789502483389,
            "rating_q025": 1120.918733388382
        },
        "mixtral-8x22b-instruct-v0.1": {
            "rating": 1139.4769671465451,
            "rating_q975": 1148.2667807458931,
            "rating_q025": 1130.687153547197
        },
        "qwen1.5-110b-chat": {
            "rating": 1139.0899726822863,
            "rating_q975": 1150.0426261716564,
            "rating_q025": 1128.1373191929163
        },
        "mistral-medium": {
            "rating": 1138.0124401416715,
            "rating_q975": 1148.621097115161,
            "rating_q025": 1127.403783168182
        },
        "reka-flash-21b-20240226-online": {
            "rating": 1134.5265515878452,
            "rating_q975": 1148.6368862832078,
            "rating_q025": 1120.4162168924827
        },
        "llama-3-8b-instruct": {
            "rating": 1132.106453866441,
            "rating_q975": 1139.7490491778306,
            "rating_q025": 1124.4638585550513
        },
        "zephyr-orpo-141b-A35b-v0.1": {
            "rating": 1128.634777069713,
            "rating_q975": 1151.7498765379282,
            "rating_q025": 1105.5196776014977
        },
        "gemma-2-2b-it": {
            "rating": 1127.3082939507544,
            "rating_q975": 1134.8062431349865,
            "rating_q025": 1119.8103447665223
        },
        "qwen1.5-72b-chat": {
            "rating": 1125.714825254122,
            "rating_q975": 1135.6464194719613,
            "rating_q025": 1115.7832310362826
        },
        "deepseek-coder-v2": {
            "rating": 1122.7924709193012,
            "rating_q975": 1135.4236492627088,
            "rating_q025": 1110.1612925758936
        },
        "yi-1.5-34b-chat": {
            "rating": 1120.9897444483788,
            "rating_q975": 1131.5156687346603,
            "rating_q025": 1110.4638201620974
        },
        "tulu-2-dpo-70b": {
            "rating": 1116.1040735287058,
            "rating_q975": 1136.297431062476,
            "rating_q025": 1095.9107159949356
        },
        "qwq-32b-preview": {
            "rating": 1115.5474969812199,
            "rating_q975": 1141.9182148241937,
            "rating_q025": 1089.176779138246
        },
        "wizardlm-70b": {
            "rating": 1112.8537878546538,
            "rating_q975": 1130.3657011760909,
            "rating_q025": 1095.3418745332167
        },
        "granite-3.1-8b-instruct": {
            "rating": 1111.4715930106472,
            "rating_q975": 1136.6459869826858,
            "rating_q025": 1086.2971990386086
        },
        "yi-34b-chat": {
            "rating": 1107.0915411519304,
            "rating_q975": 1120.4092023316057,
            "rating_q025": 1093.7738799722551
        },
        "mixtral-8x7b-instruct-v0.1": {
            "rating": 1105.7899711976227,
            "rating_q975": 1114.048311954385,
            "rating_q025": 1097.5316304408602
        },
        "granite-3.1-2b-instruct": {
            "rating": 1105.2261243008647,
            "rating_q975": 1129.3123982666928,
            "rating_q025": 1081.1398503350367
        },
        "internlm2_5-20b-chat": {
            "rating": 1103.515759474707,
            "rating_q975": 1119.198533971748,
            "rating_q025": 1087.832984977666
        },
        "vicuna-33b": {
            "rating": 1103.4747758375665,
            "rating_q975": 1115.4926210448473,
            "rating_q025": 1091.4569306302858
        },
        "reka-flash-21b-20240226": {
            "rating": 1101.6422432835093,
            "rating_q975": 1113.347258750295,
            "rating_q025": 1089.9372278167236
        },
        "gemini-pro-dev-api": {
            "rating": 1099.993109196218,
            "rating_q975": 1113.9787054782462,
            "rating_q025": 1086.0075129141899
        },
        "dbrx-instruct-preview": {
            "rating": 1099.2652511177293,
            "rating_q975": 1110.607233515504,
            "rating_q025": 1087.9232687199546
        },
        "openchat-3.5": {
            "rating": 1096.960181050828,
            "rating_q975": 1114.481091671843,
            "rating_q025": 1079.439270429813
        },
        "gpt-3.5-turbo-0125": {
            "rating": 1089.3191117716647,
            "rating_q975": 1097.759623576238,
            "rating_q025": 1080.8785999670913
        },
        "gemini-pro": {
            "rating": 1085.5649892979982,
            "rating_q975": 1106.248525585881,
            "rating_q025": 1064.8814530101154
        },
        "starling-lm-7b-beta": {
            "rating": 1085.4032189000268,
            "rating_q975": 1100.068706927913,
            "rating_q025": 1070.7377308721407
        },
        "llama-3.2-3b-instruct": {
            "rating": 1084.2309151963298,
            "rating_q975": 1101.8916128392375,
            "rating_q025": 1066.570217553422
        },
        "starling-lm-7b-alpha": {
            "rating": 1083.0592111872893,
            "rating_q975": 1098.4363694216427,
            "rating_q025": 1067.682052952936
        },
        "phi-3-medium-4k-instruct": {
            "rating": 1082.2729840640059,
            "rating_q975": 1092.6076643508097,
            "rating_q025": 1071.938303777202
        },
        "qwen1.5-32b-chat": {
            "rating": 1081.6717733970836,
            "rating_q975": 1093.7413732231987,
            "rating_q025": 1069.6021735709685
        },
        "wizardlm-13b": {
            "rating": 1075.633724581701,
            "rating_q975": 1094.3002380365506,
            "rating_q025": 1056.9672111268515
        },
        "openchat-3.5-0106": {
            "rating": 1074.800738575668,
            "rating_q975": 1089.3220084130844,
            "rating_q025": 1060.2794687382516
        },
        "openhermes-2.5-mistral-7b": {
            "rating": 1074.5237055263237,
            "rating_q975": 1095.7836611825153,
            "rating_q025": 1053.2637498701322
        },
        "guanaco-33b": {
            "rating": 1073.2922646544635,
            "rating_q975": 1102.8420113324814,
            "rating_q025": 1043.7425179764455
        },
        "llama2-70b-steerlm-chat": {
            "rating": 1069.68522147779,
            "rating_q975": 1094.577217633079,
            "rating_q025": 1044.793225322501
        },
        "snowflake-arctic-instruct": {
            "rating": 1069.5578235101977,
            "rating_q975": 1081.3870363214185,
            "rating_q025": 1057.728610698977
        },
        "qwen1.5-14b-chat": {
            "rating": 1069.3214354510533,
            "rating_q975": 1082.9790076382412,
            "rating_q025": 1055.6638632638653
        },
        "nous-hermes-2-mixtral-8x7b-dpo": {
            "rating": 1067.2693499044085,
            "rating_q975": 1091.214410292779,
            "rating_q025": 1043.324289516038
        },
        "llama-2-70b-chat": {
            "rating": 1064.9360113520006,
            "rating_q975": 1074.8755759544306,
            "rating_q025": 1054.9964467495706
        },
        "zephyr-7b-beta": {
            "rating": 1063.2021083669586,
            "rating_q975": 1079.2932592299899,
            "rating_q025": 1047.1109575039272
        },
        "granite-3.0-8b-instruct": {
            "rating": 1062.2472148916825,
            "rating_q975": 1082.3121626938314,
            "rating_q025": 1042.1822670895335
        },
        "deepseek-llm-67b-chat": {
            "rating": 1062.2173564522568,
            "rating_q975": 1084.0554862019246,
            "rating_q025": 1040.379226702589
        },
        "falcon-180b-chat": {
            "rating": 1059.0378325494512,
            "rating_q975": 1097.8802545946742,
            "rating_q025": 1020.1954105042283
        },
        "solar-10.7b-instruct-v1.0": {
            "rating": 1058.9958853360154,
            "rating_q975": 1083.8236137471845,
            "rating_q025": 1034.1681569248462
        },
        "mistral-7b-instruct-v0.2": {
            "rating": 1058.5105495927155,
            "rating_q975": 1070.6780515341422,
            "rating_q025": 1046.3430476512888
        },
        "phi-3-small-8k-instruct": {
            "rating": 1056.4196909992856,
            "rating_q975": 1068.7913845574242,
            "rating_q025": 1044.0479974411471
        },
        "mpt-30b-chat": {
            "rating": 1055.6637350525848,
            "rating_q975": 1085.1097637234839,
            "rating_q025": 1026.2177063816857
        },
        "gemma-1.1-7b-it": {
            "rating": 1051.122720833289,
            "rating_q975": 1062.4141199334356,
            "rating_q025": 1039.8313217331422
        },
        "dolphin-2.2.1-mistral-7b": {
            "rating": 1050.3461132476102,
            "rating_q975": 1084.7455802687107,
            "rating_q025": 1015.9466462265098
        },
        "zephyr-7b-alpha": {
            "rating": 1048.9422449685562,
            "rating_q975": 1081.656092125443,
            "rating_q025": 1016.2283978116694
        },
        "llama-2-13b-chat": {
            "rating": 1048.4082903409972,
            "rating_q975": 1060.8827448062416,
            "rating_q025": 1035.9338358757527
        },
        "granite-3.0-2b-instruct": {
            "rating": 1038.247245056081,
            "rating_q975": 1058.749664822995,
            "rating_q025": 1017.7448252891671
        },
        "gpt-3.5-turbo-1106": {
            "rating": 1033.1563472089506,
            "rating_q975": 1048.5679273282472,
            "rating_q025": 1017.744767089654
        },
        "phi-3-mini-4k-instruct-june-2024": {
            "rating": 1031.457424290728,
            "rating_q975": 1045.2106509572297,
            "rating_q025": 1017.7041976242265
        },
        "vicuna-13b": {
            "rating": 1031.4203188818196,
            "rating_q975": 1044.02374235559,
            "rating_q025": 1018.8168954080493
        },
        "qwen1.5-7b-chat": {
            "rating": 1030.5852140078828,
            "rating_q975": 1053.1939743632165,
            "rating_q025": 1007.9764536525489
        },
        "llama-3.2-1b-instruct": {
            "rating": 1025.1547997141583,
            "rating_q975": 1043.6119750489013,
            "rating_q025": 1006.6976243794155
        },
        "llama-2-7b-chat": {
            "rating": 1020.317794750974,
            "rating_q975": 1033.9217914541675,
            "rating_q025": 1006.7137980477805
        },
        "phi-3-mini-4k-instruct": {
            "rating": 1020.0278763384902,
            "rating_q975": 1032.1113821142242,
            "rating_q025": 1007.9443705627563
        },
        "vicuna-7b": {
            "rating": 1017.1047206372253,
            "rating_q975": 1034.816655201455,
            "rating_q025": 999.3927860729958
        },
        "codellama-34b-instruct": {
            "rating": 1015.0062052684946,
            "rating_q975": 1031.991356733126,
            "rating_q025": 998.0210538038632
        },
        "stripedhyena-nous-7b": {
            "rating": 1011.9787840486554,
            "rating_q975": 1033.4354184365432,
            "rating_q025": 990.5221496607677
        },
        "smollm2-1.7b-instruct": {
            "rating": 1011.7502607498632,
            "rating_q975": 1045.2140209406086,
            "rating_q025": 978.2865005591176
        },
        "phi-3-mini-128k-instruct": {
            "rating": 1009.9289663654099,
            "rating_q975": 1023.7880676304777,
            "rating_q025": 996.0698651003421
        },
        "gemma-7b-it": {
            "rating": 1002.0545020035823,
            "rating_q975": 1019.760749066308,
            "rating_q025": 984.3482549408567
        },
        "mistral-7b-instruct": {
            "rating": 1000.0983269301846,
            "rating_q975": 1017.6840622654453,
            "rating_q025": 982.512591594924
        },
        "qwen-14b-chat": {
            "rating": 997.0980824732318,
            "rating_q975": 1018.5916699221408,
            "rating_q025": 975.6044950243228
        },
        "palm-2": {
            "rating": 992.737054250544,
            "rating_q975": 1010.2915758720966,
            "rating_q025": 975.1825326289915
        },
        "olmo-7b-instruct": {
            "rating": 991.4805937185499,
            "rating_q975": 1012.3387754293879,
            "rating_q025": 970.622412007712
        },
        "gemma-1.1-2b-it": {
            "rating": 980.7617226741454,
            "rating_q975": 997.4707824378892,
            "rating_q025": 964.0526629104016
        },
        "gemma-2b-it": {
            "rating": 968.1622114224315,
            "rating_q975": 991.0164324587514,
            "rating_q025": 945.3079903861116
        },
        "qwen1.5-4b-chat": {
            "rating": 953.1829844811391,
            "rating_q975": 971.4620686905913,
            "rating_q025": 934.9039002716869
        },
        "koala-13b": {
            "rating": 945.3214842110896,
            "rating_q975": 965.9642572509866,
            "rating_q025": 924.6787111711925
        },
        "gpt4all-13b-snoozy": {
            "rating": 941.8440309948323,
            "rating_q975": 980.3023907201117,
            "rating_q025": 903.385671269553
        },
        "alpaca-13b": {
            "rating": 932.2837426359538,
            "rating_q975": 954.6091342660125,
            "rating_q025": 909.9583510058951
        },
        "chatglm3-6b": {
            "rating": 929.041672817815,
            "rating_q975": 952.935623779084,
            "rating_q025": 905.1477218565459
        },
        "mpt-7b-chat": {
            "rating": 928.6547379896624,
            "rating_q975": 952.9811121760977,
            "rating_q025": 904.3283638032271
        },
        "chatglm2-6b": {
            "rating": 922.39224738178,
            "rating_q975": 951.092584513723,
            "rating_q025": 893.691910249837
        },
        "RWKV-4-Raven-14B": {
            "rating": 903.7804679929824,
            "rating_q975": 926.0384356454587,
            "rating_q025": 881.5225003405061
        },
        "oasst-pythia-12b": {
            "rating": 885.5762885272244,
            "rating_q975": 906.8953522656898,
            "rating_q025": 864.257224788759
        },
        "fastchat-t5-3b": {
            "rating": 860.5259298775907,
            "rating_q975": 885.2368740817533,
            "rating_q025": 835.814985673428
        },
        "chatglm-6b": {
            "rating": 841.425467514945,
            "rating_q975": 866.2149969133671,
            "rating_q025": 816.6359381165229
        },
        "stablelm-tuned-alpha-7b": {
            "rating": 823.4771217334678,
            "rating_q975": 852.1973865029486,
            "rating_q025": 794.756856963987
        },
        "dolly-v2-12b": {
            "rating": 809.4519107339854,
            "rating_q975": 837.0441353551951,
            "rating_q025": 781.8596861127758
        },
        "llama-13b": {
            "rating": 785.2206303146743,
            "rating_q975": 817.0711635744135,
            "rating_q025": 753.3700970549351
        }
    },
    "industry_legal_and_government": {
        "gemini-3-pro": {
            "rating": 1492.805813397903,
            "rating_q975": 1511.8002518237595,
            "rating_q025": 1473.8113749720465
        },
        "gemini-2.5-pro": {
            "rating": 1490.1059576358364,
            "rating_q975": 1499.7357646987562,
            "rating_q025": 1480.4761505729166
        },
        "mistral-large-3": {
            "rating": 1475.003432921951,
            "rating_q975": 1503.4152257728474,
            "rating_q025": 1446.5916400710544
        },
        "grok-4.1-thinking": {
            "rating": 1472.438425139535,
            "rating_q975": 1490.9555062179047,
            "rating_q025": 1453.9213440611652
        },
        "claude-opus-4-5-20251101": {
            "rating": 1459.7413299062507,
            "rating_q975": 1482.288004876081,
            "rating_q025": 1437.1946549364204
        },
        "deepseek-v3.1-terminus-thinking": {
            "rating": 1457.3237673478168,
            "rating_q975": 1492.8818797807912,
            "rating_q025": 1421.7656549148423
        },
        "ernie-5.0-preview-1103": {
            "rating": 1456.090014509597,
            "rating_q975": 1482.8426158488248,
            "rating_q025": 1429.3374131703692
        },
        "grok-4.1": {
            "rating": 1454.7344353848957,
            "rating_q975": 1473.352738429025,
            "rating_q025": 1436.1161323407664
        },
        "gpt-5.1-high": {
            "rating": 1452.1801238528658,
            "rating_q975": 1472.158536420892,
            "rating_q025": 1432.2017112848396
        },
        "mistral-medium-2508": {
            "rating": 1450.1449489581996,
            "rating_q975": 1461.9755313001178,
            "rating_q025": 1438.3143666162814
        },
        "chatgpt-4o-latest-20250326": {
            "rating": 1446.2389791722223,
            "rating_q975": 1456.5951590382788,
            "rating_q025": 1435.882799306166
        },
        "gpt-5.1": {
            "rating": 1445.0638552927473,
            "rating_q975": 1464.5407204330763,
            "rating_q025": 1425.5869901524184
        },
        "qwen3-vl-235b-a22b-instruct": {
            "rating": 1441.9165109973553,
            "rating_q975": 1466.8422907948832,
            "rating_q025": 1416.9907311998275
        },
        "glm-4.6": {
            "rating": 1441.7791626308938,
            "rating_q975": 1457.5416454150504,
            "rating_q025": 1426.0166798467371
        },
        "glm-4.5": {
            "rating": 1439.9102485828582,
            "rating_q975": 1455.5738405730322,
            "rating_q025": 1424.2466565926843
        },
        "grok-3-preview-02-24": {
            "rating": 1439.1255538261612,
            "rating_q975": 1452.966316244289,
            "rating_q025": 1425.2847914080335
        },
        "deepseek-v3.2": {
            "rating": 1438.839182160333,
            "rating_q975": 1467.7940490920616,
            "rating_q025": 1409.8843152286042
        },
        "claude-opus-4-5-20251101-thinking-32k": {
            "rating": 1438.1402938532103,
            "rating_q975": 1460.9985090321668,
            "rating_q025": 1415.2820786742539
        },
        "qwen3-next-80b-a3b-instruct": {
            "rating": 1436.3048917802244,
            "rating_q975": 1452.3962756786036,
            "rating_q025": 1420.213507881845
        },
        "gpt-4.5-preview-2025-02-27": {
            "rating": 1433.9905242706946,
            "rating_q975": 1456.4425726567129,
            "rating_q025": 1411.5384758846762
        },
        "claude-sonnet-4-5-20250929": {
            "rating": 1432.6163179144733,
            "rating_q975": 1448.6683575712525,
            "rating_q025": 1416.564278257694
        },
        "qwen3-max-preview": {
            "rating": 1432.4791602174441,
            "rating_q975": 1447.113401184927,
            "rating_q025": 1417.8449192499613
        },
        "gpt-5-chat": {
            "rating": 1431.8088859217662,
            "rating_q975": 1445.8560899713473,
            "rating_q025": 1417.7616818721851
        },
        "gemini-2.5-flash": {
            "rating": 1431.4170359842965,
            "rating_q975": 1440.7964266826048,
            "rating_q025": 1422.0376452859882
        },
        "o3-2025-04-16": {
            "rating": 1430.8158737118754,
            "rating_q975": 1441.1724928424992,
            "rating_q025": 1420.4592545812516
        },
        "grok-4-0709": {
            "rating": 1430.1704375330482,
            "rating_q975": 1442.0261282124804,
            "rating_q025": 1418.314746853616
        },
        "deepseek-v3.2-thinking": {
            "rating": 1424.7797702358766,
            "rating_q975": 1453.308798388664,
            "rating_q025": 1396.2507420830893
        },
        "gpt-5-high": {
            "rating": 1423.8572677521863,
            "rating_q975": 1438.0536009097834,
            "rating_q025": 1409.6609345945892
        },
        "grok-4-fast-reasoning": {
            "rating": 1423.5661802695804,
            "rating_q975": 1441.0143672443053,
            "rating_q025": 1406.1179932948555
        },
        "gemini-2.5-flash-preview-09-2025": {
            "rating": 1423.0230944768023,
            "rating_q975": 1437.3366574923086,
            "rating_q025": 1408.709531461296
        },
        "claude-sonnet-4-5-20250929-thinking-32k": {
            "rating": 1422.9571179284,
            "rating_q975": 1438.0318245085673,
            "rating_q025": 1407.8824113482328
        },
        "deepseek-v3.1": {
            "rating": 1421.8843252482302,
            "rating_q975": 1440.299476994235,
            "rating_q025": 1403.4691735022254
        },
        "claude-opus-4-1-20250805-thinking-16k": {
            "rating": 1419.7892872486552,
            "rating_q975": 1431.8800724247221,
            "rating_q025": 1407.6985020725883
        },
        "qwen3-235b-a22b-instruct-2507": {
            "rating": 1419.2485350959778,
            "rating_q975": 1430.442611800333,
            "rating_q025": 1408.0544583916226
        },
        "deepseek-r1-0528": {
            "rating": 1418.6452082908793,
            "rating_q975": 1434.8507795776686,
            "rating_q025": 1402.43963700409
        },
        "grok-4-fast-chat": {
            "rating": 1417.2796302863378,
            "rating_q975": 1444.6664315028652,
            "rating_q025": 1389.8928290698104
        },
        "deepseek-v3.1-thinking": {
            "rating": 1415.0690761509072,
            "rating_q975": 1435.761186299436,
            "rating_q025": 1394.3769660023784
        },
        "claude-opus-4-1-20250805": {
            "rating": 1415.0596959681939,
            "rating_q975": 1425.765387331312,
            "rating_q025": 1404.3540046050757
        },
        "deepseek-v3.2-exp-thinking": {
            "rating": 1415.0254812106275,
            "rating_q975": 1440.278216627383,
            "rating_q025": 1389.772745793872
        },
        "longcat-flash-chat": {
            "rating": 1414.9366182622423,
            "rating_q975": 1436.006580547652,
            "rating_q025": 1393.8666559768326
        },
        "deepseek-v3.1-terminus": {
            "rating": 1414.8198124207129,
            "rating_q975": 1449.712613682842,
            "rating_q025": 1379.9270111585838
        },
        "qwen3-235b-a22b-thinking-2507": {
            "rating": 1409.6277167559333,
            "rating_q975": 1433.7092691367166,
            "rating_q025": 1385.54616437515
        },
        "grok-4-1-fast-reasoning": {
            "rating": 1409.4693529860797,
            "rating_q975": 1434.1697172548718,
            "rating_q025": 1384.7689887172876
        },
        "kimi-k2-thinking-turbo": {
            "rating": 1408.6048920860974,
            "rating_q975": 1428.068513054576,
            "rating_q025": 1389.1412711176188
        },
        "mai-1-preview": {
            "rating": 1406.4714315454905,
            "rating_q975": 1423.8256899502856,
            "rating_q025": 1389.1171731406955
        },
        "deepseek-v3.2-exp": {
            "rating": 1405.5191141933847,
            "rating_q975": 1426.8037498689935,
            "rating_q025": 1384.2344785177759
        },
        "kimi-k2-0905-preview": {
            "rating": 1404.871752582168,
            "rating_q975": 1426.1463326061582,
            "rating_q025": 1383.5971725581778
        },
        "qwen3-vl-235b-a22b-thinking": {
            "rating": 1404.6938698678414,
            "rating_q975": 1430.0830631181043,
            "rating_q025": 1379.3046766175785
        },
        "qwen3-max-2025-09-23": {
            "rating": 1403.6126670701349,
            "rating_q975": 1428.0862038003547,
            "rating_q025": 1379.139130339915
        },
        "gpt-4.1-2025-04-14": {
            "rating": 1400.3511645956441,
            "rating_q975": 1411.1982634162746,
            "rating_q025": 1389.5040657750137
        },
        "hunyuan-t1-20250711": {
            "rating": 1399.820167856184,
            "rating_q975": 1433.9787904929794,
            "rating_q025": 1365.6615452193887
        },
        "amazon-nova-experimental-chat-10-20": {
            "rating": 1392.3318690535912,
            "rating_q975": 1418.853745314045,
            "rating_q025": 1365.8099927931373
        },
        "qwen3-235b-a22b-no-thinking": {
            "rating": 1392.2053440492225,
            "rating_q975": 1404.2452564287398,
            "rating_q025": 1380.1654316697052
        },
        "grok-3-mini-high": {
            "rating": 1391.3158313379117,
            "rating_q975": 1408.49630564335,
            "rating_q025": 1374.1353570324734
        },
        "gemini-2.5-flash-lite-preview-09-2025-no-thinking": {
            "rating": 1389.7712956671503,
            "rating_q975": 1404.1002845498772,
            "rating_q025": 1375.4423067844234
        },
        "mistral-medium-2505": {
            "rating": 1387.2652717850558,
            "rating_q975": 1400.067663432433,
            "rating_q025": 1374.4628801376787
        },
        "qwen3-30b-a3b-instruct-2507": {
            "rating": 1385.5318941103678,
            "rating_q975": 1400.9525559211604,
            "rating_q025": 1370.1112322995752
        },
        "glm-4.5-air": {
            "rating": 1383.3590244720526,
            "rating_q975": 1397.0892836143846,
            "rating_q025": 1369.6287653297206
        },
        "gemma-3-12b-it": {
            "rating": 1381.8976267592689,
            "rating_q975": 1420.8227811511379,
            "rating_q025": 1342.9724723673999
        },
        "deepseek-v3-0324": {
            "rating": 1380.282993029151,
            "rating_q975": 1391.5729779510132,
            "rating_q025": 1368.9930081072887
        },
        "gemma-3-27b-it": {
            "rating": 1376.2497868703326,
            "rating_q975": 1387.708029309719,
            "rating_q025": 1364.7915444309463
        },
        "qwen2.5-max": {
            "rating": 1375.0881013636724,
            "rating_q975": 1388.7800185631725,
            "rating_q025": 1361.3961841641724
        },
        "gemini-2.0-flash-001": {
            "rating": 1374.7776171344153,
            "rating_q975": 1386.2348045522347,
            "rating_q025": 1363.320429716596
        },
        "gemini-2.5-flash-lite-preview-06-17-thinking": {
            "rating": 1374.236065485663,
            "rating_q975": 1387.2861804884722,
            "rating_q025": 1361.1859504828537
        },
        "gpt-5-mini-high": {
            "rating": 1372.5673641037708,
            "rating_q975": 1387.3719652755194,
            "rating_q025": 1357.7627629320223
        },
        "deepseek-r1": {
            "rating": 1371.8924077037732,
            "rating_q975": 1389.2950955492172,
            "rating_q025": 1354.4897198583292
        },
        "claude-opus-4-20250514": {
            "rating": 1371.742117938597,
            "rating_q975": 1383.2115432951946,
            "rating_q025": 1360.2726925819993
        },
        "claude-haiku-4-5-20251001": {
            "rating": 1371.5336168983742,
            "rating_q975": 1387.437383990443,
            "rating_q025": 1355.6298498063054
        },
        "grok-3-mini-beta": {
            "rating": 1370.3943151121975,
            "rating_q975": 1385.69061647632,
            "rating_q025": 1355.0980137480751
        },
        "hunyuan-turbos-20250416": {
            "rating": 1370.0072549611862,
            "rating_q975": 1391.1800854060198,
            "rating_q025": 1348.8344245163526
        },
        "o1-2024-12-17": {
            "rating": 1369.3957731244452,
            "rating_q975": 1384.7798833292295,
            "rating_q025": 1354.011662919661
        },
        "ling-flash-2.0": {
            "rating": 1369.3938841938398,
            "rating_q975": 1396.7071848834628,
            "rating_q025": 1342.0805835042167
        },
        "amazon-nova-experimental-chat-10-09": {
            "rating": 1365.7088429774692,
            "rating_q975": 1392.2538792216628,
            "rating_q025": 1339.1638067332756
        },
        "claude-opus-4-20250514-thinking-16k": {
            "rating": 1365.5052121740594,
            "rating_q975": 1378.1727782059816,
            "rating_q025": 1352.8376461421371
        },
        "glm-4-plus-0111": {
            "rating": 1363.2881472923275,
            "rating_q975": 1393.3048886764802,
            "rating_q025": 1333.2714059081748
        },
        "qwen3-next-80b-a3b-thinking": {
            "rating": 1361.576998841546,
            "rating_q975": 1381.8935566458251,
            "rating_q025": 1341.2604410372667
        },
        "qwen3-coder-480b-a35b-instruct": {
            "rating": 1357.740631979334,
            "rating_q975": 1373.6515994039685,
            "rating_q025": 1341.8296645546995
        },
        "qwen3-235b-a22b": {
            "rating": 1357.637311330641,
            "rating_q975": 1371.6979071411636,
            "rating_q025": 1343.5767155201186
        },
        "kimi-k2-0711-preview": {
            "rating": 1355.7913039687512,
            "rating_q975": 1370.3584944031672,
            "rating_q025": 1341.2241135343352
        },
        "gpt-oss-120b": {
            "rating": 1353.9218652493641,
            "rating_q975": 1367.9334223812684,
            "rating_q025": 1339.9103081174599
        },
        "nova-2-lite": {
            "rating": 1352.144388388796,
            "rating_q975": 1381.9468843095974,
            "rating_q025": 1322.3418924679945
        },
        "o4-mini-2025-04-16": {
            "rating": 1351.428783719317,
            "rating_q975": 1363.0611620927793,
            "rating_q025": 1339.7964053458545
        },
        "minimax-m2": {
            "rating": 1351.2670921538818,
            "rating_q975": 1379.9940833951307,
            "rating_q025": 1322.5401009126329
        },
        "qwen-plus-0125": {
            "rating": 1349.7536556738166,
            "rating_q975": 1378.3753604413644,
            "rating_q025": 1321.131950906269
        },
        "step-1o-turbo-202506": {
            "rating": 1348.9619757353319,
            "rating_q975": 1371.9328669903052,
            "rating_q025": 1325.9910844803585
        },
        "o1-preview": {
            "rating": 1347.9822906398292,
            "rating_q975": 1361.9056086094458,
            "rating_q025": 1334.0589726702126
        },
        "gpt-4.1-mini-2025-04-14": {
            "rating": 1347.0544388548994,
            "rating_q975": 1359.1554831723936,
            "rating_q025": 1334.9533945374053
        },
        "command-a-03-2025": {
            "rating": 1346.6766769349365,
            "rating_q975": 1357.1466901279891,
            "rating_q025": 1336.2066637418839
        },
        "mistral-small-2506": {
            "rating": 1346.11153684374,
            "rating_q975": 1363.1168390731498,
            "rating_q025": 1329.10623461433
        },
        "nvidia-llama-3.3-nemotron-super-49b-v1.5": {
            "rating": 1345.992695791213,
            "rating_q975": 1382.4802675401843,
            "rating_q025": 1309.5051240422417
        },
        "gemini-2.0-flash-lite-preview-02-05": {
            "rating": 1345.5572736049608,
            "rating_q975": 1360.7070913531088,
            "rating_q025": 1330.4074558568127
        },
        "step-3": {
            "rating": 1345.3088283770312,
            "rating_q975": 1373.825456425811,
            "rating_q025": 1316.7922003282515
        },
        "deepseek-v3": {
            "rating": 1342.6772618631994,
            "rating_q975": 1358.7932971515152,
            "rating_q025": 1326.5612265748837
        },
        "minimax-m1": {
            "rating": 1341.94923239088,
            "rating_q975": 1354.2002904694168,
            "rating_q025": 1329.6981743123433
        },
        "claude-sonnet-4-20250514": {
            "rating": 1341.041495788609,
            "rating_q975": 1353.2327004702083,
            "rating_q025": 1328.8502911070095
        },
        "qwq-32b": {
            "rating": 1337.9998782876442,
            "rating_q975": 1352.2443698188686,
            "rating_q025": 1323.7553867564197
        },
        "step-2-16k-exp-202412": {
            "rating": 1337.844086626527,
            "rating_q975": 1371.4629363400154,
            "rating_q025": 1304.2252369130388
        },
        "claude-sonnet-4-20250514-thinking-32k": {
            "rating": 1336.5483239933094,
            "rating_q975": 1349.6484293835613,
            "rating_q025": 1323.4482186030575
        },
        "glm-4.5v": {
            "rating": 1333.7937867216401,
            "rating_q975": 1368.4953086679945,
            "rating_q025": 1299.0922647752857
        },
        "o3-mini-high": {
            "rating": 1329.860766046916,
            "rating_q975": 1347.6570658007524,
            "rating_q025": 1312.0644662930797
        },
        "gemini-1.5-pro-002": {
            "rating": 1329.3755950509167,
            "rating_q975": 1339.859974093822,
            "rating_q025": 1318.8912160080113
        },
        "yi-lightning": {
            "rating": 1329.3127397721107,
            "rating_q975": 1343.6524653684983,
            "rating_q025": 1314.9730141757232
        },
        "gemma-3-4b-it": {
            "rating": 1328.8071520611925,
            "rating_q975": 1364.9942275558114,
            "rating_q025": 1292.6200765665735
        },
        "grok-2-2024-08-13": {
            "rating": 1326.8883091790112,
            "rating_q975": 1337.2308815355461,
            "rating_q025": 1316.5457368224763
        },
        "qwen3-32b": {
            "rating": 1325.9149869890812,
            "rating_q975": 1358.452077040167,
            "rating_q025": 1293.3778969379953
        },
        "qwen3-30b-a3b": {
            "rating": 1317.5480953418178,
            "rating_q975": 1331.3460502527028,
            "rating_q025": 1303.7501404309328
        },
        "o1-mini": {
            "rating": 1316.6389885147055,
            "rating_q975": 1327.6709418725623,
            "rating_q025": 1305.6070351568487
        },
        "gpt-4o-2024-05-13": {
            "rating": 1315.2264199381007,
            "rating_q975": 1324.5227906443301,
            "rating_q025": 1305.9300492318712
        },
        "glm-4-plus": {
            "rating": 1310.7271891276619,
            "rating_q975": 1325.335134448553,
            "rating_q025": 1296.1192438067708
        },
        "gemma-3n-e4b-it": {
            "rating": 1310.6688041381703,
            "rating_q975": 1326.152077416343,
            "rating_q025": 1295.1855308599977
        },
        "qwen2.5-plus-1127": {
            "rating": 1308.7506085092004,
            "rating_q975": 1332.4582969974444,
            "rating_q025": 1285.0429200209564
        },
        "ring-flash-2.0": {
            "rating": 1308.4746612746126,
            "rating_q975": 1336.9517841518552,
            "rating_q025": 1279.99753839737
        },
        "gpt-4o-mini-2024-07-18": {
            "rating": 1306.0290276585283,
            "rating_q975": 1316.09844412838,
            "rating_q025": 1295.9596111886767
        },
        "gemini-advanced-0514": {
            "rating": 1305.9364692340278,
            "rating_q975": 1319.5918819566543,
            "rating_q025": 1292.2810565114012
        },
        "o3-mini": {
            "rating": 1304.6522023260857,
            "rating_q975": 1314.6492101023953,
            "rating_q025": 1294.655194549776
        },
        "llama-3.1-405b-instruct-fp8": {
            "rating": 1304.6278023197865,
            "rating_q975": 1315.499775248977,
            "rating_q025": 1293.755829390596
        },
        "gemini-1.5-flash-002": {
            "rating": 1303.9848068167125,
            "rating_q975": 1316.8053611916864,
            "rating_q025": 1291.1642524417387
        },
        "llama-3.1-nemotron-70b-instruct": {
            "rating": 1303.9028148081147,
            "rating_q975": 1330.3137209288122,
            "rating_q025": 1277.4919086874172
        },
        "gpt-5-nano-high": {
            "rating": 1303.5969925930067,
            "rating_q975": 1330.9546095025314,
            "rating_q025": 1276.239375683482
        },
        "claude-3-7-sonnet-20250219-thinking-32k": {
            "rating": 1303.4656279314972,
            "rating_q975": 1315.7927881489486,
            "rating_q025": 1291.1384677140459
        },
        "llama-3.1-405b-instruct-bf16": {
            "rating": 1302.8006108321415,
            "rating_q975": 1315.103713821039,
            "rating_q025": 1290.497507843244
        },
        "athene-v2-chat": {
            "rating": 1300.4890008506034,
            "rating_q975": 1315.806069627855,
            "rating_q025": 1285.1719320733516
        },
        "claude-3-7-sonnet-20250219": {
            "rating": 1300.1632780332768,
            "rating_q975": 1312.5730483626605,
            "rating_q025": 1287.753507703893
        },
        "gpt-4.1-nano-2025-04-14": {
            "rating": 1299.0127021546327,
            "rating_q975": 1327.4412250036607,
            "rating_q025": 1270.5841793056047
        },
        "athene-70b-0725": {
            "rating": 1294.1855992483343,
            "rating_q975": 1312.9401577221345,
            "rating_q025": 1275.431040774534
        },
        "grok-2-mini-2024-08-13": {
            "rating": 1293.6213109576472,
            "rating_q975": 1304.8533764000445,
            "rating_q025": 1282.38924551525
        },
        "hunyuan-standard-2025-02-10": {
            "rating": 1290.6287419156738,
            "rating_q975": 1324.855657404294,
            "rating_q025": 1256.4018264270535
        },
        "qwen2.5-72b-instruct": {
            "rating": 1289.2345292298955,
            "rating_q975": 1301.4191758211734,
            "rating_q025": 1277.0498826386176
        },
        "llama-4-scout-17b-16e-instruct": {
            "rating": 1287.1906755616515,
            "rating_q975": 1301.06099432013,
            "rating_q025": 1273.320356803173
        },
        "llama-4-maverick-17b-128e-instruct": {
            "rating": 1286.9978482047268,
            "rating_q975": 1299.1051946802068,
            "rating_q025": 1274.8905017292468
        },
        "olmo-3-32b-think": {
            "rating": 1286.43887408815,
            "rating_q975": 1328.5337753521387,
            "rating_q025": 1244.3439728241613
        },
        "llama-3.3-70b-instruct": {
            "rating": 1286.2131919952274,
            "rating_q975": 1296.640233245272,
            "rating_q025": 1275.7861507451828
        },
        "llama-3.1-70b-instruct": {
            "rating": 1285.2423641660891,
            "rating_q975": 1296.3547352663886,
            "rating_q025": 1274.1299930657897
        },
        "deepseek-v2.5": {
            "rating": 1285.2373080518232,
            "rating_q975": 1300.1507691522932,
            "rating_q025": 1270.3238469513533
        },
        "gpt-oss-20b": {
            "rating": 1284.7266019273527,
            "rating_q975": 1308.0874464567876,
            "rating_q025": 1261.3657573979178
        },
        "qwen-max-0919": {
            "rating": 1284.2141998793904,
            "rating_q975": 1301.8326609780327,
            "rating_q025": 1266.5957387807482
        },
        "amazon-nova-pro-v1.0": {
            "rating": 1282.5427730476563,
            "rating_q975": 1298.417761850522,
            "rating_q025": 1266.6677842447905
        },
        "hunyuan-large-2025-02-10": {
            "rating": 1281.6488753389212,
            "rating_q975": 1317.9725312715705,
            "rating_q025": 1245.325219406272
        },
        "claude-3-5-sonnet-20241022": {
            "rating": 1280.9602844856413,
            "rating_q975": 1289.2364145666697,
            "rating_q025": 1272.6841544046129
        },
        "deepseek-v2.5-1210": {
            "rating": 1280.0533759996497,
            "rating_q975": 1309.3456753295857,
            "rating_q025": 1250.7610766697137
        },
        "mistral-large-2407": {
            "rating": 1277.8337142709654,
            "rating_q975": 1289.5222997119467,
            "rating_q025": 1266.145128829984
        },
        "gpt-4o-2024-08-06": {
            "rating": 1276.5326730877816,
            "rating_q975": 1288.401587251998,
            "rating_q025": 1264.6637589235652
        },
        "mistral-large-2411": {
            "rating": 1275.816373764846,
            "rating_q975": 1290.4699779301513,
            "rating_q025": 1261.1627695995408
        },
        "reka-core-20240904": {
            "rating": 1274.8200657137822,
            "rating_q975": 1303.5128191342326,
            "rating_q025": 1246.127312293332
        },
        "mistral-small-3.1-24b-instruct-2503": {
            "rating": 1273.185990720307,
            "rating_q975": 1286.2931669132772,
            "rating_q025": 1260.0788145273368
        },
        "gemini-1.5-pro-001": {
            "rating": 1271.3352625765028,
            "rating_q975": 1282.4066197969228,
            "rating_q025": 1260.263905356083
        },
        "gemma-2-9b-it-simpo": {
            "rating": 1269.75697211012,
            "rating_q975": 1294.054604718116,
            "rating_q025": 1245.4593395021238
        },
        "command-r-plus-08-2024": {
            "rating": 1269.7004086259044,
            "rating_q975": 1293.0193454061289,
            "rating_q025": 1246.38147184568
        },
        "claude-3-5-sonnet-20240620": {
            "rating": 1267.348043514903,
            "rating_q975": 1277.532666297416,
            "rating_q025": 1257.1634207323903
        },
        "claude-3-opus-20240229": {
            "rating": 1265.9945417090476,
            "rating_q975": 1274.5319690954152,
            "rating_q025": 1257.45711432268
        },
        "gpt-4-turbo-2024-04-09": {
            "rating": 1265.6905360828882,
            "rating_q975": 1276.13749687863,
            "rating_q025": 1255.2435752871465
        },
        "jamba-1.5-large": {
            "rating": 1265.4883622753262,
            "rating_q975": 1292.5062931108864,
            "rating_q025": 1238.470431439766
        },
        "gpt-4-0125-preview": {
            "rating": 1262.6158365792703,
            "rating_q975": 1273.6629738949266,
            "rating_q025": 1251.568699263614
        },
        "qwen2.5-coder-32b-instruct": {
            "rating": 1258.2108687262084,
            "rating_q975": 1292.649234529308,
            "rating_q025": 1223.772502923109
        },
        "claude-3-5-haiku-20241022": {
            "rating": 1257.357119017655,
            "rating_q975": 1266.8585270930248,
            "rating_q025": 1247.855710942285
        },
        "llama-3.1-nemotron-51b-instruct": {
            "rating": 1256.179764585093,
            "rating_q975": 1292.244859826653,
            "rating_q025": 1220.1146693435328
        },
        "gpt-4-1106-preview": {
            "rating": 1250.2663115949715,
            "rating_q975": 1261.0643595422623,
            "rating_q025": 1239.4682636476807
        },
        "gemini-1.5-flash-8b-001": {
            "rating": 1249.2165297166284,
            "rating_q975": 1262.0789341018528,
            "rating_q025": 1236.354125331404
        },
        "c4ai-aya-expanse-32b": {
            "rating": 1249.1513979098625,
            "rating_q975": 1263.0956584489309,
            "rating_q025": 1235.207137370794
        },
        "gemini-1.5-flash-001": {
            "rating": 1248.8063674333182,
            "rating_q975": 1260.4103042091765,
            "rating_q025": 1237.20243065746
        },
        "nemotron-4-340b-instruct": {
            "rating": 1247.247950816945,
            "rating_q975": 1264.9823785144026,
            "rating_q025": 1229.5135231194872
        },
        "hunyuan-large-vision": {
            "rating": 1246.7308927385684,
            "rating_q975": 1278.1823105506444,
            "rating_q025": 1215.2794749264924
        },
        "command-r-plus": {
            "rating": 1246.3846248644732,
            "rating_q975": 1258.0956817832766,
            "rating_q025": 1234.6735679456697
        },
        "glm-4-0520": {
            "rating": 1245.4986153508848,
            "rating_q975": 1269.8763681739604,
            "rating_q025": 1221.1208625278093
        },
        "gemma-2-27b-it": {
            "rating": 1242.6931530290187,
            "rating_q975": 1252.3441279089736,
            "rating_q025": 1233.0421781490638
        },
        "phi-4": {
            "rating": 1241.6979108462538,
            "rating_q975": 1257.9840119274495,
            "rating_q025": 1225.411809765058
        },
        "amazon-nova-lite-v1.0": {
            "rating": 1238.7415617141082,
            "rating_q975": 1256.6946438419843,
            "rating_q025": 1220.7884795862321
        },
        "command-r-08-2024": {
            "rating": 1230.9841141248844,
            "rating_q975": 1254.8986501853535,
            "rating_q025": 1207.0695780644153
        },
        "llama-3-70b-instruct": {
            "rating": 1229.0852030692429,
            "rating_q975": 1239.091186010392,
            "rating_q025": 1219.0792201280938
        },
        "olmo-2-0325-32b-instruct": {
            "rating": 1228.9441960884958,
            "rating_q975": 1270.1060535524625,
            "rating_q025": 1187.782338624529
        },
        "magistral-medium-2506": {
            "rating": 1228.743124770397,
            "rating_q975": 1250.9276761690214,
            "rating_q025": 1206.5585733717724
        },
        "c4ai-aya-expanse-8b": {
            "rating": 1226.2807032158385,
            "rating_q975": 1251.0837604725245,
            "rating_q025": 1201.4776459591524
        },
        "jamba-1.5-mini": {
            "rating": 1224.9558337897524,
            "rating_q975": 1249.7837275725815,
            "rating_q025": 1200.1279400069234
        },
        "amazon-nova-micro-v1.0": {
            "rating": 1222.2053371732231,
            "rating_q975": 1240.5571035114476,
            "rating_q025": 1203.8535708349987
        },
        "mistral-small-24b-instruct-2501": {
            "rating": 1220.0998562912098,
            "rating_q975": 1240.6026500758196,
            "rating_q025": 1199.5970625066
        },
        "reka-flash-20240904": {
            "rating": 1218.482449583369,
            "rating_q975": 1247.9396818084942,
            "rating_q025": 1189.025217358244
        },
        "gemma-2-9b-it": {
            "rating": 1216.594430353342,
            "rating_q975": 1227.4631226564861,
            "rating_q025": 1205.7257380501978
        },
        "claude-3-sonnet-20240229": {
            "rating": 1215.0783465365726,
            "rating_q975": 1226.3054599804968,
            "rating_q025": 1203.8512330926483
        },
        "ministral-8b-2410": {
            "rating": 1212.7008952572678,
            "rating_q975": 1245.777234697839,
            "rating_q025": 1179.6245558166966
        },
        "command-r": {
            "rating": 1208.2168411367752,
            "rating_q975": 1221.3854018034854,
            "rating_q025": 1195.048280470065
        },
        "llama-3.1-8b-instruct": {
            "rating": 1207.414794307203,
            "rating_q975": 1219.0875568234214,
            "rating_q025": 1195.7420317909846
        },
        "yi-1.5-34b-chat": {
            "rating": 1197.8207061706353,
            "rating_q975": 1213.8424007457425,
            "rating_q025": 1181.799011595528
        },
        "reka-flash-21b-20240226-online": {
            "rating": 1195.5383926270056,
            "rating_q975": 1215.9630166259146,
            "rating_q025": 1175.1137686280965
        },
        "qwen2-72b-instruct": {
            "rating": 1194.4821869314949,
            "rating_q975": 1207.939236447399,
            "rating_q025": 1181.0251374155907
        },
        "gpt-4-0314": {
            "rating": 1192.6169737236157,
            "rating_q975": 1206.4178770768074,
            "rating_q025": 1178.816070370424
        },
        "claude-3-haiku-20240307": {
            "rating": 1192.5487519558396,
            "rating_q975": 1202.635429963464,
            "rating_q025": 1182.4620739482152
        },
        "qwen1.5-110b-chat": {
            "rating": 1189.347154814238,
            "rating_q975": 1206.0411687229766,
            "rating_q025": 1172.6531409054992
        },
        "reka-flash-21b-20240226": {
            "rating": 1182.010177787184,
            "rating_q975": 1199.4149836671143,
            "rating_q025": 1164.6053719072536
        },
        "mistral-large-2402": {
            "rating": 1181.8123435443101,
            "rating_q975": 1194.7632907278596,
            "rating_q025": 1168.8613963607606
        },
        "qwen1.5-72b-chat": {
            "rating": 1175.0326644807346,
            "rating_q975": 1189.6322487989185,
            "rating_q025": 1160.4330801625508
        },
        "granite-3.1-8b-instruct": {
            "rating": 1171.965333188531,
            "rating_q975": 1213.0923386474474,
            "rating_q025": 1130.8383277296148
        },
        "mistral-medium": {
            "rating": 1171.416147004696,
            "rating_q975": 1187.4359287815248,
            "rating_q025": 1155.3963652278674
        },
        "gemma-2-2b-it": {
            "rating": 1171.0208090358544,
            "rating_q975": 1183.1577855400785,
            "rating_q025": 1158.8838325316303
        },
        "llama-3-8b-instruct": {
            "rating": 1169.0982842261756,
            "rating_q975": 1180.089198683827,
            "rating_q025": 1158.1073697685242
        },
        "gemini-pro-dev-api": {
            "rating": 1167.1493906382816,
            "rating_q975": 1188.1327863274464,
            "rating_q025": 1146.1659949491168
        },
        "mixtral-8x22b-instruct-v0.1": {
            "rating": 1166.3803419727926,
            "rating_q975": 1179.3806742116708,
            "rating_q025": 1153.3800097339144
        },
        "deepseek-coder-v2": {
            "rating": 1163.6028738973405,
            "rating_q975": 1183.688404451981,
            "rating_q025": 1143.5173433427
        },
        "hunyuan-standard-256k": {
            "rating": 1163.1294707619932,
            "rating_q975": 1206.0850702137166,
            "rating_q025": 1120.1738713102698
        },
        "gpt-4-0613": {
            "rating": 1155.8476124321476,
            "rating_q975": 1167.5951212594398,
            "rating_q025": 1144.1001036048553
        },
        "internlm2_5-20b-chat": {
            "rating": 1152.8398670877264,
            "rating_q975": 1175.7398741078412,
            "rating_q025": 1129.9398600676116
        },
        "starling-lm-7b-beta": {
            "rating": 1152.1784506424929,
            "rating_q975": 1172.9915302920294,
            "rating_q025": 1131.3653709929563
        },
        "qwq-32b-preview": {
            "rating": 1143.427504659595,
            "rating_q975": 1184.9797189035817,
            "rating_q025": 1101.875290415608
        },
        "qwen1.5-32b-chat": {
            "rating": 1142.2336049789346,
            "rating_q975": 1159.8143435244062,
            "rating_q025": 1124.652866433463
        },
        "yi-34b-chat": {
            "rating": 1138.9610752772878,
            "rating_q975": 1160.6877375620024,
            "rating_q025": 1117.2344129925732
        },
        "tulu-2-dpo-70b": {
            "rating": 1135.7349122106127,
            "rating_q975": 1165.9657567133468,
            "rating_q025": 1105.5040677078787
        },
        "zephyr-orpo-141b-A35b-v0.1": {
            "rating": 1135.3348455289859,
            "rating_q975": 1173.0894835746199,
            "rating_q025": 1097.5802074833518
        },
        "mixtral-8x7b-instruct-v0.1": {
            "rating": 1133.3713540151107,
            "rating_q975": 1145.5127288913689,
            "rating_q025": 1121.2299791388525
        },
        "phi-3-medium-4k-instruct": {
            "rating": 1132.075143016602,
            "rating_q975": 1147.9648915635757,
            "rating_q025": 1116.1853944696281
        },
        "wizardlm-70b": {
            "rating": 1130.5165904379437,
            "rating_q975": 1159.7846122193234,
            "rating_q025": 1101.248568656564
        },
        "starling-lm-7b-alpha": {
            "rating": 1123.5363381413576,
            "rating_q975": 1150.4035440392015,
            "rating_q025": 1096.6691322435138
        },
        "qwen1.5-14b-chat": {
            "rating": 1120.711127667149,
            "rating_q975": 1140.0751343075337,
            "rating_q025": 1101.3471210267642
        },
        "gpt-3.5-turbo-0125": {
            "rating": 1119.4695497373991,
            "rating_q975": 1131.5565867162943,
            "rating_q025": 1107.382512758504
        },
        "llama-3.2-3b-instruct": {
            "rating": 1116.6550845478982,
            "rating_q975": 1144.595961962208,
            "rating_q025": 1088.7142071335884
        },
        "llama-2-70b-chat": {
            "rating": 1115.0464584466827,
            "rating_q975": 1130.144530400377,
            "rating_q025": 1099.9483864929882
        },
        "openchat-3.5": {
            "rating": 1114.2789677538462,
            "rating_q975": 1142.8614964654378,
            "rating_q025": 1085.6964390422547
        },
        "gemini-pro": {
            "rating": 1107.860479896773,
            "rating_q975": 1141.1876778716398,
            "rating_q025": 1074.5332819219063
        },
        "openchat-3.5-0106": {
            "rating": 1106.643280761173,
            "rating_q975": 1130.574360986733,
            "rating_q025": 1082.712200535613
        },
        "qwen1.5-7b-chat": {
            "rating": 1105.9609749590188,
            "rating_q975": 1146.0641374019453,
            "rating_q025": 1065.8578125160923
        },
        "dbrx-instruct-preview": {
            "rating": 1105.8028246716476,
            "rating_q975": 1122.2199439890974,
            "rating_q025": 1089.3857053541979
        },
        "phi-3-small-8k-instruct": {
            "rating": 1104.230627485459,
            "rating_q975": 1122.0198610720988,
            "rating_q025": 1086.4413938988193
        },
        "wizardlm-13b": {
            "rating": 1101.1254154934147,
            "rating_q975": 1133.6005136246238,
            "rating_q025": 1068.6503173622057
        },
        "openhermes-2.5-mistral-7b": {
            "rating": 1100.9074808894588,
            "rating_q975": 1136.863204095145,
            "rating_q025": 1064.9517576837727
        },
        "mistral-7b-instruct-v0.2": {
            "rating": 1100.1890613943267,
            "rating_q975": 1120.1592449354828,
            "rating_q025": 1080.2188778531706
        },
        "vicuna-33b": {
            "rating": 1100.070893354703,
            "rating_q975": 1119.1838385067454,
            "rating_q025": 1080.9579482026606
        },
        "zephyr-7b-beta": {
            "rating": 1096.4878907292418,
            "rating_q975": 1122.1137460904163,
            "rating_q025": 1070.8620353680674
        },
        "gemma-1.1-7b-it": {
            "rating": 1095.3906770218987,
            "rating_q975": 1112.3009319252342,
            "rating_q025": 1078.4804221185632
        },
        "snowflake-arctic-instruct": {
            "rating": 1092.8013726263619,
            "rating_q975": 1110.8432807649358,
            "rating_q025": 1074.759464487788
        },
        "deepseek-llm-67b-chat": {
            "rating": 1090.6072501576002,
            "rating_q975": 1125.7804626702741,
            "rating_q025": 1055.4340376449263
        },
        "granite-3.0-2b-instruct": {
            "rating": 1087.612239584239,
            "rating_q975": 1118.537497613754,
            "rating_q025": 1056.6869815547238
        },
        "granite-3.0-8b-instruct": {
            "rating": 1085.582171671491,
            "rating_q975": 1118.7870487564562,
            "rating_q025": 1052.377294586526
        },
        "solar-10.7b-instruct-v1.0": {
            "rating": 1083.7639784275489,
            "rating_q975": 1123.3531477648667,
            "rating_q025": 1044.174809090231
        },
        "llama-2-13b-chat": {
            "rating": 1081.2674480622468,
            "rating_q975": 1101.8916061968478,
            "rating_q025": 1060.6432899276458
        },
        "phi-3-mini-4k-instruct": {
            "rating": 1072.385065027067,
            "rating_q975": 1091.2105803348886,
            "rating_q025": 1053.5595497192453
        },
        "llama-3.2-1b-instruct": {
            "rating": 1072.1323455507945,
            "rating_q975": 1101.215306921342,
            "rating_q025": 1043.049384180247
        },
        "phi-3-mini-4k-instruct-june-2024": {
            "rating": 1069.4886462663717,
            "rating_q975": 1094.0447055265383,
            "rating_q025": 1044.932587006205
        },
        "llama-2-7b-chat": {
            "rating": 1066.8482511601883,
            "rating_q975": 1089.3419659920132,
            "rating_q025": 1044.3545363283633
        },
        "codellama-34b-instruct": {
            "rating": 1065.4914299569966,
            "rating_q975": 1098.0278893231794,
            "rating_q025": 1032.954970590814
        },
        "vicuna-13b": {
            "rating": 1058.0024341767546,
            "rating_q975": 1079.922000758817,
            "rating_q025": 1036.0828675946923
        },
        "gpt-3.5-turbo-1106": {
            "rating": 1057.6289804002586,
            "rating_q975": 1080.3099534312666,
            "rating_q025": 1034.9480073692505
        },
        "qwen-14b-chat": {
            "rating": 1051.9444391717007,
            "rating_q975": 1090.1306680243397,
            "rating_q025": 1013.7582103190617
        },
        "olmo-7b-instruct": {
            "rating": 1048.1481189097694,
            "rating_q975": 1083.1347327424264,
            "rating_q025": 1013.1615050771125
        },
        "gemma-7b-it": {
            "rating": 1046.152646627998,
            "rating_q975": 1074.8882715408809,
            "rating_q025": 1017.417021715115
        },
        "vicuna-7b": {
            "rating": 1033.3928738043885,
            "rating_q975": 1068.7878693256355,
            "rating_q025": 997.9978782831415
        },
        "mistral-7b-instruct": {
            "rating": 1026.3416430357627,
            "rating_q975": 1055.6464497953893,
            "rating_q025": 997.0368362761359
        },
        "gemma-2b-it": {
            "rating": 1021.0609750273143,
            "rating_q975": 1059.569818467867,
            "rating_q025": 982.5521315867616
        },
        "qwen1.5-4b-chat": {
            "rating": 1011.6424392567917,
            "rating_q975": 1043.7703461758942,
            "rating_q025": 979.514532337689
        },
        "phi-3-mini-128k-instruct": {
            "rating": 1007.8748962654649,
            "rating_q975": 1029.6013952995625,
            "rating_q025": 986.1483972313674
        },
        "palm-2": {
            "rating": 1006.8814819819736,
            "rating_q975": 1038.9335319630095,
            "rating_q025": 974.8294320009378
        },
        "stripedhyena-nous-7b": {
            "rating": 1001.6781892582744,
            "rating_q975": 1037.1798856786274,
            "rating_q025": 966.1764928379215
        },
        "gemma-1.1-2b-it": {
            "rating": 996.1864697173646,
            "rating_q975": 1024.2910713302988,
            "rating_q025": 968.0818681044304
        },
        "RWKV-4-Raven-14B": {
            "rating": 977.0945750180308,
            "rating_q975": 1026.2553652640338,
            "rating_q025": 927.9337847720278
        },
        "chatglm3-6b": {
            "rating": 974.6915302377229,
            "rating_q975": 1016.4197932106769,
            "rating_q025": 932.9632672647689
        },
        "koala-13b": {
            "rating": 964.9933052247823,
            "rating_q975": 1005.96759264315,
            "rating_q025": 924.0190178064145
        },
        "oasst-pythia-12b": {
            "rating": 923.578218053879,
            "rating_q975": 964.8260802310092,
            "rating_q025": 882.3303558767489
        },
        "alpaca-13b": {
            "rating": 912.2081039133554,
            "rating_q975": 956.3439834639692,
            "rating_q025": 868.0722243627417
        },
        "fastchat-t5-3b": {
            "rating": 900.0645722101397,
            "rating_q975": 948.4999515149667,
            "rating_q025": 851.6291929053126
        },
        "chatglm-6b": {
            "rating": 896.6959034243544,
            "rating_q975": 944.7191281661387,
            "rating_q025": 848.67267868257
        }
    },
    "industry_life_and_physical_and_social_science": {
        "gemini-3-pro": {
            "rating": 1503.5312136075013,
            "rating_q975": 1515.9831159235334,
            "rating_q025": 1491.0793112914691
        },
        "gemini-2.5-pro": {
            "rating": 1491.221482679173,
            "rating_q975": 1497.5028165625906,
            "rating_q025": 1484.9401487957555
        },
        "glm-4.6": {
            "rating": 1461.1084574639963,
            "rating_q975": 1470.7946035595337,
            "rating_q025": 1451.4223113684588
        },
        "qwen3-max-preview": {
            "rating": 1460.0928423256164,
            "rating_q975": 1469.6164803826828,
            "rating_q025": 1450.56920426855
        },
        "grok-4.1": {
            "rating": 1456.3894159350275,
            "rating_q975": 1468.4874613792447,
            "rating_q025": 1444.2913704908103
        },
        "mistral-large-3": {
            "rating": 1456.1429914941377,
            "rating_q975": 1474.548271518938,
            "rating_q025": 1437.7377114693375
        },
        "deepseek-v3.1-terminus": {
            "rating": 1455.7166485342623,
            "rating_q975": 1480.390228560252,
            "rating_q025": 1431.0430685082727
        },
        "gpt-5.1-high": {
            "rating": 1455.314420304189,
            "rating_q975": 1468.3890378111837,
            "rating_q025": 1442.2398027971944
        },
        "ernie-5.0-preview-1103": {
            "rating": 1455.2972227554726,
            "rating_q975": 1474.3113053180016,
            "rating_q025": 1436.2831401929436
        },
        "mistral-medium-2508": {
            "rating": 1455.0211827879189,
            "rating_q975": 1462.7438977689576,
            "rating_q025": 1447.2984678068801
        },
        "qwen3-vl-235b-a22b-instruct": {
            "rating": 1450.8908041858174,
            "rating_q975": 1467.195238291977,
            "rating_q025": 1434.5863700796579
        },
        "deepseek-v3.2-thinking": {
            "rating": 1450.6992895510257,
            "rating_q975": 1468.9820511659807,
            "rating_q025": 1432.4165279360707
        },
        "grok-4.1-thinking": {
            "rating": 1450.40245954483,
            "rating_q975": 1462.3046935054194,
            "rating_q025": 1438.5002255842405
        },
        "deepseek-v3.1-terminus-thinking": {
            "rating": 1449.8609964064588,
            "rating_q975": 1475.04322153929,
            "rating_q025": 1424.6787712736275
        },
        "glm-4.5": {
            "rating": 1447.6284666542376,
            "rating_q975": 1457.3431525708743,
            "rating_q025": 1437.913780737601
        },
        "claude-opus-4-5-20251101": {
            "rating": 1445.345869910743,
            "rating_q975": 1460.4454566444774,
            "rating_q025": 1430.2462831770085
        },
        "claude-sonnet-4-5-20250929": {
            "rating": 1444.284016439952,
            "rating_q975": 1454.6047060544452,
            "rating_q025": 1433.9633268254588
        },
        "chatgpt-4o-latest-20250326": {
            "rating": 1443.039752297875,
            "rating_q975": 1449.3990903732479,
            "rating_q025": 1436.6804142225023
        },
        "deepseek-v3.2-exp-thinking": {
            "rating": 1442.611620574833,
            "rating_q975": 1457.8364344164295,
            "rating_q025": 1427.3868067332367
        },
        "gpt-5.1": {
            "rating": 1440.7467888028698,
            "rating_q975": 1453.3517790048832,
            "rating_q025": 1428.1417986008564
        },
        "grok-4-0709": {
            "rating": 1440.1241976525832,
            "rating_q975": 1447.6936783507772,
            "rating_q025": 1432.5547169543893
        },
        "amazon-nova-experimental-chat-10-20": {
            "rating": 1439.7420552864667,
            "rating_q975": 1456.1986591043367,
            "rating_q025": 1423.2854514685966
        },
        "deepseek-v3.1": {
            "rating": 1439.4830093872142,
            "rating_q975": 1451.8019263830336,
            "rating_q025": 1427.164092391395
        },
        "grok-3-preview-02-24": {
            "rating": 1438.5651010914235,
            "rating_q975": 1446.5575591744657,
            "rating_q025": 1430.5726430083812
        },
        "qwen3-235b-a22b-instruct-2507": {
            "rating": 1438.5556249133601,
            "rating_q975": 1445.768511525651,
            "rating_q025": 1431.3427383010692
        },
        "gemini-2.5-flash-preview-09-2025": {
            "rating": 1438.3285132899487,
            "rating_q975": 1447.5509638927874,
            "rating_q025": 1429.10606268711
        },
        "claude-sonnet-4-5-20250929-thinking-32k": {
            "rating": 1436.2505054527746,
            "rating_q975": 1445.796599413476,
            "rating_q025": 1426.7044114920732
        },
        "qwen3-next-80b-a3b-instruct": {
            "rating": 1435.8614768585878,
            "rating_q975": 1446.1122409277552,
            "rating_q025": 1425.6107127894204
        },
        "qwen3-235b-a22b-thinking-2507": {
            "rating": 1435.259921969804,
            "rating_q975": 1450.345128370293,
            "rating_q025": 1420.1747155693151
        },
        "claude-opus-4-5-20251101-thinking-32k": {
            "rating": 1435.1689112960248,
            "rating_q975": 1450.6919658921522,
            "rating_q025": 1419.6458566998974
        },
        "o3-2025-04-16": {
            "rating": 1433.1319038469524,
            "rating_q975": 1439.8696630958013,
            "rating_q025": 1426.3941445981034
        },
        "deepseek-v3.1-thinking": {
            "rating": 1432.6690438346748,
            "rating_q975": 1446.2207273885028,
            "rating_q025": 1419.1173602808467
        },
        "gemini-2.5-flash": {
            "rating": 1432.0417726925887,
            "rating_q975": 1438.2556459405157,
            "rating_q025": 1425.8278994446616
        },
        "hunyuan-t1-20250711": {
            "rating": 1431.4871315456191,
            "rating_q975": 1453.632442714644,
            "rating_q025": 1409.3418203765943
        },
        "deepseek-v3.2-exp": {
            "rating": 1431.3178879078416,
            "rating_q975": 1444.9437495865711,
            "rating_q025": 1417.6920262291121
        },
        "deepseek-v3.2": {
            "rating": 1429.389066420828,
            "rating_q975": 1447.559716571466,
            "rating_q025": 1411.21841627019
        },
        "deepseek-r1-0528": {
            "rating": 1428.240815276568,
            "rating_q975": 1438.556053415226,
            "rating_q025": 1417.9255771379098
        },
        "longcat-flash-chat": {
            "rating": 1427.1078698634822,
            "rating_q975": 1441.3241079915358,
            "rating_q025": 1412.8916317354285
        },
        "grok-4-fast-reasoning": {
            "rating": 1426.9973752477783,
            "rating_q975": 1437.943296229312,
            "rating_q025": 1416.0514542662447
        },
        "gpt-4.5-preview-2025-02-27": {
            "rating": 1424.168478288088,
            "rating_q975": 1435.9213454555681,
            "rating_q025": 1412.4156111206078
        },
        "grok-4-1-fast-reasoning": {
            "rating": 1424.0030504259012,
            "rating_q975": 1439.6734584142496,
            "rating_q025": 1408.3326424375527
        },
        "grok-4-fast-chat": {
            "rating": 1421.438832347254,
            "rating_q975": 1440.1396679678958,
            "rating_q025": 1402.7379967266122
        },
        "claude-opus-4-1-20250805-thinking-16k": {
            "rating": 1419.7123175916095,
            "rating_q975": 1427.467177445324,
            "rating_q025": 1411.9574577378949
        },
        "gpt-5-chat": {
            "rating": 1419.500425285691,
            "rating_q975": 1428.140275376752,
            "rating_q025": 1410.8605751946302
        },
        "qwen3-max-2025-09-23": {
            "rating": 1418.8493979934353,
            "rating_q975": 1434.2062517147815,
            "rating_q025": 1403.4925442720892
        },
        "hunyuan-vision-1.5-thinking": {
            "rating": 1417.5470267445348,
            "rating_q975": 1448.9962962453644,
            "rating_q025": 1386.0977572437052
        },
        "claude-opus-4-1-20250805": {
            "rating": 1417.1479137387578,
            "rating_q975": 1424.307741200951,
            "rating_q025": 1409.9880862765644
        },
        "kimi-k2-thinking-turbo": {
            "rating": 1416.536301303201,
            "rating_q975": 1428.6049279736535,
            "rating_q025": 1404.4676746327486
        },
        "qwen3-vl-235b-a22b-thinking": {
            "rating": 1415.1356675059053,
            "rating_q975": 1431.815502621273,
            "rating_q025": 1398.4558323905376
        },
        "mai-1-preview": {
            "rating": 1410.4587367909387,
            "rating_q975": 1421.3543925968886,
            "rating_q025": 1399.5630809849888
        },
        "glm-4.5-air": {
            "rating": 1410.3279513162881,
            "rating_q975": 1418.9295758896023,
            "rating_q025": 1401.726326742974
        },
        "qwen3-235b-a22b-no-thinking": {
            "rating": 1406.5220980680745,
            "rating_q975": 1414.6293557787233,
            "rating_q025": 1398.4148403574256
        },
        "gpt-5-high": {
            "rating": 1406.3655059587297,
            "rating_q975": 1415.1234906858203,
            "rating_q025": 1397.607521231639
        },
        "hunyuan-turbos-20250416": {
            "rating": 1400.3000057869965,
            "rating_q975": 1413.4828471936391,
            "rating_q025": 1387.1171643803539
        },
        "gemini-2.5-flash-lite-preview-09-2025-no-thinking": {
            "rating": 1398.926217901287,
            "rating_q975": 1408.079507614379,
            "rating_q025": 1389.7729281881948
        },
        "qwen3-30b-a3b-instruct-2507": {
            "rating": 1394.8171722909497,
            "rating_q975": 1404.5893026059007,
            "rating_q025": 1385.0450419759986
        },
        "claude-haiku-4-5-20251001": {
            "rating": 1390.7495699024132,
            "rating_q975": 1400.587246699505,
            "rating_q025": 1380.9118931053215
        },
        "kimi-k2-0905-preview": {
            "rating": 1388.5995167348492,
            "rating_q975": 1403.0333061090369,
            "rating_q025": 1374.1657273606615
        },
        "nova-2-lite": {
            "rating": 1387.6168113530503,
            "rating_q975": 1407.3877035374605,
            "rating_q025": 1367.84591916864
        },
        "ling-flash-2.0": {
            "rating": 1387.5756117733047,
            "rating_q975": 1405.6005801924541,
            "rating_q025": 1369.5506433541552
        },
        "grok-3-mini-high": {
            "rating": 1386.8549162257548,
            "rating_q975": 1398.0369594763722,
            "rating_q025": 1375.6728729751374
        },
        "gemma-3-27b-it": {
            "rating": 1386.3244864523149,
            "rating_q975": 1393.3066127463444,
            "rating_q025": 1379.3423601582854
        },
        "gpt-4.1-2025-04-14": {
            "rating": 1385.492123929826,
            "rating_q975": 1392.4022941587614,
            "rating_q025": 1378.5819537008906
        },
        "qwen2.5-max": {
            "rating": 1385.2363454883528,
            "rating_q975": 1393.1229818172758,
            "rating_q025": 1377.3497091594297
        },
        "deepseek-v3-0324": {
            "rating": 1384.4824317377524,
            "rating_q975": 1391.5949606787785,
            "rating_q025": 1377.3699027967264
        },
        "gpt-oss-120b": {
            "rating": 1383.7214360910968,
            "rating_q975": 1392.6703365466915,
            "rating_q025": 1374.7725356355022
        },
        "qwen3-next-80b-a3b-thinking": {
            "rating": 1382.8542629052968,
            "rating_q975": 1395.6962102906816,
            "rating_q025": 1370.012315519912
        },
        "mistral-medium-2505": {
            "rating": 1381.5464612011629,
            "rating_q975": 1389.809477401128,
            "rating_q025": 1373.2834450011976
        },
        "deepseek-r1": {
            "rating": 1378.763355594718,
            "rating_q975": 1388.8953644741753,
            "rating_q025": 1368.6313467152606
        },
        "grok-3-mini-beta": {
            "rating": 1377.8294269659186,
            "rating_q975": 1387.4018208038165,
            "rating_q025": 1368.2570331280208
        },
        "qwen3-235b-a22b": {
            "rating": 1377.1780789606594,
            "rating_q975": 1386.0718289527572,
            "rating_q025": 1368.2843289685616
        },
        "gemini-2.5-flash-lite-preview-06-17-thinking": {
            "rating": 1376.67952993941,
            "rating_q975": 1385.124244705938,
            "rating_q025": 1368.234815172882
        },
        "qwen3-32b": {
            "rating": 1375.320251909433,
            "rating_q975": 1395.7553720478888,
            "rating_q025": 1354.885131770977
        },
        "gpt-5-mini-high": {
            "rating": 1375.1742974378813,
            "rating_q975": 1384.671810508383,
            "rating_q025": 1365.6767843673795
        },
        "o1-2024-12-17": {
            "rating": 1372.8198325686144,
            "rating_q975": 1381.485838831344,
            "rating_q025": 1364.1538263058849
        },
        "claude-opus-4-20250514-thinking-16k": {
            "rating": 1369.915591437897,
            "rating_q975": 1378.1630187092942,
            "rating_q025": 1361.6681641665
        },
        "gemma-3-12b-it": {
            "rating": 1368.5238731211573,
            "rating_q975": 1389.1799035200281,
            "rating_q025": 1347.8678427222865
        },
        "kimi-k2-0711-preview": {
            "rating": 1368.4248482193314,
            "rating_q975": 1377.6284093243412,
            "rating_q025": 1359.2212871143215
        },
        "minimax-m1": {
            "rating": 1368.1226907785535,
            "rating_q975": 1376.041763383138,
            "rating_q025": 1360.203618173969
        },
        "amazon-nova-experimental-chat-10-09": {
            "rating": 1366.3822838730941,
            "rating_q975": 1381.8037221598959,
            "rating_q025": 1350.9608455862924
        },
        "gemini-2.0-flash-001": {
            "rating": 1364.997816283988,
            "rating_q975": 1371.8985539954417,
            "rating_q025": 1358.0970785725342
        },
        "step-1o-turbo-202506": {
            "rating": 1364.780783335608,
            "rating_q975": 1379.2485589210664,
            "rating_q025": 1350.3130077501496
        },
        "nvidia-llama-3.3-nemotron-super-49b-v1.5": {
            "rating": 1364.1006151442707,
            "rating_q975": 1387.034685875281,
            "rating_q025": 1341.1665444132605
        },
        "claude-opus-4-20250514": {
            "rating": 1363.6250320226661,
            "rating_q975": 1371.359770144156,
            "rating_q025": 1355.8902939011762
        },
        "step-3": {
            "rating": 1359.4220013361075,
            "rating_q975": 1377.6283747502519,
            "rating_q025": 1341.2156279219632
        },
        "o4-mini-2025-04-16": {
            "rating": 1357.1867146397863,
            "rating_q975": 1364.467870743267,
            "rating_q025": 1349.9055585363055
        },
        "qwen-plus-0125": {
            "rating": 1356.4022217618524,
            "rating_q975": 1374.894754792577,
            "rating_q025": 1337.9096887311277
        },
        "glm-4-plus-0111": {
            "rating": 1353.9967919251403,
            "rating_q975": 1372.398166371517,
            "rating_q025": 1335.5954174787637
        },
        "o1-preview": {
            "rating": 1352.8697232117947,
            "rating_q975": 1361.7994214849846,
            "rating_q025": 1343.940024938605
        },
        "intellect-3": {
            "rating": 1352.1679674344591,
            "rating_q975": 1383.3136886365226,
            "rating_q025": 1321.0222462323957
        },
        "qwen3-coder-480b-a35b-instruct": {
            "rating": 1350.9611188489953,
            "rating_q975": 1360.8830084748188,
            "rating_q025": 1341.0392292231718
        },
        "qwq-32b": {
            "rating": 1349.7605104594593,
            "rating_q975": 1358.4817444979258,
            "rating_q025": 1341.0392764209928
        },
        "minimax-m2": {
            "rating": 1348.2658627724613,
            "rating_q975": 1366.4041292767918,
            "rating_q025": 1330.127596268131
        },
        "claude-sonnet-4-20250514-thinking-32k": {
            "rating": 1347.759643730462,
            "rating_q975": 1356.065465679755,
            "rating_q025": 1339.4538217811687
        },
        "mistral-small-2506": {
            "rating": 1345.5563818393357,
            "rating_q975": 1356.449003160713,
            "rating_q025": 1334.6637605179585
        },
        "o3-mini-high": {
            "rating": 1342.5299950908245,
            "rating_q975": 1352.8260807372878,
            "rating_q025": 1332.2339094443612
        },
        "claude-sonnet-4-20250514": {
            "rating": 1342.2022474932494,
            "rating_q975": 1350.2395712951322,
            "rating_q025": 1334.1649236913665
        },
        "ring-flash-2.0": {
            "rating": 1341.6082566167663,
            "rating_q975": 1359.5232543798413,
            "rating_q025": 1323.6932588536913
        },
        "command-a-03-2025": {
            "rating": 1339.8039360639664,
            "rating_q975": 1346.3712336333977,
            "rating_q025": 1333.236638494535
        },
        "llama-3.3-nemotron-49b-super-v1": {
            "rating": 1336.3002636689898,
            "rating_q975": 1364.6707030500722,
            "rating_q025": 1307.9298242879074
        },
        "deepseek-v3": {
            "rating": 1336.205233606825,
            "rating_q975": 1345.691543313494,
            "rating_q025": 1326.718923900156
        },
        "gemini-2.0-flash-lite-preview-02-05": {
            "rating": 1335.3343753382242,
            "rating_q975": 1344.192412897931,
            "rating_q025": 1326.4763377785173
        },
        "step-2-16k-exp-202412": {
            "rating": 1334.017559125939,
            "rating_q975": 1353.4964320334182,
            "rating_q025": 1314.5386862184598
        },
        "glm-4.5v": {
            "rating": 1332.3145203999516,
            "rating_q975": 1354.255516689241,
            "rating_q025": 1310.3735241106622
        },
        "gpt-4.1-mini-2025-04-14": {
            "rating": 1331.904852381393,
            "rating_q975": 1339.7060290423028,
            "rating_q025": 1324.1036757204834
        },
        "hunyuan-turbo-0110": {
            "rating": 1330.7379198325984,
            "rating_q975": 1357.9627563536305,
            "rating_q025": 1303.5130833115663
        },
        "gemma-3n-e4b-it": {
            "rating": 1328.4310399680899,
            "rating_q975": 1338.2415177170672,
            "rating_q025": 1318.6205622191126
        },
        "llama-3.1-nemotron-ultra-253b-v1": {
            "rating": 1327.762132494633,
            "rating_q975": 1353.5568462480528,
            "rating_q025": 1301.9674187412134
        },
        "qwen3-30b-a3b": {
            "rating": 1325.8895534886394,
            "rating_q975": 1334.8489325284659,
            "rating_q025": 1316.930174448813
        },
        "gemini-1.5-pro-002": {
            "rating": 1324.6610423444672,
            "rating_q975": 1331.2803865297649,
            "rating_q025": 1318.0416981591695
        },
        "gpt-5-nano-high": {
            "rating": 1321.5512571588463,
            "rating_q975": 1337.9199852527292,
            "rating_q025": 1305.1825290649633
        },
        "qwen2.5-plus-1127": {
            "rating": 1321.4863851377165,
            "rating_q975": 1334.9554513454348,
            "rating_q025": 1308.0173189299983
        },
        "o3-mini": {
            "rating": 1320.5466700361653,
            "rating_q975": 1326.912476635356,
            "rating_q025": 1314.1808634369747
        },
        "o1-mini": {
            "rating": 1319.8963397150164,
            "rating_q975": 1326.8971348926946,
            "rating_q025": 1312.8955445373383
        },
        "hunyuan-turbos-20250226": {
            "rating": 1319.8069240367545,
            "rating_q975": 1347.4861860414908,
            "rating_q025": 1292.1276620320182
        },
        "yi-lightning": {
            "rating": 1319.6886865848892,
            "rating_q975": 1329.135053246072,
            "rating_q025": 1310.2423199237064
        },
        "grok-2-2024-08-13": {
            "rating": 1318.517782726347,
            "rating_q975": 1325.3354750806143,
            "rating_q025": 1311.7000903720796
        },
        "athene-v2-chat": {
            "rating": 1311.141661009839,
            "rating_q975": 1320.0802436362114,
            "rating_q025": 1302.2030783834666
        },
        "gemma-3-4b-it": {
            "rating": 1308.2852101327476,
            "rating_q975": 1329.0941553280325,
            "rating_q025": 1287.4762649374627
        },
        "grok-2-mini-2024-08-13": {
            "rating": 1303.661808198382,
            "rating_q975": 1310.8319224904426,
            "rating_q025": 1296.4916939063214
        },
        "gemini-1.5-flash-002": {
            "rating": 1303.3973012470078,
            "rating_q975": 1311.4873305501096,
            "rating_q025": 1295.307271943906
        },
        "claude-3-7-sonnet-20250219-thinking-32k": {
            "rating": 1303.3189733053678,
            "rating_q975": 1311.2572367941154,
            "rating_q025": 1295.38070981662
        },
        "gpt-oss-20b": {
            "rating": 1301.698261390603,
            "rating_q975": 1316.6067417140396,
            "rating_q025": 1286.7897810671664
        },
        "gpt-4.1-nano-2025-04-14": {
            "rating": 1301.018018333029,
            "rating_q975": 1317.37673185657,
            "rating_q025": 1284.659304809488
        },
        "olmo-3-32b-think": {
            "rating": 1300.4500925798875,
            "rating_q975": 1326.3695343908546,
            "rating_q025": 1274.5306507689204
        },
        "mercury": {
            "rating": 1300.15419340001,
            "rating_q975": 1335.4685075927569,
            "rating_q025": 1264.839879207263
        },
        "gpt-4o-2024-05-13": {
            "rating": 1299.0614784857144,
            "rating_q975": 1305.4946774798993,
            "rating_q025": 1292.6282794915294
        },
        "glm-4-plus": {
            "rating": 1298.8560047879128,
            "rating_q975": 1308.267221031542,
            "rating_q025": 1289.4447885442835
        },
        "llama-3.1-405b-instruct-bf16": {
            "rating": 1298.8543929713728,
            "rating_q975": 1305.9373552616853,
            "rating_q025": 1291.7714306810603
        },
        "athene-70b-0725": {
            "rating": 1297.5083964339403,
            "rating_q975": 1308.8542441251566,
            "rating_q025": 1286.162548742724
        },
        "llama-3.1-nemotron-70b-instruct": {
            "rating": 1297.154092622404,
            "rating_q975": 1313.245444182357,
            "rating_q025": 1281.062741062451
        },
        "hunyuan-large-2025-02-10": {
            "rating": 1295.4531705298082,
            "rating_q975": 1316.4330207162793,
            "rating_q025": 1274.473320343337
        },
        "deepseek-v2.5-1210": {
            "rating": 1292.631004332432,
            "rating_q975": 1309.3052253751857,
            "rating_q025": 1275.9567832896782
        },
        "llama-4-maverick-17b-128e-instruct": {
            "rating": 1291.6628053532645,
            "rating_q975": 1299.4770372234645,
            "rating_q025": 1283.8485734830645
        },
        "gpt-4o-mini-2024-07-18": {
            "rating": 1289.9956572994301,
            "rating_q975": 1296.3103116260133,
            "rating_q025": 1283.681002972847
        },
        "llama-3.3-70b-instruct": {
            "rating": 1289.2442197872376,
            "rating_q975": 1295.477394982449,
            "rating_q025": 1283.0110445920263
        },
        "hunyuan-standard-2025-02-10": {
            "rating": 1288.5178735910467,
            "rating_q975": 1310.1929114706224,
            "rating_q025": 1266.842835711471
        },
        "llama-3.1-405b-instruct-fp8": {
            "rating": 1288.324875922477,
            "rating_q975": 1295.3584157789587,
            "rating_q025": 1281.2913360659954
        },
        "claude-3-7-sonnet-20250219": {
            "rating": 1288.1393962254028,
            "rating_q975": 1295.646625396796,
            "rating_q025": 1280.6321670540096
        },
        "qwen-max-0919": {
            "rating": 1283.1854824853922,
            "rating_q975": 1294.1600406508123,
            "rating_q025": 1272.210924319972
        },
        "llama-4-scout-17b-16e-instruct": {
            "rating": 1282.7867109699346,
            "rating_q975": 1291.6847835812764,
            "rating_q025": 1273.8886383585927
        },
        "llama-3.1-70b-instruct": {
            "rating": 1280.0198849204917,
            "rating_q975": 1287.1408247481133,
            "rating_q025": 1272.89894509287
        },
        "qwen2.5-72b-instruct": {
            "rating": 1278.977257638794,
            "rating_q975": 1286.601637682125,
            "rating_q025": 1271.352877595463
        },
        "gpt-4o-2024-08-06": {
            "rating": 1278.0205513074911,
            "rating_q975": 1285.8193497255995,
            "rating_q025": 1270.2217528893827
        },
        "deepseek-v2.5": {
            "rating": 1277.6099838632645,
            "rating_q975": 1286.9543681742514,
            "rating_q025": 1268.2655995522775
        },
        "claude-3-5-sonnet-20241022": {
            "rating": 1275.048614254506,
            "rating_q975": 1280.4129823682758,
            "rating_q025": 1269.6842461407361
        },
        "claude-3-5-sonnet-20240620": {
            "rating": 1274.2086019051044,
            "rating_q975": 1281.1486282555106,
            "rating_q025": 1267.2685755546981
        },
        "mistral-small-3.1-24b-instruct-2503": {
            "rating": 1272.6144296274902,
            "rating_q975": 1281.2899377489725,
            "rating_q025": 1263.9389215060078
        },
        "gemini-advanced-0514": {
            "rating": 1271.8315279127637,
            "rating_q975": 1280.903596047013,
            "rating_q025": 1262.7594597785144
        },
        "gemini-1.5-pro-001": {
            "rating": 1271.411098895966,
            "rating_q975": 1279.04008765143,
            "rating_q025": 1263.782110140502
        },
        "llama-3.1-tulu-3-70b": {
            "rating": 1270.9545628584688,
            "rating_q975": 1295.4511689563003,
            "rating_q025": 1246.4579567606372
        },
        "mistral-large-2407": {
            "rating": 1270.1870946254778,
            "rating_q975": 1278.1611212591954,
            "rating_q025": 1262.2130679917602
        },
        "reka-core-20240904": {
            "rating": 1269.8493618722287,
            "rating_q975": 1285.9254903015553,
            "rating_q025": 1253.773233442902
        },
        "hunyuan-large-vision": {
            "rating": 1266.9366529486942,
            "rating_q975": 1286.8075595068979,
            "rating_q025": 1247.0657463904906
        },
        "mistral-large-2411": {
            "rating": 1264.1533157849115,
            "rating_q975": 1272.6674850187133,
            "rating_q025": 1255.6391465511097
        },
        "gpt-4-turbo-2024-04-09": {
            "rating": 1259.780198156621,
            "rating_q975": 1266.924186926893,
            "rating_q025": 1252.636209386349
        },
        "amazon-nova-pro-v1.0": {
            "rating": 1259.1268567164147,
            "rating_q975": 1268.1534903200948,
            "rating_q025": 1250.1002231127347
        },
        "gpt-4-1106-preview": {
            "rating": 1258.5772076092403,
            "rating_q975": 1266.0054629264328,
            "rating_q025": 1251.1489522920479
        },
        "claude-3-opus-20240229": {
            "rating": 1257.8990661728308,
            "rating_q975": 1263.6960044644507,
            "rating_q025": 1252.102127881211
        },
        "command-r-plus-08-2024": {
            "rating": 1256.1685901582011,
            "rating_q975": 1270.4973557000465,
            "rating_q025": 1241.8398246163558
        },
        "gpt-4-0125-preview": {
            "rating": 1254.1508014653296,
            "rating_q975": 1261.694436216224,
            "rating_q025": 1246.6071667144352
        },
        "jamba-1.5-large": {
            "rating": 1253.322004354139,
            "rating_q975": 1269.2222421303322,
            "rating_q025": 1237.4217665779456
        },
        "claude-3-5-haiku-20241022": {
            "rating": 1250.2663533570396,
            "rating_q975": 1256.228866061647,
            "rating_q025": 1244.3038406524322
        },
        "olmo-2-0325-32b-instruct": {
            "rating": 1243.0990323503318,
            "rating_q975": 1266.9455738849092,
            "rating_q025": 1219.2524908157543
        },
        "magistral-medium-2506": {
            "rating": 1239.2012356069133,
            "rating_q975": 1253.7114558624853,
            "rating_q025": 1224.6910153513413
        },
        "mistral-small-24b-instruct-2501": {
            "rating": 1238.9299172725155,
            "rating_q975": 1250.5455914641645,
            "rating_q025": 1227.3142430808664
        },
        "c4ai-aya-expanse-32b": {
            "rating": 1236.6165678208044,
            "rating_q975": 1245.64569179348,
            "rating_q025": 1227.587443848129
        },
        "gemini-1.5-flash-8b-001": {
            "rating": 1236.5608173658834,
            "rating_q975": 1244.6681539074648,
            "rating_q025": 1228.453480824302
        },
        "amazon-nova-lite-v1.0": {
            "rating": 1236.249145959562,
            "rating_q975": 1246.4231165304136,
            "rating_q025": 1226.0751753887102
        },
        "gemini-1.5-flash-001": {
            "rating": 1235.8512281908888,
            "rating_q975": 1243.7362445274152,
            "rating_q025": 1227.9662118543624
        },
        "gemma-2-9b-it-simpo": {
            "rating": 1235.2062060878443,
            "rating_q975": 1249.9623453101756,
            "rating_q025": 1220.450066865513
        },
        "nemotron-4-340b-instruct": {
            "rating": 1232.9973770646072,
            "rating_q975": 1244.5763132847203,
            "rating_q025": 1221.4184408444942
        },
        "gemma-2-27b-it": {
            "rating": 1232.1399974121223,
            "rating_q975": 1238.398266401612,
            "rating_q025": 1225.8817284226325
        },
        "llama-3.1-nemotron-51b-instruct": {
            "rating": 1230.0435621060149,
            "rating_q975": 1251.602115863495,
            "rating_q025": 1208.4850083485346
        },
        "llama-3-70b-instruct": {
            "rating": 1229.8880896837552,
            "rating_q975": 1236.9915186036353,
            "rating_q025": 1222.784660763875
        },
        "glm-4-0520": {
            "rating": 1228.9670516159322,
            "rating_q975": 1243.9596276394368,
            "rating_q025": 1213.9744755924276
        },
        "reka-flash-20240904": {
            "rating": 1226.8661411298026,
            "rating_q975": 1242.709885669295,
            "rating_q025": 1211.02239659031
        },
        "qwen2.5-coder-32b-instruct": {
            "rating": 1225.578878479035,
            "rating_q975": 1243.6902747765917,
            "rating_q025": 1207.4674821814783
        },
        "command-r-08-2024": {
            "rating": 1223.0228206292213,
            "rating_q975": 1237.2511912305774,
            "rating_q025": 1208.7944500278652
        },
        "command-r-plus": {
            "rating": 1220.4927595987047,
            "rating_q975": 1228.6535638271803,
            "rating_q025": 1212.331955370229
        },
        "amazon-nova-micro-v1.0": {
            "rating": 1214.407178992001,
            "rating_q975": 1224.7569283664218,
            "rating_q025": 1204.0574296175803
        },
        "claude-3-sonnet-20240229": {
            "rating": 1213.154984535131,
            "rating_q975": 1220.6400435447604,
            "rating_q025": 1205.6699255255016
        },
        "phi-4": {
            "rating": 1210.5330393344132,
            "rating_q975": 1220.0099336553183,
            "rating_q025": 1201.056145013508
        },
        "c4ai-aya-expanse-8b": {
            "rating": 1208.1392104768715,
            "rating_q975": 1222.3393429768128,
            "rating_q025": 1193.9390779769303
        },
        "gemma-2-9b-it": {
            "rating": 1207.7467701383785,
            "rating_q975": 1214.8039873124103,
            "rating_q025": 1200.6895529643466
        },
        "hunyuan-standard-256k": {
            "rating": 1205.1477033496049,
            "rating_q975": 1230.035894599298,
            "rating_q025": 1180.2595120999117
        },
        "qwen2-72b-instruct": {
            "rating": 1199.270262718772,
            "rating_q975": 1208.468904838636,
            "rating_q025": 1190.071620598908
        },
        "llama-3.1-tulu-3-8b": {
            "rating": 1197.466265805053,
            "rating_q975": 1222.1611676829482,
            "rating_q025": 1172.7713639271576
        },
        "llama-3.1-8b-instruct": {
            "rating": 1197.4655167588971,
            "rating_q975": 1205.1005088002853,
            "rating_q025": 1189.830524717509
        },
        "jamba-1.5-mini": {
            "rating": 1194.311361935213,
            "rating_q975": 1210.017546038671,
            "rating_q025": 1178.6051778317549
        },
        "ministral-8b-2410": {
            "rating": 1193.2176802154224,
            "rating_q975": 1213.0957946131286,
            "rating_q025": 1173.3395658177162
        },
        "claude-3-haiku-20240307": {
            "rating": 1182.5983012810632,
            "rating_q975": 1189.6012919183895,
            "rating_q025": 1175.5953106437369
        },
        "gpt-4-0314": {
            "rating": 1180.9220630225886,
            "rating_q975": 1190.1199663200407,
            "rating_q025": 1171.7241597251366
        },
        "yi-1.5-34b-chat": {
            "rating": 1176.6546365824302,
            "rating_q975": 1187.346087597302,
            "rating_q025": 1165.9631855675584
        },
        "command-r": {
            "rating": 1174.7214098717793,
            "rating_q975": 1183.8451688578323,
            "rating_q025": 1165.5976508857264
        },
        "llama-3-8b-instruct": {
            "rating": 1174.4964482504906,
            "rating_q975": 1182.2226846006097,
            "rating_q025": 1166.7702119003716
        },
        "reka-flash-21b-20240226-online": {
            "rating": 1171.8083379244465,
            "rating_q975": 1185.2874733395672,
            "rating_q025": 1158.3292025093258
        },
        "qwen1.5-110b-chat": {
            "rating": 1170.2971976175354,
            "rating_q975": 1181.233251948639,
            "rating_q025": 1159.3611432864318
        },
        "internlm2_5-20b-chat": {
            "rating": 1169.2076339900113,
            "rating_q975": 1183.8827938091733,
            "rating_q025": 1154.5324741708494
        },
        "deepseek-coder-v2": {
            "rating": 1166.5859277505178,
            "rating_q975": 1179.406405293422,
            "rating_q025": 1153.7654502076136
        },
        "reka-flash-21b-20240226": {
            "rating": 1163.6130240166517,
            "rating_q975": 1174.941981775737,
            "rating_q025": 1152.2840662575663
        },
        "gemma-2-2b-it": {
            "rating": 1162.9710295815594,
            "rating_q975": 1170.623309887789,
            "rating_q025": 1155.3187492753298
        },
        "mistral-medium": {
            "rating": 1162.8296637859173,
            "rating_q975": 1173.263365821496,
            "rating_q025": 1152.3959617503385
        },
        "qwen1.5-72b-chat": {
            "rating": 1162.46473909494,
            "rating_q975": 1172.227809300054,
            "rating_q025": 1152.7016688898257
        },
        "qwq-32b-preview": {
            "rating": 1158.3476722307064,
            "rating_q975": 1183.6103293415383,
            "rating_q025": 1133.0850151198745
        },
        "mistral-large-2402": {
            "rating": 1157.8923786325263,
            "rating_q975": 1166.7692109277646,
            "rating_q025": 1149.015546337288
        },
        "gpt-4-0613": {
            "rating": 1157.7117840411179,
            "rating_q975": 1165.7361523342888,
            "rating_q025": 1149.687415747947
        },
        "mixtral-8x22b-instruct-v0.1": {
            "rating": 1155.115051273929,
            "rating_q975": 1163.9836850051533,
            "rating_q025": 1146.2464175427049
        },
        "gemini-pro-dev-api": {
            "rating": 1147.882574821166,
            "rating_q975": 1161.4716011729706,
            "rating_q025": 1134.2935484693612
        },
        "zephyr-orpo-141b-A35b-v0.1": {
            "rating": 1147.0577902014534,
            "rating_q975": 1167.9826857144722,
            "rating_q025": 1126.1328946884346
        },
        "starling-lm-7b-beta": {
            "rating": 1146.4315673130266,
            "rating_q975": 1160.0817500318112,
            "rating_q025": 1132.781384594242
        },
        "phi-3-medium-4k-instruct": {
            "rating": 1142.0253824605882,
            "rating_q975": 1152.4932911161093,
            "rating_q025": 1131.557473805067
        },
        "granite-3.1-8b-instruct": {
            "rating": 1141.3224154199588,
            "rating_q975": 1166.4939518120327,
            "rating_q025": 1116.150879027885
        },
        "yi-34b-chat": {
            "rating": 1137.923087985395,
            "rating_q975": 1151.1655444210724,
            "rating_q025": 1124.6806315497174
        },
        "qwen1.5-32b-chat": {
            "rating": 1136.6916600773352,
            "rating_q975": 1148.1095734899443,
            "rating_q025": 1125.273746664726
        },
        "llama-2-70b-chat": {
            "rating": 1123.95337615859,
            "rating_q975": 1133.8748681642805,
            "rating_q025": 1114.0318841528992
        },
        "gemini-pro": {
            "rating": 1122.623022885697,
            "rating_q975": 1143.0964255422211,
            "rating_q025": 1102.149620229173
        },
        "mixtral-8x7b-instruct-v0.1": {
            "rating": 1121.36150443996,
            "rating_q975": 1129.6113880697155,
            "rating_q025": 1113.1116208102046
        },
        "starling-lm-7b-alpha": {
            "rating": 1114.4867025347296,
            "rating_q975": 1129.6295380898332,
            "rating_q025": 1099.343866979626
        },
        "wizardlm-70b": {
            "rating": 1113.1694528603075,
            "rating_q975": 1131.0906294582273,
            "rating_q025": 1095.2482762623877
        },
        "granite-3.1-2b-instruct": {
            "rating": 1112.1967036434114,
            "rating_q975": 1139.5207347529986,
            "rating_q025": 1084.8726725338242
        },
        "phi-3-small-8k-instruct": {
            "rating": 1111.025616784466,
            "rating_q975": 1123.235152371678,
            "rating_q025": 1098.8160811972539
        },
        "llama-3.2-3b-instruct": {
            "rating": 1110.2100417745469,
            "rating_q975": 1127.517433814705,
            "rating_q025": 1092.9026497343887
        },
        "tulu-2-dpo-70b": {
            "rating": 1109.0914651475694,
            "rating_q975": 1127.8762561399037,
            "rating_q025": 1090.306674155235
        },
        "nous-hermes-2-mixtral-8x7b-dpo": {
            "rating": 1108.0615983819398,
            "rating_q975": 1131.1053157162169,
            "rating_q025": 1085.0178810476627
        },
        "qwen1.5-14b-chat": {
            "rating": 1107.6903657425855,
            "rating_q975": 1121.0172812437536,
            "rating_q025": 1094.3634502414175
        },
        "dbrx-instruct-preview": {
            "rating": 1104.3070749887718,
            "rating_q975": 1115.8807082695716,
            "rating_q025": 1092.733441707972
        },
        "vicuna-33b": {
            "rating": 1103.752259676867,
            "rating_q975": 1115.3116352763975,
            "rating_q025": 1092.1928840773364
        },
        "granite-3.0-8b-instruct": {
            "rating": 1103.2189999866796,
            "rating_q975": 1122.3641223895847,
            "rating_q025": 1084.0738775837744
        },
        "llama2-70b-steerlm-chat": {
            "rating": 1098.4736830671231,
            "rating_q975": 1122.4758896267408,
            "rating_q025": 1074.4714765075055
        },
        "gpt-3.5-turbo-0125": {
            "rating": 1091.5252505706148,
            "rating_q975": 1099.9008071668422,
            "rating_q025": 1083.1496939743874
        },
        "llama-2-13b-chat": {
            "rating": 1086.2034370576896,
            "rating_q975": 1098.998649774244,
            "rating_q025": 1073.408224341135
        },
        "snowflake-arctic-instruct": {
            "rating": 1086.1221528615606,
            "rating_q975": 1097.6709176366603,
            "rating_q025": 1074.573388086461
        },
        "mistral-7b-instruct-v0.2": {
            "rating": 1082.97503960471,
            "rating_q975": 1095.459232128511,
            "rating_q025": 1070.490847080909
        },
        "openchat-3.5-0106": {
            "rating": 1082.8147237344256,
            "rating_q975": 1096.872523908909,
            "rating_q025": 1068.7569235599422
        },
        "gemma-1.1-7b-it": {
            "rating": 1082.4766591699542,
            "rating_q975": 1093.5524251634847,
            "rating_q025": 1071.4008931764238
        },
        "qwen1.5-7b-chat": {
            "rating": 1080.2276056849182,
            "rating_q975": 1101.3551861046053,
            "rating_q025": 1059.1000252652311
        },
        "granite-3.0-2b-instruct": {
            "rating": 1076.537062236823,
            "rating_q975": 1095.2338666555418,
            "rating_q025": 1057.8402578181042
        },
        "solar-10.7b-instruct-v1.0": {
            "rating": 1076.3619164487386,
            "rating_q975": 1100.2338741971603,
            "rating_q025": 1052.489958700317
        },
        "wizardlm-13b": {
            "rating": 1073.1952765115911,
            "rating_q975": 1091.509728101846,
            "rating_q025": 1054.8808249213364
        },
        "phi-3-mini-4k-instruct-june-2024": {
            "rating": 1072.2310359702071,
            "rating_q975": 1086.7548220308033,
            "rating_q025": 1057.707249909611
        },
        "openchat-3.5": {
            "rating": 1071.638044001736,
            "rating_q975": 1089.5036866339826,
            "rating_q025": 1053.7724013694894
        },
        "codellama-34b-instruct": {
            "rating": 1070.154521355736,
            "rating_q975": 1087.7993241280615,
            "rating_q025": 1052.5097185834106
        },
        "deepseek-llm-67b-chat": {
            "rating": 1070.047675773831,
            "rating_q975": 1092.1169843299415,
            "rating_q025": 1047.9783672177207
        },
        "dolphin-2.2.1-mistral-7b": {
            "rating": 1069.6067886556039,
            "rating_q975": 1103.2693744379949,
            "rating_q025": 1035.9442028732128
        },
        "openhermes-2.5-mistral-7b": {
            "rating": 1069.5443029318176,
            "rating_q975": 1090.075142331992,
            "rating_q025": 1049.013463531643
        },
        "phi-3-mini-4k-instruct": {
            "rating": 1066.0375479457653,
            "rating_q975": 1078.4557477664803,
            "rating_q025": 1053.6193481250502
        },
        "zephyr-7b-beta": {
            "rating": 1064.2674419569112,
            "rating_q975": 1080.1230844655915,
            "rating_q025": 1048.4117994482308
        },
        "guanaco-33b": {
            "rating": 1063.6561067731554,
            "rating_q975": 1090.7375731548766,
            "rating_q025": 1036.5746403914343
        },
        "llama-3.2-1b-instruct": {
            "rating": 1059.0170422033914,
            "rating_q975": 1076.8740225206031,
            "rating_q025": 1041.1600618861796
        },
        "gpt-3.5-turbo-1106": {
            "rating": 1055.4501594820897,
            "rating_q975": 1070.506014630897,
            "rating_q025": 1040.3943043332824
        },
        "smollm2-1.7b-instruct": {
            "rating": 1052.9117331951088,
            "rating_q975": 1088.5261466126058,
            "rating_q025": 1017.2973197776118
        },
        "llama-2-7b-chat": {
            "rating": 1051.2604245506786,
            "rating_q975": 1064.6423188939168,
            "rating_q025": 1037.8785302074405
        },
        "mpt-30b-chat": {
            "rating": 1042.540583343991,
            "rating_q975": 1069.3322999487232,
            "rating_q025": 1015.7488667392591
        },
        "vicuna-13b": {
            "rating": 1038.6514597476864,
            "rating_q975": 1051.611473783341,
            "rating_q025": 1025.691445712032
        },
        "zephyr-7b-alpha": {
            "rating": 1033.3865554510714,
            "rating_q975": 1068.3549158441106,
            "rating_q025": 998.4181950580323
        },
        "phi-3-mini-128k-instruct": {
            "rating": 1027.220139621936,
            "rating_q975": 1040.7731473117751,
            "rating_q025": 1013.6671319320967
        },
        "gemma-7b-it": {
            "rating": 1024.8155241019786,
            "rating_q975": 1042.0902154245614,
            "rating_q025": 1007.5408327793956
        },
        "falcon-180b-chat": {
            "rating": 1022.9060942376974,
            "rating_q975": 1065.3963732210798,
            "rating_q025": 980.415815254315
        },
        "stripedhyena-nous-7b": {
            "rating": 1016.16687050256,
            "rating_q975": 1037.2228420478216,
            "rating_q025": 995.1108989572984
        },
        "palm-2": {
            "rating": 1015.5424778638496,
            "rating_q975": 1033.8490738691903,
            "rating_q025": 997.2358818585091
        },
        "qwen-14b-chat": {
            "rating": 1014.7011981044302,
            "rating_q975": 1036.3230748167418,
            "rating_q025": 993.0793213921185
        },
        "olmo-7b-instruct": {
            "rating": 1012.1660543982885,
            "rating_q975": 1032.129385076516,
            "rating_q025": 992.2027237200609
        },
        "vicuna-7b": {
            "rating": 1005.1600862776058,
            "rating_q975": 1024.1982994278897,
            "rating_q025": 986.121873127322
        },
        "mistral-7b-instruct": {
            "rating": 1002.4124546568228,
            "rating_q975": 1020.5544041169662,
            "rating_q025": 984.2705051966793
        },
        "gemma-1.1-2b-it": {
            "rating": 1000.7710289971899,
            "rating_q975": 1016.9112265398642,
            "rating_q025": 984.6308314545156
        },
        "koala-13b": {
            "rating": 990.3487540721458,
            "rating_q975": 1011.1427156261725,
            "rating_q025": 969.554792518119
        },
        "qwen1.5-4b-chat": {
            "rating": 980.9532521839419,
            "rating_q975": 999.3796807140128,
            "rating_q025": 962.526823653871
        },
        "gemma-2b-it": {
            "rating": 954.7190030059471,
            "rating_q975": 977.6335220854146,
            "rating_q025": 931.8044839264796
        },
        "chatglm3-6b": {
            "rating": 935.7879544147368,
            "rating_q975": 959.0855905779629,
            "rating_q025": 912.4903182515106
        },
        "RWKV-4-Raven-14B": {
            "rating": 931.9382895752364,
            "rating_q975": 955.8225071084904,
            "rating_q025": 908.0540720419823
        },
        "chatglm2-6b": {
            "rating": 920.4442985064184,
            "rating_q975": 951.2410859343794,
            "rating_q025": 889.6475110784573
        },
        "mpt-7b-chat": {
            "rating": 917.4024052485082,
            "rating_q975": 942.1986604501767,
            "rating_q025": 892.6061500468397
        },
        "gpt4all-13b-snoozy": {
            "rating": 906.0727306462189,
            "rating_q975": 943.1238362923482,
            "rating_q025": 869.0216250000897
        },
        "oasst-pythia-12b": {
            "rating": 900.8211682453962,
            "rating_q975": 922.0745693925317,
            "rating_q025": 879.5677670982607
        },
        "alpaca-13b": {
            "rating": 886.9496958992903,
            "rating_q975": 908.9704041213939,
            "rating_q025": 864.9289876771867
        },
        "fastchat-t5-3b": {
            "rating": 869.6677850625695,
            "rating_q975": 895.2558027271334,
            "rating_q025": 844.0797673980055
        },
        "chatglm-6b": {
            "rating": 853.6202147616394,
            "rating_q975": 879.0819602243092,
            "rating_q025": 828.1584692989696
        },
        "llama-13b": {
            "rating": 810.3763437405166,
            "rating_q975": 843.4347163116302,
            "rating_q025": 777.3179711694031
        },
        "stablelm-tuned-alpha-7b": {
            "rating": 807.4393996791764,
            "rating_q975": 835.1772481698551,
            "rating_q025": 779.7015511884977
        },
        "dolly-v2-12b": {
            "rating": 805.0013838261204,
            "rating_q975": 834.1024289632769,
            "rating_q025": 775.900338688964
        }
    },
    "industry_mathematical": {
        "claude-opus-4-5-20251101": {
            "rating": 1481.3668077588225,
            "rating_q975": 1507.6887317649455,
            "rating_q025": 1455.0448837526994
        },
        "gemini-3-pro": {
            "rating": 1478.2727578038914,
            "rating_q975": 1497.7976231724786,
            "rating_q025": 1458.7478924353043
        },
        "gpt-5.1-high": {
            "rating": 1474.4725976520936,
            "rating_q975": 1496.8912447111495,
            "rating_q025": 1452.0539505930376
        },
        "claude-sonnet-4-5-20250929-thinking-32k": {
            "rating": 1464.255388683092,
            "rating_q975": 1480.3363735251532,
            "rating_q025": 1448.1744038410307
        },
        "gemini-2.5-pro": {
            "rating": 1460.7732828512462,
            "rating_q975": 1470.3002595791907,
            "rating_q025": 1451.2463061233018
        },
        "claude-opus-4-5-20251101-thinking-32k": {
            "rating": 1460.1327154226817,
            "rating_q975": 1487.1370965666447,
            "rating_q025": 1433.1283342787187
        },
        "glm-4.6": {
            "rating": 1453.180761132814,
            "rating_q975": 1470.153137821417,
            "rating_q025": 1436.208384444211
        },
        "qwen3-max-preview": {
            "rating": 1450.6287931911909,
            "rating_q975": 1466.4366381963155,
            "rating_q025": 1434.8209481860663
        },
        "claude-sonnet-4-5-20250929": {
            "rating": 1450.537293266955,
            "rating_q975": 1467.8689321394245,
            "rating_q025": 1433.2056543944855
        },
        "longcat-flash-chat": {
            "rating": 1448.2925714223773,
            "rating_q975": 1473.1738989452545,
            "rating_q025": 1423.4112438995
        },
        "qwen3-235b-a22b-instruct-2507": {
            "rating": 1446.9625356150104,
            "rating_q975": 1458.4779975217202,
            "rating_q025": 1435.4470737083006
        },
        "ernie-5.0-preview-1103": {
            "rating": 1446.41985412494,
            "rating_q975": 1475.9010363920274,
            "rating_q025": 1416.9386718578526
        },
        "deepseek-v3.2": {
            "rating": 1445.8276005029131,
            "rating_q975": 1476.8738575833643,
            "rating_q025": 1414.781343422462
        },
        "deepseek-v3.1-thinking": {
            "rating": 1444.179893296923,
            "rating_q975": 1468.2859428561721,
            "rating_q025": 1420.0738437376738
        },
        "qwen3-next-80b-a3b-instruct": {
            "rating": 1443.6563148466103,
            "rating_q975": 1461.7033022981254,
            "rating_q025": 1425.609327395095
        },
        "qwen3-235b-a22b-thinking-2507": {
            "rating": 1442.8338492948933,
            "rating_q975": 1467.0614540449403,
            "rating_q025": 1418.6062445448463
        },
        "qwen3-vl-235b-a22b-thinking": {
            "rating": 1439.0594729712614,
            "rating_q975": 1468.465645190604,
            "rating_q025": 1409.6533007519188
        },
        "claude-opus-4-1-20250805-thinking-16k": {
            "rating": 1437.4965954651623,
            "rating_q975": 1450.1112163024552,
            "rating_q025": 1424.8819746278693
        },
        "kimi-k2-thinking-turbo": {
            "rating": 1436.9724987409397,
            "rating_q975": 1458.0009399424719,
            "rating_q025": 1415.9440575394076
        },
        "glm-4.5": {
            "rating": 1436.2310559724406,
            "rating_q975": 1452.9185724999277,
            "rating_q025": 1419.5435394449535
        },
        "grok-4-fast-chat": {
            "rating": 1432.5554274158667,
            "rating_q975": 1463.915779838006,
            "rating_q025": 1401.1950749937273
        },
        "gemini-2.5-flash-preview-09-2025": {
            "rating": 1432.435044088553,
            "rating_q975": 1448.2314410721876,
            "rating_q025": 1416.6386471049184
        },
        "o3-2025-04-16": {
            "rating": 1432.1671282446093,
            "rating_q975": 1442.2724336448362,
            "rating_q025": 1422.0618228443825
        },
        "grok-4-0709": {
            "rating": 1431.880967193284,
            "rating_q975": 1444.5808317916121,
            "rating_q025": 1419.181102594956
        },
        "claude-opus-4-1-20250805": {
            "rating": 1431.3439443059465,
            "rating_q975": 1442.4026454500113,
            "rating_q025": 1420.2852431618817
        },
        "deepseek-v3.2-exp-thinking": {
            "rating": 1430.2745025823317,
            "rating_q975": 1460.3997526299722,
            "rating_q025": 1400.1492525346912
        },
        "grok-4.1-thinking": {
            "rating": 1430.066499220229,
            "rating_q975": 1450.757580966468,
            "rating_q025": 1409.37541747399
        },
        "qwen3-max-2025-09-23": {
            "rating": 1427.986520158628,
            "rating_q975": 1453.634238913719,
            "rating_q025": 1402.3388014035372
        },
        "gpt-5.1": {
            "rating": 1425.772703231685,
            "rating_q975": 1445.882543484237,
            "rating_q025": 1405.662862979133
        },
        "qwen3-32b": {
            "rating": 1425.2744550043712,
            "rating_q975": 1457.1815243829935,
            "rating_q025": 1393.367385625749
        },
        "grok-4.1": {
            "rating": 1422.5491143209824,
            "rating_q975": 1441.5158023359734,
            "rating_q025": 1403.5824263059915
        },
        "gemini-2.5-flash": {
            "rating": 1422.3964659446506,
            "rating_q975": 1431.4709614668402,
            "rating_q025": 1413.321970422461
        },
        "deepseek-v3.2-exp": {
            "rating": 1422.2154111904347,
            "rating_q975": 1444.7895929529727,
            "rating_q025": 1399.6412294278966
        },
        "deepseek-v3.1": {
            "rating": 1421.652550329938,
            "rating_q975": 1441.177523665413,
            "rating_q025": 1402.1275769944632
        },
        "qwen3-vl-235b-a22b-instruct": {
            "rating": 1421.624075740442,
            "rating_q975": 1447.8423921705114,
            "rating_q025": 1395.4057593103728
        },
        "mistral-medium-2508": {
            "rating": 1420.828371778353,
            "rating_q975": 1433.0827524812255,
            "rating_q025": 1408.5739910754803
        },
        "claude-haiku-4-5-20251001": {
            "rating": 1415.8889113508178,
            "rating_q975": 1432.3272904376747,
            "rating_q025": 1399.450532263961
        },
        "deepseek-r1-0528": {
            "rating": 1415.2884906357829,
            "rating_q975": 1433.6181738731452,
            "rating_q025": 1396.9588073984205
        },
        "gpt-4.5-preview-2025-02-27": {
            "rating": 1415.176628832801,
            "rating_q975": 1430.5373576861878,
            "rating_q025": 1399.8158999794143
        },
        "qwen3-30b-a3b-instruct-2507": {
            "rating": 1414.6954937837659,
            "rating_q975": 1430.97026195792,
            "rating_q025": 1398.4207256096117
        },
        "amazon-nova-experimental-chat-10-09": {
            "rating": 1413.372834629723,
            "rating_q975": 1441.719709468179,
            "rating_q025": 1385.025959791267
        },
        "gpt-5-high": {
            "rating": 1411.6283639518317,
            "rating_q975": 1425.57201463948,
            "rating_q025": 1397.6847132641835
        },
        "amazon-nova-experimental-chat-10-20": {
            "rating": 1411.0863017048823,
            "rating_q975": 1439.1443008874821,
            "rating_q025": 1383.0283025222825
        },
        "grok-3-preview-02-24": {
            "rating": 1410.2532316633292,
            "rating_q975": 1421.463822087437,
            "rating_q025": 1399.0426412392214
        },
        "minimax-m1": {
            "rating": 1408.97309456507,
            "rating_q975": 1421.9488895418538,
            "rating_q025": 1395.997299588286
        },
        "chatgpt-4o-latest-20250326": {
            "rating": 1406.728184947595,
            "rating_q975": 1415.9125145063902,
            "rating_q025": 1397.5438553888
        },
        "qwen3-235b-a22b-no-thinking": {
            "rating": 1406.632456268089,
            "rating_q975": 1418.5048997767296,
            "rating_q025": 1394.7600127594485
        },
        "grok-4-fast-reasoning": {
            "rating": 1405.0324364391295,
            "rating_q975": 1424.005073541467,
            "rating_q025": 1386.059799336792
        },
        "mai-1-preview": {
            "rating": 1404.885799737969,
            "rating_q975": 1424.99282544423,
            "rating_q025": 1384.7787740317078
        },
        "qwen3-235b-a22b": {
            "rating": 1404.5994118537583,
            "rating_q975": 1419.0541974810203,
            "rating_q025": 1390.1446262264963
        },
        "kimi-k2-0905-preview": {
            "rating": 1404.4823097239466,
            "rating_q975": 1427.3793979749148,
            "rating_q025": 1381.5852214729784
        },
        "deepseek-v3.2-thinking": {
            "rating": 1403.7749149562442,
            "rating_q975": 1437.6607898093648,
            "rating_q025": 1369.8890401031235
        },
        "o3-mini-high": {
            "rating": 1403.742460796873,
            "rating_q975": 1417.3755289281644,
            "rating_q025": 1390.1093926655817
        },
        "nvidia-llama-3.3-nemotron-super-49b-v1.5": {
            "rating": 1402.0086085754378,
            "rating_q975": 1440.335828617259,
            "rating_q025": 1363.6813885336167
        },
        "grok-4-1-fast-reasoning": {
            "rating": 1401.3412519685521,
            "rating_q975": 1428.4033228325993,
            "rating_q025": 1374.279181104505
        },
        "glm-4.5-air": {
            "rating": 1399.3846250686647,
            "rating_q975": 1414.7031721630447,
            "rating_q025": 1384.0660779742848
        },
        "gpt-5-chat": {
            "rating": 1398.6255197043859,
            "rating_q975": 1413.2147682153864,
            "rating_q025": 1384.0362711933853
        },
        "qwen3-next-80b-a3b-thinking": {
            "rating": 1397.7634219882996,
            "rating_q975": 1420.2565586829426,
            "rating_q025": 1375.2702852936566
        },
        "claude-opus-4-20250514-thinking-16k": {
            "rating": 1395.3718305143368,
            "rating_q975": 1407.8973864560658,
            "rating_q025": 1382.8462745726079
        },
        "o1-2024-12-17": {
            "rating": 1395.2768131429973,
            "rating_q975": 1406.3678459943246,
            "rating_q025": 1384.18578029167
        },
        "mistral-large-3": {
            "rating": 1393.9468098582697,
            "rating_q975": 1426.4155183977043,
            "rating_q025": 1361.4781013188351
        },
        "deepseek-r1": {
            "rating": 1393.322856702949,
            "rating_q975": 1407.7000943687333,
            "rating_q025": 1378.9456190371645
        },
        "gpt-oss-120b": {
            "rating": 1389.188722118124,
            "rating_q975": 1403.9924198399822,
            "rating_q025": 1374.3850243962656
        },
        "hunyuan-t1-20250711": {
            "rating": 1388.295897291566,
            "rating_q975": 1426.5187778616462,
            "rating_q025": 1350.0730167214858
        },
        "claude-sonnet-4-20250514-thinking-32k": {
            "rating": 1387.2616319483668,
            "rating_q975": 1400.2324766703746,
            "rating_q025": 1374.290787226359
        },
        "gpt-5-mini-high": {
            "rating": 1387.130928141639,
            "rating_q975": 1403.5358680963982,
            "rating_q025": 1370.72598818688
        },
        "o4-mini-2025-04-16": {
            "rating": 1385.780673168565,
            "rating_q975": 1396.5313033411403,
            "rating_q025": 1375.0300429959898
        },
        "o1-preview": {
            "rating": 1385.5437528690995,
            "rating_q975": 1395.478673038981,
            "rating_q025": 1375.608832699218
        },
        "o3-mini": {
            "rating": 1385.075597461036,
            "rating_q975": 1393.6237972957001,
            "rating_q025": 1376.527397626372
        },
        "gemini-2.5-flash-lite-preview-09-2025-no-thinking": {
            "rating": 1384.396894723213,
            "rating_q975": 1400.2092435310972,
            "rating_q025": 1368.584545915329
        },
        "step-3": {
            "rating": 1382.159806641055,
            "rating_q975": 1415.5643499502473,
            "rating_q025": 1348.7552633318626
        },
        "ling-flash-2.0": {
            "rating": 1380.3977606443354,
            "rating_q975": 1408.8393198295698,
            "rating_q025": 1351.956201459101
        },
        "claude-opus-4-20250514": {
            "rating": 1377.9411089028551,
            "rating_q975": 1388.9990606181636,
            "rating_q025": 1366.8831571875467
        },
        "qwen3-coder-480b-a35b-instruct": {
            "rating": 1374.7175702343682,
            "rating_q975": 1390.227310099049,
            "rating_q025": 1359.2078303696874
        },
        "qwen3-30b-a3b": {
            "rating": 1374.4428639009157,
            "rating_q975": 1388.345006631875,
            "rating_q025": 1360.5407211699562
        },
        "qwen2.5-max": {
            "rating": 1373.2016217842581,
            "rating_q975": 1383.2226931241075,
            "rating_q025": 1363.1805504444087
        },
        "grok-3-mini-high": {
            "rating": 1372.763222560271,
            "rating_q975": 1390.4363015718473,
            "rating_q025": 1355.0901435486949
        },
        "minimax-m2": {
            "rating": 1372.7166586778094,
            "rating_q975": 1407.5676606041402,
            "rating_q025": 1337.8656567514786
        },
        "gemini-2.5-flash-lite-preview-06-17-thinking": {
            "rating": 1371.577077991692,
            "rating_q975": 1384.104897995961,
            "rating_q025": 1359.049257987423
        },
        "ring-flash-2.0": {
            "rating": 1371.5071123342289,
            "rating_q975": 1401.9341084060513,
            "rating_q025": 1341.0801162624064
        },
        "o1-mini": {
            "rating": 1371.4990562479873,
            "rating_q975": 1379.2772182571618,
            "rating_q025": 1363.7208942388127
        },
        "deepseek-v3-0324": {
            "rating": 1368.3274975529905,
            "rating_q975": 1378.7435894388902,
            "rating_q025": 1357.9114056670908
        },
        "hunyuan-turbos-20250416": {
            "rating": 1366.5822151629886,
            "rating_q975": 1386.0545417066658,
            "rating_q025": 1347.1098886193115
        },
        "nova-2-lite": {
            "rating": 1365.2010936518786,
            "rating_q975": 1398.7176349086894,
            "rating_q025": 1331.6845523950678
        },
        "kimi-k2-0711-preview": {
            "rating": 1363.8366572195157,
            "rating_q975": 1378.271875936215,
            "rating_q025": 1349.4014385028163
        },
        "claude-sonnet-4-20250514": {
            "rating": 1362.5836926173395,
            "rating_q975": 1374.4383778793438,
            "rating_q025": 1350.7290073553352
        },
        "gpt-4.1-2025-04-14": {
            "rating": 1361.864423199812,
            "rating_q975": 1372.118959309817,
            "rating_q025": 1351.6098870898072
        },
        "grok-3-mini-beta": {
            "rating": 1361.8385665265332,
            "rating_q975": 1375.880001434921,
            "rating_q025": 1347.7971316181454
        },
        "gemini-2.0-flash-001": {
            "rating": 1360.6534162375458,
            "rating_q975": 1369.561100800091,
            "rating_q025": 1351.7457316750006
        },
        "mistral-small-2506": {
            "rating": 1360.3270955036805,
            "rating_q975": 1378.006187647634,
            "rating_q025": 1342.648003359727
        },
        "qwq-32b": {
            "rating": 1358.919895563039,
            "rating_q975": 1372.7035340284658,
            "rating_q025": 1345.1362570976123
        },
        "mistral-medium-2505": {
            "rating": 1354.9793477231447,
            "rating_q975": 1366.6931203702131,
            "rating_q025": 1343.2655750760762
        },
        "step-1o-turbo-202506": {
            "rating": 1352.536433301868,
            "rating_q975": 1374.3936996077082,
            "rating_q025": 1330.679166996028
        },
        "gpt-4.1-mini-2025-04-14": {
            "rating": 1351.9466662296863,
            "rating_q975": 1363.2198965327293,
            "rating_q025": 1340.6734359266434
        },
        "llama-3.3-nemotron-49b-super-v1": {
            "rating": 1350.9094161161986,
            "rating_q975": 1388.1107165295227,
            "rating_q025": 1313.7081157028745
        },
        "claude-3-7-sonnet-20250219-thinking-32k": {
            "rating": 1345.6784979147064,
            "rating_q975": 1356.8563715648122,
            "rating_q025": 1334.5006242646007
        },
        "gemma-3-12b-it": {
            "rating": 1341.2699922270538,
            "rating_q975": 1371.523599657671,
            "rating_q025": 1311.0163847964366
        },
        "glm-4.5v": {
            "rating": 1337.8524026427424,
            "rating_q975": 1375.0073753813083,
            "rating_q025": 1300.6974299041765
        },
        "qwen-plus-0125": {
            "rating": 1336.998740475876,
            "rating_q975": 1358.2228918138198,
            "rating_q025": 1315.7745891379323
        },
        "gpt-5-nano-high": {
            "rating": 1335.715953652941,
            "rating_q975": 1363.8560239378244,
            "rating_q025": 1307.5758833680575
        },
        "gemma-3-27b-it": {
            "rating": 1331.7332605483887,
            "rating_q975": 1341.4779971544851,
            "rating_q025": 1321.9885239422922
        },
        "gemini-1.5-pro-002": {
            "rating": 1330.1855402922872,
            "rating_q975": 1337.324915938271,
            "rating_q025": 1323.0461646463034
        },
        "gemini-2.0-flash-lite-preview-02-05": {
            "rating": 1323.2391028948127,
            "rating_q975": 1334.119754126956,
            "rating_q025": 1312.3584516626695
        },
        "deepseek-v3": {
            "rating": 1319.1800808113958,
            "rating_q975": 1330.509807178247,
            "rating_q025": 1307.8503544445446
        },
        "claude-3-7-sonnet-20250219": {
            "rating": 1319.1132816126124,
            "rating_q975": 1329.0535946676252,
            "rating_q025": 1309.1729685575995
        },
        "command-a-03-2025": {
            "rating": 1316.6283411248492,
            "rating_q975": 1326.046931900983,
            "rating_q025": 1307.2097503487153
        },
        "step-2-16k-exp-202412": {
            "rating": 1315.3347564717055,
            "rating_q975": 1337.4496517614161,
            "rating_q025": 1293.219861181995
        },
        "claude-3-5-sonnet-20241022": {
            "rating": 1312.842546976367,
            "rating_q975": 1319.0362754622813,
            "rating_q025": 1306.6488184904526
        },
        "yi-lightning": {
            "rating": 1312.201965486251,
            "rating_q975": 1322.2144705788119,
            "rating_q025": 1302.1894603936903
        },
        "qwen2.5-plus-1127": {
            "rating": 1310.846603252064,
            "rating_q975": 1325.22336071936,
            "rating_q025": 1296.4698457847678
        },
        "athene-v2-chat": {
            "rating": 1310.749388862404,
            "rating_q975": 1320.5666439277466,
            "rating_q025": 1300.9321337970614
        },
        "gpt-oss-20b": {
            "rating": 1310.4280155966667,
            "rating_q975": 1334.0136467398056,
            "rating_q025": 1286.8423844535278
        },
        "hunyuan-large-2025-02-10": {
            "rating": 1309.8143963266336,
            "rating_q975": 1335.8425684190413,
            "rating_q025": 1283.786224234226
        },
        "hunyuan-large-vision": {
            "rating": 1309.702543588834,
            "rating_q975": 1337.2969981107922,
            "rating_q025": 1282.108089066876
        },
        "hunyuan-turbo-0110": {
            "rating": 1302.8594650623743,
            "rating_q975": 1336.874267591763,
            "rating_q025": 1268.8446625329855
        },
        "llama-4-maverick-17b-128e-instruct": {
            "rating": 1301.940607941259,
            "rating_q975": 1313.0791438647807,
            "rating_q025": 1290.8020720177374
        },
        "claude-3-5-sonnet-20240620": {
            "rating": 1299.3663349031708,
            "rating_q975": 1306.4377677287828,
            "rating_q025": 1292.2949020775588
        },
        "glm-4-plus-0111": {
            "rating": 1296.8136704674357,
            "rating_q975": 1317.4662423528684,
            "rating_q025": 1276.161098582003
        },
        "qwen2.5-72b-instruct": {
            "rating": 1295.7241287637175,
            "rating_q975": 1303.893789614088,
            "rating_q025": 1287.554467913347
        },
        "hunyuan-standard-2025-02-10": {
            "rating": 1294.5819045684593,
            "rating_q975": 1320.0237336753,
            "rating_q025": 1269.1400754616186
        },
        "hunyuan-turbos-20250226": {
            "rating": 1294.225666094865,
            "rating_q975": 1326.376412712387,
            "rating_q025": 1262.0749194773427
        },
        "llama-3.1-nemotron-70b-instruct": {
            "rating": 1292.8640143893972,
            "rating_q975": 1310.9961082061711,
            "rating_q025": 1274.7319205726233
        },
        "llama-4-scout-17b-16e-instruct": {
            "rating": 1291.242789270484,
            "rating_q975": 1304.5045169066664,
            "rating_q025": 1277.9810616343018
        },
        "gpt-4o-2024-05-13": {
            "rating": 1289.8976167551632,
            "rating_q975": 1296.3788719174522,
            "rating_q025": 1283.4163615928742
        },
        "grok-2-2024-08-13": {
            "rating": 1289.423641566129,
            "rating_q975": 1296.366617714902,
            "rating_q025": 1282.4806654173558
        },
        "gpt-4o-2024-08-06": {
            "rating": 1288.8413088644725,
            "rating_q975": 1296.7144688817993,
            "rating_q025": 1280.9681488471456
        },
        "glm-4-plus": {
            "rating": 1288.3819798235247,
            "rating_q975": 1298.4779550659757,
            "rating_q025": 1278.2860045810737
        },
        "gemini-1.5-flash-002": {
            "rating": 1284.8536696973129,
            "rating_q975": 1293.5027495748575,
            "rating_q025": 1276.2045898197682
        },
        "qwen-max-0919": {
            "rating": 1284.5218844445694,
            "rating_q975": 1297.1923625701206,
            "rating_q025": 1271.8514063190182
        },
        "gemma-3n-e4b-it": {
            "rating": 1283.957896786892,
            "rating_q975": 1298.8904396457556,
            "rating_q025": 1269.0253539280284
        },
        "deepseek-v2.5-1210": {
            "rating": 1283.623321186762,
            "rating_q975": 1301.0593695353978,
            "rating_q025": 1266.1872728381263
        },
        "gemini-1.5-pro-001": {
            "rating": 1281.9998310814628,
            "rating_q975": 1289.557599472649,
            "rating_q025": 1274.4420626902768
        },
        "llama-3.1-405b-instruct-fp8": {
            "rating": 1281.8260212182754,
            "rating_q975": 1289.1099642869642,
            "rating_q025": 1274.5420781495866
        },
        "llama-3.1-405b-instruct-bf16": {
            "rating": 1281.570495400695,
            "rating_q975": 1289.6579266166796,
            "rating_q025": 1273.4830641847107
        },
        "gemini-advanced-0514": {
            "rating": 1281.2575169920688,
            "rating_q975": 1290.73194486936,
            "rating_q025": 1271.7830891147776
        },
        "mistral-small-3.1-24b-instruct-2503": {
            "rating": 1280.4535197040232,
            "rating_q975": 1293.4336078411225,
            "rating_q025": 1267.4734315669239
        },
        "gpt-4.1-nano-2025-04-14": {
            "rating": 1279.7309648038918,
            "rating_q975": 1303.8547797321582,
            "rating_q025": 1255.6071498756253
        },
        "deepseek-v2.5": {
            "rating": 1279.5363207940072,
            "rating_q975": 1289.4432722725314,
            "rating_q025": 1269.629369315483
        },
        "grok-2-mini-2024-08-13": {
            "rating": 1278.2029078207079,
            "rating_q975": 1285.6012031736689,
            "rating_q025": 1270.804612467747
        },
        "gpt-4o-mini-2024-07-18": {
            "rating": 1276.4123047198746,
            "rating_q975": 1283.0183766081977,
            "rating_q025": 1269.8062328315514
        },
        "gpt-4-1106-preview": {
            "rating": 1275.6536105219338,
            "rating_q975": 1283.1748611318583,
            "rating_q025": 1268.1323599120094
        },
        "gpt-4-turbo-2024-04-09": {
            "rating": 1273.4403412864697,
            "rating_q975": 1280.7367786632744,
            "rating_q025": 1266.143903909665
        },
        "llama-3.3-70b-instruct": {
            "rating": 1272.4698160493858,
            "rating_q975": 1280.0223383845664,
            "rating_q025": 1264.9172937142052
        },
        "mistral-large-2407": {
            "rating": 1271.530902919274,
            "rating_q975": 1279.4296253978873,
            "rating_q025": 1263.6321804406607
        },
        "magistral-medium-2506": {
            "rating": 1269.7132282801863,
            "rating_q975": 1294.8154578931744,
            "rating_q025": 1244.6109986671981
        },
        "claude-3-opus-20240229": {
            "rating": 1269.2753301079642,
            "rating_q975": 1275.176810075067,
            "rating_q025": 1263.3738501408616
        },
        "amazon-nova-pro-v1.0": {
            "rating": 1266.4475138605512,
            "rating_q975": 1276.4758609387002,
            "rating_q025": 1256.4191667824023
        },
        "gpt-4-0125-preview": {
            "rating": 1266.3987276347234,
            "rating_q975": 1274.009991488191,
            "rating_q025": 1258.7874637812558
        },
        "mistral-large-2411": {
            "rating": 1262.7999608163468,
            "rating_q975": 1272.3976448989342,
            "rating_q025": 1253.2022767337594
        },
        "gemma-3-4b-it": {
            "rating": 1260.8263368932128,
            "rating_q975": 1291.0551611167818,
            "rating_q025": 1230.5975126696437
        },
        "phi-4": {
            "rating": 1259.4434708438835,
            "rating_q975": 1270.68068572864,
            "rating_q025": 1248.206255959127
        },
        "llama-3.1-70b-instruct": {
            "rating": 1258.8405190516369,
            "rating_q975": 1266.2523519593883,
            "rating_q025": 1251.4286861438854
        },
        "claude-3-5-haiku-20241022": {
            "rating": 1256.2121496427985,
            "rating_q975": 1263.6901700412543,
            "rating_q025": 1248.7341292443427
        },
        "llama-3.1-tulu-3-70b": {
            "rating": 1251.9608865398232,
            "rating_q975": 1279.8135681253782,
            "rating_q025": 1224.108204954268
        },
        "mistral-small-24b-instruct-2501": {
            "rating": 1249.2200563248568,
            "rating_q975": 1263.3549017341213,
            "rating_q025": 1235.0852109155924
        },
        "qwen2.5-coder-32b-instruct": {
            "rating": 1248.9558381935071,
            "rating_q975": 1269.5073215290645,
            "rating_q025": 1228.4043548579498
        },
        "hunyuan-standard-256k": {
            "rating": 1248.9320565135197,
            "rating_q975": 1280.291945542392,
            "rating_q025": 1217.5721674846473
        },
        "reka-core-20240904": {
            "rating": 1244.5398214086226,
            "rating_q975": 1259.858126258088,
            "rating_q025": 1229.2215165591572
        },
        "gemini-1.5-flash-001": {
            "rating": 1243.6899545774177,
            "rating_q975": 1251.4930801310682,
            "rating_q025": 1235.8868290237672
        },
        "amazon-nova-lite-v1.0": {
            "rating": 1240.3336589550286,
            "rating_q975": 1251.5420623655375,
            "rating_q025": 1229.1252555445196
        },
        "athene-70b-0725": {
            "rating": 1238.8644306177907,
            "rating_q975": 1249.449170262365,
            "rating_q025": 1228.2796909732165
        },
        "deepseek-coder-v2": {
            "rating": 1238.640805734808,
            "rating_q975": 1252.3434609531753,
            "rating_q025": 1224.9381505164408
        },
        "qwen2-72b-instruct": {
            "rating": 1235.8378600826077,
            "rating_q975": 1245.2513968985393,
            "rating_q025": 1226.424323266676
        },
        "glm-4-0520": {
            "rating": 1234.957198480349,
            "rating_q975": 1251.0910689305972,
            "rating_q025": 1218.8233280301008
        },
        "llama-3.1-nemotron-51b-instruct": {
            "rating": 1234.188939797993,
            "rating_q975": 1259.597578651118,
            "rating_q025": 1208.780300944868
        },
        "jamba-1.5-large": {
            "rating": 1233.2330647504382,
            "rating_q975": 1249.7332487001433,
            "rating_q025": 1216.732880800733
        },
        "gpt-4-0314": {
            "rating": 1233.082860963297,
            "rating_q975": 1242.7186590024437,
            "rating_q025": 1223.4470629241503
        },
        "gemini-1.5-flash-8b-001": {
            "rating": 1231.4514541947954,
            "rating_q975": 1239.9381792601976,
            "rating_q025": 1222.9647291293932
        },
        "qwq-32b-preview": {
            "rating": 1227.2841695649267,
            "rating_q975": 1253.6902545721696,
            "rating_q025": 1200.878084557684
        },
        "gemma-2-27b-it": {
            "rating": 1227.067692146834,
            "rating_q975": 1233.4864665531093,
            "rating_q025": 1220.6489177405585
        },
        "nemotron-4-340b-instruct": {
            "rating": 1221.124359546036,
            "rating_q975": 1233.329899156973,
            "rating_q025": 1208.918819935099
        },
        "llama-3-70b-instruct": {
            "rating": 1219.202238747699,
            "rating_q975": 1226.2511695381859,
            "rating_q025": 1212.1533079572123
        },
        "claude-3-sonnet-20240229": {
            "rating": 1218.8847826133028,
            "rating_q975": 1226.6256273213858,
            "rating_q025": 1211.14393790522
        },
        "amazon-nova-micro-v1.0": {
            "rating": 1217.616922988836,
            "rating_q975": 1229.1823620047371,
            "rating_q025": 1206.0514839729349
        },
        "c4ai-aya-expanse-32b": {
            "rating": 1213.9188483955354,
            "rating_q975": 1223.7720580353425,
            "rating_q025": 1204.0656387557283
        },
        "reka-flash-20240904": {
            "rating": 1207.767042549845,
            "rating_q975": 1222.7004585596749,
            "rating_q025": 1192.833626540015
        },
        "gpt-4-0613": {
            "rating": 1206.5590235754526,
            "rating_q975": 1214.741181353563,
            "rating_q025": 1198.3768657973421
        },
        "command-r-plus-08-2024": {
            "rating": 1203.8350016440268,
            "rating_q975": 1218.4115522321667,
            "rating_q025": 1189.2584510558868
        },
        "olmo-2-0325-32b-instruct": {
            "rating": 1201.7679057268224,
            "rating_q975": 1231.684661747834,
            "rating_q025": 1171.8511497058107
        },
        "gemma-2-9b-it-simpo": {
            "rating": 1201.489975173005,
            "rating_q975": 1216.9225089752704,
            "rating_q025": 1186.0574413707395
        },
        "gemma-2-9b-it": {
            "rating": 1199.0839999786208,
            "rating_q975": 1206.5102474455402,
            "rating_q025": 1191.6577525117013
        },
        "llama-3.1-tulu-3-8b": {
            "rating": 1198.3479161051719,
            "rating_q975": 1227.7437913012132,
            "rating_q025": 1168.9520409091306
        },
        "qwen1.5-110b-chat": {
            "rating": 1196.0794628654464,
            "rating_q975": 1207.3961086554714,
            "rating_q025": 1184.7628170754215
        },
        "mistral-large-2402": {
            "rating": 1195.4728316647008,
            "rating_q975": 1204.3751978636933,
            "rating_q025": 1186.5704654657084
        },
        "claude-3-haiku-20240307": {
            "rating": 1193.1986033589178,
            "rating_q975": 1200.2643558546422,
            "rating_q025": 1186.1328508631934
        },
        "granite-3.1-2b-instruct": {
            "rating": 1192.3695993213214,
            "rating_q975": 1220.828872938915,
            "rating_q025": 1163.9103257037277
        },
        "yi-1.5-34b-chat": {
            "rating": 1191.125187977243,
            "rating_q975": 1202.3236944253738,
            "rating_q025": 1179.9266815291123
        },
        "ministral-8b-2410": {
            "rating": 1189.967856108578,
            "rating_q975": 1211.6662153917823,
            "rating_q025": 1168.2694968253736
        },
        "granite-3.1-8b-instruct": {
            "rating": 1187.7512673743186,
            "rating_q975": 1218.331088073348,
            "rating_q025": 1157.1714466752892
        },
        "internlm2_5-20b-chat": {
            "rating": 1186.8130034053606,
            "rating_q975": 1202.86234140681,
            "rating_q025": 1170.7636654039113
        },
        "llama-3.1-8b-instruct": {
            "rating": 1185.9138810672298,
            "rating_q975": 1193.7013471935754,
            "rating_q025": 1178.1264149408842
        },
        "mixtral-8x22b-instruct-v0.1": {
            "rating": 1184.6286340704264,
            "rating_q975": 1193.5322522117654,
            "rating_q025": 1175.7250159290875
        },
        "mistral-medium": {
            "rating": 1183.2979174114741,
            "rating_q975": 1194.1733134401024,
            "rating_q025": 1172.4225213828458
        },
        "c4ai-aya-expanse-8b": {
            "rating": 1182.6118645960323,
            "rating_q975": 1198.2801763217851,
            "rating_q025": 1166.9435528702795
        },
        "phi-3-medium-4k-instruct": {
            "rating": 1181.7196101389277,
            "rating_q975": 1192.4164092349856,
            "rating_q025": 1171.0228110428698
        },
        "qwen1.5-72b-chat": {
            "rating": 1177.4243349131452,
            "rating_q975": 1187.2039593116108,
            "rating_q025": 1167.6447105146797
        },
        "reka-flash-21b-20240226-online": {
            "rating": 1171.760936042822,
            "rating_q975": 1185.9458154444092,
            "rating_q025": 1157.576056641235
        },
        "command-r-08-2024": {
            "rating": 1171.5829312405485,
            "rating_q975": 1185.6972680209115,
            "rating_q025": 1157.4685944601856
        },
        "command-r-plus": {
            "rating": 1170.8783090065149,
            "rating_q975": 1179.2076775592163,
            "rating_q025": 1162.5489404538134
        },
        "qwen1.5-32b-chat": {
            "rating": 1168.3093012249133,
            "rating_q975": 1180.3826331412033,
            "rating_q025": 1156.2359693086232
        },
        "jamba-1.5-mini": {
            "rating": 1166.7820107089833,
            "rating_q975": 1183.7158314414432,
            "rating_q025": 1149.8481899765234
        },
        "reka-flash-21b-20240226": {
            "rating": 1164.5367246566893,
            "rating_q975": 1176.1312634109265,
            "rating_q025": 1152.9421859024521
        },
        "llama-3-8b-instruct": {
            "rating": 1159.161686385138,
            "rating_q975": 1166.705748979873,
            "rating_q025": 1151.6176237904028
        },
        "phi-3-small-8k-instruct": {
            "rating": 1158.661180993763,
            "rating_q975": 1171.8659977288416,
            "rating_q025": 1145.4563642586845
        },
        "granite-3.0-8b-instruct": {
            "rating": 1157.9176024400786,
            "rating_q975": 1178.9037767691036,
            "rating_q025": 1136.9314281110535
        },
        "phi-3-mini-4k-instruct-june-2024": {
            "rating": 1152.0614737311696,
            "rating_q975": 1166.3251014710627,
            "rating_q025": 1137.7978459912765
        },
        "gemma-2-2b-it": {
            "rating": 1151.3456537445456,
            "rating_q975": 1159.2309272395503,
            "rating_q025": 1143.460380249541
        },
        "zephyr-orpo-141b-A35b-v0.1": {
            "rating": 1151.1470811553131,
            "rating_q975": 1174.913034284727,
            "rating_q025": 1127.3811280258992
        },
        "mixtral-8x7b-instruct-v0.1": {
            "rating": 1148.6808029152523,
            "rating_q975": 1157.0423344541591,
            "rating_q025": 1140.3192713763456
        },
        "gemini-pro": {
            "rating": 1141.9979950946308,
            "rating_q975": 1162.649657491812,
            "rating_q025": 1121.3463326974497
        },
        "qwen1.5-14b-chat": {
            "rating": 1140.9488243557144,
            "rating_q975": 1154.3861038437392,
            "rating_q025": 1127.5115448676895
        },
        "granite-3.0-2b-instruct": {
            "rating": 1136.6317746124305,
            "rating_q975": 1157.3241979779289,
            "rating_q025": 1115.9393512469321
        },
        "dbrx-instruct-preview": {
            "rating": 1136.4230347803846,
            "rating_q975": 1148.0604458704033,
            "rating_q025": 1124.7856236903658
        },
        "starling-lm-7b-beta": {
            "rating": 1135.4883184993657,
            "rating_q975": 1149.720645366186,
            "rating_q025": 1121.2559916325454
        },
        "gpt-3.5-turbo-1106": {
            "rating": 1134.1810080872797,
            "rating_q975": 1150.4893466748165,
            "rating_q025": 1117.8726694997429
        },
        "llama-3.2-3b-instruct": {
            "rating": 1134.1387686049893,
            "rating_q975": 1150.6159109840246,
            "rating_q025": 1117.661626225954
        },
        "gpt-3.5-turbo-0125": {
            "rating": 1132.6665122904524,
            "rating_q975": 1141.0863015310586,
            "rating_q025": 1124.2467230498462
        },
        "command-r": {
            "rating": 1130.6060125001436,
            "rating_q975": 1140.1688269891533,
            "rating_q025": 1121.0431980111339
        },
        "gemini-pro-dev-api": {
            "rating": 1129.380434758537,
            "rating_q975": 1143.964464911604,
            "rating_q025": 1114.79640460547
        },
        "smollm2-1.7b-instruct": {
            "rating": 1128.7953018739674,
            "rating_q975": 1162.72781853633,
            "rating_q025": 1094.862785211605
        },
        "yi-34b-chat": {
            "rating": 1121.7382469619115,
            "rating_q975": 1135.6421112023443,
            "rating_q025": 1107.8343827214787
        },
        "phi-3-mini-4k-instruct": {
            "rating": 1115.5021935991263,
            "rating_q975": 1128.12196037056,
            "rating_q025": 1102.8824268276926
        },
        "wizardlm-70b": {
            "rating": 1112.9388230749255,
            "rating_q975": 1133.369316090421,
            "rating_q025": 1092.50833005943
        },
        "qwen1.5-7b-chat": {
            "rating": 1112.4745882985258,
            "rating_q975": 1135.312042904609,
            "rating_q025": 1089.6371336924426
        },
        "tulu-2-dpo-70b": {
            "rating": 1104.4893592464537,
            "rating_q975": 1124.7944112648995,
            "rating_q025": 1084.1843072280078
        },
        "snowflake-arctic-instruct": {
            "rating": 1103.57723860438,
            "rating_q975": 1115.1085113477866,
            "rating_q025": 1092.0459658609734
        },
        "gemma-1.1-7b-it": {
            "rating": 1103.3680195951658,
            "rating_q975": 1114.874506482395,
            "rating_q025": 1091.8615327079367
        },
        "llama-3.2-1b-instruct": {
            "rating": 1103.330954136497,
            "rating_q975": 1120.942934510484,
            "rating_q025": 1085.71897376251
        },
        "openhermes-2.5-mistral-7b": {
            "rating": 1102.5576640859672,
            "rating_q975": 1124.588385654051,
            "rating_q025": 1080.5269425178833
        },
        "openchat-3.5-0106": {
            "rating": 1099.6058064714266,
            "rating_q975": 1114.3060652663053,
            "rating_q025": 1084.905547676548
        },
        "deepseek-llm-67b-chat": {
            "rating": 1098.7801748970753,
            "rating_q975": 1125.2958873922112,
            "rating_q025": 1072.2644624019395
        },
        "llama-2-70b-chat": {
            "rating": 1094.7288721344544,
            "rating_q975": 1105.2617869849812,
            "rating_q025": 1084.1959572839276
        },
        "mistral-7b-instruct-v0.2": {
            "rating": 1091.6561643088612,
            "rating_q975": 1104.1451858241667,
            "rating_q025": 1079.1671427935557
        },
        "phi-3-mini-128k-instruct": {
            "rating": 1089.3946018672505,
            "rating_q975": 1102.7048574686053,
            "rating_q025": 1076.0843462658956
        },
        "starling-lm-7b-alpha": {
            "rating": 1088.561762093374,
            "rating_q975": 1105.531722567796,
            "rating_q025": 1071.591801618952
        },
        "vicuna-33b": {
            "rating": 1081.788464508265,
            "rating_q975": 1094.929484982345,
            "rating_q025": 1068.647444034185
        },
        "qwen-14b-chat": {
            "rating": 1078.7216924538138,
            "rating_q975": 1104.4324562642773,
            "rating_q025": 1053.0109286433503
        },
        "llama-2-13b-chat": {
            "rating": 1074.643985788247,
            "rating_q975": 1088.386942870571,
            "rating_q025": 1060.901028705923
        },
        "openchat-3.5": {
            "rating": 1074.5428069071747,
            "rating_q975": 1094.4004374626775,
            "rating_q025": 1054.685176351672
        },
        "llama2-70b-steerlm-chat": {
            "rating": 1070.630257321899,
            "rating_q975": 1100.5671435754725,
            "rating_q025": 1040.6933710683256
        },
        "gemma-7b-it": {
            "rating": 1067.5538328196255,
            "rating_q975": 1084.8129199051016,
            "rating_q025": 1050.2947457341495
        },
        "solar-10.7b-instruct-v1.0": {
            "rating": 1062.1489141202314,
            "rating_q975": 1085.5415008734951,
            "rating_q025": 1038.7563273669678
        },
        "dolphin-2.2.1-mistral-7b": {
            "rating": 1061.0170457324666,
            "rating_q975": 1095.6945321599464,
            "rating_q025": 1026.3395593049868
        },
        "codellama-34b-instruct": {
            "rating": 1060.5660867929105,
            "rating_q975": 1081.6542219536827,
            "rating_q025": 1039.4779516321382
        },
        "mpt-30b-chat": {
            "rating": 1058.7060867559562,
            "rating_q975": 1096.0611968560684,
            "rating_q025": 1021.350976655844
        },
        "nous-hermes-2-mixtral-8x7b-dpo": {
            "rating": 1055.5585423942189,
            "rating_q975": 1081.2981738510794,
            "rating_q025": 1029.8189109373584
        },
        "zephyr-7b-beta": {
            "rating": 1049.4724086749513,
            "rating_q975": 1067.450163443568,
            "rating_q025": 1031.4946539063346
        },
        "gemma-1.1-2b-it": {
            "rating": 1049.1256051314124,
            "rating_q975": 1065.9724888089954,
            "rating_q025": 1032.2787214538293
        },
        "palm-2": {
            "rating": 1048.536824238483,
            "rating_q975": 1069.4545436152616,
            "rating_q025": 1027.6191048617043
        },
        "llama-2-7b-chat": {
            "rating": 1044.3451166741816,
            "rating_q975": 1059.4063517038778,
            "rating_q025": 1029.2838816444853
        },
        "vicuna-13b": {
            "rating": 1027.2118530770185,
            "rating_q975": 1041.9857101728687,
            "rating_q025": 1012.4379959811682
        },
        "stripedhyena-nous-7b": {
            "rating": 1026.7705744511982,
            "rating_q975": 1049.9884547572738,
            "rating_q025": 1003.5526941451227
        },
        "guanaco-33b": {
            "rating": 1025.4223071798997,
            "rating_q975": 1061.0394464222395,
            "rating_q025": 989.80516793756
        },
        "olmo-7b-instruct": {
            "rating": 1024.2226935245117,
            "rating_q975": 1044.4259504754286,
            "rating_q025": 1004.0194365735947
        },
        "wizardlm-13b": {
            "rating": 1020.5725919330328,
            "rating_q975": 1043.7753452659626,
            "rating_q025": 997.3698386001029
        },
        "mistral-7b-instruct": {
            "rating": 1014.7629998198931,
            "rating_q975": 1035.706298141561,
            "rating_q025": 993.8197014982251
        },
        "gemma-2b-it": {
            "rating": 1010.924311070065,
            "rating_q975": 1035.306685086187,
            "rating_q025": 986.5419370539429
        },
        "qwen1.5-4b-chat": {
            "rating": 1003.7335100782338,
            "rating_q975": 1023.4940435174965,
            "rating_q025": 983.9729766389712
        },
        "vicuna-7b": {
            "rating": 985.2330614896932,
            "rating_q975": 1008.9409093744521,
            "rating_q025": 961.5252136049344
        },
        "chatglm3-6b": {
            "rating": 969.8893713726268,
            "rating_q975": 996.5703591431295,
            "rating_q025": 943.2083836021241
        },
        "koala-13b": {
            "rating": 934.0235692749613,
            "rating_q975": 956.9167027986124,
            "rating_q025": 911.1304357513103
        },
        "RWKV-4-Raven-14B": {
            "rating": 924.4417532186031,
            "rating_q975": 950.511859396675,
            "rating_q025": 898.3716470405312
        },
        "chatglm-6b": {
            "rating": 917.4100522476924,
            "rating_q975": 945.1920084114125,
            "rating_q025": 889.6280960839723
        },
        "mpt-7b-chat": {
            "rating": 912.2773900471151,
            "rating_q975": 941.0250844461551,
            "rating_q025": 883.5296956480751
        },
        "oasst-pythia-12b": {
            "rating": 896.1042550170944,
            "rating_q975": 921.2431515316479,
            "rating_q025": 870.9653585025409
        },
        "alpaca-13b": {
            "rating": 884.788492899223,
            "rating_q975": 910.3452961207876,
            "rating_q025": 859.2316896776584
        },
        "fastchat-t5-3b": {
            "rating": 856.640423746521,
            "rating_q975": 885.2713974124111,
            "rating_q025": 828.0094500806309
        },
        "dolly-v2-12b": {
            "rating": 845.3041334355245,
            "rating_q975": 876.2000938287345,
            "rating_q025": 814.4081730423145
        },
        "stablelm-tuned-alpha-7b": {
            "rating": 840.4393237774658,
            "rating_q975": 872.1469364314652,
            "rating_q025": 808.7317111234664
        },
        "llama-13b": {
            "rating": 838.7405519390468,
            "rating_q975": 876.098523552565,
            "rating_q025": 801.3825803255286
        }
    },
    "industry_medicine_and_healthcare": {
        "gemini-3-pro": {
            "rating": 1508.763827803621,
            "rating_q975": 1531.3052935292596,
            "rating_q025": 1486.2223620779826
        },
        "gemini-2.5-pro": {
            "rating": 1483.9502282166122,
            "rating_q975": 1494.3574714117717,
            "rating_q025": 1473.5429850214528
        },
        "grok-4.1-thinking": {
            "rating": 1477.7250196973523,
            "rating_q975": 1499.913652967445,
            "rating_q025": 1455.5363864272597
        },
        "deepseek-v3.2-exp-thinking": {
            "rating": 1472.2434190876374,
            "rating_q975": 1501.384631682687,
            "rating_q025": 1443.1022064925878
        },
        "qwen3-max-preview": {
            "rating": 1471.897898715259,
            "rating_q975": 1488.4134976786388,
            "rating_q025": 1455.3822997518794
        },
        "gpt-5.1-high": {
            "rating": 1470.9289056521343,
            "rating_q975": 1494.5524781533172,
            "rating_q025": 1447.3053331509514
        },
        "grok-3-preview-02-24": {
            "rating": 1470.3738981744914,
            "rating_q975": 1485.3338928590529,
            "rating_q025": 1455.41390348993
        },
        "deepseek-v3.1-terminus-thinking": {
            "rating": 1466.752958331303,
            "rating_q975": 1505.6187896898655,
            "rating_q025": 1427.8871269727406
        },
        "mistral-medium-2508": {
            "rating": 1465.5138546044527,
            "rating_q975": 1479.0561896451704,
            "rating_q025": 1451.971519563735
        },
        "longcat-flash-chat": {
            "rating": 1464.386505870682,
            "rating_q975": 1488.295656220782,
            "rating_q025": 1440.477355520582
        },
        "qwen3-next-80b-a3b-instruct": {
            "rating": 1461.6772209804544,
            "rating_q975": 1479.6015219736366,
            "rating_q025": 1443.7529199872722
        },
        "chatgpt-4o-latest-20250326": {
            "rating": 1461.0453815595977,
            "rating_q975": 1472.433564568709,
            "rating_q025": 1449.6571985504863
        },
        "glm-4.6": {
            "rating": 1460.3958001415529,
            "rating_q975": 1479.111531625818,
            "rating_q025": 1441.6800686572876
        },
        "qwen3-235b-a22b-thinking-2507": {
            "rating": 1459.4584726123683,
            "rating_q975": 1485.1217940632484,
            "rating_q025": 1433.795151161488
        },
        "grok-4.1": {
            "rating": 1458.3190300636816,
            "rating_q975": 1479.5711567601247,
            "rating_q025": 1437.0669033672384
        },
        "glm-4.5": {
            "rating": 1458.2264620516503,
            "rating_q975": 1474.9819105478068,
            "rating_q025": 1441.4710135554938
        },
        "hunyuan-t1-20250711": {
            "rating": 1455.893923857344,
            "rating_q975": 1494.3982828510832,
            "rating_q025": 1417.3895648636046
        },
        "mistral-large-3": {
            "rating": 1455.7998260755442,
            "rating_q975": 1490.2923589170207,
            "rating_q025": 1421.3072932340676
        },
        "o3-2025-04-16": {
            "rating": 1454.6760930154549,
            "rating_q975": 1466.1087780390017,
            "rating_q025": 1443.243407991908
        },
        "ernie-5.0-preview-1103": {
            "rating": 1453.6344503282357,
            "rating_q975": 1485.434654233889,
            "rating_q025": 1421.8342464225825
        },
        "deepseek-v3.1-terminus": {
            "rating": 1452.0458403124621,
            "rating_q975": 1489.9405437490154,
            "rating_q025": 1414.1511368759088
        },
        "qwen3-235b-a22b-instruct-2507": {
            "rating": 1450.507435372438,
            "rating_q975": 1463.261712374288,
            "rating_q025": 1437.7531583705882
        },
        "claude-opus-4-5-20251101": {
            "rating": 1449.9614417132116,
            "rating_q975": 1477.3209072722984,
            "rating_q025": 1422.6019761541247
        },
        "deepseek-v3.1-thinking": {
            "rating": 1449.6528334584057,
            "rating_q975": 1472.2557401674446,
            "rating_q025": 1427.0499267493667
        },
        "deepseek-r1-0528": {
            "rating": 1446.9100106170108,
            "rating_q975": 1464.210308816442,
            "rating_q025": 1429.6097124175797
        },
        "claude-sonnet-4-5-20250929": {
            "rating": 1446.1625621275343,
            "rating_q975": 1464.8800027553111,
            "rating_q025": 1427.4451214997575
        },
        "gpt-5.1": {
            "rating": 1445.4894323661226,
            "rating_q975": 1469.0875301462213,
            "rating_q025": 1421.891334586024
        },
        "deepseek-v3.2": {
            "rating": 1445.4143187010004,
            "rating_q975": 1478.3264223221076,
            "rating_q025": 1412.5022150798932
        },
        "grok-4-0709": {
            "rating": 1444.911077151085,
            "rating_q975": 1458.1292935187996,
            "rating_q025": 1431.6928607833704
        },
        "deepseek-v3.1": {
            "rating": 1442.9417472414796,
            "rating_q975": 1462.4875989134318,
            "rating_q025": 1423.3958955695273
        },
        "qwen3-vl-235b-a22b-instruct": {
            "rating": 1439.6431120434304,
            "rating_q975": 1468.205373220458,
            "rating_q025": 1411.080850866403
        },
        "deepseek-v3.2-thinking": {
            "rating": 1431.3350849821677,
            "rating_q975": 1463.95239224124,
            "rating_q025": 1398.7177777230954
        },
        "deepseek-v3.2-exp": {
            "rating": 1430.9109459305403,
            "rating_q975": 1456.422880394869,
            "rating_q025": 1405.3990114662115
        },
        "claude-opus-4-5-20251101-thinking-32k": {
            "rating": 1430.8984485149074,
            "rating_q975": 1459.8912941378856,
            "rating_q025": 1401.9056028919292
        },
        "gemini-2.5-flash-preview-09-2025": {
            "rating": 1430.10024510418,
            "rating_q975": 1447.0793170629079,
            "rating_q025": 1413.121173145452
        },
        "gemini-2.5-flash": {
            "rating": 1428.0147342492971,
            "rating_q975": 1438.3100525206316,
            "rating_q025": 1417.7194159779626
        },
        "grok-4-fast-chat": {
            "rating": 1426.074239576963,
            "rating_q975": 1456.759531007362,
            "rating_q025": 1395.388948146564
        },
        "amazon-nova-experimental-chat-10-20": {
            "rating": 1424.672165234491,
            "rating_q975": 1454.8525635425237,
            "rating_q025": 1394.4917669264585
        },
        "mai-1-preview": {
            "rating": 1423.950640810654,
            "rating_q975": 1442.2784281974311,
            "rating_q025": 1405.622853423877
        },
        "kimi-k2-thinking-turbo": {
            "rating": 1423.650780414223,
            "rating_q975": 1446.1480664675476,
            "rating_q025": 1401.1534943608983
        },
        "gpt-5-high": {
            "rating": 1422.4456262888284,
            "rating_q975": 1437.5306799389616,
            "rating_q025": 1407.3605726386952
        },
        "gpt-5-chat": {
            "rating": 1420.531857061546,
            "rating_q975": 1435.6998193843858,
            "rating_q025": 1405.363894738706
        },
        "claude-sonnet-4-5-20250929-thinking-32k": {
            "rating": 1418.862185161854,
            "rating_q975": 1436.9169533063275,
            "rating_q025": 1400.8074170173807
        },
        "qwen3-vl-235b-a22b-thinking": {
            "rating": 1418.8420744435002,
            "rating_q975": 1447.734230905778,
            "rating_q025": 1389.9499179812224
        },
        "claude-opus-4-1-20250805-thinking-16k": {
            "rating": 1418.7257772743171,
            "rating_q975": 1432.406851417889,
            "rating_q025": 1405.0447031307453
        },
        "grok-4-1-fast-reasoning": {
            "rating": 1418.3907965849885,
            "rating_q975": 1447.5078178692052,
            "rating_q025": 1389.2737753007718
        },
        "grok-4-fast-reasoning": {
            "rating": 1417.3286881719232,
            "rating_q975": 1438.3398738551114,
            "rating_q025": 1396.317502488735
        },
        "gpt-4.5-preview-2025-02-27": {
            "rating": 1416.0826080712204,
            "rating_q975": 1440.4063357340078,
            "rating_q025": 1391.758880408433
        },
        "hunyuan-turbos-20250416": {
            "rating": 1415.4478600747213,
            "rating_q975": 1439.877894393383,
            "rating_q025": 1391.0178257560597
        },
        "qwen3-max-2025-09-23": {
            "rating": 1414.3995909007178,
            "rating_q975": 1442.8531097863072,
            "rating_q025": 1385.9460720151285
        },
        "claude-opus-4-1-20250805": {
            "rating": 1411.8406771267946,
            "rating_q975": 1424.0668070388747,
            "rating_q025": 1399.6145472147145
        },
        "qwen3-235b-a22b-no-thinking": {
            "rating": 1411.7679977859552,
            "rating_q975": 1424.673063549474,
            "rating_q025": 1398.8629320224366
        },
        "glm-4.5-air": {
            "rating": 1410.4750115571403,
            "rating_q975": 1425.4758006368186,
            "rating_q025": 1395.474222477462
        },
        "gemini-2.5-flash-lite-preview-09-2025-no-thinking": {
            "rating": 1399.6577639216325,
            "rating_q975": 1417.1290096978705,
            "rating_q025": 1382.1865181453945
        },
        "grok-3-mini-high": {
            "rating": 1397.4791974015807,
            "rating_q975": 1416.3516544402005,
            "rating_q025": 1378.6067403629609
        },
        "gpt-oss-120b": {
            "rating": 1395.5899964521361,
            "rating_q975": 1411.1456203064372,
            "rating_q025": 1380.034372597835
        },
        "qwen3-30b-a3b-instruct-2507": {
            "rating": 1395.1121045856041,
            "rating_q975": 1411.8501149691183,
            "rating_q025": 1378.37409420209
        },
        "qwen3-next-80b-a3b-thinking": {
            "rating": 1394.105333987777,
            "rating_q975": 1416.7916555729635,
            "rating_q025": 1371.4190124025904
        },
        "gemma-3-27b-it": {
            "rating": 1393.723281877998,
            "rating_q975": 1406.3422179622607,
            "rating_q025": 1381.1043457937353
        },
        "glm-4-plus-0111": {
            "rating": 1393.551634487634,
            "rating_q975": 1427.450593491045,
            "rating_q025": 1359.6526754842228
        },
        "gemini-2.5-flash-lite-preview-06-17-thinking": {
            "rating": 1391.8409433426104,
            "rating_q975": 1405.7890836199522,
            "rating_q025": 1377.8928030652687
        },
        "kimi-k2-0905-preview": {
            "rating": 1390.6005551856574,
            "rating_q975": 1413.3372044444568,
            "rating_q025": 1367.863905926858
        },
        "qwen2.5-max": {
            "rating": 1388.8208310733999,
            "rating_q975": 1403.5247183607275,
            "rating_q025": 1374.1169437860722
        },
        "deepseek-v3-0324": {
            "rating": 1387.2583437549454,
            "rating_q975": 1399.1452983353581,
            "rating_q025": 1375.3713891745326
        },
        "gpt-4.1-2025-04-14": {
            "rating": 1387.0973733027445,
            "rating_q975": 1399.0866575526366,
            "rating_q025": 1375.1080890528524
        },
        "gpt-5-mini-high": {
            "rating": 1384.8321964049812,
            "rating_q975": 1401.2820274661763,
            "rating_q025": 1368.3823653437862
        },
        "mistral-medium-2505": {
            "rating": 1384.3634094048684,
            "rating_q975": 1398.0658519624283,
            "rating_q025": 1370.6609668473086
        },
        "claude-haiku-4-5-20251001": {
            "rating": 1382.2286586592545,
            "rating_q975": 1400.5353913831925,
            "rating_q025": 1363.9219259353165
        },
        "ling-flash-2.0": {
            "rating": 1379.7340599248791,
            "rating_q975": 1409.9873173564588,
            "rating_q025": 1349.4808024932995
        },
        "nova-2-lite": {
            "rating": 1378.3692292543324,
            "rating_q975": 1413.7574912973616,
            "rating_q025": 1342.980967211303
        },
        "nvidia-llama-3.3-nemotron-super-49b-v1.5": {
            "rating": 1377.3955010747147,
            "rating_q975": 1418.565738230024,
            "rating_q025": 1336.2252639194055
        },
        "minimax-m1": {
            "rating": 1377.0575316016366,
            "rating_q975": 1390.2811147212965,
            "rating_q025": 1363.8339484819767
        },
        "deepseek-r1": {
            "rating": 1375.2276652476285,
            "rating_q975": 1395.7054867786835,
            "rating_q025": 1354.7498437165734
        },
        "kimi-k2-0711-preview": {
            "rating": 1375.1430122254224,
            "rating_q975": 1390.0330677035167,
            "rating_q025": 1360.252956747328
        },
        "gemini-2.0-flash-001": {
            "rating": 1373.6027463130783,
            "rating_q975": 1386.1177630092845,
            "rating_q025": 1361.0877296168721
        },
        "amazon-nova-experimental-chat-10-09": {
            "rating": 1373.5325365259887,
            "rating_q975": 1405.5720606447153,
            "rating_q025": 1341.493012407262
        },
        "qwen3-32b": {
            "rating": 1373.2003571201187,
            "rating_q975": 1412.3067411597533,
            "rating_q025": 1334.0939730804841
        },
        "grok-3-mini-beta": {
            "rating": 1369.3412017515238,
            "rating_q975": 1385.3045859511356,
            "rating_q025": 1353.3778175519121
        },
        "qwen3-235b-a22b": {
            "rating": 1368.872891095141,
            "rating_q975": 1384.1196704029192,
            "rating_q025": 1353.626111787363
        },
        "o4-mini-2025-04-16": {
            "rating": 1366.6992977800937,
            "rating_q975": 1379.2200915637886,
            "rating_q025": 1354.1785039963988
        },
        "minimax-m2": {
            "rating": 1366.6549348344313,
            "rating_q975": 1400.7211945628414,
            "rating_q025": 1332.5886751060211
        },
        "claude-opus-4-20250514": {
            "rating": 1365.3087573773344,
            "rating_q975": 1377.6425646328846,
            "rating_q025": 1352.974950121784
        },
        "step-3": {
            "rating": 1363.4428036194195,
            "rating_q975": 1394.8005859448924,
            "rating_q025": 1332.0850212939465
        },
        "claude-opus-4-20250514-thinking-16k": {
            "rating": 1363.332790027086,
            "rating_q975": 1376.5810319258333,
            "rating_q025": 1350.0845481283388
        },
        "o1-2024-12-17": {
            "rating": 1360.9000690088199,
            "rating_q975": 1377.5756280266519,
            "rating_q025": 1344.2245099909878
        },
        "step-2-16k-exp-202412": {
            "rating": 1360.1275903641301,
            "rating_q975": 1395.5175578391818,
            "rating_q025": 1324.7376228890785
        },
        "step-1o-turbo-202506": {
            "rating": 1358.9574764221964,
            "rating_q975": 1381.9468296955167,
            "rating_q025": 1335.968123148876
        },
        "glm-4.5v": {
            "rating": 1356.8539101712913,
            "rating_q975": 1395.6764276516412,
            "rating_q025": 1318.0313926909414
        },
        "qwen-plus-0125": {
            "rating": 1355.364877342705,
            "rating_q975": 1387.4232501875722,
            "rating_q025": 1323.306504497838
        },
        "mistral-small-2506": {
            "rating": 1351.7460142501898,
            "rating_q975": 1369.605360681732,
            "rating_q025": 1333.8866678186475
        },
        "deepseek-v3": {
            "rating": 1350.4989368276492,
            "rating_q975": 1368.3215769200249,
            "rating_q025": 1332.6762967352736
        },
        "gemini-2.0-flash-lite-preview-02-05": {
            "rating": 1350.440550972655,
            "rating_q975": 1368.8758248156546,
            "rating_q025": 1332.0052771296555
        },
        "qwen3-coder-480b-a35b-instruct": {
            "rating": 1348.9719262483502,
            "rating_q975": 1365.8554255512067,
            "rating_q025": 1332.0884269454937
        },
        "ring-flash-2.0": {
            "rating": 1347.4284025253712,
            "rating_q975": 1378.3054856961658,
            "rating_q025": 1316.5513193545767
        },
        "qwq-32b": {
            "rating": 1346.3290998472341,
            "rating_q975": 1362.0435243999602,
            "rating_q025": 1330.614675294508
        },
        "gemma-3-4b-it": {
            "rating": 1346.1400069855333,
            "rating_q975": 1385.4654210358933,
            "rating_q025": 1306.8145929351733
        },
        "hunyuan-large-2025-02-10": {
            "rating": 1345.4214040662569,
            "rating_q975": 1384.0326363902254,
            "rating_q025": 1306.8101717422883
        },
        "gpt-5-nano-high": {
            "rating": 1345.3676339271394,
            "rating_q975": 1372.8110239429757,
            "rating_q025": 1317.9242439113032
        },
        "command-a-03-2025": {
            "rating": 1340.1746643141278,
            "rating_q975": 1351.5642464105192,
            "rating_q025": 1328.7850822177363
        },
        "gemma-3-12b-it": {
            "rating": 1339.57355845227,
            "rating_q975": 1387.3303031907192,
            "rating_q025": 1291.8168137138207
        },
        "o3-mini-high": {
            "rating": 1335.4747366927152,
            "rating_q975": 1356.3125859813872,
            "rating_q025": 1314.6368874040431
        },
        "claude-sonnet-4-20250514": {
            "rating": 1334.3786306271134,
            "rating_q975": 1347.5800396391091,
            "rating_q025": 1321.1772216151176
        },
        "gpt-4.1-mini-2025-04-14": {
            "rating": 1330.4255111216244,
            "rating_q975": 1343.3063133301819,
            "rating_q025": 1317.5447089130669
        },
        "claude-sonnet-4-20250514-thinking-32k": {
            "rating": 1330.2762601763434,
            "rating_q975": 1343.8348736073292,
            "rating_q025": 1316.7176467453576
        },
        "gemma-3n-e4b-it": {
            "rating": 1329.6822727194624,
            "rating_q975": 1346.0793098037323,
            "rating_q025": 1313.2852356351925
        },
        "qwen3-30b-a3b": {
            "rating": 1324.6076333337073,
            "rating_q975": 1339.554475555726,
            "rating_q025": 1309.6607911116887
        },
        "gpt-oss-20b": {
            "rating": 1322.5247054365784,
            "rating_q975": 1348.0678306597715,
            "rating_q025": 1296.9815802133853
        },
        "olmo-3-32b-think": {
            "rating": 1318.7754716758268,
            "rating_q975": 1369.881382888308,
            "rating_q025": 1267.6695604633455
        },
        "hunyuan-standard-2025-02-10": {
            "rating": 1314.6858808958896,
            "rating_q975": 1351.4798202507902,
            "rating_q025": 1277.891941540989
        },
        "o1-preview": {
            "rating": 1313.1525609216305,
            "rating_q975": 1327.8985556596976,
            "rating_q025": 1298.4065661835634
        },
        "grok-2-2024-08-13": {
            "rating": 1311.9798191461796,
            "rating_q975": 1322.9476193939392,
            "rating_q025": 1301.01201889842
        },
        "yi-lightning": {
            "rating": 1311.4195514723174,
            "rating_q975": 1326.9052788865206,
            "rating_q025": 1295.9338240581142
        },
        "gemini-1.5-pro-002": {
            "rating": 1310.9366576161553,
            "rating_q975": 1322.5807573529767,
            "rating_q025": 1299.292557879334
        },
        "qwen2.5-plus-1127": {
            "rating": 1307.1109682172064,
            "rating_q975": 1333.2620367824788,
            "rating_q025": 1280.959899651934
        },
        "llama-3.1-nemotron-70b-instruct": {
            "rating": 1306.1313896125669,
            "rating_q975": 1336.412369888313,
            "rating_q025": 1275.8504093368208
        },
        "o3-mini": {
            "rating": 1305.2242569246584,
            "rating_q975": 1316.3653124895718,
            "rating_q025": 1294.083201359745
        },
        "grok-2-mini-2024-08-13": {
            "rating": 1302.9561668950032,
            "rating_q975": 1314.9492591265123,
            "rating_q025": 1290.9630746634941
        },
        "o1-mini": {
            "rating": 1302.3154115549673,
            "rating_q975": 1314.1022419274148,
            "rating_q025": 1290.52858118252
        },
        "athene-v2-chat": {
            "rating": 1301.2712251646299,
            "rating_q975": 1317.8466623446648,
            "rating_q025": 1284.695787984595
        },
        "deepseek-v2.5-1210": {
            "rating": 1297.4068548656562,
            "rating_q975": 1329.8902639940513,
            "rating_q025": 1264.923445737261
        },
        "gemini-1.5-flash-002": {
            "rating": 1295.4318432142754,
            "rating_q975": 1309.7405053181187,
            "rating_q025": 1281.1231811104321
        },
        "claude-3-7-sonnet-20250219-thinking-32k": {
            "rating": 1294.852779878308,
            "rating_q975": 1308.2145832838996,
            "rating_q025": 1281.4909764727163
        },
        "glm-4-plus": {
            "rating": 1294.643010161646,
            "rating_q975": 1309.5566386099367,
            "rating_q025": 1279.7293817133555
        },
        "llama-3.1-405b-instruct-bf16": {
            "rating": 1291.7211625117177,
            "rating_q975": 1305.0710424113977,
            "rating_q025": 1278.3712826120377
        },
        "gpt-4o-mini-2024-07-18": {
            "rating": 1286.8377219531376,
            "rating_q975": 1297.1845742981777,
            "rating_q025": 1276.4908696080975
        },
        "llama-4-maverick-17b-128e-instruct": {
            "rating": 1285.8610340942269,
            "rating_q975": 1299.1627998400347,
            "rating_q025": 1272.559268348419
        },
        "gpt-4o-2024-05-13": {
            "rating": 1283.5201173483365,
            "rating_q975": 1293.1932654584891,
            "rating_q025": 1273.8469692381839
        },
        "gpt-4.1-nano-2025-04-14": {
            "rating": 1281.4613728143063,
            "rating_q975": 1314.0934317871645,
            "rating_q025": 1248.829313841448
        },
        "llama-4-scout-17b-16e-instruct": {
            "rating": 1281.2399965034788,
            "rating_q975": 1296.1241927403294,
            "rating_q025": 1266.3558002666282
        },
        "llama-3.3-70b-instruct": {
            "rating": 1281.2083543647714,
            "rating_q975": 1292.6695737674281,
            "rating_q025": 1269.7471349621146
        },
        "athene-70b-0725": {
            "rating": 1276.318845100239,
            "rating_q975": 1294.6088833342294,
            "rating_q025": 1258.0288068662487
        },
        "reka-core-20240904": {
            "rating": 1276.0679001114236,
            "rating_q975": 1304.1937779154096,
            "rating_q025": 1247.9420223074376
        },
        "llama-3.1-405b-instruct-fp8": {
            "rating": 1275.532421970331,
            "rating_q975": 1286.8708768831098,
            "rating_q025": 1264.193967057552
        },
        "mistral-small-3.1-24b-instruct-2503": {
            "rating": 1273.199891767239,
            "rating_q975": 1287.5520228556272,
            "rating_q025": 1258.8477606788508
        },
        "amazon-nova-pro-v1.0": {
            "rating": 1265.559681761271,
            "rating_q975": 1282.8254762927656,
            "rating_q025": 1248.2938872297761
        },
        "qwen-max-0919": {
            "rating": 1264.3377124327994,
            "rating_q975": 1282.5473118183968,
            "rating_q025": 1246.128113047202
        },
        "deepseek-v2.5": {
            "rating": 1264.076091540036,
            "rating_q975": 1280.5352889539647,
            "rating_q025": 1247.6168941261074
        },
        "qwen2.5-72b-instruct": {
            "rating": 1263.9244560824309,
            "rating_q975": 1277.1508090925706,
            "rating_q025": 1250.6981030722911
        },
        "claude-3-7-sonnet-20250219": {
            "rating": 1263.5126555253141,
            "rating_q975": 1277.1060834764237,
            "rating_q025": 1249.9192275742046
        },
        "claude-3-5-sonnet-20241022": {
            "rating": 1262.2914614281674,
            "rating_q975": 1271.359845045288,
            "rating_q025": 1253.2230778110468
        },
        "llama-3.1-70b-instruct": {
            "rating": 1261.92183608545,
            "rating_q975": 1273.5793251607208,
            "rating_q025": 1250.264347010179
        },
        "mistral-large-2411": {
            "rating": 1259.911173402174,
            "rating_q975": 1276.1944323520825,
            "rating_q025": 1243.6279144522655
        },
        "gpt-4o-2024-08-06": {
            "rating": 1256.4807473865262,
            "rating_q975": 1269.5042957970704,
            "rating_q025": 1243.457198975982
        },
        "gemini-advanced-0514": {
            "rating": 1254.4550722739077,
            "rating_q975": 1268.0163730841741,
            "rating_q025": 1240.8937714636413
        },
        "mistral-large-2407": {
            "rating": 1251.1190386841372,
            "rating_q975": 1263.6332484571167,
            "rating_q025": 1238.6048289111577
        },
        "claude-3-5-sonnet-20240620": {
            "rating": 1250.078377029115,
            "rating_q975": 1260.5174832005825,
            "rating_q025": 1239.6392708576475
        },
        "magistral-medium-2506": {
            "rating": 1249.2860483760887,
            "rating_q975": 1272.5811157985127,
            "rating_q025": 1225.9909809536648
        },
        "gpt-4-turbo-2024-04-09": {
            "rating": 1244.24960004142,
            "rating_q975": 1254.918474771068,
            "rating_q025": 1233.580725311772
        },
        "command-r-plus-08-2024": {
            "rating": 1241.2173996877304,
            "rating_q975": 1265.080065158538,
            "rating_q025": 1217.354734216923
        },
        "gpt-4-0125-preview": {
            "rating": 1237.2922873261225,
            "rating_q975": 1248.2778079339976,
            "rating_q025": 1226.3067667182474
        },
        "claude-3-opus-20240229": {
            "rating": 1236.035099000761,
            "rating_q975": 1244.7151603494342,
            "rating_q025": 1227.3550376520877
        },
        "hunyuan-large-vision": {
            "rating": 1234.5203885063588,
            "rating_q975": 1266.2006465325821,
            "rating_q025": 1202.8401304801355
        },
        "claude-3-5-haiku-20241022": {
            "rating": 1231.0197598271607,
            "rating_q975": 1241.6466400413237,
            "rating_q025": 1220.3928796129976
        },
        "gpt-4-1106-preview": {
            "rating": 1228.901001920683,
            "rating_q975": 1239.852353976295,
            "rating_q025": 1217.949649865071
        },
        "c4ai-aya-expanse-32b": {
            "rating": 1227.8010192785382,
            "rating_q975": 1243.6155669618647,
            "rating_q025": 1211.9864715952117
        },
        "gemma-2-9b-it-simpo": {
            "rating": 1225.794966268703,
            "rating_q975": 1251.536880983626,
            "rating_q025": 1200.0530515537803
        },
        "mistral-small-24b-instruct-2501": {
            "rating": 1220.785032198025,
            "rating_q975": 1244.4476471612006,
            "rating_q025": 1197.1224172348493
        },
        "llama-3-70b-instruct": {
            "rating": 1218.9461626160182,
            "rating_q975": 1229.116990449945,
            "rating_q025": 1208.7753347820915
        },
        "gemini-1.5-flash-8b-001": {
            "rating": 1218.7545466386196,
            "rating_q975": 1232.9533090722512,
            "rating_q025": 1204.555784204988
        },
        "gemini-1.5-pro-001": {
            "rating": 1217.5698422581506,
            "rating_q975": 1229.0452112329062,
            "rating_q025": 1206.094473283395
        },
        "amazon-nova-lite-v1.0": {
            "rating": 1217.5676753212924,
            "rating_q975": 1237.04866059657,
            "rating_q025": 1198.0866900460148
        },
        "amazon-nova-micro-v1.0": {
            "rating": 1213.059946411006,
            "rating_q975": 1231.703924481474,
            "rating_q025": 1194.415968340538
        },
        "command-r-08-2024": {
            "rating": 1211.746028277908,
            "rating_q975": 1236.4635342295815,
            "rating_q025": 1187.0285223262345
        },
        "command-r-plus": {
            "rating": 1208.4667146325344,
            "rating_q975": 1220.4155982259772,
            "rating_q025": 1196.5178310390916
        },
        "c4ai-aya-expanse-8b": {
            "rating": 1208.2803714394522,
            "rating_q975": 1235.012519946656,
            "rating_q025": 1181.5482229322483
        },
        "glm-4-0520": {
            "rating": 1207.3428308893772,
            "rating_q975": 1231.409966955692,
            "rating_q025": 1183.2756948230624
        },
        "phi-4": {
            "rating": 1206.9591391606682,
            "rating_q975": 1226.1534244771885,
            "rating_q025": 1187.7648538441479
        },
        "gemma-2-27b-it": {
            "rating": 1202.4945098336466,
            "rating_q975": 1212.8319877825645,
            "rating_q025": 1192.1570318847287
        },
        "reka-flash-20240904": {
            "rating": 1201.7872606886392,
            "rating_q975": 1228.6696607967715,
            "rating_q025": 1174.904860580507
        },
        "jamba-1.5-large": {
            "rating": 1201.5658707424122,
            "rating_q975": 1228.9824305303869,
            "rating_q025": 1174.1493109544376
        },
        "nemotron-4-340b-instruct": {
            "rating": 1199.913566136152,
            "rating_q975": 1218.1866883531188,
            "rating_q025": 1181.6404439191851
        },
        "claude-3-sonnet-20240229": {
            "rating": 1193.414819476069,
            "rating_q975": 1204.6337149447513,
            "rating_q025": 1182.1959240073866
        },
        "gemini-1.5-flash-001": {
            "rating": 1191.9255109063877,
            "rating_q975": 1204.0535655480608,
            "rating_q025": 1179.7974562647146
        },
        "llama-3.1-nemotron-51b-instruct": {
            "rating": 1191.8794321829005,
            "rating_q975": 1231.7384130666667,
            "rating_q025": 1152.0204512991343
        },
        "qwen2.5-coder-32b-instruct": {
            "rating": 1191.85827826559,
            "rating_q975": 1228.6198882357355,
            "rating_q025": 1155.0966682954443
        },
        "llama-3.1-8b-instruct": {
            "rating": 1186.7953391073124,
            "rating_q975": 1199.0793018154186,
            "rating_q025": 1174.5113763992063
        },
        "olmo-2-0325-32b-instruct": {
            "rating": 1186.5979757505097,
            "rating_q975": 1231.6358147499552,
            "rating_q025": 1141.5601367510642
        },
        "jamba-1.5-mini": {
            "rating": 1186.213271285702,
            "rating_q975": 1212.6341139172928,
            "rating_q025": 1159.792428654111
        },
        "ministral-8b-2410": {
            "rating": 1185.3473256058794,
            "rating_q975": 1218.90473695525,
            "rating_q025": 1151.7899142565088
        },
        "qwen2-72b-instruct": {
            "rating": 1180.2233946432066,
            "rating_q975": 1194.0614048166965,
            "rating_q025": 1166.3853844697167
        },
        "gemma-2-9b-it": {
            "rating": 1170.9905007915818,
            "rating_q975": 1182.7819218687118,
            "rating_q025": 1159.1990797144517
        },
        "claude-3-haiku-20240307": {
            "rating": 1170.3529060317674,
            "rating_q975": 1180.5263868409563,
            "rating_q025": 1160.1794252225784
        },
        "yi-1.5-34b-chat": {
            "rating": 1164.0719118752347,
            "rating_q975": 1181.0892423877453,
            "rating_q025": 1147.054581362724
        },
        "command-r": {
            "rating": 1157.6958778464536,
            "rating_q975": 1171.0469274232455,
            "rating_q025": 1144.3448282696618
        },
        "internlm2_5-20b-chat": {
            "rating": 1157.175251014281,
            "rating_q975": 1181.8742148944702,
            "rating_q025": 1132.4762871340918
        },
        "llama-3-8b-instruct": {
            "rating": 1153.2917384020436,
            "rating_q975": 1164.563714176143,
            "rating_q025": 1142.0197626279441
        },
        "reka-flash-21b-20240226": {
            "rating": 1152.7354113558474,
            "rating_q975": 1170.1199053865087,
            "rating_q025": 1135.3509173251862
        },
        "qwen1.5-110b-chat": {
            "rating": 1151.2357986635507,
            "rating_q975": 1168.0080475425266,
            "rating_q025": 1134.4635497845748
        },
        "gpt-4-0314": {
            "rating": 1150.2517033014237,
            "rating_q975": 1164.2565335397521,
            "rating_q025": 1136.2468730630953
        },
        "gemma-2-2b-it": {
            "rating": 1149.6632708715508,
            "rating_q975": 1162.5649654675547,
            "rating_q025": 1136.761576275547
        },
        "reka-flash-21b-20240226-online": {
            "rating": 1148.2441007942048,
            "rating_q975": 1169.2102227569271,
            "rating_q025": 1127.2779788314824
        },
        "qwen1.5-72b-chat": {
            "rating": 1141.7377637029128,
            "rating_q975": 1155.7490868190825,
            "rating_q025": 1127.7264405867431
        },
        "gemini-pro-dev-api": {
            "rating": 1140.014221364705,
            "rating_q975": 1160.1601836376203,
            "rating_q025": 1119.8682590917897
        },
        "deepseek-coder-v2": {
            "rating": 1138.4396085095548,
            "rating_q975": 1158.8279076380447,
            "rating_q025": 1118.0513093810648
        },
        "mistral-large-2402": {
            "rating": 1138.2633017562307,
            "rating_q975": 1151.0887752745523,
            "rating_q025": 1125.4378282379091
        },
        "mistral-medium": {
            "rating": 1137.4253718671298,
            "rating_q975": 1152.9394525970365,
            "rating_q025": 1121.911291137223
        },
        "starling-lm-7b-beta": {
            "rating": 1133.6067785332834,
            "rating_q975": 1154.6826992770764,
            "rating_q025": 1112.5308577894905
        },
        "gpt-4-0613": {
            "rating": 1128.6082521392696,
            "rating_q975": 1140.3253210621783,
            "rating_q025": 1116.8911832163608
        },
        "mixtral-8x22b-instruct-v0.1": {
            "rating": 1124.8551795392723,
            "rating_q975": 1137.8110334856049,
            "rating_q025": 1111.8993255929397
        },
        "phi-3-medium-4k-instruct": {
            "rating": 1124.0875276408751,
            "rating_q975": 1140.7030955251805,
            "rating_q025": 1107.4719597565697
        },
        "gemini-pro": {
            "rating": 1121.5933148080048,
            "rating_q975": 1159.187019232143,
            "rating_q025": 1083.9996103838666
        },
        "starling-lm-7b-alpha": {
            "rating": 1116.6564602382912,
            "rating_q975": 1141.810207370081,
            "rating_q025": 1091.5027131065015
        },
        "qwen1.5-32b-chat": {
            "rating": 1116.1303309891823,
            "rating_q975": 1134.0608879265487,
            "rating_q025": 1098.199774051816
        },
        "zephyr-orpo-141b-A35b-v0.1": {
            "rating": 1111.063301509153,
            "rating_q975": 1146.1072504264957,
            "rating_q025": 1076.0193525918103
        },
        "llama-3.2-3b-instruct": {
            "rating": 1110.1420270785757,
            "rating_q975": 1139.9288186539486,
            "rating_q025": 1080.3552355032027
        },
        "qwen1.5-14b-chat": {
            "rating": 1110.0495059155935,
            "rating_q975": 1130.083746809096,
            "rating_q025": 1090.015265022091
        },
        "yi-34b-chat": {
            "rating": 1107.6487987997016,
            "rating_q975": 1129.4551501436536,
            "rating_q025": 1085.8424474557496
        },
        "phi-3-small-8k-instruct": {
            "rating": 1102.8366607729379,
            "rating_q975": 1121.7159321595245,
            "rating_q025": 1083.9573893863512
        },
        "mixtral-8x7b-instruct-v0.1": {
            "rating": 1098.880616518311,
            "rating_q975": 1110.7593605303653,
            "rating_q025": 1087.0018725062566
        },
        "wizardlm-70b": {
            "rating": 1098.7300511259164,
            "rating_q975": 1129.2270995662516,
            "rating_q025": 1068.2330026855811
        },
        "llama-2-70b-chat": {
            "rating": 1098.476213154096,
            "rating_q975": 1113.2701355765812,
            "rating_q025": 1083.682290731611
        },
        "gpt-3.5-turbo-0125": {
            "rating": 1079.6376470524342,
            "rating_q975": 1091.5369990744898,
            "rating_q025": 1067.7382950303786
        },
        "openchat-3.5-0106": {
            "rating": 1078.486294065916,
            "rating_q975": 1099.7616413245594,
            "rating_q025": 1057.2109468072724
        },
        "gemma-1.1-7b-it": {
            "rating": 1077.6407839632648,
            "rating_q975": 1095.5874927183925,
            "rating_q025": 1059.694075208137
        },
        "llama-2-13b-chat": {
            "rating": 1076.5368981911463,
            "rating_q975": 1096.9422041604396,
            "rating_q025": 1056.131592221853
        },
        "mistral-7b-instruct-v0.2": {
            "rating": 1073.413153361717,
            "rating_q975": 1091.5824264587898,
            "rating_q025": 1055.243880264644
        },
        "dbrx-instruct-preview": {
            "rating": 1073.2256477544033,
            "rating_q975": 1090.3896018013968,
            "rating_q025": 1056.0616937074099
        },
        "wizardlm-13b": {
            "rating": 1071.2697423518648,
            "rating_q975": 1106.333234868023,
            "rating_q025": 1036.2062498357066
        },
        "openchat-3.5": {
            "rating": 1071.0889791459736,
            "rating_q975": 1100.8607525390034,
            "rating_q025": 1041.3172057529437
        },
        "snowflake-arctic-instruct": {
            "rating": 1068.948754892677,
            "rating_q975": 1087.2800927059436,
            "rating_q025": 1050.6174170794104
        },
        "deepseek-llm-67b-chat": {
            "rating": 1066.8221136414409,
            "rating_q975": 1095.4212511988678,
            "rating_q025": 1038.222976084014
        },
        "tulu-2-dpo-70b": {
            "rating": 1065.0764399514026,
            "rating_q975": 1096.6294379605883,
            "rating_q025": 1033.5234419422168
        },
        "vicuna-33b": {
            "rating": 1065.0712281491037,
            "rating_q975": 1083.815946234377,
            "rating_q025": 1046.3265100638305
        },
        "granite-3.0-8b-instruct": {
            "rating": 1063.2857634918446,
            "rating_q975": 1099.0150931015423,
            "rating_q025": 1027.5564338821468
        },
        "qwen1.5-7b-chat": {
            "rating": 1061.5066881352445,
            "rating_q975": 1097.374466901098,
            "rating_q025": 1025.638909369391
        },
        "nous-hermes-2-mixtral-8x7b-dpo": {
            "rating": 1061.4435538902608,
            "rating_q975": 1093.6355166434382,
            "rating_q025": 1029.2515911370833
        },
        "openhermes-2.5-mistral-7b": {
            "rating": 1057.0615779424184,
            "rating_q975": 1092.6970895818638,
            "rating_q025": 1021.4260663029729
        },
        "solar-10.7b-instruct-v1.0": {
            "rating": 1052.340173532722,
            "rating_q975": 1092.895135744356,
            "rating_q025": 1011.7852113210882
        },
        "phi-3-mini-4k-instruct-june-2024": {
            "rating": 1047.9458427738973,
            "rating_q975": 1073.130730691559,
            "rating_q025": 1022.7609548562358
        },
        "llama-2-7b-chat": {
            "rating": 1040.5455778864573,
            "rating_q975": 1063.1304725583007,
            "rating_q025": 1017.9606832146139
        },
        "olmo-7b-instruct": {
            "rating": 1039.5885906377864,
            "rating_q975": 1071.7639293285065,
            "rating_q025": 1007.4132519470663
        },
        "phi-3-mini-4k-instruct": {
            "rating": 1035.5264372521917,
            "rating_q975": 1055.3826481526214,
            "rating_q025": 1015.670226351762
        },
        "gemma-7b-it": {
            "rating": 1033.061627326846,
            "rating_q975": 1058.3865407292228,
            "rating_q025": 1007.7367139244694
        },
        "zephyr-7b-beta": {
            "rating": 1032.9221106309055,
            "rating_q975": 1059.039145302647,
            "rating_q025": 1006.8050759591641
        },
        "codellama-34b-instruct": {
            "rating": 1031.7010749131614,
            "rating_q975": 1063.022025367695,
            "rating_q025": 1000.3801244586277
        },
        "vicuna-13b": {
            "rating": 1023.9960976745053,
            "rating_q975": 1045.8955610976082,
            "rating_q025": 1002.0966342514025
        },
        "qwen-14b-chat": {
            "rating": 1015.8153420540564,
            "rating_q975": 1054.349969799981,
            "rating_q025": 977.2807143081319
        },
        "llama-3.2-1b-instruct": {
            "rating": 1014.662568159058,
            "rating_q975": 1045.705705965878,
            "rating_q025": 983.6194303522379
        },
        "gpt-3.5-turbo-1106": {
            "rating": 1011.1470141248558,
            "rating_q975": 1033.216699005069,
            "rating_q025": 989.0773292446427
        },
        "granite-3.0-2b-instruct": {
            "rating": 1008.6930089705213,
            "rating_q975": 1044.9865488019468,
            "rating_q025": 972.3994691390959
        },
        "vicuna-7b": {
            "rating": 1003.1542165159615,
            "rating_q975": 1039.1007352320603,
            "rating_q025": 967.2076977998628
        },
        "phi-3-mini-128k-instruct": {
            "rating": 1001.0017450643878,
            "rating_q975": 1022.0448745769258,
            "rating_q025": 979.9586155518498
        },
        "mistral-7b-instruct": {
            "rating": 998.902424468725,
            "rating_q975": 1026.3074433831393,
            "rating_q025": 971.4974055543108
        },
        "gemma-1.1-2b-it": {
            "rating": 995.8866955289551,
            "rating_q975": 1022.3557941354916,
            "rating_q025": 969.4175969224186
        },
        "stripedhyena-nous-7b": {
            "rating": 989.8330552999339,
            "rating_q975": 1020.5519527407831,
            "rating_q025": 959.1141578590847
        },
        "palm-2": {
            "rating": 967.4607959817713,
            "rating_q975": 1004.3893427230464,
            "rating_q025": 930.5322492404962
        },
        "koala-13b": {
            "rating": 961.2034852754791,
            "rating_q975": 1001.8981776608719,
            "rating_q025": 920.5087928900864
        },
        "qwen1.5-4b-chat": {
            "rating": 961.161326285977,
            "rating_q975": 991.8973153593835,
            "rating_q025": 930.4253372125705
        },
        "RWKV-4-Raven-14B": {
            "rating": 949.7462033463232,
            "rating_q975": 999.0252545122345,
            "rating_q025": 900.467152180412
        },
        "gemma-2b-it": {
            "rating": 943.5859542176782,
            "rating_q975": 980.8858091260635,
            "rating_q025": 906.286099309293
        },
        "chatglm3-6b": {
            "rating": 895.4141957793634,
            "rating_q975": 937.2408512808568,
            "rating_q025": 853.58754027787
        },
        "chatglm-6b": {
            "rating": 829.1504050600616,
            "rating_q975": 882.9243743089518,
            "rating_q025": 775.3764358111715
        },
        "alpaca-13b": {
            "rating": 825.2694228612628,
            "rating_q975": 875.8259949146618,
            "rating_q025": 774.7128508078638
        },
        "oasst-pythia-12b": {
            "rating": 824.3273255021156,
            "rating_q975": 872.8961542971641,
            "rating_q025": 775.7584967070671
        }
    },
    "industry_software_and_it_services": {
        "gemini-3-pro": {
            "rating": 1490.3635808809931,
            "rating_q975": 1499.5945076845376,
            "rating_q025": 1481.1326540774487
        },
        "claude-opus-4-5-20251101-thinking-32k": {
            "rating": 1483.4880537753181,
            "rating_q975": 1494.3632086123723,
            "rating_q025": 1472.612898938264
        },
        "claude-opus-4-5-20251101": {
            "rating": 1482.9497524296423,
            "rating_q975": 1493.6101369509022,
            "rating_q025": 1472.2893679083825
        },
        "ernie-5.0-preview-1103": {
            "rating": 1470.8648390591277,
            "rating_q975": 1484.3431316192132,
            "rating_q025": 1457.3865464990422
        },
        "claude-sonnet-4-5-20250929-thinking-32k": {
            "rating": 1467.3729175857268,
            "rating_q975": 1474.2229399812593,
            "rating_q025": 1460.5228951901943
        },
        "gemini-2.5-pro": {
            "rating": 1465.8248593741769,
            "rating_q975": 1470.8131703711165,
            "rating_q025": 1460.8365483772372
        },
        "grok-4.1-thinking": {
            "rating": 1461.520028867035,
            "rating_q975": 1470.5634367661853,
            "rating_q025": 1452.4766209678849
        },
        "claude-sonnet-4-5-20250929": {
            "rating": 1460.336931615291,
            "rating_q975": 1467.7637058361026,
            "rating_q025": 1452.9101573944793
        },
        "longcat-flash-chat": {
            "rating": 1459.3523391768879,
            "rating_q975": 1468.991433493673,
            "rating_q025": 1449.7132448601028
        },
        "qwen3-max-preview": {
            "rating": 1458.994467760648,
            "rating_q975": 1465.7794064848495,
            "rating_q025": 1452.2095290364464
        },
        "glm-4.6": {
            "rating": 1457.4809551662902,
            "rating_q975": 1464.511520038487,
            "rating_q025": 1450.4503902940933
        },
        "claude-opus-4-1-20250805-thinking-16k": {
            "rating": 1457.2095481847407,
            "rating_q975": 1462.9796211841813,
            "rating_q025": 1451.4394751853001
        },
        "grok-4.1": {
            "rating": 1452.4923351843163,
            "rating_q975": 1461.4211447230082,
            "rating_q025": 1443.5635256456244
        },
        "qwen3-next-80b-a3b-instruct": {
            "rating": 1449.3753332326953,
            "rating_q975": 1456.44037838798,
            "rating_q025": 1442.3102880774106
        },
        "mistral-large-3": {
            "rating": 1447.5194997335225,
            "rating_q975": 1460.0985562508456,
            "rating_q025": 1434.9404432161994
        },
        "qwen3-235b-a22b-instruct-2507": {
            "rating": 1445.6580578606115,
            "rating_q975": 1451.10551758226,
            "rating_q025": 1440.210598138963
        },
        "claude-opus-4-1-20250805": {
            "rating": 1445.3770796811675,
            "rating_q975": 1450.8699263866608,
            "rating_q025": 1439.8842329756742
        },
        "gpt-5.1-high": {
            "rating": 1444.9394860905782,
            "rating_q975": 1454.6023274299976,
            "rating_q025": 1435.2766447511588
        },
        "qwen3-vl-235b-a22b-instruct": {
            "rating": 1444.8036869506834,
            "rating_q975": 1455.2332725827564,
            "rating_q025": 1434.3741013186104
        },
        "mistral-medium-2508": {
            "rating": 1441.333420100285,
            "rating_q975": 1447.0162136417048,
            "rating_q025": 1435.650626558865
        },
        "glm-4.5": {
            "rating": 1439.127439234815,
            "rating_q975": 1446.249983640433,
            "rating_q025": 1432.0048948291972
        },
        "deepseek-v3.2-exp": {
            "rating": 1438.9686312940953,
            "rating_q975": 1448.6188749276814,
            "rating_q025": 1429.3183876605092
        },
        "qwen3-max-2025-09-23": {
            "rating": 1438.0871324741356,
            "rating_q975": 1448.1463424132276,
            "rating_q025": 1428.0279225350437
        },
        "deepseek-v3.2-exp-thinking": {
            "rating": 1436.6125398572296,
            "rating_q975": 1447.0499760018772,
            "rating_q025": 1426.175103712582
        },
        "grok-3-preview-02-24": {
            "rating": 1436.4790184532585,
            "rating_q975": 1443.1488368950709,
            "rating_q025": 1429.8092000114461
        },
        "deepseek-v3.2": {
            "rating": 1436.0881572452356,
            "rating_q975": 1448.6190195139511,
            "rating_q025": 1423.55729497652
        },
        "kimi-k2-thinking-turbo": {
            "rating": 1435.7494052526806,
            "rating_q975": 1444.6094550379194,
            "rating_q025": 1426.8893554674419
        },
        "deepseek-r1-0528": {
            "rating": 1435.2533314376994,
            "rating_q975": 1443.5622078399774,
            "rating_q025": 1426.9444550354215
        },
        "gpt-5.1": {
            "rating": 1434.4600235570051,
            "rating_q975": 1443.5722087173854,
            "rating_q025": 1425.3478383966249
        },
        "grok-4-fast-chat": {
            "rating": 1432.2940087027503,
            "rating_q975": 1444.6459225206502,
            "rating_q025": 1419.9420948848503
        },
        "claude-haiku-4-5-20251001": {
            "rating": 1431.1820901927701,
            "rating_q975": 1438.141220667431,
            "rating_q025": 1424.2229597181092
        },
        "deepseek-v3.2-thinking": {
            "rating": 1431.0727400161563,
            "rating_q975": 1444.4413797498735,
            "rating_q025": 1417.7041002824392
        },
        "qwen3-235b-a22b-thinking-2507": {
            "rating": 1428.4212598410998,
            "rating_q975": 1439.200401430307,
            "rating_q025": 1417.6421182518925
        },
        "deepseek-v3.1-thinking": {
            "rating": 1427.4157585614637,
            "rating_q975": 1437.4867410939391,
            "rating_q025": 1417.3447760289882
        },
        "chatgpt-4o-latest-20250326": {
            "rating": 1427.0533902383042,
            "rating_q975": 1432.0680386899792,
            "rating_q025": 1422.0387417866293
        },
        "deepseek-v3.1": {
            "rating": 1426.8297057255013,
            "rating_q975": 1435.6925970392808,
            "rating_q025": 1417.9668144117218
        },
        "qwen3-vl-235b-a22b-thinking": {
            "rating": 1426.6696107866521,
            "rating_q975": 1437.5384353698387,
            "rating_q025": 1415.8007862034656
        },
        "gemini-2.5-flash": {
            "rating": 1424.1655979961618,
            "rating_q975": 1429.0838171186588,
            "rating_q025": 1419.2473788736647
        },
        "deepseek-v3.1-terminus-thinking": {
            "rating": 1423.149736570248,
            "rating_q975": 1440.3770827963872,
            "rating_q025": 1405.9223903441089
        },
        "hunyuan-vision-1.5-thinking": {
            "rating": 1422.2360872818338,
            "rating_q975": 1443.0549947071768,
            "rating_q025": 1401.4171798564907
        },
        "gpt-5-high": {
            "rating": 1421.5218192917973,
            "rating_q975": 1428.0275984890877,
            "rating_q025": 1415.016040094507
        },
        "amazon-nova-experimental-chat-10-20": {
            "rating": 1420.0523721450147,
            "rating_q975": 1431.2767427659871,
            "rating_q025": 1408.8280015240423
        },
        "qwen3-30b-a3b-instruct-2507": {
            "rating": 1417.7271999671245,
            "rating_q975": 1424.8703231222983,
            "rating_q025": 1410.5840768119508
        },
        "grok-4-1-fast-reasoning": {
            "rating": 1416.54574046634,
            "rating_q975": 1427.3540057482473,
            "rating_q025": 1405.7374751844327
        },
        "o3-2025-04-16": {
            "rating": 1414.5058724026032,
            "rating_q975": 1419.8040093033192,
            "rating_q025": 1409.2077355018873
        },
        "deepseek-v3.1-terminus": {
            "rating": 1412.4675363339811,
            "rating_q975": 1428.576685852876,
            "rating_q025": 1396.3583868150863
        },
        "gpt-4.5-preview-2025-02-27": {
            "rating": 1411.4345238248031,
            "rating_q975": 1421.5143449385814,
            "rating_q025": 1401.3547027110249
        },
        "grok-4-fast-reasoning": {
            "rating": 1411.2797932179633,
            "rating_q975": 1418.8738890586483,
            "rating_q025": 1403.6856973772783
        },
        "grok-4-0709": {
            "rating": 1408.758428424551,
            "rating_q975": 1414.4522498528256,
            "rating_q025": 1403.0646069962766
        },
        "gemini-2.5-flash-preview-09-2025": {
            "rating": 1408.249458056996,
            "rating_q975": 1414.81176533201,
            "rating_q025": 1401.687150781982
        },
        "qwen3-235b-a22b-no-thinking": {
            "rating": 1408.0695192880564,
            "rating_q975": 1414.2400395866591,
            "rating_q025": 1401.8989989894537
        },
        "hunyuan-t1-20250711": {
            "rating": 1406.874926556804,
            "rating_q975": 1421.4730465512503,
            "rating_q025": 1392.2768065623577
        },
        "gpt-5-chat": {
            "rating": 1406.852528467348,
            "rating_q975": 1413.2310554931776,
            "rating_q025": 1400.4740014415186
        },
        "claude-opus-4-20250514-thinking-16k": {
            "rating": 1405.4206969363024,
            "rating_q975": 1411.7488520985505,
            "rating_q025": 1399.0925417740543
        },
        "mai-1-preview": {
            "rating": 1403.0742952620324,
            "rating_q975": 1411.1647654632068,
            "rating_q025": 1394.983825060858
        },
        "ling-flash-2.0": {
            "rating": 1402.8472302258795,
            "rating_q975": 1414.354122461989,
            "rating_q025": 1391.34033798977
        },
        "glm-4.5-air": {
            "rating": 1399.9532237997685,
            "rating_q975": 1406.271895712648,
            "rating_q025": 1393.6345518868889
        },
        "nova-2-lite": {
            "rating": 1397.3664366854164,
            "rating_q975": 1410.4009876263021,
            "rating_q025": 1384.3318857445306
        },
        "kimi-k2-0905-preview": {
            "rating": 1396.5698789861578,
            "rating_q975": 1406.3084643577106,
            "rating_q025": 1386.831293614605
        },
        "qwen3-next-80b-a3b-thinking": {
            "rating": 1394.6119259007135,
            "rating_q975": 1403.3367475857342,
            "rating_q025": 1385.8871042156927
        },
        "gpt-5-mini-high": {
            "rating": 1394.2246803347357,
            "rating_q975": 1401.129972218829,
            "rating_q025": 1387.3193884506425
        },
        "hunyuan-turbos-20250416": {
            "rating": 1391.4689162792135,
            "rating_q975": 1402.0067680523061,
            "rating_q025": 1380.931064506121
        },
        "qwen3-coder-480b-a35b-instruct": {
            "rating": 1390.9151947584219,
            "rating_q975": 1398.2363108716288,
            "rating_q025": 1383.594078645215
        },
        "gpt-4.1-2025-04-14": {
            "rating": 1390.3415626198744,
            "rating_q975": 1395.7875642283113,
            "rating_q025": 1384.8955610114374
        },
        "gpt-oss-120b": {
            "rating": 1386.4892616403033,
            "rating_q975": 1392.997029281526,
            "rating_q025": 1379.9814939990806
        },
        "qwen3-235b-a22b": {
            "rating": 1385.9430594522792,
            "rating_q975": 1392.9699092469018,
            "rating_q025": 1378.9162096576565
        },
        "kimi-k2-0711-preview": {
            "rating": 1385.548925472941,
            "rating_q975": 1392.4654841727693,
            "rating_q025": 1378.6323667731126
        },
        "mistral-medium-2505": {
            "rating": 1383.8000772189905,
            "rating_q975": 1390.3363617368225,
            "rating_q025": 1377.2637927011585
        },
        "gemini-2.5-flash-lite-preview-09-2025-no-thinking": {
            "rating": 1382.9750025984006,
            "rating_q975": 1389.5343439584199,
            "rating_q025": 1376.4156612383813
        },
        "claude-sonnet-4-20250514-thinking-32k": {
            "rating": 1380.3807216432508,
            "rating_q975": 1386.7362224744165,
            "rating_q025": 1374.025220812085
        },
        "amazon-nova-experimental-chat-10-09": {
            "rating": 1379.0977704988559,
            "rating_q975": 1389.280660665669,
            "rating_q025": 1368.9148803320427
        },
        "claude-opus-4-20250514": {
            "rating": 1377.6940455430342,
            "rating_q975": 1383.6917775921474,
            "rating_q025": 1371.696313493921
        },
        "deepseek-v3-0324": {
            "rating": 1377.6688381077101,
            "rating_q975": 1383.3564745164315,
            "rating_q025": 1371.9812016989888
        },
        "intellect-3": {
            "rating": 1377.2655826125256,
            "rating_q975": 1398.7000052896801,
            "rating_q025": 1355.831159935371
        },
        "gemini-2.5-flash-lite-preview-06-17-thinking": {
            "rating": 1376.1810421745888,
            "rating_q975": 1382.586403819176,
            "rating_q025": 1369.7756805300016
        },
        "deepseek-r1": {
            "rating": 1374.6293257021814,
            "rating_q975": 1383.696954716067,
            "rating_q025": 1365.5616966882958
        },
        "grok-3-mini-high": {
            "rating": 1373.6587250794523,
            "rating_q975": 1381.5794612494926,
            "rating_q025": 1365.737988909412
        },
        "minimax-m2": {
            "rating": 1373.5911276194383,
            "rating_q975": 1385.5103982394744,
            "rating_q025": 1361.6718569994023
        },
        "qwen2.5-max": {
            "rating": 1371.0049068416383,
            "rating_q975": 1377.5119988196427,
            "rating_q025": 1364.497814863634
        },
        "grok-3-mini-beta": {
            "rating": 1370.5713233921902,
            "rating_q975": 1377.8105663982114,
            "rating_q025": 1363.3320803861689
        },
        "ring-flash-2.0": {
            "rating": 1368.2219579559035,
            "rating_q975": 1379.6755116001193,
            "rating_q025": 1356.7684043116876
        },
        "o4-mini-2025-04-16": {
            "rating": 1367.115460411017,
            "rating_q975": 1372.836603925232,
            "rating_q025": 1361.394316896802
        },
        "o1-2024-12-17": {
            "rating": 1366.2593980149322,
            "rating_q975": 1373.8081696124664,
            "rating_q025": 1358.710626417398
        },
        "qwen3-32b": {
            "rating": 1366.129570839929,
            "rating_q975": 1385.462754588914,
            "rating_q025": 1346.796387090944
        },
        "step-3": {
            "rating": 1363.5221701049225,
            "rating_q975": 1376.0175699685046,
            "rating_q025": 1351.0267702413403
        },
        "o3-mini-high": {
            "rating": 1363.3097511141368,
            "rating_q975": 1372.5043807926731,
            "rating_q025": 1354.1151214356005
        },
        "mistral-small-2506": {
            "rating": 1361.589067226851,
            "rating_q975": 1369.2907426695676,
            "rating_q025": 1353.8873917841345
        },
        "o1-preview": {
            "rating": 1361.5504066629335,
            "rating_q975": 1369.306598952981,
            "rating_q025": 1353.794214372886
        },
        "gpt-4.1-mini-2025-04-14": {
            "rating": 1361.2280517536124,
            "rating_q975": 1367.3216093062015,
            "rating_q025": 1355.1344942010232
        },
        "gemini-2.0-flash-001": {
            "rating": 1360.7644421271402,
            "rating_q975": 1366.473542121235,
            "rating_q025": 1355.0553421330455
        },
        "minimax-m1": {
            "rating": 1360.6654571508136,
            "rating_q975": 1366.822680773359,
            "rating_q025": 1354.5082335282682
        },
        "claude-sonnet-4-20250514": {
            "rating": 1359.061381751631,
            "rating_q975": 1365.1678371909516,
            "rating_q025": 1352.9549263123104
        },
        "glm-4.5v": {
            "rating": 1355.7594042312078,
            "rating_q975": 1369.700646591034,
            "rating_q025": 1341.8181618713816
        },
        "gemma-3-27b-it": {
            "rating": 1355.3051276962547,
            "rating_q975": 1360.8130801900465,
            "rating_q025": 1349.7971752024628
        },
        "o1-mini": {
            "rating": 1353.5071118384833,
            "rating_q975": 1359.5331408427576,
            "rating_q025": 1347.481082834209
        },
        "nvidia-llama-3.3-nemotron-super-49b-v1.5": {
            "rating": 1353.2748430764611,
            "rating_q975": 1369.8496932886228,
            "rating_q025": 1336.6999928642995
        },
        "step-1o-turbo-202506": {
            "rating": 1353.161518679995,
            "rating_q975": 1364.1131963635833,
            "rating_q025": 1342.2098409964067
        },
        "hunyuan-turbos-20250226": {
            "rating": 1351.2701801738215,
            "rating_q975": 1376.3037613526246,
            "rating_q025": 1326.2365989950183
        },
        "qwq-32b": {
            "rating": 1347.2570805430512,
            "rating_q975": 1354.2498964662404,
            "rating_q025": 1340.264264619862
        },
        "gpt-5-nano-high": {
            "rating": 1345.0396973832214,
            "rating_q975": 1356.183286949555,
            "rating_q025": 1333.896107816888
        },
        "o3-mini": {
            "rating": 1343.4551085523876,
            "rating_q975": 1348.676740550302,
            "rating_q025": 1338.2334765544733
        },
        "qwen-plus-0125": {
            "rating": 1342.2795329722017,
            "rating_q975": 1357.379409441088,
            "rating_q025": 1327.1796565033153
        },
        "qwen3-30b-a3b": {
            "rating": 1340.049584470119,
            "rating_q975": 1346.9755582033183,
            "rating_q025": 1333.1236107369198
        },
        "deepseek-v3": {
            "rating": 1336.540874326808,
            "rating_q975": 1344.8208059641622,
            "rating_q025": 1328.260942689454
        },
        "command-a-03-2025": {
            "rating": 1336.4500071348339,
            "rating_q975": 1341.5981702768947,
            "rating_q025": 1331.301843992773
        },
        "olmo-3-32b-think": {
            "rating": 1336.0314874686499,
            "rating_q975": 1353.5991067558225,
            "rating_q025": 1318.4638681814772
        },
        "gemini-2.0-flash-lite-preview-02-05": {
            "rating": 1335.1298922588524,
            "rating_q975": 1342.860376407009,
            "rating_q025": 1327.3994081106957
        },
        "hunyuan-turbo-0110": {
            "rating": 1331.3249320656332,
            "rating_q975": 1354.7356900440175,
            "rating_q025": 1307.914174087249
        },
        "llama-3.1-nemotron-ultra-253b-v1": {
            "rating": 1326.692085137554,
            "rating_q975": 1350.5197574736517,
            "rating_q025": 1302.8644128014562
        },
        "claude-3-7-sonnet-20250219-thinking-32k": {
            "rating": 1324.5463468813775,
            "rating_q975": 1330.906183663209,
            "rating_q025": 1318.186510099546
        },
        "glm-4-plus-0111": {
            "rating": 1320.0956485152467,
            "rating_q975": 1334.927268790952,
            "rating_q025": 1305.2640282395414
        },
        "mercury": {
            "rating": 1318.4067719173763,
            "rating_q975": 1340.9767085773071,
            "rating_q025": 1295.8368352574455
        },
        "qwen2.5-plus-1127": {
            "rating": 1315.8575820802334,
            "rating_q975": 1327.1579982674089,
            "rating_q025": 1304.557165893058
        },
        "gpt-oss-20b": {
            "rating": 1315.7942478072946,
            "rating_q975": 1325.871794292121,
            "rating_q025": 1305.7167013224682
        },
        "claude-3-5-sonnet-20241022": {
            "rating": 1315.5394551106428,
            "rating_q975": 1319.889844854512,
            "rating_q025": 1311.1890653667738
        },
        "step-2-16k-exp-202412": {
            "rating": 1314.944938646469,
            "rating_q975": 1330.6415315224135,
            "rating_q025": 1299.2483457705243
        },
        "yi-lightning": {
            "rating": 1313.7344778537251,
            "rating_q975": 1321.8414624046777,
            "rating_q025": 1305.6274933027726
        },
        "claude-3-7-sonnet-20250219": {
            "rating": 1313.5112317855314,
            "rating_q975": 1319.4832934942756,
            "rating_q025": 1307.5391700767873
        },
        "gemma-3-12b-it": {
            "rating": 1313.1620692902397,
            "rating_q975": 1332.082081444761,
            "rating_q025": 1294.2420571357186
        },
        "deepseek-v2.5-1210": {
            "rating": 1313.0528460783048,
            "rating_q975": 1327.10216766147,
            "rating_q025": 1299.0035244951396
        },
        "gemma-3n-e4b-it": {
            "rating": 1310.4653566609356,
            "rating_q975": 1318.180682642772,
            "rating_q025": 1302.7500306790994
        },
        "athene-v2-chat": {
            "rating": 1309.8247733762032,
            "rating_q975": 1317.3133188729325,
            "rating_q025": 1302.3362278794739
        },
        "hunyuan-large-2025-02-10": {
            "rating": 1306.0451797155058,
            "rating_q975": 1325.6784229854318,
            "rating_q025": 1286.4119364455798
        },
        "gpt-4.1-nano-2025-04-14": {
            "rating": 1304.824563552999,
            "rating_q975": 1319.6286848984225,
            "rating_q025": 1290.0204422075756
        },
        "gemini-1.5-pro-002": {
            "rating": 1303.458702798352,
            "rating_q975": 1309.0678161438505,
            "rating_q025": 1297.8495894528537
        },
        "mistral-small-3.1-24b-instruct-2503": {
            "rating": 1302.2593286449805,
            "rating_q975": 1308.7074571953228,
            "rating_q025": 1295.8112000946383
        },
        "llama-4-maverick-17b-128e-instruct": {
            "rating": 1300.3583093596762,
            "rating_q975": 1306.5066501388894,
            "rating_q025": 1294.209968580463
        },
        "llama-3.3-nemotron-49b-super-v1": {
            "rating": 1300.321375569323,
            "rating_q975": 1324.8903261119374,
            "rating_q025": 1275.7524250267086
        },
        "gpt-4o-2024-05-13": {
            "rating": 1297.0507541072484,
            "rating_q975": 1302.4707118467777,
            "rating_q025": 1291.630796367719
        },
        "deepseek-v2.5": {
            "rating": 1295.1052413925513,
            "rating_q975": 1302.9781762351035,
            "rating_q025": 1287.232306549999
        },
        "grok-2-2024-08-13": {
            "rating": 1294.3566008070834,
            "rating_q975": 1300.029687039283,
            "rating_q025": 1288.6835145748837
        },
        "qwen2.5-72b-instruct": {
            "rating": 1292.0563746038454,
            "rating_q975": 1298.4825616758478,
            "rating_q025": 1285.630187531843
        },
        "glm-4-plus": {
            "rating": 1291.0926125929764,
            "rating_q975": 1298.9574741269032,
            "rating_q025": 1283.2277510590495
        },
        "gpt-4o-mini-2024-07-18": {
            "rating": 1290.5960942978093,
            "rating_q975": 1295.8981936754556,
            "rating_q025": 1285.293994920163
        },
        "qwen-max-0919": {
            "rating": 1290.4487823208597,
            "rating_q975": 1299.7762632556855,
            "rating_q025": 1281.1213013860338
        },
        "llama-3.1-405b-instruct-bf16": {
            "rating": 1290.2551322375875,
            "rating_q975": 1296.2772951864088,
            "rating_q025": 1284.2329692887663
        },
        "claude-3-5-sonnet-20240620": {
            "rating": 1288.4455208125223,
            "rating_q975": 1294.1832735995245,
            "rating_q025": 1282.7077680255202
        },
        "llama-4-scout-17b-16e-instruct": {
            "rating": 1286.8508596307938,
            "rating_q975": 1293.6776517200526,
            "rating_q025": 1280.024067541535
        },
        "hunyuan-standard-2025-02-10": {
            "rating": 1284.0958964424306,
            "rating_q975": 1303.3978710402682,
            "rating_q025": 1264.793921844593
        },
        "llama-3.1-nemotron-70b-instruct": {
            "rating": 1283.2941716862524,
            "rating_q975": 1295.7929238283107,
            "rating_q025": 1270.7954195441941
        },
        "magistral-medium-2506": {
            "rating": 1283.1528768073351,
            "rating_q975": 1292.7874476017817,
            "rating_q025": 1273.5183060128886
        },
        "hunyuan-large-vision": {
            "rating": 1282.5483982613646,
            "rating_q975": 1296.8519748734595,
            "rating_q025": 1268.2448216492696
        },
        "llama-3.1-405b-instruct-fp8": {
            "rating": 1281.0144619013806,
            "rating_q975": 1286.8912262305257,
            "rating_q025": 1275.1376975722355
        },
        "gemini-1.5-flash-002": {
            "rating": 1277.9687272966298,
            "rating_q975": 1284.667060834714,
            "rating_q025": 1271.2703937585457
        },
        "gpt-4o-2024-08-06": {
            "rating": 1277.7080322715642,
            "rating_q975": 1284.2708726981944,
            "rating_q025": 1271.145191844934
        },
        "grok-2-mini-2024-08-13": {
            "rating": 1277.4738565843304,
            "rating_q975": 1283.4584299910182,
            "rating_q025": 1271.4892831776426
        },
        "mistral-large-2407": {
            "rating": 1276.1087772412518,
            "rating_q975": 1282.6389090026316,
            "rating_q025": 1269.578645479872
        },
        "llama-3.3-70b-instruct": {
            "rating": 1274.2339292066088,
            "rating_q975": 1279.4240982513606,
            "rating_q025": 1269.0437601618569
        },
        "mistral-large-2411": {
            "rating": 1273.903755626292,
            "rating_q975": 1281.0482538892102,
            "rating_q025": 1266.7592573633738
        },
        "claude-3-5-haiku-20241022": {
            "rating": 1272.4506100061753,
            "rating_q975": 1277.2550018795896,
            "rating_q025": 1267.646218132761
        },
        "gemini-1.5-pro-001": {
            "rating": 1272.309003539969,
            "rating_q975": 1278.6072547716929,
            "rating_q025": 1266.010752308245
        },
        "amazon-nova-pro-v1.0": {
            "rating": 1270.5994666326208,
            "rating_q975": 1277.9819034357488,
            "rating_q025": 1263.2170298294927
        },
        "gemma-3-4b-it": {
            "rating": 1268.3551058938756,
            "rating_q975": 1286.9462214670937,
            "rating_q025": 1249.7639903206575
        },
        "gpt-4-turbo-2024-04-09": {
            "rating": 1267.2045056451707,
            "rating_q975": 1273.2398831598316,
            "rating_q025": 1261.1691281305098
        },
        "gemini-advanced-0514": {
            "rating": 1266.6094102236416,
            "rating_q975": 1274.118500293256,
            "rating_q025": 1259.1003201540273
        },
        "athene-70b-0725": {
            "rating": 1265.204598258391,
            "rating_q975": 1274.3249588699987,
            "rating_q025": 1256.084237646783
        },
        "qwen2.5-coder-32b-instruct": {
            "rating": 1261.180227419365,
            "rating_q975": 1275.9069063114553,
            "rating_q025": 1246.453548527275
        },
        "llama-3.1-70b-instruct": {
            "rating": 1259.8367797746544,
            "rating_q975": 1265.7659579599979,
            "rating_q025": 1253.9076015893108
        },
        "claude-3-opus-20240229": {
            "rating": 1258.7293005559618,
            "rating_q975": 1263.555491841422,
            "rating_q025": 1253.9031092705015
        },
        "gpt-4-1106-preview": {
            "rating": 1250.219933911153,
            "rating_q975": 1256.398449301183,
            "rating_q025": 1244.041418521123
        },
        "gpt-4-0125-preview": {
            "rating": 1249.556148430849,
            "rating_q975": 1255.9000480826585,
            "rating_q025": 1243.2122487790393
        },
        "mistral-small-24b-instruct-2501": {
            "rating": 1247.8587058300732,
            "rating_q975": 1257.7181896209645,
            "rating_q025": 1237.9992220391819
        },
        "llama-3.1-tulu-3-70b": {
            "rating": 1242.012197807293,
            "rating_q975": 1261.9742272708831,
            "rating_q025": 1222.0501683437028
        },
        "gemini-1.5-flash-001": {
            "rating": 1241.372883149143,
            "rating_q975": 1247.900308616237,
            "rating_q025": 1234.845457682049
        },
        "amazon-nova-lite-v1.0": {
            "rating": 1241.1914659095942,
            "rating_q975": 1249.611380521157,
            "rating_q025": 1232.7715512980315
        },
        "deepseek-coder-v2": {
            "rating": 1238.913126994091,
            "rating_q975": 1249.028719222445,
            "rating_q025": 1228.797534765737
        },
        "jamba-1.5-large": {
            "rating": 1236.748284683629,
            "rating_q975": 1248.8116796834067,
            "rating_q025": 1224.6848896838512
        },
        "reka-core-20240904": {
            "rating": 1231.513198530826,
            "rating_q975": 1244.090421731231,
            "rating_q025": 1218.9359753304211
        },
        "llama-3.1-nemotron-51b-instruct": {
            "rating": 1230.7931900328338,
            "rating_q975": 1248.432649192062,
            "rating_q025": 1213.1537308736056
        },
        "phi-4": {
            "rating": 1227.8511246729176,
            "rating_q975": 1235.8021407289473,
            "rating_q025": 1219.900108616888
        },
        "gemma-2-27b-it": {
            "rating": 1227.7740797789443,
            "rating_q975": 1233.0231728813617,
            "rating_q025": 1222.5249866765269
        },
        "gemini-1.5-flash-8b-001": {
            "rating": 1227.177550356792,
            "rating_q975": 1233.9373909658461,
            "rating_q025": 1220.4177097477377
        },
        "glm-4-0520": {
            "rating": 1225.6387855933995,
            "rating_q975": 1237.1625718913808,
            "rating_q025": 1214.114999295418
        },
        "hunyuan-standard-256k": {
            "rating": 1222.027675506768,
            "rating_q975": 1242.8523535163897,
            "rating_q025": 1201.2029974971463
        },
        "claude-3-sonnet-20240229": {
            "rating": 1220.981252425855,
            "rating_q975": 1227.096592811563,
            "rating_q025": 1214.8659120401471
        },
        "nemotron-4-340b-instruct": {
            "rating": 1215.2135328351187,
            "rating_q975": 1224.4074046609444,
            "rating_q025": 1206.019661009293
        },
        "amazon-nova-micro-v1.0": {
            "rating": 1214.9728160033899,
            "rating_q975": 1223.559386344616,
            "rating_q025": 1206.3862456621637
        },
        "olmo-2-0325-32b-instruct": {
            "rating": 1214.1501231127809,
            "rating_q975": 1235.9005810677531,
            "rating_q025": 1192.3996651578086
        },
        "ministral-8b-2410": {
            "rating": 1212.9720552344797,
            "rating_q975": 1228.6420515354305,
            "rating_q025": 1197.302058933529
        },
        "c4ai-aya-expanse-32b": {
            "rating": 1212.2686193706131,
            "rating_q975": 1219.8814365569688,
            "rating_q025": 1204.6558021842575
        },
        "gemma-2-9b-it-simpo": {
            "rating": 1211.2880081614558,
            "rating_q975": 1223.1681791231847,
            "rating_q025": 1199.4078371997268
        },
        "llama-3-70b-instruct": {
            "rating": 1204.3958477031038,
            "rating_q975": 1210.2601645774846,
            "rating_q025": 1198.531530828723
        },
        "reka-flash-20240904": {
            "rating": 1198.8413666567158,
            "rating_q975": 1211.3240833122743,
            "rating_q025": 1186.3586500011572
        },
        "command-r-plus-08-2024": {
            "rating": 1197.0590827532455,
            "rating_q975": 1208.062750275972,
            "rating_q025": 1186.0554152305192
        },
        "gemma-2-9b-it": {
            "rating": 1196.415325821218,
            "rating_q975": 1202.3169065460468,
            "rating_q025": 1190.5137450963891
        },
        "llama-3.1-8b-instruct": {
            "rating": 1194.9496289304743,
            "rating_q975": 1201.3245612131932,
            "rating_q025": 1188.5746966477554
        },
        "gpt-4-0314": {
            "rating": 1194.664207959835,
            "rating_q975": 1202.4976291414944,
            "rating_q025": 1186.8307867781757
        },
        "claude-3-haiku-20240307": {
            "rating": 1193.8728561192588,
            "rating_q975": 1199.6935152186063,
            "rating_q025": 1188.0521970199113
        },
        "qwen2-72b-instruct": {
            "rating": 1192.9585893113558,
            "rating_q975": 1200.4620700104906,
            "rating_q025": 1185.455108612221
        },
        "llama-3.1-tulu-3-8b": {
            "rating": 1191.1286802044376,
            "rating_q975": 1211.0260679709424,
            "rating_q025": 1171.2312924379328
        },
        "jamba-1.5-mini": {
            "rating": 1188.7947637572543,
            "rating_q975": 1201.2504937919332,
            "rating_q025": 1176.3390337225753
        },
        "command-r-plus": {
            "rating": 1185.9056685209448,
            "rating_q975": 1192.4473862832276,
            "rating_q025": 1179.363950758662
        },
        "c4ai-aya-expanse-8b": {
            "rating": 1176.7598523373658,
            "rating_q975": 1188.565703854443,
            "rating_q025": 1164.9540008202887
        },
        "qwen1.5-110b-chat": {
            "rating": 1174.3832383626777,
            "rating_q975": 1183.3057490207761,
            "rating_q025": 1165.4607277045793
        },
        "command-r-08-2024": {
            "rating": 1173.6434618971944,
            "rating_q975": 1184.5519998905968,
            "rating_q025": 1162.734923903792
        },
        "yi-1.5-34b-chat": {
            "rating": 1171.6214423115593,
            "rating_q975": 1180.310863706497,
            "rating_q025": 1162.9320209166217
        },
        "mistral-large-2402": {
            "rating": 1170.8499091423012,
            "rating_q975": 1178.0909954258925,
            "rating_q025": 1163.6088228587098
        },
        "gpt-4-0613": {
            "rating": 1168.7121181298858,
            "rating_q975": 1175.3632692341926,
            "rating_q025": 1162.060967025579
        },
        "reka-flash-21b-20240226-online": {
            "rating": 1165.1435210061204,
            "rating_q975": 1176.0812852760484,
            "rating_q025": 1154.2057567361924
        },
        "internlm2_5-20b-chat": {
            "rating": 1163.6721643236015,
            "rating_q975": 1175.426676752066,
            "rating_q025": 1151.917651895137
        },
        "granite-3.1-8b-instruct": {
            "rating": 1162.0625200890545,
            "rating_q975": 1182.5594278551769,
            "rating_q025": 1141.565612322932
        },
        "qwen1.5-72b-chat": {
            "rating": 1160.9875000748139,
            "rating_q975": 1169.2073612887482,
            "rating_q025": 1152.7676388608795
        },
        "llama-3-8b-instruct": {
            "rating": 1156.3093284348138,
            "rating_q975": 1162.7327815507488,
            "rating_q025": 1149.8858753188788
        },
        "reka-flash-21b-20240226": {
            "rating": 1155.501513253193,
            "rating_q975": 1164.5522315830226,
            "rating_q025": 1146.4507949233634
        },
        "mixtral-8x22b-instruct-v0.1": {
            "rating": 1154.281468743763,
            "rating_q975": 1161.5299912047697,
            "rating_q025": 1147.0329462827565
        },
        "qwq-32b-preview": {
            "rating": 1153.754965234867,
            "rating_q975": 1174.3693706864692,
            "rating_q025": 1133.140559783265
        },
        "mistral-medium": {
            "rating": 1153.7142249122064,
            "rating_q975": 1162.6291378556136,
            "rating_q025": 1144.7993119687992
        },
        "qwen1.5-32b-chat": {
            "rating": 1146.7997676259165,
            "rating_q975": 1156.2522358935705,
            "rating_q025": 1137.3472993582625
        },
        "command-r": {
            "rating": 1142.729662529018,
            "rating_q975": 1150.1187278738726,
            "rating_q025": 1135.3405971841635
        },
        "starling-lm-7b-beta": {
            "rating": 1141.804860481154,
            "rating_q975": 1152.7518005825461,
            "rating_q025": 1130.857920379762
        },
        "qwen1.5-14b-chat": {
            "rating": 1140.9613856363867,
            "rating_q975": 1151.827826078628,
            "rating_q025": 1130.0949451941453
        },
        "granite-3.1-2b-instruct": {
            "rating": 1139.6089962750978,
            "rating_q975": 1159.9191538268126,
            "rating_q025": 1119.298838723383
        },
        "zephyr-orpo-141b-A35b-v0.1": {
            "rating": 1133.7954377066058,
            "rating_q975": 1150.649541597993,
            "rating_q025": 1116.9413338152185
        },
        "phi-3-medium-4k-instruct": {
            "rating": 1133.6339494766153,
            "rating_q975": 1142.0447575528285,
            "rating_q025": 1125.223141400402
        },
        "gemma-2-2b-it": {
            "rating": 1132.2285408627956,
            "rating_q975": 1138.7215179208824,
            "rating_q025": 1125.7355638047088
        },
        "gemini-pro-dev-api": {
            "rating": 1131.251180650498,
            "rating_q975": 1142.6958758386088,
            "rating_q025": 1119.8064854623874
        },
        "mixtral-8x7b-instruct-v0.1": {
            "rating": 1125.1894829436053,
            "rating_q975": 1132.0957736183132,
            "rating_q025": 1118.2831922688974
        },
        "yi-34b-chat": {
            "rating": 1122.033116953307,
            "rating_q975": 1132.8121967370898,
            "rating_q025": 1111.254037169524
        },
        "dbrx-instruct-preview": {
            "rating": 1116.7567701637522,
            "rating_q975": 1126.0541273855006,
            "rating_q025": 1107.4594129420038
        },
        "gpt-3.5-turbo-0125": {
            "rating": 1115.5826440053293,
            "rating_q975": 1122.5778179723682,
            "rating_q025": 1108.5874700382903
        },
        "gemini-pro": {
            "rating": 1111.1658622441778,
            "rating_q975": 1129.9331325360176,
            "rating_q025": 1092.398591952338
        },
        "tulu-2-dpo-70b": {
            "rating": 1110.2483625054583,
            "rating_q975": 1126.9587928477386,
            "rating_q025": 1093.537932163178
        },
        "phi-3-small-8k-instruct": {
            "rating": 1108.744059713051,
            "rating_q975": 1118.5222279872294,
            "rating_q025": 1098.9658914388726
        },
        "openchat-3.5-0106": {
            "rating": 1105.0359602925157,
            "rating_q975": 1116.8036057225297,
            "rating_q025": 1093.2683148625017
        },
        "llama-3.2-3b-instruct": {
            "rating": 1103.0396733647397,
            "rating_q975": 1115.967585912532,
            "rating_q025": 1090.1117608169473
        },
        "granite-3.0-8b-instruct": {
            "rating": 1100.2429127701075,
            "rating_q975": 1115.0030748895624,
            "rating_q025": 1085.4827506506526
        },
        "llama-2-70b-chat": {
            "rating": 1099.0707067285834,
            "rating_q975": 1107.418315991475,
            "rating_q025": 1090.7230974656918
        },
        "gemma-1.1-7b-it": {
            "rating": 1095.529138838382,
            "rating_q975": 1104.2841420449936,
            "rating_q025": 1086.7741356317706
        },
        "deepseek-llm-67b-chat": {
            "rating": 1095.077128337697,
            "rating_q975": 1113.9287506989758,
            "rating_q025": 1076.2255059764184
        },
        "nous-hermes-2-mixtral-8x7b-dpo": {
            "rating": 1094.8730560467448,
            "rating_q975": 1113.7348865180927,
            "rating_q025": 1076.0112255753968
        },
        "starling-lm-7b-alpha": {
            "rating": 1091.8157334420764,
            "rating_q975": 1104.8709955665313,
            "rating_q025": 1078.7604713176215
        },
        "gpt-3.5-turbo-1106": {
            "rating": 1091.391946123831,
            "rating_q975": 1104.6109478386154,
            "rating_q025": 1078.1729444090467
        },
        "qwen1.5-7b-chat": {
            "rating": 1090.3723469253941,
            "rating_q975": 1106.817792547346,
            "rating_q025": 1073.9269013034423
        },
        "phi-3-mini-4k-instruct-june-2024": {
            "rating": 1088.1695648764576,
            "rating_q975": 1099.455359877422,
            "rating_q025": 1076.883769875493
        },
        "wizardlm-70b": {
            "rating": 1088.1132714973526,
            "rating_q975": 1103.4903668635927,
            "rating_q025": 1072.7361761311124
        },
        "snowflake-arctic-instruct": {
            "rating": 1087.9350839525034,
            "rating_q975": 1097.6608341726903,
            "rating_q025": 1078.2093337323165
        },
        "vicuna-33b": {
            "rating": 1085.7339231628239,
            "rating_q975": 1095.9030155954633,
            "rating_q025": 1075.5648307301844
        },
        "openchat-3.5": {
            "rating": 1083.7716765577247,
            "rating_q975": 1099.3853774860972,
            "rating_q025": 1068.1579756293522
        },
        "mistral-7b-instruct-v0.2": {
            "rating": 1083.001250165008,
            "rating_q975": 1093.0430925290061,
            "rating_q025": 1072.95940780101
        },
        "phi-3-mini-4k-instruct": {
            "rating": 1082.1042018239436,
            "rating_q975": 1091.9205357566068,
            "rating_q025": 1072.2878678912805
        },
        "granite-3.0-2b-instruct": {
            "rating": 1079.0887599047937,
            "rating_q975": 1093.3768486793724,
            "rating_q025": 1064.800671130215
        },
        "openhermes-2.5-mistral-7b": {
            "rating": 1076.913184579866,
            "rating_q975": 1094.6257593226994,
            "rating_q025": 1059.2006098370327
        },
        "llama-2-13b-chat": {
            "rating": 1072.588234205992,
            "rating_q975": 1082.9065977023597,
            "rating_q025": 1062.2698707096242
        },
        "solar-10.7b-instruct-v1.0": {
            "rating": 1068.208340241698,
            "rating_q975": 1089.004696768883,
            "rating_q025": 1047.4119837145129
        },
        "codellama-34b-instruct": {
            "rating": 1062.8160317322208,
            "rating_q975": 1077.836168046308,
            "rating_q025": 1047.7958954181336
        },
        "gemma-7b-it": {
            "rating": 1060.1920267755618,
            "rating_q975": 1074.2662482922444,
            "rating_q025": 1046.1178052588791
        },
        "mpt-30b-chat": {
            "rating": 1057.540599356008,
            "rating_q975": 1082.70129441436,
            "rating_q025": 1032.379904297656
        },
        "codellama-70b-instruct": {
            "rating": 1057.0684875634813,
            "rating_q975": 1089.9776643345401,
            "rating_q025": 1024.1593107924225
        },
        "llama-3.2-1b-instruct": {
            "rating": 1056.0587946189669,
            "rating_q975": 1069.40941309601,
            "rating_q025": 1042.7081761419238
        },
        "llama2-70b-steerlm-chat": {
            "rating": 1055.8733720625305,
            "rating_q975": 1076.8684653029966,
            "rating_q025": 1034.8782788220644
        },
        "zephyr-7b-alpha": {
            "rating": 1053.4006179372454,
            "rating_q975": 1082.7925300654263,
            "rating_q025": 1024.0087058090646
        },
        "qwen-14b-chat": {
            "rating": 1052.6605728577583,
            "rating_q975": 1071.2630540115365,
            "rating_q025": 1034.0580917039802
        },
        "wizardlm-13b": {
            "rating": 1052.5580595686536,
            "rating_q975": 1068.6843848692297,
            "rating_q025": 1036.4317342680774
        },
        "zephyr-7b-beta": {
            "rating": 1048.2241925908127,
            "rating_q975": 1062.5749173372965,
            "rating_q025": 1033.8734678443288
        },
        "vicuna-13b": {
            "rating": 1047.996420849398,
            "rating_q975": 1058.8014115094124,
            "rating_q025": 1037.1914301893835
        },
        "dolphin-2.2.1-mistral-7b": {
            "rating": 1046.7217595076486,
            "rating_q975": 1075.6894411257879,
            "rating_q025": 1017.7540778895093
        },
        "smollm2-1.7b-instruct": {
            "rating": 1046.4962109931043,
            "rating_q975": 1073.1317539820984,
            "rating_q025": 1019.8606680041102
        },
        "olmo-7b-instruct": {
            "rating": 1037.472625524833,
            "rating_q975": 1055.0498197952481,
            "rating_q025": 1019.8954312544178
        },
        "phi-3-mini-128k-instruct": {
            "rating": 1034.2585424695071,
            "rating_q975": 1045.5490400559227,
            "rating_q025": 1022.9680448830916
        },
        "gemma-1.1-2b-it": {
            "rating": 1031.5348934166468,
            "rating_q975": 1043.5109068933732,
            "rating_q025": 1019.5588799399203
        },
        "llama-2-7b-chat": {
            "rating": 1029.1833952100046,
            "rating_q975": 1040.258816715404,
            "rating_q025": 1018.1079737046052
        },
        "falcon-180b-chat": {
            "rating": 1024.57554670813,
            "rating_q975": 1058.76945015051,
            "rating_q025": 990.3816432657503
        },
        "stripedhyena-nous-7b": {
            "rating": 1021.7932798457509,
            "rating_q975": 1039.6458572105234,
            "rating_q025": 1003.9407024809785
        },
        "gemma-2b-it": {
            "rating": 1019.7913789039922,
            "rating_q975": 1037.7449869591157,
            "rating_q025": 1001.8377708488686
        },
        "vicuna-7b": {
            "rating": 1017.0472851369095,
            "rating_q975": 1033.5230559865167,
            "rating_q025": 1000.5715142873023
        },
        "mistral-7b-instruct": {
            "rating": 1014.6741987286734,
            "rating_q975": 1030.5650885988077,
            "rating_q025": 998.783308858539
        },
        "guanaco-33b": {
            "rating": 1012.7722807693922,
            "rating_q975": 1037.061560221072,
            "rating_q025": 988.4830013177121
        },
        "palm-2": {
            "rating": 999.7388744422722,
            "rating_q975": 1015.1328281266129,
            "rating_q025": 984.3449207579314
        },
        "qwen1.5-4b-chat": {
            "rating": 994.4648383405104,
            "rating_q975": 1008.9895386464576,
            "rating_q025": 979.9401380345631
        },
        "chatglm3-6b": {
            "rating": 969.5062679880186,
            "rating_q975": 990.2752596511136,
            "rating_q025": 948.7372763249236
        },
        "koala-13b": {
            "rating": 960.7484734588854,
            "rating_q975": 979.08482825705,
            "rating_q025": 942.4121186607208
        },
        "gpt4all-13b-snoozy": {
            "rating": 931.3704752934693,
            "rating_q975": 961.7013091056555,
            "rating_q025": 901.0396414812832
        },
        "chatglm2-6b": {
            "rating": 917.5956924990448,
            "rating_q975": 942.707255199511,
            "rating_q025": 892.4841297985787
        },
        "RWKV-4-Raven-14B": {
            "rating": 914.5660951788288,
            "rating_q975": 934.8473333932105,
            "rating_q025": 894.2848569644472
        },
        "mpt-7b-chat": {
            "rating": 912.5064345019222,
            "rating_q975": 934.8595094824229,
            "rating_q025": 890.1533595214214
        },
        "chatglm-6b": {
            "rating": 888.4435562504773,
            "rating_q975": 908.8573059697238,
            "rating_q025": 868.0298065312307
        },
        "oasst-pythia-12b": {
            "rating": 881.4080634642525,
            "rating_q975": 900.743859841927,
            "rating_q025": 862.0722670865779
        },
        "stablelm-tuned-alpha-7b": {
            "rating": 857.7887450089931,
            "rating_q975": 882.4999882468719,
            "rating_q025": 833.0775017711144
        },
        "fastchat-t5-3b": {
            "rating": 835.8777873262136,
            "rating_q975": 856.9815356118278,
            "rating_q025": 814.7740390405994
        },
        "alpaca-13b": {
            "rating": 826.3680490532217,
            "rating_q975": 846.4969310133642,
            "rating_q025": 806.2391670930792
        },
        "dolly-v2-12b": {
            "rating": 789.1541866538037,
            "rating_q975": 813.4876694423854,
            "rating_q025": 764.820703865222
        },
        "llama-13b": {
            "rating": 719.2406665359467,
            "rating_q975": 748.9435558278473,
            "rating_q025": 689.5377772440462
        }
    },
    "industry_writing_and_literature_and_language": {
        "gemini-3-pro": {
            "rating": 1491.3112216585141,
            "rating_q975": 1502.5319843354612,
            "rating_q025": 1480.090458981567
        },
        "gemini-2.5-pro": {
            "rating": 1462.7014596940526,
            "rating_q975": 1468.5307410694352,
            "rating_q025": 1456.87217831867
        },
        "claude-opus-4-5-20251101": {
            "rating": 1445.5733852561514,
            "rating_q975": 1458.6725260907576,
            "rating_q025": 1432.474244421545
        },
        "claude-opus-4-5-20251101-thinking-32k": {
            "rating": 1435.2266107345804,
            "rating_q975": 1448.5802050328386,
            "rating_q025": 1421.8730164363221
        },
        "claude-sonnet-4-5-20250929": {
            "rating": 1429.451006891511,
            "rating_q975": 1438.516288135742,
            "rating_q025": 1420.3857256472802
        },
        "gpt-5.1-high": {
            "rating": 1427.6721980310874,
            "rating_q975": 1439.2697988567136,
            "rating_q025": 1416.0745972054613
        },
        "ernie-5.0-preview-1103": {
            "rating": 1424.0962062155486,
            "rating_q975": 1440.889097132224,
            "rating_q025": 1407.3033152988733
        },
        "claude-sonnet-4-5-20250929-thinking-32k": {
            "rating": 1423.17945734886,
            "rating_q975": 1431.4858919148662,
            "rating_q025": 1414.873022782854
        },
        "grok-4.1-thinking": {
            "rating": 1419.3004038262206,
            "rating_q975": 1430.1862505635818,
            "rating_q025": 1408.4145570888595
        },
        "claude-opus-4-1-20250805-thinking-16k": {
            "rating": 1414.771503972202,
            "rating_q975": 1421.5824038405003,
            "rating_q025": 1407.9606041039037
        },
        "claude-opus-4-1-20250805": {
            "rating": 1414.5246802605914,
            "rating_q975": 1420.8034108074137,
            "rating_q025": 1408.245949713769
        },
        "grok-4.1": {
            "rating": 1411.3989175660697,
            "rating_q975": 1422.1664209633802,
            "rating_q025": 1400.6314141687592
        },
        "chatgpt-4o-latest-20250326": {
            "rating": 1410.8925627616165,
            "rating_q975": 1416.5170303802083,
            "rating_q025": 1405.2680951430248
        },
        "gpt-4.5-preview-2025-02-27": {
            "rating": 1410.4899421193331,
            "rating_q975": 1420.0479131140357,
            "rating_q025": 1400.9319711246305
        },
        "deepseek-v3.2-exp": {
            "rating": 1410.440592417543,
            "rating_q975": 1422.3006550785447,
            "rating_q025": 1398.5805297565414
        },
        "glm-4.6": {
            "rating": 1409.8228727182775,
            "rating_q975": 1418.3214004040253,
            "rating_q025": 1401.3243450325297
        },
        "grok-3-preview-02-24": {
            "rating": 1409.2993787174132,
            "rating_q975": 1416.3104480393395,
            "rating_q025": 1402.288309395487
        },
        "gpt-5.1": {
            "rating": 1408.7667655610887,
            "rating_q975": 1419.9377700380116,
            "rating_q025": 1397.5957610841658
        },
        "deepseek-v3.1-terminus": {
            "rating": 1407.7461769283352,
            "rating_q975": 1428.5569315937876,
            "rating_q025": 1386.9354222628829
        },
        "qwen3-max-preview": {
            "rating": 1407.52048893507,
            "rating_q975": 1415.4403712727142,
            "rating_q025": 1399.600606597426
        },
        "mistral-large-3": {
            "rating": 1405.4735746526442,
            "rating_q975": 1421.0066875346333,
            "rating_q025": 1389.940461770655
        },
        "gemini-2.5-flash": {
            "rating": 1405.0503657146824,
            "rating_q975": 1410.6115318350846,
            "rating_q025": 1399.48919959428
        },
        "deepseek-v3.2-thinking": {
            "rating": 1404.5621098413071,
            "rating_q975": 1420.4658836288106,
            "rating_q025": 1388.6583360538036
        },
        "deepseek-v3.1-thinking": {
            "rating": 1403.867314880601,
            "rating_q975": 1415.186854726841,
            "rating_q025": 1392.5477750343612
        },
        "deepseek-v3.1-terminus-thinking": {
            "rating": 1402.12196981214,
            "rating_q975": 1423.299972437695,
            "rating_q025": 1380.9439671865848
        },
        "deepseek-r1-0528": {
            "rating": 1402.0016539320545,
            "rating_q975": 1411.3590688742509,
            "rating_q025": 1392.6442389898582
        },
        "glm-4.5": {
            "rating": 1401.6984305624565,
            "rating_q975": 1410.0564691686952,
            "rating_q025": 1393.3403919562177
        },
        "deepseek-v3.2": {
            "rating": 1398.938085244384,
            "rating_q975": 1414.926624266181,
            "rating_q025": 1382.9495462225868
        },
        "grok-4-0709": {
            "rating": 1397.5912109910923,
            "rating_q975": 1404.311206059978,
            "rating_q025": 1390.8712159222066
        },
        "deepseek-v3.1": {
            "rating": 1397.2775271127946,
            "rating_q975": 1407.4459225054707,
            "rating_q025": 1387.1091317201185
        },
        "mistral-medium-2508": {
            "rating": 1397.1781218840215,
            "rating_q975": 1403.815490528296,
            "rating_q025": 1390.540753239747
        },
        "gemini-2.5-flash-preview-09-2025": {
            "rating": 1394.8863534729935,
            "rating_q975": 1402.9096739330143,
            "rating_q025": 1386.8630330129727
        },
        "qwen3-vl-235b-a22b-instruct": {
            "rating": 1393.9799155296093,
            "rating_q975": 1407.6844215313884,
            "rating_q025": 1380.2754095278303
        },
        "deepseek-v3.2-exp-thinking": {
            "rating": 1392.8101643161435,
            "rating_q975": 1405.9216581655903,
            "rating_q025": 1379.6986704666967
        },
        "grok-4-1-fast-reasoning": {
            "rating": 1392.6698743056131,
            "rating_q975": 1406.0419415785207,
            "rating_q025": 1379.2978070327056
        },
        "grok-4-fast-chat": {
            "rating": 1391.3676169514206,
            "rating_q975": 1406.1945867999264,
            "rating_q025": 1376.5406471029148
        },
        "qwen3-max-2025-09-23": {
            "rating": 1389.934688448359,
            "rating_q975": 1403.0110920223417,
            "rating_q025": 1376.8582848743765
        },
        "qwen3-235b-a22b-thinking-2507": {
            "rating": 1386.7257589057022,
            "rating_q975": 1399.9312381007176,
            "rating_q025": 1373.5202797106867
        },
        "qwen3-235b-a22b-instruct-2507": {
            "rating": 1386.1759498963452,
            "rating_q975": 1392.466870638638,
            "rating_q025": 1379.8850291540523
        },
        "claude-opus-4-20250514-thinking-16k": {
            "rating": 1385.9655728435303,
            "rating_q975": 1393.2623710700982,
            "rating_q025": 1378.6687746169623
        },
        "kimi-k2-thinking-turbo": {
            "rating": 1384.7612166736271,
            "rating_q975": 1395.3403706433737,
            "rating_q025": 1374.1820627038805
        },
        "hunyuan-t1-20250711": {
            "rating": 1384.6530838693982,
            "rating_q975": 1402.7538636330946,
            "rating_q025": 1366.5523041057018
        },
        "gpt-5-chat": {
            "rating": 1383.3411728077178,
            "rating_q975": 1390.9387425285422,
            "rating_q025": 1375.7436030868935
        },
        "gpt-5-high": {
            "rating": 1381.9352707867508,
            "rating_q975": 1389.489202171895,
            "rating_q025": 1374.3813394016067
        },
        "claude-opus-4-20250514": {
            "rating": 1379.421121059994,
            "rating_q975": 1386.3079775401038,
            "rating_q025": 1372.5342645798842
        },
        "hunyuan-vision-1.5-thinking": {
            "rating": 1379.055176425962,
            "rating_q975": 1405.3213717506092,
            "rating_q025": 1352.7889811013147
        },
        "claude-haiku-4-5-20251001": {
            "rating": 1376.9952006256221,
            "rating_q975": 1385.4955576787468,
            "rating_q025": 1368.4948435724975
        },
        "grok-4-fast-reasoning": {
            "rating": 1374.8115024025335,
            "rating_q975": 1384.2692066247773,
            "rating_q025": 1365.3537981802897
        },
        "o3-2025-04-16": {
            "rating": 1372.172309525003,
            "rating_q975": 1378.121279688756,
            "rating_q025": 1366.2233393612498
        },
        "gemini-2.5-flash-lite-preview-06-17-thinking": {
            "rating": 1371.3373379261332,
            "rating_q975": 1378.7619306019226,
            "rating_q025": 1363.9127452503437
        },
        "gpt-4.1-2025-04-14": {
            "rating": 1368.7678131240898,
            "rating_q975": 1374.9439971552622,
            "rating_q025": 1362.5916290929174
        },
        "gemini-2.5-flash-lite-preview-09-2025-no-thinking": {
            "rating": 1367.9658941446205,
            "rating_q975": 1375.8909964091774,
            "rating_q025": 1360.0407918800636
        },
        "longcat-flash-chat": {
            "rating": 1367.6552723108107,
            "rating_q975": 1379.4061446219173,
            "rating_q025": 1355.904399999704
        },
        "qwen3-235b-a22b-no-thinking": {
            "rating": 1364.875205085412,
            "rating_q975": 1371.9527228251263,
            "rating_q025": 1357.7976873456978
        },
        "deepseek-v3-0324": {
            "rating": 1364.303663623779,
            "rating_q975": 1370.6439401161056,
            "rating_q025": 1357.9633871314522
        },
        "qwen3-vl-235b-a22b-thinking": {
            "rating": 1363.89218327575,
            "rating_q975": 1378.0079407971155,
            "rating_q025": 1349.7764257543847
        },
        "deepseek-r1": {
            "rating": 1363.5257542165334,
            "rating_q975": 1371.541412689892,
            "rating_q025": 1355.5100957431748
        },
        "mai-1-preview": {
            "rating": 1359.5417705202426,
            "rating_q975": 1369.068442674278,
            "rating_q025": 1350.0150983662072
        },
        "o1-2024-12-17": {
            "rating": 1359.2947295309073,
            "rating_q975": 1366.4333554758691,
            "rating_q025": 1352.1561035859454
        },
        "claude-sonnet-4-20250514-thinking-32k": {
            "rating": 1355.7136094743482,
            "rating_q975": 1363.045243131679,
            "rating_q025": 1348.3819758170175
        },
        "qwen3-next-80b-a3b-instruct": {
            "rating": 1355.428444884246,
            "rating_q975": 1363.979206102463,
            "rating_q025": 1346.8776836660288
        },
        "glm-4.5-air": {
            "rating": 1354.135526238103,
            "rating_q975": 1361.5400860503098,
            "rating_q025": 1346.7309664258962
        },
        "hunyuan-turbos-20250416": {
            "rating": 1350.9561403762991,
            "rating_q975": 1362.3427564297328,
            "rating_q025": 1339.5695243228654
        },
        "mistral-medium-2505": {
            "rating": 1350.768171314164,
            "rating_q975": 1358.1647260031118,
            "rating_q025": 1343.3716166252161
        },
        "amazon-nova-experimental-chat-10-20": {
            "rating": 1348.2515961365098,
            "rating_q975": 1362.6923126381519,
            "rating_q025": 1333.8108796348677
        },
        "claude-sonnet-4-20250514": {
            "rating": 1347.050628032721,
            "rating_q975": 1354.0752944787703,
            "rating_q025": 1340.0259615866719
        },
        "gemini-2.0-flash-001": {
            "rating": 1346.714722500347,
            "rating_q975": 1352.6845153591682,
            "rating_q025": 1340.744929641526
        },
        "grok-3-mini-high": {
            "rating": 1346.6126542077723,
            "rating_q975": 1356.3479982191282,
            "rating_q025": 1336.8773101964164
        },
        "gpt-5-mini-high": {
            "rating": 1346.1547275382495,
            "rating_q975": 1354.1288283262872,
            "rating_q025": 1338.1806267502118
        },
        "gemma-3-27b-it": {
            "rating": 1345.422695644676,
            "rating_q975": 1351.4428019791014,
            "rating_q025": 1339.4025893102505
        },
        "qwen2.5-max": {
            "rating": 1345.3440256684455,
            "rating_q975": 1351.9398631636163,
            "rating_q025": 1338.7481881732747
        },
        "grok-3-mini-beta": {
            "rating": 1344.6740572708673,
            "rating_q975": 1353.1718022503674,
            "rating_q025": 1336.1763122913671
        },
        "kimi-k2-0905-preview": {
            "rating": 1342.2988439309697,
            "rating_q975": 1354.0177935736767,
            "rating_q025": 1330.5798942882627
        },
        "qwen3-coder-480b-a35b-instruct": {
            "rating": 1338.9388944621262,
            "rating_q975": 1347.4654602827563,
            "rating_q025": 1330.412328641496
        },
        "qwen3-235b-a22b": {
            "rating": 1338.8590934676497,
            "rating_q975": 1346.6145495718552,
            "rating_q025": 1331.1036373634442
        },
        "o1-preview": {
            "rating": 1338.7468542069992,
            "rating_q975": 1346.599067222738,
            "rating_q025": 1330.8946411912602
        },
        "qwen3-30b-a3b-instruct-2507": {
            "rating": 1336.377787880021,
            "rating_q975": 1344.8485607303614,
            "rating_q025": 1327.9070150296807
        },
        "claude-3-7-sonnet-20250219-thinking-32k": {
            "rating": 1335.971217657331,
            "rating_q975": 1342.7043524199094,
            "rating_q025": 1329.2380828947526
        },
        "deepseek-v3": {
            "rating": 1330.3406526938224,
            "rating_q975": 1338.3363388645043,
            "rating_q025": 1322.3449665231406
        },
        "kimi-k2-0711-preview": {
            "rating": 1328.502155426996,
            "rating_q975": 1336.4048702907312,
            "rating_q025": 1320.599440563261
        },
        "command-a-03-2025": {
            "rating": 1326.1429978831309,
            "rating_q975": 1331.8734144101184,
            "rating_q025": 1320.4125813561434
        },
        "glm-4-plus-0111": {
            "rating": 1325.8378830625386,
            "rating_q975": 1340.9239435484255,
            "rating_q025": 1310.7518225766516
        },
        "gemini-1.5-pro-002": {
            "rating": 1325.7298242079985,
            "rating_q975": 1331.3775495978407,
            "rating_q025": 1320.0820988181563
        },
        "amazon-nova-experimental-chat-10-09": {
            "rating": 1325.3749703318613,
            "rating_q975": 1338.231714630273,
            "rating_q025": 1312.5182260334495
        },
        "qwen3-next-80b-a3b-thinking": {
            "rating": 1324.387823903417,
            "rating_q975": 1335.1670964926373,
            "rating_q025": 1313.6085513141968
        },
        "step-3": {
            "rating": 1323.0270277565478,
            "rating_q975": 1338.1776150858398,
            "rating_q025": 1307.8764404272558
        },
        "claude-3-7-sonnet-20250219": {
            "rating": 1322.9634481747078,
            "rating_q975": 1329.3774107124743,
            "rating_q025": 1316.5494856369412
        },
        "nova-2-lite": {
            "rating": 1320.7676037012577,
            "rating_q975": 1337.81627647053,
            "rating_q025": 1303.7189309319854
        },
        "gemini-2.0-flash-lite-preview-02-05": {
            "rating": 1320.6838274892912,
            "rating_q975": 1327.877645923455,
            "rating_q025": 1313.4900090551273
        },
        "gpt-4.1-mini-2025-04-14": {
            "rating": 1318.1956734992468,
            "rating_q975": 1325.0660295256646,
            "rating_q025": 1311.325317472829
        },
        "o4-mini-2025-04-16": {
            "rating": 1317.882064648684,
            "rating_q975": 1324.3347876427906,
            "rating_q025": 1311.4293416545775
        },
        "intellect-3": {
            "rating": 1317.816075067356,
            "rating_q975": 1344.4468944814653,
            "rating_q025": 1291.1852556532467
        },
        "claude-3-5-sonnet-20241022": {
            "rating": 1312.9522983946017,
            "rating_q975": 1317.6079603103824,
            "rating_q025": 1308.296636478821
        },
        "o3-mini-high": {
            "rating": 1312.3553240997353,
            "rating_q975": 1321.004426668052,
            "rating_q025": 1303.7062215314186
        },
        "minimax-m1": {
            "rating": 1312.1678620546177,
            "rating_q975": 1319.2115891072588,
            "rating_q025": 1305.1241350019766
        },
        "mistral-small-2506": {
            "rating": 1310.5563925492884,
            "rating_q975": 1319.9723293118725,
            "rating_q025": 1301.1404557867043
        },
        "step-1o-turbo-202506": {
            "rating": 1308.7138264386613,
            "rating_q975": 1321.9586894659865,
            "rating_q025": 1295.468963411336
        },
        "gemma-3-12b-it": {
            "rating": 1306.7524732154088,
            "rating_q975": 1324.3197721295812,
            "rating_q025": 1289.1851743012364
        },
        "gpt-oss-120b": {
            "rating": 1305.7299559243502,
            "rating_q975": 1313.362071693894,
            "rating_q025": 1298.0978401548064
        },
        "step-2-16k-exp-202412": {
            "rating": 1302.7603087731045,
            "rating_q975": 1318.2546203028874,
            "rating_q025": 1287.2659972433216
        },
        "glm-4.5v": {
            "rating": 1302.4590419014492,
            "rating_q975": 1320.2611988925141,
            "rating_q025": 1284.6568849103842
        },
        "qwq-32b": {
            "rating": 1300.9811242296018,
            "rating_q975": 1308.4576548291625,
            "rating_q025": 1293.5045936300412
        },
        "hunyuan-turbos-20250226": {
            "rating": 1300.6041064925826,
            "rating_q975": 1321.9764235644411,
            "rating_q025": 1279.231789420724
        },
        "llama-3.1-nemotron-ultra-253b-v1": {
            "rating": 1300.1183144091938,
            "rating_q975": 1321.2236933032814,
            "rating_q025": 1279.0129355151062
        },
        "llama-3.3-nemotron-49b-super-v1": {
            "rating": 1298.7884302821558,
            "rating_q975": 1321.5989339966566,
            "rating_q025": 1275.977926567655
        },
        "minimax-m2": {
            "rating": 1298.5232536385915,
            "rating_q975": 1314.2667980359947,
            "rating_q025": 1282.7797092411884
        },
        "qwen3-32b": {
            "rating": 1298.411153603152,
            "rating_q975": 1315.2308703104818,
            "rating_q025": 1281.591436895822
        },
        "gpt-4o-2024-05-13": {
            "rating": 1296.7645233175183,
            "rating_q975": 1302.3922716577692,
            "rating_q025": 1291.1367749772674
        },
        "qwen-plus-0125": {
            "rating": 1295.0861454381902,
            "rating_q975": 1309.8326563000521,
            "rating_q025": 1280.3396345763283
        },
        "o3-mini": {
            "rating": 1294.561850134714,
            "rating_q975": 1300.0515392217378,
            "rating_q025": 1289.07216104769
        },
        "ring-flash-2.0": {
            "rating": 1293.9107266881138,
            "rating_q975": 1309.2645289979191,
            "rating_q025": 1278.5569243783084
        },
        "ling-flash-2.0": {
            "rating": 1293.5686297823017,
            "rating_q975": 1308.9593583228516,
            "rating_q025": 1278.177901241752
        },
        "gemini-1.5-flash-002": {
            "rating": 1292.6209973540258,
            "rating_q975": 1299.382898273509,
            "rating_q025": 1285.8590964345426
        },
        "nvidia-llama-3.3-nemotron-super-49b-v1.5": {
            "rating": 1291.8271844283008,
            "rating_q975": 1313.4406083682338,
            "rating_q025": 1270.2137604883678
        },
        "grok-2-2024-08-13": {
            "rating": 1291.2922408126879,
            "rating_q975": 1296.9734510494177,
            "rating_q025": 1285.611030575958
        },
        "qwen3-30b-a3b": {
            "rating": 1291.2759321250428,
            "rating_q975": 1299.1041456636572,
            "rating_q025": 1283.4477185864284
        },
        "hunyuan-turbo-0110": {
            "rating": 1289.9768383525552,
            "rating_q975": 1309.9920612350002,
            "rating_q025": 1269.9616154701102
        },
        "gpt-4o-2024-08-06": {
            "rating": 1289.1456921874997,
            "rating_q975": 1295.8035648408497,
            "rating_q025": 1282.4878195341496
        },
        "gemini-1.5-pro-001": {
            "rating": 1288.1634200169574,
            "rating_q975": 1294.7646744781182,
            "rating_q025": 1281.5621655557966
        },
        "gemma-3-4b-it": {
            "rating": 1287.5322775668508,
            "rating_q975": 1304.589536745169,
            "rating_q025": 1270.4750183885326
        },
        "gpt-5-nano-high": {
            "rating": 1286.4745363458496,
            "rating_q975": 1300.718459807746,
            "rating_q025": 1272.2306128839532
        },
        "gemma-3n-e4b-it": {
            "rating": 1286.0253850620877,
            "rating_q975": 1294.6190555810865,
            "rating_q025": 1277.431714543089
        },
        "gemini-advanced-0514": {
            "rating": 1285.1325635814533,
            "rating_q975": 1292.8680642487648,
            "rating_q025": 1277.3970629141418
        },
        "deepseek-v2.5-1210": {
            "rating": 1282.5515374687266,
            "rating_q975": 1295.8450771292798,
            "rating_q025": 1269.2579978081733
        },
        "olmo-3-32b-think": {
            "rating": 1281.4165840352052,
            "rating_q975": 1303.621887282162,
            "rating_q025": 1259.2112807882484
        },
        "gpt-4o-mini-2024-07-18": {
            "rating": 1281.2896542441913,
            "rating_q975": 1286.6040204412373,
            "rating_q025": 1275.9752880471453
        },
        "claude-3-5-sonnet-20240620": {
            "rating": 1279.6421976965903,
            "rating_q975": 1285.5488827811812,
            "rating_q025": 1273.7355126119994
        },
        "o1-mini": {
            "rating": 1279.0025247384913,
            "rating_q975": 1284.8423459372048,
            "rating_q025": 1273.1627035397778
        },
        "llama-4-maverick-17b-128e-instruct": {
            "rating": 1278.8056102762869,
            "rating_q975": 1285.622625174556,
            "rating_q025": 1271.9885953780176
        },
        "gpt-4-turbo-2024-04-09": {
            "rating": 1278.017575672498,
            "rating_q975": 1284.264609119847,
            "rating_q025": 1271.770542225149
        },
        "glm-4-plus": {
            "rating": 1277.479784723821,
            "rating_q975": 1285.6085963949938,
            "rating_q025": 1269.3509730526482
        },
        "yi-lightning": {
            "rating": 1275.5946157090243,
            "rating_q975": 1283.6503116959318,
            "rating_q025": 1267.5389197221168
        },
        "llama-3.1-405b-instruct-fp8": {
            "rating": 1273.3312339747376,
            "rating_q975": 1279.2729570134602,
            "rating_q025": 1267.389510936015
        },
        "llama-4-scout-17b-16e-instruct": {
            "rating": 1272.8785297497143,
            "rating_q975": 1280.509725633037,
            "rating_q025": 1265.2473338663915
        },
        "qwen2.5-plus-1127": {
            "rating": 1272.596700326585,
            "rating_q975": 1283.418662236488,
            "rating_q025": 1261.774738416682
        },
        "hunyuan-large-2025-02-10": {
            "rating": 1270.4095251355668,
            "rating_q975": 1289.2278791037118,
            "rating_q025": 1251.5911711674219
        },
        "llama-3.1-405b-instruct-bf16": {
            "rating": 1269.8464190247546,
            "rating_q975": 1275.7501648989003,
            "rating_q025": 1263.942673150609
        },
        "qwen-max-0919": {
            "rating": 1269.3467657453575,
            "rating_q975": 1278.6793955259382,
            "rating_q025": 1260.0141359647769
        },
        "mistral-small-3.1-24b-instruct-2503": {
            "rating": 1268.7208169887858,
            "rating_q975": 1276.1547897346716,
            "rating_q025": 1261.2868442429
        },
        "claude-3-opus-20240229": {
            "rating": 1267.7822960151611,
            "rating_q975": 1272.7849181004378,
            "rating_q025": 1262.7796739298844
        },
        "gpt-4-1106-preview": {
            "rating": 1263.585909771057,
            "rating_q975": 1269.9380862023183,
            "rating_q025": 1257.2337333397957
        },
        "grok-2-mini-2024-08-13": {
            "rating": 1261.4405691374782,
            "rating_q975": 1267.4286980426398,
            "rating_q025": 1255.4524402323166
        },
        "gpt-4.1-nano-2025-04-14": {
            "rating": 1260.8337718745038,
            "rating_q975": 1275.0804061169413,
            "rating_q025": 1246.5871376320663
        },
        "mistral-large-2411": {
            "rating": 1259.7366156583194,
            "rating_q975": 1266.6950775221421,
            "rating_q025": 1252.7781537944966
        },
        "magistral-medium-2506": {
            "rating": 1259.2845121880664,
            "rating_q975": 1271.390961366922,
            "rating_q025": 1247.1780630092107
        },
        "hunyuan-large-vision": {
            "rating": 1258.421027112459,
            "rating_q975": 1276.3420086983706,
            "rating_q025": 1240.5000455265472
        },
        "mistral-large-2407": {
            "rating": 1257.1764307358876,
            "rating_q975": 1263.8179357921672,
            "rating_q025": 1250.534925679608
        },
        "hunyuan-standard-2025-02-10": {
            "rating": 1256.4373936166655,
            "rating_q975": 1274.6532480528908,
            "rating_q025": 1238.2215391804402
        },
        "gpt-4-0125-preview": {
            "rating": 1256.3860140020488,
            "rating_q975": 1262.8990192376734,
            "rating_q025": 1249.8730087664242
        },
        "llama-3.3-70b-instruct": {
            "rating": 1255.0970440648216,
            "rating_q975": 1260.4591433676117,
            "rating_q025": 1249.7349447620315
        },
        "claude-3-5-haiku-20241022": {
            "rating": 1255.0911842348196,
            "rating_q975": 1260.0557530604215,
            "rating_q025": 1250.1266154092177
        },
        "llama-3.1-tulu-3-70b": {
            "rating": 1253.840513193029,
            "rating_q975": 1273.2670061305837,
            "rating_q025": 1234.4140202554743
        },
        "athene-v2-chat": {
            "rating": 1253.5093063100494,
            "rating_q975": 1260.9491523110016,
            "rating_q025": 1246.0694603090972
        },
        "llama-3.1-nemotron-70b-instruct": {
            "rating": 1251.907516220342,
            "rating_q975": 1265.5956205785578,
            "rating_q025": 1238.219411862126
        },
        "gemini-1.5-flash-001": {
            "rating": 1251.0775935954498,
            "rating_q975": 1257.797510255159,
            "rating_q025": 1244.3576769357405
        },
        "gemma-2-27b-it": {
            "rating": 1247.9854100430239,
            "rating_q975": 1253.2323203610072,
            "rating_q025": 1242.7384997250406
        },
        "qwen2.5-72b-instruct": {
            "rating": 1246.259287375997,
            "rating_q975": 1252.8025957294622,
            "rating_q025": 1239.7159790225319
        },
        "deepseek-v2.5": {
            "rating": 1246.2054802051841,
            "rating_q975": 1254.2596866386339,
            "rating_q025": 1238.1512737717344
        },
        "amazon-nova-pro-v1.0": {
            "rating": 1246.0263524874356,
            "rating_q975": 1253.2368163682588,
            "rating_q025": 1238.8158886066124
        },
        "reka-core-20240904": {
            "rating": 1241.337108084449,
            "rating_q975": 1254.6065748056567,
            "rating_q025": 1228.0676413632414
        },
        "command-r-plus-08-2024": {
            "rating": 1240.3316330124187,
            "rating_q975": 1251.5256718631674,
            "rating_q025": 1229.13759416167
        },
        "athene-70b-0725": {
            "rating": 1240.0033120465378,
            "rating_q975": 1248.7692718276835,
            "rating_q025": 1231.237352265392
        },
        "gpt-oss-20b": {
            "rating": 1237.7794485738277,
            "rating_q975": 1250.6214783353112,
            "rating_q025": 1224.9374188123443
        },
        "mercury": {
            "rating": 1235.8411525928263,
            "rating_q975": 1265.0655218410875,
            "rating_q025": 1206.6167833445652
        },
        "llama-3.1-70b-instruct": {
            "rating": 1235.297824159199,
            "rating_q975": 1241.3191994105648,
            "rating_q025": 1229.2764489078334
        },
        "jamba-1.5-large": {
            "rating": 1226.5876162402024,
            "rating_q975": 1239.2052691082943,
            "rating_q025": 1213.9699633721104
        },
        "gemini-1.5-flash-8b-001": {
            "rating": 1226.0484492198352,
            "rating_q975": 1232.9233172717059,
            "rating_q025": 1219.1735811679646
        },
        "gemma-2-9b-it-simpo": {
            "rating": 1225.2503616359752,
            "rating_q975": 1236.8685270571266,
            "rating_q025": 1213.6321962148238
        },
        "nemotron-4-340b-instruct": {
            "rating": 1222.6586535494523,
            "rating_q975": 1231.9396688313811,
            "rating_q025": 1213.3776382675235
        },
        "c4ai-aya-expanse-32b": {
            "rating": 1221.3576032453889,
            "rating_q975": 1228.9488629497487,
            "rating_q025": 1213.766343541029
        },
        "llama-3.1-nemotron-51b-instruct": {
            "rating": 1218.9284173426763,
            "rating_q975": 1237.1163247453549,
            "rating_q025": 1200.7405099399978
        },
        "gemma-2-9b-it": {
            "rating": 1218.3958267166101,
            "rating_q975": 1224.1687907686996,
            "rating_q025": 1212.6228626645207
        },
        "command-r-plus": {
            "rating": 1218.0070908855218,
            "rating_q975": 1225.0026489587356,
            "rating_q025": 1211.0115328123081
        },
        "gpt-4-0314": {
            "rating": 1217.7665300982726,
            "rating_q975": 1226.0431522384642,
            "rating_q025": 1209.489907958081
        },
        "claude-3-sonnet-20240229": {
            "rating": 1216.7479859156977,
            "rating_q975": 1223.2351056775701,
            "rating_q025": 1210.2608661538252
        },
        "reka-flash-20240904": {
            "rating": 1215.961894662078,
            "rating_q975": 1228.8946969594556,
            "rating_q025": 1203.0290923647005
        },
        "gpt-4-0613": {
            "rating": 1213.4225512177945,
            "rating_q975": 1220.1757412651618,
            "rating_q025": 1206.6693611704272
        },
        "mistral-small-24b-instruct-2501": {
            "rating": 1213.2943776155466,
            "rating_q975": 1222.6270910911694,
            "rating_q025": 1203.9616641399239
        },
        "amazon-nova-lite-v1.0": {
            "rating": 1210.3607196769228,
            "rating_q975": 1218.5439557437537,
            "rating_q025": 1202.177483610092
        },
        "glm-4-0520": {
            "rating": 1209.4318727574114,
            "rating_q975": 1221.3553929780655,
            "rating_q025": 1197.5083525367572
        },
        "llama-3-70b-instruct": {
            "rating": 1205.3446509335322,
            "rating_q975": 1211.515362076919,
            "rating_q025": 1199.1739397901454
        },
        "olmo-2-0325-32b-instruct": {
            "rating": 1203.5841839519153,
            "rating_q975": 1223.0834714392365,
            "rating_q025": 1184.084896464594
        },
        "qwen2-72b-instruct": {
            "rating": 1200.7352053870839,
            "rating_q975": 1208.4299235911662,
            "rating_q025": 1193.0404871830015
        },
        "phi-4": {
            "rating": 1197.3426519240907,
            "rating_q975": 1204.9053016303355,
            "rating_q025": 1189.7800022178458
        },
        "claude-3-haiku-20240307": {
            "rating": 1193.114081510934,
            "rating_q975": 1199.202659529214,
            "rating_q025": 1187.025503492654
        },
        "command-r-08-2024": {
            "rating": 1192.3413470468272,
            "rating_q975": 1203.8491183117471,
            "rating_q025": 1180.8335757819073
        },
        "amazon-nova-micro-v1.0": {
            "rating": 1191.8508392141393,
            "rating_q975": 1200.0868792997426,
            "rating_q025": 1183.614799128536
        },
        "qwen2.5-coder-32b-instruct": {
            "rating": 1189.6665414233437,
            "rating_q975": 1204.271992245854,
            "rating_q025": 1175.0610906008333
        },
        "c4ai-aya-expanse-8b": {
            "rating": 1184.8502351389575,
            "rating_q975": 1195.9572932006101,
            "rating_q025": 1173.7431770773048
        },
        "ministral-8b-2410": {
            "rating": 1179.734864665937,
            "rating_q975": 1195.209723444174,
            "rating_q025": 1164.2600058877001
        },
        "mistral-large-2402": {
            "rating": 1178.9719382656413,
            "rating_q975": 1186.5329202177418,
            "rating_q025": 1171.4109563135407
        },
        "llama-3.1-tulu-3-8b": {
            "rating": 1176.9042795548867,
            "rating_q975": 1196.4124432615024,
            "rating_q025": 1157.396115848271
        },
        "hunyuan-standard-256k": {
            "rating": 1172.6743667651326,
            "rating_q975": 1193.512394181488,
            "rating_q025": 1151.8363393487773
        },
        "mistral-medium": {
            "rating": 1171.3496325313251,
            "rating_q975": 1180.6425122437774,
            "rating_q025": 1162.0567528188728
        },
        "qwen1.5-110b-chat": {
            "rating": 1169.7553341213056,
            "rating_q975": 1179.1304689643557,
            "rating_q025": 1160.3801992782555
        },
        "deepseek-coder-v2": {
            "rating": 1169.553869184897,
            "rating_q975": 1180.3046959609037,
            "rating_q025": 1158.8030424088902
        },
        "jamba-1.5-mini": {
            "rating": 1164.4420209527943,
            "rating_q975": 1176.9141932075797,
            "rating_q025": 1151.969848698009
        },
        "llama-3.1-8b-instruct": {
            "rating": 1161.4050617749713,
            "rating_q975": 1167.799665193201,
            "rating_q025": 1155.0104583567415
        },
        "command-r": {
            "rating": 1160.843522247727,
            "rating_q975": 1168.5637321908046,
            "rating_q025": 1153.1233123046493
        },
        "mixtral-8x22b-instruct-v0.1": {
            "rating": 1160.2067027598182,
            "rating_q975": 1167.6628471432282,
            "rating_q025": 1152.7505583764082
        },
        "reka-flash-21b-20240226-online": {
            "rating": 1159.4255384324542,
            "rating_q975": 1171.4411891899067,
            "rating_q025": 1147.4098876750018
        },
        "qwen1.5-72b-chat": {
            "rating": 1158.677194495318,
            "rating_q975": 1167.0988558811293,
            "rating_q025": 1150.2555331095066
        },
        "gemma-2-2b-it": {
            "rating": 1156.3845266899068,
            "rating_q975": 1162.633341004267,
            "rating_q025": 1150.1357123755465
        },
        "reka-flash-21b-20240226": {
            "rating": 1151.6295939172808,
            "rating_q975": 1161.460316052168,
            "rating_q025": 1141.7988717823935
        },
        "llama-3-8b-instruct": {
            "rating": 1147.1280232633776,
            "rating_q975": 1153.6391184960928,
            "rating_q025": 1140.6169280306624
        },
        "wizardlm-70b": {
            "rating": 1143.9238378931807,
            "rating_q975": 1158.7357513261268,
            "rating_q025": 1129.1119244602346
        },
        "yi-1.5-34b-chat": {
            "rating": 1143.06744056461,
            "rating_q975": 1151.8078732769118,
            "rating_q025": 1134.3270078523083
        },
        "gemini-pro-dev-api": {
            "rating": 1142.6669049911827,
            "rating_q975": 1154.4991330725954,
            "rating_q025": 1130.83467690977
        },
        "zephyr-orpo-141b-A35b-v0.1": {
            "rating": 1138.8680277338694,
            "rating_q975": 1156.824455355927,
            "rating_q025": 1120.9116001118118
        },
        "qwq-32b-preview": {
            "rating": 1138.7504800305283,
            "rating_q975": 1159.5137442333073,
            "rating_q025": 1117.9872158277492
        },
        "gpt-3.5-turbo-0125": {
            "rating": 1138.4625674266088,
            "rating_q975": 1145.7169757746185,
            "rating_q025": 1131.208159078599
        },
        "granite-3.1-8b-instruct": {
            "rating": 1137.2645324444234,
            "rating_q975": 1157.6767469789988,
            "rating_q025": 1116.852317909848
        },
        "internlm2_5-20b-chat": {
            "rating": 1135.1068522348583,
            "rating_q975": 1147.1397193294836,
            "rating_q025": 1123.073985140233
        },
        "gemini-pro": {
            "rating": 1126.083804346702,
            "rating_q975": 1145.1053640271332,
            "rating_q025": 1107.0622446662708
        },
        "phi-3-medium-4k-instruct": {
            "rating": 1125.9038696976363,
            "rating_q975": 1134.4005633350475,
            "rating_q025": 1117.407176060225
        },
        "tulu-2-dpo-70b": {
            "rating": 1122.6046470437086,
            "rating_q975": 1139.4470812096163,
            "rating_q025": 1105.762212877801
        },
        "mixtral-8x7b-instruct-v0.1": {
            "rating": 1122.0776633395053,
            "rating_q975": 1129.258130806282,
            "rating_q025": 1114.8971958727286
        },
        "dbrx-instruct-preview": {
            "rating": 1120.9737763738835,
            "rating_q975": 1130.6893073167587,
            "rating_q025": 1111.2582454310084
        },
        "qwen1.5-32b-chat": {
            "rating": 1118.1339075398514,
            "rating_q975": 1128.319178480239,
            "rating_q025": 1107.9486365994637
        },
        "vicuna-33b": {
            "rating": 1118.0402216097457,
            "rating_q975": 1128.1399956058588,
            "rating_q025": 1107.9404476136326
        },
        "yi-34b-chat": {
            "rating": 1115.8358906579629,
            "rating_q975": 1127.1667139753504,
            "rating_q025": 1104.5050673405754
        },
        "openchat-3.5": {
            "rating": 1115.5865676865983,
            "rating_q975": 1131.325077727598,
            "rating_q025": 1099.8480576455986
        },
        "qwen1.5-14b-chat": {
            "rating": 1112.0716437168749,
            "rating_q975": 1123.348818356957,
            "rating_q025": 1100.7944690767927
        },
        "starling-lm-7b-beta": {
            "rating": 1110.7847604121278,
            "rating_q975": 1122.860375205318,
            "rating_q025": 1098.7091456189376
        },
        "deepseek-llm-67b-chat": {
            "rating": 1109.292457307968,
            "rating_q975": 1128.3070838427761,
            "rating_q025": 1090.27783077316
        },
        "falcon-180b-chat": {
            "rating": 1104.416057241262,
            "rating_q975": 1137.2664963785965,
            "rating_q025": 1071.5656181039276
        },
        "openchat-3.5-0106": {
            "rating": 1104.403483986307,
            "rating_q975": 1116.6950065389694,
            "rating_q025": 1092.1119614336446
        },
        "nous-hermes-2-mixtral-8x7b-dpo": {
            "rating": 1104.3013394565933,
            "rating_q975": 1124.4013379727035,
            "rating_q025": 1084.201340940483
        },
        "snowflake-arctic-instruct": {
            "rating": 1100.416205416064,
            "rating_q975": 1110.3646896316293,
            "rating_q025": 1090.4677212004988
        },
        "wizardlm-13b": {
            "rating": 1097.5512383812284,
            "rating_q975": 1113.101213682994,
            "rating_q025": 1082.0012630794627
        },
        "starling-lm-7b-alpha": {
            "rating": 1097.4816319080892,
            "rating_q975": 1110.5281647111615,
            "rating_q025": 1084.435099105017
        },
        "openhermes-2.5-mistral-7b": {
            "rating": 1095.6010978437541,
            "rating_q975": 1114.1781573448877,
            "rating_q025": 1077.0240383426205
        },
        "llama-3.2-3b-instruct": {
            "rating": 1094.8611428265249,
            "rating_q975": 1108.6154550277327,
            "rating_q025": 1081.1068306253171
        },
        "llama2-70b-steerlm-chat": {
            "rating": 1093.6195110842823,
            "rating_q975": 1115.2954397250815,
            "rating_q025": 1071.9435824434831
        },
        "phi-3-small-8k-instruct": {
            "rating": 1093.1013963635326,
            "rating_q975": 1103.0526391283395,
            "rating_q025": 1083.1501535987256
        },
        "llama-2-70b-chat": {
            "rating": 1092.0013264297695,
            "rating_q975": 1100.6149044045146,
            "rating_q025": 1083.3877484550244
        },
        "granite-3.1-2b-instruct": {
            "rating": 1091.2433619760795,
            "rating_q975": 1112.3163090936353,
            "rating_q025": 1070.1704148585238
        },
        "gpt-3.5-turbo-1106": {
            "rating": 1090.196943963719,
            "rating_q975": 1103.8256491734064,
            "rating_q025": 1076.5682387540314
        },
        "solar-10.7b-instruct-v1.0": {
            "rating": 1087.0776401630553,
            "rating_q975": 1108.4915199852867,
            "rating_q025": 1065.663760340824
        },
        "dolphin-2.2.1-mistral-7b": {
            "rating": 1085.1717000619572,
            "rating_q975": 1114.3834847833753,
            "rating_q025": 1055.959915340539
        },
        "zephyr-7b-beta": {
            "rating": 1084.8896986732373,
            "rating_q975": 1098.9800669627612,
            "rating_q025": 1070.7993303837134
        },
        "zephyr-7b-alpha": {
            "rating": 1080.813711682215,
            "rating_q975": 1106.6430055143644,
            "rating_q025": 1054.9844178500655
        },
        "mpt-30b-chat": {
            "rating": 1078.4543500988984,
            "rating_q975": 1101.4814735155167,
            "rating_q025": 1055.4272266822802
        },
        "vicuna-13b": {
            "rating": 1078.1507312237743,
            "rating_q975": 1088.8921592529043,
            "rating_q025": 1067.4093031946443
        },
        "granite-3.0-8b-instruct": {
            "rating": 1078.0344510736684,
            "rating_q975": 1093.2551667643088,
            "rating_q025": 1062.813735383028
        },
        "gemma-1.1-7b-it": {
            "rating": 1072.6370636739816,
            "rating_q975": 1081.830629912406,
            "rating_q025": 1063.4434974355572
        },
        "mistral-7b-instruct-v0.2": {
            "rating": 1072.3554580096607,
            "rating_q975": 1082.8320384725657,
            "rating_q025": 1061.8788775467556
        },
        "guanaco-33b": {
            "rating": 1065.3832481742504,
            "rating_q975": 1088.6315692214253,
            "rating_q025": 1042.1349271270756
        },
        "qwen1.5-7b-chat": {
            "rating": 1063.8005166550836,
            "rating_q975": 1081.6760181519692,
            "rating_q025": 1045.925015158198
        },
        "llama-2-13b-chat": {
            "rating": 1060.8910204579902,
            "rating_q975": 1071.579957156382,
            "rating_q025": 1050.2020837595983
        },
        "phi-3-mini-4k-instruct-june-2024": {
            "rating": 1055.4846594025296,
            "rating_q975": 1066.6639687028999,
            "rating_q025": 1044.3053501021593
        },
        "phi-3-mini-4k-instruct": {
            "rating": 1053.8938560492265,
            "rating_q975": 1064.139450723274,
            "rating_q025": 1043.6482613751791
        },
        "granite-3.0-2b-instruct": {
            "rating": 1049.62320176181,
            "rating_q975": 1064.8011011126907,
            "rating_q025": 1034.4453024109291
        },
        "qwen-14b-chat": {
            "rating": 1049.2172283298457,
            "rating_q975": 1067.507716133335,
            "rating_q025": 1030.9267405263565
        },
        "vicuna-7b": {
            "rating": 1047.7191173606102,
            "rating_q975": 1062.9513272468382,
            "rating_q025": 1032.4869074743822
        },
        "codellama-34b-instruct": {
            "rating": 1047.4208430114822,
            "rating_q975": 1062.057724354451,
            "rating_q025": 1032.7839616685135
        },
        "phi-3-mini-128k-instruct": {
            "rating": 1039.9743944511015,
            "rating_q975": 1051.6155640454872,
            "rating_q025": 1028.3332248567158
        },
        "llama-2-7b-chat": {
            "rating": 1036.821340606184,
            "rating_q975": 1048.3278398648868,
            "rating_q025": 1025.3148413474814
        },
        "stripedhyena-nous-7b": {
            "rating": 1033.9694609096225,
            "rating_q975": 1052.053149492246,
            "rating_q025": 1015.885772326999
        },
        "gemma-7b-it": {
            "rating": 1033.067062208148,
            "rating_q975": 1047.7387854122487,
            "rating_q025": 1018.3953390040471
        },
        "mistral-7b-instruct": {
            "rating": 1029.7555721574913,
            "rating_q975": 1044.9435228714005,
            "rating_q025": 1014.5676214435822
        },
        "llama-3.2-1b-instruct": {
            "rating": 1029.0073139306708,
            "rating_q975": 1043.688416782483,
            "rating_q025": 1014.3262110788586
        },
        "smollm2-1.7b-instruct": {
            "rating": 1025.6553792340017,
            "rating_q975": 1052.3573752395328,
            "rating_q025": 998.9533832284706
        },
        "codellama-70b-instruct": {
            "rating": 1016.4447179679593,
            "rating_q975": 1054.4445185615937,
            "rating_q025": 978.4449173743247
        },
        "palm-2": {
            "rating": 1005.7778022891089,
            "rating_q975": 1021.023293356927,
            "rating_q025": 990.5323112212908
        },
        "gemma-1.1-2b-it": {
            "rating": 1005.5109108121612,
            "rating_q975": 1018.6169186899826,
            "rating_q025": 992.4049029343398
        },
        "olmo-7b-instruct": {
            "rating": 1002.4593363169215,
            "rating_q975": 1020.4565034928041,
            "rating_q025": 984.4621691410389
        },
        "qwen1.5-4b-chat": {
            "rating": 1000.5840910338625,
            "rating_q975": 1015.457446451727,
            "rating_q025": 985.7107356159979
        },
        "koala-13b": {
            "rating": 978.4612475931666,
            "rating_q975": 996.5485093978334,
            "rating_q025": 960.3739857884998
        },
        "gemma-2b-it": {
            "rating": 977.5409944136966,
            "rating_q975": 996.3229344622284,
            "rating_q025": 958.7590543651647
        },
        "chatglm3-6b": {
            "rating": 972.9810425695172,
            "rating_q975": 993.4113813080511,
            "rating_q025": 952.5507038309833
        },
        "gpt4all-13b-snoozy": {
            "rating": 972.2218102920581,
            "rating_q975": 1004.815587396791,
            "rating_q025": 939.6280331873252
        },
        "mpt-7b-chat": {
            "rating": 971.7463975543404,
            "rating_q975": 992.5857191439852,
            "rating_q025": 950.9070759646957
        },
        "alpaca-13b": {
            "rating": 967.1783577802719,
            "rating_q975": 986.8939659021205,
            "rating_q025": 947.4627496584233
        },
        "chatglm2-6b": {
            "rating": 951.8969959115193,
            "rating_q975": 974.8257099675769,
            "rating_q025": 928.9682818554617
        },
        "RWKV-4-Raven-14B": {
            "rating": 933.1084757684357,
            "rating_q975": 952.6518173152156,
            "rating_q025": 913.5651342216559
        },
        "oasst-pythia-12b": {
            "rating": 927.0260769141748,
            "rating_q975": 945.036336073708,
            "rating_q025": 909.0158177546417
        },
        "chatglm-6b": {
            "rating": 924.4032565966088,
            "rating_q975": 944.895970567289,
            "rating_q025": 903.9105426259285
        },
        "fastchat-t5-3b": {
            "rating": 906.5533832437434,
            "rating_q975": 927.7375444276119,
            "rating_q025": 885.3692220598749
        },
        "dolly-v2-12b": {
            "rating": 871.1711647388536,
            "rating_q975": 894.8197290339127,
            "rating_q025": 847.5226004437944
        },
        "stablelm-tuned-alpha-7b": {
            "rating": 866.8433899874622,
            "rating_q975": 891.0880592803159,
            "rating_q025": 842.5987206946085
        },
        "llama-13b": {
            "rating": 808.0065140459901,
            "rating_q975": 836.8473400871438,
            "rating_q025": 779.1656880048364
        }
    },
    "japanese": {
        "gemini-3-pro": {
            "rating": 1479.536282918254,
            "rating_q975": 1525.4025699722972,
            "rating_q025": 1433.669995864211
        },
        "gemini-2.5-pro": {
            "rating": 1469.3875275492642,
            "rating_q975": 1487.0175181650657,
            "rating_q025": 1451.7575369334627
        },
        "gpt-5.1-high": {
            "rating": 1443.3208295514498,
            "rating_q975": 1492.2668471516486,
            "rating_q025": 1394.374811951251
        },
        "grok-4.1-thinking": {
            "rating": 1438.3561459811856,
            "rating_q975": 1484.6060928889015,
            "rating_q025": 1392.1061990734697
        },
        "gpt-5.1": {
            "rating": 1433.605688669828,
            "rating_q975": 1482.5127361725215,
            "rating_q025": 1384.6986411671344
        },
        "grok-4.1": {
            "rating": 1428.0597608525516,
            "rating_q975": 1474.624518352287,
            "rating_q025": 1381.4950033528162
        },
        "gpt-4.5-preview-2025-02-27": {
            "rating": 1418.1202634643976,
            "rating_q975": 1455.9917764234808,
            "rating_q025": 1380.2487505053143
        },
        "o3-2025-04-16": {
            "rating": 1413.188672667356,
            "rating_q975": 1431.0713382761187,
            "rating_q025": 1395.3060070585934
        },
        "glm-4.5": {
            "rating": 1410.3778919389779,
            "rating_q975": 1433.6616859981282,
            "rating_q025": 1387.0940978798276
        },
        "glm-4.6": {
            "rating": 1408.5671265574701,
            "rating_q975": 1450.3775471250365,
            "rating_q025": 1366.7567059899038
        },
        "gpt-5-high": {
            "rating": 1407.9149901723217,
            "rating_q975": 1429.6305645753687,
            "rating_q025": 1386.1994157692748
        },
        "gpt-5-chat": {
            "rating": 1406.1249942832694,
            "rating_q975": 1435.3972411303973,
            "rating_q025": 1376.8527474361415
        },
        "chatgpt-4o-latest-20250326": {
            "rating": 1405.5834653953266,
            "rating_q975": 1425.3614527949046,
            "rating_q025": 1385.8054779957486
        },
        "qwen3-max-preview": {
            "rating": 1396.5730951504197,
            "rating_q975": 1427.3096381525052,
            "rating_q025": 1365.8365521483342
        },
        "gemini-2.5-flash-preview-09-2025": {
            "rating": 1395.9955949624784,
            "rating_q975": 1433.262854954507,
            "rating_q025": 1358.7283349704499
        },
        "gemini-2.5-flash": {
            "rating": 1395.8078662245118,
            "rating_q975": 1412.4070065828644,
            "rating_q025": 1379.2087258661593
        },
        "grok-3-preview-02-24": {
            "rating": 1393.347434917399,
            "rating_q975": 1414.0552787194822,
            "rating_q025": 1372.6395911153156
        },
        "kimi-k2-thinking-turbo": {
            "rating": 1390.0251916491372,
            "rating_q975": 1440.5894010265285,
            "rating_q025": 1339.460982271746
        },
        "grok-4-0709": {
            "rating": 1388.9861936464363,
            "rating_q975": 1409.2493106604206,
            "rating_q025": 1368.723076632452
        },
        "mistral-medium-2508": {
            "rating": 1387.1839938636451,
            "rating_q975": 1412.2001581077607,
            "rating_q025": 1362.1678296195296
        },
        "qwen3-235b-a22b-instruct-2507": {
            "rating": 1386.8089281485682,
            "rating_q975": 1406.7330023336715,
            "rating_q025": 1366.8848539634648
        },
        "qwen3-next-80b-a3b-instruct": {
            "rating": 1384.809853014386,
            "rating_q975": 1419.9034954367603,
            "rating_q025": 1349.7162105920115
        },
        "gemini-2.5-flash-lite-preview-09-2025-no-thinking": {
            "rating": 1381.6286843043686,
            "rating_q975": 1419.727832660437,
            "rating_q025": 1343.5295359483002
        },
        "deepseek-r1-0528": {
            "rating": 1377.0891224398101,
            "rating_q975": 1402.197753243499,
            "rating_q025": 1351.9804916361213
        },
        "claude-opus-4-1-20250805-thinking-16k": {
            "rating": 1373.4156527016366,
            "rating_q975": 1399.3315646826202,
            "rating_q025": 1347.499740720653
        },
        "qwen3-235b-a22b-thinking-2507": {
            "rating": 1373.3406456485877,
            "rating_q975": 1402.3204506929937,
            "rating_q025": 1344.3608406041817
        },
        "claude-opus-4-1-20250805": {
            "rating": 1371.1802305148065,
            "rating_q975": 1392.468108352228,
            "rating_q025": 1349.892352677385
        },
        "qwen3-235b-a22b-no-thinking": {
            "rating": 1368.2777985025289,
            "rating_q975": 1388.9681648773155,
            "rating_q025": 1347.5874321277422
        },
        "deepseek-v3.1": {
            "rating": 1364.7538265914952,
            "rating_q975": 1397.4232939733583,
            "rating_q025": 1332.084359209632
        },
        "deepseek-v3.1-thinking": {
            "rating": 1361.1815322023392,
            "rating_q975": 1397.874270656195,
            "rating_q025": 1324.4887937484834
        },
        "claude-sonnet-4-5-20250929": {
            "rating": 1359.7190971642087,
            "rating_q975": 1400.5292853294102,
            "rating_q025": 1318.9089089990073
        },
        "mai-1-preview": {
            "rating": 1357.181834180278,
            "rating_q975": 1391.9881984854467,
            "rating_q025": 1322.3754698751093
        },
        "gpt-5-mini-high": {
            "rating": 1357.097715173365,
            "rating_q975": 1387.8589361105114,
            "rating_q025": 1326.3364942362186
        },
        "grok-4-fast-reasoning": {
            "rating": 1356.3649405555796,
            "rating_q975": 1400.1722550070701,
            "rating_q025": 1312.557626104089
        },
        "gemini-2.5-flash-lite-preview-06-17-thinking": {
            "rating": 1354.2083204750188,
            "rating_q975": 1375.76773903272,
            "rating_q025": 1332.6489019173175
        },
        "o1-2024-12-17": {
            "rating": 1351.4442117964127,
            "rating_q975": 1376.6560668655861,
            "rating_q025": 1326.2323567272392
        },
        "glm-4.5-air": {
            "rating": 1343.6639703559608,
            "rating_q975": 1364.8246082804528,
            "rating_q025": 1322.5033324314688
        },
        "claude-sonnet-4-5-20250929-thinking-32k": {
            "rating": 1342.3328899764,
            "rating_q975": 1378.647845415228,
            "rating_q025": 1306.0179345375723
        },
        "qwen3-30b-a3b-instruct-2507": {
            "rating": 1342.2090163596972,
            "rating_q975": 1365.4964151676845,
            "rating_q025": 1318.92161755171
        },
        "hunyuan-turbos-20250416": {
            "rating": 1340.8893317975596,
            "rating_q975": 1372.8781907167927,
            "rating_q025": 1308.9004728783266
        },
        "claude-haiku-4-5-20251001": {
            "rating": 1337.7926640857422,
            "rating_q975": 1379.7939130407797,
            "rating_q025": 1295.7914151307048
        },
        "kimi-k2-0711-preview": {
            "rating": 1337.6915082161647,
            "rating_q975": 1357.5743175728344,
            "rating_q025": 1317.808698859495
        },
        "grok-3-mini-beta": {
            "rating": 1337.114016951245,
            "rating_q975": 1361.042748421162,
            "rating_q025": 1313.185285481328
        },
        "kimi-k2-0905-preview": {
            "rating": 1330.9301430792336,
            "rating_q975": 1374.8793433601998,
            "rating_q025": 1286.9809427982675
        },
        "claude-opus-4-20250514-thinking-16k": {
            "rating": 1330.7720818874266,
            "rating_q975": 1352.701672370305,
            "rating_q025": 1308.8424914045481
        },
        "deepseek-r1": {
            "rating": 1329.0962227237717,
            "rating_q975": 1354.3890878723605,
            "rating_q025": 1303.8033575751829
        },
        "deepseek-v3-0324": {
            "rating": 1328.6721053188523,
            "rating_q975": 1347.7256714743326,
            "rating_q025": 1309.6185391633721
        },
        "claude-opus-4-20250514": {
            "rating": 1326.8151777432329,
            "rating_q975": 1345.9532986363768,
            "rating_q025": 1307.677056850089
        },
        "gpt-4.1-2025-04-14": {
            "rating": 1322.9687751832237,
            "rating_q975": 1341.940539148132,
            "rating_q025": 1303.9970112183153
        },
        "gpt-oss-120b": {
            "rating": 1321.806153193562,
            "rating_q975": 1348.9189720823697,
            "rating_q025": 1294.6933343047544
        },
        "grok-3-mini-high": {
            "rating": 1319.756452309815,
            "rating_q975": 1346.9695557167688,
            "rating_q025": 1292.543348902861
        },
        "qwen3-coder-480b-a35b-instruct": {
            "rating": 1313.8667369610507,
            "rating_q975": 1334.2133795659065,
            "rating_q025": 1293.520094356195
        },
        "mistral-medium-2505": {
            "rating": 1310.8928562833426,
            "rating_q975": 1331.2121193830667,
            "rating_q025": 1290.5735931836184
        },
        "deepseek-v3.2-exp": {
            "rating": 1309.0505822308517,
            "rating_q975": 1367.4326726631857,
            "rating_q025": 1250.6684917985176
        },
        "qwen2.5-max": {
            "rating": 1308.9105172558993,
            "rating_q975": 1330.1386284692414,
            "rating_q025": 1287.6824060425572
        },
        "qwen3-235b-a22b": {
            "rating": 1308.6560466102967,
            "rating_q975": 1331.2666628049478,
            "rating_q025": 1286.0454304156456
        },
        "o4-mini-2025-04-16": {
            "rating": 1308.5978103196592,
            "rating_q975": 1327.7642658046489,
            "rating_q025": 1289.4313548346695
        },
        "gemini-2.0-flash-lite-preview-02-05": {
            "rating": 1308.24739998353,
            "rating_q975": 1332.3529834856597,
            "rating_q025": 1284.1418164814002
        },
        "o1-preview": {
            "rating": 1304.2772272856791,
            "rating_q975": 1327.2696924806237,
            "rating_q025": 1281.2847620907346
        },
        "gemini-1.5-pro-002": {
            "rating": 1298.5978239162266,
            "rating_q975": 1315.0196361741594,
            "rating_q025": 1282.1760116582939
        },
        "gemini-2.0-flash-001": {
            "rating": 1298.2097267784375,
            "rating_q975": 1316.5056855346581,
            "rating_q025": 1279.9137680222168
        },
        "command-a-03-2025": {
            "rating": 1293.9998201741487,
            "rating_q975": 1312.1260749198211,
            "rating_q025": 1275.8735654284762
        },
        "gemma-3-27b-it": {
            "rating": 1291.8087569112524,
            "rating_q975": 1310.949146634768,
            "rating_q025": 1272.6683671877367
        },
        "longcat-flash-chat": {
            "rating": 1291.0742659923328,
            "rating_q975": 1336.5054892337723,
            "rating_q025": 1245.6430427508933
        },
        "claude-sonnet-4-20250514": {
            "rating": 1288.1801784278323,
            "rating_q975": 1308.2900878390888,
            "rating_q025": 1268.0702690165758
        },
        "o3-mini-high": {
            "rating": 1287.708559869959,
            "rating_q975": 1317.4060893520773,
            "rating_q025": 1258.0110303878405
        },
        "gpt-4.1-mini-2025-04-14": {
            "rating": 1287.40426828612,
            "rating_q975": 1307.0239896223288,
            "rating_q025": 1267.7845469499111
        },
        "nvidia-llama-3.3-nemotron-super-49b-v1.5": {
            "rating": 1286.9065637216481,
            "rating_q975": 1316.6283055745919,
            "rating_q025": 1257.1848218687044
        },
        "mistral-small-2506": {
            "rating": 1285.6050152895273,
            "rating_q975": 1310.9179865581946,
            "rating_q025": 1260.29204402086
        },
        "claude-sonnet-4-20250514-thinking-32k": {
            "rating": 1283.5372163313734,
            "rating_q975": 1305.8564720244833,
            "rating_q025": 1261.2179606382635
        },
        "gemma-3n-e4b-it": {
            "rating": 1277.9790421681848,
            "rating_q975": 1300.547089523704,
            "rating_q025": 1255.4109948126656
        },
        "step-1o-turbo-202506": {
            "rating": 1277.5113595805437,
            "rating_q975": 1319.3951570656222,
            "rating_q025": 1235.6275620954652
        },
        "deepseek-v3": {
            "rating": 1274.3006422175451,
            "rating_q975": 1297.1527805729872,
            "rating_q025": 1251.448503862103
        },
        "qwen3-next-80b-a3b-thinking": {
            "rating": 1272.1867976572976,
            "rating_q975": 1315.572066813142,
            "rating_q025": 1228.801528501453
        },
        "claude-3-7-sonnet-20250219-thinking-32k": {
            "rating": 1270.8814322983621,
            "rating_q975": 1290.3718724427795,
            "rating_q025": 1251.3909921539448
        },
        "o3-mini": {
            "rating": 1270.5924980032241,
            "rating_q975": 1286.633507491028,
            "rating_q025": 1254.5514885154203
        },
        "claude-3-7-sonnet-20250219": {
            "rating": 1268.6454608753982,
            "rating_q975": 1287.9097705934632,
            "rating_q025": 1249.381151157333
        },
        "gpt-4o-2024-05-13": {
            "rating": 1263.3940912438634,
            "rating_q975": 1276.843957425242,
            "rating_q025": 1249.9442250624847
        },
        "gemini-1.5-flash-002": {
            "rating": 1261.7036499166666,
            "rating_q975": 1282.3569991719687,
            "rating_q025": 1241.0503006613644
        },
        "qwq-32b": {
            "rating": 1256.2578432344294,
            "rating_q975": 1281.1399853175922,
            "rating_q025": 1231.3757011512666
        },
        "qwen3-30b-a3b": {
            "rating": 1256.2470729382558,
            "rating_q975": 1278.6125473910226,
            "rating_q025": 1233.881598485489
        },
        "qwen-plus-0125": {
            "rating": 1255.372984312579,
            "rating_q975": 1293.807080322026,
            "rating_q025": 1216.9388883031322
        },
        "gpt-oss-20b": {
            "rating": 1252.8517511116247,
            "rating_q975": 1293.2730463682387,
            "rating_q025": 1212.4304558550107
        },
        "o1-mini": {
            "rating": 1252.3383032303582,
            "rating_q975": 1269.450594879318,
            "rating_q025": 1235.2260115813983
        },
        "grok-2-2024-08-13": {
            "rating": 1251.725556739735,
            "rating_q975": 1266.8128558862677,
            "rating_q025": 1236.6382575932025
        },
        "gemini-advanced-0514": {
            "rating": 1247.4490199814868,
            "rating_q975": 1266.9432790497174,
            "rating_q025": 1227.9547609132562
        },
        "gemini-1.5-pro-001": {
            "rating": 1245.6201628189692,
            "rating_q975": 1261.0497026299572,
            "rating_q025": 1230.1906230079812
        },
        "gpt-4o-2024-08-06": {
            "rating": 1240.7691267017162,
            "rating_q975": 1258.1648178926102,
            "rating_q025": 1223.3734355108222
        },
        "claude-3-5-sonnet-20241022": {
            "rating": 1238.7805555446942,
            "rating_q975": 1251.6530220540365,
            "rating_q025": 1225.9080890353518
        },
        "yi-lightning": {
            "rating": 1237.0788911784605,
            "rating_q975": 1259.9205188353158,
            "rating_q025": 1214.2372635216052
        },
        "claude-3-5-sonnet-20240620": {
            "rating": 1236.8578868241634,
            "rating_q975": 1251.2259771366855,
            "rating_q025": 1222.4897965116413
        },
        "glm-4-plus-0111": {
            "rating": 1235.5406759717434,
            "rating_q975": 1273.0492009909583,
            "rating_q025": 1198.0321509525286
        },
        "deepseek-v2.5-1210": {
            "rating": 1232.4504658266212,
            "rating_q975": 1272.8764860548795,
            "rating_q025": 1192.024445598363
        },
        "gpt-4o-mini-2024-07-18": {
            "rating": 1221.9863179974545,
            "rating_q975": 1235.5878220212685,
            "rating_q025": 1208.3848139736406
        },
        "athene-v2-chat": {
            "rating": 1221.9850753553978,
            "rating_q975": 1244.2192166508107,
            "rating_q025": 1199.750934059985
        },
        "minimax-m1": {
            "rating": 1221.788363385879,
            "rating_q975": 1243.514235688917,
            "rating_q025": 1200.0624910828408
        },
        "grok-2-mini-2024-08-13": {
            "rating": 1219.5954190808204,
            "rating_q975": 1235.985162296244,
            "rating_q025": 1203.2056758653969
        },
        "glm-4-plus": {
            "rating": 1216.251562109714,
            "rating_q975": 1242.063061459216,
            "rating_q025": 1190.4400627602122
        },
        "gpt-4-1106-preview": {
            "rating": 1215.6146837459592,
            "rating_q975": 1232.6615249710323,
            "rating_q025": 1198.567842520886
        },
        "mistral-small-3.1-24b-instruct-2503": {
            "rating": 1215.413887136481,
            "rating_q975": 1237.543726086806,
            "rating_q025": 1193.284048186156
        },
        "llama-3.1-405b-instruct-bf16": {
            "rating": 1213.919486242222,
            "rating_q975": 1233.300396715627,
            "rating_q025": 1194.5385757688173
        },
        "qwen2.5-plus-1127": {
            "rating": 1212.869133150648,
            "rating_q975": 1244.5033004601714,
            "rating_q025": 1181.2349658411244
        },
        "qwen-max-0919": {
            "rating": 1211.9762669437441,
            "rating_q975": 1243.7317571328472,
            "rating_q025": 1180.220776754641
        },
        "llama-4-scout-17b-16e-instruct": {
            "rating": 1211.8648461040896,
            "rating_q975": 1234.0393595122089,
            "rating_q025": 1189.6903326959703
        },
        "llama-4-maverick-17b-128e-instruct": {
            "rating": 1211.681384497151,
            "rating_q975": 1232.9904589888524,
            "rating_q025": 1190.3723100054494
        },
        "claude-3-opus-20240229": {
            "rating": 1209.9241697667062,
            "rating_q975": 1222.1426548016452,
            "rating_q025": 1197.7056847317672
        },
        "amazon-nova-pro-v1.0": {
            "rating": 1205.828238533983,
            "rating_q975": 1230.7163190893946,
            "rating_q025": 1180.9401579785715
        },
        "gpt-4.1-nano-2025-04-14": {
            "rating": 1203.4545079393165,
            "rating_q975": 1248.3318671060624,
            "rating_q025": 1158.5771487725706
        },
        "gpt-4-0125-preview": {
            "rating": 1202.0936441240506,
            "rating_q975": 1219.0651640204937,
            "rating_q025": 1185.1221242276074
        },
        "gpt-4-turbo-2024-04-09": {
            "rating": 1201.0431009808244,
            "rating_q975": 1215.7861087335593,
            "rating_q025": 1186.3000932280895
        },
        "deepseek-v2.5": {
            "rating": 1198.01360442073,
            "rating_q975": 1223.44470346553,
            "rating_q025": 1172.58250537593
        },
        "gemini-1.5-flash-001": {
            "rating": 1192.7215501916394,
            "rating_q975": 1209.1800053279633,
            "rating_q025": 1176.2630950553155
        },
        "mistral-large-2407": {
            "rating": 1191.8369884953295,
            "rating_q975": 1208.0582534765908,
            "rating_q025": 1175.6157235140681
        },
        "magistral-medium-2506": {
            "rating": 1189.6219004374532,
            "rating_q975": 1222.9926663461417,
            "rating_q025": 1156.2511345287646
        },
        "qwen2.5-72b-instruct": {
            "rating": 1186.1409209215026,
            "rating_q975": 1206.0600171200351,
            "rating_q025": 1166.22182472297
        },
        "claude-3-5-haiku-20241022": {
            "rating": 1185.1518233287761,
            "rating_q975": 1200.8412471073425,
            "rating_q025": 1169.4623995502097
        },
        "gemma-2-27b-it": {
            "rating": 1182.8440104039196,
            "rating_q975": 1196.943804112145,
            "rating_q025": 1168.7442166956941
        },
        "llama-3.1-405b-instruct-fp8": {
            "rating": 1177.5889048548934,
            "rating_q975": 1192.5420186501876,
            "rating_q025": 1162.6357910595991
        },
        "mistral-large-2411": {
            "rating": 1175.4085547648638,
            "rating_q975": 1197.0203053733644,
            "rating_q025": 1153.7968041563631
        },
        "command-r-plus-08-2024": {
            "rating": 1173.295198600859,
            "rating_q975": 1210.4734940168673,
            "rating_q025": 1136.1169031848508
        },
        "c4ai-aya-expanse-32b": {
            "rating": 1172.2635389496563,
            "rating_q975": 1193.9733149545054,
            "rating_q025": 1150.5537629448072
        },
        "phi-4": {
            "rating": 1164.3614920224477,
            "rating_q975": 1190.2212499827856,
            "rating_q025": 1138.5017340621098
        },
        "command-r-plus": {
            "rating": 1161.238220418425,
            "rating_q975": 1178.8993176549006,
            "rating_q025": 1143.5771231819494
        },
        "llama-3.3-70b-instruct": {
            "rating": 1159.046119844719,
            "rating_q975": 1176.448615938253,
            "rating_q025": 1141.643623751185
        },
        "amazon-nova-micro-v1.0": {
            "rating": 1158.7617803415426,
            "rating_q975": 1185.2101629325862,
            "rating_q025": 1132.313397750499
        },
        "amazon-nova-lite-v1.0": {
            "rating": 1158.2546507563643,
            "rating_q975": 1185.0773769753603,
            "rating_q025": 1131.4319245373683
        },
        "gemini-1.5-flash-8b-001": {
            "rating": 1157.231241965726,
            "rating_q975": 1178.4866917714435,
            "rating_q025": 1135.9757921600085
        },
        "gemma-2-9b-it": {
            "rating": 1150.9764524314855,
            "rating_q975": 1167.0124152403446,
            "rating_q025": 1134.9404896226265
        },
        "command-r-08-2024": {
            "rating": 1150.2627890187296,
            "rating_q975": 1182.8042387743894,
            "rating_q025": 1117.7213392630697
        },
        "gemma-2-9b-it-simpo": {
            "rating": 1146.3626819320557,
            "rating_q975": 1177.9336324082653,
            "rating_q025": 1114.791731455846
        },
        "athene-70b-0725": {
            "rating": 1144.3196423195877,
            "rating_q975": 1166.2363638879915,
            "rating_q025": 1122.402920751184
        },
        "gpt-4-0314": {
            "rating": 1143.3806529352596,
            "rating_q975": 1168.1328131015498,
            "rating_q025": 1118.6284927689694
        },
        "llama-3.1-70b-instruct": {
            "rating": 1139.9222980728678,
            "rating_q975": 1155.3273775840114,
            "rating_q025": 1124.5172185617241
        },
        "claude-3-sonnet-20240229": {
            "rating": 1138.9388972615754,
            "rating_q975": 1155.4651373262116,
            "rating_q025": 1122.4126571969393
        },
        "nemotron-4-340b-instruct": {
            "rating": 1134.7550150135185,
            "rating_q975": 1162.9859215979143,
            "rating_q025": 1106.5241084291226
        },
        "deepseek-coder-v2": {
            "rating": 1134.4375439663854,
            "rating_q975": 1165.693723587584,
            "rating_q025": 1103.181364345187
        },
        "c4ai-aya-expanse-8b": {
            "rating": 1130.2565080332474,
            "rating_q975": 1164.2161870846548,
            "rating_q025": 1096.29682898184
        },
        "jamba-1.5-large": {
            "rating": 1124.7010095468659,
            "rating_q975": 1160.407338320997,
            "rating_q025": 1088.9946807727347
        },
        "gpt-4-0613": {
            "rating": 1120.6475333051949,
            "rating_q975": 1138.9597150475447,
            "rating_q025": 1102.335351562845
        },
        "qwen2-72b-instruct": {
            "rating": 1117.899113474767,
            "rating_q975": 1137.678044129316,
            "rating_q025": 1098.1201828202181
        },
        "mistral-small-24b-instruct-2501": {
            "rating": 1116.4662464302369,
            "rating_q975": 1151.9334288941175,
            "rating_q025": 1080.9990639663563
        },
        "claude-3-haiku-20240307": {
            "rating": 1109.4753565577455,
            "rating_q975": 1124.500746409344,
            "rating_q025": 1094.449966706147
        },
        "command-r": {
            "rating": 1099.756339506639,
            "rating_q975": 1121.0652755593992,
            "rating_q025": 1078.447403453879
        },
        "gemma-2-2b-it": {
            "rating": 1091.0154025846573,
            "rating_q975": 1108.0615378133245,
            "rating_q025": 1073.96926735599
        },
        "reka-flash-21b-20240226-online": {
            "rating": 1080.7211125471392,
            "rating_q975": 1115.0285828242772,
            "rating_q025": 1046.4136422700012
        },
        "qwen1.5-110b-chat": {
            "rating": 1079.763666835684,
            "rating_q975": 1105.389357887367,
            "rating_q025": 1054.1379757840011
        },
        "llama-3.1-8b-instruct": {
            "rating": 1068.3399177009358,
            "rating_q975": 1085.9906151282617,
            "rating_q025": 1050.6892202736099
        },
        "qwen1.5-72b-chat": {
            "rating": 1065.4865143153108,
            "rating_q975": 1092.4627658887207,
            "rating_q025": 1038.510262741901
        },
        "reka-flash-21b-20240226": {
            "rating": 1056.6430175969126,
            "rating_q975": 1084.7255219794158,
            "rating_q025": 1028.5605132144094
        },
        "gpt-3.5-turbo-0125": {
            "rating": 1050.8460700683,
            "rating_q975": 1071.4634271774007,
            "rating_q025": 1030.2287129591991
        },
        "phi-3-medium-4k-instruct": {
            "rating": 1048.4117817065724,
            "rating_q975": 1071.3981311056104,
            "rating_q025": 1025.4254323075343
        },
        "mixtral-8x22b-instruct-v0.1": {
            "rating": 1042.4415524367225,
            "rating_q975": 1062.471385563367,
            "rating_q025": 1022.411719310078
        },
        "qwen1.5-32b-chat": {
            "rating": 1034.5427883159612,
            "rating_q975": 1067.4052139516712,
            "rating_q025": 1001.6803626802513
        },
        "gemini-pro-dev-api": {
            "rating": 1029.566224607019,
            "rating_q975": 1073.9625511826503,
            "rating_q025": 985.1698980313877
        },
        "yi-1.5-34b-chat": {
            "rating": 1028.2401159656288,
            "rating_q975": 1055.0950405105336,
            "rating_q025": 1001.385191420724
        },
        "qwen1.5-14b-chat": {
            "rating": 1027.8320504143505,
            "rating_q975": 1067.0758774076235,
            "rating_q025": 988.5882234210775
        },
        "jamba-1.5-mini": {
            "rating": 1026.8674250809572,
            "rating_q975": 1061.5390997641264,
            "rating_q025": 992.1957503977882
        },
        "llama-3-70b-instruct": {
            "rating": 1024.1610531668953,
            "rating_q975": 1038.1451137029337,
            "rating_q025": 1010.1769926308567
        },
        "mistral-medium": {
            "rating": 1020.084958969878,
            "rating_q975": 1053.0095852778672,
            "rating_q025": 987.1603326618887
        },
        "mistral-large-2402": {
            "rating": 1015.7839642995273,
            "rating_q975": 1037.1769642221393,
            "rating_q025": 994.3909643769152
        },
        "yi-34b-chat": {
            "rating": 1005.843650142325,
            "rating_q975": 1048.5594680465547,
            "rating_q025": 963.1278322380954
        },
        "starling-lm-7b-beta": {
            "rating": 1005.3900092206651,
            "rating_q975": 1048.59197146574,
            "rating_q025": 962.18804697559
        },
        "dbrx-instruct-preview": {
            "rating": 996.3280958266876,
            "rating_q975": 1025.9327853051227,
            "rating_q025": 966.7234063482524
        },
        "gemma-1.1-7b-it": {
            "rating": 976.9575269497841,
            "rating_q975": 1006.0918353901939,
            "rating_q025": 947.8232185093743
        },
        "snowflake-arctic-instruct": {
            "rating": 976.4545810832922,
            "rating_q975": 1000.5662017247857,
            "rating_q025": 952.3429604417986
        },
        "llama-3-8b-instruct": {
            "rating": 974.0693648811651,
            "rating_q975": 990.5561480281062,
            "rating_q025": 957.582581734224
        },
        "phi-3-small-8k-instruct": {
            "rating": 972.3069617780391,
            "rating_q975": 1003.0241169492795,
            "rating_q025": 941.5898066067987
        },
        "vicuna-33b": {
            "rating": 964.3175150580862,
            "rating_q975": 1005.7401594710178,
            "rating_q025": 922.8948706451546
        },
        "phi-3-mini-4k-instruct-june-2024": {
            "rating": 964.0490662100101,
            "rating_q975": 996.0993374634663,
            "rating_q025": 931.9987949565539
        },
        "phi-3-mini-4k-instruct": {
            "rating": 940.7059826693433,
            "rating_q975": 973.9230627603497,
            "rating_q025": 907.4889025783368
        },
        "mixtral-8x7b-instruct-v0.1": {
            "rating": 938.4462313362924,
            "rating_q975": 959.7652269365624,
            "rating_q025": 917.1272357360224
        },
        "llama-2-70b-chat": {
            "rating": 934.9676056963851,
            "rating_q975": 967.4325508815558,
            "rating_q025": 902.5026605112145
        },
        "vicuna-13b": {
            "rating": 925.3931413102774,
            "rating_q975": 977.2262734419978,
            "rating_q025": 873.560009178557
        },
        "phi-3-mini-128k-instruct": {
            "rating": 905.759174099876,
            "rating_q975": 936.6940403814654,
            "rating_q025": 874.8243078182866
        },
        "llama-2-13b-chat": {
            "rating": 901.0293071981921,
            "rating_q975": 950.1419114522346,
            "rating_q025": 851.9167029441496
        },
        "mistral-7b-instruct-v0.2": {
            "rating": 885.0376960302949,
            "rating_q975": 931.0446052905788,
            "rating_q025": 839.030786770011
        }
    },
    "korean": {
        "gemini-3-pro": {
            "rating": 1466.2634668723863,
            "rating_q975": 1509.906194693508,
            "rating_q025": 1422.6207390512645
        },
        "gemini-2.5-pro": {
            "rating": 1448.4189215686129,
            "rating_q975": 1466.0193748640638,
            "rating_q025": 1430.818468273162
        },
        "gpt-5.1": {
            "rating": 1447.4470961578272,
            "rating_q975": 1490.3328955568006,
            "rating_q025": 1404.5612967588538
        },
        "claude-opus-4-5-20251101": {
            "rating": 1417.1792447268685,
            "rating_q975": 1468.1954065661469,
            "rating_q025": 1366.1630828875902
        },
        "gpt-5.1-high": {
            "rating": 1413.2943682327414,
            "rating_q975": 1453.7166949988566,
            "rating_q025": 1372.8720414666261
        },
        "grok-4.1-thinking": {
            "rating": 1409.6827944218676,
            "rating_q975": 1448.1552541269061,
            "rating_q025": 1371.210334716829
        },
        "chatgpt-4o-latest-20250326": {
            "rating": 1404.6200847408238,
            "rating_q975": 1424.7717578775828,
            "rating_q025": 1384.4684116040648
        },
        "hunyuan-t1-20250711": {
            "rating": 1395.7762628918706,
            "rating_q975": 1439.8574956418547,
            "rating_q025": 1351.6950301418865
        },
        "o1-2024-12-17": {
            "rating": 1394.0159733090243,
            "rating_q975": 1424.239382320235,
            "rating_q025": 1363.7925642978134
        },
        "glm-4.6": {
            "rating": 1393.116587737381,
            "rating_q975": 1426.006237212246,
            "rating_q025": 1360.226938262516
        },
        "qwen3-vl-235b-a22b-instruct": {
            "rating": 1389.1795937235333,
            "rating_q975": 1427.2513672652344,
            "rating_q025": 1351.1078201818323
        },
        "gpt-4.5-preview-2025-02-27": {
            "rating": 1388.958442605299,
            "rating_q975": 1431.5287702235682,
            "rating_q025": 1346.38811498703
        },
        "gemini-2.5-flash-preview-09-2025": {
            "rating": 1387.6378891428867,
            "rating_q975": 1414.8645377542146,
            "rating_q025": 1360.4112405315589
        },
        "grok-4.1": {
            "rating": 1386.2716389611362,
            "rating_q975": 1425.40814249502,
            "rating_q025": 1347.1351354272524
        },
        "qwen3-235b-a22b-instruct-2507": {
            "rating": 1385.8353282172297,
            "rating_q975": 1406.6368332579284,
            "rating_q025": 1365.033823176531
        },
        "qwen3-max-preview": {
            "rating": 1384.4246586988595,
            "rating_q975": 1408.7401823700616,
            "rating_q025": 1360.1091350276574
        },
        "gemini-2.5-flash": {
            "rating": 1381.3895840097432,
            "rating_q975": 1399.0858477841268,
            "rating_q025": 1363.6933202353596
        },
        "glm-4.5": {
            "rating": 1380.3805510188377,
            "rating_q975": 1405.4070135142545,
            "rating_q025": 1355.3540885234208
        },
        "claude-opus-4-1-20250805-thinking-16k": {
            "rating": 1377.2821493157726,
            "rating_q975": 1398.804134645025,
            "rating_q025": 1355.7601639865202
        },
        "claude-sonnet-4-5-20250929": {
            "rating": 1374.3456424426115,
            "rating_q975": 1408.651145052796,
            "rating_q025": 1340.040139832427
        },
        "mistral-medium-2508": {
            "rating": 1372.486457810281,
            "rating_q975": 1392.0396257366665,
            "rating_q025": 1352.9332898838957
        },
        "claude-opus-4-5-20251101-thinking-32k": {
            "rating": 1372.155263054779,
            "rating_q975": 1425.023962080493,
            "rating_q025": 1319.286564029065
        },
        "grok-4-0709": {
            "rating": 1370.744860343251,
            "rating_q975": 1392.5968079127847,
            "rating_q025": 1348.8929127737174
        },
        "claude-sonnet-4-5-20250929-thinking-32k": {
            "rating": 1368.2466212865847,
            "rating_q975": 1398.4147543128245,
            "rating_q025": 1338.078488260345
        },
        "grok-3-preview-02-24": {
            "rating": 1365.085545866842,
            "rating_q975": 1392.0993637579093,
            "rating_q025": 1338.0717279757748
        },
        "qwen3-235b-a22b-no-thinking": {
            "rating": 1364.48847290953,
            "rating_q975": 1388.2578915094093,
            "rating_q025": 1340.7190543096506
        },
        "gpt-5-high": {
            "rating": 1364.0024271832306,
            "rating_q975": 1386.9191531380968,
            "rating_q025": 1341.0857012283643
        },
        "qwen3-max-2025-09-23": {
            "rating": 1360.2937354102903,
            "rating_q975": 1398.2022590942183,
            "rating_q025": 1322.3852117263623
        },
        "qwen3-vl-235b-a22b-thinking": {
            "rating": 1360.1635486864225,
            "rating_q975": 1400.9724703766642,
            "rating_q025": 1319.3546269961807
        },
        "gpt-5-chat": {
            "rating": 1358.6396535185308,
            "rating_q975": 1381.3855220202854,
            "rating_q025": 1335.8937850167763
        },
        "o3-2025-04-16": {
            "rating": 1358.2256372803786,
            "rating_q975": 1377.219837304304,
            "rating_q025": 1339.231437256453
        },
        "qwen3-235b-a22b-thinking-2507": {
            "rating": 1357.5343338085318,
            "rating_q975": 1399.6337975993983,
            "rating_q025": 1315.4348700176652
        },
        "claude-opus-4-1-20250805": {
            "rating": 1357.4722317567348,
            "rating_q975": 1376.8391232467452,
            "rating_q025": 1338.1053402667244
        },
        "longcat-flash-chat": {
            "rating": 1355.106135294419,
            "rating_q975": 1389.9757043793368,
            "rating_q025": 1320.236566209501
        },
        "qwen3-next-80b-a3b-instruct": {
            "rating": 1354.6192746368972,
            "rating_q975": 1383.6304723592034,
            "rating_q025": 1325.608076914591
        },
        "gemini-2.5-flash-lite-preview-06-17-thinking": {
            "rating": 1352.1455208855302,
            "rating_q975": 1375.7137470042312,
            "rating_q025": 1328.5772947668293
        },
        "hunyuan-turbos-20250416": {
            "rating": 1349.2514413538734,
            "rating_q975": 1399.9676983493175,
            "rating_q025": 1298.5351843584292
        },
        "grok-4-fast-reasoning": {
            "rating": 1349.0415965735617,
            "rating_q975": 1382.546055065257,
            "rating_q025": 1315.5371380818665
        },
        "gemini-2.5-flash-lite-preview-09-2025-no-thinking": {
            "rating": 1348.6825659430976,
            "rating_q975": 1377.414177837686,
            "rating_q025": 1319.9509540485092
        },
        "gpt-4.1-2025-04-14": {
            "rating": 1348.2396885888788,
            "rating_q975": 1368.1494566328788,
            "rating_q025": 1328.3299205448789
        },
        "deepseek-r1-0528": {
            "rating": 1340.9298133537054,
            "rating_q975": 1376.157773589198,
            "rating_q025": 1305.7018531182127
        },
        "mai-1-preview": {
            "rating": 1339.7623576526642,
            "rating_q975": 1367.3397391687024,
            "rating_q025": 1312.184976136626
        },
        "amazon-nova-experimental-chat-10-09": {
            "rating": 1339.3715297881445,
            "rating_q975": 1390.1494610851737,
            "rating_q025": 1288.5935984911152
        },
        "grok-3-mini-high": {
            "rating": 1337.3596584817437,
            "rating_q975": 1371.1876442013208,
            "rating_q025": 1303.5316727621666
        },
        "deepseek-v3.2-exp-thinking": {
            "rating": 1337.2924967316696,
            "rating_q975": 1381.9167510731022,
            "rating_q025": 1292.668242390237
        },
        "ling-flash-2.0": {
            "rating": 1334.1031929255778,
            "rating_q975": 1373.9317798779837,
            "rating_q025": 1294.274605973172
        },
        "deepseek-v3.2-exp": {
            "rating": 1333.489009852459,
            "rating_q975": 1382.5118276849944,
            "rating_q025": 1284.4661920199237
        },
        "deepseek-v3.1": {
            "rating": 1332.212944803065,
            "rating_q975": 1359.6495519701655,
            "rating_q025": 1304.7763376359646
        },
        "deepseek-v3.1-thinking": {
            "rating": 1331.362363938823,
            "rating_q975": 1363.392167735741,
            "rating_q025": 1299.3325601419049
        },
        "grok-4-fast-chat": {
            "rating": 1330.2383224241494,
            "rating_q975": 1371.371362054763,
            "rating_q025": 1289.1052827935357
        },
        "qwen3-30b-a3b-instruct-2507": {
            "rating": 1328.023771184275,
            "rating_q975": 1353.9400979481948,
            "rating_q025": 1302.107444420355
        },
        "deepseek-r1": {
            "rating": 1327.1673023194865,
            "rating_q975": 1365.8713466582133,
            "rating_q025": 1288.4632579807596
        },
        "qwen3-235b-a22b": {
            "rating": 1321.1342061627017,
            "rating_q975": 1348.214958728768,
            "rating_q025": 1294.0534535966356
        },
        "gemini-2.0-flash-lite-preview-02-05": {
            "rating": 1320.080520616192,
            "rating_q975": 1350.7370835680028,
            "rating_q025": 1289.423957664381
        },
        "kimi-k2-thinking-turbo": {
            "rating": 1312.2766742301656,
            "rating_q975": 1355.8891449041826,
            "rating_q025": 1268.6642035561485
        },
        "claude-opus-4-20250514-thinking-16k": {
            "rating": 1309.9343886037307,
            "rating_q975": 1333.52452174734,
            "rating_q025": 1286.3442554601213
        },
        "o3-mini-high": {
            "rating": 1309.8995447268542,
            "rating_q975": 1349.7864392965726,
            "rating_q025": 1270.0126501571358
        },
        "gemini-2.0-flash-001": {
            "rating": 1309.4466456358416,
            "rating_q975": 1331.997935629944,
            "rating_q025": 1286.8953556417391
        },
        "o4-mini-2025-04-16": {
            "rating": 1308.883443156737,
            "rating_q975": 1329.2618017260504,
            "rating_q025": 1288.5050845874237
        },
        "deepseek-v3-0324": {
            "rating": 1308.5928006939478,
            "rating_q975": 1328.8838295677535,
            "rating_q025": 1288.301771820142
        },
        "gpt-5-mini-high": {
            "rating": 1308.5123553586386,
            "rating_q975": 1333.500203239822,
            "rating_q025": 1283.5245074774552
        },
        "kimi-k2-0905-preview": {
            "rating": 1305.4936457237964,
            "rating_q975": 1342.1147816212504,
            "rating_q025": 1268.8725098263424
        },
        "claude-haiku-4-5-20251001": {
            "rating": 1304.8713889671478,
            "rating_q975": 1338.8100824973158,
            "rating_q025": 1270.9326954369799
        },
        "qwen2.5-max": {
            "rating": 1303.9059747090375,
            "rating_q975": 1330.5647329414087,
            "rating_q025": 1277.2472164766664
        },
        "gemma-3-27b-it": {
            "rating": 1302.6014972868763,
            "rating_q975": 1323.5011974785841,
            "rating_q025": 1281.7017970951686
        },
        "claude-opus-4-20250514": {
            "rating": 1302.4289129145784,
            "rating_q975": 1322.6075877971919,
            "rating_q025": 1282.250238031965
        },
        "glm-4.5-air": {
            "rating": 1302.103176697979,
            "rating_q975": 1326.8811499224453,
            "rating_q025": 1277.3252034735128
        },
        "grok-3-mini-beta": {
            "rating": 1299.7453362067315,
            "rating_q975": 1329.0588360291772,
            "rating_q025": 1270.4318363842858
        },
        "mistral-medium-2505": {
            "rating": 1296.332139409635,
            "rating_q975": 1320.2764059203955,
            "rating_q025": 1272.3878728988743
        },
        "qwen3-coder-480b-a35b-instruct": {
            "rating": 1296.0064743665607,
            "rating_q975": 1323.0824059486947,
            "rating_q025": 1268.9305427844267
        },
        "gpt-4.1-mini-2025-04-14": {
            "rating": 1293.8213253934355,
            "rating_q975": 1315.9542112796753,
            "rating_q025": 1271.6884395071957
        },
        "gemini-1.5-pro-002": {
            "rating": 1293.214631515919,
            "rating_q975": 1314.751510995332,
            "rating_q025": 1271.6777520365063
        },
        "o1-preview": {
            "rating": 1287.8051656010714,
            "rating_q975": 1315.2742443452657,
            "rating_q025": 1260.336086856877
        },
        "qwen3-next-80b-a3b-thinking": {
            "rating": 1286.681876404861,
            "rating_q975": 1322.0925435542329,
            "rating_q025": 1251.271209255489
        },
        "command-a-03-2025": {
            "rating": 1285.104947873105,
            "rating_q975": 1304.1218324665178,
            "rating_q025": 1266.088063279692
        },
        "claude-sonnet-4-20250514": {
            "rating": 1283.4698920971978,
            "rating_q975": 1304.8016212246616,
            "rating_q025": 1262.138162969734
        },
        "kimi-k2-0711-preview": {
            "rating": 1277.1312588538487,
            "rating_q975": 1302.3558096652098,
            "rating_q025": 1251.9067080424877
        },
        "gpt-oss-120b": {
            "rating": 1276.247820101174,
            "rating_q975": 1301.0657269080502,
            "rating_q025": 1251.4299132942979
        },
        "claude-sonnet-4-20250514-thinking-32k": {
            "rating": 1270.3616919644564,
            "rating_q975": 1294.2529508039397,
            "rating_q025": 1246.4704331249732
        },
        "mistral-small-2506": {
            "rating": 1269.2015318222757,
            "rating_q975": 1300.928401315893,
            "rating_q025": 1237.4746623286583
        },
        "qwq-32b": {
            "rating": 1265.3529043711646,
            "rating_q975": 1295.3074783821276,
            "rating_q025": 1235.3983303602017
        },
        "step-3": {
            "rating": 1263.0938210327067,
            "rating_q975": 1307.846703572716,
            "rating_q025": 1218.3409384926974
        },
        "gemma-3n-e4b-it": {
            "rating": 1259.5117430190971,
            "rating_q975": 1286.9626662320793,
            "rating_q025": 1232.060819806115
        },
        "o3-mini": {
            "rating": 1258.979100268894,
            "rating_q975": 1277.7035858522092,
            "rating_q025": 1240.2546146855786
        },
        "qwen3-30b-a3b": {
            "rating": 1257.8481275922477,
            "rating_q975": 1285.4598912399767,
            "rating_q025": 1230.2363639445186
        },
        "gpt-5-nano-high": {
            "rating": 1254.7403189109534,
            "rating_q975": 1296.804665567197,
            "rating_q025": 1212.67597225471
        },
        "ring-flash-2.0": {
            "rating": 1248.9677489990681,
            "rating_q975": 1290.829269810407,
            "rating_q025": 1207.1062281877294
        },
        "minimax-m1": {
            "rating": 1247.4560168126638,
            "rating_q975": 1272.4457035784526,
            "rating_q025": 1222.466330046875
        },
        "claude-3-7-sonnet-20250219-thinking-32k": {
            "rating": 1246.8254109674983,
            "rating_q975": 1269.8471160671313,
            "rating_q025": 1223.8037058678653
        },
        "deepseek-v3": {
            "rating": 1245.7538162460662,
            "rating_q975": 1279.1905865921174,
            "rating_q025": 1212.317045900015
        },
        "gpt-oss-20b": {
            "rating": 1244.7678099074342,
            "rating_q975": 1284.7639902159424,
            "rating_q025": 1204.771629598926
        },
        "glm-4-plus": {
            "rating": 1239.2189420058396,
            "rating_q975": 1268.9912034953268,
            "rating_q025": 1209.4466805163524
        },
        "claude-3-7-sonnet-20250219": {
            "rating": 1238.460703361221,
            "rating_q975": 1262.2261519515591,
            "rating_q025": 1214.695254770883
        },
        "grok-2-2024-08-13": {
            "rating": 1235.4922601523285,
            "rating_q975": 1255.3788879532071,
            "rating_q025": 1215.60563235145
        },
        "gpt-4o-2024-05-13": {
            "rating": 1235.223661839873,
            "rating_q975": 1250.0741224878511,
            "rating_q025": 1220.373201191895
        },
        "gemini-advanced-0514": {
            "rating": 1230.0223888909145,
            "rating_q975": 1248.5091572495567,
            "rating_q025": 1211.5356205322723
        },
        "o1-mini": {
            "rating": 1222.7879093836348,
            "rating_q975": 1244.3786875396534,
            "rating_q025": 1201.1971312276162
        },
        "gemini-1.5-pro-001": {
            "rating": 1220.9024223830916,
            "rating_q975": 1237.4251768585684,
            "rating_q025": 1204.3796679076147
        },
        "gemini-1.5-flash-002": {
            "rating": 1219.8448461500848,
            "rating_q975": 1245.783281432998,
            "rating_q025": 1193.9064108671716
        },
        "gpt-4o-2024-08-06": {
            "rating": 1219.815412503595,
            "rating_q975": 1242.6794150915273,
            "rating_q025": 1196.951409915663
        },
        "llama-4-scout-17b-16e-instruct": {
            "rating": 1212.0068199164157,
            "rating_q975": 1237.6058190636743,
            "rating_q025": 1186.407820769157
        },
        "athene-v2-chat": {
            "rating": 1206.014938266685,
            "rating_q975": 1237.4610478863497,
            "rating_q025": 1174.5688286470204
        },
        "llama-4-maverick-17b-128e-instruct": {
            "rating": 1205.038791639632,
            "rating_q975": 1227.0068104944062,
            "rating_q025": 1183.070772784858
        },
        "deepseek-v2.5": {
            "rating": 1204.966226722692,
            "rating_q975": 1235.7356590351808,
            "rating_q025": 1174.1967944102032
        },
        "mistral-large-2411": {
            "rating": 1201.337103281226,
            "rating_q975": 1229.1195473175478,
            "rating_q025": 1173.5546592449043
        },
        "mistral-small-3.1-24b-instruct-2503": {
            "rating": 1199.9167371057733,
            "rating_q975": 1225.2577482906938,
            "rating_q025": 1174.5757259208528
        },
        "yi-lightning": {
            "rating": 1199.6693907590738,
            "rating_q975": 1228.2002785735633,
            "rating_q025": 1171.1385029445844
        },
        "gpt-4o-mini-2024-07-18": {
            "rating": 1198.5864457665757,
            "rating_q975": 1217.0719004931939,
            "rating_q025": 1180.1009910399575
        },
        "claude-3-5-sonnet-20241022": {
            "rating": 1198.4703315635388,
            "rating_q975": 1215.759082050057,
            "rating_q025": 1181.1815810770206
        },
        "gemini-1.5-flash-001": {
            "rating": 1197.9752808242215,
            "rating_q975": 1214.8337336155214,
            "rating_q025": 1181.1168280329216
        },
        "claude-3-5-sonnet-20240620": {
            "rating": 1197.859497545095,
            "rating_q975": 1214.8177368110876,
            "rating_q025": 1180.9012582791026
        },
        "grok-2-mini-2024-08-13": {
            "rating": 1196.9283552137576,
            "rating_q975": 1218.3059349919936,
            "rating_q025": 1175.5507754355217
        },
        "amazon-nova-pro-v1.0": {
            "rating": 1196.511400461876,
            "rating_q975": 1226.8927662207002,
            "rating_q025": 1166.130034703052
        },
        "qwen2.5-72b-instruct": {
            "rating": 1190.1433526590895,
            "rating_q975": 1215.8658392852597,
            "rating_q025": 1164.4208660329193
        },
        "mistral-small-24b-instruct-2501": {
            "rating": 1189.1656973924605,
            "rating_q975": 1227.8317121622395,
            "rating_q025": 1150.4996826226816
        },
        "claude-3-opus-20240229": {
            "rating": 1187.1832674990574,
            "rating_q975": 1201.4446333132958,
            "rating_q025": 1172.921901684819
        },
        "gpt-4-turbo-2024-04-09": {
            "rating": 1184.9714362981522,
            "rating_q975": 1201.0745375751367,
            "rating_q025": 1168.8683350211677
        },
        "llama-3.1-405b-instruct-fp8": {
            "rating": 1184.73084374301,
            "rating_q975": 1204.5620956437924,
            "rating_q025": 1164.8995918422274
        },
        "gpt-4-1106-preview": {
            "rating": 1179.9546228943016,
            "rating_q975": 1198.732604775914,
            "rating_q025": 1161.176641012689
        },
        "gemma-2-27b-it": {
            "rating": 1173.047104765477,
            "rating_q975": 1189.9489892878385,
            "rating_q025": 1156.1452202431153
        },
        "gpt-4-0125-preview": {
            "rating": 1172.971626417516,
            "rating_q975": 1191.5612430745002,
            "rating_q025": 1154.382009760532
        },
        "mistral-large-2407": {
            "rating": 1171.6484768555579,
            "rating_q975": 1193.4275157345917,
            "rating_q025": 1149.869437976524
        },
        "llama-3.1-405b-instruct-bf16": {
            "rating": 1170.461012411941,
            "rating_q975": 1194.097207527526,
            "rating_q025": 1146.824817296356
        },
        "claude-3-5-haiku-20241022": {
            "rating": 1169.9990756987017,
            "rating_q975": 1188.4839552849485,
            "rating_q025": 1151.514196112455
        },
        "command-r-08-2024": {
            "rating": 1169.270185296993,
            "rating_q975": 1218.3577964802043,
            "rating_q025": 1120.1825741137818
        },
        "amazon-nova-micro-v1.0": {
            "rating": 1158.6900731364988,
            "rating_q975": 1193.977565444792,
            "rating_q025": 1123.4025808282056
        },
        "gemini-1.5-flash-8b-001": {
            "rating": 1157.7927671044358,
            "rating_q975": 1183.6960384577574,
            "rating_q025": 1131.8894957511143
        },
        "c4ai-aya-expanse-32b": {
            "rating": 1156.6529875433025,
            "rating_q975": 1185.5391967715289,
            "rating_q025": 1127.7667783150762
        },
        "athene-70b-0725": {
            "rating": 1154.922103859278,
            "rating_q975": 1184.923040626437,
            "rating_q025": 1124.921167092119
        },
        "amazon-nova-lite-v1.0": {
            "rating": 1152.827914762626,
            "rating_q975": 1186.315234080363,
            "rating_q025": 1119.340595444889
        },
        "phi-4": {
            "rating": 1149.4648540946725,
            "rating_q975": 1181.436876007576,
            "rating_q025": 1117.492832181769
        },
        "qwen-max-0919": {
            "rating": 1148.5929402333054,
            "rating_q975": 1182.559212023944,
            "rating_q025": 1114.6266684426669
        },
        "nemotron-4-340b-instruct": {
            "rating": 1145.0944512708734,
            "rating_q975": 1170.0657108453092,
            "rating_q025": 1120.1231916964375
        },
        "llama-3.1-70b-instruct": {
            "rating": 1144.5533497078263,
            "rating_q975": 1165.1932199343837,
            "rating_q025": 1123.913479481269
        },
        "magistral-medium-2506": {
            "rating": 1144.2887129114279,
            "rating_q975": 1192.412993390998,
            "rating_q025": 1096.1644324318577
        },
        "llama-3.3-70b-instruct": {
            "rating": 1137.9200960176345,
            "rating_q975": 1158.06124651285,
            "rating_q025": 1117.778945522419
        },
        "command-r-plus": {
            "rating": 1137.8354202316427,
            "rating_q975": 1155.5378533926794,
            "rating_q025": 1120.132987070606
        },
        "gemma-2-9b-it": {
            "rating": 1137.4770615118755,
            "rating_q975": 1156.3799601316261,
            "rating_q025": 1118.5741628921248
        },
        "claude-3-sonnet-20240229": {
            "rating": 1129.1576498937457,
            "rating_q975": 1146.1007048537408,
            "rating_q025": 1112.2145949337505
        },
        "claude-3-haiku-20240307": {
            "rating": 1111.894103121369,
            "rating_q975": 1128.003840581386,
            "rating_q025": 1095.784365661352
        },
        "reka-flash-21b-20240226-online": {
            "rating": 1104.6929755109304,
            "rating_q975": 1137.5389691948394,
            "rating_q025": 1071.8469818270214
        },
        "deepseek-coder-v2": {
            "rating": 1102.7535533268738,
            "rating_q975": 1132.9538105351535,
            "rating_q025": 1072.553296118594
        },
        "command-r": {
            "rating": 1097.2504062284524,
            "rating_q975": 1116.763871090484,
            "rating_q025": 1077.736941366421
        },
        "gpt-4-0314": {
            "rating": 1094.836342797983,
            "rating_q975": 1124.49391682588,
            "rating_q025": 1065.178768770086
        },
        "qwen2-72b-instruct": {
            "rating": 1083.1074494088718,
            "rating_q975": 1102.4242112546979,
            "rating_q025": 1063.7906875630458
        },
        "reka-flash-21b-20240226": {
            "rating": 1073.6577357756034,
            "rating_q975": 1098.1514067345397,
            "rating_q025": 1049.1640648166672
        },
        "gpt-4-0613": {
            "rating": 1061.213895897945,
            "rating_q975": 1081.256490997591,
            "rating_q025": 1041.1713007982987
        },
        "mixtral-8x22b-instruct-v0.1": {
            "rating": 1058.1008741884805,
            "rating_q975": 1077.613438209791,
            "rating_q025": 1038.58831016717
        },
        "llama-3.1-8b-instruct": {
            "rating": 1057.9176814299158,
            "rating_q975": 1079.7223755922328,
            "rating_q025": 1036.1129872675988
        },
        "gemma-2-2b-it": {
            "rating": 1056.2281449858024,
            "rating_q975": 1079.63972981491,
            "rating_q025": 1032.8165601566948
        },
        "qwen1.5-72b-chat": {
            "rating": 1050.9210484905175,
            "rating_q975": 1077.0162757062,
            "rating_q025": 1024.8258212748349
        },
        "qwen1.5-110b-chat": {
            "rating": 1047.7368755655154,
            "rating_q975": 1066.6205656407194,
            "rating_q025": 1028.8531854903115
        },
        "glm-4-0520": {
            "rating": 1043.9736864000506,
            "rating_q975": 1078.543860957902,
            "rating_q025": 1009.4035118421991
        },
        "mistral-medium": {
            "rating": 1032.359606489948,
            "rating_q975": 1065.877642328648,
            "rating_q025": 998.8415706512478
        },
        "gpt-3.5-turbo-0125": {
            "rating": 1024.7271063862886,
            "rating_q975": 1044.619491264373,
            "rating_q025": 1004.8347215082041
        },
        "mistral-large-2402": {
            "rating": 1019.528030422052,
            "rating_q975": 1040.2392804635042,
            "rating_q025": 998.8167803805998
        },
        "llama-3-70b-instruct": {
            "rating": 1019.2793415366289,
            "rating_q975": 1033.7572807306863,
            "rating_q025": 1004.8014023425715
        },
        "qwen1.5-32b-chat": {
            "rating": 1009.6423230022576,
            "rating_q975": 1038.8361077805187,
            "rating_q025": 980.4485382239965
        },
        "yi-1.5-34b-chat": {
            "rating": 1007.9807784118475,
            "rating_q975": 1030.5196980701132,
            "rating_q025": 985.4418587535818
        },
        "llama-3-8b-instruct": {
            "rating": 1006.5778375088354,
            "rating_q975": 1023.2038234962095,
            "rating_q025": 989.9518515214613
        },
        "gemma-1.1-7b-it": {
            "rating": 995.8432788546331,
            "rating_q975": 1018.3738099988403,
            "rating_q025": 973.3127477104259
        },
        "dbrx-instruct-preview": {
            "rating": 995.3015088582672,
            "rating_q975": 1024.519798901786,
            "rating_q025": 966.0832188147484
        },
        "mixtral-8x7b-instruct-v0.1": {
            "rating": 975.687014632982,
            "rating_q975": 998.573363647622,
            "rating_q025": 952.800665618342
        },
        "llama-2-70b-chat": {
            "rating": 971.8761423384228,
            "rating_q975": 1009.5336408356736,
            "rating_q025": 934.218643841172
        },
        "llama-2-13b-chat": {
            "rating": 964.7644069323774,
            "rating_q975": 1011.5054165941958,
            "rating_q025": 918.0233972705589
        },
        "phi-3-medium-4k-instruct": {
            "rating": 962.4146636130433,
            "rating_q975": 985.2784504853582,
            "rating_q025": 939.5508767407284
        },
        "yi-34b-chat": {
            "rating": 962.0244745423948,
            "rating_q975": 1000.9937741262054,
            "rating_q025": 923.0551749585843
        },
        "snowflake-arctic-instruct": {
            "rating": 947.0722891870954,
            "rating_q975": 974.076118401848,
            "rating_q025": 920.0684599723428
        },
        "phi-3-mini-4k-instruct": {
            "rating": 916.2018177593347,
            "rating_q975": 938.2966735382937,
            "rating_q025": 894.1069619803758
        },
        "phi-3-small-8k-instruct": {
            "rating": 908.0596839878517,
            "rating_q975": 930.8781990475452,
            "rating_q025": 885.2411689281582
        },
        "gemma-1.1-2b-it": {
            "rating": 902.6007836558905,
            "rating_q975": 932.96681316399,
            "rating_q025": 872.234754147791
        },
        "phi-3-mini-4k-instruct-june-2024": {
            "rating": 888.5114640253164,
            "rating_q975": 926.3680066317817,
            "rating_q025": 850.6549214188511
        },
        "phi-3-mini-128k-instruct": {
            "rating": 876.0619364509055,
            "rating_q975": 911.3214360625514,
            "rating_q025": 840.8024368392596
        }
    },
    "long_user": {
        "claude-opus-4-5-20251101": {
            "rating": 1490.517641840201,
            "rating_q975": 1503.2441943683018,
            "rating_q025": 1477.7910893121
        },
        "claude-opus-4-5-20251101-thinking-32k": {
            "rating": 1478.8853095450793,
            "rating_q975": 1491.7926770237211,
            "rating_q025": 1465.9779420664374
        },
        "gemini-3-pro": {
            "rating": 1476.3349479068945,
            "rating_q975": 1486.994289370144,
            "rating_q025": 1465.675606443645
        },
        "claude-sonnet-4-5-20250929-thinking-32k": {
            "rating": 1474.4219626399333,
            "rating_q975": 1482.7305311266846,
            "rating_q025": 1466.113394153182
        },
        "claude-sonnet-4-5-20250929": {
            "rating": 1467.2531702094504,
            "rating_q975": 1476.180393382343,
            "rating_q025": 1458.3259470365579
        },
        "gemini-2.5-pro": {
            "rating": 1458.068536391612,
            "rating_q975": 1463.9573910867514,
            "rating_q025": 1452.1796816964727
        },
        "claude-opus-4-1-20250805-thinking-16k": {
            "rating": 1454.9464379758779,
            "rating_q975": 1461.8848425321266,
            "rating_q025": 1448.008033419629
        },
        "gpt-5.1-high": {
            "rating": 1451.1962121114775,
            "rating_q975": 1462.5089648058859,
            "rating_q025": 1439.8834594170692
        },
        "qwen3-max-preview": {
            "rating": 1443.0440913227737,
            "rating_q975": 1451.320454376813,
            "rating_q025": 1434.7677282687346
        },
        "claude-opus-4-1-20250805": {
            "rating": 1441.4482750092295,
            "rating_q975": 1447.944899861373,
            "rating_q025": 1434.951650157086
        },
        "grok-3-preview-02-24": {
            "rating": 1439.9851692325556,
            "rating_q975": 1448.5633850292618,
            "rating_q025": 1431.4069534358493
        },
        "gpt-5.1": {
            "rating": 1433.7471741989175,
            "rating_q975": 1444.2931049137246,
            "rating_q025": 1423.2012434841104
        },
        "qwen3-235b-a22b-instruct-2507": {
            "rating": 1431.094110475151,
            "rating_q975": 1437.5682086145296,
            "rating_q025": 1424.6200123357723
        },
        "claude-haiku-4-5-20251001": {
            "rating": 1427.4489549682091,
            "rating_q975": 1435.7487742072076,
            "rating_q025": 1419.1491357292107
        },
        "glm-4.6": {
            "rating": 1426.2406181475214,
            "rating_q975": 1434.5141287047602,
            "rating_q025": 1417.9671075902827
        },
        "deepseek-v3.1-thinking": {
            "rating": 1424.2213565497693,
            "rating_q975": 1436.3533380616284,
            "rating_q025": 1412.0893750379103
        },
        "gemini-2.5-flash": {
            "rating": 1424.1600260234452,
            "rating_q975": 1429.9816842044252,
            "rating_q025": 1418.3383678424652
        },
        "qwen3-vl-235b-a22b-instruct": {
            "rating": 1423.6571185701584,
            "rating_q975": 1437.306232012772,
            "rating_q025": 1410.008005127545
        },
        "ernie-5.0-preview-1103": {
            "rating": 1422.7444003967732,
            "rating_q975": 1438.7240718081907,
            "rating_q025": 1406.7647289853558
        },
        "deepseek-v3.2": {
            "rating": 1422.0967259776987,
            "rating_q975": 1437.4403159860897,
            "rating_q025": 1406.7531359693078
        },
        "grok-4-fast-chat": {
            "rating": 1421.7891891118727,
            "rating_q975": 1437.1596457020505,
            "rating_q025": 1406.418732521695
        },
        "deepseek-v3.2-exp": {
            "rating": 1420.3071573737936,
            "rating_q975": 1431.540964569654,
            "rating_q025": 1409.0733501779332
        },
        "claude-opus-4-20250514-thinking-16k": {
            "rating": 1419.715604320432,
            "rating_q975": 1427.580266423564,
            "rating_q025": 1411.8509422173001
        },
        "grok-4.1": {
            "rating": 1418.8750470623497,
            "rating_q975": 1429.1465400265665,
            "rating_q025": 1408.603554098133
        },
        "deepseek-v3.1-terminus-thinking": {
            "rating": 1417.5047144466116,
            "rating_q975": 1440.2204499100126,
            "rating_q025": 1394.7889789832107
        },
        "glm-4.5": {
            "rating": 1416.5182353053435,
            "rating_q975": 1425.329548045616,
            "rating_q025": 1407.706922565071
        },
        "qwen3-max-2025-09-23": {
            "rating": 1416.3435592993405,
            "rating_q975": 1429.2903894734554,
            "rating_q025": 1403.3967291252256
        },
        "grok-4.1-thinking": {
            "rating": 1414.5974625140807,
            "rating_q975": 1424.9521078792784,
            "rating_q025": 1404.242817148883
        },
        "mistral-large-3": {
            "rating": 1414.3599631423524,
            "rating_q975": 1429.0195632331445,
            "rating_q025": 1399.7003630515603
        },
        "kimi-k2-thinking-turbo": {
            "rating": 1413.2253131721964,
            "rating_q975": 1423.5167951303429,
            "rating_q025": 1402.9338312140499
        },
        "chatgpt-4o-latest-20250326": {
            "rating": 1413.0835229212325,
            "rating_q975": 1419.11833704782,
            "rating_q025": 1407.048708794645
        },
        "deepseek-v3.2-thinking": {
            "rating": 1412.171813080756,
            "rating_q975": 1428.0345937685277,
            "rating_q025": 1396.3090323929844
        },
        "grok-4-0709": {
            "rating": 1411.5334173878964,
            "rating_q975": 1418.4467985466977,
            "rating_q025": 1404.6200362290951
        },
        "deepseek-v3.2-exp-thinking": {
            "rating": 1411.327739530803,
            "rating_q975": 1424.4839016259707,
            "rating_q025": 1398.1715774356353
        },
        "gemini-2.5-flash-preview-09-2025": {
            "rating": 1410.5626402818884,
            "rating_q975": 1418.3751698846331,
            "rating_q025": 1402.7501106791437
        },
        "grok-4-fast-reasoning": {
            "rating": 1409.4100843948834,
            "rating_q975": 1418.7217428793765,
            "rating_q025": 1400.0984259103902
        },
        "mistral-medium-2508": {
            "rating": 1409.2725804398522,
            "rating_q975": 1415.9572241845365,
            "rating_q025": 1402.5879366951679
        },
        "qwen3-next-80b-a3b-instruct": {
            "rating": 1408.3560721450124,
            "rating_q975": 1417.0359632766663,
            "rating_q025": 1399.6761810133585
        },
        "gpt-4.5-preview-2025-02-27": {
            "rating": 1407.7650774745862,
            "rating_q975": 1421.2936302322,
            "rating_q025": 1394.2365247169723
        },
        "deepseek-v3.1": {
            "rating": 1405.8356972075735,
            "rating_q975": 1416.4287927811629,
            "rating_q025": 1395.2426016339841
        },
        "gpt-5-chat": {
            "rating": 1402.7065453978212,
            "rating_q975": 1410.454882271264,
            "rating_q025": 1394.9582085243783
        },
        "qwen3-235b-a22b-thinking-2507": {
            "rating": 1401.4667538942545,
            "rating_q975": 1415.7522387173185,
            "rating_q025": 1387.1812690711904
        },
        "claude-opus-4-20250514": {
            "rating": 1400.8472193679181,
            "rating_q975": 1408.1138202813052,
            "rating_q025": 1393.580618454531
        },
        "hunyuan-vision-1.5-thinking": {
            "rating": 1397.0547088110964,
            "rating_q975": 1423.0380778746708,
            "rating_q025": 1371.071339747522
        },
        "claude-sonnet-4-20250514-thinking-32k": {
            "rating": 1396.9849653485269,
            "rating_q975": 1404.8035732579647,
            "rating_q025": 1389.166357439089
        },
        "deepseek-v3.1-terminus": {
            "rating": 1396.0033308527834,
            "rating_q975": 1416.0953912243594,
            "rating_q025": 1375.9112704812073
        },
        "longcat-flash-chat": {
            "rating": 1394.661561433401,
            "rating_q975": 1406.894583023353,
            "rating_q025": 1382.4285398434488
        },
        "gpt-5-high": {
            "rating": 1393.8964119513887,
            "rating_q975": 1401.780805227326,
            "rating_q025": 1386.0120186754514
        },
        "qwen3-vl-235b-a22b-thinking": {
            "rating": 1393.748978311918,
            "rating_q975": 1407.723157289325,
            "rating_q025": 1379.7747993345113
        },
        "deepseek-r1-0528": {
            "rating": 1393.567095085067,
            "rating_q975": 1404.1817519671336,
            "rating_q025": 1382.9524382030004
        },
        "grok-4-1-fast-reasoning": {
            "rating": 1389.042757452422,
            "rating_q975": 1401.7919060443828,
            "rating_q025": 1376.293608860461
        },
        "qwen3-235b-a22b-no-thinking": {
            "rating": 1387.8227028932822,
            "rating_q975": 1395.4128051322336,
            "rating_q025": 1380.2326006543308
        },
        "gpt-4.1-2025-04-14": {
            "rating": 1386.283853328721,
            "rating_q975": 1392.8445016032128,
            "rating_q025": 1379.7232050542293
        },
        "hunyuan-t1-20250711": {
            "rating": 1383.0344391925305,
            "rating_q975": 1402.8187577230851,
            "rating_q025": 1363.2501206619759
        },
        "qwen3-30b-a3b-instruct-2507": {
            "rating": 1381.0289790694048,
            "rating_q975": 1389.7962202161498,
            "rating_q025": 1372.26173792266
        },
        "gemini-2.5-flash-lite-preview-09-2025-no-thinking": {
            "rating": 1379.6143584541003,
            "rating_q975": 1387.3820502066894,
            "rating_q025": 1371.8466667015111
        },
        "claude-sonnet-4-20250514": {
            "rating": 1379.138414332816,
            "rating_q975": 1386.5667104342003,
            "rating_q025": 1371.7101182314316
        },
        "gemini-2.5-flash-lite-preview-06-17-thinking": {
            "rating": 1379.0340758848688,
            "rating_q975": 1387.0049306478902,
            "rating_q025": 1371.0632211218474
        },
        "qwen3-coder-480b-a35b-instruct": {
            "rating": 1378.8282373627137,
            "rating_q975": 1387.806615479265,
            "rating_q025": 1369.8498592461624
        },
        "o1-2024-12-17": {
            "rating": 1378.4718618971413,
            "rating_q975": 1388.1941121883847,
            "rating_q025": 1368.7496116058978
        },
        "amazon-nova-experimental-chat-10-20": {
            "rating": 1375.2453609457739,
            "rating_q975": 1388.8455173802306,
            "rating_q025": 1361.6452045113172
        },
        "grok-3-mini-high": {
            "rating": 1375.0901178373422,
            "rating_q975": 1385.4353719940368,
            "rating_q025": 1364.7448636806475
        },
        "o3-2025-04-16": {
            "rating": 1374.979748038344,
            "rating_q975": 1381.3062176546243,
            "rating_q025": 1368.6532784220637
        },
        "claude-3-7-sonnet-20250219-thinking-32k": {
            "rating": 1372.3841223673855,
            "rating_q975": 1380.3159742637351,
            "rating_q025": 1364.452270471036
        },
        "mai-1-preview": {
            "rating": 1371.9991112093405,
            "rating_q975": 1382.0826635874512,
            "rating_q025": 1361.9155588312299
        },
        "glm-4.5-air": {
            "rating": 1367.7772478014701,
            "rating_q975": 1375.5549442522429,
            "rating_q025": 1359.9995513506974
        },
        "hunyuan-turbos-20250416": {
            "rating": 1367.5530877596077,
            "rating_q975": 1382.1720723267235,
            "rating_q025": 1352.9341031924919
        },
        "mistral-medium-2505": {
            "rating": 1361.4439433849034,
            "rating_q975": 1369.5057608937827,
            "rating_q025": 1353.382125876024
        },
        "gpt-5-mini-high": {
            "rating": 1361.0314889112824,
            "rating_q975": 1369.4398537252684,
            "rating_q025": 1352.6231240972963
        },
        "grok-3-mini-beta": {
            "rating": 1360.8684008456896,
            "rating_q975": 1370.1392175890164,
            "rating_q025": 1351.5975841023628
        },
        "qwen2.5-max": {
            "rating": 1358.25677156655,
            "rating_q975": 1366.7216984999804,
            "rating_q025": 1349.7918446331196
        },
        "claude-3-7-sonnet-20250219": {
            "rating": 1355.9368564861365,
            "rating_q975": 1363.4289348160446,
            "rating_q025": 1348.4447781562285
        },
        "deepseek-r1": {
            "rating": 1355.80244996174,
            "rating_q975": 1367.5767382868942,
            "rating_q025": 1344.0281616365858
        },
        "qwen3-235b-a22b": {
            "rating": 1355.423105261092,
            "rating_q975": 1364.2138336005407,
            "rating_q025": 1346.632376921643
        },
        "kimi-k2-0905-preview": {
            "rating": 1355.2104732754142,
            "rating_q975": 1367.0951053714507,
            "rating_q025": 1343.3258411793777
        },
        "qwen3-next-80b-a3b-thinking": {
            "rating": 1354.3781050749674,
            "rating_q975": 1365.6992775494311,
            "rating_q025": 1343.0569326005036
        },
        "deepseek-v3-0324": {
            "rating": 1353.9631980624222,
            "rating_q975": 1360.8252622566613,
            "rating_q025": 1347.101133868183
        },
        "step-1o-turbo-202506": {
            "rating": 1352.1377806555768,
            "rating_q975": 1367.9906338517212,
            "rating_q025": 1336.2849274594323
        },
        "gemini-2.0-flash-001": {
            "rating": 1346.97804936561,
            "rating_q975": 1354.345693359372,
            "rating_q025": 1339.6104053718482
        },
        "gpt-4.1-mini-2025-04-14": {
            "rating": 1345.8178450829819,
            "rating_q975": 1353.4143851767765,
            "rating_q025": 1338.2213049891873
        },
        "nova-2-lite": {
            "rating": 1344.8083735190808,
            "rating_q975": 1361.161633121929,
            "rating_q025": 1328.4551139162324
        },
        "o1-preview": {
            "rating": 1344.624659212045,
            "rating_q975": 1354.1980235546828,
            "rating_q025": 1335.051294869407
        },
        "deepseek-v3": {
            "rating": 1343.7214714361437,
            "rating_q975": 1354.071455596506,
            "rating_q025": 1333.3714872757814
        },
        "o3-mini-high": {
            "rating": 1343.4558837267957,
            "rating_q975": 1355.556544569669,
            "rating_q025": 1331.3552228839224
        },
        "hunyuan-large-2025-02-10": {
            "rating": 1342.1280062247065,
            "rating_q975": 1370.5558714593162,
            "rating_q025": 1313.7001409900968
        },
        "minimax-m2": {
            "rating": 1341.9545497944307,
            "rating_q975": 1356.9780156367538,
            "rating_q025": 1326.9310839521077
        },
        "amazon-nova-experimental-chat-10-09": {
            "rating": 1340.643157532706,
            "rating_q975": 1353.9033900633528,
            "rating_q025": 1327.3829250020592
        },
        "gemma-3-27b-it": {
            "rating": 1335.9461919294981,
            "rating_q975": 1343.3515134308952,
            "rating_q025": 1328.540870428101
        },
        "command-a-03-2025": {
            "rating": 1334.896218194299,
            "rating_q975": 1341.1875238035368,
            "rating_q025": 1328.6049125850614
        },
        "minimax-m1": {
            "rating": 1334.0026552732438,
            "rating_q975": 1341.4860720137808,
            "rating_q025": 1326.5192385327068
        },
        "step-3": {
            "rating": 1331.4927159026934,
            "rating_q975": 1347.925039900741,
            "rating_q025": 1315.0603919046457
        },
        "kimi-k2-0711-preview": {
            "rating": 1330.820638772107,
            "rating_q975": 1339.2132561727194,
            "rating_q025": 1322.4280213714947
        },
        "mistral-small-2506": {
            "rating": 1330.5909343683652,
            "rating_q975": 1340.72296761199,
            "rating_q025": 1320.4589011247404
        },
        "qwen3-32b": {
            "rating": 1329.6403327665194,
            "rating_q975": 1354.200031034763,
            "rating_q025": 1305.0806344982757
        },
        "o3-mini": {
            "rating": 1329.4588659673677,
            "rating_q975": 1335.9068483669419,
            "rating_q025": 1323.0108835677936
        },
        "ling-flash-2.0": {
            "rating": 1327.2835022584952,
            "rating_q975": 1343.61619165726,
            "rating_q025": 1310.9508128597304
        },
        "qwen-plus-0125": {
            "rating": 1325.2647692177466,
            "rating_q975": 1346.4260736895656,
            "rating_q025": 1304.1034647459276
        },
        "ring-flash-2.0": {
            "rating": 1323.3596656703367,
            "rating_q975": 1339.422970526756,
            "rating_q025": 1307.2963608139173
        },
        "hunyuan-turbos-20250226": {
            "rating": 1321.5893581962318,
            "rating_q975": 1354.253839697575,
            "rating_q025": 1288.9248766948888
        },
        "gemini-2.0-flash-lite-preview-02-05": {
            "rating": 1321.5607184815335,
            "rating_q975": 1331.8125578629727,
            "rating_q025": 1311.3088791000944
        },
        "o1-mini": {
            "rating": 1320.8886506976942,
            "rating_q975": 1328.3032293594852,
            "rating_q025": 1313.4740720359032
        },
        "gpt-oss-120b": {
            "rating": 1320.640402704418,
            "rating_q975": 1328.617263329046,
            "rating_q025": 1312.66354207979
        },
        "gemma-3-12b-it": {
            "rating": 1320.1578988645344,
            "rating_q975": 1348.6858663856647,
            "rating_q025": 1291.6299313434042
        },
        "intellect-3": {
            "rating": 1318.4567140576803,
            "rating_q975": 1344.5030653286376,
            "rating_q025": 1292.410362786723
        },
        "o4-mini-2025-04-16": {
            "rating": 1317.7007783966092,
            "rating_q975": 1324.7122776715867,
            "rating_q025": 1310.6892791216317
        },
        "glm-4-plus-0111": {
            "rating": 1316.6966304837229,
            "rating_q975": 1337.0658422632334,
            "rating_q025": 1296.3274187042123
        },
        "nvidia-llama-3.3-nemotron-super-49b-v1.5": {
            "rating": 1316.1347162450302,
            "rating_q975": 1337.7626665816167,
            "rating_q025": 1294.5067659084436
        },
        "qwen3-30b-a3b": {
            "rating": 1315.45449162955,
            "rating_q975": 1324.375463926515,
            "rating_q025": 1306.5335193325848
        },
        "gpt-5-nano-high": {
            "rating": 1314.8295528278413,
            "rating_q975": 1329.739420860144,
            "rating_q025": 1299.9196847955386
        },
        "claude-3-5-sonnet-20241022": {
            "rating": 1312.8459545864948,
            "rating_q975": 1318.2686739559551,
            "rating_q025": 1307.4232352170345
        },
        "hunyuan-turbo-0110": {
            "rating": 1311.3193705602803,
            "rating_q975": 1341.3509000415918,
            "rating_q025": 1281.2878410789688
        },
        "qwq-32b": {
            "rating": 1310.8099084586056,
            "rating_q975": 1320.0161708774826,
            "rating_q025": 1301.6036460397286
        },
        "gemini-1.5-pro-002": {
            "rating": 1308.8266508078495,
            "rating_q975": 1315.7718367799557,
            "rating_q025": 1301.8814648357434
        },
        "step-2-16k-exp-202412": {
            "rating": 1307.0800130842931,
            "rating_q975": 1328.3311767782814,
            "rating_q025": 1285.8288493903049
        },
        "glm-4.5v": {
            "rating": 1305.731961139038,
            "rating_q975": 1324.2732317992466,
            "rating_q025": 1287.1906904788295
        },
        "mistral-small-3.1-24b-instruct-2503": {
            "rating": 1304.7999674957032,
            "rating_q975": 1312.7161261106855,
            "rating_q025": 1296.8838088807208
        },
        "olmo-3-32b-think": {
            "rating": 1304.723077330908,
            "rating_q975": 1326.5181443718097,
            "rating_q025": 1282.9280102900061
        },
        "llama-3.1-nemotron-ultra-253b-v1": {
            "rating": 1302.3226048925449,
            "rating_q975": 1332.4167544534719,
            "rating_q025": 1272.2284553316179
        },
        "deepseek-v2.5-1210": {
            "rating": 1301.0367473232188,
            "rating_q975": 1318.268952497121,
            "rating_q025": 1283.8045421493166
        },
        "hunyuan-standard-2025-02-10": {
            "rating": 1300.8412429995756,
            "rating_q975": 1328.052853958534,
            "rating_q025": 1273.6296320406173
        },
        "llama-3.3-nemotron-49b-super-v1": {
            "rating": 1299.6996236008586,
            "rating_q975": 1330.5300370946275,
            "rating_q025": 1268.8692101070897
        },
        "yi-lightning": {
            "rating": 1297.831484057144,
            "rating_q975": 1308.253198239102,
            "rating_q025": 1287.4097698751862
        },
        "magistral-medium-2506": {
            "rating": 1296.830889542155,
            "rating_q975": 1309.316946463664,
            "rating_q025": 1284.3448326206462
        },
        "qwen2.5-plus-1127": {
            "rating": 1292.0652383173954,
            "rating_q975": 1306.1559339860814,
            "rating_q025": 1277.9745426487093
        },
        "gemini-1.5-pro-001": {
            "rating": 1291.453595663251,
            "rating_q975": 1299.7419181616833,
            "rating_q025": 1283.1652731648187
        },
        "athene-v2-chat": {
            "rating": 1290.2251679665158,
            "rating_q975": 1299.7019975544827,
            "rating_q025": 1280.7483383785489
        },
        "gpt-4o-2024-05-13": {
            "rating": 1289.2467560299906,
            "rating_q975": 1296.025424578195,
            "rating_q025": 1282.4680874817861
        },
        "qwen-max-0919": {
            "rating": 1289.0013835831169,
            "rating_q975": 1300.7567551580898,
            "rating_q025": 1277.246012008144
        },
        "gpt-4o-mini-2024-07-18": {
            "rating": 1288.7958664233788,
            "rating_q975": 1295.6418051285107,
            "rating_q025": 1281.949927718247
        },
        "glm-4-plus": {
            "rating": 1286.5686245791776,
            "rating_q975": 1296.5225596280325,
            "rating_q025": 1276.6146895303227
        },
        "gpt-4.1-nano-2025-04-14": {
            "rating": 1286.3988276541852,
            "rating_q975": 1306.493869725401,
            "rating_q025": 1266.3037855829693
        },
        "hunyuan-large-vision": {
            "rating": 1284.7297861509655,
            "rating_q975": 1304.6305905726956,
            "rating_q025": 1264.8289817292355
        },
        "gemini-1.5-flash-002": {
            "rating": 1284.673684666337,
            "rating_q975": 1292.9249200005231,
            "rating_q025": 1276.422449332151
        },
        "llama-4-maverick-17b-128e-instruct": {
            "rating": 1284.6172552048233,
            "rating_q975": 1292.1442509434587,
            "rating_q025": 1277.090259466188
        },
        "gpt-4o-2024-08-06": {
            "rating": 1284.0860232982131,
            "rating_q975": 1292.3543224100222,
            "rating_q025": 1275.8177241864041
        },
        "qwen2.5-72b-instruct": {
            "rating": 1282.4323136915598,
            "rating_q975": 1290.345825595234,
            "rating_q025": 1274.5188017878856
        },
        "gemma-3n-e4b-it": {
            "rating": 1280.6830083027917,
            "rating_q975": 1291.541162477407,
            "rating_q025": 1269.8248541281764
        },
        "mercury": {
            "rating": 1279.406080284523,
            "rating_q975": 1306.0195125484702,
            "rating_q025": 1252.7926480205756
        },
        "gemma-3-4b-it": {
            "rating": 1276.9579678983628,
            "rating_q975": 1304.4403516189034,
            "rating_q025": 1249.4755841778222
        },
        "grok-2-2024-08-13": {
            "rating": 1276.9559804932678,
            "rating_q975": 1284.0325737607654,
            "rating_q025": 1269.8793872257702
        },
        "claude-3-5-sonnet-20240620": {
            "rating": 1275.7996377689174,
            "rating_q975": 1283.398512059829,
            "rating_q025": 1268.2007634780057
        },
        "deepseek-v2.5": {
            "rating": 1273.7907800253429,
            "rating_q975": 1283.8248094261385,
            "rating_q025": 1263.7567506245473
        },
        "llama-4-scout-17b-16e-instruct": {
            "rating": 1272.3064538676908,
            "rating_q975": 1280.7760187429385,
            "rating_q025": 1263.8368889924432
        },
        "grok-2-mini-2024-08-13": {
            "rating": 1267.0338905709898,
            "rating_q975": 1274.5808628724642,
            "rating_q025": 1259.4869182695154
        },
        "llama-3.1-405b-instruct-bf16": {
            "rating": 1266.2436681094027,
            "rating_q975": 1274.051184919671,
            "rating_q025": 1258.4361512991345
        },
        "mistral-large-2411": {
            "rating": 1262.383785796002,
            "rating_q975": 1271.761267382058,
            "rating_q025": 1253.0063042099462
        },
        "claude-3-5-haiku-20241022": {
            "rating": 1260.7666570212064,
            "rating_q975": 1266.7568579238869,
            "rating_q025": 1254.7764561185259
        },
        "llama-3.1-405b-instruct-fp8": {
            "rating": 1260.1753828041055,
            "rating_q975": 1267.5875975623933,
            "rating_q025": 1252.7631680458178
        },
        "claude-3-opus-20240229": {
            "rating": 1259.8685628503977,
            "rating_q975": 1266.1182639133287,
            "rating_q025": 1253.6188617874666
        },
        "mistral-large-2407": {
            "rating": 1258.3286706367617,
            "rating_q975": 1266.8576834755893,
            "rating_q025": 1249.799657797934
        },
        "gpt-oss-20b": {
            "rating": 1258.1586409464526,
            "rating_q975": 1271.6795475577926,
            "rating_q025": 1244.6377343351126
        },
        "llama-3.3-70b-instruct": {
            "rating": 1257.3899478977237,
            "rating_q975": 1263.8545641102148,
            "rating_q025": 1250.9253316852325
        },
        "amazon-nova-pro-v1.0": {
            "rating": 1256.2140618580095,
            "rating_q975": 1265.8695036769338,
            "rating_q025": 1246.558620039085
        },
        "gemini-advanced-0514": {
            "rating": 1254.1983091624961,
            "rating_q975": 1264.5633585868936,
            "rating_q025": 1243.8332597380986
        },
        "gpt-4-turbo-2024-04-09": {
            "rating": 1253.8719082694467,
            "rating_q975": 1261.6703258671944,
            "rating_q025": 1246.0734906716991
        },
        "gemini-1.5-flash-001": {
            "rating": 1252.4878320504645,
            "rating_q975": 1261.1020855792763,
            "rating_q025": 1243.8735785216527
        },
        "qwen2.5-coder-32b-instruct": {
            "rating": 1250.5502063149702,
            "rating_q975": 1269.3023269440102,
            "rating_q025": 1231.7980856859301
        },
        "mistral-small-24b-instruct-2501": {
            "rating": 1247.2348478273595,
            "rating_q975": 1260.653251704384,
            "rating_q025": 1233.816443950335
        },
        "gpt-4-0125-preview": {
            "rating": 1244.3252752305648,
            "rating_q975": 1252.8247331569598,
            "rating_q025": 1235.8258173041697
        },
        "llama-3.1-70b-instruct": {
            "rating": 1241.64654769926,
            "rating_q975": 1249.118011375468,
            "rating_q025": 1234.175084023052
        },
        "llama-3.1-nemotron-70b-instruct": {
            "rating": 1238.9668143961303,
            "rating_q975": 1256.4213564116335,
            "rating_q025": 1221.512272380627
        },
        "gpt-4-1106-preview": {
            "rating": 1236.1747296838194,
            "rating_q975": 1244.5759706242538,
            "rating_q025": 1227.7734887433849
        },
        "amazon-nova-lite-v1.0": {
            "rating": 1234.6380717850955,
            "rating_q975": 1245.282349797709,
            "rating_q025": 1223.993793772482
        },
        "athene-70b-0725": {
            "rating": 1232.1914206096826,
            "rating_q975": 1244.562668609876,
            "rating_q025": 1219.8201726094892
        },
        "gemma-2-27b-it": {
            "rating": 1231.3658871113134,
            "rating_q975": 1238.0975210100112,
            "rating_q025": 1224.6342532126157
        },
        "command-r-plus-08-2024": {
            "rating": 1230.6884197818695,
            "rating_q975": 1246.0014813885919,
            "rating_q025": 1215.375358175147
        },
        "c4ai-aya-expanse-32b": {
            "rating": 1228.5045623945398,
            "rating_q975": 1237.7471175643138,
            "rating_q025": 1219.2620072247657
        },
        "gemma-2-9b-it-simpo": {
            "rating": 1226.8721366259365,
            "rating_q975": 1246.0647147370664,
            "rating_q025": 1207.6795585148066
        },
        "llama-3.1-tulu-3-70b": {
            "rating": 1225.4787237222527,
            "rating_q975": 1250.4444562792671,
            "rating_q025": 1200.5129911652382
        },
        "hunyuan-standard-256k": {
            "rating": 1225.1749039579745,
            "rating_q975": 1251.8179734119226,
            "rating_q025": 1198.5318345040264
        },
        "nemotron-4-340b-instruct": {
            "rating": 1223.8038606397743,
            "rating_q975": 1237.1356551381193,
            "rating_q025": 1210.4720661414292
        },
        "reka-core-20240904": {
            "rating": 1221.1659838943865,
            "rating_q975": 1239.3518446929872,
            "rating_q025": 1202.9801230957858
        },
        "deepseek-coder-v2": {
            "rating": 1219.4610821258766,
            "rating_q975": 1233.4045210469965,
            "rating_q025": 1205.5176432047567
        },
        "gemini-1.5-flash-8b-001": {
            "rating": 1219.2167030739697,
            "rating_q975": 1227.5119801228489,
            "rating_q025": 1210.9214260250906
        },
        "phi-4": {
            "rating": 1218.048398218194,
            "rating_q975": 1228.7025780475383,
            "rating_q025": 1207.3942183888498
        },
        "ministral-8b-2410": {
            "rating": 1212.4272766766599,
            "rating_q975": 1232.6541378550803,
            "rating_q025": 1192.2004154982394
        },
        "claude-3-sonnet-20240229": {
            "rating": 1211.38289062873,
            "rating_q975": 1220.0397291823779,
            "rating_q025": 1202.726052075082
        },
        "jamba-1.5-large": {
            "rating": 1207.394639280133,
            "rating_q975": 1224.9072489586047,
            "rating_q025": 1189.8820296016615
        },
        "amazon-nova-micro-v1.0": {
            "rating": 1206.4860521773355,
            "rating_q975": 1217.6382585329736,
            "rating_q025": 1195.3338458216974
        },
        "glm-4-0520": {
            "rating": 1205.8409329640997,
            "rating_q975": 1222.5493792244208,
            "rating_q025": 1189.1324867037786
        },
        "llama-3.1-nemotron-51b-instruct": {
            "rating": 1205.4784105688764,
            "rating_q975": 1228.705042060166,
            "rating_q025": 1182.2517790775867
        },
        "command-r-plus": {
            "rating": 1202.885337464143,
            "rating_q975": 1211.8579114784243,
            "rating_q025": 1193.9127634498618
        },
        "command-r-08-2024": {
            "rating": 1198.7001647862562,
            "rating_q975": 1213.5141006879176,
            "rating_q025": 1183.8862288845949
        },
        "gemma-2-9b-it": {
            "rating": 1197.7815319104138,
            "rating_q975": 1205.4204352472193,
            "rating_q025": 1190.1426285736084
        },
        "olmo-2-0325-32b-instruct": {
            "rating": 1197.4595176346588,
            "rating_q975": 1232.3643763434561,
            "rating_q025": 1162.5546589258615
        },
        "qwen2-72b-instruct": {
            "rating": 1193.1237988055377,
            "rating_q975": 1203.2712140906162,
            "rating_q025": 1182.9763835204592
        },
        "c4ai-aya-expanse-8b": {
            "rating": 1193.0430420002235,
            "rating_q975": 1207.724472461668,
            "rating_q025": 1178.361611538779
        },
        "reka-flash-20240904": {
            "rating": 1192.0204037438962,
            "rating_q975": 1209.7293897926354,
            "rating_q025": 1174.311417695157
        },
        "gpt-4-0314": {
            "rating": 1190.9712037135994,
            "rating_q975": 1202.570178446707,
            "rating_q025": 1179.3722289804919
        },
        "claude-3-haiku-20240307": {
            "rating": 1190.735769075222,
            "rating_q975": 1198.3274280815226,
            "rating_q025": 1183.1441100689212
        },
        "gpt-4-0613": {
            "rating": 1188.1191590585008,
            "rating_q975": 1197.4674776192364,
            "rating_q025": 1178.7708404977652
        },
        "llama-3.1-8b-instruct": {
            "rating": 1182.305467672388,
            "rating_q975": 1190.188379690774,
            "rating_q025": 1174.422555654002
        },
        "llama-3.1-tulu-3-8b": {
            "rating": 1181.525701893792,
            "rating_q975": 1207.4670939945088,
            "rating_q025": 1155.5843097930754
        },
        "llama-3-70b-instruct": {
            "rating": 1174.762038796385,
            "rating_q975": 1182.3628653856526,
            "rating_q025": 1167.1612122071174
        },
        "mistral-large-2402": {
            "rating": 1173.4187650877839,
            "rating_q975": 1183.3224258896905,
            "rating_q025": 1163.5151042858772
        },
        "qwq-32b-preview": {
            "rating": 1166.833010595989,
            "rating_q975": 1193.2665185886308,
            "rating_q025": 1140.3995026033472
        },
        "granite-3.1-8b-instruct": {
            "rating": 1163.096787884586,
            "rating_q975": 1190.3427442562413,
            "rating_q025": 1135.8508315129309
        },
        "command-r": {
            "rating": 1158.4970306372188,
            "rating_q975": 1168.446402822803,
            "rating_q025": 1148.5476584516346
        },
        "qwen1.5-110b-chat": {
            "rating": 1157.8822088371023,
            "rating_q975": 1169.701168355497,
            "rating_q025": 1146.0632493187077
        },
        "qwen1.5-72b-chat": {
            "rating": 1157.446074908924,
            "rating_q975": 1169.0076347752608,
            "rating_q025": 1145.884515042587
        },
        "jamba-1.5-mini": {
            "rating": 1157.0189808851067,
            "rating_q975": 1174.6080959997641,
            "rating_q025": 1139.4298657704492
        },
        "granite-3.1-2b-instruct": {
            "rating": 1156.1699318314459,
            "rating_q975": 1182.5518205453839,
            "rating_q025": 1129.7880431175079
        },
        "mistral-medium": {
            "rating": 1155.2870219935996,
            "rating_q975": 1168.166978734314,
            "rating_q025": 1142.4070652528853
        },
        "internlm2_5-20b-chat": {
            "rating": 1150.5554752694234,
            "rating_q975": 1166.8841415025745,
            "rating_q025": 1134.2268090362722
        },
        "qwen1.5-32b-chat": {
            "rating": 1147.017879609915,
            "rating_q975": 1159.608778969046,
            "rating_q025": 1134.4269802507843
        },
        "mixtral-8x22b-instruct-v0.1": {
            "rating": 1144.0371591305523,
            "rating_q975": 1153.775698062154,
            "rating_q025": 1134.2986201989504
        },
        "yi-1.5-34b-chat": {
            "rating": 1143.9515323431485,
            "rating_q975": 1157.2980005725105,
            "rating_q025": 1130.6050641137865
        },
        "reka-flash-21b-20240226": {
            "rating": 1141.660820746557,
            "rating_q975": 1154.4781425490141,
            "rating_q025": 1128.8434989440998
        },
        "reka-flash-21b-20240226-online": {
            "rating": 1140.0047059593935,
            "rating_q975": 1155.7132873084754,
            "rating_q025": 1124.2961246103116
        },
        "gemini-pro-dev-api": {
            "rating": 1131.4482328679255,
            "rating_q975": 1149.259892440733,
            "rating_q025": 1113.636573295118
        },
        "gemma-2-2b-it": {
            "rating": 1130.8813448688934,
            "rating_q975": 1139.283334312258,
            "rating_q025": 1122.4793554255289
        },
        "llama-3-8b-instruct": {
            "rating": 1128.7457119933026,
            "rating_q975": 1137.3112684070938,
            "rating_q025": 1120.1801555795114
        },
        "granite-3.0-8b-instruct": {
            "rating": 1121.979913361717,
            "rating_q975": 1145.8963553750862,
            "rating_q025": 1098.063471348348
        },
        "phi-3-medium-4k-instruct": {
            "rating": 1121.8707351711641,
            "rating_q975": 1134.81350012473,
            "rating_q025": 1108.9279702175984
        },
        "gpt-3.5-turbo-0125": {
            "rating": 1121.828471926767,
            "rating_q975": 1131.020294137292,
            "rating_q025": 1112.636649716242
        },
        "qwen1.5-14b-chat": {
            "rating": 1114.007077870653,
            "rating_q975": 1128.881031155461,
            "rating_q025": 1099.1331245858448
        },
        "dbrx-instruct-preview": {
            "rating": 1112.620903442424,
            "rating_q975": 1125.1082483448242,
            "rating_q025": 1100.1335585400236
        },
        "tulu-2-dpo-70b": {
            "rating": 1106.0945796961337,
            "rating_q975": 1140.042575143221,
            "rating_q025": 1072.1465842490463
        },
        "zephyr-orpo-141b-A35b-v0.1": {
            "rating": 1105.7160912967802,
            "rating_q975": 1134.143884437704,
            "rating_q025": 1077.2882981558564
        },
        "starling-lm-7b-beta": {
            "rating": 1105.3479032061996,
            "rating_q975": 1120.8282933037297,
            "rating_q025": 1089.8675131086695
        },
        "mixtral-8x7b-instruct-v0.1": {
            "rating": 1104.4074178896542,
            "rating_q975": 1113.9678986001602,
            "rating_q025": 1094.8469371791482
        },
        "llama-3.2-3b-instruct": {
            "rating": 1101.067036916618,
            "rating_q975": 1118.9799588431229,
            "rating_q025": 1083.1541149901132
        },
        "wizardlm-70b": {
            "rating": 1100.0317306523307,
            "rating_q975": 1132.3675393551093,
            "rating_q025": 1067.695921949552
        },
        "openchat-3.5": {
            "rating": 1095.8497802438167,
            "rating_q975": 1124.8172676691463,
            "rating_q025": 1066.882292818487
        },
        "yi-34b-chat": {
            "rating": 1095.4942437961981,
            "rating_q975": 1113.6059194876837,
            "rating_q025": 1077.3825681047126
        },
        "deepseek-llm-67b-chat": {
            "rating": 1091.440210774625,
            "rating_q975": 1129.1667978295502,
            "rating_q025": 1053.7136237196999
        },
        "qwen1.5-7b-chat": {
            "rating": 1091.0307593439302,
            "rating_q975": 1121.7775944227624,
            "rating_q025": 1060.283924265098
        },
        "phi-3-small-8k-instruct": {
            "rating": 1088.6025313329635,
            "rating_q975": 1101.8002694894851,
            "rating_q025": 1075.404793176442
        },
        "openchat-3.5-0106": {
            "rating": 1086.0415870378142,
            "rating_q975": 1104.5228504617487,
            "rating_q025": 1067.5603236138797
        },
        "starling-lm-7b-alpha": {
            "rating": 1081.781152862097,
            "rating_q975": 1104.9297573246563,
            "rating_q025": 1058.6325483995379
        },
        "granite-3.0-2b-instruct": {
            "rating": 1071.6318777399836,
            "rating_q975": 1095.9366128703673,
            "rating_q025": 1047.3271426095998
        },
        "gpt-3.5-turbo-1106": {
            "rating": 1068.7380005992743,
            "rating_q975": 1090.049059767654,
            "rating_q025": 1047.4269414308947
        },
        "llama-2-13b-chat": {
            "rating": 1065.2992414421942,
            "rating_q975": 1082.6941747216538,
            "rating_q025": 1047.9043081627347
        },
        "llama-2-70b-chat": {
            "rating": 1063.503908283238,
            "rating_q975": 1076.2859087017785,
            "rating_q025": 1050.7219078646974
        },
        "mistral-7b-instruct-v0.2": {
            "rating": 1060.7320157206218,
            "rating_q975": 1075.887739767587,
            "rating_q025": 1045.5762916736567
        },
        "smollm2-1.7b-instruct": {
            "rating": 1059.6420183636146,
            "rating_q975": 1093.1539095609353,
            "rating_q025": 1026.130127166294
        },
        "gemma-1.1-7b-it": {
            "rating": 1056.9221721642846,
            "rating_q975": 1069.4995441292003,
            "rating_q025": 1044.3448001993688
        },
        "openhermes-2.5-mistral-7b": {
            "rating": 1056.4468752680589,
            "rating_q975": 1090.8403973372137,
            "rating_q025": 1022.0533531989041
        },
        "wizardlm-13b": {
            "rating": 1052.948281015592,
            "rating_q975": 1094.9961083823587,
            "rating_q025": 1010.9004536488256
        },
        "llama-3.2-1b-instruct": {
            "rating": 1050.0278172903277,
            "rating_q975": 1068.8137006971542,
            "rating_q025": 1031.2419338835011
        },
        "vicuna-13b": {
            "rating": 1048.37962822798,
            "rating_q975": 1070.0142473826631,
            "rating_q025": 1026.7450090732968
        },
        "nous-hermes-2-mixtral-8x7b-dpo": {
            "rating": 1045.404663294885,
            "rating_q975": 1081.719582720497,
            "rating_q025": 1009.089743869273
        },
        "zephyr-7b-beta": {
            "rating": 1041.9917086041448,
            "rating_q975": 1069.6555453874664,
            "rating_q025": 1014.3278718208234
        },
        "phi-3-mini-4k-instruct-june-2024": {
            "rating": 1040.2570777521842,
            "rating_q975": 1059.1753514020147,
            "rating_q025": 1021.3388041023537
        },
        "phi-3-mini-4k-instruct": {
            "rating": 1040.2292430230189,
            "rating_q975": 1055.3067291366087,
            "rating_q025": 1025.151756909429
        },
        "vicuna-7b": {
            "rating": 1039.0501525016064,
            "rating_q975": 1084.9579032530582,
            "rating_q025": 993.1424017501545
        },
        "vicuna-33b": {
            "rating": 1029.225179070354,
            "rating_q975": 1048.498637445503,
            "rating_q025": 1009.9517206952052
        },
        "qwen-14b-chat": {
            "rating": 1028.1038161093334,
            "rating_q975": 1067.872549619217,
            "rating_q025": 988.3350825994498
        },
        "gemma-7b-it": {
            "rating": 1023.5419900062475,
            "rating_q975": 1046.1776008638326,
            "rating_q025": 1000.9063791486624
        },
        "codellama-34b-instruct": {
            "rating": 1014.4777067562595,
            "rating_q975": 1048.1225686148614,
            "rating_q025": 980.8328448976578
        },
        "palm-2": {
            "rating": 1007.9192488137516,
            "rating_q975": 1046.2730483918033,
            "rating_q025": 969.5654492356998
        },
        "snowflake-arctic-instruct": {
            "rating": 1002.8260229991267,
            "rating_q975": 1017.1307258369768,
            "rating_q025": 988.5213201612767
        },
        "gemma-1.1-2b-it": {
            "rating": 1002.7202104523707,
            "rating_q975": 1020.6470211037358,
            "rating_q025": 984.7933998010055
        },
        "mistral-7b-instruct": {
            "rating": 1001.2495764208545,
            "rating_q975": 1028.5550374649908,
            "rating_q025": 973.9441153767182
        },
        "llama2-70b-steerlm-chat": {
            "rating": 1000.2592026033702,
            "rating_q975": 1043.3574083775518,
            "rating_q025": 957.1609968291887
        },
        "llama-2-7b-chat": {
            "rating": 999.6326170518389,
            "rating_q975": 1019.8269224233704,
            "rating_q025": 979.4383116803074
        },
        "phi-3-mini-128k-instruct": {
            "rating": 996.8801586642553,
            "rating_q975": 1012.8052014947289,
            "rating_q025": 980.9551158337817
        },
        "qwen1.5-4b-chat": {
            "rating": 988.8322481934725,
            "rating_q975": 1012.8309568482052,
            "rating_q025": 964.8335395387398
        },
        "gemma-2b-it": {
            "rating": 982.9142525288494,
            "rating_q975": 1013.5244131623945,
            "rating_q025": 952.3040918953043
        },
        "stripedhyena-nous-7b": {
            "rating": 982.7644002193797,
            "rating_q975": 1015.3095226039529,
            "rating_q025": 950.2192778348065
        },
        "chatglm3-6b": {
            "rating": 952.4811365901049,
            "rating_q975": 994.3974864436045,
            "rating_q025": 910.5647867366054
        }
    },
    "math": {
        "gemini-3-pro": {
            "rating": 1473.8238348350305,
            "rating_q975": 1492.292179744961,
            "rating_q025": 1455.3554899251
        },
        "claude-opus-4-5-20251101": {
            "rating": 1472.1514290293894,
            "rating_q975": 1496.4511229670711,
            "rating_q025": 1447.8517350917077
        },
        "claude-opus-4-5-20251101-thinking-32k": {
            "rating": 1460.1924180301814,
            "rating_q975": 1485.396866981522,
            "rating_q025": 1434.987969078841
        },
        "gpt-5.1-high": {
            "rating": 1459.5143392828988,
            "rating_q975": 1480.3703313569918,
            "rating_q025": 1438.658347208806
        },
        "gemini-2.5-pro": {
            "rating": 1459.2623424282324,
            "rating_q975": 1468.4368059518808,
            "rating_q025": 1450.087878904584
        },
        "claude-sonnet-4-5-20250929-thinking-32k": {
            "rating": 1454.0878838328429,
            "rating_q975": 1469.2235886554345,
            "rating_q025": 1438.9521790102513
        },
        "longcat-flash-chat": {
            "rating": 1449.8674299871682,
            "rating_q975": 1471.998412421111,
            "rating_q025": 1427.7364475532254
        },
        "qwen3-max-preview": {
            "rating": 1449.6012777852607,
            "rating_q975": 1464.6051179963422,
            "rating_q025": 1434.5974375741791
        },
        "qwen3-next-80b-a3b-instruct": {
            "rating": 1446.1395426733272,
            "rating_q975": 1462.8715330069554,
            "rating_q025": 1429.4075523396991
        },
        "qwen3-max-2025-09-23": {
            "rating": 1444.1497761727185,
            "rating_q975": 1467.7203805574422,
            "rating_q025": 1420.5791717879947
        },
        "glm-4.6": {
            "rating": 1441.5568839744205,
            "rating_q975": 1457.7856424974236,
            "rating_q025": 1425.3281254514175
        },
        "qwen3-235b-a22b-instruct-2507": {
            "rating": 1441.1122530819061,
            "rating_q975": 1452.0541265516745,
            "rating_q025": 1430.1703796121378
        },
        "deepseek-v3.2": {
            "rating": 1438.544263062597,
            "rating_q975": 1466.5946929836293,
            "rating_q025": 1410.493833141565
        },
        "claude-opus-4-1-20250805-thinking-16k": {
            "rating": 1433.4129297006652,
            "rating_q975": 1445.197550930593,
            "rating_q025": 1421.6283084707375
        },
        "grok-4-0709": {
            "rating": 1431.9356718922497,
            "rating_q975": 1444.4231709682701,
            "rating_q025": 1419.4481728162293
        },
        "o3-2025-04-16": {
            "rating": 1431.8833655788665,
            "rating_q975": 1441.7426215871137,
            "rating_q025": 1422.0241095706192
        },
        "glm-4.5": {
            "rating": 1431.2493761976295,
            "rating_q975": 1446.7150490439208,
            "rating_q025": 1415.7837033513383
        },
        "grok-4.1-thinking": {
            "rating": 1430.4296877741633,
            "rating_q975": 1450.2147076799795,
            "rating_q025": 1410.6446678683471
        },
        "qwen3-vl-235b-a22b-instruct": {
            "rating": 1424.855732790929,
            "rating_q975": 1449.6452686762423,
            "rating_q025": 1400.066196905616
        },
        "deepseek-v3.2-exp-thinking": {
            "rating": 1424.8475641075347,
            "rating_q975": 1451.4817092388591,
            "rating_q025": 1398.2134189762103
        },
        "gemini-2.5-flash-preview-09-2025": {
            "rating": 1424.7064633202324,
            "rating_q975": 1439.4235039109744,
            "rating_q025": 1409.9894227294903
        },
        "claude-sonnet-4-5-20250929": {
            "rating": 1424.1438866522274,
            "rating_q975": 1440.3832618981494,
            "rating_q025": 1407.9045114063053
        },
        "claude-opus-4-1-20250805": {
            "rating": 1423.9260168289873,
            "rating_q975": 1434.382128611239,
            "rating_q025": 1413.4699050467354
        },
        "grok-4.1": {
            "rating": 1423.6605029748443,
            "rating_q975": 1441.8682100317965,
            "rating_q025": 1405.4527959178922
        },
        "kimi-k2-thinking-turbo": {
            "rating": 1423.1765509075497,
            "rating_q975": 1443.2273964798105,
            "rating_q025": 1403.1257053352888
        },
        "amazon-nova-experimental-chat-10-20": {
            "rating": 1422.8995648967318,
            "rating_q975": 1448.5562474510155,
            "rating_q025": 1397.2428823424482
        },
        "qwen3-vl-235b-a22b-thinking": {
            "rating": 1421.7954234237284,
            "rating_q975": 1450.481920402276,
            "rating_q025": 1393.1089264451807
        },
        "deepseek-v3.1": {
            "rating": 1421.5317936648346,
            "rating_q975": 1439.7446459300445,
            "rating_q025": 1403.3189413996247
        },
        "deepseek-v3.2-exp": {
            "rating": 1421.1334509564822,
            "rating_q975": 1442.9679487069948,
            "rating_q025": 1399.2989532059696
        },
        "ernie-5.0-preview-1103": {
            "rating": 1420.24473764787,
            "rating_q975": 1448.9456229174982,
            "rating_q025": 1391.5438523782416
        },
        "deepseek-v3.1-thinking": {
            "rating": 1420.106579307145,
            "rating_q975": 1442.1770750287822,
            "rating_q025": 1398.0360835855079
        },
        "grok-4-fast-chat": {
            "rating": 1418.1863733396144,
            "rating_q975": 1446.7663864322697,
            "rating_q025": 1389.6063602469592
        },
        "amazon-nova-experimental-chat-10-09": {
            "rating": 1417.5419086047093,
            "rating_q975": 1445.769750952491,
            "rating_q025": 1389.3140662569276
        },
        "deepseek-v3.1-terminus-thinking": {
            "rating": 1415.6563458762228,
            "rating_q975": 1456.8550760079895,
            "rating_q025": 1374.457615744456
        },
        "gemini-2.5-flash": {
            "rating": 1415.6551200538886,
            "rating_q975": 1424.466808268002,
            "rating_q025": 1406.8434318397751
        },
        "gpt-4.5-preview-2025-02-27": {
            "rating": 1415.4826881975582,
            "rating_q975": 1430.4784243247805,
            "rating_q025": 1400.486952070336
        },
        "mistral-large-3": {
            "rating": 1415.058546150175,
            "rating_q975": 1443.982637948282,
            "rating_q025": 1386.1344543520681
        },
        "qwen3-235b-a22b-thinking-2507": {
            "rating": 1414.8711240112234,
            "rating_q975": 1439.1322979486881,
            "rating_q025": 1390.6099500737587
        },
        "mistral-medium-2508": {
            "rating": 1414.4291709784418,
            "rating_q975": 1425.9575204424773,
            "rating_q025": 1402.9008215144063
        },
        "deepseek-v3.2-thinking": {
            "rating": 1413.4900945087481,
            "rating_q975": 1444.791808353139,
            "rating_q025": 1382.1883806643573
        },
        "gpt-5-chat": {
            "rating": 1409.7843278169644,
            "rating_q975": 1423.3959329922618,
            "rating_q025": 1396.172722641667
        },
        "hunyuan-t1-20250711": {
            "rating": 1409.2188776325263,
            "rating_q975": 1447.4259391321177,
            "rating_q025": 1371.0118161329349
        },
        "mai-1-preview": {
            "rating": 1407.4513987541295,
            "rating_q975": 1426.6733652754706,
            "rating_q025": 1388.2294322327884
        },
        "qwen3-next-80b-a3b-thinking": {
            "rating": 1404.5397577693795,
            "rating_q975": 1424.117305309299,
            "rating_q025": 1384.9622102294602
        },
        "gpt-5-high": {
            "rating": 1404.3880007581474,
            "rating_q975": 1417.9266497855049,
            "rating_q025": 1390.84935173079
        },
        "chatgpt-4o-latest-20250326": {
            "rating": 1404.361164526654,
            "rating_q975": 1413.1426819447395,
            "rating_q025": 1395.5796471085685
        },
        "deepseek-r1-0528": {
            "rating": 1403.2425694288168,
            "rating_q975": 1422.5805800149487,
            "rating_q025": 1383.9045588426848
        },
        "qwen3-32b": {
            "rating": 1403.1350684947372,
            "rating_q975": 1433.4669087357197,
            "rating_q025": 1372.8032282537547
        },
        "qwen3-235b-a22b": {
            "rating": 1403.0197241339047,
            "rating_q975": 1416.8238463781158,
            "rating_q025": 1389.2156018896935
        },
        "glm-4.5-air": {
            "rating": 1402.9336278922538,
            "rating_q975": 1417.7902579758643,
            "rating_q025": 1388.0769978086432
        },
        "grok-4-fast-reasoning": {
            "rating": 1402.9319820862402,
            "rating_q975": 1421.1938256262995,
            "rating_q025": 1384.6701385461809
        },
        "deepseek-v3.1-terminus": {
            "rating": 1401.3176777961935,
            "rating_q975": 1439.9267993633762,
            "rating_q025": 1362.7085562290108
        },
        "qwen3-235b-a22b-no-thinking": {
            "rating": 1400.990801917402,
            "rating_q975": 1412.7044364534042,
            "rating_q025": 1389.2771673813997
        },
        "grok-4-1-fast-reasoning": {
            "rating": 1400.1413465709418,
            "rating_q975": 1426.427404247399,
            "rating_q025": 1373.8552888944846
        },
        "o3-mini-high": {
            "rating": 1399.0924614697337,
            "rating_q975": 1412.0171932316912,
            "rating_q025": 1386.1677297077763
        },
        "kimi-k2-0905-preview": {
            "rating": 1398.8321605946435,
            "rating_q975": 1419.685391216257,
            "rating_q025": 1377.97892997303
        },
        "qwen3-30b-a3b-instruct-2507": {
            "rating": 1398.6023908676511,
            "rating_q975": 1413.4779933498442,
            "rating_q025": 1383.7267883854581
        },
        "gpt-5.1": {
            "rating": 1398.212775786238,
            "rating_q975": 1417.2210585518412,
            "rating_q025": 1379.2044930206346
        },
        "nvidia-llama-3.3-nemotron-super-49b-v1.5": {
            "rating": 1396.9330750034756,
            "rating_q975": 1434.6404016026293,
            "rating_q025": 1359.2257484043218
        },
        "deepseek-r1": {
            "rating": 1396.2674680811258,
            "rating_q975": 1409.9413351389699,
            "rating_q025": 1382.5936010232817
        },
        "claude-opus-4-20250514-thinking-16k": {
            "rating": 1394.5317961032315,
            "rating_q975": 1406.6073341354613,
            "rating_q025": 1382.4562580710017
        },
        "grok-3-preview-02-24": {
            "rating": 1393.2942663725805,
            "rating_q975": 1403.9701718454075,
            "rating_q025": 1382.6183608997535
        },
        "minimax-m1": {
            "rating": 1393.2634049118499,
            "rating_q975": 1406.3284335314474,
            "rating_q025": 1380.1983762922523
        },
        "o4-mini-2025-04-16": {
            "rating": 1392.4436968444547,
            "rating_q975": 1402.9753250166914,
            "rating_q025": 1381.912068672218
        },
        "o1-2024-12-17": {
            "rating": 1391.2380817283322,
            "rating_q975": 1401.6526222907585,
            "rating_q025": 1380.823541165906
        },
        "gpt-oss-120b": {
            "rating": 1389.886345969309,
            "rating_q975": 1403.7435243520515,
            "rating_q025": 1376.0291675865667
        },
        "grok-3-mini-high": {
            "rating": 1388.7674940529362,
            "rating_q975": 1406.5312131935652,
            "rating_q025": 1371.003774912307
        },
        "claude-haiku-4-5-20251001": {
            "rating": 1386.7832476178812,
            "rating_q975": 1402.063202317955,
            "rating_q025": 1371.5032929178074
        },
        "gpt-5-mini-high": {
            "rating": 1386.7157041191365,
            "rating_q975": 1402.220210132772,
            "rating_q025": 1371.211198105501
        },
        "claude-sonnet-4-20250514-thinking-32k": {
            "rating": 1380.0982861385285,
            "rating_q975": 1392.7231995219604,
            "rating_q025": 1367.4733727550965
        },
        "deepseek-v3-0324": {
            "rating": 1378.2478275575554,
            "rating_q975": 1388.3071435975828,
            "rating_q025": 1368.188511517528
        },
        "o3-mini": {
            "rating": 1378.1719938547387,
            "rating_q975": 1386.3711074494577,
            "rating_q025": 1369.9728802600198
        },
        "gemini-2.5-flash-lite-preview-09-2025-no-thinking": {
            "rating": 1377.5849292030268,
            "rating_q975": 1392.1606795236178,
            "rating_q025": 1363.009178882436
        },
        "o1-preview": {
            "rating": 1376.364031282333,
            "rating_q975": 1385.5579722264115,
            "rating_q025": 1367.1700903382543
        },
        "kimi-k2-0711-preview": {
            "rating": 1374.7912596656463,
            "rating_q975": 1388.5496243460439,
            "rating_q025": 1361.0328949852487
        },
        "claude-opus-4-20250514": {
            "rating": 1374.3456575751197,
            "rating_q975": 1385.1254698692064,
            "rating_q025": 1363.565845281033
        },
        "ling-flash-2.0": {
            "rating": 1373.9071095104803,
            "rating_q975": 1400.5866722543303,
            "rating_q025": 1347.2275467666302
        },
        "step-3": {
            "rating": 1372.885858920447,
            "rating_q975": 1404.8162145632043,
            "rating_q025": 1340.9555032776896
        },
        "qwen2.5-max": {
            "rating": 1372.0452400132006,
            "rating_q975": 1381.5027509464912,
            "rating_q025": 1362.5877290799099
        },
        "grok-3-mini-beta": {
            "rating": 1371.1191848510837,
            "rating_q975": 1384.9588850936343,
            "rating_q025": 1357.279484608533
        },
        "nova-2-lite": {
            "rating": 1370.3302559977947,
            "rating_q975": 1400.742270668262,
            "rating_q025": 1339.9182413273272
        },
        "qwen3-coder-480b-a35b-instruct": {
            "rating": 1369.9145429118848,
            "rating_q975": 1384.8510804238244,
            "rating_q025": 1354.9780053999452
        },
        "gpt-4.1-2025-04-14": {
            "rating": 1369.4470390470067,
            "rating_q975": 1379.473986154094,
            "rating_q025": 1359.4200919399193
        },
        "gemini-2.5-flash-lite-preview-06-17-thinking": {
            "rating": 1369.2761419635747,
            "rating_q975": 1381.4571964372362,
            "rating_q025": 1357.095087489913
        },
        "llama-3.1-nemotron-ultra-253b-v1": {
            "rating": 1364.384870100719,
            "rating_q975": 1402.4504157393158,
            "rating_q025": 1326.319324462122
        },
        "qwen3-30b-a3b": {
            "rating": 1361.7604920981814,
            "rating_q975": 1375.025681071026,
            "rating_q025": 1348.495303125337
        },
        "qwq-32b": {
            "rating": 1361.6324577850423,
            "rating_q975": 1374.7557374952435,
            "rating_q025": 1348.5091780748412
        },
        "o1-mini": {
            "rating": 1361.6095531326605,
            "rating_q975": 1368.8435266359797,
            "rating_q025": 1354.3755796293412
        },
        "hunyuan-turbos-20250416": {
            "rating": 1360.9789040826627,
            "rating_q975": 1379.8862337129833,
            "rating_q025": 1342.071574452342
        },
        "claude-sonnet-4-20250514": {
            "rating": 1360.8856955443582,
            "rating_q975": 1372.2205909934628,
            "rating_q025": 1349.5508000952536
        },
        "ring-flash-2.0": {
            "rating": 1358.82148478229,
            "rating_q975": 1385.9068804072633,
            "rating_q025": 1331.7360891573169
        },
        "minimax-m2": {
            "rating": 1358.2770685602147,
            "rating_q975": 1392.8821187511649,
            "rating_q025": 1323.6720183692646
        },
        "mistral-medium-2505": {
            "rating": 1355.8573934489157,
            "rating_q975": 1367.4727360739264,
            "rating_q025": 1344.242050823905
        },
        "glm-4.5v": {
            "rating": 1354.4010613847092,
            "rating_q975": 1388.9747798012784,
            "rating_q025": 1319.82734296814
        },
        "gemini-2.0-flash-001": {
            "rating": 1353.4420549015736,
            "rating_q975": 1362.022644496755,
            "rating_q025": 1344.8614653063921
        },
        "mistral-small-2506": {
            "rating": 1347.766306505062,
            "rating_q975": 1364.8609198363574,
            "rating_q025": 1330.6716931737665
        },
        "gpt-4.1-mini-2025-04-14": {
            "rating": 1346.38706024276,
            "rating_q975": 1357.2983221606355,
            "rating_q025": 1335.4757983248846
        },
        "claude-3-7-sonnet-20250219-thinking-32k": {
            "rating": 1342.6675922377674,
            "rating_q975": 1353.4370022065125,
            "rating_q025": 1331.8981822690223
        },
        "qwen-plus-0125": {
            "rating": 1328.5612669763393,
            "rating_q975": 1347.63741424851,
            "rating_q025": 1309.4851197041687
        },
        "gpt-5-nano-high": {
            "rating": 1326.2564615754047,
            "rating_q975": 1352.9233952015586,
            "rating_q025": 1299.5895279492509
        },
        "step-1o-turbo-202506": {
            "rating": 1322.7412445201528,
            "rating_q975": 1345.0528602880656,
            "rating_q025": 1300.42962875224
        },
        "claude-3-7-sonnet-20250219": {
            "rating": 1320.3543784001947,
            "rating_q975": 1329.9921017727795,
            "rating_q025": 1310.71665502761
        },
        "gpt-oss-20b": {
            "rating": 1319.535972156638,
            "rating_q975": 1341.5928722247957,
            "rating_q025": 1297.4790720884805
        },
        "gemini-1.5-pro-002": {
            "rating": 1318.3453383939666,
            "rating_q975": 1325.0545594842536,
            "rating_q025": 1311.6361173036796
        },
        "gemma-3-27b-it": {
            "rating": 1315.5651175993812,
            "rating_q975": 1324.7718113424587,
            "rating_q025": 1306.3584238563037
        },
        "deepseek-v3": {
            "rating": 1314.3608068138985,
            "rating_q975": 1324.6496960221843,
            "rating_q025": 1304.0719176056127
        },
        "gemini-2.0-flash-lite-preview-02-05": {
            "rating": 1313.3947018227848,
            "rating_q975": 1323.3192381522026,
            "rating_q025": 1303.470165493367
        },
        "gemma-3-12b-it": {
            "rating": 1312.7075353478986,
            "rating_q975": 1339.8080567117945,
            "rating_q025": 1285.6070139840026
        },
        "claude-3-5-sonnet-20241022": {
            "rating": 1309.9252200259903,
            "rating_q975": 1315.8389025702,
            "rating_q025": 1304.0115374817806
        },
        "step-2-16k-exp-202412": {
            "rating": 1308.1399368573975,
            "rating_q975": 1327.7703398151361,
            "rating_q025": 1288.509533899659
        },
        "claude-3-5-sonnet-20240620": {
            "rating": 1306.8607890673359,
            "rating_q975": 1313.6340612639215,
            "rating_q025": 1300.0875168707503
        },
        "llama-4-maverick-17b-128e-instruct": {
            "rating": 1305.5760484967782,
            "rating_q975": 1316.0816764428273,
            "rating_q025": 1295.070420550729
        },
        "command-a-03-2025": {
            "rating": 1304.8653136372714,
            "rating_q975": 1313.932110507331,
            "rating_q025": 1295.7985167672118
        },
        "athene-v2-chat": {
            "rating": 1303.370500384696,
            "rating_q975": 1312.3733333748194,
            "rating_q025": 1294.3676673945727
        },
        "yi-lightning": {
            "rating": 1303.25718476586,
            "rating_q975": 1312.572004315856,
            "rating_q025": 1293.9423652158641
        },
        "qwen2.5-plus-1127": {
            "rating": 1301.4146752473412,
            "rating_q975": 1314.8147268252587,
            "rating_q025": 1288.0146236694236
        },
        "hunyuan-turbos-20250226": {
            "rating": 1296.402764456716,
            "rating_q975": 1327.7766882927706,
            "rating_q025": 1265.0288406206616
        },
        "llama-4-scout-17b-16e-instruct": {
            "rating": 1294.4011031490213,
            "rating_q975": 1307.334645843248,
            "rating_q025": 1281.4675604547947
        },
        "deepseek-v2.5-1210": {
            "rating": 1291.7548357054543,
            "rating_q975": 1308.1190258466452,
            "rating_q025": 1275.3906455642634
        },
        "glm-4-plus-0111": {
            "rating": 1290.6306377507067,
            "rating_q975": 1309.6887507745228,
            "rating_q025": 1271.5725247268906
        },
        "gpt-4o-2024-08-06": {
            "rating": 1288.7406685992844,
            "rating_q975": 1296.1843220566805,
            "rating_q025": 1281.2970151418883
        },
        "gpt-4o-2024-05-13": {
            "rating": 1287.9004759461636,
            "rating_q975": 1294.0460599354508,
            "rating_q025": 1281.7548919568765
        },
        "grok-2-2024-08-13": {
            "rating": 1286.6920601727006,
            "rating_q975": 1293.2819506009826,
            "rating_q025": 1280.1021697444187
        },
        "qwen2.5-72b-instruct": {
            "rating": 1285.9943719827666,
            "rating_q975": 1293.636313212266,
            "rating_q025": 1278.352430753267
        },
        "llama-3.1-405b-instruct-fp8": {
            "rating": 1285.0855592882112,
            "rating_q975": 1291.9631723102543,
            "rating_q025": 1278.2079462661682
        },
        "hunyuan-large-2025-02-10": {
            "rating": 1284.1708991676305,
            "rating_q975": 1308.063873992168,
            "rating_q025": 1260.277924343093
        },
        "llama-3.1-405b-instruct-bf16": {
            "rating": 1281.3556896664215,
            "rating_q975": 1288.796349082466,
            "rating_q025": 1273.9150302503772
        },
        "hunyuan-large-vision": {
            "rating": 1280.6526854906783,
            "rating_q975": 1309.4881479106002,
            "rating_q025": 1251.8172230707564
        },
        "hunyuan-standard-2025-02-10": {
            "rating": 1278.3375810015782,
            "rating_q975": 1302.1866628456198,
            "rating_q025": 1254.4884991575366
        },
        "qwen-max-0919": {
            "rating": 1278.3016322841718,
            "rating_q975": 1289.7843060143953,
            "rating_q025": 1266.8189585539483
        },
        "gpt-4.1-nano-2025-04-14": {
            "rating": 1278.1978668231523,
            "rating_q975": 1301.3288603956653,
            "rating_q025": 1255.0668732506392
        },
        "glm-4-plus": {
            "rating": 1277.9512329689187,
            "rating_q975": 1287.4048182292381,
            "rating_q025": 1268.4976477085993
        },
        "claude-3-opus-20240229": {
            "rating": 1275.6081802719625,
            "rating_q975": 1281.257707319389,
            "rating_q025": 1269.958653224536
        },
        "hunyuan-turbo-0110": {
            "rating": 1275.5598858996495,
            "rating_q975": 1306.3721051900768,
            "rating_q025": 1244.7476666092223
        },
        "gemini-advanced-0514": {
            "rating": 1275.1620970815588,
            "rating_q975": 1284.1511273056835,
            "rating_q025": 1266.1730668574342
        },
        "gpt-4-turbo-2024-04-09": {
            "rating": 1275.1504277429067,
            "rating_q975": 1282.1124628605694,
            "rating_q025": 1268.188392625244
        },
        "deepseek-v2.5": {
            "rating": 1274.5294498414125,
            "rating_q975": 1283.7914571884692,
            "rating_q025": 1265.267442494356
        },
        "llama-3.1-nemotron-70b-instruct": {
            "rating": 1274.3302076492937,
            "rating_q975": 1290.9500953205281,
            "rating_q025": 1257.7103199780593
        },
        "gemini-1.5-pro-001": {
            "rating": 1273.3632869753292,
            "rating_q975": 1280.6404926435803,
            "rating_q025": 1266.086081307078
        },
        "gemini-1.5-flash-002": {
            "rating": 1272.8616577245907,
            "rating_q975": 1280.87786257814,
            "rating_q025": 1264.8454528710415
        },
        "gpt-4-1106-preview": {
            "rating": 1272.7062205236498,
            "rating_q975": 1279.8906699151853,
            "rating_q025": 1265.5217711321143
        },
        "gpt-4-0125-preview": {
            "rating": 1271.2990969201653,
            "rating_q975": 1278.5355304026386,
            "rating_q025": 1264.062663437692
        },
        "llama-3.3-70b-instruct": {
            "rating": 1270.9755102303147,
            "rating_q975": 1278.1696841057296,
            "rating_q025": 1263.7813363548998
        },
        "gpt-4o-mini-2024-07-18": {
            "rating": 1270.5911687389284,
            "rating_q975": 1276.8655541499013,
            "rating_q025": 1264.3167833279556
        },
        "grok-2-mini-2024-08-13": {
            "rating": 1268.7087408390453,
            "rating_q975": 1275.7226077628102,
            "rating_q025": 1261.6948739152804
        },
        "mistral-small-3.1-24b-instruct-2503": {
            "rating": 1266.5781940691215,
            "rating_q975": 1279.2981059332592,
            "rating_q025": 1253.8582822049839
        },
        "mistral-large-2407": {
            "rating": 1265.4124161462387,
            "rating_q975": 1272.8858006911748,
            "rating_q025": 1257.9390316013025
        },
        "mistral-large-2411": {
            "rating": 1264.0853060026807,
            "rating_q975": 1272.9417708270346,
            "rating_q025": 1255.2288411783268
        },
        "gemma-3n-e4b-it": {
            "rating": 1261.417977132428,
            "rating_q975": 1275.8303288985765,
            "rating_q025": 1247.0056253662794
        },
        "amazon-nova-pro-v1.0": {
            "rating": 1255.0236393211926,
            "rating_q975": 1264.4563053910113,
            "rating_q025": 1245.590973251374
        },
        "llama-3.1-70b-instruct": {
            "rating": 1254.7130490165855,
            "rating_q975": 1261.646228857397,
            "rating_q025": 1247.779869175774
        },
        "qwen2.5-coder-32b-instruct": {
            "rating": 1254.045954834469,
            "rating_q975": 1273.037667835513,
            "rating_q025": 1235.054241833425
        },
        "magistral-medium-2506": {
            "rating": 1254.0154061541928,
            "rating_q975": 1279.25679047728,
            "rating_q025": 1228.7740218311055
        },
        "phi-4": {
            "rating": 1249.2309849993321,
            "rating_q975": 1259.3619509186733,
            "rating_q025": 1239.100019079991
        },
        "claude-3-5-haiku-20241022": {
            "rating": 1248.5450766680756,
            "rating_q975": 1255.5998232807829,
            "rating_q025": 1241.4903300553683
        },
        "deepseek-coder-v2": {
            "rating": 1244.4741519949534,
            "rating_q975": 1257.6885387961713,
            "rating_q025": 1231.2597651937356
        },
        "gemma-3-4b-it": {
            "rating": 1243.9477211513354,
            "rating_q975": 1272.1780273068737,
            "rating_q025": 1215.717414995797
        },
        "mistral-small-24b-instruct-2501": {
            "rating": 1243.6952162804032,
            "rating_q975": 1256.7714698593763,
            "rating_q025": 1230.61896270143
        },
        "llama-3.1-tulu-3-70b": {
            "rating": 1243.6287566921492,
            "rating_q975": 1267.898877979134,
            "rating_q025": 1219.3586354051643
        },
        "hunyuan-standard-256k": {
            "rating": 1239.0151024920724,
            "rating_q975": 1267.3001732443477,
            "rating_q025": 1210.7300317397971
        },
        "qwen2-72b-instruct": {
            "rating": 1237.8917331286218,
            "rating_q975": 1246.7675399322352,
            "rating_q025": 1229.0159263250084
        },
        "athene-70b-0725": {
            "rating": 1234.55730010839,
            "rating_q975": 1244.5057456587583,
            "rating_q025": 1224.608854558022
        },
        "gpt-4-0314": {
            "rating": 1233.5318201567757,
            "rating_q975": 1242.7100462497458,
            "rating_q025": 1224.3535940638055
        },
        "llama-3.1-nemotron-51b-instruct": {
            "rating": 1233.4036965266387,
            "rating_q975": 1255.7950468314893,
            "rating_q025": 1211.012346221788
        },
        "gemini-1.5-flash-001": {
            "rating": 1232.368334589371,
            "rating_q975": 1239.766375520869,
            "rating_q025": 1224.970293657873
        },
        "amazon-nova-lite-v1.0": {
            "rating": 1230.259879707421,
            "rating_q975": 1240.675080818545,
            "rating_q025": 1219.8446785962972
        },
        "reka-core-20240904": {
            "rating": 1225.7032500081555,
            "rating_q975": 1239.6671289593687,
            "rating_q025": 1211.7393710569422
        },
        "jamba-1.5-large": {
            "rating": 1225.300889211279,
            "rating_q975": 1240.4057608517846,
            "rating_q025": 1210.1960175707732
        },
        "llama-3-70b-instruct": {
            "rating": 1221.76837804061,
            "rating_q975": 1228.5210583152752,
            "rating_q025": 1215.0156977659449
        },
        "glm-4-0520": {
            "rating": 1220.692416208219,
            "rating_q975": 1235.8671844911278,
            "rating_q025": 1205.51764792531
        },
        "gpt-4-0613": {
            "rating": 1220.683143449809,
            "rating_q975": 1228.4683470572081,
            "rating_q025": 1212.8979398424099
        },
        "nemotron-4-340b-instruct": {
            "rating": 1219.826689707817,
            "rating_q975": 1231.389255385756,
            "rating_q025": 1208.2641240298778
        },
        "qwq-32b-preview": {
            "rating": 1218.1391261182202,
            "rating_q975": 1242.3557965843745,
            "rating_q025": 1193.922455652066
        },
        "claude-3-sonnet-20240229": {
            "rating": 1217.1129945289435,
            "rating_q975": 1224.539681604099,
            "rating_q025": 1209.686307453788
        },
        "gemma-2-27b-it": {
            "rating": 1215.7743362579367,
            "rating_q975": 1221.8891363301314,
            "rating_q025": 1209.6595361857421
        },
        "olmo-2-0325-32b-instruct": {
            "rating": 1212.394255454576,
            "rating_q975": 1240.7661987962265,
            "rating_q025": 1184.0223121129256
        },
        "amazon-nova-micro-v1.0": {
            "rating": 1210.7789051609684,
            "rating_q975": 1221.1433045567608,
            "rating_q025": 1200.414505765176
        },
        "gemini-1.5-flash-8b-001": {
            "rating": 1210.041411539379,
            "rating_q975": 1217.946170923243,
            "rating_q025": 1202.1366521555149
        },
        "mistral-large-2402": {
            "rating": 1203.3674704479943,
            "rating_q975": 1211.8253298961677,
            "rating_q025": 1194.9096109998209
        },
        "c4ai-aya-expanse-32b": {
            "rating": 1202.6861084757236,
            "rating_q975": 1211.8183904755851,
            "rating_q025": 1193.553826475862
        },
        "llama-3.1-tulu-3-8b": {
            "rating": 1199.1830464863383,
            "rating_q975": 1224.2140230291657,
            "rating_q025": 1174.152069943511
        },
        "reka-flash-20240904": {
            "rating": 1199.0872598966776,
            "rating_q975": 1212.7698760117473,
            "rating_q025": 1185.4046437816078
        },
        "claude-3-haiku-20240307": {
            "rating": 1191.9845460842243,
            "rating_q975": 1198.7098308784964,
            "rating_q025": 1185.2592612899523
        },
        "ministral-8b-2410": {
            "rating": 1191.8272560532596,
            "rating_q975": 1211.188828921339,
            "rating_q025": 1172.46568318518
        },
        "command-r-plus-08-2024": {
            "rating": 1191.7472512838917,
            "rating_q975": 1205.2251804479558,
            "rating_q025": 1178.2693221198276
        },
        "qwen1.5-110b-chat": {
            "rating": 1188.8616883686461,
            "rating_q975": 1199.742542502858,
            "rating_q025": 1177.9808342344343
        },
        "mixtral-8x22b-instruct-v0.1": {
            "rating": 1187.8073618353203,
            "rating_q975": 1196.1790730044572,
            "rating_q025": 1179.4356506661834
        },
        "gemma-2-9b-it": {
            "rating": 1186.9418142059542,
            "rating_q975": 1193.9403929849952,
            "rating_q025": 1179.9432354269131
        },
        "yi-1.5-34b-chat": {
            "rating": 1185.2634051824875,
            "rating_q975": 1195.8517355191107,
            "rating_q025": 1174.6750748458644
        },
        "internlm2_5-20b-chat": {
            "rating": 1184.360901066005,
            "rating_q975": 1198.8144350812433,
            "rating_q025": 1169.9073670507667
        },
        "mistral-medium": {
            "rating": 1183.3072525307134,
            "rating_q975": 1193.604622693435,
            "rating_q025": 1173.0098823679918
        },
        "llama-3.1-8b-instruct": {
            "rating": 1183.084188493308,
            "rating_q975": 1190.4093164389783,
            "rating_q025": 1175.7590605476375
        },
        "phi-3-medium-4k-instruct": {
            "rating": 1177.396905810072,
            "rating_q975": 1187.463842478379,
            "rating_q025": 1167.3299691417649
        },
        "gemma-2-9b-it-simpo": {
            "rating": 1176.3789042450635,
            "rating_q975": 1191.1644296307265,
            "rating_q025": 1161.5933788594004
        },
        "reka-flash-21b-20240226-online": {
            "rating": 1172.0630024981442,
            "rating_q975": 1185.4069594341975,
            "rating_q025": 1158.719045562091
        },
        "c4ai-aya-expanse-8b": {
            "rating": 1171.804252813032,
            "rating_q975": 1186.4980014169137,
            "rating_q025": 1157.1105042091503
        },
        "command-r-plus": {
            "rating": 1167.9139965697018,
            "rating_q975": 1175.7859644307555,
            "rating_q025": 1160.042028708648
        },
        "qwen1.5-72b-chat": {
            "rating": 1167.528951551595,
            "rating_q975": 1176.6945287659996,
            "rating_q025": 1158.3633743371902
        },
        "jamba-1.5-mini": {
            "rating": 1164.632437468251,
            "rating_q975": 1180.3222094046089,
            "rating_q025": 1148.9426655318932
        },
        "granite-3.1-2b-instruct": {
            "rating": 1162.2508504677394,
            "rating_q975": 1188.2422744101955,
            "rating_q025": 1136.2594265252833
        },
        "reka-flash-21b-20240226": {
            "rating": 1159.6059243011318,
            "rating_q975": 1170.536748826622,
            "rating_q025": 1148.6750997756417
        },
        "qwen1.5-32b-chat": {
            "rating": 1158.9503124049359,
            "rating_q975": 1170.1857072537628,
            "rating_q025": 1147.714917556109
        },
        "command-r-08-2024": {
            "rating": 1158.9491219693775,
            "rating_q975": 1172.1326210620923,
            "rating_q025": 1145.7656228766627
        },
        "granite-3.1-8b-instruct": {
            "rating": 1156.9422822642093,
            "rating_q975": 1184.676699296292,
            "rating_q025": 1129.2078652321266
        },
        "llama-3-8b-instruct": {
            "rating": 1155.3361978923554,
            "rating_q975": 1162.5430458695432,
            "rating_q025": 1148.1293499151675
        },
        "phi-3-mini-4k-instruct-june-2024": {
            "rating": 1155.3273864992807,
            "rating_q975": 1168.5454950987976,
            "rating_q025": 1142.1092778997638
        },
        "phi-3-small-8k-instruct": {
            "rating": 1154.2097865595297,
            "rating_q975": 1166.5149347079312,
            "rating_q025": 1141.9046384111282
        },
        "zephyr-orpo-141b-A35b-v0.1": {
            "rating": 1152.260071238451,
            "rating_q975": 1174.3447340118241,
            "rating_q025": 1130.175408465078
        },
        "mixtral-8x7b-instruct-v0.1": {
            "rating": 1150.7809717126959,
            "rating_q975": 1158.7669977874255,
            "rating_q025": 1142.7949456379663
        },
        "dbrx-instruct-preview": {
            "rating": 1148.7341633948984,
            "rating_q975": 1159.7540527516337,
            "rating_q025": 1137.714274038163
        },
        "granite-3.0-8b-instruct": {
            "rating": 1146.8302921178938,
            "rating_q975": 1165.2940513100289,
            "rating_q025": 1128.3665329257587
        },
        "gpt-3.5-turbo-0125": {
            "rating": 1145.5030237013025,
            "rating_q975": 1153.376411478908,
            "rating_q025": 1137.629635923697
        },
        "gpt-3.5-turbo-1106": {
            "rating": 1144.90774400511,
            "rating_q975": 1159.7442820491976,
            "rating_q025": 1130.0712059610225
        },
        "gemma-2-2b-it": {
            "rating": 1138.4070352706976,
            "rating_q975": 1145.8008269096792,
            "rating_q025": 1131.013243631716
        },
        "gemini-pro-dev-api": {
            "rating": 1135.3165085193186,
            "rating_q975": 1148.8313933382797,
            "rating_q025": 1121.8016237003576
        },
        "gemini-pro": {
            "rating": 1133.4691012944634,
            "rating_q975": 1152.3740845845498,
            "rating_q025": 1114.564118004377
        },
        "llama-3.2-3b-instruct": {
            "rating": 1129.643751600283,
            "rating_q975": 1145.0218284889745,
            "rating_q025": 1114.2656747115914
        },
        "qwen1.5-14b-chat": {
            "rating": 1128.5836540218756,
            "rating_q975": 1141.6871122241905,
            "rating_q025": 1115.4801958195608
        },
        "starling-lm-7b-beta": {
            "rating": 1128.0301036747321,
            "rating_q975": 1141.5156636744402,
            "rating_q025": 1114.544543675024
        },
        "command-r": {
            "rating": 1124.324755414967,
            "rating_q975": 1133.2589961042163,
            "rating_q025": 1115.3905147257178
        },
        "granite-3.0-2b-instruct": {
            "rating": 1121.262608284367,
            "rating_q975": 1139.9426083786059,
            "rating_q025": 1102.582608190128
        },
        "wizardlm-70b": {
            "rating": 1119.738630698333,
            "rating_q975": 1138.7102197588572,
            "rating_q025": 1100.767041637809
        },
        "yi-34b-chat": {
            "rating": 1117.2373987532699,
            "rating_q975": 1130.1047734456163,
            "rating_q025": 1104.3700240609235
        },
        "phi-3-mini-4k-instruct": {
            "rating": 1116.031397423149,
            "rating_q975": 1127.8679783933264,
            "rating_q025": 1104.1948164529715
        },
        "snowflake-arctic-instruct": {
            "rating": 1113.0135042078764,
            "rating_q975": 1123.8384836164355,
            "rating_q025": 1102.1885247993173
        },
        "deepseek-llm-67b-chat": {
            "rating": 1110.6247229511491,
            "rating_q975": 1134.011552839702,
            "rating_q025": 1087.2378930625962
        },
        "tulu-2-dpo-70b": {
            "rating": 1110.4757890917174,
            "rating_q975": 1129.2290630593418,
            "rating_q025": 1091.722515124093
        },
        "gemma-1.1-7b-it": {
            "rating": 1110.3904836586798,
            "rating_q975": 1121.2741079532395,
            "rating_q025": 1099.5068593641201
        },
        "openchat-3.5-0106": {
            "rating": 1109.9759780634076,
            "rating_q975": 1123.195851262501,
            "rating_q025": 1096.7561048643142
        },
        "smollm2-1.7b-instruct": {
            "rating": 1108.3859330644812,
            "rating_q975": 1141.2958140196251,
            "rating_q025": 1075.4760521093372
        },
        "openhermes-2.5-mistral-7b": {
            "rating": 1101.0856579372976,
            "rating_q975": 1120.9267880013474,
            "rating_q025": 1081.2445278732478
        },
        "llama-2-70b-chat": {
            "rating": 1094.5446567434487,
            "rating_q975": 1104.3702296353117,
            "rating_q025": 1084.7190838515858
        },
        "phi-3-mini-128k-instruct": {
            "rating": 1093.2536243386335,
            "rating_q975": 1106.0442611025292,
            "rating_q025": 1080.4629875747378
        },
        "mistral-7b-instruct-v0.2": {
            "rating": 1089.8739203053958,
            "rating_q975": 1101.5833708611608,
            "rating_q025": 1078.1644697496308
        },
        "llama-3.2-1b-instruct": {
            "rating": 1089.2820226610581,
            "rating_q975": 1105.0462331672054,
            "rating_q025": 1073.5178121549109
        },
        "starling-lm-7b-alpha": {
            "rating": 1085.9003674313726,
            "rating_q975": 1101.2467605835666,
            "rating_q025": 1070.5539742791786
        },
        "qwen1.5-7b-chat": {
            "rating": 1082.9945380885297,
            "rating_q975": 1103.2427708814178,
            "rating_q025": 1062.7463052956416
        },
        "dolphin-2.2.1-mistral-7b": {
            "rating": 1080.2099072374267,
            "rating_q975": 1113.0957566285558,
            "rating_q025": 1047.3240578462976
        },
        "llama2-70b-steerlm-chat": {
            "rating": 1075.3546795137104,
            "rating_q975": 1101.9918632852423,
            "rating_q025": 1048.7174957421785
        },
        "vicuna-33b": {
            "rating": 1074.05153584542,
            "rating_q975": 1086.2507095780702,
            "rating_q025": 1061.8523621127697
        },
        "openchat-3.5": {
            "rating": 1073.7712447002998,
            "rating_q975": 1091.86861607378,
            "rating_q025": 1055.6738733268196
        },
        "qwen-14b-chat": {
            "rating": 1071.609636241637,
            "rating_q975": 1095.2273406260206,
            "rating_q025": 1047.9919318572533
        },
        "gemma-7b-it": {
            "rating": 1070.1083159001564,
            "rating_q975": 1086.246795472059,
            "rating_q025": 1053.969836328254
        },
        "llama-2-13b-chat": {
            "rating": 1069.0367844972852,
            "rating_q975": 1082.0962479949294,
            "rating_q025": 1055.977320999641
        },
        "solar-10.7b-instruct-v1.0": {
            "rating": 1067.4976312447002,
            "rating_q975": 1089.021069416546,
            "rating_q025": 1045.9741930728544
        },
        "nous-hermes-2-mixtral-8x7b-dpo": {
            "rating": 1064.2157285590447,
            "rating_q975": 1085.5267520097873,
            "rating_q025": 1042.904705108302
        },
        "codellama-34b-instruct": {
            "rating": 1059.8647381490505,
            "rating_q975": 1078.889762203963,
            "rating_q025": 1040.839714094138
        },
        "palm-2": {
            "rating": 1052.38772637989,
            "rating_q975": 1071.7049715638975,
            "rating_q025": 1033.0704811958824
        },
        "gemma-1.1-2b-it": {
            "rating": 1052.064549597486,
            "rating_q975": 1067.6851625822221,
            "rating_q025": 1036.4439366127497
        },
        "mpt-30b-chat": {
            "rating": 1049.340246735217,
            "rating_q975": 1083.6868498154677,
            "rating_q025": 1014.9936436549664
        },
        "llama-2-7b-chat": {
            "rating": 1045.9581829024498,
            "rating_q975": 1059.5546458063,
            "rating_q025": 1032.3617199985997
        },
        "zephyr-7b-beta": {
            "rating": 1043.8593219653685,
            "rating_q975": 1060.5538164762982,
            "rating_q025": 1027.1648274544389
        },
        "stripedhyena-nous-7b": {
            "rating": 1036.7577703955676,
            "rating_q975": 1056.8568396930457,
            "rating_q025": 1016.6587010980894
        },
        "guanaco-33b": {
            "rating": 1036.0951811819154,
            "rating_q975": 1069.0077241443198,
            "rating_q025": 1003.1826382195112
        },
        "vicuna-13b": {
            "rating": 1033.7454871640202,
            "rating_q975": 1047.1702627828693,
            "rating_q025": 1020.3207115451712
        },
        "mistral-7b-instruct": {
            "rating": 1031.655355519371,
            "rating_q975": 1050.2760239762085,
            "rating_q025": 1013.0346870625333
        },
        "qwen1.5-4b-chat": {
            "rating": 1029.1664142992895,
            "rating_q975": 1046.5830377730547,
            "rating_q025": 1011.7497908255243
        },
        "olmo-7b-instruct": {
            "rating": 1021.7166900208354,
            "rating_q975": 1040.4902561167057,
            "rating_q025": 1002.9431239249651
        },
        "wizardlm-13b": {
            "rating": 1020.5943590869776,
            "rating_q975": 1041.1107869933787,
            "rating_q025": 1000.0779311805766
        },
        "gemma-2b-it": {
            "rating": 1013.132595199098,
            "rating_q975": 1034.98693195261,
            "rating_q025": 991.2782584455861
        },
        "vicuna-7b": {
            "rating": 998.4474212325227,
            "rating_q975": 1019.8703896685129,
            "rating_q025": 977.0244527965326
        },
        "chatglm3-6b": {
            "rating": 992.24217894843,
            "rating_q975": 1015.605473767463,
            "rating_q025": 968.8788841293971
        },
        "gpt4all-13b-snoozy": {
            "rating": 944.413600389059,
            "rating_q975": 982.3804479853914,
            "rating_q025": 906.4467527927266
        },
        "koala-13b": {
            "rating": 935.3602203663794,
            "rating_q975": 956.5534612763034,
            "rating_q025": 914.1669794564554
        },
        "chatglm-6b": {
            "rating": 929.1276011958776,
            "rating_q975": 954.5951182879029,
            "rating_q025": 903.6600841038522
        },
        "RWKV-4-Raven-14B": {
            "rating": 925.3795560172399,
            "rating_q975": 949.7308291485065,
            "rating_q025": 901.0282828859733
        },
        "mpt-7b-chat": {
            "rating": 922.720790282487,
            "rating_q975": 948.2020306693902,
            "rating_q025": 897.2395498955838
        },
        "chatglm2-6b": {
            "rating": 917.6695636171107,
            "rating_q975": 952.7873026902316,
            "rating_q025": 882.5518245439898
        },
        "alpaca-13b": {
            "rating": 911.5374811713152,
            "rating_q975": 934.3582832358735,
            "rating_q025": 888.7166791067569
        },
        "oasst-pythia-12b": {
            "rating": 895.2670096500756,
            "rating_q975": 917.3157493325671,
            "rating_q025": 873.2182699675841
        },
        "dolly-v2-12b": {
            "rating": 874.9593227307555,
            "rating_q975": 903.8497640220954,
            "rating_q025": 846.0688814394156
        },
        "fastchat-t5-3b": {
            "rating": 865.0848352638785,
            "rating_q975": 891.0764089787347,
            "rating_q025": 839.0932615490224
        },
        "stablelm-tuned-alpha-7b": {
            "rating": 841.9913649473245,
            "rating_q975": 871.0509749187346,
            "rating_q025": 812.9317549759145
        },
        "llama-13b": {
            "rating": 839.7481005625634,
            "rating_q975": 872.9251770606448,
            "rating_q025": 806.571024064482
        }
    },
    "multiturn": {
        "gemini-3-pro": {
            "rating": 1488.312075178166,
            "rating_q975": 1500.6454041197246,
            "rating_q025": 1475.9787462366073
        },
        "claude-sonnet-4-5-20250929": {
            "rating": 1461.3299003306495,
            "rating_q975": 1471.372575853244,
            "rating_q025": 1451.287224808055
        },
        "gemini-2.5-pro": {
            "rating": 1460.3697735828175,
            "rating_q975": 1466.6784616615557,
            "rating_q025": 1454.0610855040793
        },
        "claude-opus-4-5-20251101": {
            "rating": 1458.9718111833993,
            "rating_q975": 1472.9819465796172,
            "rating_q025": 1444.9616757871813
        },
        "gpt-5.1-high": {
            "rating": 1454.827615775536,
            "rating_q975": 1467.4486536711552,
            "rating_q025": 1442.206577879917
        },
        "chatgpt-4o-latest-20250326": {
            "rating": 1452.2016538544785,
            "rating_q975": 1458.5628400032372,
            "rating_q025": 1445.84046770572
        },
        "qwen3-max-preview": {
            "rating": 1449.2366934072309,
            "rating_q975": 1458.2663051766058,
            "rating_q025": 1440.207081637856
        },
        "claude-sonnet-4-5-20250929-thinking-32k": {
            "rating": 1449.1982705633152,
            "rating_q975": 1458.5419264759114,
            "rating_q025": 1439.854614650719
        },
        "claude-opus-4-5-20251101-thinking-32k": {
            "rating": 1448.7350224649708,
            "rating_q975": 1463.42666866465,
            "rating_q025": 1434.0433762652917
        },
        "grok-4.1": {
            "rating": 1443.2324160387545,
            "rating_q975": 1454.6013687884304,
            "rating_q025": 1431.8634632890787
        },
        "gpt-4.5-preview-2025-02-27": {
            "rating": 1443.0432584888765,
            "rating_q975": 1456.4240827026324,
            "rating_q025": 1429.6624342751206
        },
        "claude-opus-4-1-20250805-thinking-16k": {
            "rating": 1442.2914540803308,
            "rating_q975": 1449.8080034851748,
            "rating_q025": 1434.7749046754868
        },
        "claude-opus-4-1-20250805": {
            "rating": 1437.1741971054817,
            "rating_q975": 1444.1861026942752,
            "rating_q025": 1430.1622915166881
        },
        "qwen3-max-2025-09-23": {
            "rating": 1434.9443705775245,
            "rating_q975": 1449.5141891892574,
            "rating_q025": 1420.3745519657916
        },
        "grok-4.1-thinking": {
            "rating": 1434.6579304413879,
            "rating_q975": 1446.055789789088,
            "rating_q025": 1423.2600710936877
        },
        "ernie-5.0-preview-1103": {
            "rating": 1432.3852696755869,
            "rating_q975": 1451.4974221708603,
            "rating_q025": 1413.2731171803134
        },
        "gpt-5.1": {
            "rating": 1429.8333525543667,
            "rating_q975": 1441.7004669033518,
            "rating_q025": 1417.9662382053816
        },
        "qwen3-235b-a22b-instruct-2507": {
            "rating": 1429.3524393239975,
            "rating_q975": 1436.3854503193377,
            "rating_q025": 1422.3194283286573
        },
        "qwen3-vl-235b-a22b-instruct": {
            "rating": 1427.1931089245838,
            "rating_q975": 1442.2590882536688,
            "rating_q025": 1412.127129595499
        },
        "deepseek-v3.2": {
            "rating": 1426.6324017223073,
            "rating_q975": 1443.9408497512543,
            "rating_q025": 1409.3239536933604
        },
        "mistral-large-3": {
            "rating": 1426.2762002502527,
            "rating_q975": 1443.5247389299304,
            "rating_q025": 1409.027661570575
        },
        "mistral-medium-2508": {
            "rating": 1425.746896403761,
            "rating_q975": 1433.2356406743233,
            "rating_q025": 1418.2581521331986
        },
        "glm-4.6": {
            "rating": 1425.657560129336,
            "rating_q975": 1435.4062651275146,
            "rating_q025": 1415.9088551311572
        },
        "gpt-5-chat": {
            "rating": 1424.8597438516135,
            "rating_q975": 1433.2287213386498,
            "rating_q025": 1416.4907663645772
        },
        "grok-3-preview-02-24": {
            "rating": 1424.4417270532692,
            "rating_q975": 1433.2616708696253,
            "rating_q025": 1415.6217832369132
        },
        "deepseek-v3.2-exp": {
            "rating": 1422.7121693299139,
            "rating_q975": 1435.869777937323,
            "rating_q025": 1409.5545607225047
        },
        "grok-4-fast-chat": {
            "rating": 1418.4153297101675,
            "rating_q975": 1435.2352870141426,
            "rating_q025": 1401.5953724061924
        },
        "glm-4.5": {
            "rating": 1417.7858936055802,
            "rating_q975": 1427.5409040006678,
            "rating_q025": 1408.0308832104927
        },
        "qwen3-next-80b-a3b-instruct": {
            "rating": 1416.6711695725578,
            "rating_q975": 1426.1626887123525,
            "rating_q025": 1407.179650432763
        },
        "grok-4-0709": {
            "rating": 1416.1917756496625,
            "rating_q975": 1423.8827958153906,
            "rating_q025": 1408.5007554839344
        },
        "deepseek-v3.2-exp-thinking": {
            "rating": 1413.6733187833447,
            "rating_q975": 1428.9817712749089,
            "rating_q025": 1398.3648662917806
        },
        "deepseek-v3.1-terminus-thinking": {
            "rating": 1413.375461130061,
            "rating_q975": 1437.3207164404225,
            "rating_q025": 1389.4302058196995
        },
        "hunyuan-vision-1.5-thinking": {
            "rating": 1412.4051811484644,
            "rating_q975": 1440.5114772225807,
            "rating_q025": 1384.2988850743482
        },
        "deepseek-v3.2-thinking": {
            "rating": 1410.8127600802493,
            "rating_q975": 1428.8322164757217,
            "rating_q025": 1392.793303684777
        },
        "kimi-k2-thinking-turbo": {
            "rating": 1410.355497724577,
            "rating_q975": 1422.0878012475218,
            "rating_q025": 1398.623194201632
        },
        "deepseek-v3.1-thinking": {
            "rating": 1407.9067230711796,
            "rating_q975": 1421.5598527403154,
            "rating_q025": 1394.2535934020439
        },
        "qwen3-235b-a22b-thinking-2507": {
            "rating": 1407.2050778532673,
            "rating_q975": 1422.6254912853647,
            "rating_q025": 1391.78466442117
        },
        "deepseek-r1-0528": {
            "rating": 1406.1139251440072,
            "rating_q975": 1416.876271349133,
            "rating_q025": 1395.3515789388814
        },
        "o3-2025-04-16": {
            "rating": 1405.6187354748652,
            "rating_q975": 1412.4062950742698,
            "rating_q025": 1398.8311758754605
        },
        "gemini-2.5-flash": {
            "rating": 1404.0963382585712,
            "rating_q975": 1410.2905736971593,
            "rating_q025": 1397.9021028199832
        },
        "claude-haiku-4-5-20251001": {
            "rating": 1403.3788350023501,
            "rating_q975": 1412.7550088438745,
            "rating_q025": 1394.0026611608257
        },
        "gpt-5-high": {
            "rating": 1402.600415759798,
            "rating_q975": 1411.4201673552698,
            "rating_q025": 1393.780664164326
        },
        "longcat-flash-chat": {
            "rating": 1402.4486189026927,
            "rating_q975": 1415.4092482300603,
            "rating_q025": 1389.4879895753252
        },
        "grok-4-fast-reasoning": {
            "rating": 1402.113309370939,
            "rating_q975": 1412.9021586630702,
            "rating_q025": 1391.324460078808
        },
        "deepseek-v3.1": {
            "rating": 1400.8288042112347,
            "rating_q975": 1412.529307874606,
            "rating_q025": 1389.1283005478633
        },
        "qwen3-235b-a22b-no-thinking": {
            "rating": 1397.9637329382315,
            "rating_q975": 1405.8380399808764,
            "rating_q025": 1390.0894258955866
        },
        "gpt-4.1-2025-04-14": {
            "rating": 1397.274112905001,
            "rating_q975": 1404.1750190783623,
            "rating_q025": 1390.3732067316396
        },
        "gemini-2.5-flash-preview-09-2025": {
            "rating": 1395.4679928194362,
            "rating_q975": 1404.1759765381405,
            "rating_q025": 1386.7600091007318
        },
        "claude-opus-4-20250514-thinking-16k": {
            "rating": 1393.288769287221,
            "rating_q975": 1401.444992391531,
            "rating_q025": 1385.1325461829108
        },
        "deepseek-r1": {
            "rating": 1389.7091352746131,
            "rating_q975": 1401.4590274169063,
            "rating_q025": 1377.95924313232
        },
        "deepseek-v3.1-terminus": {
            "rating": 1388.5799054968822,
            "rating_q975": 1410.931542797752,
            "rating_q025": 1366.2282681960126
        },
        "hunyuan-t1-20250711": {
            "rating": 1387.5962608020973,
            "rating_q975": 1409.343501657101,
            "rating_q025": 1365.8490199470937
        },
        "deepseek-v3-0324": {
            "rating": 1386.9248270110998,
            "rating_q975": 1394.1211824856825,
            "rating_q025": 1379.728471536517
        },
        "grok-4-1-fast-reasoning": {
            "rating": 1385.6513819558127,
            "rating_q975": 1400.2154640169042,
            "rating_q025": 1371.0872998947211
        },
        "hunyuan-turbos-20250416": {
            "rating": 1385.4320085662812,
            "rating_q975": 1399.444965610677,
            "rating_q025": 1371.4190515218854
        },
        "qwen3-vl-235b-a22b-thinking": {
            "rating": 1385.4239623344101,
            "rating_q975": 1401.9745449001587,
            "rating_q025": 1368.8733797686616
        },
        "claude-opus-4-20250514": {
            "rating": 1383.9695084117748,
            "rating_q975": 1391.5867721991892,
            "rating_q025": 1376.3522446243603
        },
        "mai-1-preview": {
            "rating": 1382.8060144123242,
            "rating_q975": 1394.1570107175598,
            "rating_q025": 1371.4550181070886
        },
        "mistral-medium-2505": {
            "rating": 1382.0835526607868,
            "rating_q975": 1390.3150552033594,
            "rating_q025": 1373.8520501182143
        },
        "qwen3-30b-a3b-instruct-2507": {
            "rating": 1382.0794631926115,
            "rating_q975": 1391.5766897569522,
            "rating_q025": 1372.5822366282707
        },
        "claude-sonnet-4-20250514-thinking-32k": {
            "rating": 1372.5537028921403,
            "rating_q975": 1380.8108095453663,
            "rating_q025": 1364.2965962389144
        },
        "kimi-k2-0711-preview": {
            "rating": 1372.1276438913608,
            "rating_q975": 1381.133363729931,
            "rating_q025": 1363.1219240527905
        },
        "glm-4.5-air": {
            "rating": 1371.5530644558746,
            "rating_q975": 1380.0825146607478,
            "rating_q025": 1363.0236142510014
        },
        "o1-preview": {
            "rating": 1367.6480085113185,
            "rating_q975": 1376.7739998807588,
            "rating_q025": 1358.5220171418782
        },
        "kimi-k2-0905-preview": {
            "rating": 1367.4886736565747,
            "rating_q975": 1380.5832919537384,
            "rating_q025": 1354.3940553594111
        },
        "minimax-m2": {
            "rating": 1367.4527571826577,
            "rating_q975": 1384.7546508706048,
            "rating_q025": 1350.1508634947106
        },
        "qwen3-coder-480b-a35b-instruct": {
            "rating": 1364.0733460203467,
            "rating_q975": 1373.831364206988,
            "rating_q025": 1354.3153278337054
        },
        "gpt-5-mini-high": {
            "rating": 1364.0590980941713,
            "rating_q975": 1373.2568393495537,
            "rating_q025": 1354.8613568387889
        },
        "qwen2.5-max": {
            "rating": 1363.644354845789,
            "rating_q975": 1371.995963315457,
            "rating_q025": 1355.292746376121
        },
        "gemini-2.5-flash-lite-preview-09-2025-no-thinking": {
            "rating": 1363.2032098239104,
            "rating_q975": 1372.0750663808092,
            "rating_q025": 1354.3313532670115
        },
        "qwen3-235b-a22b": {
            "rating": 1362.0165601902202,
            "rating_q975": 1371.1765588896114,
            "rating_q025": 1352.8565614908289
        },
        "claude-sonnet-4-20250514": {
            "rating": 1360.7894770999162,
            "rating_q975": 1368.5982828302538,
            "rating_q025": 1352.9806713695787
        },
        "gemini-2.5-flash-lite-preview-06-17-thinking": {
            "rating": 1359.9757359957346,
            "rating_q975": 1368.260872508102,
            "rating_q025": 1351.6905994833671
        },
        "amazon-nova-experimental-chat-10-20": {
            "rating": 1358.988320124863,
            "rating_q975": 1375.3826661778548,
            "rating_q025": 1342.5939740718713
        },
        "o1-2024-12-17": {
            "rating": 1354.2115098016234,
            "rating_q975": 1363.2030072240973,
            "rating_q025": 1345.2200123791495
        },
        "grok-3-mini-high": {
            "rating": 1353.9874692828967,
            "rating_q975": 1365.016190205866,
            "rating_q025": 1342.9587483599273
        },
        "gpt-4.1-mini-2025-04-14": {
            "rating": 1352.9098783856189,
            "rating_q975": 1360.5119669927628,
            "rating_q025": 1345.307789778475
        },
        "intellect-3": {
            "rating": 1351.1911080941147,
            "rating_q975": 1382.128563072249,
            "rating_q025": 1320.2536531159803
        },
        "grok-3-mini-beta": {
            "rating": 1351.0959673490204,
            "rating_q975": 1360.6618792321772,
            "rating_q025": 1341.5300554658636
        },
        "nova-2-lite": {
            "rating": 1350.4680473917679,
            "rating_q975": 1369.3287300767727,
            "rating_q025": 1331.607364706763
        },
        "o4-mini-2025-04-16": {
            "rating": 1350.3372667714407,
            "rating_q975": 1357.5606408273252,
            "rating_q025": 1343.1138927155562
        },
        "gemini-2.0-flash-001": {
            "rating": 1348.5946244107668,
            "rating_q975": 1355.7955934238205,
            "rating_q025": 1341.393655397713
        },
        "deepseek-v3": {
            "rating": 1348.195289931589,
            "rating_q975": 1357.8140327091414,
            "rating_q025": 1338.5765471540367
        },
        "mistral-small-2506": {
            "rating": 1345.455866537355,
            "rating_q975": 1356.0324707591906,
            "rating_q025": 1334.8792623155193
        },
        "gemma-3-27b-it": {
            "rating": 1345.3954428094955,
            "rating_q975": 1352.7353554168608,
            "rating_q025": 1338.0555302021303
        },
        "amazon-nova-experimental-chat-10-09": {
            "rating": 1342.7034188602756,
            "rating_q975": 1358.0933003360483,
            "rating_q025": 1327.313537384503
        },
        "qwen3-next-80b-a3b-thinking": {
            "rating": 1340.795838288115,
            "rating_q975": 1353.397935071503,
            "rating_q025": 1328.1937415047269
        },
        "command-a-03-2025": {
            "rating": 1338.4282135993037,
            "rating_q975": 1345.0654064960968,
            "rating_q025": 1331.7910207025107
        },
        "claude-3-7-sonnet-20250219": {
            "rating": 1337.4486432697872,
            "rating_q975": 1344.993538815207,
            "rating_q025": 1329.9037477243673
        },
        "minimax-m1": {
            "rating": 1336.7713633724643,
            "rating_q975": 1344.916432562378,
            "rating_q025": 1328.6262941825505
        },
        "step-1o-turbo-202506": {
            "rating": 1336.5691703967327,
            "rating_q975": 1352.3822930808187,
            "rating_q025": 1320.7560477126467
        },
        "claude-3-7-sonnet-20250219-thinking-32k": {
            "rating": 1336.271739642278,
            "rating_q975": 1344.2659874871156,
            "rating_q025": 1328.2774917974402
        },
        "step-3": {
            "rating": 1336.2675223469748,
            "rating_q975": 1353.901741485692,
            "rating_q025": 1318.6333032082578
        },
        "qwen-plus-0125": {
            "rating": 1336.1584228183997,
            "rating_q975": 1355.2472190314882,
            "rating_q025": 1317.0696266053112
        },
        "gpt-oss-120b": {
            "rating": 1335.5821316282402,
            "rating_q975": 1344.3287414449,
            "rating_q025": 1326.8355218115803
        },
        "gemma-3-12b-it": {
            "rating": 1333.9804037633774,
            "rating_q975": 1359.9831662300467,
            "rating_q025": 1307.977641296708
        },
        "glm-4.5v": {
            "rating": 1333.519510613469,
            "rating_q975": 1353.4904235034612,
            "rating_q025": 1313.5485977234769
        },
        "qwen3-32b": {
            "rating": 1330.6931419913144,
            "rating_q975": 1353.9333064463888,
            "rating_q025": 1307.45297753624
        },
        "nvidia-llama-3.3-nemotron-super-49b-v1.5": {
            "rating": 1329.2284768647064,
            "rating_q975": 1352.979694929244,
            "rating_q025": 1305.4772588001688
        },
        "ling-flash-2.0": {
            "rating": 1328.1963177401203,
            "rating_q975": 1345.2446440896163,
            "rating_q025": 1311.1479913906244
        },
        "claude-3-5-sonnet-20241022": {
            "rating": 1325.540879051601,
            "rating_q975": 1330.8738817933536,
            "rating_q025": 1320.2078763098484
        },
        "glm-4-plus-0111": {
            "rating": 1322.9419392410405,
            "rating_q975": 1342.3059191667182,
            "rating_q025": 1303.5779593153627
        },
        "o3-mini-high": {
            "rating": 1319.715765773945,
            "rating_q975": 1331.3669100924299,
            "rating_q025": 1308.06462145546
        },
        "llama-3.1-nemotron-ultra-253b-v1": {
            "rating": 1316.9383949880978,
            "rating_q975": 1347.401284164197,
            "rating_q025": 1286.4755058119986
        },
        "hunyuan-turbos-20250226": {
            "rating": 1316.3751543163912,
            "rating_q975": 1349.7630673735664,
            "rating_q025": 1282.987241259216
        },
        "gpt-5-nano-high": {
            "rating": 1315.1175689843153,
            "rating_q975": 1330.6533912411564,
            "rating_q025": 1299.5817467274742
        },
        "qwq-32b": {
            "rating": 1313.868558150994,
            "rating_q975": 1323.295007445027,
            "rating_q025": 1304.4421088569609
        },
        "llama-3.3-nemotron-49b-super-v1": {
            "rating": 1313.4181676261328,
            "rating_q975": 1345.754170499144,
            "rating_q025": 1281.0821647531216
        },
        "o1-mini": {
            "rating": 1312.8409202790242,
            "rating_q975": 1319.9374541773757,
            "rating_q025": 1305.7443863806727
        },
        "o3-mini": {
            "rating": 1311.7749821789662,
            "rating_q975": 1318.2823384991877,
            "rating_q025": 1305.2676258587446
        },
        "yi-lightning": {
            "rating": 1311.0380181530222,
            "rating_q975": 1320.7346542781286,
            "rating_q025": 1301.3413820279159
        },
        "qwen3-30b-a3b": {
            "rating": 1309.0200006378993,
            "rating_q975": 1318.0489602179857,
            "rating_q025": 1299.991041057813
        },
        "gemini-2.0-flash-lite-preview-02-05": {
            "rating": 1306.7740978899287,
            "rating_q975": 1316.3228606651685,
            "rating_q025": 1297.225335114689
        },
        "hunyuan-turbo-0110": {
            "rating": 1303.0040447444326,
            "rating_q975": 1332.7343380491684,
            "rating_q025": 1273.2737514396968
        },
        "gpt-4o-2024-05-13": {
            "rating": 1300.8787836227282,
            "rating_q975": 1307.2563951906807,
            "rating_q025": 1294.5011720547757
        },
        "claude-3-5-sonnet-20240620": {
            "rating": 1299.0399988474505,
            "rating_q975": 1305.9339172764908,
            "rating_q025": 1292.1460804184103
        },
        "qwen2.5-plus-1127": {
            "rating": 1297.9571443782515,
            "rating_q975": 1311.104510848678,
            "rating_q025": 1284.809777907825
        },
        "deepseek-v2.5-1210": {
            "rating": 1296.7400894092748,
            "rating_q975": 1312.963939770579,
            "rating_q025": 1280.5162390479707
        },
        "llama-3.1-405b-instruct-bf16": {
            "rating": 1296.4294567535967,
            "rating_q975": 1303.797039595258,
            "rating_q025": 1289.0618739119354
        },
        "gemini-1.5-pro-002": {
            "rating": 1295.9493304697935,
            "rating_q975": 1302.5686630863847,
            "rating_q025": 1289.3299978532023
        },
        "step-2-16k-exp-202412": {
            "rating": 1291.8775206379,
            "rating_q975": 1311.811882000955,
            "rating_q025": 1271.9431592748451
        },
        "ring-flash-2.0": {
            "rating": 1291.05057620573,
            "rating_q975": 1308.4124846776201,
            "rating_q025": 1273.68866773384
        },
        "grok-2-2024-08-13": {
            "rating": 1289.9690663757217,
            "rating_q975": 1296.777850547119,
            "rating_q025": 1283.1602822043244
        },
        "olmo-3-32b-think": {
            "rating": 1288.8283123282458,
            "rating_q975": 1317.2880323625673,
            "rating_q025": 1260.3685922939244
        },
        "glm-4-plus": {
            "rating": 1288.5000094822262,
            "rating_q975": 1297.7446165163224,
            "rating_q025": 1279.25540244813
        },
        "llama-4-maverick-17b-128e-instruct": {
            "rating": 1287.9157153808821,
            "rating_q975": 1295.7122448920088,
            "rating_q025": 1280.1191858697555
        },
        "llama-3.1-405b-instruct-fp8": {
            "rating": 1286.9312674859018,
            "rating_q975": 1293.8402375426995,
            "rating_q025": 1280.0222974291041
        },
        "athene-v2-chat": {
            "rating": 1285.0493987879772,
            "rating_q975": 1294.0498480011897,
            "rating_q025": 1276.0489495747647
        },
        "mercury": {
            "rating": 1284.669620539481,
            "rating_q975": 1317.2214169120302,
            "rating_q025": 1252.1178241669318
        },
        "gpt-4o-mini-2024-07-18": {
            "rating": 1284.0401017668662,
            "rating_q975": 1290.3972135404083,
            "rating_q025": 1277.682989993324
        },
        "hunyuan-large-2025-02-10": {
            "rating": 1283.432410817014,
            "rating_q975": 1308.8606806819682,
            "rating_q025": 1258.0041409520597
        },
        "llama-4-scout-17b-16e-instruct": {
            "rating": 1282.7760074268974,
            "rating_q975": 1291.451580436697,
            "rating_q025": 1274.1004344170979
        },
        "llama-3.3-70b-instruct": {
            "rating": 1280.6972479797378,
            "rating_q975": 1287.064141670718,
            "rating_q025": 1274.3303542887575
        },
        "gpt-4o-2024-08-06": {
            "rating": 1278.5287250369001,
            "rating_q975": 1286.1864673601576,
            "rating_q025": 1270.8709827136427
        },
        "gemma-3n-e4b-it": {
            "rating": 1277.4746080709297,
            "rating_q975": 1287.7506848678343,
            "rating_q025": 1267.198531274025
        },
        "gpt-4.1-nano-2025-04-14": {
            "rating": 1276.9763244081769,
            "rating_q975": 1295.1063295276758,
            "rating_q025": 1258.846319288678
        },
        "qwen-max-0919": {
            "rating": 1276.0182731867935,
            "rating_q975": 1286.8988438993765,
            "rating_q025": 1265.1377024742105
        },
        "llama-3.1-nemotron-70b-instruct": {
            "rating": 1275.29991351405,
            "rating_q975": 1291.9391686906893,
            "rating_q025": 1258.660658337411
        },
        "magistral-medium-2506": {
            "rating": 1275.2700927969202,
            "rating_q975": 1290.2479634998235,
            "rating_q025": 1260.2922220940168
        },
        "hunyuan-standard-2025-02-10": {
            "rating": 1274.7837972159705,
            "rating_q975": 1298.7559961852355,
            "rating_q025": 1250.8115982467054
        },
        "claude-3-opus-20240229": {
            "rating": 1274.6937486989896,
            "rating_q975": 1280.520766435198,
            "rating_q025": 1268.866730962781
        },
        "mistral-small-3.1-24b-instruct-2503": {
            "rating": 1272.0987980037428,
            "rating_q975": 1280.709368032207,
            "rating_q025": 1263.4882279752785
        },
        "qwen2.5-72b-instruct": {
            "rating": 1271.6290156356986,
            "rating_q975": 1279.2537175398352,
            "rating_q025": 1264.004313731562
        },
        "gpt-oss-20b": {
            "rating": 1269.7521602262814,
            "rating_q975": 1284.0455958105529,
            "rating_q025": 1255.4587246420099
        },
        "gemini-advanced-0514": {
            "rating": 1268.844457039801,
            "rating_q975": 1278.2288749278107,
            "rating_q025": 1259.4600391517913
        },
        "gemini-1.5-pro-001": {
            "rating": 1267.1308236218283,
            "rating_q975": 1274.6888173832526,
            "rating_q025": 1259.572829860404
        },
        "gpt-4-turbo-2024-04-09": {
            "rating": 1266.4974877573877,
            "rating_q975": 1273.7195624083524,
            "rating_q025": 1259.275413106423
        },
        "grok-2-mini-2024-08-13": {
            "rating": 1265.2662090685126,
            "rating_q975": 1272.397620271757,
            "rating_q025": 1258.1347978652682
        },
        "claude-3-5-haiku-20241022": {
            "rating": 1264.0218752025512,
            "rating_q975": 1270.0114051995122,
            "rating_q025": 1258.0323452055902
        },
        "deepseek-v2.5": {
            "rating": 1260.2863590902225,
            "rating_q975": 1269.721241766107,
            "rating_q025": 1250.851476414338
        },
        "mistral-large-2411": {
            "rating": 1259.938367751453,
            "rating_q975": 1268.6977488155865,
            "rating_q025": 1251.1789866873194
        },
        "mistral-large-2407": {
            "rating": 1256.919667408924,
            "rating_q975": 1264.5925782911886,
            "rating_q025": 1249.2467565266593
        },
        "gpt-4-1106-preview": {
            "rating": 1256.2854637672108,
            "rating_q975": 1263.8681009075826,
            "rating_q025": 1248.702826626839
        },
        "athene-70b-0725": {
            "rating": 1256.2267841845405,
            "rating_q975": 1266.935613937065,
            "rating_q025": 1245.517954432016
        },
        "llama-3.1-70b-instruct": {
            "rating": 1256.1093314684667,
            "rating_q975": 1263.027566737611,
            "rating_q025": 1249.1910961993224
        },
        "gemma-3-4b-it": {
            "rating": 1254.8020764763696,
            "rating_q975": 1278.5069072128965,
            "rating_q025": 1231.0972457398427
        },
        "gemini-1.5-flash-002": {
            "rating": 1252.3078317174286,
            "rating_q975": 1260.3538525510023,
            "rating_q025": 1244.2618108838549
        },
        "hunyuan-large-vision": {
            "rating": 1252.2708348616247,
            "rating_q975": 1272.0222721074933,
            "rating_q025": 1232.5193976157561
        },
        "llama-3.1-tulu-3-70b": {
            "rating": 1251.3716751332431,
            "rating_q975": 1274.6737205073653,
            "rating_q025": 1228.069629759121
        },
        "gpt-4-0125-preview": {
            "rating": 1250.3851064305609,
            "rating_q975": 1258.0121959666546,
            "rating_q025": 1242.7580168944671
        },
        "amazon-nova-pro-v1.0": {
            "rating": 1245.5575512167202,
            "rating_q975": 1254.6552645203342,
            "rating_q025": 1236.4598379131062
        },
        "gemini-1.5-flash-001": {
            "rating": 1227.3762252167285,
            "rating_q975": 1235.1064830722573,
            "rating_q025": 1219.6459673611996
        },
        "claude-3-sonnet-20240229": {
            "rating": 1226.6696137932859,
            "rating_q975": 1234.453811852944,
            "rating_q025": 1218.8854157336277
        },
        "llama-3.1-nemotron-51b-instruct": {
            "rating": 1226.1790150219817,
            "rating_q975": 1246.3525462725395,
            "rating_q025": 1206.005483771424
        },
        "reka-core-20240904": {
            "rating": 1225.8789938579173,
            "rating_q975": 1242.043187396306,
            "rating_q025": 1209.7148003195286
        },
        "gemma-2-27b-it": {
            "rating": 1223.741999588391,
            "rating_q975": 1229.9628447725765,
            "rating_q025": 1217.5211544042056
        },
        "llama-3-70b-instruct": {
            "rating": 1222.6970030518917,
            "rating_q975": 1229.8729141653387,
            "rating_q025": 1215.5210919384447
        },
        "olmo-2-0325-32b-instruct": {
            "rating": 1221.5332117488704,
            "rating_q975": 1251.0577685112273,
            "rating_q025": 1192.0086549865134
        },
        "qwen2.5-coder-32b-instruct": {
            "rating": 1221.4003210302649,
            "rating_q975": 1239.2084681499675,
            "rating_q025": 1203.5921739105622
        },
        "jamba-1.5-large": {
            "rating": 1220.3977417084243,
            "rating_q975": 1234.7555875881196,
            "rating_q025": 1206.039895828729
        },
        "gemma-2-9b-it-simpo": {
            "rating": 1219.7092923996781,
            "rating_q975": 1234.1126763349519,
            "rating_q025": 1205.3059084644044
        },
        "glm-4-0520": {
            "rating": 1217.3860080683326,
            "rating_q975": 1231.970273052134,
            "rating_q025": 1202.8017430845312
        },
        "mistral-small-24b-instruct-2501": {
            "rating": 1216.8580048488952,
            "rating_q975": 1229.6310083576793,
            "rating_q025": 1204.0850013401111
        },
        "nemotron-4-340b-instruct": {
            "rating": 1214.1371603294265,
            "rating_q975": 1225.467678449546,
            "rating_q025": 1202.806642209307
        },
        "command-r-plus-08-2024": {
            "rating": 1212.5818051599522,
            "rating_q975": 1226.098414923024,
            "rating_q025": 1199.0651953968804
        },
        "phi-4": {
            "rating": 1205.4341074320791,
            "rating_q975": 1215.4956779985514,
            "rating_q025": 1195.372536865607
        },
        "gpt-4-0314": {
            "rating": 1204.5503651686308,
            "rating_q975": 1214.273782720554,
            "rating_q025": 1194.8269476167077
        },
        "amazon-nova-lite-v1.0": {
            "rating": 1198.5820525816573,
            "rating_q975": 1208.9748726000976,
            "rating_q025": 1188.189232563217
        },
        "qwen2-72b-instruct": {
            "rating": 1194.8561686479925,
            "rating_q975": 1203.8618770051992,
            "rating_q025": 1185.8504602907858
        },
        "gemma-2-9b-it": {
            "rating": 1193.333798907938,
            "rating_q975": 1200.321429006847,
            "rating_q025": 1186.346168809029
        },
        "command-r-plus": {
            "rating": 1192.0944715447617,
            "rating_q975": 1200.372824586605,
            "rating_q025": 1183.8161185029185
        },
        "claude-3-haiku-20240307": {
            "rating": 1190.051317448645,
            "rating_q975": 1197.0561648641676,
            "rating_q025": 1183.0464700331224
        },
        "c4ai-aya-expanse-32b": {
            "rating": 1189.4504579876154,
            "rating_q975": 1198.3135975362377,
            "rating_q025": 1180.5873184389932
        },
        "reka-flash-20240904": {
            "rating": 1188.2360197433509,
            "rating_q975": 1204.118663540571,
            "rating_q025": 1172.3533759461307
        },
        "gemini-1.5-flash-8b-001": {
            "rating": 1185.2702133704815,
            "rating_q975": 1193.4518867726213,
            "rating_q025": 1177.0885399683418
        },
        "gpt-4-0613": {
            "rating": 1183.71056688274,
            "rating_q975": 1191.9029986022363,
            "rating_q025": 1175.5181351632439
        },
        "amazon-nova-micro-v1.0": {
            "rating": 1178.9845574029744,
            "rating_q975": 1189.6117921534822,
            "rating_q025": 1168.3573226524666
        },
        "deepseek-coder-v2": {
            "rating": 1176.3934322669547,
            "rating_q975": 1188.7309026140297,
            "rating_q025": 1164.0559619198798
        },
        "hunyuan-standard-256k": {
            "rating": 1174.878133926583,
            "rating_q975": 1199.7807928287748,
            "rating_q025": 1149.975475024391
        },
        "llama-3.1-8b-instruct": {
            "rating": 1171.6162870137982,
            "rating_q975": 1179.0656029757001,
            "rating_q025": 1164.1669710518963
        },
        "mistral-large-2402": {
            "rating": 1171.313538711608,
            "rating_q975": 1180.3527922562355,
            "rating_q025": 1162.2742851669807
        },
        "ministral-8b-2410": {
            "rating": 1166.0930556141243,
            "rating_q975": 1184.9273960634814,
            "rating_q025": 1147.2587151647672
        },
        "command-r-08-2024": {
            "rating": 1162.861875771181,
            "rating_q975": 1176.419697698104,
            "rating_q025": 1149.304053844258
        },
        "qwen1.5-110b-chat": {
            "rating": 1160.2001778417575,
            "rating_q975": 1171.5236913961392,
            "rating_q025": 1148.876664287376
        },
        "qwen1.5-72b-chat": {
            "rating": 1159.7517253007984,
            "rating_q975": 1169.9381430899955,
            "rating_q025": 1149.5653075116013
        },
        "c4ai-aya-expanse-8b": {
            "rating": 1159.490302418727,
            "rating_q975": 1173.766232484162,
            "rating_q025": 1145.214372353292
        },
        "jamba-1.5-mini": {
            "rating": 1157.361813510699,
            "rating_q975": 1171.8644943173117,
            "rating_q025": 1142.8591327040863
        },
        "llama-3.1-tulu-3-8b": {
            "rating": 1152.507288069654,
            "rating_q975": 1177.9371071125256,
            "rating_q025": 1127.0774690267822
        },
        "llama-3-8b-instruct": {
            "rating": 1152.1155293846539,
            "rating_q975": 1160.0264877517714,
            "rating_q025": 1144.2045710175364
        },
        "yi-1.5-34b-chat": {
            "rating": 1152.0085881683153,
            "rating_q975": 1163.1281657995498,
            "rating_q025": 1140.8890105370808
        },
        "reka-flash-21b-20240226-online": {
            "rating": 1150.896840610129,
            "rating_q975": 1165.6598986966037,
            "rating_q025": 1136.1337825236542
        },
        "command-r": {
            "rating": 1148.0652877165348,
            "rating_q975": 1157.3538636950752,
            "rating_q025": 1138.7767117379944
        },
        "mistral-medium": {
            "rating": 1147.2018551596104,
            "rating_q975": 1158.3930550132852,
            "rating_q025": 1136.0106553059356
        },
        "gemini-pro": {
            "rating": 1141.8366284282195,
            "rating_q975": 1166.7604375817607,
            "rating_q025": 1116.9128192746782
        },
        "qwq-32b-preview": {
            "rating": 1141.3038996542416,
            "rating_q975": 1168.5729920793017,
            "rating_q025": 1114.0348072291815
        },
        "reka-flash-21b-20240226": {
            "rating": 1141.303012933855,
            "rating_q975": 1153.2157216511255,
            "rating_q025": 1129.3903042165844
        },
        "qwen1.5-32b-chat": {
            "rating": 1139.7232676716526,
            "rating_q975": 1151.8883379447718,
            "rating_q025": 1127.5581973985334
        },
        "internlm2_5-20b-chat": {
            "rating": 1136.1700518272933,
            "rating_q975": 1150.6408502818047,
            "rating_q025": 1121.6992533727819
        },
        "mixtral-8x22b-instruct-v0.1": {
            "rating": 1129.0137375115744,
            "rating_q975": 1137.8219652616065,
            "rating_q025": 1120.2055097615423
        },
        "gemini-pro-dev-api": {
            "rating": 1124.2484202962348,
            "rating_q975": 1138.7758728001984,
            "rating_q025": 1109.7209677922713
        },
        "gemma-2-2b-it": {
            "rating": 1118.089825595642,
            "rating_q975": 1125.944868382845,
            "rating_q025": 1110.234782808439
        },
        "gpt-3.5-turbo-0125": {
            "rating": 1117.3226101238515,
            "rating_q975": 1125.7749853439802,
            "rating_q025": 1108.8702349037228
        },
        "mixtral-8x7b-instruct-v0.1": {
            "rating": 1114.9787927907191,
            "rating_q975": 1123.4281310023841,
            "rating_q025": 1106.5294545790541
        },
        "yi-34b-chat": {
            "rating": 1112.868805508346,
            "rating_q975": 1127.659004532208,
            "rating_q025": 1098.078606484484
        },
        "dbrx-instruct-preview": {
            "rating": 1111.08681863233,
            "rating_q975": 1122.6514209712293,
            "rating_q025": 1099.5222162934308
        },
        "starling-lm-7b-beta": {
            "rating": 1110.6426793745493,
            "rating_q975": 1125.6158355881312,
            "rating_q025": 1095.6695231609674
        },
        "qwen1.5-14b-chat": {
            "rating": 1110.0026931394048,
            "rating_q975": 1124.1882587833145,
            "rating_q025": 1095.817127495495
        },
        "granite-3.1-8b-instruct": {
            "rating": 1109.5222872518693,
            "rating_q975": 1135.438263337303,
            "rating_q025": 1083.6063111664357
        },
        "wizardlm-70b": {
            "rating": 1109.2097604419682,
            "rating_q975": 1128.701986385884,
            "rating_q025": 1089.7175344980524
        },
        "llama-3.2-3b-instruct": {
            "rating": 1105.1173472673634,
            "rating_q975": 1121.9807314258894,
            "rating_q025": 1088.2539631088373
        },
        "zephyr-orpo-141b-A35b-v0.1": {
            "rating": 1100.9747469478748,
            "rating_q975": 1125.1722780256307,
            "rating_q025": 1076.7772158701189
        },
        "granite-3.1-2b-instruct": {
            "rating": 1099.9506047499112,
            "rating_q975": 1127.1982657099243,
            "rating_q025": 1072.7029437898982
        },
        "openchat-3.5-0106": {
            "rating": 1090.6221819843315,
            "rating_q975": 1105.6270232171917,
            "rating_q025": 1075.6173407514714
        },
        "llama-2-70b-chat": {
            "rating": 1088.3234124322064,
            "rating_q975": 1098.7241553205874,
            "rating_q025": 1077.9226695438254
        },
        "phi-3-medium-4k-instruct": {
            "rating": 1087.475358342342,
            "rating_q975": 1098.2803171994026,
            "rating_q025": 1076.6703994852812
        },
        "tulu-2-dpo-70b": {
            "rating": 1086.2455424978427,
            "rating_q975": 1107.6038083302358,
            "rating_q025": 1064.8872766654497
        },
        "starling-lm-7b-alpha": {
            "rating": 1085.707192553286,
            "rating_q975": 1103.1584077277405,
            "rating_q025": 1068.2559773788314
        },
        "openchat-3.5": {
            "rating": 1085.5205374063526,
            "rating_q975": 1104.2784971876679,
            "rating_q025": 1066.7625776250372
        },
        "deepseek-llm-67b-chat": {
            "rating": 1081.7765047393896,
            "rating_q975": 1106.040482068201,
            "rating_q025": 1057.512527410578
        },
        "nous-hermes-2-mixtral-8x7b-dpo": {
            "rating": 1081.2907949940495,
            "rating_q975": 1107.3854721458915,
            "rating_q025": 1055.1961178422075
        },
        "vicuna-33b": {
            "rating": 1080.7295264635952,
            "rating_q975": 1093.658626457862,
            "rating_q025": 1067.8004264693284
        },
        "gpt-3.5-turbo-1106": {
            "rating": 1078.9640341855002,
            "rating_q975": 1094.8192871347103,
            "rating_q025": 1063.10878123629
        },
        "snowflake-arctic-instruct": {
            "rating": 1072.258014132317,
            "rating_q975": 1084.6839155215073,
            "rating_q025": 1059.8321127431266
        },
        "phi-3-small-8k-instruct": {
            "rating": 1067.3299913576157,
            "rating_q975": 1079.4004561881243,
            "rating_q025": 1055.259526527107
        },
        "openhermes-2.5-mistral-7b": {
            "rating": 1064.5392684559856,
            "rating_q975": 1087.3331601044556,
            "rating_q025": 1041.7453768075156
        },
        "mistral-7b-instruct-v0.2": {
            "rating": 1063.6759564353717,
            "rating_q975": 1076.7477244754402,
            "rating_q025": 1050.6041883953033
        },
        "granite-3.0-8b-instruct": {
            "rating": 1063.5831093267113,
            "rating_q975": 1083.2369971730568,
            "rating_q025": 1043.9292214803659
        },
        "qwen1.5-7b-chat": {
            "rating": 1061.5962894252757,
            "rating_q975": 1086.811522290058,
            "rating_q025": 1036.3810565604933
        },
        "llama2-70b-steerlm-chat": {
            "rating": 1061.317397014056,
            "rating_q975": 1089.8239636761296,
            "rating_q025": 1032.8108303519825
        },
        "mpt-30b-chat": {
            "rating": 1055.8903942235204,
            "rating_q975": 1088.4352695217797,
            "rating_q025": 1023.3455189252611
        },
        "granite-3.0-2b-instruct": {
            "rating": 1054.4870002940843,
            "rating_q975": 1073.4422357134831,
            "rating_q025": 1035.5317648746855
        },
        "llama-2-13b-chat": {
            "rating": 1050.7706478829664,
            "rating_q975": 1064.627545590805,
            "rating_q025": 1036.9137501751277
        },
        "phi-3-mini-4k-instruct-june-2024": {
            "rating": 1047.9659426294652,
            "rating_q975": 1062.5872084433897,
            "rating_q025": 1033.3446768155407
        },
        "solar-10.7b-instruct-v1.0": {
            "rating": 1046.668804233369,
            "rating_q975": 1071.9164806897068,
            "rating_q025": 1021.4211277770312
        },
        "wizardlm-13b": {
            "rating": 1045.6560597863215,
            "rating_q975": 1065.8004345314152,
            "rating_q025": 1025.5116850412278
        },
        "gemma-1.1-7b-it": {
            "rating": 1039.9117068852522,
            "rating_q975": 1051.4339303104007,
            "rating_q025": 1028.3894834601037
        },
        "zephyr-7b-beta": {
            "rating": 1038.0762869754676,
            "rating_q975": 1055.7151329965986,
            "rating_q025": 1020.4374409543366
        },
        "vicuna-13b": {
            "rating": 1031.5550079516458,
            "rating_q975": 1045.627521117743,
            "rating_q025": 1017.4824947855485
        },
        "llama-3.2-1b-instruct": {
            "rating": 1031.00181262942,
            "rating_q975": 1049.5086805418387,
            "rating_q025": 1012.4949447170017
        },
        "llama-2-7b-chat": {
            "rating": 1028.8411813688995,
            "rating_q975": 1043.905810713237,
            "rating_q025": 1013.7765520245617
        },
        "dolphin-2.2.1-mistral-7b": {
            "rating": 1021.014126543618,
            "rating_q975": 1063.0688659480677,
            "rating_q025": 978.9593871391683
        },
        "qwen-14b-chat": {
            "rating": 1020.76563239032,
            "rating_q975": 1044.2832087620689,
            "rating_q025": 997.2480560185712
        },
        "phi-3-mini-4k-instruct": {
            "rating": 1018.7256281403472,
            "rating_q975": 1031.9382121011986,
            "rating_q025": 1005.5130441794959
        },
        "zephyr-7b-alpha": {
            "rating": 1015.8876178904313,
            "rating_q975": 1051.1917106571464,
            "rating_q025": 980.5835251237162
        },
        "codellama-34b-instruct": {
            "rating": 1015.8852391441791,
            "rating_q975": 1034.3595340119368,
            "rating_q025": 997.4109442764212
        },
        "falcon-180b-chat": {
            "rating": 1012.9982443670533,
            "rating_q975": 1054.1147048411199,
            "rating_q025": 971.8817838929867
        },
        "mistral-7b-instruct": {
            "rating": 1010.120409931698,
            "rating_q975": 1029.4994980930444,
            "rating_q025": 990.7413217703516
        },
        "stripedhyena-nous-7b": {
            "rating": 1009.7536860227506,
            "rating_q975": 1032.87190284376,
            "rating_q025": 986.6354692017412
        },
        "guanaco-33b": {
            "rating": 1007.8305330328601,
            "rating_q975": 1042.1084742117503,
            "rating_q025": 973.5525918539698
        },
        "olmo-7b-instruct": {
            "rating": 1004.7468078816322,
            "rating_q975": 1032.5274661110036,
            "rating_q025": 976.9661496522608
        },
        "palm-2": {
            "rating": 995.1973077606747,
            "rating_q975": 1014.9507565276804,
            "rating_q025": 975.443858993669
        },
        "smollm2-1.7b-instruct": {
            "rating": 993.4232837247803,
            "rating_q975": 1032.366242368991,
            "rating_q025": 954.4803250805695
        },
        "phi-3-mini-128k-instruct": {
            "rating": 990.0518984300761,
            "rating_q975": 1005.4989830987461,
            "rating_q025": 974.6048137614061
        },
        "vicuna-7b": {
            "rating": 989.765984930233,
            "rating_q975": 1010.9825154804037,
            "rating_q025": 968.5494543800623
        },
        "qwen1.5-4b-chat": {
            "rating": 977.6191286447695,
            "rating_q975": 996.4330243948381,
            "rating_q025": 958.8052328947009
        },
        "gemma-7b-it": {
            "rating": 963.7947273321238,
            "rating_q975": 982.5871813419111,
            "rating_q025": 945.0022733223365
        },
        "chatglm3-6b": {
            "rating": 962.169824774924,
            "rating_q975": 988.1547555101821,
            "rating_q025": 936.1848940396659
        },
        "gemma-1.1-2b-it": {
            "rating": 958.9068684910302,
            "rating_q975": 976.7364588791854,
            "rating_q025": 941.077278102875
        },
        "gemma-2b-it": {
            "rating": 944.4114556451984,
            "rating_q975": 968.0108521756033,
            "rating_q025": 920.8120591147936
        },
        "gpt4all-13b-snoozy": {
            "rating": 924.7683822099837,
            "rating_q975": 963.7150088466402,
            "rating_q025": 885.8217555733271
        },
        "koala-13b": {
            "rating": 922.553373037121,
            "rating_q975": 947.2212833323632,
            "rating_q025": 897.8854627418788
        },
        "chatglm2-6b": {
            "rating": 904.1909420683206,
            "rating_q975": 937.0085989949777,
            "rating_q025": 871.3732851416636
        },
        "mpt-7b-chat": {
            "rating": 903.1923279597754,
            "rating_q975": 932.6020428401705,
            "rating_q025": 873.7826130793803
        },
        "RWKV-4-Raven-14B": {
            "rating": 895.9161907973762,
            "rating_q975": 923.6408220185662,
            "rating_q025": 868.1915595761863
        },
        "alpaca-13b": {
            "rating": 886.4062812596726,
            "rating_q975": 912.6475292049024,
            "rating_q025": 860.1650333144428
        },
        "oasst-pythia-12b": {
            "rating": 870.5313085334312,
            "rating_q975": 896.316483909399,
            "rating_q025": 844.7461331574634
        },
        "chatglm-6b": {
            "rating": 857.0387519234059,
            "rating_q975": 886.8454737364424,
            "rating_q025": 827.2320301103695
        },
        "fastchat-t5-3b": {
            "rating": 853.41391043868,
            "rating_q975": 884.1698198021196,
            "rating_q025": 822.6580010752403
        },
        "stablelm-tuned-alpha-7b": {
            "rating": 822.8176062036277,
            "rating_q975": 857.5158860062728,
            "rating_q025": 788.1193264009827
        },
        "llama-13b": {
            "rating": 753.6853147130845,
            "rating_q975": 796.9949811625114,
            "rating_q025": 710.3756482636576
        },
        "dolly-v2-12b": {
            "rating": 740.8052217598481,
            "rating_q975": 776.9433288846723,
            "rating_q025": 704.667114635024
        }
    },
    "no_refusal": {
        "gemini-3-pro": {
            "rating": 1486.102402336068,
            "rating_q975": 1492.3335556454824,
            "rating_q025": 1479.8712490266537
        },
        "gemini-2.5-pro": {
            "rating": 1463.3194236173426,
            "rating_q975": 1466.7765530857655,
            "rating_q025": 1459.8622941489198
        },
        "grok-4.1-thinking": {
            "rating": 1450.4903412508618,
            "rating_q975": 1456.6167681095162,
            "rating_q025": 1444.3639143922073
        },
        "claude-opus-4-5-20251101": {
            "rating": 1445.6617903680212,
            "rating_q975": 1452.7340533448025,
            "rating_q025": 1438.58952739124
        },
        "gpt-5.1-high": {
            "rating": 1444.937147939206,
            "rating_q975": 1451.3605165641761,
            "rating_q025": 1438.5137793142358
        },
        "ernie-5.0-preview-1103": {
            "rating": 1444.8567670259342,
            "rating_q975": 1453.760967422792,
            "rating_q025": 1435.9525666290765
        },
        "grok-4.1": {
            "rating": 1442.954458724287,
            "rating_q975": 1449.0179176270067,
            "rating_q025": 1436.8909998215672
        },
        "claude-opus-4-5-20251101-thinking-32k": {
            "rating": 1441.4759414159396,
            "rating_q975": 1448.6809279775462,
            "rating_q025": 1434.270954854333
        },
        "glm-4.6": {
            "rating": 1440.6507189152699,
            "rating_q975": 1445.4093931593347,
            "rating_q025": 1435.892044671205
        },
        "qwen3-max-preview": {
            "rating": 1437.3155122202327,
            "rating_q975": 1441.8875142777795,
            "rating_q025": 1432.7435101626859
        },
        "mistral-large-3": {
            "rating": 1430.6633023283944,
            "rating_q975": 1438.9973128979598,
            "rating_q025": 1422.329291758829
        },
        "mistral-medium-2508": {
            "rating": 1429.4986401761112,
            "rating_q975": 1433.3577534435776,
            "rating_q025": 1425.6395269086447
        },
        "chatgpt-4o-latest-20250326": {
            "rating": 1427.4742283279502,
            "rating_q975": 1430.8068797892422,
            "rating_q025": 1424.1415768666582
        },
        "glm-4.5": {
            "rating": 1427.2885496475187,
            "rating_q975": 1432.1682089406738,
            "rating_q025": 1422.4088903543636
        },
        "claude-sonnet-4-5-20250929-thinking-32k": {
            "rating": 1426.2713813280775,
            "rating_q975": 1430.8297741512288,
            "rating_q025": 1421.7129885049262
        },
        "claude-sonnet-4-5-20250929": {
            "rating": 1425.3166721006035,
            "rating_q975": 1430.404333392232,
            "rating_q025": 1420.2290108089749
        },
        "deepseek-r1-0528": {
            "rating": 1424.7234591526287,
            "rating_q975": 1430.3284375234373,
            "rating_q025": 1419.1184807818202
        },
        "grok-3-preview-02-24": {
            "rating": 1423.1986102912065,
            "rating_q975": 1427.424306242623,
            "rating_q025": 1418.97291433979
        },
        "deepseek-v3.2-exp": {
            "rating": 1423.0480362657415,
            "rating_q975": 1429.5939697894569,
            "rating_q025": 1416.5021027420262
        },
        "longcat-flash-chat": {
            "rating": 1422.8474880809822,
            "rating_q975": 1429.2598542742776,
            "rating_q025": 1416.4351218876868
        },
        "qwen3-vl-235b-a22b-instruct": {
            "rating": 1421.5274286978358,
            "rating_q975": 1428.2223279807235,
            "rating_q025": 1414.832529414948
        },
        "deepseek-v3.2-exp-thinking": {
            "rating": 1420.315632555967,
            "rating_q975": 1426.9080915045397,
            "rating_q025": 1413.7231736073945
        },
        "gpt-5.1": {
            "rating": 1419.7740812207383,
            "rating_q975": 1425.9945600754074,
            "rating_q025": 1413.553602366069
        },
        "qwen3-235b-a22b-instruct-2507": {
            "rating": 1419.5054700821584,
            "rating_q975": 1423.209552579299,
            "rating_q025": 1415.8013875850177
        },
        "deepseek-v3.1": {
            "rating": 1419.442901142407,
            "rating_q975": 1425.4757906220473,
            "rating_q025": 1413.4100116627667
        },
        "claude-opus-4-1-20250805-thinking-16k": {
            "rating": 1418.9380455349417,
            "rating_q975": 1422.8066510051597,
            "rating_q025": 1415.0694400647237
        },
        "gpt-4.5-preview-2025-02-27": {
            "rating": 1418.874206539875,
            "rating_q975": 1424.5546577623381,
            "rating_q025": 1413.193755317412
        },
        "qwen3-next-80b-a3b-instruct": {
            "rating": 1418.3167089665637,
            "rating_q975": 1423.1472490658643,
            "rating_q025": 1413.4861688672631
        },
        "deepseek-v3.1-terminus": {
            "rating": 1418.0057816567007,
            "rating_q975": 1427.669202423338,
            "rating_q025": 1408.3423608900634
        },
        "deepseek-v3.2": {
            "rating": 1416.4112189213251,
            "rating_q975": 1424.7219861942433,
            "rating_q025": 1408.100451648407
        },
        "deepseek-v3.1-thinking": {
            "rating": 1415.8893145346249,
            "rating_q975": 1422.4988734012597,
            "rating_q025": 1409.27975566799
        },
        "deepseek-v3.2-thinking": {
            "rating": 1415.807916263057,
            "rating_q975": 1424.3006742818934,
            "rating_q025": 1407.3151582442206
        },
        "deepseek-v3.1-terminus-thinking": {
            "rating": 1415.7866569484356,
            "rating_q975": 1425.782742017073,
            "rating_q025": 1405.7905718797983
        },
        "gemini-2.5-flash": {
            "rating": 1414.1977283843373,
            "rating_q975": 1417.5861827487015,
            "rating_q025": 1410.8092740199731
        },
        "qwen3-max-2025-09-23": {
            "rating": 1412.7153706430595,
            "rating_q975": 1419.1652223614694,
            "rating_q025": 1406.2655189246495
        },
        "qwen3-235b-a22b-thinking-2507": {
            "rating": 1412.6374420306747,
            "rating_q975": 1419.0819044287473,
            "rating_q025": 1406.1929796326021
        },
        "claude-opus-4-1-20250805": {
            "rating": 1412.1082598960995,
            "rating_q975": 1415.851697142406,
            "rating_q025": 1408.364822649793
        },
        "grok-4-0709": {
            "rating": 1411.2623643059999,
            "rating_q975": 1415.220592341623,
            "rating_q025": 1407.3041362703768
        },
        "o3-2025-04-16": {
            "rating": 1410.7553393565652,
            "rating_q975": 1414.3760987403825,
            "rating_q025": 1407.1345799727478
        },
        "kimi-k2-thinking-turbo": {
            "rating": 1408.8078088297345,
            "rating_q975": 1414.6404996640767,
            "rating_q025": 1402.9751179953923
        },
        "grok-4-1-fast-reasoning": {
            "rating": 1408.7566811322865,
            "rating_q975": 1415.7155183105447,
            "rating_q025": 1401.7978439540284
        },
        "grok-4-fast-chat": {
            "rating": 1406.572528236153,
            "rating_q975": 1414.1574275649934,
            "rating_q025": 1398.9876289073125
        },
        "gpt-5-high": {
            "rating": 1406.3500236141595,
            "rating_q975": 1410.829125357413,
            "rating_q025": 1401.870921870906
        },
        "gemini-2.5-flash-preview-09-2025": {
            "rating": 1406.245397616255,
            "rating_q975": 1410.631221849063,
            "rating_q025": 1401.8595733834472
        },
        "hunyuan-vision-1.5-thinking": {
            "rating": 1403.064571712657,
            "rating_q975": 1415.5287299778377,
            "rating_q025": 1390.6004134474763
        },
        "gpt-5-chat": {
            "rating": 1401.7073612061713,
            "rating_q975": 1406.0141472616508,
            "rating_q025": 1397.4005751506918
        },
        "qwen3-vl-235b-a22b-thinking": {
            "rating": 1399.5379314363395,
            "rating_q975": 1406.3825555742876,
            "rating_q025": 1392.6933072983913
        },
        "hunyuan-t1-20250711": {
            "rating": 1398.9072622680324,
            "rating_q975": 1407.5223582324538,
            "rating_q025": 1390.2921663036109
        },
        "amazon-nova-experimental-chat-10-20": {
            "rating": 1396.8471245708329,
            "rating_q975": 1404.147795014677,
            "rating_q025": 1389.5464541269887
        },
        "grok-4-fast-reasoning": {
            "rating": 1396.7559772410634,
            "rating_q975": 1401.887246098827,
            "rating_q025": 1391.6247083832998
        },
        "qwen3-235b-a22b-no-thinking": {
            "rating": 1392.1936051410898,
            "rating_q975": 1396.6826888804849,
            "rating_q025": 1387.7045214016948
        },
        "mai-1-preview": {
            "rating": 1392.1892049737278,
            "rating_q975": 1397.6382528085219,
            "rating_q025": 1386.7401571389337
        },
        "qwen3-30b-a3b-instruct-2507": {
            "rating": 1384.1739963503717,
            "rating_q975": 1389.0675516416884,
            "rating_q025": 1379.280441059055
        },
        "claude-haiku-4-5-20251001": {
            "rating": 1383.4365646332471,
            "rating_q975": 1388.056881273859,
            "rating_q025": 1378.8162479926352
        },
        "gpt-4.1-2025-04-14": {
            "rating": 1382.6569796082363,
            "rating_q975": 1386.3747208539485,
            "rating_q025": 1378.939238362524
        },
        "glm-4.5-air": {
            "rating": 1381.4312940066056,
            "rating_q975": 1385.7045646953104,
            "rating_q025": 1377.1580233179009
        },
        "kimi-k2-0905-preview": {
            "rating": 1379.4071805330054,
            "rating_q975": 1385.9848045269575,
            "rating_q025": 1372.8295565390533
        },
        "gemini-2.5-flash-lite-preview-09-2025-no-thinking": {
            "rating": 1377.7542882049102,
            "rating_q975": 1382.1204932563903,
            "rating_q025": 1373.38808315343
        },
        "hunyuan-turbos-20250416": {
            "rating": 1375.664094813079,
            "rating_q975": 1381.9944457902714,
            "rating_q025": 1369.3337438358865
        },
        "gpt-5-mini-high": {
            "rating": 1374.8350450866476,
            "rating_q975": 1379.4424860591078,
            "rating_q025": 1370.2276041141874
        },
        "claude-opus-4-20250514-thinking-16k": {
            "rating": 1374.2154537977863,
            "rating_q975": 1378.6201021904476,
            "rating_q025": 1369.810805405125
        },
        "deepseek-v3-0324": {
            "rating": 1373.2761978485535,
            "rating_q975": 1377.123856107785,
            "rating_q025": 1369.4285395893219
        },
        "deepseek-r1": {
            "rating": 1372.022958311222,
            "rating_q975": 1376.8037597889936,
            "rating_q025": 1367.2421568334505
        },
        "kimi-k2-0711-preview": {
            "rating": 1370.5595922301798,
            "rating_q975": 1375.387234846046,
            "rating_q025": 1365.7319496143134
        },
        "gemini-2.5-flash-lite-preview-06-17-thinking": {
            "rating": 1368.158648828252,
            "rating_q975": 1372.6355490262818,
            "rating_q025": 1363.681748630222
        },
        "mistral-medium-2505": {
            "rating": 1367.716906129956,
            "rating_q975": 1372.3751515496613,
            "rating_q025": 1363.0586607102507
        },
        "qwen3-next-80b-a3b-thinking": {
            "rating": 1367.145487390618,
            "rating_q975": 1373.0379019592592,
            "rating_q025": 1361.2530728219767
        },
        "grok-3-mini-high": {
            "rating": 1367.143216585265,
            "rating_q975": 1372.4619545370613,
            "rating_q025": 1361.8244786334687
        },
        "qwen2.5-max": {
            "rating": 1366.986204101008,
            "rating_q975": 1370.9761378919966,
            "rating_q025": 1362.9962703100196
        },
        "o1-2024-12-17": {
            "rating": 1365.836694033131,
            "rating_q975": 1370.2346801402691,
            "rating_q025": 1361.4387079259927
        },
        "qwen3-235b-a22b": {
            "rating": 1365.7185908348715,
            "rating_q975": 1370.4065716268951,
            "rating_q025": 1361.030610042848
        },
        "gpt-oss-120b": {
            "rating": 1364.8698986938389,
            "rating_q975": 1369.2626344947762,
            "rating_q025": 1360.4771628929016
        },
        "ling-flash-2.0": {
            "rating": 1363.7788086399332,
            "rating_q975": 1370.985719799612,
            "rating_q025": 1356.5718974802544
        },
        "claude-opus-4-20250514": {
            "rating": 1362.9811049211455,
            "rating_q975": 1367.2839685281238,
            "rating_q025": 1358.6782413141673
        },
        "nova-2-lite": {
            "rating": 1362.980927310339,
            "rating_q975": 1371.587902411972,
            "rating_q025": 1354.373952208706
        },
        "grok-3-mini-beta": {
            "rating": 1362.0681955712544,
            "rating_q975": 1367.0497444849047,
            "rating_q025": 1357.086646657604
        },
        "o1-preview": {
            "rating": 1358.7474982607127,
            "rating_q975": 1363.7934877198188,
            "rating_q025": 1353.7015088016067
        },
        "amazon-nova-experimental-chat-10-09": {
            "rating": 1356.808847744928,
            "rating_q975": 1363.3574478754083,
            "rating_q025": 1350.2602476144477
        },
        "gemma-3-27b-it": {
            "rating": 1356.8046189721274,
            "rating_q975": 1360.425537086087,
            "rating_q025": 1353.1837008581679
        },
        "qwen3-coder-480b-a35b-instruct": {
            "rating": 1355.7845487538102,
            "rating_q975": 1360.8179245380677,
            "rating_q025": 1350.7511729695527
        },
        "gemini-2.0-flash-001": {
            "rating": 1353.4417242121797,
            "rating_q975": 1357.1093927938823,
            "rating_q025": 1349.774055630477
        },
        "o4-mini-2025-04-16": {
            "rating": 1353.3485523737504,
            "rating_q975": 1357.2967725168444,
            "rating_q025": 1349.4003322306564
        },
        "step-3": {
            "rating": 1348.7375248663257,
            "rating_q975": 1356.0880474510425,
            "rating_q025": 1341.3870022816088
        },
        "claude-sonnet-4-20250514-thinking-32k": {
            "rating": 1348.1134423150452,
            "rating_q975": 1352.5795822565399,
            "rating_q025": 1343.6473023735505
        },
        "intellect-3": {
            "rating": 1346.8525534371067,
            "rating_q975": 1359.4715473055783,
            "rating_q025": 1334.2335595686352
        },
        "minimax-m1": {
            "rating": 1345.6527437215827,
            "rating_q975": 1349.9099989897397,
            "rating_q025": 1341.3954884534257
        },
        "minimax-m2": {
            "rating": 1341.454662222397,
            "rating_q975": 1349.1781328208447,
            "rating_q025": 1333.7311916239494
        },
        "gpt-4.1-mini-2025-04-14": {
            "rating": 1339.9899822163163,
            "rating_q975": 1344.2713730532175,
            "rating_q025": 1335.708591379415
        },
        "qwen3-32b": {
            "rating": 1338.8240182337343,
            "rating_q975": 1348.256223478624,
            "rating_q025": 1329.3918129888445
        },
        "o3-mini-high": {
            "rating": 1338.4525888940796,
            "rating_q975": 1343.690367481554,
            "rating_q025": 1333.2148103066052
        },
        "mistral-small-2506": {
            "rating": 1338.4190345576746,
            "rating_q975": 1343.5842003778685,
            "rating_q025": 1333.2538687374808
        },
        "claude-sonnet-4-20250514": {
            "rating": 1337.240874025958,
            "rating_q975": 1341.632068136912,
            "rating_q025": 1332.849679915004
        },
        "nvidia-llama-3.3-nemotron-super-49b-v1.5": {
            "rating": 1335.916336513727,
            "rating_q975": 1345.7844349603681,
            "rating_q025": 1326.0482380670858
        },
        "step-1o-turbo-202506": {
            "rating": 1335.1894281071127,
            "rating_q975": 1341.84900134081,
            "rating_q025": 1328.5298548734154
        },
        "gemma-3-12b-it": {
            "rating": 1333.8505149999603,
            "rating_q975": 1343.2915819111092,
            "rating_q025": 1324.4094480888114
        },
        "glm-4.5v": {
            "rating": 1332.4983297985063,
            "rating_q975": 1340.9305874327817,
            "rating_q025": 1324.066072164231
        },
        "ring-flash-2.0": {
            "rating": 1331.7412482196985,
            "rating_q975": 1338.9287212663749,
            "rating_q025": 1324.5537751730221
        },
        "deepseek-v3": {
            "rating": 1330.9744304226806,
            "rating_q975": 1335.6443108361289,
            "rating_q025": 1326.3045500092323
        },
        "glm-4-plus-0111": {
            "rating": 1330.639992184435,
            "rating_q975": 1339.0827147946,
            "rating_q025": 1322.19726957427
        },
        "command-a-03-2025": {
            "rating": 1330.2355230632143,
            "rating_q975": 1333.6770801254588,
            "rating_q025": 1326.7939660009697
        },
        "gemini-2.0-flash-lite-preview-02-05": {
            "rating": 1329.192274993625,
            "rating_q975": 1333.4156144896185,
            "rating_q025": 1324.9689354976315
        },
        "qwq-32b": {
            "rating": 1328.3055425756502,
            "rating_q975": 1332.6850511708208,
            "rating_q025": 1323.9260339804796
        },
        "qwen-plus-0125": {
            "rating": 1326.0364323374454,
            "rating_q975": 1334.462323853043,
            "rating_q025": 1317.6105408218477
        },
        "o3-mini": {
            "rating": 1321.757030932698,
            "rating_q975": 1325.2368040883043,
            "rating_q025": 1318.2772577770916
        },
        "step-2-16k-exp-202412": {
            "rating": 1321.3767523542865,
            "rating_q975": 1329.9951588879203,
            "rating_q025": 1312.7583458206527
        },
        "hunyuan-turbos-20250226": {
            "rating": 1320.8492141220188,
            "rating_q975": 1332.6829439695082,
            "rating_q025": 1309.0154842745294
        },
        "gpt-5-nano-high": {
            "rating": 1320.5171831453488,
            "rating_q975": 1327.3561470006955,
            "rating_q025": 1313.678219290002
        },
        "o1-mini": {
            "rating": 1320.2365847231035,
            "rating_q975": 1323.7919264648103,
            "rating_q025": 1316.6812429813967
        },
        "llama-3.1-nemotron-ultra-253b-v1": {
            "rating": 1319.2907163819204,
            "rating_q975": 1330.965213311235,
            "rating_q025": 1307.616219452606
        },
        "gemini-1.5-pro-002": {
            "rating": 1318.6546092632125,
            "rating_q975": 1321.918379322934,
            "rating_q025": 1315.390839203491
        },
        "qwen3-30b-a3b": {
            "rating": 1316.940920044302,
            "rating_q975": 1321.630860897887,
            "rating_q025": 1312.2509791907169
        },
        "claude-3-7-sonnet-20250219-thinking-32k": {
            "rating": 1313.79420202416,
            "rating_q975": 1317.9869362734223,
            "rating_q025": 1309.6014677748979
        },
        "hunyuan-turbo-0110": {
            "rating": 1309.960875269381,
            "rating_q975": 1321.6008108198498,
            "rating_q025": 1298.320939718912
        },
        "llama-3.3-nemotron-49b-super-v1": {
            "rating": 1308.9858284747575,
            "rating_q975": 1321.2161998006645,
            "rating_q025": 1296.7554571488504
        },
        "gemma-3n-e4b-it": {
            "rating": 1306.545044475671,
            "rating_q975": 1311.6568774039279,
            "rating_q025": 1301.433211547414
        },
        "olmo-3-32b-think": {
            "rating": 1304.6170645701866,
            "rating_q975": 1315.2293624794333,
            "rating_q025": 1294.0047666609398
        },
        "grok-2-2024-08-13": {
            "rating": 1303.834803050811,
            "rating_q975": 1307.411996922435,
            "rating_q025": 1300.2576091791868
        },
        "yi-lightning": {
            "rating": 1300.566767224708,
            "rating_q975": 1305.4213967119824,
            "rating_q025": 1295.7121377374335
        },
        "qwen2.5-plus-1127": {
            "rating": 1299.9198717139752,
            "rating_q975": 1306.2531268328585,
            "rating_q025": 1293.586616595092
        },
        "gpt-4o-2024-05-13": {
            "rating": 1299.7472554961662,
            "rating_q975": 1303.1214855120622,
            "rating_q025": 1296.3730254802701
        },
        "claude-3-7-sonnet-20250219": {
            "rating": 1298.2778562930198,
            "rating_q975": 1302.1892097756456,
            "rating_q025": 1294.366502810394
        },
        "claude-3-5-sonnet-20241022": {
            "rating": 1298.2543012622018,
            "rating_q975": 1301.2897765479483,
            "rating_q025": 1295.2188259764553
        },
        "deepseek-v2.5-1210": {
            "rating": 1294.2506136917773,
            "rating_q975": 1302.5255838988012,
            "rating_q025": 1285.9756434847534
        },
        "gemma-3-4b-it": {
            "rating": 1290.356896449674,
            "rating_q975": 1299.6640610978184,
            "rating_q025": 1281.0497318015296
        },
        "athene-v2-chat": {
            "rating": 1290.2927537114174,
            "rating_q975": 1294.7769431039715,
            "rating_q025": 1285.8085643188633
        },
        "glm-4-plus": {
            "rating": 1289.6400557135503,
            "rating_q975": 1294.5237871017703,
            "rating_q025": 1284.7563243253303
        },
        "hunyuan-large-2025-02-10": {
            "rating": 1289.334442332237,
            "rating_q975": 1299.3690465954164,
            "rating_q025": 1279.2998380690574
        },
        "gpt-oss-20b": {
            "rating": 1287.881179172883,
            "rating_q975": 1294.2453389638365,
            "rating_q025": 1281.5170193819297
        },
        "llama-4-maverick-17b-128e-instruct": {
            "rating": 1287.427235725076,
            "rating_q975": 1291.6547061078552,
            "rating_q025": 1283.1997653422966
        },
        "mercury": {
            "rating": 1286.8600889148202,
            "rating_q975": 1300.6537515482332,
            "rating_q025": 1273.066426281407
        },
        "gemini-1.5-flash-002": {
            "rating": 1286.5134874559942,
            "rating_q975": 1290.6348676312393,
            "rating_q025": 1282.392107280749
        },
        "gpt-4o-mini-2024-07-18": {
            "rating": 1286.239580014309,
            "rating_q975": 1289.6390666491204,
            "rating_q025": 1282.8400933794976
        },
        "gpt-4.1-nano-2025-04-14": {
            "rating": 1285.7081794922583,
            "rating_q975": 1293.4442360265973,
            "rating_q025": 1277.9721229579193
        },
        "claude-3-5-sonnet-20240620": {
            "rating": 1284.2704256073032,
            "rating_q975": 1287.6973048105076,
            "rating_q025": 1280.8435464040988
        },
        "gpt-4o-2024-08-06": {
            "rating": 1282.7727953468209,
            "rating_q975": 1286.9126222483935,
            "rating_q025": 1278.6329684452483
        },
        "qwen-max-0919": {
            "rating": 1282.4110529271372,
            "rating_q975": 1288.0955483697833,
            "rating_q025": 1276.7265574844912
        },
        "llama-3.1-405b-instruct-bf16": {
            "rating": 1282.3162879249521,
            "rating_q975": 1285.887828704821,
            "rating_q025": 1278.7447471450832
        },
        "llama-3.1-nemotron-70b-instruct": {
            "rating": 1281.5898169596317,
            "rating_q975": 1289.33770259778,
            "rating_q025": 1273.8419313214833
        },
        "llama-4-scout-17b-16e-instruct": {
            "rating": 1280.9178875342068,
            "rating_q975": 1285.6070352157867,
            "rating_q025": 1276.2287398526269
        },
        "llama-3.1-405b-instruct-fp8": {
            "rating": 1280.72048152465,
            "rating_q975": 1284.2076336484408,
            "rating_q025": 1277.2333294008592
        },
        "grok-2-mini-2024-08-13": {
            "rating": 1280.446565078177,
            "rating_q975": 1284.0664497494222,
            "rating_q025": 1276.8266804069317
        },
        "mistral-small-3.1-24b-instruct-2503": {
            "rating": 1277.971652161547,
            "rating_q975": 1282.4799308059871,
            "rating_q025": 1273.4633735171067
        },
        "gemini-advanced-0514": {
            "rating": 1276.53645546724,
            "rating_q975": 1281.669188647752,
            "rating_q025": 1271.4037222867282
        },
        "hunyuan-standard-2025-02-10": {
            "rating": 1276.1769510256154,
            "rating_q975": 1286.0210205423878,
            "rating_q025": 1266.332881508843
        },
        "gemini-1.5-pro-001": {
            "rating": 1274.6982459756423,
            "rating_q975": 1278.6555677382498,
            "rating_q025": 1270.7409242130348
        },
        "llama-3.3-70b-instruct": {
            "rating": 1274.646706998798,
            "rating_q975": 1278.0042528682225,
            "rating_q025": 1271.2891611293735
        },
        "gpt-4-turbo-2024-04-09": {
            "rating": 1271.112348114269,
            "rating_q975": 1274.9756689236556,
            "rating_q025": 1267.2490273048825
        },
        "deepseek-v2.5": {
            "rating": 1270.9540488403882,
            "rating_q975": 1275.6184217762864,
            "rating_q025": 1266.28967590449
        },
        "claude-3-opus-20240229": {
            "rating": 1269.81527548668,
            "rating_q975": 1272.8379565522455,
            "rating_q025": 1266.7925944211147
        },
        "qwen2.5-72b-instruct": {
            "rating": 1268.80810610443,
            "rating_q975": 1272.7953428482385,
            "rating_q025": 1264.8208693606214
        },
        "hunyuan-large-vision": {
            "rating": 1268.2798905773734,
            "rating_q975": 1277.548224176718,
            "rating_q025": 1259.011556978029
        },
        "gpt-4-1106-preview": {
            "rating": 1265.2098192879516,
            "rating_q975": 1269.103579204385,
            "rating_q025": 1261.3160593715183
        },
        "mistral-large-2407": {
            "rating": 1265.0552642069815,
            "rating_q975": 1268.9125027807622,
            "rating_q025": 1261.1980256332008
        },
        "mistral-large-2411": {
            "rating": 1264.7963795880432,
            "rating_q975": 1269.1421435303528,
            "rating_q025": 1260.4506156457337
        },
        "gpt-4-0125-preview": {
            "rating": 1264.154119171926,
            "rating_q975": 1268.247799411049,
            "rating_q025": 1260.0604389328028
        },
        "athene-70b-0725": {
            "rating": 1263.5463289088525,
            "rating_q975": 1269.1846401423754,
            "rating_q025": 1257.9080176753296
        },
        "claude-3-5-haiku-20241022": {
            "rating": 1260.730365259208,
            "rating_q975": 1263.9141921022424,
            "rating_q025": 1257.5465384161735
        },
        "llama-3.1-70b-instruct": {
            "rating": 1259.6498281727686,
            "rating_q975": 1263.270091269681,
            "rating_q025": 1256.0295650758562
        },
        "amazon-nova-pro-v1.0": {
            "rating": 1257.9175867271804,
            "rating_q975": 1262.36797970199,
            "rating_q025": 1253.4671937523708
        },
        "magistral-medium-2506": {
            "rating": 1254.5401811862703,
            "rating_q975": 1260.9294450676423,
            "rating_q025": 1248.1509173048983
        },
        "llama-3.1-tulu-3-70b": {
            "rating": 1253.218914496736,
            "rating_q975": 1263.842061481568,
            "rating_q025": 1242.5957675119041
        },
        "reka-core-20240904": {
            "rating": 1246.924471565261,
            "rating_q975": 1254.0599448626658,
            "rating_q025": 1239.7889982678562
        },
        "gemini-1.5-flash-001": {
            "rating": 1239.475362923794,
            "rating_q975": 1243.9584861962628,
            "rating_q025": 1234.992239651325
        },
        "jamba-1.5-large": {
            "rating": 1235.9793328792953,
            "rating_q975": 1243.3694313931396,
            "rating_q025": 1228.589234365451
        },
        "mistral-small-24b-instruct-2501": {
            "rating": 1234.2078499519603,
            "rating_q975": 1240.0588919028376,
            "rating_q025": 1228.356808001083
        },
        "command-r-plus-08-2024": {
            "rating": 1231.4281573525043,
            "rating_q975": 1238.0647275995495,
            "rating_q025": 1224.791587105459
        },
        "gemma-2-27b-it": {
            "rating": 1231.3843399138054,
            "rating_q975": 1234.6610762212042,
            "rating_q025": 1228.1076036064067
        },
        "qwen2.5-coder-32b-instruct": {
            "rating": 1228.9243853059647,
            "rating_q975": 1237.0399199440985,
            "rating_q025": 1220.808850667831
        },
        "amazon-nova-lite-v1.0": {
            "rating": 1228.6797229830993,
            "rating_q975": 1233.7419922666736,
            "rating_q025": 1223.617453699525
        },
        "gemini-1.5-flash-8b-001": {
            "rating": 1226.9628785062678,
            "rating_q975": 1231.1678415590131,
            "rating_q025": 1222.7579154535224
        },
        "llama-3.1-nemotron-51b-instruct": {
            "rating": 1226.805513986143,
            "rating_q975": 1236.8781843660986,
            "rating_q025": 1216.7328436061875
        },
        "gemma-2-9b-it-simpo": {
            "rating": 1225.2774272076167,
            "rating_q975": 1232.2288825701366,
            "rating_q025": 1218.3259718450968
        },
        "nemotron-4-340b-instruct": {
            "rating": 1224.0394840197923,
            "rating_q975": 1229.4345906043707,
            "rating_q025": 1218.644377435214
        },
        "c4ai-aya-expanse-32b": {
            "rating": 1223.9878923038073,
            "rating_q975": 1228.812995954215,
            "rating_q025": 1219.1627886533995
        },
        "glm-4-0520": {
            "rating": 1223.8899449441617,
            "rating_q975": 1230.9278344235602,
            "rating_q025": 1216.8520554647632
        },
        "claude-3-sonnet-20240229": {
            "rating": 1221.3330451412962,
            "rating_q975": 1225.3692211456646,
            "rating_q025": 1217.2968691369279
        },
        "llama-3-70b-instruct": {
            "rating": 1218.0829034998067,
            "rating_q975": 1221.6833032031611,
            "rating_q025": 1214.4825037964522
        },
        "phi-4": {
            "rating": 1217.0198377670667,
            "rating_q975": 1221.5586870989362,
            "rating_q025": 1212.4809884351973
        },
        "reka-flash-20240904": {
            "rating": 1216.7944465341275,
            "rating_q975": 1223.7724220386212,
            "rating_q025": 1209.8164710296337
        },
        "olmo-2-0325-32b-instruct": {
            "rating": 1216.6166896776851,
            "rating_q975": 1227.5050782174,
            "rating_q025": 1205.7283011379702
        },
        "deepseek-coder-v2": {
            "rating": 1212.5878771077018,
            "rating_q975": 1219.208492502516,
            "rating_q025": 1205.9672617128876
        },
        "amazon-nova-micro-v1.0": {
            "rating": 1208.9028203497141,
            "rating_q975": 1213.9448103900604,
            "rating_q025": 1203.8608303093679
        },
        "gemma-2-9b-it": {
            "rating": 1206.9329374560793,
            "rating_q975": 1210.6518668720698,
            "rating_q025": 1203.2140080400889
        },
        "command-r-plus": {
            "rating": 1204.3093618035402,
            "rating_q975": 1208.66706108276,
            "rating_q025": 1199.9516625243205
        },
        "gpt-4-0314": {
            "rating": 1203.817565335828,
            "rating_q975": 1208.7018702587325,
            "rating_q025": 1198.9332604129236
        },
        "hunyuan-standard-256k": {
            "rating": 1203.2675438493638,
            "rating_q975": 1215.0447129169902,
            "rating_q025": 1191.4903747817375
        },
        "qwen2-72b-instruct": {
            "rating": 1203.1031200075854,
            "rating_q975": 1208.0299239031906,
            "rating_q025": 1198.1763161119802
        },
        "claude-3-haiku-20240307": {
            "rating": 1199.1045611031088,
            "rating_q975": 1202.8626675657413,
            "rating_q025": 1195.3464546404764
        },
        "llama-3.1-tulu-3-8b": {
            "rating": 1194.010823056798,
            "rating_q975": 1204.674142640724,
            "rating_q025": 1183.347503472872
        },
        "ministral-8b-2410": {
            "rating": 1190.2354257576021,
            "rating_q975": 1199.2922529828406,
            "rating_q025": 1181.1785985323636
        },
        "command-r-08-2024": {
            "rating": 1188.840487399405,
            "rating_q975": 1195.4310946706416,
            "rating_q025": 1182.2498801281683
        },
        "gpt-4-0613": {
            "rating": 1186.9177839535482,
            "rating_q975": 1191.061893603599,
            "rating_q025": 1182.7736743034975
        },
        "jamba-1.5-mini": {
            "rating": 1186.6047566161292,
            "rating_q975": 1193.8701169576811,
            "rating_q025": 1179.3393962745772
        },
        "llama-3.1-8b-instruct": {
            "rating": 1185.8742591241344,
            "rating_q975": 1189.9033689936416,
            "rating_q025": 1181.8451492546271
        },
        "c4ai-aya-expanse-8b": {
            "rating": 1185.7511988250067,
            "rating_q975": 1192.6668340755068,
            "rating_q025": 1178.8355635745065
        },
        "mistral-large-2402": {
            "rating": 1173.9198587881524,
            "rating_q975": 1178.7044649966729,
            "rating_q025": 1169.135252579632
        },
        "qwen1.5-110b-chat": {
            "rating": 1173.2169956474647,
            "rating_q975": 1178.8144547715774,
            "rating_q025": 1167.619536523352
        },
        "yi-1.5-34b-chat": {
            "rating": 1170.8616496021164,
            "rating_q975": 1175.9570494491004,
            "rating_q025": 1165.7662497551323
        },
        "reka-flash-21b-20240226-online": {
            "rating": 1167.7457541281829,
            "rating_q975": 1175.1860115981847,
            "rating_q025": 1160.305496658181
        },
        "qwq-32b-preview": {
            "rating": 1165.5591968523818,
            "rating_q975": 1177.2477660063282,
            "rating_q025": 1153.8706276984353
        },
        "qwen1.5-72b-chat": {
            "rating": 1165.2931273329368,
            "rating_q975": 1170.620359701178,
            "rating_q025": 1159.9658949646957
        },
        "llama-3-8b-instruct": {
            "rating": 1163.2231244971072,
            "rating_q975": 1166.9691677594617,
            "rating_q025": 1159.4770812347526
        },
        "reka-flash-21b-20240226": {
            "rating": 1162.533648549326,
            "rating_q975": 1168.549664869372,
            "rating_q025": 1156.51763222928
        },
        "command-r": {
            "rating": 1161.8172523763988,
            "rating_q975": 1166.6084691638896,
            "rating_q025": 1157.026035588908
        },
        "mistral-medium": {
            "rating": 1161.6369815707508,
            "rating_q975": 1167.2358657798543,
            "rating_q025": 1156.0380973616473
        },
        "mixtral-8x22b-instruct-v0.1": {
            "rating": 1159.51507285562,
            "rating_q975": 1164.0770336640471,
            "rating_q025": 1154.953112047193
        },
        "internlm2_5-20b-chat": {
            "rating": 1159.372023053914,
            "rating_q975": 1166.5221550242734,
            "rating_q025": 1152.2218910835547
        },
        "gemma-2-2b-it": {
            "rating": 1155.1390145079376,
            "rating_q975": 1159.1128124371064,
            "rating_q025": 1151.1652165787689
        },
        "granite-3.1-8b-instruct": {
            "rating": 1150.3314653795928,
            "rating_q975": 1161.4544017975452,
            "rating_q025": 1139.2085289616405
        },
        "gemini-pro-dev-api": {
            "rating": 1146.9283215898681,
            "rating_q975": 1154.3915821657645,
            "rating_q025": 1139.4650610139718
        },
        "zephyr-orpo-141b-A35b-v0.1": {
            "rating": 1141.126461191844,
            "rating_q975": 1152.095748882672,
            "rating_q025": 1130.1571735010161
        },
        "qwen1.5-32b-chat": {
            "rating": 1136.6072836239841,
            "rating_q975": 1142.816336085527,
            "rating_q025": 1130.3982311624413
        },
        "phi-3-medium-4k-instruct": {
            "rating": 1136.3902980897508,
            "rating_q975": 1141.539651267982,
            "rating_q025": 1131.2409449115196
        },
        "gemini-pro": {
            "rating": 1130.9176153108617,
            "rating_q975": 1142.7901530182774,
            "rating_q025": 1119.045077603446
        },
        "yi-34b-chat": {
            "rating": 1129.2791355430056,
            "rating_q975": 1136.2828268335506,
            "rating_q025": 1122.2754442524606
        },
        "starling-lm-7b-beta": {
            "rating": 1129.1951743303998,
            "rating_q975": 1136.6281718029793,
            "rating_q025": 1121.7621768578204
        },
        "mixtral-8x7b-instruct-v0.1": {
            "rating": 1127.6059079164154,
            "rating_q975": 1131.9342932773868,
            "rating_q025": 1123.277522555444
        },
        "qwen1.5-14b-chat": {
            "rating": 1127.1784495848697,
            "rating_q975": 1134.4050053800788,
            "rating_q025": 1119.9518937896605
        },
        "gpt-3.5-turbo-0125": {
            "rating": 1126.5193786819898,
            "rating_q975": 1131.300213797807,
            "rating_q025": 1121.7385435661727
        },
        "granite-3.1-2b-instruct": {
            "rating": 1126.4060918826115,
            "rating_q975": 1137.6148497181412,
            "rating_q025": 1115.1973340470818
        },
        "tulu-2-dpo-70b": {
            "rating": 1117.3202136509406,
            "rating_q975": 1127.4342212102777,
            "rating_q025": 1107.2062060916035
        },
        "dbrx-instruct-preview": {
            "rating": 1116.587574185413,
            "rating_q975": 1122.7906097850705,
            "rating_q025": 1110.3845385857553
        },
        "wizardlm-70b": {
            "rating": 1114.1725424859214,
            "rating_q975": 1123.8796529380563,
            "rating_q025": 1104.4654320337866
        },
        "llama-2-70b-chat": {
            "rating": 1112.738292488562,
            "rating_q975": 1118.362981569676,
            "rating_q025": 1107.1136034074477
        },
        "phi-3-small-8k-instruct": {
            "rating": 1109.063832296537,
            "rating_q975": 1115.0724011641846,
            "rating_q025": 1103.0552634288892
        },
        "nous-hermes-2-mixtral-8x7b-dpo": {
            "rating": 1109.0304368958637,
            "rating_q975": 1121.1853162539628,
            "rating_q025": 1096.8755575377645
        },
        "llama-3.2-3b-instruct": {
            "rating": 1108.1335806673078,
            "rating_q975": 1115.764221389413,
            "rating_q025": 1100.5029399452026
        },
        "gpt-3.5-turbo-1106": {
            "rating": 1105.6739479355672,
            "rating_q975": 1114.9113333028156,
            "rating_q025": 1096.4365625683188
        },
        "openchat-3.5-0106": {
            "rating": 1102.6684162876595,
            "rating_q975": 1110.7560394309148,
            "rating_q025": 1094.5807931444042
        },
        "deepseek-llm-67b-chat": {
            "rating": 1101.8040149306148,
            "rating_q975": 1113.7813354634136,
            "rating_q025": 1089.826694397816
        },
        "starling-lm-7b-alpha": {
            "rating": 1100.3710280405369,
            "rating_q975": 1108.5480552969339,
            "rating_q025": 1092.19400078414
        },
        "vicuna-33b": {
            "rating": 1098.8216257042645,
            "rating_q975": 1105.1668163149714,
            "rating_q025": 1092.4764350935577
        },
        "snowflake-arctic-instruct": {
            "rating": 1098.3360767201557,
            "rating_q975": 1104.3488463799208,
            "rating_q025": 1092.3233070603906
        },
        "granite-3.0-8b-instruct": {
            "rating": 1096.637257096308,
            "rating_q975": 1105.3710757970568,
            "rating_q025": 1087.9034383955593
        },
        "gemma-1.1-7b-it": {
            "rating": 1092.3053792302308,
            "rating_q975": 1098.3559022016952,
            "rating_q025": 1086.2548562587663
        },
        "llama2-70b-steerlm-chat": {
            "rating": 1091.8613085524912,
            "rating_q975": 1104.787832690485,
            "rating_q025": 1078.9347844144975
        },
        "openchat-3.5": {
            "rating": 1086.3908406833593,
            "rating_q975": 1096.4671451248546,
            "rating_q025": 1076.314536241864
        },
        "llama-2-13b-chat": {
            "rating": 1085.9041728569362,
            "rating_q975": 1092.7384212111506,
            "rating_q025": 1079.0699245027217
        },
        "openhermes-2.5-mistral-7b": {
            "rating": 1085.671037884751,
            "rating_q975": 1096.3710917805397,
            "rating_q025": 1074.9709839889624
        },
        "mistral-7b-instruct-v0.2": {
            "rating": 1085.6550419781802,
            "rating_q975": 1092.4148505801586,
            "rating_q025": 1078.8952333762018
        },
        "granite-3.0-2b-instruct": {
            "rating": 1078.6386387485932,
            "rating_q975": 1087.046268560873,
            "rating_q025": 1070.2310089363134
        },
        "qwen1.5-7b-chat": {
            "rating": 1078.568746809704,
            "rating_q975": 1088.5607457850776,
            "rating_q025": 1068.5767478343303
        },
        "phi-3-mini-4k-instruct-june-2024": {
            "rating": 1077.3110356893712,
            "rating_q975": 1083.8017320781653,
            "rating_q025": 1070.8203393005772
        },
        "solar-10.7b-instruct-v1.0": {
            "rating": 1076.9059616958853,
            "rating_q975": 1090.4593572929414,
            "rating_q025": 1063.3525660988291
        },
        "wizardlm-13b": {
            "rating": 1072.7978757883707,
            "rating_q975": 1082.5325209638852,
            "rating_q025": 1063.0632306128562
        },
        "phi-3-mini-4k-instruct": {
            "rating": 1072.7411332326767,
            "rating_q975": 1079.1630756244622,
            "rating_q025": 1066.3191908408912
        },
        "dolphin-2.2.1-mistral-7b": {
            "rating": 1072.019182807245,
            "rating_q975": 1087.9432880661686,
            "rating_q025": 1056.0950775483213
        },
        "codellama-70b-instruct": {
            "rating": 1063.6676632182448,
            "rating_q975": 1082.9637721837,
            "rating_q025": 1044.3715542527896
        },
        "codellama-34b-instruct": {
            "rating": 1062.1936286901978,
            "rating_q975": 1071.3553544564206,
            "rating_q025": 1053.031902923975
        },
        "zephyr-7b-beta": {
            "rating": 1061.4214544935699,
            "rating_q975": 1070.4934973049576,
            "rating_q025": 1052.349411682182
        },
        "mpt-30b-chat": {
            "rating": 1059.2372618611937,
            "rating_q975": 1072.0321060967533,
            "rating_q025": 1046.442417625634
        },
        "llama-2-7b-chat": {
            "rating": 1055.7755416396976,
            "rating_q975": 1063.0205300850128,
            "rating_q025": 1048.5305531943825
        },
        "vicuna-13b": {
            "rating": 1055.3427483471048,
            "rating_q975": 1062.213750786894,
            "rating_q025": 1048.4717459073156
        },
        "llama-3.2-1b-instruct": {
            "rating": 1054.8132081683189,
            "rating_q975": 1062.57294627889,
            "rating_q025": 1047.0534700577477
        },
        "guanaco-33b": {
            "rating": 1054.0383109074944,
            "rating_q975": 1066.9495674424772,
            "rating_q025": 1041.1270543725116
        },
        "gemma-7b-it": {
            "rating": 1053.1892135053881,
            "rating_q975": 1062.9659468403806,
            "rating_q025": 1043.4124801703956
        },
        "phi-3-mini-128k-instruct": {
            "rating": 1049.423347236324,
            "rating_q975": 1056.7974633848985,
            "rating_q025": 1042.0492310877494
        },
        "qwen-14b-chat": {
            "rating": 1048.1284481954135,
            "rating_q975": 1059.5762317814574,
            "rating_q025": 1036.6806646093696
        },
        "smollm2-1.7b-instruct": {
            "rating": 1047.66124048562,
            "rating_q975": 1062.1718747127431,
            "rating_q025": 1033.150606258497
        },
        "falcon-180b-chat": {
            "rating": 1047.359792276849,
            "rating_q975": 1065.7317936458242,
            "rating_q025": 1028.987790907874
        },
        "zephyr-7b-alpha": {
            "rating": 1045.7946307424797,
            "rating_q975": 1062.324200986524,
            "rating_q025": 1029.2650604984356
        },
        "stripedhyena-nous-7b": {
            "rating": 1033.6011589707045,
            "rating_q975": 1044.993290224276,
            "rating_q025": 1022.2090277171332
        },
        "vicuna-7b": {
            "rating": 1026.9873062407567,
            "rating_q975": 1036.5981696014212,
            "rating_q025": 1017.3764428800921
        },
        "olmo-7b-instruct": {
            "rating": 1024.4217269737483,
            "rating_q975": 1035.8887455128938,
            "rating_q025": 1012.9547084346027
        },
        "gemma-1.1-2b-it": {
            "rating": 1021.4977899048329,
            "rating_q975": 1029.2763950540484,
            "rating_q025": 1013.7191847556172
        },
        "palm-2": {
            "rating": 1016.4006095341904,
            "rating_q975": 1026.1370866053285,
            "rating_q025": 1006.6641324630524
        },
        "mistral-7b-instruct": {
            "rating": 1010.9825305995828,
            "rating_q975": 1020.5562899825932,
            "rating_q025": 1001.4087712165724
        },
        "gemma-2b-it": {
            "rating": 999.3945481285871,
            "rating_q975": 1011.3430462495329,
            "rating_q025": 987.4460500076412
        },
        "qwen1.5-4b-chat": {
            "rating": 992.6103124873193,
            "rating_q975": 1002.1930999865722,
            "rating_q025": 983.0275249880665
        },
        "koala-13b": {
            "rating": 984.4018011119125,
            "rating_q975": 995.0947976377751,
            "rating_q025": 973.70880458605
        },
        "chatglm3-6b": {
            "rating": 962.4866548940604,
            "rating_q975": 974.8989935524695,
            "rating_q025": 950.0743162356513
        },
        "mpt-7b-chat": {
            "rating": 950.8927495842123,
            "rating_q975": 963.4541525687755,
            "rating_q025": 938.3313465996491
        },
        "gpt4all-13b-snoozy": {
            "rating": 948.7417259795491,
            "rating_q975": 965.0508949138723,
            "rating_q025": 932.4325570452258
        },
        "RWKV-4-Raven-14B": {
            "rating": 936.5431698930533,
            "rating_q975": 948.5388035235133,
            "rating_q025": 924.5475362625934
        },
        "chatglm2-6b": {
            "rating": 922.8608312489841,
            "rating_q975": 937.6079817615321,
            "rating_q025": 908.1136807364362
        },
        "alpaca-13b": {
            "rating": 917.0767555696739,
            "rating_q975": 929.0941712280659,
            "rating_q025": 905.0593399112819
        },
        "oasst-pythia-12b": {
            "rating": 903.6938290739295,
            "rating_q975": 915.1869984339309,
            "rating_q025": 892.2006597139281
        },
        "chatglm-6b": {
            "rating": 902.9609059308705,
            "rating_q975": 916.2791495548662,
            "rating_q025": 889.6426623068747
        },
        "fastchat-t5-3b": {
            "rating": 878.7728058303264,
            "rating_q975": 891.9341728386237,
            "rating_q025": 865.6114388220292
        },
        "stablelm-tuned-alpha-7b": {
            "rating": 853.5868577760004,
            "rating_q975": 867.3923462989704,
            "rating_q025": 839.7813692530304
        },
        "dolly-v2-12b": {
            "rating": 832.7664164261441,
            "rating_q975": 846.8826043534584,
            "rating_q025": 818.6502284988298
        },
        "llama-13b": {
            "rating": 816.8298440599019,
            "rating_q975": 833.4870869713617,
            "rating_q025": 800.1726011484421
        }
    },
    "no_short": {
        "gemini-3-pro": {
            "rating": 1487.55014979061,
            "rating_q975": 1493.793814139884,
            "rating_q025": 1481.306485441336
        },
        "gemini-2.5-pro": {
            "rating": 1464.9398411830396,
            "rating_q975": 1468.4061194685862,
            "rating_q025": 1461.473562897493
        },
        "grok-4.1-thinking": {
            "rating": 1450.6837220600244,
            "rating_q975": 1456.814281522158,
            "rating_q025": 1444.5531625978908
        },
        "claude-opus-4-5-20251101": {
            "rating": 1447.7662517902759,
            "rating_q975": 1454.8608899757062,
            "rating_q025": 1440.6716136048456
        },
        "gpt-5.1-high": {
            "rating": 1446.8404548348226,
            "rating_q975": 1453.2882813268095,
            "rating_q025": 1440.3926283428357
        },
        "ernie-5.0-preview-1103": {
            "rating": 1445.1578093579749,
            "rating_q975": 1454.0654207905266,
            "rating_q025": 1436.2501979254232
        },
        "claude-opus-4-5-20251101-thinking-32k": {
            "rating": 1443.6631571615846,
            "rating_q975": 1450.8707118756392,
            "rating_q025": 1436.45560244753
        },
        "grok-4.1": {
            "rating": 1443.3627001322286,
            "rating_q975": 1449.4327839970013,
            "rating_q025": 1437.292616267456
        },
        "glm-4.6": {
            "rating": 1441.5964544544718,
            "rating_q975": 1446.3464725227077,
            "rating_q025": 1436.8464363862358
        },
        "qwen3-max-preview": {
            "rating": 1438.2131269861502,
            "rating_q975": 1442.7950715879158,
            "rating_q025": 1433.6311823843846
        },
        "mistral-large-3": {
            "rating": 1430.9965097130762,
            "rating_q975": 1439.3523702975822,
            "rating_q025": 1422.6406491285702
        },
        "mistral-medium-2508": {
            "rating": 1430.0109618812928,
            "rating_q975": 1433.8787054531294,
            "rating_q025": 1426.1432183094562
        },
        "glm-4.5": {
            "rating": 1428.450442608488,
            "rating_q975": 1433.3470616477073,
            "rating_q025": 1423.5538235692686
        },
        "claude-sonnet-4-5-20250929": {
            "rating": 1427.3567924061601,
            "rating_q975": 1432.4505485317056,
            "rating_q025": 1422.2630362806146
        },
        "claude-sonnet-4-5-20250929-thinking-32k": {
            "rating": 1427.2654479722469,
            "rating_q975": 1431.8240367301996,
            "rating_q025": 1422.7068592142941
        },
        "chatgpt-4o-latest-20250326": {
            "rating": 1427.2614366414177,
            "rating_q975": 1430.6004414910553,
            "rating_q025": 1423.9224317917801
        },
        "deepseek-r1-0528": {
            "rating": 1424.7408983616565,
            "rating_q975": 1430.359790558347,
            "rating_q025": 1419.122006164966
        },
        "grok-3-preview-02-24": {
            "rating": 1423.9764772063743,
            "rating_q975": 1428.2100699124762,
            "rating_q025": 1419.7428845002723
        },
        "deepseek-v3.2-exp": {
            "rating": 1423.6291038226902,
            "rating_q975": 1430.1678162771111,
            "rating_q025": 1417.0903913682694
        },
        "longcat-flash-chat": {
            "rating": 1422.2775463193002,
            "rating_q975": 1428.6991618998004,
            "rating_q025": 1415.8559307388
        },
        "qwen3-vl-235b-a22b-instruct": {
            "rating": 1421.9387817706827,
            "rating_q975": 1428.6461382691223,
            "rating_q025": 1415.231425272243
        },
        "gpt-5.1": {
            "rating": 1421.1837717302628,
            "rating_q975": 1427.4183182416455,
            "rating_q025": 1414.9492252188802
        },
        "deepseek-v3.2-exp-thinking": {
            "rating": 1420.7239592516894,
            "rating_q975": 1427.3286873358293,
            "rating_q025": 1414.1192311675495
        },
        "deepseek-v3.1": {
            "rating": 1420.5051683889392,
            "rating_q975": 1426.5490893420736,
            "rating_q025": 1414.4612474358048
        },
        "claude-opus-4-1-20250805-thinking-16k": {
            "rating": 1420.1219857461176,
            "rating_q975": 1423.9954059649237,
            "rating_q025": 1416.2485655273115
        },
        "qwen3-235b-a22b-instruct-2507": {
            "rating": 1419.426731060601,
            "rating_q975": 1423.1286126355853,
            "rating_q025": 1415.7248494856167
        },
        "deepseek-v3.2": {
            "rating": 1418.3377708136138,
            "rating_q975": 1426.6634257124804,
            "rating_q025": 1410.0121159147473
        },
        "qwen3-next-80b-a3b-instruct": {
            "rating": 1418.2164691995765,
            "rating_q975": 1423.045993104465,
            "rating_q025": 1413.386945294688
        },
        "gpt-4.5-preview-2025-02-27": {
            "rating": 1417.8315281888276,
            "rating_q975": 1423.5086040580632,
            "rating_q025": 1412.154452319592
        },
        "deepseek-v3.1-terminus": {
            "rating": 1417.613837851254,
            "rating_q975": 1427.2913718757986,
            "rating_q025": 1407.9363038267093
        },
        "deepseek-v3.1-terminus-thinking": {
            "rating": 1417.143481066317,
            "rating_q975": 1427.1662465452418,
            "rating_q025": 1407.1207155873922
        },
        "deepseek-v3.2-thinking": {
            "rating": 1416.8879843392838,
            "rating_q975": 1425.3955523072327,
            "rating_q025": 1408.3804163713348
        },
        "deepseek-v3.1-thinking": {
            "rating": 1415.8256951166975,
            "rating_q975": 1422.4699201787435,
            "rating_q025": 1409.1814700546515
        },
        "gemini-2.5-flash": {
            "rating": 1415.34962977262,
            "rating_q975": 1418.74359081807,
            "rating_q025": 1411.9556687271697
        },
        "claude-opus-4-1-20250805": {
            "rating": 1413.7432660996355,
            "rating_q975": 1417.4974424145685,
            "rating_q025": 1409.9890897847026
        },
        "qwen3-max-2025-09-23": {
            "rating": 1413.711480623203,
            "rating_q975": 1420.1913771365794,
            "rating_q025": 1407.2315841098266
        },
        "qwen3-235b-a22b-thinking-2507": {
            "rating": 1412.364282076923,
            "rating_q975": 1418.834390051797,
            "rating_q025": 1405.894174102049
        },
        "o3-2025-04-16": {
            "rating": 1410.7370995602164,
            "rating_q975": 1414.3607899082817,
            "rating_q025": 1407.113409212151
        },
        "grok-4-1-fast-reasoning": {
            "rating": 1409.6575289733803,
            "rating_q975": 1416.627615167706,
            "rating_q025": 1402.6874427790547
        },
        "kimi-k2-thinking-turbo": {
            "rating": 1409.3979123766171,
            "rating_q975": 1415.24314984092,
            "rating_q025": 1403.5526749123142
        },
        "grok-4-0709": {
            "rating": 1408.8612979134107,
            "rating_q975": 1412.7987198678206,
            "rating_q025": 1404.9238759590007
        },
        "grok-4-fast-chat": {
            "rating": 1408.0106724096024,
            "rating_q975": 1415.630375969751,
            "rating_q025": 1400.3909688494539
        },
        "gemini-2.5-flash-preview-09-2025": {
            "rating": 1407.2126581182285,
            "rating_q975": 1411.6062186952245,
            "rating_q025": 1402.8190975412326
        },
        "gpt-5-high": {
            "rating": 1407.0680398892068,
            "rating_q975": 1411.5643566332715,
            "rating_q025": 1402.5717231451422
        },
        "hunyuan-vision-1.5-thinking": {
            "rating": 1404.9007830213495,
            "rating_q975": 1417.3980013832097,
            "rating_q025": 1392.4035646594893
        },
        "gpt-5-chat": {
            "rating": 1403.5246092373568,
            "rating_q975": 1407.8445399243087,
            "rating_q025": 1399.2046785504049
        },
        "qwen3-vl-235b-a22b-thinking": {
            "rating": 1400.1959548505042,
            "rating_q975": 1407.0433378053965,
            "rating_q025": 1393.348571895612
        },
        "hunyuan-t1-20250711": {
            "rating": 1397.5280351735732,
            "rating_q975": 1406.1433107163039,
            "rating_q025": 1388.9127596308426
        },
        "amazon-nova-experimental-chat-10-20": {
            "rating": 1396.1543199325943,
            "rating_q975": 1403.4631535248195,
            "rating_q025": 1388.845486340369
        },
        "grok-4-fast-reasoning": {
            "rating": 1395.9255623700878,
            "rating_q975": 1401.0329766818622,
            "rating_q025": 1390.8181480583135
        },
        "mai-1-preview": {
            "rating": 1392.7204256621587,
            "rating_q975": 1398.1866454571511,
            "rating_q025": 1387.2542058671663
        },
        "qwen3-235b-a22b-no-thinking": {
            "rating": 1392.2930533758195,
            "rating_q975": 1396.7890800051764,
            "rating_q025": 1387.7970267464625
        },
        "qwen3-30b-a3b-instruct-2507": {
            "rating": 1384.4954008546806,
            "rating_q975": 1389.3903770231846,
            "rating_q025": 1379.6004246861767
        },
        "claude-haiku-4-5-20251001": {
            "rating": 1383.8312793853988,
            "rating_q975": 1388.455583543612,
            "rating_q025": 1379.2069752271857
        },
        "gpt-4.1-2025-04-14": {
            "rating": 1382.13169549587,
            "rating_q975": 1385.8498139573906,
            "rating_q025": 1378.4135770343494
        },
        "glm-4.5-air": {
            "rating": 1381.6332799275308,
            "rating_q975": 1385.9176429537806,
            "rating_q025": 1377.348916901281
        },
        "kimi-k2-0905-preview": {
            "rating": 1380.2645158054038,
            "rating_q975": 1386.868949977201,
            "rating_q025": 1373.6600816336065
        },
        "gemini-2.5-flash-lite-preview-09-2025-no-thinking": {
            "rating": 1378.3707360183732,
            "rating_q975": 1382.737545149487,
            "rating_q025": 1374.0039268872595
        },
        "hunyuan-turbos-20250416": {
            "rating": 1375.6010688799988,
            "rating_q975": 1381.9453967832155,
            "rating_q025": 1369.256740976782
        },
        "claude-opus-4-20250514-thinking-16k": {
            "rating": 1374.8652294641477,
            "rating_q975": 1379.2838444760328,
            "rating_q025": 1370.4466144522626
        },
        "gpt-5-mini-high": {
            "rating": 1373.5565938026084,
            "rating_q975": 1378.1727117340286,
            "rating_q025": 1368.9404758711883
        },
        "deepseek-v3-0324": {
            "rating": 1373.2418374249578,
            "rating_q975": 1377.0941363160146,
            "rating_q025": 1369.389538533901
        },
        "deepseek-r1": {
            "rating": 1371.86775884029,
            "rating_q975": 1376.6585129923183,
            "rating_q025": 1367.0770046882617
        },
        "kimi-k2-0711-preview": {
            "rating": 1370.2612344331064,
            "rating_q975": 1375.1048553865571,
            "rating_q025": 1365.4176134796558
        },
        "gemini-2.5-flash-lite-preview-06-17-thinking": {
            "rating": 1368.5712155350418,
            "rating_q975": 1373.0530632612101,
            "rating_q025": 1364.0893678088735
        },
        "mistral-medium-2505": {
            "rating": 1368.234011572901,
            "rating_q975": 1372.8963059444982,
            "rating_q025": 1363.5717172013037
        },
        "grok-3-mini-high": {
            "rating": 1367.0302417323896,
            "rating_q975": 1372.3465702702977,
            "rating_q025": 1361.7139131944816
        },
        "qwen3-235b-a22b": {
            "rating": 1366.6419256549923,
            "rating_q975": 1371.3409786465897,
            "rating_q025": 1361.9428726633948
        },
        "qwen3-next-80b-a3b-thinking": {
            "rating": 1365.94976209897,
            "rating_q975": 1371.8463030594128,
            "rating_q025": 1360.0532211385273
        },
        "qwen2.5-max": {
            "rating": 1365.7215704187781,
            "rating_q975": 1369.7032191946278,
            "rating_q025": 1361.7399216429285
        },
        "o1-2024-12-17": {
            "rating": 1365.660043678313,
            "rating_q975": 1370.0562657676471,
            "rating_q025": 1361.263821588979
        },
        "claude-opus-4-20250514": {
            "rating": 1364.3733140975592,
            "rating_q975": 1368.683574548812,
            "rating_q025": 1360.0630536463063
        },
        "gpt-oss-120b": {
            "rating": 1363.716948947523,
            "rating_q975": 1368.1221857922196,
            "rating_q025": 1359.3117121028263
        },
        "grok-3-mini-beta": {
            "rating": 1362.8661467829347,
            "rating_q975": 1367.8461817221616,
            "rating_q025": 1357.8861118437078
        },
        "ling-flash-2.0": {
            "rating": 1362.692484395409,
            "rating_q975": 1369.935617350195,
            "rating_q025": 1355.4493514406233
        },
        "nova-2-lite": {
            "rating": 1362.117193649184,
            "rating_q975": 1370.7513436739487,
            "rating_q025": 1353.4830436244192
        },
        "amazon-nova-experimental-chat-10-09": {
            "rating": 1357.0774046213687,
            "rating_q975": 1363.6324327904338,
            "rating_q025": 1350.5223764523037
        },
        "gemma-3-27b-it": {
            "rating": 1357.0124641690306,
            "rating_q975": 1360.6333835163953,
            "rating_q025": 1353.391544821666
        },
        "qwen3-coder-480b-a35b-instruct": {
            "rating": 1354.7773030690505,
            "rating_q975": 1359.8195814993253,
            "rating_q025": 1349.7350246387757
        },
        "gemini-2.0-flash-001": {
            "rating": 1353.7976103061362,
            "rating_q975": 1357.4657411235028,
            "rating_q025": 1350.1294794887697
        },
        "o4-mini-2025-04-16": {
            "rating": 1352.7543031698995,
            "rating_q975": 1356.7132331544642,
            "rating_q025": 1348.7953731853347
        },
        "o1-preview": {
            "rating": 1352.031541305472,
            "rating_q975": 1356.9907813863308,
            "rating_q025": 1347.0723012246133
        },
        "step-3": {
            "rating": 1349.4341580321907,
            "rating_q975": 1356.8385610069906,
            "rating_q025": 1342.0297550573907
        },
        "claude-sonnet-4-20250514-thinking-32k": {
            "rating": 1348.7517517109695,
            "rating_q975": 1353.2229327518648,
            "rating_q025": 1344.2805706700742
        },
        "intellect-3": {
            "rating": 1347.9435890771128,
            "rating_q975": 1360.5769039251534,
            "rating_q025": 1335.3102742290723
        },
        "minimax-m1": {
            "rating": 1345.8427385245125,
            "rating_q975": 1350.1003744731377,
            "rating_q025": 1341.5851025758873
        },
        "minimax-m2": {
            "rating": 1342.3605430758084,
            "rating_q975": 1350.0847661191458,
            "rating_q025": 1334.636320032471
        },
        "gpt-4.1-mini-2025-04-14": {
            "rating": 1339.656986905863,
            "rating_q975": 1343.9498344492717,
            "rating_q025": 1335.3641393624544
        },
        "qwen3-32b": {
            "rating": 1339.518550265097,
            "rating_q975": 1348.956984699469,
            "rating_q025": 1330.080115830725
        },
        "claude-sonnet-4-20250514": {
            "rating": 1338.621103220177,
            "rating_q975": 1343.0259979427137,
            "rating_q025": 1334.2162084976403
        },
        "mistral-small-2506": {
            "rating": 1338.4633196683624,
            "rating_q975": 1343.6451031674771,
            "rating_q025": 1333.2815361692476
        },
        "o3-mini-high": {
            "rating": 1335.8039072101994,
            "rating_q975": 1341.0092757386699,
            "rating_q025": 1330.598538681729
        },
        "step-1o-turbo-202506": {
            "rating": 1335.4544966848796,
            "rating_q975": 1342.143813732341,
            "rating_q025": 1328.7651796374182
        },
        "nvidia-llama-3.3-nemotron-super-49b-v1.5": {
            "rating": 1335.3339736153243,
            "rating_q975": 1345.2038431379071,
            "rating_q025": 1325.4641040927415
        },
        "gemma-3-12b-it": {
            "rating": 1333.8905271762594,
            "rating_q975": 1343.3273656665406,
            "rating_q025": 1324.4536886859782
        },
        "glm-4.5v": {
            "rating": 1332.6657601740474,
            "rating_q975": 1341.1334295120319,
            "rating_q025": 1324.1980908360629
        },
        "ring-flash-2.0": {
            "rating": 1332.051217279186,
            "rating_q975": 1339.2440091613068,
            "rating_q025": 1324.858425397065
        },
        "deepseek-v3": {
            "rating": 1331.830755969805,
            "rating_q975": 1336.4922579419897,
            "rating_q025": 1327.1692539976204
        },
        "glm-4-plus-0111": {
            "rating": 1331.0296237288094,
            "rating_q975": 1339.4470205101575,
            "rating_q025": 1322.6122269474613
        },
        "command-a-03-2025": {
            "rating": 1330.2006919649218,
            "rating_q975": 1333.6452616392828,
            "rating_q025": 1326.7561222905608
        },
        "qwq-32b": {
            "rating": 1328.5818659917331,
            "rating_q975": 1332.9634963886883,
            "rating_q025": 1324.200235594778
        },
        "gemini-2.0-flash-lite-preview-02-05": {
            "rating": 1328.349320999881,
            "rating_q975": 1332.5711083281872,
            "rating_q025": 1324.1275336715748
        },
        "qwen-plus-0125": {
            "rating": 1325.660978641491,
            "rating_q975": 1334.013263686013,
            "rating_q025": 1317.308693596969
        },
        "step-2-16k-exp-202412": {
            "rating": 1319.3582982347325,
            "rating_q975": 1327.9254890809366,
            "rating_q025": 1310.7911073885284
        },
        "llama-3.1-nemotron-ultra-253b-v1": {
            "rating": 1319.225133932437,
            "rating_q975": 1330.873417857562,
            "rating_q025": 1307.5768500073123
        },
        "o3-mini": {
            "rating": 1319.2167542881684,
            "rating_q975": 1322.6920155618438,
            "rating_q025": 1315.741493014493
        },
        "gpt-5-nano-high": {
            "rating": 1318.8829871196167,
            "rating_q975": 1325.7440544998342,
            "rating_q025": 1312.0219197393992
        },
        "hunyuan-turbos-20250226": {
            "rating": 1318.612972947271,
            "rating_q975": 1330.403983245324,
            "rating_q025": 1306.8219626492178
        },
        "gemini-1.5-pro-002": {
            "rating": 1318.5453672583324,
            "rating_q975": 1321.8021373675115,
            "rating_q025": 1315.2885971491532
        },
        "qwen3-30b-a3b": {
            "rating": 1316.7066454205733,
            "rating_q975": 1321.4059139001308,
            "rating_q025": 1312.0073769410158
        },
        "o1-mini": {
            "rating": 1316.2694600547125,
            "rating_q975": 1319.8004771840165,
            "rating_q025": 1312.7384429254084
        },
        "claude-3-7-sonnet-20250219-thinking-32k": {
            "rating": 1314.775615737953,
            "rating_q975": 1318.9730997888744,
            "rating_q025": 1310.5781316870318
        },
        "hunyuan-turbo-0110": {
            "rating": 1310.9020809070294,
            "rating_q975": 1322.4341975611921,
            "rating_q025": 1299.3699642528666
        },
        "llama-3.3-nemotron-49b-super-v1": {
            "rating": 1309.6868608110435,
            "rating_q975": 1321.813598425187,
            "rating_q025": 1297.5601231969001
        },
        "olmo-3-32b-think": {
            "rating": 1306.1793068054762,
            "rating_q975": 1316.8155194922426,
            "rating_q025": 1295.5430941187099
        },
        "gemma-3n-e4b-it": {
            "rating": 1305.228565667385,
            "rating_q975": 1310.3399919802514,
            "rating_q025": 1300.1171393545187
        },
        "grok-2-2024-08-13": {
            "rating": 1304.7275013297312,
            "rating_q975": 1308.2932566590584,
            "rating_q025": 1301.161746000404
        },
        "yi-lightning": {
            "rating": 1301.71268389841,
            "rating_q975": 1306.5478158175383,
            "rating_q025": 1296.8775519792816
        },
        "gpt-4o-2024-05-13": {
            "rating": 1300.238913808926,
            "rating_q975": 1303.5896638780655,
            "rating_q025": 1296.8881637397867
        },
        "claude-3-7-sonnet-20250219": {
            "rating": 1299.083820346284,
            "rating_q975": 1302.9948851511294,
            "rating_q025": 1295.1727555414386
        },
        "qwen2.5-plus-1127": {
            "rating": 1297.8185233508614,
            "rating_q975": 1304.1154088401004,
            "rating_q025": 1291.5216378616224
        },
        "claude-3-5-sonnet-20241022": {
            "rating": 1297.6211586499317,
            "rating_q975": 1300.6437017579003,
            "rating_q025": 1294.598615541963
        },
        "deepseek-v2.5-1210": {
            "rating": 1293.0686845055702,
            "rating_q975": 1301.2982442026496,
            "rating_q025": 1284.8391248084909
        },
        "athene-v2-chat": {
            "rating": 1290.2036094588868,
            "rating_q975": 1294.6736217850391,
            "rating_q025": 1285.7335971327345
        },
        "glm-4-plus": {
            "rating": 1288.8034968400602,
            "rating_q975": 1293.6553286702133,
            "rating_q025": 1283.9516650099072
        },
        "gemma-3-4b-it": {
            "rating": 1288.3925752498922,
            "rating_q975": 1297.7196795031396,
            "rating_q025": 1279.0654709966448
        },
        "hunyuan-large-2025-02-10": {
            "rating": 1287.8102457334053,
            "rating_q975": 1297.709013874224,
            "rating_q025": 1277.9114775925866
        },
        "llama-4-maverick-17b-128e-instruct": {
            "rating": 1287.4191598430634,
            "rating_q975": 1291.654640336813,
            "rating_q025": 1283.183679349314
        },
        "gpt-oss-20b": {
            "rating": 1286.703799742367,
            "rating_q975": 1293.099519105107,
            "rating_q025": 1280.308080379627
        },
        "gemini-1.5-flash-002": {
            "rating": 1286.5946546565367,
            "rating_q975": 1290.700656751788,
            "rating_q025": 1282.4886525612853
        },
        "mercury": {
            "rating": 1286.5137475731235,
            "rating_q975": 1300.3036635310764,
            "rating_q025": 1272.7238316151706
        },
        "gpt-4o-mini-2024-07-18": {
            "rating": 1285.148742801403,
            "rating_q975": 1288.5330324345873,
            "rating_q025": 1281.7644531682186
        },
        "gpt-4.1-nano-2025-04-14": {
            "rating": 1284.676732830902,
            "rating_q975": 1292.4084047446538,
            "rating_q025": 1276.9450609171502
        },
        "llama-3.1-405b-instruct-bf16": {
            "rating": 1282.7038786417233,
            "rating_q975": 1286.272924924478,
            "rating_q025": 1279.1348323589687
        },
        "gpt-4o-2024-08-06": {
            "rating": 1282.3784130243207,
            "rating_q975": 1286.4967584686292,
            "rating_q025": 1278.2600675800122
        },
        "llama-3.1-nemotron-70b-instruct": {
            "rating": 1281.9354300456653,
            "rating_q975": 1289.642238283427,
            "rating_q025": 1274.2286218079034
        },
        "qwen-max-0919": {
            "rating": 1281.905270366794,
            "rating_q975": 1287.5527464713464,
            "rating_q025": 1276.2577942622415
        },
        "llama-3.1-405b-instruct-fp8": {
            "rating": 1281.2776843456893,
            "rating_q975": 1284.745394812583,
            "rating_q025": 1277.8099738787955
        },
        "grok-2-mini-2024-08-13": {
            "rating": 1280.38099573941,
            "rating_q975": 1283.98399853023,
            "rating_q025": 1276.77799294859
        },
        "claude-3-5-sonnet-20240620": {
            "rating": 1280.3014881560832,
            "rating_q975": 1283.6539141357205,
            "rating_q025": 1276.949062176446
        },
        "llama-4-scout-17b-16e-instruct": {
            "rating": 1279.6382341741546,
            "rating_q975": 1284.3372118794287,
            "rating_q025": 1274.9392564688806
        },
        "gemini-advanced-0514": {
            "rating": 1277.8622791285852,
            "rating_q975": 1282.9778886699055,
            "rating_q025": 1272.746669587265
        },
        "mistral-small-3.1-24b-instruct-2503": {
            "rating": 1277.629946794565,
            "rating_q975": 1282.1402993125582,
            "rating_q025": 1273.119594276572
        },
        "llama-3.3-70b-instruct": {
            "rating": 1274.455085213545,
            "rating_q975": 1277.8105758471866,
            "rating_q025": 1271.0995945799036
        },
        "hunyuan-standard-2025-02-10": {
            "rating": 1273.963686293298,
            "rating_q975": 1283.774933156905,
            "rating_q025": 1264.152439429691
        },
        "gemini-1.5-pro-001": {
            "rating": 1272.471370838679,
            "rating_q975": 1276.3944936383295,
            "rating_q025": 1268.5482480390283
        },
        "gpt-4-turbo-2024-04-09": {
            "rating": 1271.630575567303,
            "rating_q975": 1275.4770976249679,
            "rating_q025": 1267.784053509638
        },
        "deepseek-v2.5": {
            "rating": 1270.5601070598857,
            "rating_q975": 1275.1849147943597,
            "rating_q025": 1265.9352993254117
        },
        "qwen2.5-72b-instruct": {
            "rating": 1268.7309593697846,
            "rating_q975": 1272.7005870002836,
            "rating_q025": 1264.7613317392857
        },
        "mistral-large-2407": {
            "rating": 1265.5941460699908,
            "rating_q975": 1269.417719718371,
            "rating_q025": 1261.7705724216105
        },
        "hunyuan-large-vision": {
            "rating": 1265.2031497469802,
            "rating_q975": 1274.3926931716449,
            "rating_q025": 1256.0136063223156
        },
        "mistral-large-2411": {
            "rating": 1264.9700550657253,
            "rating_q975": 1269.296847409468,
            "rating_q025": 1260.6432627219826
        },
        "athene-70b-0725": {
            "rating": 1263.5497785578107,
            "rating_q975": 1269.1578781934213,
            "rating_q025": 1257.9416789222
        },
        "gpt-4-1106-preview": {
            "rating": 1263.1063963054773,
            "rating_q975": 1266.9482242661466,
            "rating_q025": 1259.2645683448081
        },
        "claude-3-opus-20240229": {
            "rating": 1261.7351455701241,
            "rating_q975": 1264.676740435955,
            "rating_q025": 1258.7935507042932
        },
        "gpt-4-0125-preview": {
            "rating": 1261.4024894493302,
            "rating_q975": 1265.4626330921508,
            "rating_q025": 1257.3423458065097
        },
        "llama-3.1-70b-instruct": {
            "rating": 1260.3860289810477,
            "rating_q975": 1263.9932349248802,
            "rating_q025": 1256.7788230372153
        },
        "amazon-nova-pro-v1.0": {
            "rating": 1257.6765775903675,
            "rating_q975": 1262.1185659915604,
            "rating_q025": 1253.2345891891746
        },
        "llama-3.1-tulu-3-70b": {
            "rating": 1255.1287490106272,
            "rating_q975": 1265.6247260508412,
            "rating_q025": 1244.6327719704132
        },
        "claude-3-5-haiku-20241022": {
            "rating": 1254.9962278305115,
            "rating_q975": 1258.1198855000437,
            "rating_q025": 1251.8725701609794
        },
        "magistral-medium-2506": {
            "rating": 1254.7149591528207,
            "rating_q975": 1261.1147487115857,
            "rating_q025": 1248.3151695940558
        },
        "reka-core-20240904": {
            "rating": 1246.5276249319882,
            "rating_q975": 1253.6295651258595,
            "rating_q025": 1239.4256847381168
        },
        "gemini-1.5-flash-001": {
            "rating": 1237.963620017435,
            "rating_q975": 1242.391291741572,
            "rating_q025": 1233.535948293298
        },
        "jamba-1.5-large": {
            "rating": 1236.4057825119494,
            "rating_q975": 1243.7332531440288,
            "rating_q025": 1229.07831187987
        },
        "mistral-small-24b-instruct-2501": {
            "rating": 1232.8415141922185,
            "rating_q975": 1238.673416008461,
            "rating_q025": 1227.009612375976
        },
        "gemma-2-27b-it": {
            "rating": 1230.7866065570756,
            "rating_q975": 1234.0368548488404,
            "rating_q025": 1227.5363582653108
        },
        "command-r-plus-08-2024": {
            "rating": 1228.8280302522421,
            "rating_q975": 1235.3618377071232,
            "rating_q025": 1222.294222797361
        },
        "qwen2.5-coder-32b-instruct": {
            "rating": 1228.7021324287375,
            "rating_q975": 1236.773454422238,
            "rating_q025": 1220.630810435237
        },
        "amazon-nova-lite-v1.0": {
            "rating": 1227.2710912450843,
            "rating_q975": 1232.3179229284513,
            "rating_q025": 1222.2242595617174
        },
        "llama-3.1-nemotron-51b-instruct": {
            "rating": 1227.0114784168595,
            "rating_q975": 1236.9943871370947,
            "rating_q025": 1217.0285696966243
        },
        "gemma-2-9b-it-simpo": {
            "rating": 1226.3223581376042,
            "rating_q975": 1233.2064091698282,
            "rating_q025": 1219.43830710538
        },
        "gemini-1.5-flash-8b-001": {
            "rating": 1225.4445156393144,
            "rating_q975": 1229.6131055238159,
            "rating_q025": 1221.275925754813
        },
        "glm-4-0520": {
            "rating": 1225.304647542347,
            "rating_q975": 1232.2842660897827,
            "rating_q025": 1218.3250289949115
        },
        "nemotron-4-340b-instruct": {
            "rating": 1224.3396958777846,
            "rating_q975": 1229.6314275984898,
            "rating_q025": 1219.0479641570794
        },
        "c4ai-aya-expanse-32b": {
            "rating": 1223.870477947692,
            "rating_q975": 1228.6586525598414,
            "rating_q025": 1219.0823033355427
        },
        "llama-3-70b-instruct": {
            "rating": 1219.7642171546263,
            "rating_q975": 1223.3363166499357,
            "rating_q025": 1216.1921176593169
        },
        "claude-3-sonnet-20240229": {
            "rating": 1217.526690104944,
            "rating_q975": 1221.5134715774623,
            "rating_q025": 1213.5399086324257
        },
        "reka-flash-20240904": {
            "rating": 1217.3850112255823,
            "rating_q975": 1224.3148688698382,
            "rating_q025": 1210.4551535813264
        },
        "olmo-2-0325-32b-instruct": {
            "rating": 1217.14847437362,
            "rating_q975": 1227.9706954438786,
            "rating_q025": 1206.3262533033615
        },
        "phi-4": {
            "rating": 1215.4508915593447,
            "rating_q975": 1219.952303291828,
            "rating_q025": 1210.9494798268613
        },
        "amazon-nova-micro-v1.0": {
            "rating": 1208.2254524169807,
            "rating_q975": 1213.2563976470592,
            "rating_q025": 1203.1945071869022
        },
        "gemma-2-9b-it": {
            "rating": 1206.4328637338715,
            "rating_q975": 1210.1296652300389,
            "rating_q025": 1202.7360622377041
        },
        "gpt-4-0314": {
            "rating": 1205.3180912882162,
            "rating_q975": 1210.1502442485007,
            "rating_q025": 1200.4859383279318
        },
        "command-r-plus": {
            "rating": 1204.5936204858867,
            "rating_q975": 1208.8910515943737,
            "rating_q025": 1200.2961893773997
        },
        "hunyuan-standard-256k": {
            "rating": 1204.0869698648416,
            "rating_q975": 1215.7212039605538,
            "rating_q025": 1192.4527357691295
        },
        "qwen2-72b-instruct": {
            "rating": 1202.0770634989397,
            "rating_q975": 1206.9663321769217,
            "rating_q025": 1197.1877948209576
        },
        "llama-3.1-tulu-3-8b": {
            "rating": 1194.7129635838546,
            "rating_q975": 1205.2314696881356,
            "rating_q025": 1184.1944574795737
        },
        "claude-3-haiku-20240307": {
            "rating": 1193.783913149329,
            "rating_q975": 1197.4822115959967,
            "rating_q025": 1190.0856147026614
        },
        "deepseek-coder-v2": {
            "rating": 1190.937630630372,
            "rating_q975": 1197.314643908556,
            "rating_q025": 1184.560617352188
        },
        "ministral-8b-2410": {
            "rating": 1189.7694182698165,
            "rating_q975": 1198.7798383302336,
            "rating_q025": 1180.7589982093994
        },
        "command-r-08-2024": {
            "rating": 1187.3835061539316,
            "rating_q975": 1193.8984133372908,
            "rating_q025": 1180.8685989705725
        },
        "jamba-1.5-mini": {
            "rating": 1186.2443219012162,
            "rating_q975": 1193.442428331566,
            "rating_q025": 1179.0462154708664
        },
        "llama-3.1-8b-instruct": {
            "rating": 1186.0384350865083,
            "rating_q975": 1190.048813039792,
            "rating_q025": 1182.0280571332246
        },
        "gpt-4-0613": {
            "rating": 1185.9380403720384,
            "rating_q975": 1190.009657030065,
            "rating_q025": 1181.8664237140117
        },
        "c4ai-aya-expanse-8b": {
            "rating": 1185.7768695059067,
            "rating_q975": 1192.6591154008606,
            "rating_q025": 1178.8946236109527
        },
        "mistral-large-2402": {
            "rating": 1175.7727988120528,
            "rating_q975": 1180.4859613647652,
            "rating_q025": 1171.0596362593403
        },
        "qwen1.5-110b-chat": {
            "rating": 1173.8821482697936,
            "rating_q975": 1179.4467561652575,
            "rating_q025": 1168.3175403743296
        },
        "yi-1.5-34b-chat": {
            "rating": 1171.2950709301533,
            "rating_q975": 1176.327940298832,
            "rating_q025": 1166.2622015614747
        },
        "reka-flash-21b-20240226-online": {
            "rating": 1169.24550841074,
            "rating_q975": 1176.6579703669308,
            "rating_q025": 1161.8330464545493
        },
        "qwen1.5-72b-chat": {
            "rating": 1164.9834577974802,
            "rating_q975": 1170.2293549985473,
            "rating_q025": 1159.7375605964132
        },
        "mistral-medium": {
            "rating": 1164.1214599883556,
            "rating_q975": 1169.62298335656,
            "rating_q025": 1158.619936620151
        },
        "llama-3-8b-instruct": {
            "rating": 1163.4269658509756,
            "rating_q975": 1167.1428278732062,
            "rating_q025": 1159.711103828745
        },
        "reka-flash-21b-20240226": {
            "rating": 1162.9140875422318,
            "rating_q975": 1168.876716233753,
            "rating_q025": 1156.9514588507104
        },
        "command-r": {
            "rating": 1162.3328697707705,
            "rating_q975": 1167.08702019233,
            "rating_q025": 1157.5787193492108
        },
        "mixtral-8x22b-instruct-v0.1": {
            "rating": 1161.7936463420629,
            "rating_q975": 1166.3038482977447,
            "rating_q025": 1157.283444386381
        },
        "qwq-32b-preview": {
            "rating": 1161.1800845036987,
            "rating_q975": 1172.6578565891123,
            "rating_q025": 1149.7023124182851
        },
        "internlm2_5-20b-chat": {
            "rating": 1158.6157881705153,
            "rating_q975": 1165.6853104513195,
            "rating_q025": 1151.546265889711
        },
        "gemma-2-2b-it": {
            "rating": 1154.52247755456,
            "rating_q975": 1158.4734594948288,
            "rating_q025": 1150.5714956142913
        },
        "granite-3.1-8b-instruct": {
            "rating": 1148.7072631447577,
            "rating_q975": 1159.6509476427984,
            "rating_q025": 1137.763578646717
        },
        "gemini-pro-dev-api": {
            "rating": 1147.5170858392903,
            "rating_q975": 1154.8508258492784,
            "rating_q025": 1140.1833458293022
        },
        "zephyr-orpo-141b-A35b-v0.1": {
            "rating": 1144.3752745451245,
            "rating_q975": 1155.2730621907165,
            "rating_q025": 1133.4774868995326
        },
        "qwen1.5-32b-chat": {
            "rating": 1136.6355278192332,
            "rating_q975": 1142.7836784979315,
            "rating_q025": 1130.4873771405348
        },
        "phi-3-medium-4k-instruct": {
            "rating": 1136.2979084732526,
            "rating_q975": 1141.4077745603802,
            "rating_q025": 1131.188042386125
        },
        "mixtral-8x7b-instruct-v0.1": {
            "rating": 1130.9049602189775,
            "rating_q975": 1135.1690073000677,
            "rating_q025": 1126.6409131378873
        },
        "starling-lm-7b-beta": {
            "rating": 1130.8175923055842,
            "rating_q975": 1138.2186634292293,
            "rating_q025": 1123.416521181939
        },
        "gemini-pro": {
            "rating": 1129.4983667485706,
            "rating_q975": 1141.208048414239,
            "rating_q025": 1117.788685082902
        },
        "granite-3.1-2b-instruct": {
            "rating": 1128.7876627445187,
            "rating_q975": 1139.8528042746818,
            "rating_q025": 1117.7225212143555
        },
        "yi-34b-chat": {
            "rating": 1127.8104108202483,
            "rating_q975": 1134.671495319646,
            "rating_q025": 1120.9493263208506
        },
        "qwen1.5-14b-chat": {
            "rating": 1127.2362128100413,
            "rating_q975": 1134.372449394727,
            "rating_q025": 1120.0999762253555
        },
        "gpt-3.5-turbo-0125": {
            "rating": 1123.6441760524108,
            "rating_q975": 1128.3424522690855,
            "rating_q025": 1118.945899835736
        },
        "tulu-2-dpo-70b": {
            "rating": 1120.1917501679293,
            "rating_q975": 1130.10182725268,
            "rating_q025": 1110.2816730831785
        },
        "dbrx-instruct-preview": {
            "rating": 1118.6023384719622,
            "rating_q975": 1124.7072865851371,
            "rating_q025": 1112.4973903587872
        },
        "wizardlm-70b": {
            "rating": 1117.097001168266,
            "rating_q975": 1126.6219126493113,
            "rating_q025": 1107.5720896872206
        },
        "llama-2-70b-chat": {
            "rating": 1114.5185858538866,
            "rating_q975": 1120.0777302099893,
            "rating_q025": 1108.959441497784
        },
        "nous-hermes-2-mixtral-8x7b-dpo": {
            "rating": 1110.665726785748,
            "rating_q975": 1122.6316500891314,
            "rating_q025": 1098.6998034823644
        },
        "phi-3-small-8k-instruct": {
            "rating": 1109.1092680247289,
            "rating_q975": 1115.0001088088964,
            "rating_q025": 1103.2184272405614
        },
        "llama-3.2-3b-instruct": {
            "rating": 1107.6582979519903,
            "rating_q975": 1115.2210239694537,
            "rating_q025": 1100.095571934527
        },
        "starling-lm-7b-alpha": {
            "rating": 1106.4762755458983,
            "rating_q975": 1114.549574991632,
            "rating_q025": 1098.4029761001646
        },
        "openchat-3.5-0106": {
            "rating": 1104.3464132343727,
            "rating_q975": 1112.3432630266677,
            "rating_q025": 1096.3495634420776
        },
        "vicuna-33b": {
            "rating": 1103.4920807878907,
            "rating_q975": 1109.7421036531798,
            "rating_q025": 1097.2420579226016
        },
        "deepseek-llm-67b-chat": {
            "rating": 1102.3137411103744,
            "rating_q975": 1114.1063729276268,
            "rating_q025": 1090.521109293122
        },
        "snowflake-arctic-instruct": {
            "rating": 1098.8437693385727,
            "rating_q975": 1104.8165498284084,
            "rating_q025": 1092.870988848737
        },
        "granite-3.0-8b-instruct": {
            "rating": 1097.8665937709507,
            "rating_q975": 1106.4386329715412,
            "rating_q025": 1089.29455457036
        },
        "llama2-70b-steerlm-chat": {
            "rating": 1096.7291987544004,
            "rating_q975": 1109.4540386790206,
            "rating_q025": 1084.0043588297801
        },
        "openchat-3.5": {
            "rating": 1094.939500007053,
            "rating_q975": 1104.7577416962822,
            "rating_q025": 1085.121258317824
        },
        "gpt-3.5-turbo-1106": {
            "rating": 1091.7840740016263,
            "rating_q975": 1100.6801775343079,
            "rating_q025": 1082.8879704689448
        },
        "openhermes-2.5-mistral-7b": {
            "rating": 1091.5986950742617,
            "rating_q975": 1102.1590785932617,
            "rating_q025": 1081.0383115552618
        },
        "gemma-1.1-7b-it": {
            "rating": 1091.5773237675533,
            "rating_q975": 1097.6210830888836,
            "rating_q025": 1085.533564446223
        },
        "mistral-7b-instruct-v0.2": {
            "rating": 1087.506369011503,
            "rating_q975": 1094.163590356757,
            "rating_q025": 1080.849147666249
        },
        "llama-2-13b-chat": {
            "rating": 1083.4871987224763,
            "rating_q975": 1090.246896759694,
            "rating_q025": 1076.7275006852585
        },
        "solar-10.7b-instruct-v1.0": {
            "rating": 1083.13784573695,
            "rating_q975": 1096.4947366653262,
            "rating_q025": 1069.780954808574
        },
        "qwen1.5-7b-chat": {
            "rating": 1081.235354392125,
            "rating_q975": 1091.05780588363,
            "rating_q025": 1071.4129029006199
        },
        "dolphin-2.2.1-mistral-7b": {
            "rating": 1079.8250144673052,
            "rating_q975": 1095.5646181460493,
            "rating_q025": 1064.0854107885611
        },
        "granite-3.0-2b-instruct": {
            "rating": 1079.3132243727396,
            "rating_q975": 1087.5593226980877,
            "rating_q025": 1071.0671260473914
        },
        "phi-3-mini-4k-instruct-june-2024": {
            "rating": 1078.462215002238,
            "rating_q975": 1084.8267295475546,
            "rating_q025": 1072.0977004569215
        },
        "wizardlm-13b": {
            "rating": 1075.1549918244937,
            "rating_q975": 1084.6810702416583,
            "rating_q025": 1065.628913407329
        },
        "phi-3-mini-4k-instruct": {
            "rating": 1071.9339979592355,
            "rating_q975": 1078.2391477898377,
            "rating_q025": 1065.6288481286333
        },
        "zephyr-7b-beta": {
            "rating": 1066.6729365936737,
            "rating_q975": 1075.5779411716928,
            "rating_q025": 1057.7679320156547
        },
        "mpt-30b-chat": {
            "rating": 1066.6236013189841,
            "rating_q975": 1079.1010045633793,
            "rating_q025": 1054.146198074589
        },
        "codellama-34b-instruct": {
            "rating": 1062.857377809393,
            "rating_q975": 1071.8061420524848,
            "rating_q025": 1053.9086135663013
        },
        "zephyr-7b-alpha": {
            "rating": 1056.9874314824347,
            "rating_q975": 1073.2274061087828,
            "rating_q025": 1040.7474568560865
        },
        "vicuna-13b": {
            "rating": 1056.2062619506262,
            "rating_q975": 1062.9383823012818,
            "rating_q025": 1049.4741415999706
        },
        "codellama-70b-instruct": {
            "rating": 1054.7749080552699,
            "rating_q975": 1073.3845908720689,
            "rating_q025": 1036.1652252384708
        },
        "falcon-180b-chat": {
            "rating": 1054.1793615977497,
            "rating_q975": 1071.7363381377995,
            "rating_q025": 1036.6223850576998
        },
        "llama-3.2-1b-instruct": {
            "rating": 1053.336829879495,
            "rating_q975": 1061.0659907616607,
            "rating_q025": 1045.6076689973295
        },
        "gemma-7b-it": {
            "rating": 1053.1359082619115,
            "rating_q975": 1062.8311711904298,
            "rating_q025": 1043.4406453333931
        },
        "guanaco-33b": {
            "rating": 1052.7433030818013,
            "rating_q975": 1065.108177114498,
            "rating_q025": 1040.3784290491046
        },
        "llama-2-7b-chat": {
            "rating": 1051.1625479894446,
            "rating_q975": 1058.2448108779636,
            "rating_q025": 1044.0802851009257
        },
        "qwen-14b-chat": {
            "rating": 1048.7423400083592,
            "rating_q975": 1059.8454524947254,
            "rating_q025": 1037.639227521993
        },
        "phi-3-mini-128k-instruct": {
            "rating": 1048.255852706151,
            "rating_q975": 1055.5832237128106,
            "rating_q025": 1040.9284816994914
        },
        "smollm2-1.7b-instruct": {
            "rating": 1044.8997565431773,
            "rating_q975": 1059.1699082926402,
            "rating_q025": 1030.6296047937144
        },
        "stripedhyena-nous-7b": {
            "rating": 1036.4098855852235,
            "rating_q975": 1047.5581811556367,
            "rating_q025": 1025.2615900148103
        },
        "vicuna-7b": {
            "rating": 1029.6105470377279,
            "rating_q975": 1039.0081116635135,
            "rating_q025": 1020.2129824119422
        },
        "olmo-7b-instruct": {
            "rating": 1028.637237364499,
            "rating_q975": 1039.9340523346357,
            "rating_q025": 1017.3404223943623
        },
        "palm-2": {
            "rating": 1024.106963350101,
            "rating_q975": 1033.6423553573757,
            "rating_q025": 1014.5715713428266
        },
        "mistral-7b-instruct": {
            "rating": 1021.920037244463,
            "rating_q975": 1031.2865225744872,
            "rating_q025": 1012.5535519144386
        },
        "gemma-1.1-2b-it": {
            "rating": 1018.835788405216,
            "rating_q975": 1026.615351888983,
            "rating_q025": 1011.0562249214491
        },
        "gemma-2b-it": {
            "rating": 999.0427612201604,
            "rating_q975": 1010.8575104230177,
            "rating_q025": 987.2280120173031
        },
        "qwen1.5-4b-chat": {
            "rating": 994.3682017915606,
            "rating_q975": 1003.7857451298263,
            "rating_q025": 984.950658453295
        },
        "koala-13b": {
            "rating": 986.1304797082009,
            "rating_q975": 996.3273145075539,
            "rating_q025": 975.933644908848
        },
        "chatglm3-6b": {
            "rating": 968.9866359790617,
            "rating_q975": 980.7908258700646,
            "rating_q025": 957.1824460880588
        },
        "gpt4all-13b-snoozy": {
            "rating": 953.5937491071214,
            "rating_q975": 969.2267497545955,
            "rating_q025": 937.9607484596473
        },
        "mpt-7b-chat": {
            "rating": 951.3673272611891,
            "rating_q975": 963.5343270554785,
            "rating_q025": 939.2003274668997
        },
        "RWKV-4-Raven-14B": {
            "rating": 944.6295820346666,
            "rating_q975": 956.2971352779799,
            "rating_q025": 932.9620287913532
        },
        "chatglm2-6b": {
            "rating": 935.0227996749215,
            "rating_q975": 948.8888152711597,
            "rating_q025": 921.1567840786834
        },
        "alpaca-13b": {
            "rating": 926.1486686227518,
            "rating_q975": 937.8399683992737,
            "rating_q025": 914.4573688462298
        },
        "oasst-pythia-12b": {
            "rating": 913.2710220574485,
            "rating_q975": 924.4337619226558,
            "rating_q025": 902.1082821922412
        },
        "chatglm-6b": {
            "rating": 913.1413873843685,
            "rating_q975": 925.9895025006638,
            "rating_q025": 900.2932722680732
        },
        "fastchat-t5-3b": {
            "rating": 889.9575571374457,
            "rating_q975": 902.7308309497811,
            "rating_q025": 877.1842833251104
        },
        "stablelm-tuned-alpha-7b": {
            "rating": 861.8978194542118,
            "rating_q975": 875.1275322256417,
            "rating_q025": 848.6681066827819
        },
        "dolly-v2-12b": {
            "rating": 846.1891820689102,
            "rating_q975": 860.0277398902206,
            "rating_q025": 832.3506242475999
        },
        "llama-13b": {
            "rating": 830.829171741581,
            "rating_q975": 847.0979570991313,
            "rating_q025": 814.5603863840307
        }
    },
    "no_tie": {
        "gemini-3-pro": {
            "rating": 1499.8511982142375,
            "rating_q975": 1508.4289189007875,
            "rating_q025": 1491.2734775276874
        },
        "gemini-2.5-pro": {
            "rating": 1470.4696938798004,
            "rating_q975": 1475.313509886923,
            "rating_q025": 1465.6258778726778
        },
        "grok-4.1-thinking": {
            "rating": 1450.3401720867682,
            "rating_q975": 1458.5591808076733,
            "rating_q025": 1442.1211633658631
        },
        "ernie-5.0-preview-1103": {
            "rating": 1445.9513665617542,
            "rating_q975": 1458.1927635376521,
            "rating_q025": 1433.7099695858562
        },
        "claude-opus-4-5-20251101": {
            "rating": 1444.4704973439677,
            "rating_q975": 1453.768860349438,
            "rating_q025": 1435.1721343384975
        },
        "gpt-5.1-high": {
            "rating": 1442.589316775478,
            "rating_q975": 1451.1145113661762,
            "rating_q025": 1434.0641221847798
        },
        "grok-4.1": {
            "rating": 1440.3302889951924,
            "rating_q975": 1448.5475150922448,
            "rating_q025": 1432.11306289814
        },
        "glm-4.6": {
            "rating": 1438.4764468939172,
            "rating_q975": 1445.0895785127398,
            "rating_q025": 1431.8633152750947
        },
        "claude-opus-4-5-20251101-thinking-32k": {
            "rating": 1438.032404924976,
            "rating_q975": 1447.5705941253318,
            "rating_q025": 1428.49421572462
        },
        "qwen3-max-preview": {
            "rating": 1434.7390788580533,
            "rating_q975": 1441.11794938632,
            "rating_q025": 1428.3602083297865
        },
        "mistral-large-3": {
            "rating": 1425.8642147758983,
            "rating_q975": 1437.0852663414173,
            "rating_q025": 1414.6431632103793
        },
        "mistral-medium-2508": {
            "rating": 1424.0586089534047,
            "rating_q975": 1429.4621600244511,
            "rating_q025": 1418.6550578823583
        },
        "chatgpt-4o-latest-20250326": {
            "rating": 1420.2395791786878,
            "rating_q975": 1424.8705344928528,
            "rating_q025": 1415.6086238645228
        },
        "glm-4.5": {
            "rating": 1420.0122942269502,
            "rating_q975": 1426.781883925884,
            "rating_q025": 1413.2427045280165
        },
        "claude-sonnet-4-5-20250929": {
            "rating": 1417.8563299322134,
            "rating_q975": 1424.621441791791,
            "rating_q025": 1411.0912180726357
        },
        "grok-3-preview-02-24": {
            "rating": 1417.360681953386,
            "rating_q975": 1423.3184902278915,
            "rating_q025": 1411.4028736788803
        },
        "deepseek-r1-0528": {
            "rating": 1417.2537084419932,
            "rating_q975": 1424.9871669021968,
            "rating_q025": 1409.5202499817897
        },
        "deepseek-v3.2-exp": {
            "rating": 1416.791407158638,
            "rating_q975": 1425.8162062132562,
            "rating_q025": 1407.76660810402
        },
        "claude-sonnet-4-5-20250929-thinking-32k": {
            "rating": 1416.6056642231074,
            "rating_q975": 1422.7344409543095,
            "rating_q025": 1410.4768874919052
        },
        "longcat-flash-chat": {
            "rating": 1411.8476377407503,
            "rating_q975": 1420.5759529283691,
            "rating_q025": 1403.1193225531315
        },
        "gpt-4.5-preview-2025-02-27": {
            "rating": 1410.9026118054987,
            "rating_q975": 1419.3294967231361,
            "rating_q025": 1402.4757268878614
        },
        "qwen3-vl-235b-a22b-instruct": {
            "rating": 1410.484737817188,
            "rating_q975": 1419.956914274254,
            "rating_q025": 1401.0125613601222
        },
        "deepseek-v3.2-exp-thinking": {
            "rating": 1409.6871224058518,
            "rating_q975": 1418.7671354946845,
            "rating_q025": 1400.6071093170192
        },
        "gpt-5.1": {
            "rating": 1408.6307983936542,
            "rating_q975": 1416.8809940443139,
            "rating_q025": 1400.3806027429946
        },
        "qwen3-235b-a22b-instruct-2507": {
            "rating": 1407.72034455731,
            "rating_q975": 1412.8572400969895,
            "rating_q025": 1402.5834490176305
        },
        "claude-opus-4-1-20250805-thinking-16k": {
            "rating": 1407.6162286756448,
            "rating_q975": 1412.8670425972182,
            "rating_q025": 1402.3654147540715
        },
        "deepseek-v3.1": {
            "rating": 1405.5074357079718,
            "rating_q975": 1413.7569978597692,
            "rating_q025": 1397.2578735561744
        },
        "qwen3-next-80b-a3b-instruct": {
            "rating": 1405.317609660705,
            "rating_q975": 1411.9454422104786,
            "rating_q025": 1398.6897771109316
        },
        "deepseek-v3.1-terminus": {
            "rating": 1404.3695028332274,
            "rating_q975": 1418.1231297720979,
            "rating_q025": 1390.615875894357
        },
        "deepseek-v3.2-thinking": {
            "rating": 1403.7433728878534,
            "rating_q975": 1415.156869720827,
            "rating_q025": 1392.3298760548798
        },
        "deepseek-v3.1-terminus-thinking": {
            "rating": 1403.4515128127364,
            "rating_q975": 1417.6241311903757,
            "rating_q025": 1389.278894435097
        },
        "deepseek-v3.2": {
            "rating": 1403.3355608340642,
            "rating_q975": 1414.4036616946546,
            "rating_q025": 1392.2674599734737
        },
        "deepseek-v3.1-thinking": {
            "rating": 1402.7037766498568,
            "rating_q975": 1411.6235100243418,
            "rating_q025": 1393.7840432753717
        },
        "gemini-2.5-flash": {
            "rating": 1400.7464440582114,
            "rating_q975": 1405.4005724451122,
            "rating_q025": 1396.0923156713106
        },
        "qwen3-max-2025-09-23": {
            "rating": 1399.3900287660215,
            "rating_q975": 1408.5206005147797,
            "rating_q025": 1390.2594570172632
        },
        "qwen3-235b-a22b-thinking-2507": {
            "rating": 1398.445847850958,
            "rating_q975": 1407.601686900775,
            "rating_q025": 1389.290008801141
        },
        "claude-opus-4-1-20250805": {
            "rating": 1397.0416808417879,
            "rating_q975": 1402.0731599548692,
            "rating_q025": 1392.0102017287065
        },
        "o3-2025-04-16": {
            "rating": 1394.4303498513593,
            "rating_q975": 1399.4216223761782,
            "rating_q025": 1389.4390773265404
        },
        "kimi-k2-thinking-turbo": {
            "rating": 1393.5970048549623,
            "rating_q975": 1401.5179966923415,
            "rating_q025": 1385.676013017583
        },
        "grok-4-1-fast-reasoning": {
            "rating": 1392.9555920166392,
            "rating_q975": 1402.5806883607977,
            "rating_q025": 1383.3304956724808
        },
        "grok-4-0709": {
            "rating": 1392.298488966522,
            "rating_q975": 1397.6427743941788,
            "rating_q025": 1386.9542035388652
        },
        "grok-4-fast-chat": {
            "rating": 1390.7917598145693,
            "rating_q975": 1401.125182756342,
            "rating_q025": 1380.4583368727967
        },
        "gemini-2.5-flash-preview-09-2025": {
            "rating": 1389.59523940621,
            "rating_q975": 1395.6517937379685,
            "rating_q025": 1383.5386850744517
        },
        "gpt-5-high": {
            "rating": 1388.771096071371,
            "rating_q975": 1394.747808446153,
            "rating_q025": 1382.794383696589
        },
        "hunyuan-vision-1.5-thinking": {
            "rating": 1383.800865101849,
            "rating_q975": 1401.3171696771328,
            "rating_q025": 1366.2845605265652
        },
        "gpt-5-chat": {
            "rating": 1383.5613246189982,
            "rating_q975": 1389.4648077808854,
            "rating_q025": 1377.657841457111
        },
        "qwen3-vl-235b-a22b-thinking": {
            "rating": 1378.9017993662226,
            "rating_q975": 1388.5329504619322,
            "rating_q025": 1369.270648270513
        },
        "hunyuan-t1-20250711": {
            "rating": 1376.5742803182388,
            "rating_q975": 1388.7542709129148,
            "rating_q025": 1364.394289723563
        },
        "amazon-nova-experimental-chat-10-20": {
            "rating": 1376.1035440729963,
            "rating_q975": 1386.032363402751,
            "rating_q025": 1366.1747247432418
        },
        "grok-4-fast-reasoning": {
            "rating": 1374.4643502587712,
            "rating_q975": 1381.5411791789709,
            "rating_q025": 1367.3875213385716
        },
        "mai-1-preview": {
            "rating": 1372.3295093829622,
            "rating_q975": 1379.831813648511,
            "rating_q025": 1364.8272051174135
        },
        "qwen3-235b-a22b-no-thinking": {
            "rating": 1368.7382102375489,
            "rating_q975": 1374.7545445037215,
            "rating_q025": 1362.7218759713762
        },
        "claude-haiku-4-5-20251001": {
            "rating": 1359.3951286961517,
            "rating_q975": 1365.7651023649619,
            "rating_q025": 1353.0251550273415
        },
        "qwen3-30b-a3b-instruct-2507": {
            "rating": 1357.6691182897866,
            "rating_q975": 1364.3893793598606,
            "rating_q025": 1350.9488572197126
        },
        "glm-4.5-air": {
            "rating": 1355.7081696885741,
            "rating_q975": 1361.6707494623986,
            "rating_q025": 1349.7455899147496
        },
        "gpt-4.1-2025-04-14": {
            "rating": 1354.9133736999172,
            "rating_q975": 1359.9918549621507,
            "rating_q025": 1349.8348924376837
        },
        "kimi-k2-0905-preview": {
            "rating": 1351.268908045778,
            "rating_q975": 1359.850454487435,
            "rating_q025": 1342.6873616041212
        },
        "gemini-2.5-flash-lite-preview-09-2025-no-thinking": {
            "rating": 1349.8301219658863,
            "rating_q975": 1355.916318597388,
            "rating_q025": 1343.7439253343846
        },
        "hunyuan-turbos-20250416": {
            "rating": 1346.760218248294,
            "rating_q975": 1355.5514235335022,
            "rating_q025": 1337.9690129630858
        },
        "deepseek-r1": {
            "rating": 1345.5978276057567,
            "rating_q975": 1352.6923874696333,
            "rating_q025": 1338.50326774188
        },
        "gpt-5-mini-high": {
            "rating": 1344.7115172720576,
            "rating_q975": 1350.8795819411964,
            "rating_q025": 1338.5434526029187
        },
        "deepseek-v3-0324": {
            "rating": 1344.345982000822,
            "rating_q975": 1349.6975689746296,
            "rating_q025": 1338.9943950270144
        },
        "claude-opus-4-20250514-thinking-16k": {
            "rating": 1343.5849801155975,
            "rating_q975": 1349.3957201295907,
            "rating_q025": 1337.7742401016044
        },
        "kimi-k2-0711-preview": {
            "rating": 1338.7643434810304,
            "rating_q975": 1345.1233283599286,
            "rating_q025": 1332.4053586021323
        },
        "mistral-medium-2505": {
            "rating": 1337.5884855868924,
            "rating_q975": 1343.9508563187721,
            "rating_q025": 1331.2261148550126
        },
        "qwen2.5-max": {
            "rating": 1336.6611349931125,
            "rating_q975": 1342.4790880420317,
            "rating_q025": 1330.8431819441932
        },
        "gemini-2.5-flash-lite-preview-06-17-thinking": {
            "rating": 1335.6112950727997,
            "rating_q975": 1341.7363882915538,
            "rating_q025": 1329.4862018540457
        },
        "o1-2024-12-17": {
            "rating": 1333.0243272721766,
            "rating_q975": 1339.3322701563784,
            "rating_q025": 1326.7163843879748
        },
        "qwen3-235b-a22b": {
            "rating": 1333.006297895185,
            "rating_q975": 1339.5041086751814,
            "rating_q025": 1326.5084871151887
        },
        "grok-3-mini-high": {
            "rating": 1332.488614184863,
            "rating_q975": 1339.6577766984751,
            "rating_q025": 1325.319451671251
        },
        "qwen3-next-80b-a3b-thinking": {
            "rating": 1331.9318121488752,
            "rating_q975": 1339.9330189021234,
            "rating_q025": 1323.930605395627
        },
        "nova-2-lite": {
            "rating": 1329.9314612297073,
            "rating_q975": 1341.6234633682768,
            "rating_q025": 1318.2394590911379
        },
        "gpt-oss-120b": {
            "rating": 1329.9212102036333,
            "rating_q975": 1336.0101186112092,
            "rating_q025": 1323.8323017960574
        },
        "claude-opus-4-20250514": {
            "rating": 1329.6726084785641,
            "rating_q975": 1335.3768516863329,
            "rating_q025": 1323.9683652707954
        },
        "ling-flash-2.0": {
            "rating": 1327.4686391215857,
            "rating_q975": 1337.5858150234446,
            "rating_q025": 1317.3514632197268
        },
        "grok-3-mini-beta": {
            "rating": 1327.4154690723528,
            "rating_q975": 1334.2271731289636,
            "rating_q025": 1320.603765015742
        },
        "gemma-3-27b-it": {
            "rating": 1321.0074181415098,
            "rating_q975": 1326.063623246444,
            "rating_q025": 1315.9512130365756
        },
        "amazon-nova-experimental-chat-10-09": {
            "rating": 1319.1940553160048,
            "rating_q975": 1328.404852858474,
            "rating_q025": 1309.9832577735356
        },
        "qwen3-coder-480b-a35b-instruct": {
            "rating": 1317.8808597767086,
            "rating_q975": 1324.674851185879,
            "rating_q025": 1311.086868367538
        },
        "gemini-2.0-flash-001": {
            "rating": 1317.7482413321811,
            "rating_q975": 1322.8943124590962,
            "rating_q025": 1312.602170205266
        },
        "o4-mini-2025-04-16": {
            "rating": 1315.3075687205776,
            "rating_q975": 1320.7157781495814,
            "rating_q025": 1309.8993592915738
        },
        "o1-preview": {
            "rating": 1314.099958193171,
            "rating_q975": 1321.3531033949657,
            "rating_q025": 1306.8468129913763
        },
        "step-3": {
            "rating": 1310.1295863782946,
            "rating_q975": 1320.5398425277742,
            "rating_q025": 1299.719330228815
        },
        "claude-sonnet-4-20250514-thinking-32k": {
            "rating": 1308.8034235550408,
            "rating_q975": 1314.6556180889952,
            "rating_q025": 1302.9512290210864
        },
        "minimax-m1": {
            "rating": 1304.0918639318388,
            "rating_q975": 1309.9343396357692,
            "rating_q025": 1298.2493882279084
        },
        "intellect-3": {
            "rating": 1301.5308717497776,
            "rating_q975": 1319.7505801503469,
            "rating_q025": 1283.3111633492083
        },
        "minimax-m2": {
            "rating": 1299.5626096641886,
            "rating_q975": 1310.0658488235583,
            "rating_q025": 1289.0593705048188
        },
        "gpt-4.1-mini-2025-04-14": {
            "rating": 1295.9628339138385,
            "rating_q975": 1301.7673047655217,
            "rating_q025": 1290.1583630621553
        },
        "qwen3-32b": {
            "rating": 1295.3732559708606,
            "rating_q975": 1309.6926002295124,
            "rating_q025": 1281.0539117122087
        },
        "claude-sonnet-4-20250514": {
            "rating": 1293.4169251500214,
            "rating_q975": 1299.2069427106155,
            "rating_q025": 1287.6269075894272
        },
        "mistral-small-2506": {
            "rating": 1293.287219046869,
            "rating_q975": 1300.5005320405246,
            "rating_q025": 1286.0739060532135
        },
        "o3-mini-high": {
            "rating": 1290.7773721577926,
            "rating_q975": 1298.3745062271873,
            "rating_q025": 1283.1802380883978
        },
        "nvidia-llama-3.3-nemotron-super-49b-v1.5": {
            "rating": 1289.9946352474103,
            "rating_q975": 1304.431184179402,
            "rating_q025": 1275.5580863154187
        },
        "deepseek-v3": {
            "rating": 1289.1974047635385,
            "rating_q975": 1296.3950210879882,
            "rating_q025": 1281.999788439089
        },
        "step-1o-turbo-202506": {
            "rating": 1288.6168934286343,
            "rating_q975": 1297.8957653446978,
            "rating_q025": 1279.3380215125708
        },
        "gemma-3-12b-it": {
            "rating": 1288.4552975804993,
            "rating_q975": 1302.572740447044,
            "rating_q025": 1274.3378547139546
        },
        "glm-4-plus-0111": {
            "rating": 1284.777292398223,
            "rating_q975": 1297.3308103823294,
            "rating_q025": 1272.2237744141164
        },
        "glm-4.5v": {
            "rating": 1284.7711748338513,
            "rating_q975": 1296.946229064776,
            "rating_q025": 1272.5961206029267
        },
        "ring-flash-2.0": {
            "rating": 1284.06584862195,
            "rating_q975": 1294.1875685913706,
            "rating_q025": 1273.9441286525293
        },
        "gemini-2.0-flash-lite-preview-02-05": {
            "rating": 1280.966981436265,
            "rating_q975": 1287.4551466701535,
            "rating_q025": 1274.4788162023767
        },
        "command-a-03-2025": {
            "rating": 1280.8080843357827,
            "rating_q975": 1285.7509537039994,
            "rating_q025": 1275.865214967566
        },
        "qwen-plus-0125": {
            "rating": 1279.7409801985693,
            "rating_q975": 1292.5162604265763,
            "rating_q025": 1266.9656999705624
        },
        "qwq-32b": {
            "rating": 1278.9637265684366,
            "rating_q975": 1285.3593710791254,
            "rating_q025": 1272.568082057748
        },
        "step-2-16k-exp-202412": {
            "rating": 1272.3653320546157,
            "rating_q975": 1286.154219797718,
            "rating_q025": 1258.5764443115133
        },
        "gpt-5-nano-high": {
            "rating": 1269.3936595878226,
            "rating_q975": 1278.8240450238493,
            "rating_q025": 1259.963274151796
        },
        "gemini-1.5-pro-002": {
            "rating": 1266.5126545803505,
            "rating_q975": 1271.5682709610046,
            "rating_q025": 1261.4570381996964
        },
        "o3-mini": {
            "rating": 1266.0100414220858,
            "rating_q975": 1270.806755426955,
            "rating_q025": 1261.2133274172165
        },
        "hunyuan-turbos-20250226": {
            "rating": 1263.810465278052,
            "rating_q975": 1282.8336519940979,
            "rating_q025": 1244.7872785620063
        },
        "llama-3.1-nemotron-ultra-253b-v1": {
            "rating": 1263.096309521049,
            "rating_q975": 1280.4272119249833,
            "rating_q025": 1245.7654071171148
        },
        "o1-mini": {
            "rating": 1263.0859681954835,
            "rating_q975": 1268.4265314158863,
            "rating_q025": 1257.7454049750806
        },
        "claude-3-7-sonnet-20250219-thinking-32k": {
            "rating": 1261.4896487240685,
            "rating_q975": 1267.0442685302653,
            "rating_q025": 1255.9350289178717
        },
        "qwen3-30b-a3b": {
            "rating": 1261.083514683573,
            "rating_q975": 1267.663617727115,
            "rating_q025": 1254.503411640031
        },
        "llama-3.3-nemotron-49b-super-v1": {
            "rating": 1252.3929038795588,
            "rating_q975": 1271.4172358785686,
            "rating_q025": 1233.368571880549
        },
        "hunyuan-turbo-0110": {
            "rating": 1247.4760970338948,
            "rating_q975": 1266.6255565943145,
            "rating_q025": 1228.326637473475
        },
        "gemma-3n-e4b-it": {
            "rating": 1246.684902429914,
            "rating_q975": 1253.7067334170574,
            "rating_q025": 1239.6630714427706
        },
        "grok-2-2024-08-13": {
            "rating": 1244.602417651723,
            "rating_q975": 1249.9799323515085,
            "rating_q025": 1239.2249029519376
        },
        "olmo-3-32b-think": {
            "rating": 1243.6343583659514,
            "rating_q975": 1259.2620633336066,
            "rating_q025": 1228.006653398296
        },
        "yi-lightning": {
            "rating": 1242.1285091335267,
            "rating_q975": 1249.6010100432293,
            "rating_q025": 1234.656008223824
        },
        "claude-3-7-sonnet-20250219": {
            "rating": 1240.87509530756,
            "rating_q975": 1246.1213346947402,
            "rating_q025": 1235.62885592038
        },
        "gpt-4o-2024-05-13": {
            "rating": 1238.7224636502633,
            "rating_q975": 1244.053229522282,
            "rating_q025": 1233.3916977782446
        },
        "claude-3-5-sonnet-20241022": {
            "rating": 1236.525575625316,
            "rating_q975": 1240.6002313006768,
            "rating_q025": 1232.450919949955
        },
        "qwen2.5-plus-1127": {
            "rating": 1235.8694165513562,
            "rating_q975": 1245.872439090581,
            "rating_q025": 1225.8663940121312
        },
        "deepseek-v2.5-1210": {
            "rating": 1229.1894130286605,
            "rating_q975": 1242.2405448072764,
            "rating_q025": 1216.1382812500447
        },
        "athene-v2-chat": {
            "rating": 1223.961822037315,
            "rating_q975": 1230.8859564297445,
            "rating_q025": 1217.0376876448854
        },
        "gpt-oss-20b": {
            "rating": 1223.8986026785747,
            "rating_q975": 1232.7384995097973,
            "rating_q025": 1215.058705847352
        },
        "llama-4-maverick-17b-128e-instruct": {
            "rating": 1222.5478622511378,
            "rating_q975": 1228.473160086146,
            "rating_q025": 1216.6225644161295
        },
        "glm-4-plus": {
            "rating": 1221.7543053938339,
            "rating_q975": 1229.3237805008232,
            "rating_q025": 1214.1848302868445
        },
        "gemma-3-4b-it": {
            "rating": 1220.9233150162477,
            "rating_q975": 1234.78117242293,
            "rating_q025": 1207.0654576095653
        },
        "mercury": {
            "rating": 1217.682194804223,
            "rating_q975": 1238.58993486873,
            "rating_q025": 1196.7744547397158
        },
        "hunyuan-large-2025-02-10": {
            "rating": 1216.9828082854679,
            "rating_q975": 1232.1577025221316,
            "rating_q025": 1201.8079140488042
        },
        "gpt-4o-mini-2024-07-18": {
            "rating": 1216.5807725157044,
            "rating_q975": 1221.6400944931743,
            "rating_q025": 1211.5214505382346
        },
        "gemini-1.5-flash-002": {
            "rating": 1216.1773517279375,
            "rating_q975": 1222.5224699396476,
            "rating_q025": 1209.8322335162275
        },
        "llama-3.1-405b-instruct-bf16": {
            "rating": 1213.8768928281406,
            "rating_q975": 1219.2752107180502,
            "rating_q025": 1208.478574938231
        },
        "llama-3.1-nemotron-70b-instruct": {
            "rating": 1211.5327123396573,
            "rating_q975": 1222.8961083226325,
            "rating_q025": 1200.1693163566822
        },
        "llama-4-scout-17b-16e-instruct": {
            "rating": 1210.700528866998,
            "rating_q975": 1217.2700246175987,
            "rating_q025": 1204.1310331163972
        },
        "gpt-4.1-nano-2025-04-14": {
            "rating": 1210.6988570785506,
            "rating_q975": 1222.7618194887784,
            "rating_q025": 1198.6358946683229
        },
        "gpt-4o-2024-08-06": {
            "rating": 1209.8079032475855,
            "rating_q975": 1216.1584954436246,
            "rating_q025": 1203.4573110515464
        },
        "llama-3.1-405b-instruct-fp8": {
            "rating": 1209.5803943855285,
            "rating_q975": 1215.1734805013139,
            "rating_q025": 1203.9873082697432
        },
        "grok-2-mini-2024-08-13": {
            "rating": 1209.0146495927174,
            "rating_q975": 1214.6382825501066,
            "rating_q025": 1203.3910166353282
        },
        "qwen-max-0919": {
            "rating": 1206.3190285454584,
            "rating_q975": 1214.8453081800276,
            "rating_q025": 1197.7927489108893
        },
        "claude-3-5-sonnet-20240620": {
            "rating": 1206.2701714897698,
            "rating_q975": 1211.3602449496464,
            "rating_q025": 1201.1800980298933
        },
        "mistral-small-3.1-24b-instruct-2503": {
            "rating": 1204.438241983723,
            "rating_q975": 1210.817414915597,
            "rating_q025": 1198.0590690518488
        },
        "gemini-advanced-0514": {
            "rating": 1203.6843912796253,
            "rating_q975": 1210.9827682283426,
            "rating_q025": 1196.386014330908
        },
        "llama-3.3-70b-instruct": {
            "rating": 1201.3039986994809,
            "rating_q975": 1206.142980898347,
            "rating_q025": 1196.4650165006146
        },
        "hunyuan-standard-2025-02-10": {
            "rating": 1200.5269883621397,
            "rating_q975": 1215.8057531967563,
            "rating_q025": 1185.2482235275231
        },
        "gemini-1.5-pro-001": {
            "rating": 1195.677806638762,
            "rating_q975": 1201.8393799248329,
            "rating_q025": 1189.516233352691
        },
        "deepseek-v2.5": {
            "rating": 1193.4704953150708,
            "rating_q975": 1200.8685014091864,
            "rating_q025": 1186.0724892209553
        },
        "hunyuan-large-vision": {
            "rating": 1191.1216326376143,
            "rating_q975": 1203.8071551398966,
            "rating_q025": 1178.436110135332
        },
        "gpt-4-turbo-2024-04-09": {
            "rating": 1190.7441049902186,
            "rating_q975": 1196.5436220232623,
            "rating_q025": 1184.944587957175
        },
        "qwen2.5-72b-instruct": {
            "rating": 1189.7616044232664,
            "rating_q975": 1196.0243769297417,
            "rating_q025": 1183.498831916791
        },
        "athene-70b-0725": {
            "rating": 1187.837671007956,
            "rating_q975": 1196.5523365888182,
            "rating_q025": 1179.1230054270939
        },
        "mistral-large-2407": {
            "rating": 1186.1471048031422,
            "rating_q975": 1192.152167835055,
            "rating_q025": 1180.1420417712293
        },
        "mistral-large-2411": {
            "rating": 1179.5822408927784,
            "rating_q975": 1186.2727269133366,
            "rating_q025": 1172.8917548722202
        },
        "magistral-medium-2506": {
            "rating": 1178.1506980603776,
            "rating_q975": 1187.0584624342855,
            "rating_q025": 1169.2429336864698
        },
        "llama-3.1-70b-instruct": {
            "rating": 1177.5963307694915,
            "rating_q975": 1183.3214380244326,
            "rating_q025": 1171.8712235145504
        },
        "claude-3-opus-20240229": {
            "rating": 1175.2193322461476,
            "rating_q975": 1179.8024060263638,
            "rating_q025": 1170.6362584659314
        },
        "gpt-4-1106-preview": {
            "rating": 1174.3833394773178,
            "rating_q975": 1180.2815559176152,
            "rating_q025": 1168.4851230370205
        },
        "claude-3-5-haiku-20241022": {
            "rating": 1172.3516189486193,
            "rating_q975": 1176.875404963751,
            "rating_q025": 1167.8278329334876
        },
        "gpt-4-0125-preview": {
            "rating": 1172.256308179971,
            "rating_q975": 1178.3872257851876,
            "rating_q025": 1166.1253905747544
        },
        "amazon-nova-pro-v1.0": {
            "rating": 1169.35854782006,
            "rating_q975": 1176.3084068345486,
            "rating_q025": 1162.4086888055715
        },
        "llama-3.1-tulu-3-70b": {
            "rating": 1169.208037582658,
            "rating_q975": 1186.7268082420553,
            "rating_q025": 1151.689266923261
        },
        "reka-core-20240904": {
            "rating": 1156.2741171399225,
            "rating_q975": 1167.874737200244,
            "rating_q025": 1144.673497079601
        },
        "gemini-1.5-flash-001": {
            "rating": 1142.6124892428047,
            "rating_q975": 1149.2907533566336,
            "rating_q025": 1135.9342251289759
        },
        "jamba-1.5-large": {
            "rating": 1140.4034320256915,
            "rating_q975": 1151.630367795225,
            "rating_q025": 1129.1764962561579
        },
        "mistral-small-24b-instruct-2501": {
            "rating": 1129.6875275543632,
            "rating_q975": 1138.8399239323646,
            "rating_q025": 1120.5351311763618
        },
        "gemma-2-27b-it": {
            "rating": 1129.409145871023,
            "rating_q975": 1134.4401095564726,
            "rating_q025": 1124.3781821855732
        },
        "qwen2.5-coder-32b-instruct": {
            "rating": 1125.9213535825927,
            "rating_q975": 1139.219691510924,
            "rating_q025": 1112.6230156542615
        },
        "command-r-plus-08-2024": {
            "rating": 1125.9137688849462,
            "rating_q975": 1136.1847918525516,
            "rating_q025": 1115.6427459173408
        },
        "glm-4-0520": {
            "rating": 1124.1977015624611,
            "rating_q975": 1135.0421041674106,
            "rating_q025": 1113.3532989575117
        },
        "gemma-2-9b-it-simpo": {
            "rating": 1123.4502636421466,
            "rating_q975": 1134.140989184649,
            "rating_q025": 1112.7595380996443
        },
        "nemotron-4-340b-instruct": {
            "rating": 1122.6702479733997,
            "rating_q975": 1130.9820798164344,
            "rating_q025": 1114.358416130365
        },
        "llama-3.1-nemotron-51b-instruct": {
            "rating": 1122.0546028499034,
            "rating_q975": 1138.0739190921456,
            "rating_q025": 1106.0352866076612
        },
        "amazon-nova-lite-v1.0": {
            "rating": 1120.1888192006616,
            "rating_q975": 1128.2520560364264,
            "rating_q025": 1112.1255823648967
        },
        "gemini-1.5-flash-8b-001": {
            "rating": 1119.2062610121247,
            "rating_q975": 1125.8444675481019,
            "rating_q025": 1112.5680544761476
        },
        "llama-3-70b-instruct": {
            "rating": 1116.1569896665142,
            "rating_q975": 1121.7067535100311,
            "rating_q025": 1110.6072258229972
        },
        "c4ai-aya-expanse-32b": {
            "rating": 1115.6053184907682,
            "rating_q975": 1123.2943157137606,
            "rating_q025": 1107.9163212677759
        },
        "claude-3-sonnet-20240229": {
            "rating": 1108.9606307131876,
            "rating_q975": 1114.81499096638,
            "rating_q025": 1103.1062704599951
        },
        "olmo-2-0325-32b-instruct": {
            "rating": 1106.9024311166575,
            "rating_q975": 1124.1761903589547,
            "rating_q025": 1089.6286718743602
        },
        "reka-flash-20240904": {
            "rating": 1103.4921999786654,
            "rating_q975": 1115.3965635448035,
            "rating_q025": 1091.5878364125274
        },
        "phi-4": {
            "rating": 1100.2042326005535,
            "rating_q975": 1107.7980714473822,
            "rating_q025": 1092.6103937537248
        },
        "command-r-plus": {
            "rating": 1092.1529487917423,
            "rating_q975": 1098.4684886909893,
            "rating_q025": 1085.8374088924954
        },
        "gemma-2-9b-it": {
            "rating": 1090.8613269027476,
            "rating_q975": 1096.6055513617089,
            "rating_q025": 1085.1171024437863
        },
        "qwen2-72b-instruct": {
            "rating": 1087.2319590551324,
            "rating_q975": 1094.5364729089213,
            "rating_q025": 1079.9274452013435
        },
        "amazon-nova-micro-v1.0": {
            "rating": 1085.845610686345,
            "rating_q975": 1094.1210884947798,
            "rating_q025": 1077.5701328779103
        },
        "gpt-4-0314": {
            "rating": 1085.6836236916527,
            "rating_q975": 1092.8026493583325,
            "rating_q025": 1078.5645980249728
        },
        "hunyuan-standard-256k": {
            "rating": 1081.1235823517159,
            "rating_q975": 1099.5141807983675,
            "rating_q025": 1062.7329839050642
        },
        "claude-3-haiku-20240307": {
            "rating": 1076.1204773328895,
            "rating_q975": 1081.9006340560613,
            "rating_q025": 1070.3403206097178
        },
        "deepseek-coder-v2": {
            "rating": 1070.5969520156968,
            "rating_q975": 1080.1015756435613,
            "rating_q025": 1061.0923283878324
        },
        "llama-3.1-tulu-3-8b": {
            "rating": 1061.4236154187163,
            "rating_q975": 1080.460803513547,
            "rating_q025": 1042.3864273238855
        },
        "ministral-8b-2410": {
            "rating": 1060.8052295980294,
            "rating_q975": 1075.7442062075734,
            "rating_q025": 1045.8662529884855
        },
        "gpt-4-0613": {
            "rating": 1059.154495045976,
            "rating_q975": 1065.1515983852482,
            "rating_q025": 1053.157391706704
        },
        "jamba-1.5-mini": {
            "rating": 1058.6055813764683,
            "rating_q975": 1070.3415138870591,
            "rating_q025": 1046.8696488658775
        },
        "command-r-08-2024": {
            "rating": 1058.4104576557538,
            "rating_q975": 1068.980289154402,
            "rating_q025": 1047.8406261571056
        },
        "llama-3.1-8b-instruct": {
            "rating": 1056.3538341085055,
            "rating_q975": 1062.8169604774798,
            "rating_q025": 1049.890707739531
        },
        "c4ai-aya-expanse-8b": {
            "rating": 1054.716623871354,
            "rating_q975": 1066.2775904440289,
            "rating_q025": 1043.155657298679
        },
        "mistral-large-2402": {
            "rating": 1046.787383312601,
            "rating_q975": 1053.7031644772799,
            "rating_q025": 1039.871602147922
        },
        "qwen1.5-110b-chat": {
            "rating": 1045.2512072613545,
            "rating_q975": 1053.8847238197886,
            "rating_q025": 1036.6176907029203
        },
        "yi-1.5-34b-chat": {
            "rating": 1042.7603936231023,
            "rating_q975": 1050.9789863920978,
            "rating_q025": 1034.541800854107
        },
        "reka-flash-21b-20240226-online": {
            "rating": 1041.0705171463278,
            "rating_q975": 1052.073134540696,
            "rating_q025": 1030.0678997519597
        },
        "qwen1.5-72b-chat": {
            "rating": 1033.601981482965,
            "rating_q975": 1041.5232379328081,
            "rating_q025": 1025.6807250331217
        },
        "reka-flash-21b-20240226": {
            "rating": 1032.7036785584032,
            "rating_q975": 1041.9608628580452,
            "rating_q025": 1023.4464942587612
        },
        "mistral-medium": {
            "rating": 1031.2453829919855,
            "rating_q975": 1039.2921627312085,
            "rating_q025": 1023.1986032527625
        },
        "llama-3-8b-instruct": {
            "rating": 1030.9882790695126,
            "rating_q975": 1036.9652728550425,
            "rating_q025": 1025.0112852839827
        },
        "command-r": {
            "rating": 1029.3775798747179,
            "rating_q975": 1036.503871191579,
            "rating_q025": 1022.2512885578567
        },
        "qwq-32b-preview": {
            "rating": 1024.7508970625067,
            "rating_q975": 1043.036691319474,
            "rating_q025": 1006.4651028055396
        },
        "mixtral-8x22b-instruct-v0.1": {
            "rating": 1024.259718186257,
            "rating_q975": 1031.2139621618705,
            "rating_q025": 1017.3054742106436
        },
        "internlm2_5-20b-chat": {
            "rating": 1012.8295018820093,
            "rating_q975": 1024.878391286625,
            "rating_q025": 1000.7806124773937
        },
        "gemini-pro-dev-api": {
            "rating": 1008.8230885775604,
            "rating_q975": 1019.3893524002665,
            "rating_q025": 998.2568247548543
        },
        "gemma-2-2b-it": {
            "rating": 1005.4592546696695,
            "rating_q975": 1011.9923891890169,
            "rating_q025": 998.926120150322
        },
        "zephyr-orpo-141b-A35b-v0.1": {
            "rating": 1000.2942218287394,
            "rating_q975": 1016.0777400665937,
            "rating_q025": 984.5107035908851
        },
        "granite-3.1-8b-instruct": {
            "rating": 994.2077313954069,
            "rating_q975": 1013.888319507043,
            "rating_q025": 974.5271432837708
        },
        "qwen1.5-32b-chat": {
            "rating": 990.7062303829655,
            "rating_q975": 1000.1375235529393,
            "rating_q025": 981.2749372129916
        },
        "starling-lm-7b-beta": {
            "rating": 987.3270251034635,
            "rating_q975": 998.1695123889426,
            "rating_q025": 976.4845378179843
        },
        "mixtral-8x7b-instruct-v0.1": {
            "rating": 979.4850174971175,
            "rating_q975": 986.011603872959,
            "rating_q025": 972.958431121276
        },
        "gemini-pro": {
            "rating": 979.1198588725942,
            "rating_q975": 995.3475605236027,
            "rating_q025": 962.8921572215858
        },
        "phi-3-medium-4k-instruct": {
            "rating": 979.1120549334996,
            "rating_q975": 987.6306162424046,
            "rating_q025": 970.5934936245947
        },
        "qwen1.5-14b-chat": {
            "rating": 978.5847800950281,
            "rating_q975": 989.5175257967123,
            "rating_q025": 967.6520343933439
        },
        "yi-34b-chat": {
            "rating": 977.2093461728907,
            "rating_q975": 987.2378970420917,
            "rating_q025": 967.1807953036897
        },
        "gpt-3.5-turbo-0125": {
            "rating": 968.7475646471377,
            "rating_q975": 975.6569120785397,
            "rating_q025": 961.8382172157357
        },
        "wizardlm-70b": {
            "rating": 967.6671191998452,
            "rating_q975": 980.8836864094753,
            "rating_q025": 954.450551990215
        },
        "tulu-2-dpo-70b": {
            "rating": 964.4007676295275,
            "rating_q975": 978.4186668685522,
            "rating_q025": 950.3828683905028
        },
        "dbrx-instruct-preview": {
            "rating": 960.2535042693262,
            "rating_q975": 969.5753099678511,
            "rating_q025": 950.9316985708012
        },
        "llama-2-70b-chat": {
            "rating": 956.4671297646239,
            "rating_q975": 964.6434291694095,
            "rating_q025": 948.2908303598383
        },
        "nous-hermes-2-mixtral-8x7b-dpo": {
            "rating": 952.6097822553014,
            "rating_q975": 969.7487259048797,
            "rating_q025": 935.4708386057231
        },
        "granite-3.1-2b-instruct": {
            "rating": 948.6817760072494,
            "rating_q975": 969.8341807967548,
            "rating_q025": 927.5293712177439
        },
        "vicuna-33b": {
            "rating": 946.4078143749964,
            "rating_q975": 955.6632867490522,
            "rating_q025": 937.1523420009406
        },
        "starling-lm-7b-alpha": {
            "rating": 946.3286187130539,
            "rating_q975": 958.0289326678213,
            "rating_q025": 934.6283047582864
        },
        "openchat-3.5-0106": {
            "rating": 945.2363878138276,
            "rating_q975": 956.8658334364512,
            "rating_q025": 933.606942191204
        },
        "deepseek-llm-67b-chat": {
            "rating": 942.1877402980267,
            "rating_q975": 959.1671735068909,
            "rating_q025": 925.2083070891625
        },
        "phi-3-small-8k-instruct": {
            "rating": 936.9288782335449,
            "rating_q975": 947.3131586132946,
            "rating_q025": 926.5445978537952
        },
        "llama-3.2-3b-instruct": {
            "rating": 932.7790954909285,
            "rating_q975": 946.221182958613,
            "rating_q025": 919.337008023244
        },
        "llama2-70b-steerlm-chat": {
            "rating": 932.2107804677688,
            "rating_q975": 949.7603492772706,
            "rating_q025": 914.661211658267
        },
        "openchat-3.5": {
            "rating": 930.2043655765336,
            "rating_q975": 944.3412403938572,
            "rating_q025": 916.06749075921
        },
        "snowflake-arctic-instruct": {
            "rating": 928.7981201746686,
            "rating_q975": 938.3791010606585,
            "rating_q025": 919.2171392886787
        },
        "openhermes-2.5-mistral-7b": {
            "rating": 925.8033715382453,
            "rating_q975": 941.067277406848,
            "rating_q025": 910.5394656696426
        },
        "gpt-3.5-turbo-1106": {
            "rating": 923.5114349611779,
            "rating_q975": 935.8743332054888,
            "rating_q025": 911.1485367168669
        },
        "gemma-1.1-7b-it": {
            "rating": 920.2726535619684,
            "rating_q975": 929.3026528987615,
            "rating_q025": 911.2426542251752
        },
        "mistral-7b-instruct-v0.2": {
            "rating": 916.6283214344313,
            "rating_q975": 926.7228384133606,
            "rating_q025": 906.533804455502
        },
        "granite-3.0-8b-instruct": {
            "rating": 912.8383651705074,
            "rating_q975": 928.7331458713057,
            "rating_q025": 896.943584469709
        },
        "solar-10.7b-instruct-v1.0": {
            "rating": 910.6785975861237,
            "rating_q975": 929.8640573844674,
            "rating_q025": 891.49313778778
        },
        "llama-2-13b-chat": {
            "rating": 910.061899495237,
            "rating_q975": 920.0722239129824,
            "rating_q025": 900.0515750774915
        },
        "qwen1.5-7b-chat": {
            "rating": 908.0747335027418,
            "rating_q975": 923.2787999561115,
            "rating_q025": 892.8706670493721
        },
        "dolphin-2.2.1-mistral-7b": {
            "rating": 906.5542119569798,
            "rating_q975": 929.1235619356471,
            "rating_q025": 883.9848619783124
        },
        "wizardlm-13b": {
            "rating": 906.5138570901261,
            "rating_q975": 920.0956832833301,
            "rating_q025": 892.932030896922
        },
        "mpt-30b-chat": {
            "rating": 897.367349030464,
            "rating_q975": 915.4716041439426,
            "rating_q025": 879.2630939169853
        },
        "zephyr-7b-beta": {
            "rating": 889.4928321043308,
            "rating_q975": 902.0064201182479,
            "rating_q025": 876.9792440904137
        },
        "codellama-34b-instruct": {
            "rating": 883.8486738556716,
            "rating_q975": 896.6521590294212,
            "rating_q025": 871.0451886819219
        },
        "zephyr-7b-alpha": {
            "rating": 878.1171439941817,
            "rating_q975": 901.0514482743397,
            "rating_q025": 855.1828397140237
        },
        "granite-3.0-2b-instruct": {
            "rating": 874.7298457810484,
            "rating_q975": 891.5482948766105,
            "rating_q025": 857.9113966854864
        },
        "guanaco-33b": {
            "rating": 874.533455690264,
            "rating_q975": 892.6594081580944,
            "rating_q025": 856.4075032224335
        },
        "phi-3-mini-4k-instruct-june-2024": {
            "rating": 873.9631946007928,
            "rating_q975": 886.1380292371961,
            "rating_q025": 861.7883599643895
        },
        "codellama-70b-instruct": {
            "rating": 873.0811238998613,
            "rating_q975": 901.2788252917911,
            "rating_q025": 844.8834225079314
        },
        "phi-3-mini-4k-instruct": {
            "rating": 872.5821120155556,
            "rating_q975": 883.8931487961584,
            "rating_q025": 861.2710752349528
        },
        "vicuna-13b": {
            "rating": 870.1140358192722,
            "rating_q975": 880.1800513287849,
            "rating_q025": 860.0480203097595
        },
        "falcon-180b-chat": {
            "rating": 869.879582669414,
            "rating_q975": 894.0911916602753,
            "rating_q025": 845.6679736785528
        },
        "qwen-14b-chat": {
            "rating": 866.7832559063161,
            "rating_q975": 882.615870387422,
            "rating_q025": 850.9506414252102
        },
        "gemma-7b-it": {
            "rating": 864.4815123951902,
            "rating_q975": 878.9430695689198,
            "rating_q025": 850.0199552214606
        },
        "llama-2-7b-chat": {
            "rating": 862.628529692998,
            "rating_q975": 873.0999996934025,
            "rating_q025": 852.1570596925934
        },
        "phi-3-mini-128k-instruct": {
            "rating": 847.4546680431979,
            "rating_q975": 860.0676955454278,
            "rating_q025": 834.841640540968
        },
        "vicuna-7b": {
            "rating": 843.0601038708576,
            "rating_q975": 856.594343826249,
            "rating_q025": 829.5258639154662
        },
        "stripedhyena-nous-7b": {
            "rating": 840.8276587129965,
            "rating_q975": 857.5750781566752,
            "rating_q025": 824.0802392693178
        },
        "palm-2": {
            "rating": 831.7698173697206,
            "rating_q975": 844.8181554053554,
            "rating_q025": 818.7214793340859
        },
        "olmo-7b-instruct": {
            "rating": 827.2372277735719,
            "rating_q975": 844.7844942487146,
            "rating_q025": 809.6899612984292
        },
        "llama-3.2-1b-instruct": {
            "rating": 825.5613687617305,
            "rating_q975": 841.3047589192181,
            "rating_q025": 809.8179786042429
        },
        "mistral-7b-instruct": {
            "rating": 821.2733506132307,
            "rating_q975": 834.9686531189567,
            "rating_q025": 807.5780481075047
        },
        "smollm2-1.7b-instruct": {
            "rating": 808.1395811404793,
            "rating_q975": 839.6354992932434,
            "rating_q025": 776.6436629877153
        },
        "gemma-1.1-2b-it": {
            "rating": 798.5316771755391,
            "rating_q975": 812.123560927389,
            "rating_q025": 784.9397934236893
        },
        "koala-13b": {
            "rating": 783.3368751407558,
            "rating_q975": 798.8348578109195,
            "rating_q025": 767.838892470592
        },
        "gemma-2b-it": {
            "rating": 781.4204841300358,
            "rating_q975": 799.8615497780776,
            "rating_q025": 762.979418481994
        },
        "qwen1.5-4b-chat": {
            "rating": 765.0700643694079,
            "rating_q975": 780.969413029172,
            "rating_q025": 749.1707157096438
        },
        "chatglm3-6b": {
            "rating": 743.3998583226344,
            "rating_q975": 761.8444070972439,
            "rating_q025": 724.9553095480248
        },
        "mpt-7b-chat": {
            "rating": 729.037897544565,
            "rating_q975": 747.316467112539,
            "rating_q025": 710.759327976591
        },
        "gpt4all-13b-snoozy": {
            "rating": 727.7038374814947,
            "rating_q975": 751.8490258713472,
            "rating_q025": 703.5586490916422
        },
        "RWKV-4-Raven-14B": {
            "rating": 723.7110472248523,
            "rating_q975": 741.3922779943168,
            "rating_q025": 706.0298164553878
        },
        "alpaca-13b": {
            "rating": 699.4171524920191,
            "rating_q975": 716.6878317755575,
            "rating_q025": 682.1464732084808
        },
        "chatglm2-6b": {
            "rating": 687.3354814436874,
            "rating_q975": 709.3507386244802,
            "rating_q025": 665.3202242628946
        },
        "oasst-pythia-12b": {
            "rating": 673.5718155533572,
            "rating_q975": 690.2100231910406,
            "rating_q025": 656.9336079156737
        },
        "chatglm-6b": {
            "rating": 663.5461824438382,
            "rating_q975": 683.0366440708058,
            "rating_q025": 644.0557208168707
        },
        "fastchat-t5-3b": {
            "rating": 636.233652677008,
            "rating_q975": 655.6323609538993,
            "rating_q025": 616.8349444001167
        },
        "stablelm-tuned-alpha-7b": {
            "rating": 584.7468457277404,
            "rating_q975": 606.5273375546213,
            "rating_q025": 562.9663539008594
        },
        "dolly-v2-12b": {
            "rating": 569.4531869420018,
            "rating_q975": 591.6438493912415,
            "rating_q025": 547.2625244927622
        },
        "llama-13b": {
            "rating": 533.6734582051985,
            "rating_q975": 559.8050588398212,
            "rating_q025": 507.5418575705758
        }
    },
    "russian": {
        "gemini-3-pro": {
            "rating": 1498.925742483212,
            "rating_q975": 1516.6997122682635,
            "rating_q025": 1481.1517726981604
        },
        "gemini-2.5-pro": {
            "rating": 1471.762603206134,
            "rating_q975": 1481.2676133713858,
            "rating_q025": 1462.257593040882
        },
        "ernie-5.0-preview-1103": {
            "rating": 1449.2988772492279,
            "rating_q975": 1477.656278422497,
            "rating_q025": 1420.9414760759587
        },
        "claude-opus-4-5-20251101": {
            "rating": 1444.7049091567865,
            "rating_q975": 1464.672560942086,
            "rating_q025": 1424.737257371487
        },
        "grok-4.1-thinking": {
            "rating": 1442.0982621941732,
            "rating_q975": 1458.8800755961554,
            "rating_q025": 1425.316448792191
        },
        "deepseek-v3.1-terminus-thinking": {
            "rating": 1432.6073227472566,
            "rating_q975": 1468.9705263335,
            "rating_q025": 1396.2441191610133
        },
        "grok-4.1": {
            "rating": 1429.5109715221238,
            "rating_q975": 1446.5787632071583,
            "rating_q025": 1412.4431798370892
        },
        "deepseek-v3.1-terminus": {
            "rating": 1429.0794799519304,
            "rating_q975": 1463.4933690273563,
            "rating_q025": 1394.6655908765044
        },
        "gpt-5.1": {
            "rating": 1424.9293417682354,
            "rating_q975": 1443.2835143897905,
            "rating_q025": 1406.5751691466803
        },
        "chatgpt-4o-latest-20250326": {
            "rating": 1424.2595899155465,
            "rating_q975": 1433.6019673978224,
            "rating_q025": 1414.9172124332706
        },
        "claude-opus-4-1-20250805": {
            "rating": 1422.6537507780497,
            "rating_q975": 1433.4685757875807,
            "rating_q025": 1411.8389257685187
        },
        "claude-opus-4-5-20251101-thinking-32k": {
            "rating": 1422.0151784314164,
            "rating_q975": 1442.4415254099513,
            "rating_q025": 1401.5888314528815
        },
        "claude-sonnet-4-5-20250929": {
            "rating": 1421.060557803611,
            "rating_q975": 1436.2669647767118,
            "rating_q025": 1405.85415083051
        },
        "deepseek-r1-0528": {
            "rating": 1420.6926864496959,
            "rating_q975": 1436.937015993743,
            "rating_q025": 1404.4483569056488
        },
        "qwen3-max-preview": {
            "rating": 1420.625799851881,
            "rating_q975": 1436.6685157273048,
            "rating_q025": 1404.5830839764574
        },
        "qwen3-max-2025-09-23": {
            "rating": 1420.325523734599,
            "rating_q975": 1444.4753451077986,
            "rating_q025": 1396.1757023613995
        },
        "gpt-5.1-high": {
            "rating": 1419.8030555328016,
            "rating_q975": 1438.3687733831923,
            "rating_q025": 1401.237337682411
        },
        "glm-4.6": {
            "rating": 1419.1395422411324,
            "rating_q975": 1434.6709128915027,
            "rating_q025": 1403.6081715907621
        },
        "gemini-2.5-flash": {
            "rating": 1419.1083801130474,
            "rating_q975": 1428.0552178055511,
            "rating_q025": 1410.1615424205436
        },
        "claude-sonnet-4-5-20250929-thinking-32k": {
            "rating": 1417.788368073916,
            "rating_q975": 1432.1328093642244,
            "rating_q025": 1403.4439267836076
        },
        "gpt-4.5-preview-2025-02-27": {
            "rating": 1417.382947014802,
            "rating_q975": 1432.5727968296233,
            "rating_q025": 1402.193097199981
        },
        "grok-3-preview-02-24": {
            "rating": 1416.299787248862,
            "rating_q975": 1427.7852790612203,
            "rating_q025": 1404.8142954365037
        },
        "deepseek-v3.2": {
            "rating": 1416.1025134139002,
            "rating_q975": 1441.843383000608,
            "rating_q025": 1390.3616438271924
        },
        "grok-4-0709": {
            "rating": 1414.6858405003177,
            "rating_q975": 1427.3600759590558,
            "rating_q025": 1402.0116050415795
        },
        "glm-4.5": {
            "rating": 1412.7728602177795,
            "rating_q975": 1429.044763508591,
            "rating_q025": 1396.500956926968
        },
        "claude-opus-4-1-20250805-thinking-16k": {
            "rating": 1411.43692662858,
            "rating_q975": 1423.491708108242,
            "rating_q025": 1399.3821451489182
        },
        "o3-2025-04-16": {
            "rating": 1410.3855772241525,
            "rating_q975": 1420.2570242222384,
            "rating_q025": 1400.5141302260665
        },
        "qwen3-235b-a22b-instruct-2507": {
            "rating": 1409.3800243391447,
            "rating_q975": 1420.3564637437762,
            "rating_q025": 1398.4035849345132
        },
        "deepseek-v3.2-exp-thinking": {
            "rating": 1409.2693047783694,
            "rating_q975": 1434.2520555096787,
            "rating_q025": 1384.28655404706
        },
        "mistral-medium-2508": {
            "rating": 1408.0986355760829,
            "rating_q975": 1420.0093644004908,
            "rating_q025": 1396.187906751675
        },
        "deepseek-v3.1": {
            "rating": 1406.6990804840846,
            "rating_q975": 1427.6795268782228,
            "rating_q025": 1385.7186340899464
        },
        "qwen3-next-80b-a3b-instruct": {
            "rating": 1405.804319869072,
            "rating_q975": 1422.7689375587447,
            "rating_q025": 1388.8397021793994
        },
        "qwen3-235b-a22b-thinking-2507": {
            "rating": 1404.3539284609587,
            "rating_q975": 1431.725920028504,
            "rating_q025": 1376.9819368934134
        },
        "deepseek-v3.2-exp": {
            "rating": 1403.5731539838914,
            "rating_q975": 1424.7334831751232,
            "rating_q025": 1382.4128247926596
        },
        "gemini-2.5-flash-preview-09-2025": {
            "rating": 1403.4656430380294,
            "rating_q975": 1417.5036476601888,
            "rating_q025": 1389.42763841587
        },
        "gpt-5-high": {
            "rating": 1402.9770894584724,
            "rating_q975": 1417.93110905239,
            "rating_q025": 1388.0230698645548
        },
        "deepseek-v3.1-thinking": {
            "rating": 1402.7076652074702,
            "rating_q975": 1425.3764484226804,
            "rating_q025": 1380.03888199226
        },
        "gpt-5-chat": {
            "rating": 1402.2381665723206,
            "rating_q975": 1417.1481220448122,
            "rating_q025": 1387.3282110998289
        },
        "mistral-large-3": {
            "rating": 1396.388920105799,
            "rating_q975": 1421.6628628607264,
            "rating_q025": 1371.1149773508714
        },
        "grok-4-1-fast-reasoning": {
            "rating": 1395.057222051451,
            "rating_q975": 1416.7733217985372,
            "rating_q025": 1373.3411223043647
        },
        "qwen3-vl-235b-a22b-instruct": {
            "rating": 1394.509669906156,
            "rating_q975": 1419.6111750393748,
            "rating_q025": 1369.4081647729372
        },
        "qwen3-235b-a22b-no-thinking": {
            "rating": 1388.899872347205,
            "rating_q975": 1400.8639767531092,
            "rating_q025": 1376.9357679413008
        },
        "deepseek-v3.2-thinking": {
            "rating": 1388.1711280922175,
            "rating_q975": 1415.5650523294298,
            "rating_q025": 1360.7772038550052
        },
        "hunyuan-t1-20250711": {
            "rating": 1387.9935442437572,
            "rating_q975": 1422.6685292892462,
            "rating_q025": 1353.3185591982683
        },
        "mai-1-preview": {
            "rating": 1386.2737616049387,
            "rating_q975": 1404.8675592532013,
            "rating_q025": 1367.6799639566761
        },
        "claude-opus-4-20250514-thinking-16k": {
            "rating": 1384.8348365779839,
            "rating_q975": 1397.5862010687433,
            "rating_q025": 1372.0834720872244
        },
        "longcat-flash-chat": {
            "rating": 1384.0450555895316,
            "rating_q975": 1405.9223962367528,
            "rating_q025": 1362.1677149423103
        },
        "grok-4-fast-reasoning": {
            "rating": 1383.2330532008032,
            "rating_q975": 1401.6962573662279,
            "rating_q025": 1364.7698490353785
        },
        "kimi-k2-thinking-turbo": {
            "rating": 1383.2096432194787,
            "rating_q975": 1401.0013342216507,
            "rating_q025": 1365.4179522173067
        },
        "grok-4-fast-chat": {
            "rating": 1380.1218895027794,
            "rating_q975": 1407.9841073528194,
            "rating_q025": 1352.2596716527394
        },
        "claude-opus-4-20250514": {
            "rating": 1379.758259263217,
            "rating_q975": 1391.1556055551002,
            "rating_q025": 1368.3609129713338
        },
        "amazon-nova-experimental-chat-10-20": {
            "rating": 1376.067730166165,
            "rating_q975": 1401.1508544385954,
            "rating_q025": 1350.9846058937344
        },
        "glm-4.5-air": {
            "rating": 1375.0977371555311,
            "rating_q975": 1390.0699438011136,
            "rating_q025": 1360.1255305099487
        },
        "gpt-4.1-2025-04-14": {
            "rating": 1374.656007049005,
            "rating_q975": 1385.209541617135,
            "rating_q025": 1364.102472480875
        },
        "kimi-k2-0905-preview": {
            "rating": 1370.5153123716993,
            "rating_q975": 1393.2308501401922,
            "rating_q025": 1347.7997746032065
        },
        "deepseek-v3-0324": {
            "rating": 1369.1981017521387,
            "rating_q975": 1379.520232182049,
            "rating_q025": 1358.8759713222282
        },
        "hunyuan-turbos-20250416": {
            "rating": 1368.9510086027872,
            "rating_q975": 1387.1023015068884,
            "rating_q025": 1350.799715698686
        },
        "gemini-2.5-flash-lite-preview-06-17-thinking": {
            "rating": 1367.7227425022413,
            "rating_q975": 1381.309736047028,
            "rating_q025": 1354.1357489574546
        },
        "qwen3-30b-a3b-instruct-2507": {
            "rating": 1367.6995133714008,
            "rating_q975": 1384.2541311921618,
            "rating_q025": 1351.1448955506398
        },
        "gemini-2.5-flash-lite-preview-09-2025-no-thinking": {
            "rating": 1367.2077405865284,
            "rating_q975": 1381.3758791693879,
            "rating_q025": 1353.039602003669
        },
        "amazon-nova-experimental-chat-10-09": {
            "rating": 1361.3357218306128,
            "rating_q975": 1391.8227075733253,
            "rating_q025": 1330.8487360879003
        },
        "gpt-5-mini-high": {
            "rating": 1360.9070956567718,
            "rating_q975": 1376.5711969677059,
            "rating_q025": 1345.2429943458378
        },
        "qwen3-coder-480b-a35b-instruct": {
            "rating": 1356.3349347962314,
            "rating_q975": 1372.9080847183286,
            "rating_q025": 1339.7617848741343
        },
        "claude-sonnet-4-20250514-thinking-32k": {
            "rating": 1356.1663482587546,
            "rating_q975": 1369.57914466955,
            "rating_q025": 1342.7535518479592
        },
        "kimi-k2-0711-preview": {
            "rating": 1355.9954109083887,
            "rating_q975": 1370.7831636620583,
            "rating_q025": 1341.2076581547192
        },
        "claude-haiku-4-5-20251001": {
            "rating": 1355.891249749953,
            "rating_q975": 1371.2700478303946,
            "rating_q025": 1340.5124516695114
        },
        "mistral-medium-2505": {
            "rating": 1355.2629040777604,
            "rating_q975": 1367.0154174958052,
            "rating_q025": 1343.5103906597155
        },
        "qwen3-vl-235b-a22b-thinking": {
            "rating": 1354.8885310957942,
            "rating_q975": 1380.7437161739454,
            "rating_q025": 1329.033346017643
        },
        "o1-2024-12-17": {
            "rating": 1353.855842871498,
            "rating_q975": 1363.9947642969835,
            "rating_q025": 1343.7169214460125
        },
        "gemini-2.0-flash-001": {
            "rating": 1352.4348661132306,
            "rating_q975": 1362.0630818395623,
            "rating_q025": 1342.8066503868988
        },
        "grok-3-mini-beta": {
            "rating": 1352.4047180140371,
            "rating_q975": 1367.8855934832927,
            "rating_q025": 1336.9238425447816
        },
        "deepseek-r1": {
            "rating": 1352.0088825077842,
            "rating_q975": 1364.5775663536795,
            "rating_q025": 1339.4401986618889
        },
        "qwen2.5-max": {
            "rating": 1350.9469014230312,
            "rating_q975": 1361.3980195443728,
            "rating_q025": 1340.4957833016897
        },
        "gemma-3-27b-it": {
            "rating": 1350.3994304267403,
            "rating_q975": 1360.7192435787827,
            "rating_q025": 1340.079617274698
        },
        "nova-2-lite": {
            "rating": 1350.1808994242735,
            "rating_q975": 1377.0335585492248,
            "rating_q025": 1323.3282402993223
        },
        "grok-3-mini-high": {
            "rating": 1347.9777716657354,
            "rating_q975": 1366.238657783241,
            "rating_q025": 1329.7168855482298
        },
        "claude-sonnet-4-20250514": {
            "rating": 1342.0854074588096,
            "rating_q975": 1353.8808638099636,
            "rating_q025": 1330.2899511076557
        },
        "qwen3-235b-a22b": {
            "rating": 1340.8919097337225,
            "rating_q975": 1353.7915463572422,
            "rating_q025": 1327.9922731102029
        },
        "qwen3-next-80b-a3b-thinking": {
            "rating": 1339.6764781283287,
            "rating_q975": 1360.1442985835583,
            "rating_q025": 1319.208657673099
        },
        "gpt-oss-120b": {
            "rating": 1339.4168861494459,
            "rating_q975": 1354.1982101259698,
            "rating_q025": 1324.635562172922
        },
        "gemma-3-12b-it": {
            "rating": 1337.5869551454289,
            "rating_q975": 1369.3129244077668,
            "rating_q025": 1305.860985883091
        },
        "o4-mini-2025-04-16": {
            "rating": 1334.6038415572866,
            "rating_q975": 1345.3790474518596,
            "rating_q025": 1323.8286356627136
        },
        "step-1o-turbo-202506": {
            "rating": 1330.77139489261,
            "rating_q975": 1354.3172339851162,
            "rating_q025": 1307.2255558001038
        },
        "gemini-2.0-flash-lite-preview-02-05": {
            "rating": 1327.0048120920035,
            "rating_q975": 1338.3043149943062,
            "rating_q025": 1315.7053091897008
        },
        "step-3": {
            "rating": 1324.8023617583842,
            "rating_q975": 1353.867218635607,
            "rating_q025": 1295.7375048811614
        },
        "mistral-small-2506": {
            "rating": 1322.557191013167,
            "rating_q975": 1340.6345152169763,
            "rating_q025": 1304.4798668093579
        },
        "step-2-16k-exp-202412": {
            "rating": 1322.5295582760739,
            "rating_q975": 1344.2302562680516,
            "rating_q025": 1300.8288602840962
        },
        "qwen-plus-0125": {
            "rating": 1322.0934649695964,
            "rating_q975": 1344.151526131077,
            "rating_q025": 1300.035403808116
        },
        "minimax-m1": {
            "rating": 1322.0399905058773,
            "rating_q975": 1335.1602159429926,
            "rating_q025": 1308.919765068762
        },
        "deepseek-v3": {
            "rating": 1322.0052776462028,
            "rating_q975": 1333.077161231928,
            "rating_q025": 1310.9333940604777
        },
        "gemini-1.5-pro-002": {
            "rating": 1317.9675009417322,
            "rating_q975": 1325.0700538705287,
            "rating_q025": 1310.8649480129357
        },
        "gpt-4.1-mini-2025-04-14": {
            "rating": 1316.9441577561752,
            "rating_q975": 1328.4213995859918,
            "rating_q025": 1305.4669159263585
        },
        "o1-preview": {
            "rating": 1315.2551052679764,
            "rating_q975": 1324.4765365697926,
            "rating_q025": 1306.0336739661602
        },
        "command-a-03-2025": {
            "rating": 1314.0239649367359,
            "rating_q975": 1323.6045282333737,
            "rating_q025": 1304.443401640098
        },
        "minimax-m2": {
            "rating": 1311.5499904971932,
            "rating_q975": 1344.8937529539123,
            "rating_q025": 1278.2062280404741
        },
        "glm-4-plus-0111": {
            "rating": 1311.0660799701568,
            "rating_q975": 1332.5034057935313,
            "rating_q025": 1289.6287541467823
        },
        "claude-3-7-sonnet-20250219": {
            "rating": 1310.5587419965082,
            "rating_q975": 1320.8527949173488,
            "rating_q025": 1300.2646890756675
        },
        "qwen3-32b": {
            "rating": 1309.5078220263026,
            "rating_q975": 1335.0496866889555,
            "rating_q025": 1283.9659573636497
        },
        "hunyuan-turbos-20250226": {
            "rating": 1309.3047047004134,
            "rating_q975": 1345.4224776615,
            "rating_q025": 1273.1869317393268
        },
        "claude-3-7-sonnet-20250219-thinking-32k": {
            "rating": 1308.8136591881246,
            "rating_q975": 1319.611578992087,
            "rating_q025": 1298.015739384162
        },
        "claude-3-5-sonnet-20241022": {
            "rating": 1304.1258314218517,
            "rating_q975": 1310.3717192082295,
            "rating_q025": 1297.8799436354739
        },
        "hunyuan-turbo-0110": {
            "rating": 1303.9389092324916,
            "rating_q975": 1336.1951111429169,
            "rating_q025": 1271.6827073220663
        },
        "o3-mini-high": {
            "rating": 1303.085106359945,
            "rating_q975": 1316.2740991187602,
            "rating_q025": 1289.8961136011299
        },
        "gpt-5-nano-high": {
            "rating": 1300.7571068978336,
            "rating_q975": 1327.1386559997609,
            "rating_q025": 1274.3755577959064
        },
        "ling-flash-2.0": {
            "rating": 1300.285740612295,
            "rating_q975": 1330.6297058621892,
            "rating_q025": 1269.941775362401
        },
        "o3-mini": {
            "rating": 1297.597192697825,
            "rating_q975": 1306.14147496568,
            "rating_q025": 1289.05291042997
        },
        "glm-4.5v": {
            "rating": 1296.4857819154945,
            "rating_q975": 1327.995498944679,
            "rating_q025": 1264.97606488631
        },
        "gemma-3-4b-it": {
            "rating": 1294.7163033705806,
            "rating_q975": 1325.422795209575,
            "rating_q025": 1264.0098115315861
        },
        "qwq-32b": {
            "rating": 1294.2554866600685,
            "rating_q975": 1307.2558139392747,
            "rating_q025": 1281.2551593808623
        },
        "gemma-3n-e4b-it": {
            "rating": 1293.9762691164567,
            "rating_q975": 1309.221828736165,
            "rating_q025": 1278.7307094967484
        },
        "qwen3-30b-a3b": {
            "rating": 1291.6840635600238,
            "rating_q975": 1304.7336770086365,
            "rating_q025": 1278.634450111411
        },
        "llama-4-maverick-17b-128e-instruct": {
            "rating": 1289.7563955584187,
            "rating_q975": 1300.9913670834744,
            "rating_q025": 1278.521424033363
        },
        "deepseek-v2.5-1210": {
            "rating": 1287.009010472199,
            "rating_q975": 1303.9726180628988,
            "rating_q025": 1270.045402881499
        },
        "gemini-1.5-flash-002": {
            "rating": 1285.8905100442535,
            "rating_q975": 1294.2023228042801,
            "rating_q025": 1277.5786972842268
        },
        "grok-2-2024-08-13": {
            "rating": 1284.3544126925035,
            "rating_q975": 1291.415972680473,
            "rating_q025": 1277.292852704534
        },
        "gpt-4o-2024-05-13": {
            "rating": 1284.092560658216,
            "rating_q975": 1290.8856703587549,
            "rating_q025": 1277.299450957677
        },
        "llama-3.1-nemotron-ultra-253b-v1": {
            "rating": 1283.5193380253545,
            "rating_q975": 1313.3915969552322,
            "rating_q025": 1253.6470790954768
        },
        "claude-3-5-sonnet-20240620": {
            "rating": 1281.3482695860923,
            "rating_q975": 1288.8066530387835,
            "rating_q025": 1273.8898861334012
        },
        "o1-mini": {
            "rating": 1280.7408413924586,
            "rating_q975": 1288.071647164329,
            "rating_q025": 1273.4100356205881
        },
        "athene-v2-chat": {
            "rating": 1280.269635013443,
            "rating_q975": 1289.8116454586498,
            "rating_q025": 1270.727624568236
        },
        "gemini-advanced-0514": {
            "rating": 1279.7954060901043,
            "rating_q975": 1289.785139221546,
            "rating_q025": 1269.8056729586626
        },
        "claude-3-opus-20240229": {
            "rating": 1278.8623044542796,
            "rating_q975": 1285.0696456820565,
            "rating_q025": 1272.6549632265028
        },
        "gemini-1.5-pro-001": {
            "rating": 1274.774273363962,
            "rating_q975": 1282.9944496846424,
            "rating_q025": 1266.5540970432817
        },
        "glm-4-plus": {
            "rating": 1274.2327360939685,
            "rating_q975": 1283.8831491665744,
            "rating_q025": 1264.5823230213625
        },
        "gpt-4o-mini-2024-07-18": {
            "rating": 1273.9393747344056,
            "rating_q975": 1280.7663373530854,
            "rating_q025": 1267.1124121157259
        },
        "qwen-max-0919": {
            "rating": 1272.6932613749027,
            "rating_q975": 1284.1313470621724,
            "rating_q025": 1261.255175687633
        },
        "gpt-oss-20b": {
            "rating": 1271.061926666868,
            "rating_q975": 1295.0715515059271,
            "rating_q025": 1247.0523018278088
        },
        "gpt-4o-2024-08-06": {
            "rating": 1270.4573487374316,
            "rating_q975": 1278.7230929676027,
            "rating_q025": 1262.1916045072605
        },
        "qwen2.5-plus-1127": {
            "rating": 1269.0002705762677,
            "rating_q975": 1283.8938967213653,
            "rating_q025": 1254.10664443117
        },
        "llama-3.3-nemotron-49b-super-v1": {
            "rating": 1268.78137878505,
            "rating_q975": 1302.9751139101702,
            "rating_q025": 1234.5876436599299
        },
        "llama-4-scout-17b-16e-instruct": {
            "rating": 1265.5121698992248,
            "rating_q975": 1279.0759681186491,
            "rating_q025": 1251.9483716798004
        },
        "hunyuan-large-2025-02-10": {
            "rating": 1264.2397944160746,
            "rating_q975": 1293.0207958577653,
            "rating_q025": 1235.4587929743839
        },
        "llama-3.1-405b-instruct-fp8": {
            "rating": 1263.9147793261877,
            "rating_q975": 1271.2309804933561,
            "rating_q025": 1256.5985781590193
        },
        "qwen2.5-72b-instruct": {
            "rating": 1262.4491624435575,
            "rating_q975": 1270.3797407122104,
            "rating_q025": 1254.5185841749046
        },
        "mistral-small-3.1-24b-instruct-2503": {
            "rating": 1262.035521787678,
            "rating_q975": 1275.131208981837,
            "rating_q025": 1248.9398345935188
        },
        "gpt-4.1-nano-2025-04-14": {
            "rating": 1261.9513472268052,
            "rating_q975": 1282.8310119518267,
            "rating_q025": 1241.0716825017837
        },
        "grok-2-mini-2024-08-13": {
            "rating": 1260.0365431176565,
            "rating_q975": 1267.4207445363718,
            "rating_q025": 1252.6523416989412
        },
        "gpt-4-turbo-2024-04-09": {
            "rating": 1258.1919775727013,
            "rating_q975": 1265.9605977285241,
            "rating_q025": 1250.4233574168784
        },
        "hunyuan-standard-2025-02-10": {
            "rating": 1256.6780659708452,
            "rating_q975": 1283.7115995873817,
            "rating_q025": 1229.6445323543087
        },
        "mistral-large-2407": {
            "rating": 1255.5517798821456,
            "rating_q975": 1263.7775217595004,
            "rating_q025": 1247.326038004791
        },
        "llama-3.1-405b-instruct-bf16": {
            "rating": 1254.7732588955132,
            "rating_q975": 1262.911361565434,
            "rating_q025": 1246.6351562255925
        },
        "yi-lightning": {
            "rating": 1253.9627026707649,
            "rating_q975": 1263.4638513770951,
            "rating_q025": 1244.4615539644346
        },
        "claude-3-5-haiku-20241022": {
            "rating": 1252.3916864925159,
            "rating_q975": 1259.7283987073604,
            "rating_q025": 1245.0549742776714
        },
        "deepseek-v2.5": {
            "rating": 1251.2080132102465,
            "rating_q975": 1261.020126962053,
            "rating_q025": 1241.39589945844
        },
        "mistral-large-2411": {
            "rating": 1250.014865870073,
            "rating_q975": 1259.6602137731736,
            "rating_q025": 1240.3695179669724
        },
        "gpt-4-1106-preview": {
            "rating": 1248.7318383148486,
            "rating_q975": 1257.372694392759,
            "rating_q025": 1240.090982236938
        },
        "athene-70b-0725": {
            "rating": 1248.3361382608814,
            "rating_q975": 1261.1916250435258,
            "rating_q025": 1235.480651478237
        },
        "llama-3.3-70b-instruct": {
            "rating": 1248.0762752887367,
            "rating_q975": 1255.7212093660194,
            "rating_q025": 1240.431341211454
        },
        "reka-core-20240904": {
            "rating": 1247.5990692307043,
            "rating_q975": 1265.1771228670357,
            "rating_q025": 1230.021015594373
        },
        "hunyuan-large-vision": {
            "rating": 1244.5381631941395,
            "rating_q975": 1275.5595245551733,
            "rating_q025": 1213.5168018331058
        },
        "llama-3.1-tulu-3-70b": {
            "rating": 1244.0208911597394,
            "rating_q975": 1271.1042157606216,
            "rating_q025": 1216.9375665588573
        },
        "gpt-4-0125-preview": {
            "rating": 1240.255984628002,
            "rating_q975": 1248.6078694331234,
            "rating_q025": 1231.9040998228804
        },
        "olmo-3-32b-think": {
            "rating": 1238.7689830217196,
            "rating_q975": 1278.258825919002,
            "rating_q025": 1199.2791401244372
        },
        "amazon-nova-pro-v1.0": {
            "rating": 1238.2615907178247,
            "rating_q975": 1248.213177650523,
            "rating_q025": 1228.3100037851264
        },
        "gemini-1.5-flash-001": {
            "rating": 1238.0200999379892,
            "rating_q975": 1246.6259842651596,
            "rating_q025": 1229.414215610819
        },
        "gemini-1.5-flash-8b-001": {
            "rating": 1234.2697038044464,
            "rating_q975": 1242.4718213542706,
            "rating_q025": 1226.0675862546223
        },
        "gemma-2-27b-it": {
            "rating": 1232.5123974547803,
            "rating_q975": 1239.0959720708909,
            "rating_q025": 1225.9288228386697
        },
        "llama-3.1-70b-instruct": {
            "rating": 1232.4029130335682,
            "rating_q975": 1239.855297380383,
            "rating_q025": 1224.9505286867534
        },
        "command-r-plus-08-2024": {
            "rating": 1226.7814090934937,
            "rating_q975": 1241.5005185675936,
            "rating_q025": 1212.0622996193938
        },
        "claude-3-sonnet-20240229": {
            "rating": 1226.005218203588,
            "rating_q975": 1234.6394737423484,
            "rating_q025": 1217.3709626648274
        },
        "qwen2.5-coder-32b-instruct": {
            "rating": 1225.8046632258424,
            "rating_q975": 1244.1093754206959,
            "rating_q025": 1207.499951030989
        },
        "c4ai-aya-expanse-32b": {
            "rating": 1225.6825301111278,
            "rating_q975": 1235.000792377957,
            "rating_q025": 1216.3642678442986
        },
        "ring-flash-2.0": {
            "rating": 1225.5439185017983,
            "rating_q975": 1255.607123730877,
            "rating_q025": 1195.4807132727196
        },
        "llama-3.1-nemotron-70b-instruct": {
            "rating": 1225.2348625954608,
            "rating_q975": 1242.173859698239,
            "rating_q025": 1208.2958654926824
        },
        "gemma-2-9b-it-simpo": {
            "rating": 1223.5287390688031,
            "rating_q975": 1240.1500688497906,
            "rating_q025": 1206.9074092878157
        },
        "nemotron-4-340b-instruct": {
            "rating": 1219.454629723859,
            "rating_q975": 1231.65751556784,
            "rating_q025": 1207.251743879878
        },
        "magistral-medium-2506": {
            "rating": 1217.4243857192414,
            "rating_q975": 1239.0968025814705,
            "rating_q025": 1195.7519688570123
        },
        "mistral-small-24b-instruct-2501": {
            "rating": 1215.0799286263007,
            "rating_q975": 1229.4509786764286,
            "rating_q025": 1200.7088785761728
        },
        "amazon-nova-lite-v1.0": {
            "rating": 1214.4269498690708,
            "rating_q975": 1225.4818851091866,
            "rating_q025": 1203.372014628955
        },
        "reka-flash-20240904": {
            "rating": 1211.356836043648,
            "rating_q975": 1228.491285192245,
            "rating_q025": 1194.222386895051
        },
        "glm-4-0520": {
            "rating": 1211.1993006471266,
            "rating_q975": 1227.1750376414864,
            "rating_q025": 1195.2235636527669
        },
        "phi-4": {
            "rating": 1206.389247026872,
            "rating_q975": 1217.2743903139135,
            "rating_q025": 1195.5041037398305
        },
        "command-r-plus": {
            "rating": 1204.334187973073,
            "rating_q975": 1213.205445451609,
            "rating_q025": 1195.4629304945372
        },
        "claude-3-haiku-20240307": {
            "rating": 1203.588432426777,
            "rating_q975": 1211.184031754165,
            "rating_q025": 1195.992833099389
        },
        "gemma-2-9b-it": {
            "rating": 1198.8228254398632,
            "rating_q975": 1206.3447251312737,
            "rating_q025": 1191.3009257484528
        },
        "c4ai-aya-expanse-8b": {
            "rating": 1196.6675831499288,
            "rating_q975": 1211.0575588119063,
            "rating_q025": 1182.2776074879512
        },
        "gpt-4-0314": {
            "rating": 1194.5292846973975,
            "rating_q975": 1206.2888086681317,
            "rating_q025": 1182.7697607266634
        },
        "ministral-8b-2410": {
            "rating": 1193.360599651239,
            "rating_q975": 1212.8188283958887,
            "rating_q025": 1173.9023709065893
        },
        "jamba-1.5-large": {
            "rating": 1193.1394950568142,
            "rating_q975": 1210.6836719244554,
            "rating_q025": 1175.595318189173
        },
        "llama-3.1-tulu-3-8b": {
            "rating": 1190.8436622682068,
            "rating_q975": 1215.2776231150467,
            "rating_q025": 1166.409701421367
        },
        "olmo-2-0325-32b-instruct": {
            "rating": 1187.5715346527477,
            "rating_q975": 1220.864880362884,
            "rating_q025": 1154.2781889426115
        },
        "deepseek-coder-v2": {
            "rating": 1186.6422101234746,
            "rating_q975": 1200.4408143486437,
            "rating_q025": 1172.8436058983054
        },
        "llama-3.1-nemotron-51b-instruct": {
            "rating": 1185.558959571094,
            "rating_q975": 1207.5027226653806,
            "rating_q025": 1163.6151964768073
        },
        "gemini-pro-dev-api": {
            "rating": 1185.4741427308902,
            "rating_q975": 1205.4343399412473,
            "rating_q025": 1165.513945520533
        },
        "amazon-nova-micro-v1.0": {
            "rating": 1184.177480044873,
            "rating_q975": 1195.3840934012985,
            "rating_q025": 1172.9708666884474
        },
        "mistral-large-2402": {
            "rating": 1177.299834512803,
            "rating_q975": 1187.3671154875103,
            "rating_q025": 1167.2325535380958
        },
        "command-r-08-2024": {
            "rating": 1174.7208386020475,
            "rating_q975": 1190.0019457050719,
            "rating_q025": 1159.439731499023
        },
        "gpt-4-0613": {
            "rating": 1171.6764885382418,
            "rating_q975": 1181.2790354152185,
            "rating_q025": 1162.073941661265
        },
        "qwen2-72b-instruct": {
            "rating": 1167.371630567082,
            "rating_q975": 1177.326578276047,
            "rating_q025": 1157.4166828581172
        },
        "mistral-medium": {
            "rating": 1166.2472654993635,
            "rating_q975": 1180.850764333889,
            "rating_q025": 1151.643766664838
        },
        "reka-flash-21b-20240226-online": {
            "rating": 1163.2096308722366,
            "rating_q975": 1178.947174500496,
            "rating_q025": 1147.4720872439773
        },
        "hunyuan-standard-256k": {
            "rating": 1158.4322330485024,
            "rating_q975": 1184.423796341116,
            "rating_q025": 1132.4406697558888
        },
        "reka-flash-21b-20240226": {
            "rating": 1158.4244194457588,
            "rating_q975": 1171.1816709797665,
            "rating_q025": 1145.667167911751
        },
        "llama-3-70b-instruct": {
            "rating": 1158.372959321766,
            "rating_q975": 1166.1426377148505,
            "rating_q025": 1150.6032809286817
        },
        "llama-3.1-8b-instruct": {
            "rating": 1157.9698947412016,
            "rating_q975": 1165.7984395274627,
            "rating_q025": 1150.1413499549406
        },
        "command-r": {
            "rating": 1157.048858019738,
            "rating_q975": 1167.088286592406,
            "rating_q025": 1147.00942944707
        },
        "jamba-1.5-mini": {
            "rating": 1156.4670648179235,
            "rating_q975": 1174.0176633339113,
            "rating_q025": 1138.9164663019358
        },
        "mixtral-8x22b-instruct-v0.1": {
            "rating": 1156.2402166982038,
            "rating_q975": 1165.9304507021598,
            "rating_q025": 1146.5499826942478
        },
        "phi-3-medium-4k-instruct": {
            "rating": 1144.2339733168037,
            "rating_q975": 1155.2603744650958,
            "rating_q025": 1133.2075721685117
        },
        "wizardlm-70b": {
            "rating": 1143.9144441926946,
            "rating_q975": 1188.5296178916672,
            "rating_q025": 1099.2992704937221
        },
        "gpt-3.5-turbo-0125": {
            "rating": 1122.98640610696,
            "rating_q975": 1132.7661490989124,
            "rating_q025": 1113.2066631150076
        },
        "qwen1.5-110b-chat": {
            "rating": 1117.8156947478847,
            "rating_q975": 1129.5776527896007,
            "rating_q025": 1106.0537367061686
        },
        "gemma-2-2b-it": {
            "rating": 1117.0054430039158,
            "rating_q975": 1125.2566230258324,
            "rating_q025": 1108.7542629819993
        },
        "zephyr-orpo-141b-A35b-v0.1": {
            "rating": 1113.4767974447877,
            "rating_q975": 1140.4544850015254,
            "rating_q025": 1086.49910988805
        },
        "qwq-32b-preview": {
            "rating": 1113.3896461171248,
            "rating_q975": 1139.5302252665817,
            "rating_q025": 1087.2490669676679
        },
        "openchat-3.5": {
            "rating": 1111.268690738027,
            "rating_q975": 1152.1422178315436,
            "rating_q025": 1070.3951636445106
        },
        "llama-3-8b-instruct": {
            "rating": 1110.145726210301,
            "rating_q975": 1118.6154396081029,
            "rating_q025": 1101.6760128124993
        },
        "phi-3-small-8k-instruct": {
            "rating": 1109.9193529504068,
            "rating_q975": 1122.6928494339745,
            "rating_q025": 1097.1458564668392
        },
        "internlm2_5-20b-chat": {
            "rating": 1105.986972595712,
            "rating_q975": 1121.3551272014636,
            "rating_q025": 1090.6188179899602
        },
        "qwen1.5-72b-chat": {
            "rating": 1104.5701284750512,
            "rating_q975": 1116.9275703846747,
            "rating_q025": 1092.2126865654277
        },
        "snowflake-arctic-instruct": {
            "rating": 1102.7976447630294,
            "rating_q975": 1115.7204726632115,
            "rating_q025": 1089.8748168628474
        },
        "starling-lm-7b-beta": {
            "rating": 1102.1893484949246,
            "rating_q975": 1118.1541834379343,
            "rating_q025": 1086.224513551915
        },
        "starling-lm-7b-alpha": {
            "rating": 1094.3113432566552,
            "rating_q975": 1121.7495085491266,
            "rating_q025": 1066.8731779641837
        },
        "granite-3.1-8b-instruct": {
            "rating": 1092.6051393993675,
            "rating_q975": 1120.4990342398848,
            "rating_q025": 1064.7112445588502
        },
        "yi-1.5-34b-chat": {
            "rating": 1091.004405571698,
            "rating_q975": 1102.4745459462063,
            "rating_q025": 1079.5342651971898
        },
        "mixtral-8x7b-instruct-v0.1": {
            "rating": 1089.3606600899996,
            "rating_q975": 1099.4005451748812,
            "rating_q025": 1079.3207750051179
        },
        "openchat-3.5-0106": {
            "rating": 1085.6952209932124,
            "rating_q975": 1106.305273305493,
            "rating_q025": 1065.0851686809317
        },
        "llama-2-70b-chat": {
            "rating": 1083.60343302702,
            "rating_q975": 1097.6948129503603,
            "rating_q025": 1069.5120531036796
        },
        "vicuna-33b": {
            "rating": 1081.3235801830335,
            "rating_q975": 1102.9061557216226,
            "rating_q025": 1059.7410046444445
        },
        "dbrx-instruct-preview": {
            "rating": 1077.3780082924304,
            "rating_q975": 1089.9448976169451,
            "rating_q025": 1064.8111189679157
        },
        "gpt-3.5-turbo-1106": {
            "rating": 1075.964596633643,
            "rating_q975": 1105.0540568088536,
            "rating_q025": 1046.8751364584323
        },
        "codellama-34b-instruct": {
            "rating": 1075.760709222769,
            "rating_q975": 1121.1698046726333,
            "rating_q025": 1030.3516137729048
        },
        "qwen1.5-32b-chat": {
            "rating": 1073.3130785166431,
            "rating_q975": 1086.5605468908807,
            "rating_q025": 1060.0656101424056
        },
        "granite-3.1-2b-instruct": {
            "rating": 1063.0231911375595,
            "rating_q975": 1090.9423187170455,
            "rating_q025": 1035.1040635580734
        },
        "zephyr-7b-beta": {
            "rating": 1062.7329263171496,
            "rating_q975": 1101.4795149545048,
            "rating_q025": 1023.9863376797942
        },
        "granite-3.0-8b-instruct": {
            "rating": 1060.668959924974,
            "rating_q975": 1079.9252797262325,
            "rating_q025": 1041.4126401237154
        },
        "llama-2-13b-chat": {
            "rating": 1053.0980059356457,
            "rating_q975": 1073.6369697690106,
            "rating_q025": 1032.5590421022807
        },
        "yi-34b-chat": {
            "rating": 1049.4657201933048,
            "rating_q975": 1070.2754250672924,
            "rating_q025": 1028.6560153193172
        },
        "granite-3.0-2b-instruct": {
            "rating": 1047.85175610522,
            "rating_q975": 1066.6149532958602,
            "rating_q025": 1029.0885589145796
        },
        "qwen1.5-14b-chat": {
            "rating": 1047.772864983215,
            "rating_q975": 1062.9085249056177,
            "rating_q025": 1032.6372050608122
        },
        "gemma-1.1-7b-it": {
            "rating": 1045.705417834144,
            "rating_q975": 1057.8723707211427,
            "rating_q025": 1033.5384649471455
        },
        "vicuna-13b": {
            "rating": 1038.7204113402101,
            "rating_q975": 1065.197415948361,
            "rating_q025": 1012.2434067320595
        },
        "phi-3-mini-4k-instruct": {
            "rating": 1021.9440184883865,
            "rating_q975": 1034.647849845877,
            "rating_q025": 1009.2401871308961
        },
        "mistral-7b-instruct-v0.2": {
            "rating": 1021.0021022282464,
            "rating_q975": 1037.9275721000263,
            "rating_q025": 1004.0766323564663
        },
        "phi-3-mini-4k-instruct-june-2024": {
            "rating": 1018.6345486501266,
            "rating_q975": 1035.0186224301028,
            "rating_q025": 1002.2504748701502
        },
        "qwen1.5-7b-chat": {
            "rating": 1009.2568730486934,
            "rating_q975": 1042.9713271235137,
            "rating_q025": 975.5424189738729
        },
        "phi-3-mini-128k-instruct": {
            "rating": 1004.95294785653,
            "rating_q975": 1020.4484402161963,
            "rating_q025": 989.4574554968638
        },
        "mistral-7b-instruct": {
            "rating": 1001.9075928336197,
            "rating_q975": 1043.2266339036528,
            "rating_q025": 960.5885517635866
        },
        "llama-2-7b-chat": {
            "rating": 994.3684674354042,
            "rating_q975": 1017.5086052392666,
            "rating_q025": 971.2283296315419
        },
        "gemma-7b-it": {
            "rating": 991.2441280621388,
            "rating_q975": 1014.544195038469,
            "rating_q025": 967.9440610858086
        },
        "gemma-1.1-2b-it": {
            "rating": 990.8488448118371,
            "rating_q975": 1008.752522267288,
            "rating_q025": 972.9451673563863
        },
        "smollm2-1.7b-instruct": {
            "rating": 987.0022829373726,
            "rating_q975": 1018.2057971102985,
            "rating_q025": 955.7987687644467
        },
        "qwen1.5-4b-chat": {
            "rating": 952.9186848775196,
            "rating_q975": 977.7286360378837,
            "rating_q025": 928.1087337171555
        },
        "llama-3.2-3b-instruct": {
            "rating": 949.4979112290752,
            "rating_q975": 971.7513817666112,
            "rating_q025": 927.2444406915391
        },
        "olmo-7b-instruct": {
            "rating": 946.9279101095192,
            "rating_q975": 974.8221427605764,
            "rating_q025": 919.033677458462
        },
        "llama-3.2-1b-instruct": {
            "rating": 939.5566658710316,
            "rating_q975": 961.7792244893625,
            "rating_q025": 917.3341072527006
        },
        "gemma-2b-it": {
            "rating": 936.3334146714606,
            "rating_q975": 972.9288834826426,
            "rating_q025": 899.7379458602785
        }
    },
    "spanish": {
        "gemini-3-pro": {
            "rating": 1499.1615332767258,
            "rating_q975": 1531.4592520682463,
            "rating_q025": 1466.8638144852052
        },
        "grok-4.1-thinking": {
            "rating": 1483.6584113138633,
            "rating_q975": 1517.0673994288804,
            "rating_q025": 1450.2494231988462
        },
        "gemini-2.5-pro": {
            "rating": 1478.1045339193254,
            "rating_q975": 1496.6279833340202,
            "rating_q025": 1459.5810845046306
        },
        "ernie-5.0-preview-1103": {
            "rating": 1473.535800191497,
            "rating_q975": 1515.9970318937985,
            "rating_q025": 1431.0745684891954
        },
        "claude-opus-4-5-20251101": {
            "rating": 1465.2976044182813,
            "rating_q975": 1505.603718248471,
            "rating_q025": 1424.9914905880914
        },
        "claude-sonnet-4-5-20250929": {
            "rating": 1462.759945105728,
            "rating_q975": 1489.8132607987088,
            "rating_q025": 1435.7066294127474
        },
        "qwen3-max-preview": {
            "rating": 1461.2176922821811,
            "rating_q975": 1485.643210683446,
            "rating_q025": 1436.7921738809164
        },
        "glm-4.5": {
            "rating": 1458.4709780222188,
            "rating_q975": 1484.7617769912404,
            "rating_q025": 1432.1801790531972
        },
        "glm-4.6": {
            "rating": 1451.4581825096352,
            "rating_q975": 1477.937456846929,
            "rating_q025": 1424.9789081723413
        },
        "qwen3-next-80b-a3b-instruct": {
            "rating": 1448.5638626710577,
            "rating_q975": 1475.2589729125036,
            "rating_q025": 1421.8687524296117
        },
        "gpt-5.1-high": {
            "rating": 1446.6635947789152,
            "rating_q975": 1480.769247896903,
            "rating_q025": 1412.5579416609276
        },
        "longcat-flash-chat": {
            "rating": 1445.0745905846497,
            "rating_q975": 1478.172187605576,
            "rating_q025": 1411.9769935637235
        },
        "claude-opus-4-1-20250805-thinking-16k": {
            "rating": 1442.7740101890754,
            "rating_q975": 1464.7366338812676,
            "rating_q025": 1420.8113864968832
        },
        "mistral-medium-2508": {
            "rating": 1440.5576309845264,
            "rating_q975": 1461.2714640172464,
            "rating_q025": 1419.8437979518064
        },
        "chatgpt-4o-latest-20250326": {
            "rating": 1438.9557624898769,
            "rating_q975": 1459.0577705916219,
            "rating_q025": 1418.8537543881318
        },
        "deepseek-v3.2-thinking": {
            "rating": 1436.785479681903,
            "rating_q975": 1488.347978002606,
            "rating_q025": 1385.2229813612003
        },
        "claude-opus-4-1-20250805": {
            "rating": 1435.940832658361,
            "rating_q975": 1455.1667142586473,
            "rating_q025": 1416.7149510580746
        },
        "grok-4-1-fast-reasoning": {
            "rating": 1433.9854157722966,
            "rating_q975": 1480.8412142797827,
            "rating_q025": 1387.1296172648106
        },
        "grok-4.1": {
            "rating": 1432.750705769024,
            "rating_q975": 1465.0551094628415,
            "rating_q025": 1400.4463020752066
        },
        "claude-sonnet-4-5-20250929-thinking-32k": {
            "rating": 1432.2172638465083,
            "rating_q975": 1456.2018555188797,
            "rating_q025": 1408.232672174137
        },
        "grok-4-fast-chat": {
            "rating": 1431.9488564479668,
            "rating_q975": 1471.8544503879828,
            "rating_q025": 1392.0432625079509
        },
        "qwen3-235b-a22b-instruct-2507": {
            "rating": 1431.1876397799078,
            "rating_q975": 1451.4487362877355,
            "rating_q025": 1410.9265432720802
        },
        "gpt-5.1": {
            "rating": 1428.2839304812808,
            "rating_q975": 1461.9283738297966,
            "rating_q025": 1394.639487132765
        },
        "grok-3-preview-02-24": {
            "rating": 1427.4284761520444,
            "rating_q975": 1459.0778226499872,
            "rating_q025": 1395.7791296541016
        },
        "claude-opus-4-5-20251101-thinking-32k": {
            "rating": 1425.5353060269806,
            "rating_q975": 1464.1816812402521,
            "rating_q025": 1386.888930813709
        },
        "grok-4-0709": {
            "rating": 1420.795947898669,
            "rating_q975": 1442.7625576657524,
            "rating_q025": 1398.8293381315857
        },
        "deepseek-v3.2-exp": {
            "rating": 1420.1440263641166,
            "rating_q975": 1455.724990658027,
            "rating_q025": 1384.5630620702061
        },
        "qwen3-vl-235b-a22b-instruct": {
            "rating": 1417.5169313343488,
            "rating_q975": 1451.6229668549354,
            "rating_q025": 1383.4108958137622
        },
        "deepseek-v3.1-thinking": {
            "rating": 1415.485456095453,
            "rating_q975": 1449.8189618034587,
            "rating_q025": 1381.1519503874472
        },
        "gemini-2.5-flash": {
            "rating": 1413.5968827705112,
            "rating_q975": 1432.2087317882008,
            "rating_q025": 1394.9850337528217
        },
        "deepseek-v3.1": {
            "rating": 1411.121205509083,
            "rating_q975": 1445.067531193195,
            "rating_q025": 1377.174879824971
        },
        "deepseek-v3.2-exp-thinking": {
            "rating": 1410.0092145568328,
            "rating_q975": 1445.9154351190723,
            "rating_q025": 1374.1029939945934
        },
        "deepseek-r1-0528": {
            "rating": 1409.4904349788505,
            "rating_q975": 1447.761422874819,
            "rating_q025": 1371.2194470828822
        },
        "kimi-k2-thinking-turbo": {
            "rating": 1408.8011641046978,
            "rating_q975": 1441.8685993214726,
            "rating_q025": 1375.733728887923
        },
        "claude-haiku-4-5-20251001": {
            "rating": 1408.3628051686253,
            "rating_q975": 1435.0886113305655,
            "rating_q025": 1381.636999006685
        },
        "grok-4-fast-reasoning": {
            "rating": 1405.273714020674,
            "rating_q975": 1432.8231411115928,
            "rating_q025": 1377.7242869297554
        },
        "qwen3-235b-a22b-no-thinking": {
            "rating": 1404.3101336579052,
            "rating_q975": 1429.4426235797669,
            "rating_q025": 1379.1776437360436
        },
        "ling-flash-2.0": {
            "rating": 1402.651785026944,
            "rating_q975": 1441.6130081858428,
            "rating_q025": 1363.6905618680453
        },
        "qwen3-max-2025-09-23": {
            "rating": 1401.4864875234077,
            "rating_q975": 1433.2753740671722,
            "rating_q025": 1369.6976009796433
        },
        "mai-1-preview": {
            "rating": 1401.4246503893971,
            "rating_q975": 1428.43502684205,
            "rating_q025": 1374.4142739367442
        },
        "gemini-2.5-flash-preview-09-2025": {
            "rating": 1401.2377450753736,
            "rating_q975": 1425.229412471588,
            "rating_q025": 1377.2460776791593
        },
        "gemini-2.5-flash-lite-preview-09-2025-no-thinking": {
            "rating": 1400.002237215999,
            "rating_q975": 1423.0697495412217,
            "rating_q025": 1376.9347248907764
        },
        "grok-3-mini-beta": {
            "rating": 1399.9242498671133,
            "rating_q975": 1430.3525611198297,
            "rating_q025": 1369.495938614397
        },
        "qwen3-vl-235b-a22b-thinking": {
            "rating": 1394.3202580529232,
            "rating_q975": 1429.215422394925,
            "rating_q025": 1359.4250937109214
        },
        "qwen3-30b-a3b-instruct-2507": {
            "rating": 1392.9909729679064,
            "rating_q975": 1418.6323288245085,
            "rating_q025": 1367.3496171113043
        },
        "gpt-5-chat": {
            "rating": 1392.438426954047,
            "rating_q975": 1416.7299426858904,
            "rating_q025": 1368.1469112222035
        },
        "gpt-oss-120b": {
            "rating": 1391.8424438485754,
            "rating_q975": 1416.3368998569988,
            "rating_q025": 1367.347987840152
        },
        "gpt-5-high": {
            "rating": 1389.628521935255,
            "rating_q975": 1413.255593249841,
            "rating_q025": 1366.0014506206692
        },
        "o3-2025-04-16": {
            "rating": 1388.4398683251911,
            "rating_q975": 1409.592241213972,
            "rating_q025": 1367.2874954364102
        },
        "step-3": {
            "rating": 1384.714459650418,
            "rating_q975": 1429.712566790986,
            "rating_q025": 1339.7163525098497
        },
        "claude-opus-4-20250514-thinking-16k": {
            "rating": 1381.7586784744115,
            "rating_q975": 1405.3849822622385,
            "rating_q025": 1358.1323746865844
        },
        "kimi-k2-0905-preview": {
            "rating": 1381.3877361471386,
            "rating_q975": 1417.4403186596157,
            "rating_q025": 1345.3351536346615
        },
        "qwen2.5-max": {
            "rating": 1380.8774018939623,
            "rating_q975": 1417.041436298814,
            "rating_q025": 1344.7133674891106
        },
        "ring-flash-2.0": {
            "rating": 1380.009276313617,
            "rating_q975": 1418.1889778599837,
            "rating_q025": 1341.8295747672503
        },
        "deepseek-r1": {
            "rating": 1378.5549784650689,
            "rating_q975": 1431.2771770766801,
            "rating_q025": 1325.8327798534576
        },
        "glm-4.5-air": {
            "rating": 1377.4361168139226,
            "rating_q975": 1401.8183195275399,
            "rating_q025": 1353.0539141003053
        },
        "qwen3-235b-a22b": {
            "rating": 1376.7509840589184,
            "rating_q975": 1406.8435891097358,
            "rating_q025": 1346.658379008101
        },
        "amazon-nova-experimental-chat-10-20": {
            "rating": 1374.8347430898575,
            "rating_q975": 1417.4828607025497,
            "rating_q025": 1332.1866254771653
        },
        "mistral-medium-2505": {
            "rating": 1371.983210489447,
            "rating_q975": 1400.5141681098205,
            "rating_q025": 1343.4522528690734
        },
        "gpt-5-nano-high": {
            "rating": 1371.8137218450665,
            "rating_q975": 1416.1434301168915,
            "rating_q025": 1327.4840135732416
        },
        "gpt-4.1-2025-04-14": {
            "rating": 1371.5771753309236,
            "rating_q975": 1393.0394509655707,
            "rating_q025": 1350.1148996962766
        },
        "amazon-nova-experimental-chat-10-09": {
            "rating": 1369.8884481277641,
            "rating_q975": 1413.5671569378603,
            "rating_q025": 1326.209739317668
        },
        "gemini-2.5-flash-lite-preview-06-17-thinking": {
            "rating": 1367.8511948586279,
            "rating_q975": 1392.3107035336286,
            "rating_q025": 1343.3916861836271
        },
        "gemini-2.0-flash-001": {
            "rating": 1365.6779790076666,
            "rating_q975": 1391.9010438780683,
            "rating_q025": 1339.454914137265
        },
        "gpt-5-mini-high": {
            "rating": 1360.511296967226,
            "rating_q975": 1384.6614234267647,
            "rating_q025": 1336.3611705076871
        },
        "grok-3-mini-high": {
            "rating": 1359.467735419097,
            "rating_q975": 1395.3203719934102,
            "rating_q025": 1323.6150988447837
        },
        "qwen3-coder-480b-a35b-instruct": {
            "rating": 1359.2037372501443,
            "rating_q975": 1387.7299083175674,
            "rating_q025": 1330.6775661827212
        },
        "claude-sonnet-4-20250514": {
            "rating": 1358.8703700662413,
            "rating_q975": 1382.315355056179,
            "rating_q025": 1335.4253850763037
        },
        "qwen3-next-80b-a3b-thinking": {
            "rating": 1357.6778525326433,
            "rating_q975": 1388.5921826208155,
            "rating_q025": 1326.7635224444712
        },
        "mistral-small-2506": {
            "rating": 1357.3806483226606,
            "rating_q975": 1390.1902483166668,
            "rating_q025": 1324.5710483286543
        },
        "deepseek-v3": {
            "rating": 1355.0935396340183,
            "rating_q975": 1403.1234222029602,
            "rating_q025": 1307.0636570650763
        },
        "claude-opus-4-20250514": {
            "rating": 1353.6676631764653,
            "rating_q975": 1376.4108981551017,
            "rating_q025": 1330.924428197829
        },
        "qwq-32b": {
            "rating": 1351.8557288826958,
            "rating_q975": 1384.226416463705,
            "rating_q025": 1319.4850413016866
        },
        "claude-sonnet-4-20250514-thinking-32k": {
            "rating": 1350.8616706447258,
            "rating_q975": 1375.414612764339,
            "rating_q025": 1326.3087285251127
        },
        "o4-mini-2025-04-16": {
            "rating": 1349.7562972620512,
            "rating_q975": 1371.9261451211903,
            "rating_q025": 1327.5864494029122
        },
        "minimax-m1": {
            "rating": 1346.7832793164682,
            "rating_q975": 1371.1560428694631,
            "rating_q025": 1322.4105157634733
        },
        "o1-2024-12-17": {
            "rating": 1345.9469533083868,
            "rating_q975": 1394.0444272261482,
            "rating_q025": 1297.8494793906254
        },
        "gemma-3-27b-it": {
            "rating": 1343.6954294993423,
            "rating_q975": 1366.181186440646,
            "rating_q025": 1321.2096725580386
        },
        "deepseek-v3-0324": {
            "rating": 1341.9476812202972,
            "rating_q975": 1364.243314037526,
            "rating_q025": 1319.6520484030684
        },
        "command-a-03-2025": {
            "rating": 1337.6415771621348,
            "rating_q975": 1358.063940047669,
            "rating_q025": 1317.2192142766007
        },
        "glm-4.5v": {
            "rating": 1333.7004934232282,
            "rating_q975": 1380.9719689033363,
            "rating_q025": 1286.42901794312
        },
        "kimi-k2-0711-preview": {
            "rating": 1333.363176430178,
            "rating_q975": 1362.4368433286459,
            "rating_q025": 1304.2895095317103
        },
        "minimax-m2": {
            "rating": 1330.2502504431272,
            "rating_q975": 1378.1341927852968,
            "rating_q025": 1282.3663081009577
        },
        "o3-mini-high": {
            "rating": 1322.4976449687053,
            "rating_q975": 1372.5140870568048,
            "rating_q025": 1272.481202880606
        },
        "qwen3-30b-a3b": {
            "rating": 1320.9580429458847,
            "rating_q975": 1351.9417977413757,
            "rating_q025": 1289.9742881503937
        },
        "yi-lightning": {
            "rating": 1320.4590961553706,
            "rating_q975": 1351.1828101522071,
            "rating_q025": 1289.735382158534
        },
        "glm-4-plus": {
            "rating": 1315.3039689413497,
            "rating_q975": 1346.0148444586162,
            "rating_q025": 1284.5930934240832
        },
        "gemini-1.5-pro-002": {
            "rating": 1314.6630776515044,
            "rating_q975": 1342.5802558574437,
            "rating_q025": 1286.745899445565
        },
        "gemini-2.0-flash-lite-preview-02-05": {
            "rating": 1312.3847319768556,
            "rating_q975": 1356.2057173497105,
            "rating_q025": 1268.5637466040007
        },
        "gpt-4.1-mini-2025-04-14": {
            "rating": 1309.2835536471957,
            "rating_q975": 1333.0757149326735,
            "rating_q025": 1285.491392361718
        },
        "o1-mini": {
            "rating": 1307.172987596006,
            "rating_q975": 1333.6991024241809,
            "rating_q025": 1280.646872767831
        },
        "claude-3-7-sonnet-20250219-thinking-32k": {
            "rating": 1306.8400104880682,
            "rating_q975": 1334.43378434746,
            "rating_q025": 1279.2462366286763
        },
        "o1-preview": {
            "rating": 1306.6877471744951,
            "rating_q975": 1336.799435540869,
            "rating_q025": 1276.5760588081214
        },
        "o3-mini": {
            "rating": 1304.7001644893603,
            "rating_q975": 1327.0758662666328,
            "rating_q025": 1282.3244627120878
        },
        "gemma-3n-e4b-it": {
            "rating": 1298.1627458119651,
            "rating_q975": 1329.6685557562116,
            "rating_q025": 1266.6569358677186
        },
        "gpt-4o-2024-05-13": {
            "rating": 1297.461252476224,
            "rating_q975": 1315.5426913176977,
            "rating_q025": 1279.3798136347502
        },
        "claude-3-7-sonnet-20250219": {
            "rating": 1296.643699748578,
            "rating_q975": 1323.32775402185,
            "rating_q025": 1269.959645475306
        },
        "qwen-max-0919": {
            "rating": 1295.0590753787747,
            "rating_q975": 1332.8051170468323,
            "rating_q025": 1257.313033710717
        },
        "claude-3-5-sonnet-20240620": {
            "rating": 1294.1933590075407,
            "rating_q975": 1314.6871575909202,
            "rating_q025": 1273.6995604241613
        },
        "llama-4-maverick-17b-128e-instruct": {
            "rating": 1291.2396098699548,
            "rating_q975": 1315.0773771823112,
            "rating_q025": 1267.4018425575985
        },
        "claude-3-5-sonnet-20241022": {
            "rating": 1289.240419850338,
            "rating_q975": 1308.772433475164,
            "rating_q025": 1269.708406225512
        },
        "grok-2-2024-08-13": {
            "rating": 1286.127604766451,
            "rating_q975": 1308.96294321856,
            "rating_q025": 1263.292266314342
        },
        "magistral-medium-2506": {
            "rating": 1285.2712054219287,
            "rating_q975": 1328.2382164793328,
            "rating_q025": 1242.3041943645246
        },
        "gpt-4o-mini-2024-07-18": {
            "rating": 1284.0386041408242,
            "rating_q975": 1306.0865895077704,
            "rating_q025": 1261.990618773878
        },
        "grok-2-mini-2024-08-13": {
            "rating": 1283.3873797240633,
            "rating_q975": 1307.0615165257766,
            "rating_q025": 1259.71324292235
        },
        "mistral-small-3.1-24b-instruct-2503": {
            "rating": 1281.4374102664995,
            "rating_q975": 1306.7610348306694,
            "rating_q025": 1256.1137857023296
        },
        "athene-v2-chat": {
            "rating": 1278.1888003109989,
            "rating_q975": 1317.2078340044343,
            "rating_q025": 1239.1697666175635
        },
        "llama-4-scout-17b-16e-instruct": {
            "rating": 1275.943290954252,
            "rating_q975": 1302.9007839306282,
            "rating_q025": 1248.9857979778758
        },
        "gpt-4o-2024-08-06": {
            "rating": 1274.8677244479454,
            "rating_q975": 1300.3653551858822,
            "rating_q025": 1249.3700937100086
        },
        "mistral-large-2411": {
            "rating": 1270.7178588581687,
            "rating_q975": 1315.0704072891845,
            "rating_q025": 1226.365310427153
        },
        "llama-3.3-70b-instruct": {
            "rating": 1270.5953476560205,
            "rating_q975": 1295.8435248636881,
            "rating_q025": 1245.347170448353
        },
        "gpt-4-1106-preview": {
            "rating": 1266.9454160682722,
            "rating_q975": 1287.0202953487708,
            "rating_q025": 1246.8705367877735
        },
        "gpt-4-turbo-2024-04-09": {
            "rating": 1264.640502717592,
            "rating_q975": 1283.8531168933123,
            "rating_q025": 1245.4278885418717
        },
        "athene-70b-0725": {
            "rating": 1264.4912004366013,
            "rating_q975": 1299.1230568877834,
            "rating_q025": 1229.8593439854192
        },
        "llama-3.1-405b-instruct-bf16": {
            "rating": 1263.9584777651771,
            "rating_q975": 1293.0497586561266,
            "rating_q025": 1234.8671968742276
        },
        "gpt-oss-20b": {
            "rating": 1263.3395836257391,
            "rating_q975": 1305.000445535427,
            "rating_q025": 1221.6787217160513
        },
        "qwen2.5-72b-instruct": {
            "rating": 1259.9704588009333,
            "rating_q975": 1289.7165703223286,
            "rating_q025": 1230.224347279538
        },
        "claude-3-5-haiku-20241022": {
            "rating": 1258.4287721680626,
            "rating_q975": 1280.159623488274,
            "rating_q025": 1236.697920847851
        },
        "llama-3.1-70b-instruct": {
            "rating": 1258.1861375581263,
            "rating_q975": 1281.796285365011,
            "rating_q025": 1234.5759897512417
        },
        "llama-3.1-405b-instruct-fp8": {
            "rating": 1257.7558311856724,
            "rating_q975": 1281.3618622299919,
            "rating_q025": 1234.149800141353
        },
        "gpt-4-0125-preview": {
            "rating": 1253.2864923340635,
            "rating_q975": 1273.922166687198,
            "rating_q025": 1232.650817980929
        },
        "deepseek-v2.5": {
            "rating": 1253.0506566584659,
            "rating_q975": 1286.2475475066424,
            "rating_q025": 1219.8537658102894
        },
        "claude-3-opus-20240229": {
            "rating": 1252.328793283984,
            "rating_q975": 1269.0930567154278,
            "rating_q025": 1235.56452985254
        },
        "gemini-1.5-pro-001": {
            "rating": 1247.8013282816228,
            "rating_q975": 1267.9350902163192,
            "rating_q025": 1227.6675663469264
        },
        "gemini-1.5-flash-002": {
            "rating": 1247.0438922559845,
            "rating_q975": 1279.6030965734078,
            "rating_q025": 1214.4846879385611
        },
        "llama-3-70b-instruct": {
            "rating": 1247.0094432652793,
            "rating_q975": 1264.4420045012062,
            "rating_q025": 1229.5768820293524
        },
        "gemini-advanced-0514": {
            "rating": 1246.9061150489415,
            "rating_q975": 1269.75997055879,
            "rating_q025": 1224.052259539093
        },
        "mistral-large-2407": {
            "rating": 1240.798007532991,
            "rating_q975": 1265.1871427699355,
            "rating_q025": 1216.4088722960466
        },
        "phi-4": {
            "rating": 1236.080554192079,
            "rating_q975": 1287.2336962332065,
            "rating_q025": 1184.9274121509516
        },
        "gemma-2-27b-it": {
            "rating": 1232.8116954336974,
            "rating_q975": 1253.7492392322388,
            "rating_q025": 1211.874151635156
        },
        "amazon-nova-micro-v1.0": {
            "rating": 1229.4074660787505,
            "rating_q975": 1273.99866792055,
            "rating_q025": 1184.8162642369512
        },
        "amazon-nova-lite-v1.0": {
            "rating": 1228.7823138636736,
            "rating_q975": 1281.532252109066,
            "rating_q025": 1176.0323756182813
        },
        "gemini-1.5-flash-001": {
            "rating": 1228.592675236086,
            "rating_q975": 1249.2863454046444,
            "rating_q025": 1207.8990050675277
        },
        "gemini-1.5-flash-8b-001": {
            "rating": 1217.756643809174,
            "rating_q975": 1247.910933092802,
            "rating_q025": 1187.602354525546
        },
        "claude-3-sonnet-20240229": {
            "rating": 1210.472943178605,
            "rating_q975": 1230.426598150686,
            "rating_q025": 1190.519288206524
        },
        "gemma-2-9b-it": {
            "rating": 1205.2068225093406,
            "rating_q975": 1229.4546558346356,
            "rating_q025": 1180.9589891840455
        },
        "gpt-4-0314": {
            "rating": 1202.3600095001998,
            "rating_q975": 1228.4317208756545,
            "rating_q025": 1176.288298124745
        },
        "nemotron-4-340b-instruct": {
            "rating": 1201.097917461073,
            "rating_q975": 1231.7478311989673,
            "rating_q025": 1170.4480037231785
        },
        "mistral-large-2402": {
            "rating": 1199.4245166323353,
            "rating_q975": 1222.3027515210908,
            "rating_q025": 1176.5462817435798
        },
        "c4ai-aya-expanse-32b": {
            "rating": 1197.7190774451342,
            "rating_q975": 1232.6785620794878,
            "rating_q025": 1162.7595928107805
        },
        "command-r-plus": {
            "rating": 1192.912081186957,
            "rating_q975": 1213.7993873090531,
            "rating_q025": 1172.024775064861
        },
        "amazon-nova-pro-v1.0": {
            "rating": 1186.4378360917128,
            "rating_q975": 1235.765151534278,
            "rating_q025": 1137.1105206491477
        },
        "llama-3-8b-instruct": {
            "rating": 1178.9274331282827,
            "rating_q975": 1198.0894266887824,
            "rating_q025": 1159.765439567783
        },
        "qwen2-72b-instruct": {
            "rating": 1175.3572157895849,
            "rating_q975": 1201.586850102162,
            "rating_q025": 1149.1275814770077
        },
        "gpt-4-0613": {
            "rating": 1174.9942069347903,
            "rating_q975": 1195.479841558586,
            "rating_q025": 1154.5085723109946
        },
        "llama-3.1-8b-instruct": {
            "rating": 1174.4854191862157,
            "rating_q975": 1200.2903515625278,
            "rating_q025": 1148.6804868099036
        },
        "claude-3-haiku-20240307": {
            "rating": 1171.3276200990576,
            "rating_q975": 1189.8534678415554,
            "rating_q025": 1152.80177235656
        },
        "command-r": {
            "rating": 1157.0768813587913,
            "rating_q975": 1182.1451838695198,
            "rating_q025": 1132.0085788480628
        },
        "mixtral-8x22b-instruct-v0.1": {
            "rating": 1155.8754435930618,
            "rating_q975": 1179.5998090769017,
            "rating_q025": 1132.151078109222
        },
        "deepseek-coder-v2": {
            "rating": 1155.7463479596008,
            "rating_q975": 1192.480864659982,
            "rating_q025": 1119.0118312592197
        },
        "reka-flash-21b-20240226-online": {
            "rating": 1155.161396734971,
            "rating_q975": 1195.2896096736656,
            "rating_q025": 1115.0331837962765
        },
        "mistral-medium": {
            "rating": 1149.480373497995,
            "rating_q975": 1180.1765609906663,
            "rating_q025": 1118.7841860053238
        },
        "qwen1.5-110b-chat": {
            "rating": 1149.294879310461,
            "rating_q975": 1177.8958792426117,
            "rating_q025": 1120.6938793783104
        },
        "llama-2-70b-chat": {
            "rating": 1148.3778332714314,
            "rating_q975": 1176.0555181563723,
            "rating_q025": 1120.7001483864906
        },
        "gemma-2-2b-it": {
            "rating": 1145.8397097009447,
            "rating_q975": 1171.8136396290547,
            "rating_q025": 1119.8657797728347
        },
        "reka-flash-21b-20240226": {
            "rating": 1138.2996181619772,
            "rating_q975": 1168.9255681510608,
            "rating_q025": 1107.6736681728935
        },
        "gemini-pro-dev-api": {
            "rating": 1126.8050723104188,
            "rating_q975": 1167.6225844956098,
            "rating_q025": 1085.987560125228
        },
        "gpt-3.5-turbo-0125": {
            "rating": 1125.7782290392192,
            "rating_q975": 1149.0165016587293,
            "rating_q025": 1102.5399564197091
        },
        "yi-1.5-34b-chat": {
            "rating": 1123.5485550890548,
            "rating_q975": 1152.8776768758214,
            "rating_q025": 1094.2194333022883
        },
        "mixtral-8x7b-instruct-v0.1": {
            "rating": 1118.1840400264966,
            "rating_q975": 1140.26868110498,
            "rating_q025": 1096.0993989480132
        },
        "qwen1.5-72b-chat": {
            "rating": 1116.5234109833086,
            "rating_q975": 1144.96883975848,
            "rating_q025": 1088.0779822081372
        },
        "phi-3-small-8k-instruct": {
            "rating": 1113.2465490354184,
            "rating_q975": 1150.0087236829559,
            "rating_q025": 1076.484374387881
        },
        "phi-3-medium-4k-instruct": {
            "rating": 1099.3872657026006,
            "rating_q975": 1129.0858369195316,
            "rating_q025": 1069.6886944856697
        },
        "gpt-3.5-turbo-1106": {
            "rating": 1098.7724849823267,
            "rating_q975": 1138.4660745795734,
            "rating_q025": 1059.07889538508
        },
        "snowflake-arctic-instruct": {
            "rating": 1095.4978683837408,
            "rating_q975": 1124.3095426296925,
            "rating_q025": 1066.686194137789
        },
        "qwen1.5-32b-chat": {
            "rating": 1095.0886372813075,
            "rating_q975": 1125.2418206404145,
            "rating_q025": 1064.9354539222004
        },
        "llama-2-13b-chat": {
            "rating": 1094.651620691995,
            "rating_q975": 1133.162258589919,
            "rating_q025": 1056.140982794071
        },
        "phi-3-mini-4k-instruct": {
            "rating": 1091.1621227313165,
            "rating_q975": 1122.2492541140768,
            "rating_q025": 1060.074991348556
        },
        "qwen1.5-14b-chat": {
            "rating": 1091.0471038998255,
            "rating_q975": 1125.6016652038193,
            "rating_q025": 1056.4925425958318
        },
        "vicuna-33b": {
            "rating": 1084.1977079885555,
            "rating_q975": 1121.2494854594986,
            "rating_q025": 1047.1459305176124
        },
        "vicuna-13b": {
            "rating": 1082.9672803723565,
            "rating_q975": 1131.2313685616452,
            "rating_q025": 1034.7031921830678
        },
        "zephyr-7b-beta": {
            "rating": 1080.5632024650279,
            "rating_q975": 1135.6999865414803,
            "rating_q025": 1025.4264183885755
        },
        "yi-34b-chat": {
            "rating": 1077.0327195438726,
            "rating_q975": 1117.4577477529908,
            "rating_q025": 1036.6076913347545
        },
        "dbrx-instruct-preview": {
            "rating": 1071.712908756334,
            "rating_q975": 1103.0734258311256,
            "rating_q025": 1040.3523916815423
        },
        "phi-3-mini-128k-instruct": {
            "rating": 1063.8162244481864,
            "rating_q975": 1096.980867375189,
            "rating_q025": 1030.6515815211837
        },
        "gemma-1.1-7b-it": {
            "rating": 1054.7402692102432,
            "rating_q975": 1086.3879053694584,
            "rating_q025": 1023.0926330510281
        },
        "mistral-7b-instruct-v0.2": {
            "rating": 1034.2770619359505,
            "rating_q975": 1078.70271116561,
            "rating_q025": 989.8514127062912
        },
        "llama-2-7b-chat": {
            "rating": 1017.5230651462399,
            "rating_q975": 1067.6922064814212,
            "rating_q025": 967.3539238110586
        },
        "gemma-1.1-2b-it": {
            "rating": 987.3734783362684,
            "rating_q975": 1036.7252238512708,
            "rating_q025": 938.0217328212659
        }
    }
}