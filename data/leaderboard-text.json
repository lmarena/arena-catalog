{
    "chinese": {
        "gemini-2.5-pro": {
            "rating": 1519.5073159933527,
            "rating_q975": 1535.0456436507247,
            "rating_q025": 1503.9689883359806
        },
        "qwen-max-2025-08-15": {
            "rating": 1480.009024909073,
            "rating_q975": 1515.9085851924228,
            "rating_q025": 1444.1094646257234
        },
        "qwen3-235b-a22b-thinking-2507": {
            "rating": 1472.7878263322007,
            "rating_q975": 1502.4367681246777,
            "rating_q025": 1443.138884539724
        },
        "deepseek-v3.1-thinking": {
            "rating": 1464.012045015717,
            "rating_q975": 1500.6169446836627,
            "rating_q025": 1427.407145347771
        },
        "qwen3-235b-a22b-instruct-2507": {
            "rating": 1457.3798764110284,
            "rating_q975": 1480.2514672485481,
            "rating_q025": 1434.5082855735088
        },
        "deepseek-r1-0528": {
            "rating": 1457.0501619881468,
            "rating_q975": 1475.742616645357,
            "rating_q025": 1438.3577073309366
        },
        "glm-4.5": {
            "rating": 1454.6848761381234,
            "rating_q975": 1480.082515424747,
            "rating_q025": 1429.2872368514998
        },
        "chatgpt-4o-latest-20250326": {
            "rating": 1451.9064717516023,
            "rating_q975": 1465.7306042213513,
            "rating_q025": 1438.0823392818534
        },
        "gemini-2.5-flash": {
            "rating": 1451.8295131558268,
            "rating_q975": 1466.0512228675339,
            "rating_q025": 1437.6078034441198
        },
        "deepseek-v3.1": {
            "rating": 1450.2178560444163,
            "rating_q975": 1484.628982590983,
            "rating_q025": 1415.8067294978496
        },
        "mistral-medium-2508": {
            "rating": 1442.0214125333994,
            "rating_q975": 1474.0200918481903,
            "rating_q025": 1410.0227332186087
        },
        "o3-2025-04-16": {
            "rating": 1441.3151635488298,
            "rating_q975": 1455.6187646675,
            "rating_q025": 1427.0115624301593
        },
        "grok-3-preview-02-24": {
            "rating": 1441.223109037262,
            "rating_q975": 1454.9955493378739,
            "rating_q025": 1427.4506687366502
        },
        "grok-4-0709": {
            "rating": 1440.8994286095494,
            "rating_q975": 1462.159626701014,
            "rating_q025": 1419.6392305180848
        },
        "claude-opus-4-1-20250805": {
            "rating": 1431.328519094065,
            "rating_q975": 1455.424240944207,
            "rating_q025": 1407.2327972439234
        },
        "qwen3-30b-a3b-instruct-2507": {
            "rating": 1426.8902680727695,
            "rating_q975": 1454.5340618920663,
            "rating_q025": 1399.2464742534726
        },
        "hunyuan-t1-20250711": {
            "rating": 1425.5486633505818,
            "rating_q975": 1459.749621799399,
            "rating_q025": 1391.347704901765
        },
        "gpt-5-high": {
            "rating": 1422.8977775706096,
            "rating_q975": 1449.5107018046413,
            "rating_q025": 1396.284853336578
        },
        "qwen3-235b-a22b-no-thinking": {
            "rating": 1416.5998496264872,
            "rating_q975": 1432.6814086731817,
            "rating_q025": 1400.5182905797924
        },
        "glm-4.5-air": {
            "rating": 1416.3073480063345,
            "rating_q975": 1442.3765420437987,
            "rating_q025": 1390.23815396887
        },
        "claude-opus-4-1-20250805-thinking-16k": {
            "rating": 1415.7545246622112,
            "rating_q975": 1445.3013443471855,
            "rating_q025": 1386.207704977237
        },
        "gpt-5-chat": {
            "rating": 1413.3248846120173,
            "rating_q975": 1441.049172420759,
            "rating_q025": 1385.6005968032753
        },
        "gpt-4.5-preview-2025-02-27": {
            "rating": 1413.004060071641,
            "rating_q975": 1431.4409483193563,
            "rating_q025": 1394.567171823926
        },
        "hunyuan-turbos-20250416": {
            "rating": 1405.2842906784879,
            "rating_q975": 1430.3551186828704,
            "rating_q025": 1380.2134626741056
        },
        "kimi-k2-0711-preview": {
            "rating": 1404.881789730184,
            "rating_q975": 1425.1757222529923,
            "rating_q025": 1384.5878572073755
        },
        "gpt-5-mini-high": {
            "rating": 1404.6154890665453,
            "rating_q975": 1437.644088684737,
            "rating_q025": 1371.5868894483538
        },
        "mai-1-preview": {
            "rating": 1403.1493141121493,
            "rating_q975": 1436.1658689948886,
            "rating_q025": 1370.1327592294103
        },
        "deepseek-r1": {
            "rating": 1396.464563841507,
            "rating_q975": 1413.5420882256028,
            "rating_q025": 1379.3870394574112
        },
        "gpt-oss-120b": {
            "rating": 1393.7098485340866,
            "rating_q975": 1420.6198637884895,
            "rating_q025": 1366.7998332796838
        },
        "o1-2024-12-17": {
            "rating": 1393.3953181058016,
            "rating_q975": 1406.9817735495562,
            "rating_q025": 1379.808862662047
        },
        "deepseek-v3-0324": {
            "rating": 1392.702911434671,
            "rating_q975": 1407.2255667847082,
            "rating_q025": 1378.1802560846338
        },
        "claude-opus-4-20250514-thinking-16k": {
            "rating": 1384.7264738454944,
            "rating_q975": 1402.6668490712314,
            "rating_q025": 1366.7860986197575
        },
        "glm-4-plus-0111": {
            "rating": 1384.3507265136816,
            "rating_q975": 1413.3664785369613,
            "rating_q025": 1355.3349744904017
        },
        "claude-opus-4-20250514": {
            "rating": 1382.4702699411516,
            "rating_q975": 1397.4561609123966,
            "rating_q025": 1367.4843789699069
        },
        "grok-3-mini-high": {
            "rating": 1379.9799657957872,
            "rating_q975": 1402.9150246783333,
            "rating_q025": 1357.044906913241
        },
        "gemini-2.0-flash-001": {
            "rating": 1377.1904150710325,
            "rating_q975": 1389.0179840813107,
            "rating_q025": 1365.3628460607545
        },
        "grok-3-mini-beta": {
            "rating": 1376.3785007128783,
            "rating_q975": 1394.558489904494,
            "rating_q025": 1358.1985115212628
        },
        "qwen3-235b-a22b": {
            "rating": 1374.2365476494565,
            "rating_q975": 1390.7878060672158,
            "rating_q025": 1357.6852892316974
        },
        "qwq-32b": {
            "rating": 1374.1162926656195,
            "rating_q975": 1389.977710777869,
            "rating_q025": 1358.25487455337
        },
        "qwen2.5-max": {
            "rating": 1373.847420487712,
            "rating_q975": 1386.2826937824107,
            "rating_q025": 1361.4121471930132
        },
        "o3-mini-high": {
            "rating": 1373.2240278150284,
            "rating_q975": 1389.6587197605188,
            "rating_q025": 1356.789335869538
        },
        "gpt-5-nano-high": {
            "rating": 1370.7594092435008,
            "rating_q975": 1406.689395776769,
            "rating_q025": 1334.8294227102324
        },
        "mistral-medium-2505": {
            "rating": 1368.978655534514,
            "rating_q975": 1383.5947995039874,
            "rating_q025": 1354.3625115650404
        },
        "gpt-4.1-2025-04-14": {
            "rating": 1366.4149004504363,
            "rating_q975": 1382.387533818708,
            "rating_q025": 1350.4422670821643
        },
        "minimax-m1": {
            "rating": 1361.581629688906,
            "rating_q975": 1379.6492342482593,
            "rating_q025": 1343.514025129553
        },
        "step-1o-turbo-202506": {
            "rating": 1361.4131000332268,
            "rating_q975": 1386.8224271551485,
            "rating_q025": 1336.003772911305
        },
        "qwen3-32b": {
            "rating": 1358.0119340792003,
            "rating_q975": 1392.7759722523772,
            "rating_q025": 1323.2478959060236
        },
        "qwen3-30b-a3b": {
            "rating": 1355.5204615679793,
            "rating_q975": 1372.0362688778932,
            "rating_q025": 1339.0046542580653
        },
        "hunyuan-turbo-0110": {
            "rating": 1351.3956401487028,
            "rating_q975": 1388.4936486643744,
            "rating_q025": 1314.2976316330314
        },
        "qwen-plus-0125": {
            "rating": 1347.1162950796122,
            "rating_q975": 1374.26907137683,
            "rating_q025": 1319.9635187823944
        },
        "o4-mini-2025-04-16": {
            "rating": 1346.6030993507993,
            "rating_q975": 1362.7441988792634,
            "rating_q025": 1330.461999822335
        },
        "qwen3-coder-480b-a35b-instruct": {
            "rating": 1345.0234990020663,
            "rating_q975": 1371.6329447572396,
            "rating_q025": 1318.414053246893
        },
        "gemma-3-27b-it": {
            "rating": 1341.7787447738122,
            "rating_q975": 1355.7435037933476,
            "rating_q025": 1327.8139857542765
        },
        "hunyuan-large-2025-02-10": {
            "rating": 1341.7516319475787,
            "rating_q975": 1374.1971448482686,
            "rating_q025": 1309.3061190468889
        },
        "claude-sonnet-4-20250514-thinking-32k": {
            "rating": 1341.6007779304496,
            "rating_q975": 1359.8088790111472,
            "rating_q025": 1323.3926768497518
        },
        "claude-sonnet-4-20250514": {
            "rating": 1340.1291130841769,
            "rating_q975": 1356.0572183993168,
            "rating_q025": 1324.2010077690368
        },
        "gemini-2.0-flash-lite-preview-02-05": {
            "rating": 1337.3179186482462,
            "rating_q975": 1351.433147191199,
            "rating_q025": 1323.2026901052936
        },
        "deepseek-v3": {
            "rating": 1336.3447773489706,
            "rating_q975": 1351.0017501573468,
            "rating_q025": 1321.6878045405945
        },
        "mistral-small-2506": {
            "rating": 1333.2262538449747,
            "rating_q975": 1354.0646039574867,
            "rating_q025": 1312.3879037324627
        },
        "amazon-nova-experimental-chat-05-14": {
            "rating": 1329.366496678089,
            "rating_q975": 1349.3485380800669,
            "rating_q025": 1309.3844552761116
        },
        "gemini-1.5-pro-002": {
            "rating": 1328.8298369240008,
            "rating_q975": 1337.5723099768547,
            "rating_q025": 1320.0873638711466
        },
        "gpt-oss-20b": {
            "rating": 1326.8395119145805,
            "rating_q975": 1355.7454417964977,
            "rating_q025": 1297.933582032663
        },
        "gpt-4.1-mini-2025-04-14": {
            "rating": 1325.7262762940338,
            "rating_q975": 1342.0095530358446,
            "rating_q025": 1309.4429995522228
        },
        "o3-mini": {
            "rating": 1324.3312964233646,
            "rating_q975": 1335.5084716037234,
            "rating_q025": 1313.1541212430059
        },
        "o1-preview": {
            "rating": 1323.900631506901,
            "rating_q975": 1335.309083944818,
            "rating_q025": 1312.492179068984
        },
        "step-2-16k-exp-202412": {
            "rating": 1321.247600019444,
            "rating_q975": 1352.571451312517,
            "rating_q025": 1289.9237487263713
        },
        "hunyuan-turbos-20250226": {
            "rating": 1317.7103012698592,
            "rating_q975": 1355.5647299534921,
            "rating_q025": 1279.8558725862265
        },
        "hunyuan-standard-2025-02-10": {
            "rating": 1316.9870069102124,
            "rating_q975": 1347.6194534478939,
            "rating_q025": 1286.3545603725306
        },
        "deepseek-v2.5-1210": {
            "rating": 1316.953683035143,
            "rating_q975": 1342.3889847293908,
            "rating_q025": 1291.5183813408955
        },
        "yi-lightning": {
            "rating": 1316.9174178974924,
            "rating_q975": 1328.114119583505,
            "rating_q025": 1305.7207162114798
        },
        "gemma-3n-e4b-it": {
            "rating": 1312.7931795213833,
            "rating_q975": 1334.1927827926143,
            "rating_q025": 1291.3935762501521
        },
        "o1-mini": {
            "rating": 1312.4738760665132,
            "rating_q975": 1321.4724293848121,
            "rating_q025": 1303.4753227482142
        },
        "qwen2.5-plus-1127": {
            "rating": 1309.8614568971846,
            "rating_q975": 1331.6325827795206,
            "rating_q025": 1288.0903310148485
        },
        "command-a-03-2025": {
            "rating": 1306.9154327646013,
            "rating_q975": 1320.7555979822291,
            "rating_q025": 1293.0752675469737
        },
        "claude-3-7-sonnet-20250219-thinking-32k": {
            "rating": 1304.2440873492287,
            "rating_q975": 1317.9705245802709,
            "rating_q025": 1290.5176501181868
        },
        "athene-v2-chat": {
            "rating": 1300.7508176466063,
            "rating_q975": 1313.6848810245965,
            "rating_q025": 1287.8167542686158
        },
        "claude-3-7-sonnet-20250219": {
            "rating": 1295.7569013183572,
            "rating_q975": 1308.5329255699965,
            "rating_q025": 1282.980877066718
        },
        "gemini-1.5-flash-002": {
            "rating": 1294.2956903645097,
            "rating_q975": 1304.6248021144409,
            "rating_q025": 1283.9665786145783
        },
        "glm-4-plus": {
            "rating": 1292.8870038956368,
            "rating_q975": 1304.6513528447715,
            "rating_q025": 1281.1226549465023
        },
        "grok-2-2024-08-13": {
            "rating": 1288.2784268764187,
            "rating_q975": 1296.5149334940845,
            "rating_q025": 1280.0419202587527
        },
        "deepseek-v2.5": {
            "rating": 1281.049965796442,
            "rating_q975": 1292.9561769989687,
            "rating_q025": 1269.1437545939154
        },
        "llama-3.3-nemotron-49b-super-v1": {
            "rating": 1280.2851899156722,
            "rating_q975": 1315.186984508355,
            "rating_q025": 1245.3833953229891
        },
        "gpt-4o-2024-05-13": {
            "rating": 1276.4292161042713,
            "rating_q975": 1283.6437969644694,
            "rating_q025": 1269.2146352440732
        },
        "gemini-1.5-pro-001": {
            "rating": 1273.66583004278,
            "rating_q975": 1282.252381875807,
            "rating_q025": 1265.0792782097533
        },
        "gemini-advanced-0514": {
            "rating": 1273.1573962336254,
            "rating_q975": 1283.2454018367114,
            "rating_q025": 1263.0693906305394
        },
        "llama-4-maverick-17b-128e-instruct": {
            "rating": 1271.1520385456383,
            "rating_q975": 1286.7591211955753,
            "rating_q025": 1255.5449558957016
        },
        "claude-3-5-sonnet-20241022": {
            "rating": 1270.8861294010712,
            "rating_q975": 1278.3410854297365,
            "rating_q025": 1263.4311733724062
        },
        "qwen2.5-72b-instruct": {
            "rating": 1270.8065971292972,
            "rating_q975": 1280.6050201738465,
            "rating_q025": 1261.008174084748
        },
        "hunyuan-large-vision": {
            "rating": 1267.4386116080527,
            "rating_q975": 1303.647529617991,
            "rating_q025": 1231.2296935981142
        },
        "gpt-4.1-nano-2025-04-14": {
            "rating": 1267.3523780445357,
            "rating_q975": 1302.2319245864394,
            "rating_q025": 1232.4728315026323
        },
        "claude-3-5-sonnet-20240620": {
            "rating": 1264.0312466307341,
            "rating_q975": 1271.999270108556,
            "rating_q025": 1256.0632231529123
        },
        "gpt-4o-mini-2024-07-18": {
            "rating": 1263.1850320727028,
            "rating_q975": 1271.0832722390032,
            "rating_q025": 1255.2867919064024
        },
        "grok-2-mini-2024-08-13": {
            "rating": 1262.703069833729,
            "rating_q975": 1271.4553952027038,
            "rating_q025": 1253.9507444647538
        },
        "llama-3.1-nemotron-70b-instruct": {
            "rating": 1261.5413390892222,
            "rating_q975": 1281.704952920458,
            "rating_q025": 1241.3777252579864
        },
        "gpt-4o-2024-08-06": {
            "rating": 1254.6555641796767,
            "rating_q975": 1264.1618966440715,
            "rating_q025": 1245.1492317152818
        },
        "qwen-max-0919": {
            "rating": 1253.5771630428703,
            "rating_q975": 1268.1560122977091,
            "rating_q025": 1238.9983137880317
        },
        "llama-3.1-tulu-3-70b": {
            "rating": 1253.1467882448833,
            "rating_q975": 1288.8640634649548,
            "rating_q025": 1217.429513024812
        },
        "llama-4-scout-17b-16e-instruct": {
            "rating": 1250.6745887409402,
            "rating_q975": 1271.0185106286153,
            "rating_q025": 1230.3306668532648
        },
        "claude-3-opus-20240229": {
            "rating": 1247.9485167596508,
            "rating_q975": 1254.3747280195655,
            "rating_q025": 1241.5223054997364
        },
        "amazon-nova-pro-v1.0": {
            "rating": 1243.7172559125024,
            "rating_q975": 1257.0474293879226,
            "rating_q025": 1230.3870824370822
        },
        "gpt-4-turbo-2024-04-09": {
            "rating": 1242.1098231731517,
            "rating_q975": 1250.2000062057532,
            "rating_q025": 1234.0196401405503
        },
        "reka-core-20240904": {
            "rating": 1242.0718091368121,
            "rating_q975": 1264.1334797679297,
            "rating_q025": 1220.0101385056946
        },
        "gpt-4-1106-preview": {
            "rating": 1241.8429019259988,
            "rating_q975": 1250.5078084044524,
            "rating_q025": 1233.177995447545
        },
        "mistral-large-2411": {
            "rating": 1241.1896134930123,
            "rating_q975": 1253.726126531803,
            "rating_q025": 1228.6531004542217
        },
        "llama-3.1-405b-instruct-bf16": {
            "rating": 1240.7947667171584,
            "rating_q975": 1250.7958780167005,
            "rating_q025": 1230.7936554176163
        },
        "mistral-large-2407": {
            "rating": 1240.1041590204231,
            "rating_q975": 1249.5740723349566,
            "rating_q025": 1230.6342457058895
        },
        "qwen2-72b-instruct": {
            "rating": 1239.047770753244,
            "rating_q975": 1249.4406038862012,
            "rating_q025": 1228.6549376202872
        },
        "hunyuan-standard-256k": {
            "rating": 1238.2444883305989,
            "rating_q975": 1271.1724120909446,
            "rating_q025": 1205.3165645702534
        },
        "mistral-small-3.1-24b-instruct-2503": {
            "rating": 1237.8262040161346,
            "rating_q975": 1257.7005311769665,
            "rating_q025": 1217.9518768553028
        },
        "athene-70b-0725": {
            "rating": 1236.7814884112618,
            "rating_q975": 1250.4138468382585,
            "rating_q025": 1223.1491299842653
        },
        "gpt-4-0125-preview": {
            "rating": 1236.3861581488227,
            "rating_q975": 1244.829152205279,
            "rating_q025": 1227.9431640923663
        },
        "llama-3.1-405b-instruct-fp8": {
            "rating": 1234.3257549540133,
            "rating_q975": 1242.7268670931012,
            "rating_q025": 1225.9246428149254
        },
        "gemini-1.5-flash-001": {
            "rating": 1233.532027257092,
            "rating_q975": 1242.4456485339394,
            "rating_q025": 1224.618405980245
        },
        "gemini-1.5-flash-8b-001": {
            "rating": 1231.5191551638432,
            "rating_q975": 1242.0728924886248,
            "rating_q025": 1220.9654178390615
        },
        "magistral-medium-2506": {
            "rating": 1230.2355896804202,
            "rating_q975": 1258.8493700801514,
            "rating_q025": 1201.621809280689
        },
        "glm-4-0520": {
            "rating": 1230.0744939832393,
            "rating_q975": 1246.1464314604823,
            "rating_q025": 1214.0025565059962
        },
        "command-r-plus-08-2024": {
            "rating": 1226.5680459732357,
            "rating_q975": 1245.2813272432359,
            "rating_q025": 1207.8547647032353
        },
        "gemma-2-9b-it-simpo": {
            "rating": 1226.4897649876675,
            "rating_q975": 1246.322065777315,
            "rating_q025": 1206.65746419802
        },
        "claude-3-5-haiku-20241022": {
            "rating": 1224.7176037370923,
            "rating_q975": 1234.672458753745,
            "rating_q025": 1214.7627487204393
        },
        "amazon-nova-lite-v1.0": {
            "rating": 1224.049203239092,
            "rating_q975": 1239.1189057984006,
            "rating_q025": 1208.9795006797833
        },
        "reka-flash-20240904": {
            "rating": 1222.409179788918,
            "rating_q975": 1244.5672346701053,
            "rating_q025": 1200.2511249077306
        },
        "gemma-2-27b-it": {
            "rating": 1220.9438681549316,
            "rating_q975": 1228.397312871934,
            "rating_q025": 1213.4904234379292
        },
        "qwen2.5-coder-32b-instruct": {
            "rating": 1218.3628661611147,
            "rating_q975": 1241.641321771913,
            "rating_q025": 1195.0844105503163
        },
        "qwq-32b-preview": {
            "rating": 1217.615427011558,
            "rating_q975": 1257.5386079055447,
            "rating_q025": 1177.6922461175714
        },
        "llama-3.1-70b-instruct": {
            "rating": 1215.3938927339523,
            "rating_q975": 1223.9525946119822,
            "rating_q025": 1206.835190855922
        },
        "nemotron-4-340b-instruct": {
            "rating": 1212.901008689977,
            "rating_q975": 1225.108581646578,
            "rating_q025": 1200.6934357333762
        },
        "llama-3.3-70b-instruct": {
            "rating": 1212.813724515383,
            "rating_q975": 1223.0569858345966,
            "rating_q025": 1202.5704631961692
        },
        "phi-4": {
            "rating": 1212.6550049620282,
            "rating_q975": 1227.2799333055746,
            "rating_q025": 1198.0300766184819
        },
        "yi-1.5-34b-chat": {
            "rating": 1212.3814683443388,
            "rating_q975": 1224.1314345653864,
            "rating_q025": 1200.6315021232913
        },
        "amazon-nova-micro-v1.0": {
            "rating": 1212.237475470843,
            "rating_q975": 1227.4047461627383,
            "rating_q025": 1197.0702047789475
        },
        "c4ai-aya-expanse-32b": {
            "rating": 1211.7065519510502,
            "rating_q975": 1223.1952456043605,
            "rating_q025": 1200.2178582977401
        },
        "qwen1.5-110b-chat": {
            "rating": 1205.0047872172345,
            "rating_q975": 1217.1688896157416,
            "rating_q025": 1192.8406848187274
        },
        "internlm2_5-20b-chat": {
            "rating": 1204.467910608575,
            "rating_q975": 1221.8008808229838,
            "rating_q025": 1187.134940394166
        },
        "jamba-1.5-large": {
            "rating": 1203.779093817863,
            "rating_q975": 1224.743734750464,
            "rating_q025": 1182.814452885262
        },
        "mistral-small-24b-instruct-2501": {
            "rating": 1203.3221486345883,
            "rating_q975": 1220.1898398591075,
            "rating_q025": 1186.4544574100692
        },
        "deepseek-coder-v2": {
            "rating": 1202.5589837129025,
            "rating_q975": 1216.7694804402097,
            "rating_q025": 1188.3484869855954
        },
        "olmo-2-0325-32b-instruct": {
            "rating": 1198.6195940994,
            "rating_q975": 1232.3983815684753,
            "rating_q025": 1164.8408066303248
        },
        "ministral-8b-2410": {
            "rating": 1198.2942725826442,
            "rating_q975": 1222.3470285596445,
            "rating_q025": 1174.241516605644
        },
        "command-r-plus": {
            "rating": 1192.908853761669,
            "rating_q975": 1201.3913602206635,
            "rating_q025": 1184.4263473026745
        },
        "claude-3-sonnet-20240229": {
            "rating": 1190.2853995337568,
            "rating_q975": 1198.1711372054706,
            "rating_q025": 1182.3996618620436
        },
        "qwen1.5-72b-chat": {
            "rating": 1186.67247253916,
            "rating_q975": 1197.8521309058135,
            "rating_q025": 1175.4928141725068
        },
        "gemma-2-9b-it": {
            "rating": 1186.3187053578074,
            "rating_q975": 1194.824481921298,
            "rating_q025": 1177.8129287943168
        },
        "command-r-08-2024": {
            "rating": 1185.3027936296214,
            "rating_q975": 1204.1069137611748,
            "rating_q025": 1166.4986734980678
        },
        "gpt-4-0314": {
            "rating": 1184.6783746121778,
            "rating_q975": 1195.324938623791,
            "rating_q025": 1174.0318106005648
        },
        "c4ai-aya-expanse-8b": {
            "rating": 1183.6351019050899,
            "rating_q975": 1205.9767336691116,
            "rating_q025": 1161.2934701410682
        },
        "llama-3.1-nemotron-51b-instruct": {
            "rating": 1181.0960734983612,
            "rating_q975": 1207.9973908640732,
            "rating_q025": 1154.1947561326492
        },
        "qwen1.5-32b-chat": {
            "rating": 1178.6776956899453,
            "rating_q975": 1190.9129701413194,
            "rating_q025": 1166.442421238571
        },
        "yi-34b-chat": {
            "rating": 1175.95459094007,
            "rating_q975": 1193.2490165492584,
            "rating_q025": 1158.6601653308815
        },
        "llama-3.1-tulu-3-8b": {
            "rating": 1175.479590413608,
            "rating_q975": 1211.9194465515604,
            "rating_q025": 1139.0397342756557
        },
        "claude-3-haiku-20240307": {
            "rating": 1156.8296192973658,
            "rating_q975": 1164.2974166420545,
            "rating_q025": 1149.361821952677
        },
        "llama-3.1-8b-instruct": {
            "rating": 1152.4419409019079,
            "rating_q975": 1161.6572793380365,
            "rating_q025": 1143.2266024657793
        },
        "qwen1.5-14b-chat": {
            "rating": 1150.9278122960018,
            "rating_q975": 1163.8232502482192,
            "rating_q025": 1138.0323743437843
        },
        "command-r": {
            "rating": 1149.752238283477,
            "rating_q975": 1159.2645227013545,
            "rating_q025": 1140.2399538655995
        },
        "granite-3.1-2b-instruct": {
            "rating": 1144.027927820176,
            "rating_q975": 1181.5083750318413,
            "rating_q025": 1106.5474806085108
        },
        "reka-flash-21b-20240226-online": {
            "rating": 1143.9744379413828,
            "rating_q975": 1158.2124724241226,
            "rating_q025": 1129.7364034586428
        },
        "granite-3.1-8b-instruct": {
            "rating": 1143.5363443566362,
            "rating_q975": 1181.5913104422912,
            "rating_q025": 1105.481378270981
        },
        "jamba-1.5-mini": {
            "rating": 1140.0656677040338,
            "rating_q975": 1160.5167258259205,
            "rating_q025": 1119.614609582147
        },
        "qwen1.5-7b-chat": {
            "rating": 1139.1484388738886,
            "rating_q975": 1166.947529937847,
            "rating_q025": 1111.3493478099297
        },
        "gpt-4-0613": {
            "rating": 1137.1582057446458,
            "rating_q975": 1146.3362779689778,
            "rating_q025": 1127.980133520314
        },
        "reka-flash-21b-20240226": {
            "rating": 1136.5045643373055,
            "rating_q975": 1148.95124963608,
            "rating_q025": 1124.0578790385312
        },
        "gemma-2-2b-it": {
            "rating": 1133.3595884750048,
            "rating_q975": 1143.0859174903126,
            "rating_q025": 1123.633259459697
        },
        "deepseek-llm-67b-chat": {
            "rating": 1131.9184135059756,
            "rating_q975": 1171.6964000959797,
            "rating_q025": 1092.1404269159714
        },
        "gemini-pro-dev-api": {
            "rating": 1125.778960648324,
            "rating_q975": 1142.287501819924,
            "rating_q025": 1109.2704194767243
        },
        "mistral-large-2402": {
            "rating": 1121.7456099464935,
            "rating_q975": 1131.215968214753,
            "rating_q025": 1112.2752516782339
        },
        "starling-lm-7b-beta": {
            "rating": 1119.9554994591517,
            "rating_q975": 1133.795165327719,
            "rating_q025": 1106.1158335905843
        },
        "mixtral-8x22b-instruct-v0.1": {
            "rating": 1119.0662222613391,
            "rating_q975": 1128.96214447571,
            "rating_q025": 1109.1703000469684
        },
        "llama-3-70b-instruct": {
            "rating": 1117.6273078790891,
            "rating_q975": 1125.3444102281435,
            "rating_q025": 1109.9102055300348
        },
        "mistral-medium": {
            "rating": 1111.6835498740893,
            "rating_q975": 1124.1782000551968,
            "rating_q025": 1099.188899692982
        },
        "phi-3-medium-4k-instruct": {
            "rating": 1110.4396740416098,
            "rating_q975": 1122.182549723827,
            "rating_q025": 1098.6967983593927
        },
        "gemini-pro": {
            "rating": 1101.7463070232347,
            "rating_q975": 1138.6033982409729,
            "rating_q025": 1064.8892158054964
        },
        "openchat-3.5-0106": {
            "rating": 1086.9220713186405,
            "rating_q975": 1103.5192003191603,
            "rating_q025": 1070.3249423181207
        },
        "zephyr-orpo-141b-A35b-v0.1": {
            "rating": 1086.8824668342659,
            "rating_q975": 1109.1752793927844,
            "rating_q025": 1064.5896542757473
        },
        "llama-3-8b-instruct": {
            "rating": 1079.818995601073,
            "rating_q975": 1088.2689162112624,
            "rating_q025": 1071.3690749908835
        },
        "qwen-14b-chat": {
            "rating": 1079.7021650019115,
            "rating_q975": 1123.0334834298428,
            "rating_q025": 1036.37084657398
        },
        "gpt-3.5-turbo-0125": {
            "rating": 1079.4710238436614,
            "rating_q975": 1088.5695649203426,
            "rating_q025": 1070.3724827669803
        },
        "chatglm-6b": {
            "rating": 1076.9292851113987,
            "rating_q975": 1116.1181035027814,
            "rating_q025": 1037.740466720016
        },
        "openchat-3.5": {
            "rating": 1073.9653281823635,
            "rating_q975": 1105.6033794529296,
            "rating_q025": 1042.3272769117975
        },
        "dbrx-instruct-preview": {
            "rating": 1072.6630605473856,
            "rating_q975": 1084.6504346518616,
            "rating_q025": 1060.6756864429094
        },
        "snowflake-arctic-instruct": {
            "rating": 1071.009531843754,
            "rating_q975": 1083.6009992969769,
            "rating_q025": 1058.4180643905315
        },
        "granite-3.0-8b-instruct": {
            "rating": 1070.9328289579166,
            "rating_q975": 1093.3322712875952,
            "rating_q025": 1048.533386628238
        },
        "granite-3.0-2b-instruct": {
            "rating": 1069.830299939409,
            "rating_q975": 1091.9355036118784,
            "rating_q025": 1047.7250962669398
        },
        "chatglm3-6b": {
            "rating": 1065.2462980769585,
            "rating_q975": 1107.6220847533932,
            "rating_q025": 1022.8705114005238
        },
        "gemma-1.1-7b-it": {
            "rating": 1064.2371820675885,
            "rating_q975": 1075.6128573667586,
            "rating_q025": 1052.8615067684184
        },
        "phi-3-small-8k-instruct": {
            "rating": 1063.969721426993,
            "rating_q975": 1076.925132212387,
            "rating_q025": 1051.0143106415987
        },
        "wizardlm-70b": {
            "rating": 1062.2493728904656,
            "rating_q975": 1094.2132327925704,
            "rating_q025": 1030.2855129883608
        },
        "mixtral-8x7b-instruct-v0.1": {
            "rating": 1059.3704878754684,
            "rating_q975": 1068.603323361519,
            "rating_q025": 1050.1376523894178
        },
        "starling-lm-7b-alpha": {
            "rating": 1047.6007354415278,
            "rating_q975": 1068.4912065148208,
            "rating_q025": 1026.7102643682351
        },
        "vicuna-13b": {
            "rating": 1042.334228088138,
            "rating_q975": 1060.8336781224489,
            "rating_q025": 1023.8347780538272
        },
        "vicuna-33b": {
            "rating": 1040.633144353361,
            "rating_q975": 1056.9754992028013,
            "rating_q025": 1024.290789503921
        },
        "gemma-7b-it": {
            "rating": 1040.0349725608642,
            "rating_q975": 1058.9559549145918,
            "rating_q025": 1021.1139902071366
        },
        "phi-3-mini-4k-instruct-june-2024": {
            "rating": 1036.9612383309586,
            "rating_q975": 1053.834734018777,
            "rating_q025": 1020.0877426431405
        },
        "qwen1.5-4b-chat": {
            "rating": 1028.6727632868092,
            "rating_q975": 1047.7458561306673,
            "rating_q025": 1009.5996704429513
        },
        "llama-3.2-3b-instruct": {
            "rating": 1027.2718382137903,
            "rating_q975": 1050.2451006860917,
            "rating_q025": 1004.2985757414888
        },
        "wizardlm-13b": {
            "rating": 1025.5659755489987,
            "rating_q975": 1058.320085514427,
            "rating_q025": 992.8118655835704
        },
        "phi-3-mini-4k-instruct": {
            "rating": 1024.958259964048,
            "rating_q975": 1038.3442537667447,
            "rating_q025": 1011.5722661613511
        },
        "phi-3-mini-128k-instruct": {
            "rating": 1024.0778153194215,
            "rating_q975": 1038.812612435558,
            "rating_q025": 1009.343018203285
        },
        "gemma-1.1-2b-it": {
            "rating": 1019.2279286105469,
            "rating_q975": 1036.031874694216,
            "rating_q025": 1002.4239825268778
        },
        "gpt-3.5-turbo-1106": {
            "rating": 1019.0617659260996,
            "rating_q975": 1043.2156552589984,
            "rating_q025": 994.907876593201
        },
        "olmo-7b-instruct": {
            "rating": 1017.7629575091247,
            "rating_q975": 1040.141835857571,
            "rating_q025": 995.3840791606783
        },
        "openhermes-2.5-mistral-7b": {
            "rating": 1015.6140778045111,
            "rating_q975": 1057.9768389332953,
            "rating_q025": 973.2513166757269
        },
        "mistral-7b-instruct-v0.2": {
            "rating": 1013.2235570239692,
            "rating_q975": 1027.412409695907,
            "rating_q025": 999.0347043520314
        },
        "tulu-2-dpo-70b": {
            "rating": 1011.4770249250334,
            "rating_q975": 1046.909534248278,
            "rating_q025": 976.0445156017887
        },
        "llama-2-13b-chat": {
            "rating": 1003.6439953678419,
            "rating_q975": 1021.5627107636203,
            "rating_q025": 985.7252799720635
        },
        "llama-2-70b-chat": {
            "rating": 998.5488786244682,
            "rating_q975": 1010.9263499252677,
            "rating_q025": 986.1714073236685
        },
        "gemma-2b-it": {
            "rating": 994.0816224095374,
            "rating_q975": 1018.4177691107877,
            "rating_q025": 969.7454757082874
        },
        "vicuna-7b": {
            "rating": 981.9134969038041,
            "rating_q975": 1014.6745751023583,
            "rating_q025": 949.1524187052498
        },
        "llama-2-7b-chat": {
            "rating": 978.6740304513069,
            "rating_q975": 997.5190719230043,
            "rating_q025": 959.8289889796092
        },
        "codellama-34b-instruct": {
            "rating": 978.0007460170664,
            "rating_q975": 1015.5665721567661,
            "rating_q025": 940.4349198773668
        },
        "zephyr-7b-beta": {
            "rating": 967.4047996775137,
            "rating_q975": 997.3698526825106,
            "rating_q025": 937.4397466725168
        },
        "llama-3.2-1b-instruct": {
            "rating": 966.8319447922644,
            "rating_q975": 992.0151714377417,
            "rating_q025": 941.6487181467871
        },
        "mpt-7b-chat": {
            "rating": 963.1943280176766,
            "rating_q975": 1004.5272545569715,
            "rating_q025": 921.8614014783818
        },
        "mistral-7b-instruct": {
            "rating": 941.5334331546519,
            "rating_q975": 974.1142788733373,
            "rating_q025": 908.9525874359666
        },
        "RWKV-4-Raven-14B": {
            "rating": 905.6329424078749,
            "rating_q975": 944.4936832835531,
            "rating_q025": 866.772201532197
        },
        "palm-2": {
            "rating": 891.8264267596787,
            "rating_q975": 928.2643368288152,
            "rating_q025": 855.3885166905422
        },
        "koala-13b": {
            "rating": 878.6162960209751,
            "rating_q975": 910.0846710222922,
            "rating_q025": 847.147921019658
        },
        "dolly-v2-12b": {
            "rating": 833.2394291964031,
            "rating_q975": 877.7695998880456,
            "rating_q025": 788.7092585047608
        },
        "oasst-pythia-12b": {
            "rating": 802.5523607839789,
            "rating_q975": 835.9060968107681,
            "rating_q025": 769.1986247571897
        },
        "alpaca-13b": {
            "rating": 783.470360212415,
            "rating_q975": 822.3399298480226,
            "rating_q025": 744.6007905768074
        },
        "fastchat-t5-3b": {
            "rating": 711.2434993087905,
            "rating_q975": 750.0154476310844,
            "rating_q025": 672.4715509864967
        }
    },
    "coding": {
        "claude-opus-4-1-20250805-thinking-16k": {
            "rating": 1473.208609908666,
            "rating_q975": 1484.8595067017543,
            "rating_q025": 1461.5577131155776
        },
        "gemini-2.5-pro": {
            "rating": 1469.8922622439977,
            "rating_q975": 1477.1816538873834,
            "rating_q025": 1462.6028706006123
        },
        "claude-opus-4-1-20250805": {
            "rating": 1462.2235578162065,
            "rating_q975": 1472.3509938389666,
            "rating_q025": 1452.0961217934464
        },
        "qwen-max-2025-08-15": {
            "rating": 1460.3894389900086,
            "rating_q975": 1474.9582934539612,
            "rating_q025": 1445.820584526056
        },
        "mistral-medium-2508": {
            "rating": 1458.6413980089328,
            "rating_q975": 1470.7935257265835,
            "rating_q025": 1446.4892702912823
        },
        "qwen3-235b-a22b-instruct-2507": {
            "rating": 1456.9224619448073,
            "rating_q975": 1466.6963434644072,
            "rating_q025": 1447.1485804252075
        },
        "gpt-5-high": {
            "rating": 1450.2608680785238,
            "rating_q975": 1460.5935979867354,
            "rating_q025": 1439.9281381703124
        },
        "glm-4.5": {
            "rating": 1446.9027060192077,
            "rating_q975": 1457.0408307579537,
            "rating_q025": 1436.764581280462
        },
        "qwen3-235b-a22b-thinking-2507": {
            "rating": 1444.0334160819175,
            "rating_q975": 1455.6434355777421,
            "rating_q025": 1432.4233965860926
        },
        "grok-3-preview-02-24": {
            "rating": 1440.7160838488703,
            "rating_q975": 1447.5792157386313,
            "rating_q025": 1433.8529519591093
        },
        "o3-2025-04-16": {
            "rating": 1437.8937266523603,
            "rating_q975": 1444.4028484960522,
            "rating_q025": 1431.3846048086684
        },
        "deepseek-r1-0528": {
            "rating": 1436.4302508810724,
            "rating_q975": 1444.8251226826917,
            "rating_q025": 1428.035379079453
        },
        "deepseek-v3.1": {
            "rating": 1436.3534115241798,
            "rating_q975": 1451.9916682570174,
            "rating_q025": 1420.715154791342
        },
        "grok-4-0709": {
            "rating": 1435.8316497598087,
            "rating_q975": 1444.1898573503631,
            "rating_q025": 1427.473442169254
        },
        "chatgpt-4o-latest-20250326": {
            "rating": 1434.7034215341553,
            "rating_q975": 1441.557006086428,
            "rating_q025": 1427.8498369818828
        },
        "qwen-vl-max-2025-08-13": {
            "rating": 1430.6267753258528,
            "rating_q975": 1458.639502566555,
            "rating_q025": 1402.614048085151
        },
        "claude-opus-4-20250514-thinking-16k": {
            "rating": 1429.0088543154566,
            "rating_q975": 1437.1996424778883,
            "rating_q025": 1420.8180661530248
        },
        "deepseek-v3.1-thinking": {
            "rating": 1426.2714796569126,
            "rating_q975": 1443.3720301554144,
            "rating_q025": 1409.1709291584107
        },
        "qwen3-30b-a3b-instruct-2507": {
            "rating": 1423.5648596023955,
            "rating_q975": 1434.9593753987606,
            "rating_q025": 1412.1703438060304
        },
        "gemini-2.5-flash": {
            "rating": 1420.0188364079613,
            "rating_q975": 1427.0672749683056,
            "rating_q025": 1412.9703978476173
        },
        "gpt-5-chat": {
            "rating": 1419.6508310537508,
            "rating_q975": 1431.9420795186,
            "rating_q025": 1407.359582588902
        },
        "gpt-4.5-preview-2025-02-27": {
            "rating": 1419.1072386979808,
            "rating_q975": 1429.663844250195,
            "rating_q025": 1408.5506331457668
        },
        "gpt-5-mini-high": {
            "rating": 1415.754224470259,
            "rating_q975": 1427.9613973073833,
            "rating_q025": 1403.5470516331347
        },
        "gpt-5-old": {
            "rating": 1414.2768097655746,
            "rating_q975": 1455.209730005378,
            "rating_q025": 1373.3438895257711
        },
        "glm-4.5-air": {
            "rating": 1413.9554389490952,
            "rating_q975": 1424.3092953058813,
            "rating_q025": 1403.6015825923091
        },
        "qwen3-235b-a22b-no-thinking": {
            "rating": 1412.1632665619463,
            "rating_q975": 1419.4893583188273,
            "rating_q025": 1404.8371748050656
        },
        "mai-1-preview": {
            "rating": 1412.0005716949793,
            "rating_q975": 1428.797937436144,
            "rating_q025": 1395.2032059538149
        },
        "hunyuan-t1-20250711": {
            "rating": 1410.134884235078,
            "rating_q975": 1423.4809882054317,
            "rating_q025": 1396.7887802647244
        },
        "claude-sonnet-4-20250514-thinking-32k": {
            "rating": 1409.261145984106,
            "rating_q975": 1417.523862957004,
            "rating_q025": 1400.9984290112077
        },
        "gpt-oss-120b": {
            "rating": 1407.0285402766851,
            "rating_q975": 1417.9693497169142,
            "rating_q025": 1396.087730836456
        },
        "qwen3-coder-480b-a35b-instruct": {
            "rating": 1402.8792434965692,
            "rating_q975": 1412.6773024919194,
            "rating_q025": 1393.081184501219
        },
        "claude-opus-4-20250514": {
            "rating": 1402.502168516668,
            "rating_q975": 1409.99374966125,
            "rating_q025": 1395.010587372086
        },
        "kimi-k2-0711-preview": {
            "rating": 1399.367894621898,
            "rating_q975": 1407.75367075576,
            "rating_q025": 1390.982118488036
        },
        "gpt-4.1-2025-04-14": {
            "rating": 1396.4209723310878,
            "rating_q975": 1403.8916520302998,
            "rating_q025": 1388.9502926318755
        },
        "step-3": {
            "rating": 1394.6186489706938,
            "rating_q975": 1413.1976294567487,
            "rating_q025": 1376.039668484639
        },
        "qwen3-235b-a22b": {
            "rating": 1392.5899241890068,
            "rating_q975": 1400.3806140117365,
            "rating_q025": 1384.7992343662768
        },
        "deepseek-v3-0324": {
            "rating": 1391.5954504478743,
            "rating_q975": 1398.647341818293,
            "rating_q025": 1384.5435590774557
        },
        "hunyuan-turbos-20250416": {
            "rating": 1389.1480104782013,
            "rating_q975": 1399.841081895205,
            "rating_q025": 1378.4549390611976
        },
        "mistral-medium-2505": {
            "rating": 1388.5659088684652,
            "rating_q975": 1395.7873587872946,
            "rating_q025": 1381.3444589496357
        },
        "o4-mini-2025-04-16": {
            "rating": 1384.326433338147,
            "rating_q975": 1391.5206391664012,
            "rating_q025": 1377.1322275098926
        },
        "claude-sonnet-4-20250514": {
            "rating": 1382.589879423898,
            "rating_q975": 1390.3706680655876,
            "rating_q025": 1374.8090907822086
        },
        "deepseek-r1": {
            "rating": 1382.1120673897885,
            "rating_q975": 1391.8164815547557,
            "rating_q025": 1372.4076532248214
        },
        "o3-mini-high": {
            "rating": 1380.7406218888161,
            "rating_q975": 1390.521246683681,
            "rating_q025": 1370.9599970939514
        },
        "grok-3-mini-high": {
            "rating": 1380.2226524418784,
            "rating_q975": 1389.065001797343,
            "rating_q025": 1371.3803030864135
        },
        "o1-2024-12-17": {
            "rating": 1377.535838031403,
            "rating_q975": 1385.6124672933681,
            "rating_q025": 1369.4592087694377
        },
        "qwen3-32b": {
            "rating": 1376.0959860354226,
            "rating_q975": 1396.7806417801296,
            "rating_q025": 1355.4113302907156
        },
        "o1-preview": {
            "rating": 1375.6073491344498,
            "rating_q975": 1383.638324309705,
            "rating_q025": 1367.5763739591946
        },
        "grok-3-mini-beta": {
            "rating": 1375.3888006026195,
            "rating_q975": 1383.3408661289282,
            "rating_q025": 1367.436735076311
        },
        "qwen2.5-max": {
            "rating": 1372.9128455759208,
            "rating_q975": 1379.7482184177252,
            "rating_q025": 1366.0774727341163
        },
        "gpt-4.1-mini-2025-04-14": {
            "rating": 1371.5327811651769,
            "rating_q975": 1378.923507013237,
            "rating_q025": 1364.1420553171167
        },
        "minimax-m1": {
            "rating": 1367.2010670837149,
            "rating_q975": 1374.9783300902163,
            "rating_q025": 1359.4238040772134
        },
        "o1-mini": {
            "rating": 1366.2742908329512,
            "rating_q975": 1372.3273087721266,
            "rating_q025": 1360.221272893776
        },
        "gemini-2.0-flash-001": {
            "rating": 1365.099393969042,
            "rating_q975": 1371.4066827495612,
            "rating_q025": 1358.7921051885228
        },
        "mistral-small-2506": {
            "rating": 1363.3802046047488,
            "rating_q975": 1372.4774691501664,
            "rating_q025": 1354.2829400593312
        },
        "gpt-5-nano-high": {
            "rating": 1362.643638304746,
            "rating_q975": 1377.8114061145413,
            "rating_q025": 1347.4758704949506
        },
        "o3-mini": {
            "rating": 1361.9437589574395,
            "rating_q975": 1368.0387718005893,
            "rating_q025": 1355.8487461142895
        },
        "step-1o-turbo-202506": {
            "rating": 1361.0791763834663,
            "rating_q975": 1372.3575949301228,
            "rating_q025": 1349.80075783681
        },
        "nvidia-llama-3.3-nemotron-super-49b-v1.5": {
            "rating": 1357.4723299935265,
            "rating_q975": 1374.2285210432458,
            "rating_q025": 1340.716138943807
        },
        "gpt-oss-20b": {
            "rating": 1355.5811490946048,
            "rating_q975": 1367.4320441942718,
            "rating_q025": 1343.7302539949378
        },
        "claude-3-7-sonnet-20250219-thinking-32k": {
            "rating": 1354.4007968646454,
            "rating_q975": 1361.540822609963,
            "rating_q025": 1347.2607711193277
        },
        "qwq-32b": {
            "rating": 1351.6313658936301,
            "rating_q975": 1359.4974286414074,
            "rating_q025": 1343.7653031458528
        },
        "gemma-3-27b-it": {
            "rating": 1350.283986190433,
            "rating_q975": 1357.105789039108,
            "rating_q025": 1343.4621833417582
        },
        "qwen3-30b-a3b": {
            "rating": 1346.3557181998026,
            "rating_q975": 1354.1709891216929,
            "rating_q025": 1338.5404472779126
        },
        "hunyuan-turbos-20250226": {
            "rating": 1346.0505809258386,
            "rating_q975": 1372.0823064641102,
            "rating_q025": 1320.0188553875669
        },
        "llama-3.1-nemotron-ultra-253b-v1": {
            "rating": 1344.955962936303,
            "rating_q975": 1371.0343849387968,
            "rating_q025": 1318.8775409338093
        },
        "claude-3-5-sonnet-20241022": {
            "rating": 1339.5184590329304,
            "rating_q975": 1344.1493525072374,
            "rating_q025": 1334.8875655586235
        },
        "claude-3-7-sonnet-20250219": {
            "rating": 1339.2429898101443,
            "rating_q975": 1345.9167792525534,
            "rating_q025": 1332.5692003677354
        },
        "command-a-03-2025": {
            "rating": 1338.539340820693,
            "rating_q975": 1345.3514100122893,
            "rating_q025": 1331.727271629097
        },
        "qwen-plus-0125": {
            "rating": 1338.454443782211,
            "rating_q975": 1354.6724338659676,
            "rating_q025": 1322.2364536984544
        },
        "glm-4.5v": {
            "rating": 1337.7752600194672,
            "rating_q975": 1368.1102291025175,
            "rating_q025": 1307.440290936417
        },
        "gemini-2.0-flash-lite-preview-02-05": {
            "rating": 1337.544198791944,
            "rating_q975": 1345.7211216522383,
            "rating_q025": 1329.3672759316496
        },
        "deepseek-v3": {
            "rating": 1337.1780186725273,
            "rating_q975": 1345.8251071142856,
            "rating_q025": 1328.5309302307687
        },
        "amazon-nova-experimental-chat-05-14": {
            "rating": 1337.0017108821253,
            "rating_q975": 1345.4519325694407,
            "rating_q025": 1328.5514891948096
        },
        "hunyuan-turbo-0110": {
            "rating": 1335.1128378824167,
            "rating_q975": 1359.7621520638024,
            "rating_q025": 1310.4635237010307
        },
        "yi-lightning": {
            "rating": 1320.9321556013451,
            "rating_q975": 1329.3738948397727,
            "rating_q025": 1312.4904163629174
        },
        "qwen2.5-plus-1127": {
            "rating": 1320.2779932385483,
            "rating_q975": 1332.2212977357697,
            "rating_q025": 1308.334688741327
        },
        "llama-3.3-nemotron-49b-super-v1": {
            "rating": 1319.8731041080507,
            "rating_q975": 1345.388430620117,
            "rating_q025": 1294.3577775959845
        },
        "athene-v2-chat": {
            "rating": 1319.3560558014385,
            "rating_q975": 1327.1325079070446,
            "rating_q025": 1311.5796036958325
        },
        "deepseek-v2.5-1210": {
            "rating": 1316.2658784046644,
            "rating_q975": 1330.9084822395077,
            "rating_q025": 1301.6232745698212
        },
        "gpt-4.1-nano-2025-04-14": {
            "rating": 1312.968858254412,
            "rating_q975": 1329.37217178622,
            "rating_q025": 1296.565544722604
        },
        "step-2-16k-exp-202412": {
            "rating": 1312.7567022650285,
            "rating_q975": 1330.1636056944442,
            "rating_q025": 1295.349798835613
        },
        "hunyuan-large-2025-02-10": {
            "rating": 1311.1893229678333,
            "rating_q975": 1332.8730263634525,
            "rating_q025": 1289.5056195722138
        },
        "gemma-3-12b-it": {
            "rating": 1310.9262687055914,
            "rating_q975": 1331.1803091465488,
            "rating_q025": 1290.672228264634
        },
        "gemini-1.5-pro-002": {
            "rating": 1310.355527857019,
            "rating_q975": 1316.0622100997516,
            "rating_q025": 1304.6488456142868
        },
        "glm-4-plus-0111": {
            "rating": 1309.4563487451323,
            "rating_q975": 1325.1377756092152,
            "rating_q025": 1293.7749218810495
        },
        "claude-3-5-sonnet-20240620": {
            "rating": 1308.485712553797,
            "rating_q975": 1314.4361120898293,
            "rating_q025": 1302.5353130177648
        },
        "mistral-small-3.1-24b-instruct-2503": {
            "rating": 1307.6347126054475,
            "rating_q975": 1316.2403220427589,
            "rating_q025": 1299.029103168136
        },
        "gpt-4o-2024-05-13": {
            "rating": 1306.5699712932678,
            "rating_q975": 1311.9917627784962,
            "rating_q025": 1301.1481798080392
        },
        "magistral-medium-2506": {
            "rating": 1306.1833260774101,
            "rating_q975": 1317.255039268907,
            "rating_q025": 1295.111612885913
        },
        "deepseek-v2.5": {
            "rating": 1305.3718924524683,
            "rating_q975": 1313.4693124766854,
            "rating_q025": 1297.274472428251
        },
        "gemma-3n-e4b-it": {
            "rating": 1304.8288815663973,
            "rating_q975": 1313.9321497686446,
            "rating_q025": 1295.7256133641497
        },
        "llama-4-maverick-17b-128e-instruct": {
            "rating": 1304.2681510664918,
            "rating_q975": 1311.8569785198738,
            "rating_q025": 1296.6793236131098
        },
        "qwen2.5-72b-instruct": {
            "rating": 1301.576358296175,
            "rating_q975": 1308.0953812124087,
            "rating_q025": 1295.0573353799412
        },
        "glm-4-plus": {
            "rating": 1300.976280670514,
            "rating_q975": 1308.9824121275108,
            "rating_q025": 1292.970149213517
        },
        "gpt-4o-mini-2024-07-18": {
            "rating": 1299.8616155482687,
            "rating_q975": 1305.2940907761347,
            "rating_q025": 1294.429140320403
        },
        "llama-3.1-405b-instruct-bf16": {
            "rating": 1298.7014401208758,
            "rating_q975": 1305.0951542205394,
            "rating_q025": 1292.307726021212
        },
        "hunyuan-large-vision": {
            "rating": 1298.3342150859705,
            "rating_q975": 1313.4062076283856,
            "rating_q025": 1283.2622225435557
        },
        "grok-2-2024-08-13": {
            "rating": 1297.5738771170647,
            "rating_q975": 1303.3084028038782,
            "rating_q025": 1291.8393514302513
        },
        "qwen-max-0919": {
            "rating": 1296.1111569367572,
            "rating_q975": 1305.7131386006804,
            "rating_q025": 1286.509175272834
        },
        "llama-4-scout-17b-16e-instruct": {
            "rating": 1293.821169256957,
            "rating_q975": 1302.536888969243,
            "rating_q025": 1285.105449544671
        },
        "gpt-4o-2024-08-06": {
            "rating": 1292.212629584229,
            "rating_q975": 1298.999383687901,
            "rating_q025": 1285.4258754805567
        },
        "llama-3.1-405b-instruct-fp8": {
            "rating": 1291.8838477102272,
            "rating_q975": 1297.9354640346187,
            "rating_q025": 1285.832231385836
        },
        "hunyuan-standard-2025-02-10": {
            "rating": 1288.4551402993538,
            "rating_q975": 1309.1669271799685,
            "rating_q025": 1267.7433534187392
        },
        "llama-3.1-nemotron-70b-instruct": {
            "rating": 1288.3971134917415,
            "rating_q975": 1301.7730912458733,
            "rating_q025": 1275.0211357376102
        },
        "claude-3-5-haiku-20241022": {
            "rating": 1287.1688145237285,
            "rating_q975": 1292.639699689436,
            "rating_q025": 1281.6979293580214
        },
        "mistral-large-2407": {
            "rating": 1286.5544124125213,
            "rating_q975": 1293.1873839168359,
            "rating_q025": 1279.9214409082065
        },
        "mistral-large-2411": {
            "rating": 1283.5602503315135,
            "rating_q975": 1291.0181146544526,
            "rating_q025": 1276.102386008575
        },
        "amazon-nova-pro-v1.0": {
            "rating": 1281.8614327273658,
            "rating_q975": 1289.5009649449296,
            "rating_q025": 1274.221900509802
        },
        "llama-3.3-70b-instruct": {
            "rating": 1280.4680722802514,
            "rating_q975": 1286.1889860266888,
            "rating_q025": 1274.747158533814
        },
        "gpt-4-turbo-2024-04-09": {
            "rating": 1280.0185488559957,
            "rating_q975": 1286.1829338465807,
            "rating_q025": 1273.8541638654108
        },
        "grok-2-mini-2024-08-13": {
            "rating": 1278.6544941852228,
            "rating_q975": 1284.6922027810751,
            "rating_q025": 1272.6167855893705
        },
        "qwen2.5-coder-32b-instruct": {
            "rating": 1278.3295625883643,
            "rating_q975": 1293.6612696408777,
            "rating_q025": 1262.9978555358512
        },
        "gemini-1.5-pro-001": {
            "rating": 1276.4002053634804,
            "rating_q975": 1282.892250090614,
            "rating_q025": 1269.9081606363463
        },
        "athene-70b-0725": {
            "rating": 1273.7090122215109,
            "rating_q975": 1283.1984038871697,
            "rating_q025": 1264.2196205558523
        },
        "gemini-1.5-flash-002": {
            "rating": 1272.7361344210362,
            "rating_q975": 1279.5675354161397,
            "rating_q025": 1265.9047334259326
        },
        "gemini-advanced-0514": {
            "rating": 1272.3622822454045,
            "rating_q975": 1280.1641321536342,
            "rating_q025": 1264.5604323371747
        },
        "claude-3-opus-20240229": {
            "rating": 1268.6512057234581,
            "rating_q975": 1273.4720073029166,
            "rating_q025": 1263.8304041439994
        },
        "gpt-4-1106-preview": {
            "rating": 1268.2588445777537,
            "rating_q975": 1274.5997839315924,
            "rating_q025": 1261.917905223915
        },
        "llama-3.1-70b-instruct": {
            "rating": 1267.6885941943628,
            "rating_q975": 1273.568117140266,
            "rating_q025": 1261.8090712484598
        },
        "gemma-3-4b-it": {
            "rating": 1267.1982208745424,
            "rating_q975": 1287.0304083753038,
            "rating_q025": 1247.3660333737807
        },
        "gpt-4-0125-preview": {
            "rating": 1261.1015171947274,
            "rating_q975": 1267.6465895431465,
            "rating_q025": 1254.5564448463078
        },
        "deepseek-coder-v2": {
            "rating": 1258.5278617267031,
            "rating_q975": 1269.3604246229909,
            "rating_q025": 1247.6952988304151
        },
        "amazon-nova-lite-v1.0": {
            "rating": 1252.3897640933146,
            "rating_q975": 1261.1592917188568,
            "rating_q025": 1243.620236467772
        },
        "llama-3.1-tulu-3-70b": {
            "rating": 1250.8875570400983,
            "rating_q975": 1271.5537010966777,
            "rating_q025": 1230.2214129835188
        },
        "mistral-small-24b-instruct-2501": {
            "rating": 1250.321485945961,
            "rating_q975": 1260.898423454305,
            "rating_q025": 1239.7445484376171
        },
        "gemini-1.5-flash-001": {
            "rating": 1247.2146710049005,
            "rating_q975": 1253.7468732882323,
            "rating_q025": 1240.682468721569
        },
        "jamba-1.5-large": {
            "rating": 1243.6129218837727,
            "rating_q975": 1256.406258499477,
            "rating_q025": 1230.8195852680685
        },
        "hunyuan-standard-256k": {
            "rating": 1243.5683667338628,
            "rating_q975": 1264.9745204832377,
            "rating_q025": 1222.162212984488
        },
        "phi-4": {
            "rating": 1240.9109444198957,
            "rating_q975": 1249.440101910367,
            "rating_q025": 1232.3817869294246
        },
        "reka-core-20240904": {
            "rating": 1237.7312097093586,
            "rating_q975": 1250.8884286777954,
            "rating_q025": 1224.5739907409215
        },
        "glm-4-0520": {
            "rating": 1236.3348905648709,
            "rating_q975": 1248.7324460275765,
            "rating_q025": 1223.9373351021654
        },
        "claude-3-sonnet-20240229": {
            "rating": 1232.27054081051,
            "rating_q975": 1238.5873596109702,
            "rating_q025": 1225.9537220100501
        },
        "gemini-1.5-flash-8b-001": {
            "rating": 1228.0158418006108,
            "rating_q975": 1234.8716500366702,
            "rating_q025": 1221.1600335645512
        },
        "amazon-nova-micro-v1.0": {
            "rating": 1227.2445598817956,
            "rating_q975": 1236.0390844636802,
            "rating_q025": 1218.4500352999112
        },
        "llama-3.1-nemotron-51b-instruct": {
            "rating": 1226.8882176938996,
            "rating_q975": 1246.277348175417,
            "rating_q025": 1207.4990872123822
        },
        "gemma-2-27b-it": {
            "rating": 1226.1224263235522,
            "rating_q975": 1231.4348292925615,
            "rating_q025": 1220.8100233545426
        },
        "nemotron-4-340b-instruct": {
            "rating": 1219.8146857056643,
            "rating_q975": 1230.0009959614636,
            "rating_q025": 1209.628375449865
        },
        "ministral-8b-2410": {
            "rating": 1218.6134436237207,
            "rating_q975": 1234.8584112703293,
            "rating_q025": 1202.3684759771122
        },
        "gpt-4-0314": {
            "rating": 1217.3658204726466,
            "rating_q975": 1225.8440242898323,
            "rating_q025": 1208.8876166554608
        },
        "llama-3-70b-instruct": {
            "rating": 1216.1783076487263,
            "rating_q975": 1222.1668391892663,
            "rating_q025": 1210.189776108186
        },
        "olmo-2-0325-32b-instruct": {
            "rating": 1215.395370429078,
            "rating_q975": 1239.6837480616998,
            "rating_q025": 1191.1069927964563
        },
        "c4ai-aya-expanse-32b": {
            "rating": 1211.1665927518793,
            "rating_q975": 1219.1406953532671,
            "rating_q025": 1203.1924901504915
        },
        "gemma-2-9b-it-simpo": {
            "rating": 1210.4724829932848,
            "rating_q975": 1223.582955552628,
            "rating_q025": 1197.3620104339416
        },
        "reka-flash-20240904": {
            "rating": 1207.7458704746718,
            "rating_q975": 1220.9324738557339,
            "rating_q025": 1194.5592670936098
        },
        "claude-3-haiku-20240307": {
            "rating": 1207.50826391691,
            "rating_q975": 1213.378068144449,
            "rating_q025": 1201.638459689371
        },
        "qwen2-72b-instruct": {
            "rating": 1205.566169656686,
            "rating_q975": 1213.4620891412312,
            "rating_q025": 1197.6702501721409
        },
        "llama-3.1-8b-instruct": {
            "rating": 1202.6540013037747,
            "rating_q975": 1208.7524483010131,
            "rating_q025": 1196.5555543065361
        },
        "command-r-plus-08-2024": {
            "rating": 1200.073113864519,
            "rating_q975": 1212.2614502024182,
            "rating_q025": 1187.8847775266195
        },
        "llama-3.1-tulu-3-8b": {
            "rating": 1197.018105948966,
            "rating_q975": 1217.427032083586,
            "rating_q025": 1176.6091798143461
        },
        "jamba-1.5-mini": {
            "rating": 1196.331705955536,
            "rating_q975": 1209.7600434401027,
            "rating_q025": 1182.9033684709693
        },
        "gemma-2-9b-it": {
            "rating": 1193.6600494685126,
            "rating_q975": 1199.7344551064284,
            "rating_q025": 1187.585643830597
        },
        "mistral-large-2402": {
            "rating": 1193.4886579011663,
            "rating_q975": 1201.089661227221,
            "rating_q025": 1185.8876545751116
        },
        "qwen1.5-110b-chat": {
            "rating": 1191.6768666274315,
            "rating_q975": 1201.0035011756383,
            "rating_q025": 1182.350232079225
        },
        "gpt-4-0613": {
            "rating": 1191.3805472688407,
            "rating_q975": 1198.4453348944492,
            "rating_q025": 1184.3157596432325
        },
        "granite-3.1-8b-instruct": {
            "rating": 1191.024918524703,
            "rating_q975": 1213.573349793177,
            "rating_q025": 1168.476487256229
        },
        "c4ai-aya-expanse-8b": {
            "rating": 1183.5373534989153,
            "rating_q975": 1196.1653619837873,
            "rating_q025": 1170.909345014043
        },
        "command-r-plus": {
            "rating": 1183.5046270661874,
            "rating_q975": 1190.3261068556824,
            "rating_q025": 1176.6831472766921
        },
        "yi-1.5-34b-chat": {
            "rating": 1181.1992657468147,
            "rating_q975": 1190.579056539368,
            "rating_q025": 1171.8194749542615
        },
        "command-r-08-2024": {
            "rating": 1179.8860477158469,
            "rating_q975": 1191.750089324519,
            "rating_q025": 1168.022006107175
        },
        "internlm2_5-20b-chat": {
            "rating": 1178.5029680735493,
            "rating_q975": 1190.9209438538205,
            "rating_q025": 1166.0849922932778
        },
        "qwen1.5-72b-chat": {
            "rating": 1175.2483294750868,
            "rating_q975": 1183.917313439097,
            "rating_q025": 1166.5793455110766
        },
        "mixtral-8x22b-instruct-v0.1": {
            "rating": 1174.4288411971029,
            "rating_q975": 1182.0421568691193,
            "rating_q025": 1166.8155255250863
        },
        "mistral-medium": {
            "rating": 1171.67844906776,
            "rating_q975": 1181.177775157099,
            "rating_q025": 1162.179122978421
        },
        "reka-flash-21b-20240226-online": {
            "rating": 1168.065063153731,
            "rating_q975": 1179.4591715129275,
            "rating_q025": 1156.6709547945343
        },
        "reka-flash-21b-20240226": {
            "rating": 1167.6672801283826,
            "rating_q975": 1177.0197858052013,
            "rating_q025": 1158.3147744515636
        },
        "granite-3.1-2b-instruct": {
            "rating": 1165.6468281856387,
            "rating_q975": 1187.35686413606,
            "rating_q025": 1143.9367922352174
        },
        "qwq-32b-preview": {
            "rating": 1164.1374853870402,
            "rating_q975": 1185.9019775185436,
            "rating_q025": 1142.3729932555366
        },
        "llama-3-8b-instruct": {
            "rating": 1164.0490094654708,
            "rating_q975": 1170.6219061125926,
            "rating_q025": 1157.476112818349
        },
        "qwen1.5-32b-chat": {
            "rating": 1162.8539019499171,
            "rating_q975": 1172.7705421979701,
            "rating_q025": 1152.937261701864
        },
        "starling-lm-7b-beta": {
            "rating": 1150.4793688844343,
            "rating_q975": 1162.1092110784546,
            "rating_q025": 1138.8495266904138
        },
        "gpt-3.5-turbo-0125": {
            "rating": 1145.595645940526,
            "rating_q975": 1152.8663979129042,
            "rating_q025": 1138.3248939681478
        },
        "phi-3-medium-4k-instruct": {
            "rating": 1145.3434029327368,
            "rating_q975": 1154.3477717928695,
            "rating_q025": 1136.3390340726041
        },
        "zephyr-orpo-141b-A35b-v0.1": {
            "rating": 1144.0081925119198,
            "rating_q975": 1163.2024071968701,
            "rating_q025": 1124.8139778269692
        },
        "qwen1.5-14b-chat": {
            "rating": 1143.6694303278596,
            "rating_q975": 1155.56085447882,
            "rating_q025": 1131.7780061768995
        },
        "command-r": {
            "rating": 1140.6390387505144,
            "rating_q975": 1148.4046291575287,
            "rating_q025": 1132.8734483435
        },
        "dbrx-instruct-preview": {
            "rating": 1140.6346534074441,
            "rating_q975": 1150.609748529283,
            "rating_q025": 1130.6595582856053
        },
        "mixtral-8x7b-instruct-v0.1": {
            "rating": 1135.9998719711386,
            "rating_q975": 1143.2254856126556,
            "rating_q025": 1128.7742583296217
        },
        "gemma-2-2b-it": {
            "rating": 1129.54584052882,
            "rating_q975": 1136.2291986059695,
            "rating_q025": 1122.8624824516708
        },
        "yi-34b-chat": {
            "rating": 1128.7962435821837,
            "rating_q975": 1140.597968094448,
            "rating_q025": 1116.9945190699193
        },
        "gemini-pro-dev-api": {
            "rating": 1124.7759929883985,
            "rating_q975": 1137.129889590888,
            "rating_q025": 1112.4220963859088
        },
        "gpt-3.5-turbo-1106": {
            "rating": 1123.534517462341,
            "rating_q975": 1138.4207338235597,
            "rating_q025": 1108.6483011011226
        },
        "phi-3-small-8k-instruct": {
            "rating": 1122.345425892699,
            "rating_q975": 1132.9319431455676,
            "rating_q025": 1111.7589086398307
        },
        "gemini-pro": {
            "rating": 1120.6203495899908,
            "rating_q975": 1141.6483085804514,
            "rating_q025": 1099.5923905995303
        },
        "tulu-2-dpo-70b": {
            "rating": 1120.1103338399457,
            "rating_q975": 1139.419805423834,
            "rating_q025": 1100.8008622560576
        },
        "openchat-3.5-0106": {
            "rating": 1119.2760165789575,
            "rating_q975": 1132.3388589073957,
            "rating_q025": 1106.2131742505194
        },
        "granite-3.0-8b-instruct": {
            "rating": 1114.8722007336978,
            "rating_q975": 1131.1694669263295,
            "rating_q025": 1098.5749345410659
        },
        "qwen1.5-7b-chat": {
            "rating": 1109.6423675241333,
            "rating_q975": 1128.1967688767288,
            "rating_q025": 1091.0879661715378
        },
        "deepseek-llm-67b-chat": {
            "rating": 1105.4793748221468,
            "rating_q975": 1127.276129072555,
            "rating_q025": 1083.6826205717384
        },
        "gemma-1.1-7b-it": {
            "rating": 1104.9010086719582,
            "rating_q975": 1114.1800606266602,
            "rating_q025": 1095.6219567172564
        },
        "starling-lm-7b-alpha": {
            "rating": 1104.148490824607,
            "rating_q975": 1119.1664617161525,
            "rating_q025": 1089.1305199330616
        },
        "granite-3.0-2b-instruct": {
            "rating": 1103.5349477714403,
            "rating_q975": 1119.0049129593583,
            "rating_q025": 1088.0649825835226
        },
        "nous-hermes-2-mixtral-8x7b-dpo": {
            "rating": 1103.1443235269778,
            "rating_q975": 1124.9053396342692,
            "rating_q025": 1081.3833074196864
        },
        "phi-3-mini-4k-instruct": {
            "rating": 1102.3091193916562,
            "rating_q975": 1112.8564502942745,
            "rating_q025": 1091.7617884890376
        },
        "snowflake-arctic-instruct": {
            "rating": 1100.4891281898533,
            "rating_q975": 1110.6749016672584,
            "rating_q025": 1090.3033547124483
        },
        "llama-2-70b-chat": {
            "rating": 1098.7228533791376,
            "rating_q975": 1107.7663705836317,
            "rating_q025": 1089.6793361746436
        },
        "phi-3-mini-4k-instruct-june-2024": {
            "rating": 1098.1025917994716,
            "rating_q975": 1110.1923987243001,
            "rating_q025": 1086.0127848746433
        },
        "llama-3.2-3b-instruct": {
            "rating": 1096.7521486975243,
            "rating_q975": 1110.3447094942048,
            "rating_q025": 1083.1595879008437
        },
        "mistral-7b-instruct-v0.2": {
            "rating": 1094.0514193826793,
            "rating_q975": 1104.6827267748386,
            "rating_q025": 1083.4201119905204
        },
        "wizardlm-70b": {
            "rating": 1092.1026455743531,
            "rating_q975": 1110.4515975069849,
            "rating_q025": 1073.7536936417214
        },
        "vicuna-33b": {
            "rating": 1091.3642597821051,
            "rating_q975": 1103.0146210265204,
            "rating_q025": 1079.7138985376898
        },
        "openhermes-2.5-mistral-7b": {
            "rating": 1082.4173894988073,
            "rating_q975": 1103.8622660977844,
            "rating_q025": 1060.9725128998302
        },
        "qwen-14b-chat": {
            "rating": 1082.3611316092138,
            "rating_q975": 1105.2703718953487,
            "rating_q025": 1059.451891323079
        },
        "llama-2-13b-chat": {
            "rating": 1077.4793485880944,
            "rating_q975": 1089.1683686627198,
            "rating_q025": 1065.7903285134687
        },
        "openchat-3.5": {
            "rating": 1076.255979555157,
            "rating_q975": 1094.5788699056018,
            "rating_q025": 1057.9330892047121
        },
        "solar-10.7b-instruct-v1.0": {
            "rating": 1073.2780419596108,
            "rating_q975": 1098.8366493340093,
            "rating_q025": 1047.7194345852124
        },
        "codellama-70b-instruct": {
            "rating": 1068.0155128100132,
            "rating_q975": 1107.0368628046558,
            "rating_q025": 1028.9941628153704
        },
        "gemma-7b-it": {
            "rating": 1065.3295666814506,
            "rating_q975": 1080.380650501364,
            "rating_q025": 1050.278482861537
        },
        "codellama-34b-instruct": {
            "rating": 1065.0996496322473,
            "rating_q975": 1083.8510372380845,
            "rating_q025": 1046.3482620264103
        },
        "llama-3.2-1b-instruct": {
            "rating": 1063.0868072337473,
            "rating_q975": 1076.2934790578024,
            "rating_q025": 1049.8801354096922
        },
        "smollm2-1.7b-instruct": {
            "rating": 1061.0571829462913,
            "rating_q975": 1089.2170508533789,
            "rating_q025": 1032.8973150392037
        },
        "zephyr-7b-alpha": {
            "rating": 1060.1247834263304,
            "rating_q975": 1097.4587432329704,
            "rating_q025": 1022.7908236196906
        },
        "mpt-30b-chat": {
            "rating": 1054.8186304289602,
            "rating_q975": 1089.1481625751426,
            "rating_q025": 1020.4890982827781
        },
        "phi-3-mini-128k-instruct": {
            "rating": 1052.423496319051,
            "rating_q975": 1064.3786999471783,
            "rating_q025": 1040.4682926909236
        },
        "zephyr-7b-beta": {
            "rating": 1051.854833409449,
            "rating_q975": 1068.9229931429227,
            "rating_q025": 1034.7866736759756
        },
        "gemma-1.1-2b-it": {
            "rating": 1051.3769013031433,
            "rating_q975": 1064.0272379986313,
            "rating_q025": 1038.7265646076553
        },
        "vicuna-13b": {
            "rating": 1050.5240773058952,
            "rating_q975": 1063.4898440543166,
            "rating_q025": 1037.5583105574738
        },
        "dolphin-2.2.1-mistral-7b": {
            "rating": 1049.5132095116032,
            "rating_q975": 1087.5227440486262,
            "rating_q025": 1011.5036749745802
        },
        "wizardlm-13b": {
            "rating": 1048.4930597277312,
            "rating_q975": 1068.7994111912312,
            "rating_q025": 1028.186708264231
        },
        "llama2-70b-steerlm-chat": {
            "rating": 1046.6890176363372,
            "rating_q975": 1072.1780014509243,
            "rating_q025": 1021.20003382175
        },
        "olmo-7b-instruct": {
            "rating": 1038.857060935816,
            "rating_q975": 1058.6986631717043,
            "rating_q025": 1019.0154586999275
        },
        "mistral-7b-instruct": {
            "rating": 1028.7292421036805,
            "rating_q975": 1047.018556773358,
            "rating_q025": 1010.4399274340029
        },
        "stripedhyena-nous-7b": {
            "rating": 1026.3315134800562,
            "rating_q975": 1047.6027780005163,
            "rating_q025": 1005.060248959596
        },
        "llama-2-7b-chat": {
            "rating": 1023.2160871858555,
            "rating_q975": 1036.128017523346,
            "rating_q025": 1010.3041568483651
        },
        "gemma-2b-it": {
            "rating": 1021.2778741637833,
            "rating_q975": 1041.328634927346,
            "rating_q025": 1001.2271134002206
        },
        "palm-2": {
            "rating": 1015.2213274414426,
            "rating_q975": 1034.0888464394488,
            "rating_q025": 996.3538084434364
        },
        "qwen1.5-4b-chat": {
            "rating": 1010.2873733343276,
            "rating_q975": 1026.6110233832806,
            "rating_q025": 993.9637232853745
        },
        "vicuna-7b": {
            "rating": 1007.5969282937565,
            "rating_q975": 1029.0355340509807,
            "rating_q025": 986.1583225365323
        },
        "guanaco-33b": {
            "rating": 988.9539792827013,
            "rating_q975": 1020.9562255856897,
            "rating_q025": 956.9517329797129
        },
        "chatglm3-6b": {
            "rating": 974.4305304910438,
            "rating_q975": 999.5015675295281,
            "rating_q025": 949.3594934525595
        },
        "koala-13b": {
            "rating": 954.997681647411,
            "rating_q975": 977.3269422558988,
            "rating_q025": 932.6684210389233
        },
        "gpt4all-13b-snoozy": {
            "rating": 932.4260608551949,
            "rating_q975": 973.324434387381,
            "rating_q025": 891.5276873230088
        },
        "mpt-7b-chat": {
            "rating": 922.8846023082338,
            "rating_q975": 953.4571464683696,
            "rating_q025": 892.312058148098
        },
        "RWKV-4-Raven-14B": {
            "rating": 918.947047723788,
            "rating_q975": 944.9006377135856,
            "rating_q025": 892.9934577339906
        },
        "chatglm2-6b": {
            "rating": 914.8091654134888,
            "rating_q975": 947.7139812467035,
            "rating_q025": 881.9043495802741
        },
        "chatglm-6b": {
            "rating": 905.0323689012253,
            "rating_q975": 930.0304956353198,
            "rating_q025": 880.0342421671306
        },
        "oasst-pythia-12b": {
            "rating": 896.2367994210969,
            "rating_q975": 919.7762245829545,
            "rating_q025": 872.6973742592393
        },
        "stablelm-tuned-alpha-7b": {
            "rating": 879.804709443581,
            "rating_q975": 910.1410885281067,
            "rating_q025": 849.4683303590552
        },
        "alpaca-13b": {
            "rating": 813.3749062107369,
            "rating_q975": 839.8909201709607,
            "rating_q025": 786.858892250513
        },
        "fastchat-t5-3b": {
            "rating": 781.5322354364682,
            "rating_q975": 809.5527353046109,
            "rating_q025": 753.5117355683257
        },
        "dolly-v2-12b": {
            "rating": 767.8902427974604,
            "rating_q975": 799.7888131428053,
            "rating_q025": 735.9916724521155
        },
        "llama-13b": {
            "rating": 690.121203734382,
            "rating_q975": 730.0733682339616,
            "rating_q025": 650.1690392348023
        }
    },
    "creative_writing": {
        "gemini-2.5-pro": {
            "rating": 1461.172197015608,
            "rating_q975": 1470.935392912835,
            "rating_q025": 1451.409001118381
        },
        "grok-3-preview-02-24": {
            "rating": 1414.612016483707,
            "rating_q975": 1422.992330077548,
            "rating_q025": 1406.231702889866
        },
        "grok-4-0709": {
            "rating": 1413.5059162188975,
            "rating_q975": 1425.465839574106,
            "rating_q025": 1401.5459928636892
        },
        "chatgpt-4o-latest-20250326": {
            "rating": 1408.0385346457454,
            "rating_q975": 1416.8342281401772,
            "rating_q025": 1399.2428411513138
        },
        "deepseek-r1-0528": {
            "rating": 1407.969516428647,
            "rating_q975": 1419.380847403885,
            "rating_q025": 1396.5581854534094
        },
        "gemini-2.5-flash": {
            "rating": 1407.8155095042102,
            "rating_q975": 1416.967351061636,
            "rating_q025": 1398.6636679467845
        },
        "claude-opus-4-1-20250805-thinking-16k": {
            "rating": 1404.728380337017,
            "rating_q975": 1422.8297124608353,
            "rating_q025": 1386.6270482131986
        },
        "claude-opus-4-1-20250805": {
            "rating": 1402.7429310357677,
            "rating_q975": 1418.2177242776374,
            "rating_q025": 1387.268137793898
        },
        "qwen-max-2025-08-15": {
            "rating": 1402.5436320541273,
            "rating_q975": 1423.9247580541087,
            "rating_q025": 1381.162506054146
        },
        "hunyuan-t1-20250711": {
            "rating": 1399.2894260501828,
            "rating_q975": 1420.5774455286632,
            "rating_q025": 1378.0014065717023
        },
        "qwen3-235b-a22b-thinking-2507": {
            "rating": 1397.3323276273838,
            "rating_q975": 1414.5560915575488,
            "rating_q025": 1380.1085636972186
        },
        "deepseek-v3.1": {
            "rating": 1396.1481022275318,
            "rating_q975": 1417.5386642742928,
            "rating_q025": 1374.7575401807705
        },
        "gpt-4.5-preview-2025-02-27": {
            "rating": 1395.4109873357638,
            "rating_q975": 1406.6445164274,
            "rating_q025": 1384.1774582441278
        },
        "gpt-5-high": {
            "rating": 1394.526345235349,
            "rating_q975": 1409.426290704335,
            "rating_q025": 1379.6263997663632
        },
        "glm-4.5": {
            "rating": 1392.3247538740118,
            "rating_q975": 1407.4661275355284,
            "rating_q025": 1377.183380212495
        },
        "mistral-medium-2508": {
            "rating": 1391.1939850097099,
            "rating_q975": 1409.7683951279246,
            "rating_q025": 1372.6195748914954
        },
        "deepseek-v3.1-thinking": {
            "rating": 1390.2909672185128,
            "rating_q975": 1412.9560540277091,
            "rating_q025": 1367.6258804093166
        },
        "claude-opus-4-20250514-thinking-16k": {
            "rating": 1381.2703259678776,
            "rating_q975": 1392.4834309871426,
            "rating_q025": 1370.057220948613
        },
        "gpt-5-chat": {
            "rating": 1380.5406204004005,
            "rating_q975": 1398.3425993097205,
            "rating_q025": 1362.7386414910807
        },
        "o3-2025-04-16": {
            "rating": 1372.5132632410036,
            "rating_q975": 1381.223897457565,
            "rating_q025": 1363.8026290244422
        },
        "claude-opus-4-20250514": {
            "rating": 1372.4909723328835,
            "rating_q975": 1382.5145397707183,
            "rating_q025": 1362.467404895049
        },
        "qwen3-235b-a22b-instruct-2507": {
            "rating": 1370.6105245944914,
            "rating_q975": 1385.0478605756496,
            "rating_q025": 1356.1731886133332
        },
        "deepseek-v3-0324": {
            "rating": 1369.2586026787183,
            "rating_q975": 1378.2114793841502,
            "rating_q025": 1360.3057259732866
        },
        "glm-4.5-air": {
            "rating": 1365.7412078980312,
            "rating_q975": 1381.7406065505943,
            "rating_q025": 1349.7418092454684
        },
        "gpt-4.1-2025-04-14": {
            "rating": 1363.5049506781934,
            "rating_q975": 1373.0054732934193,
            "rating_q025": 1354.0044280629675
        },
        "hunyuan-turbos-20250416": {
            "rating": 1363.23602419923,
            "rating_q975": 1377.4425396254348,
            "rating_q025": 1349.029508773025
        },
        "mai-1-preview": {
            "rating": 1362.333425171986,
            "rating_q975": 1385.390455791867,
            "rating_q025": 1339.276394552105
        },
        "deepseek-r1": {
            "rating": 1358.356638521394,
            "rating_q975": 1367.9948071067295,
            "rating_q025": 1348.7184699360585
        },
        "qwen3-235b-a22b-no-thinking": {
            "rating": 1357.2742405438457,
            "rating_q975": 1367.2909981732862,
            "rating_q025": 1347.2574829144053
        },
        "o1-2024-12-17": {
            "rating": 1349.472114656762,
            "rating_q975": 1357.8635126174217,
            "rating_q025": 1341.0807166961022
        },
        "mistral-medium-2505": {
            "rating": 1348.463358954669,
            "rating_q975": 1357.6936676050927,
            "rating_q025": 1339.2330503042454
        },
        "gemma-3-27b-it": {
            "rating": 1348.250316983815,
            "rating_q975": 1356.4849571556213,
            "rating_q025": 1340.015676812009
        },
        "claude-sonnet-4-20250514-thinking-32k": {
            "rating": 1346.5447406061944,
            "rating_q975": 1357.9064610234757,
            "rating_q025": 1335.183020188913
        },
        "grok-3-mini-beta": {
            "rating": 1346.0561697881526,
            "rating_q975": 1357.1782088005511,
            "rating_q025": 1334.934130775754
        },
        "qwen2.5-max": {
            "rating": 1345.0769552908694,
            "rating_q975": 1353.01861138279,
            "rating_q025": 1337.1352991989488
        },
        "gemini-2.0-flash-001": {
            "rating": 1343.6657134332138,
            "rating_q975": 1351.0470860237779,
            "rating_q025": 1336.28434084265
        },
        "kimi-k2-0711-preview": {
            "rating": 1340.276222449887,
            "rating_q975": 1352.191016025013,
            "rating_q025": 1328.361428874761
        },
        "qwen3-30b-a3b-instruct-2507": {
            "rating": 1337.3558711510607,
            "rating_q975": 1354.476820138774,
            "rating_q025": 1320.2349221633472
        },
        "gemini-1.5-pro-002": {
            "rating": 1335.954326173521,
            "rating_q975": 1342.4693938544392,
            "rating_q025": 1329.4392584926027
        },
        "claude-sonnet-4-20250514": {
            "rating": 1334.430050765774,
            "rating_q975": 1344.6154617160412,
            "rating_q025": 1324.2446398155068
        },
        "deepseek-v3": {
            "rating": 1334.2905938819954,
            "rating_q975": 1343.6269914070272,
            "rating_q025": 1324.9541963569636
        },
        "gemma-3-12b-it": {
            "rating": 1333.8193805441513,
            "rating_q975": 1355.994960943634,
            "rating_q025": 1311.6438001446688
        },
        "claude-3-7-sonnet-20250219-thinking-32k": {
            "rating": 1333.4759890820226,
            "rating_q975": 1341.9711967888406,
            "rating_q025": 1324.9807813752043
        },
        "grok-3-mini-high": {
            "rating": 1332.1754371339835,
            "rating_q975": 1345.2662853812149,
            "rating_q025": 1319.084588886752
        },
        "step-2-16k-exp-202412": {
            "rating": 1331.1316647738,
            "rating_q975": 1350.7404027135094,
            "rating_q025": 1311.5229268340902
        },
        "qwen3-coder-480b-a35b-instruct": {
            "rating": 1329.9079309793249,
            "rating_q975": 1343.6775758031563,
            "rating_q025": 1316.1382861554935
        },
        "qwen3-235b-a22b": {
            "rating": 1329.3233378038924,
            "rating_q975": 1339.4024126431855,
            "rating_q025": 1319.2442629645996
        },
        "gpt-5-mini-high": {
            "rating": 1326.4286447026534,
            "rating_q975": 1345.6385180961363,
            "rating_q025": 1307.2187713091703
        },
        "gemini-2.0-flash-lite-preview-02-05": {
            "rating": 1323.106436587242,
            "rating_q975": 1331.6588933201483,
            "rating_q025": 1314.5539798543355
        },
        "o1-preview": {
            "rating": 1323.050572311598,
            "rating_q975": 1332.1206996082665,
            "rating_q025": 1313.9804450149297
        },
        "claude-3-7-sonnet-20250219": {
            "rating": 1320.568826785131,
            "rating_q975": 1328.4119598884095,
            "rating_q025": 1312.7256936818526
        },
        "command-a-03-2025": {
            "rating": 1319.6751400533115,
            "rating_q975": 1328.1066065706937,
            "rating_q025": 1311.243673535929
        },
        "llama-3.1-nemotron-ultra-253b-v1": {
            "rating": 1318.9361940959554,
            "rating_q975": 1344.5573911042873,
            "rating_q025": 1293.3149970876239
        },
        "minimax-m1": {
            "rating": 1317.8418534501047,
            "rating_q975": 1328.6689861629277,
            "rating_q025": 1307.0147207372816
        },
        "mistral-small-2506": {
            "rating": 1316.477900571403,
            "rating_q975": 1329.482829891812,
            "rating_q025": 1303.4729712509945
        },
        "step-3": {
            "rating": 1315.5697725564844,
            "rating_q975": 1343.9307772169461,
            "rating_q025": 1287.2087678960224
        },
        "step-1o-turbo-202506": {
            "rating": 1315.3444815176406,
            "rating_q975": 1332.0029995615757,
            "rating_q025": 1298.6859634737054
        },
        "o4-mini-2025-04-16": {
            "rating": 1312.8119804605615,
            "rating_q975": 1322.3839481477428,
            "rating_q025": 1303.24001277338
        },
        "glm-4-plus-0111": {
            "rating": 1312.6288067212959,
            "rating_q975": 1330.4926344441456,
            "rating_q025": 1294.7649789984462
        },
        "nvidia-llama-3.3-nemotron-super-49b-v1.5": {
            "rating": 1308.6414825112215,
            "rating_q975": 1335.1421430246432,
            "rating_q025": 1282.1408219977998
        },
        "qwen3-32b": {
            "rating": 1305.728023822805,
            "rating_q975": 1327.5071945930736,
            "rating_q025": 1283.9488530525364
        },
        "gpt-4.1-mini-2025-04-14": {
            "rating": 1305.1386220007018,
            "rating_q975": 1314.7377776387261,
            "rating_q025": 1295.5394663626773
        },
        "amazon-nova-experimental-chat-05-14": {
            "rating": 1301.7726752783963,
            "rating_q975": 1313.5595387918402,
            "rating_q025": 1289.9858117649526
        },
        "qwq-32b": {
            "rating": 1298.3342319483677,
            "rating_q975": 1307.987801692,
            "rating_q025": 1288.6806622047357
        },
        "gpt-4o-2024-05-13": {
            "rating": 1298.1163681604783,
            "rating_q975": 1304.35615627323,
            "rating_q025": 1291.8765800477265
        },
        "claude-3-5-sonnet-20241022": {
            "rating": 1296.3631580100805,
            "rating_q975": 1302.0271458174939,
            "rating_q025": 1290.6991702026671
        },
        "qwen-plus-0125": {
            "rating": 1295.77610391708,
            "rating_q975": 1313.027520618107,
            "rating_q025": 1278.524687216053
        },
        "llama-3.3-nemotron-49b-super-v1": {
            "rating": 1292.953644558353,
            "rating_q975": 1317.951883952291,
            "rating_q025": 1267.9554051644152
        },
        "o3-mini-high": {
            "rating": 1292.8879985139654,
            "rating_q975": 1302.9250687635576,
            "rating_q025": 1282.8509282643731
        },
        "gemma-3n-e4b-it": {
            "rating": 1292.8081154627848,
            "rating_q975": 1304.6774090781119,
            "rating_q025": 1280.9388218474578
        },
        "gemini-1.5-flash-002": {
            "rating": 1292.4447467669631,
            "rating_q975": 1300.445004423834,
            "rating_q025": 1284.4444891100925
        },
        "gemini-advanced-0514": {
            "rating": 1292.026311497529,
            "rating_q975": 1301.1115904854914,
            "rating_q025": 1282.9410325095666
        },
        "deepseek-v2.5-1210": {
            "rating": 1291.3218319856026,
            "rating_q975": 1307.5851764204663,
            "rating_q025": 1275.0584875507388
        },
        "gpt-oss-120b": {
            "rating": 1290.9254503266575,
            "rating_q975": 1308.6421635861736,
            "rating_q025": 1273.2087370671413
        },
        "grok-2-2024-08-13": {
            "rating": 1290.3099502511266,
            "rating_q975": 1296.8565649365498,
            "rating_q025": 1283.763335565703
        },
        "yi-lightning": {
            "rating": 1287.4486354066944,
            "rating_q975": 1297.0485268218054,
            "rating_q025": 1277.8487439915832
        },
        "qwen3-30b-a3b": {
            "rating": 1281.6808147747988,
            "rating_q975": 1291.8448029115877,
            "rating_q025": 1271.51682663801
        },
        "o3-mini": {
            "rating": 1281.5403534803495,
            "rating_q975": 1288.6576231421107,
            "rating_q025": 1274.4230838185879
        },
        "gpt-4o-2024-08-06": {
            "rating": 1281.0617869902835,
            "rating_q975": 1288.6913961006046,
            "rating_q025": 1273.4321778799622
        },
        "gemini-1.5-pro-001": {
            "rating": 1280.1276635619895,
            "rating_q975": 1287.4266518039483,
            "rating_q025": 1272.8286753200307
        },
        "gemma-3-4b-it": {
            "rating": 1279.2774346853212,
            "rating_q975": 1299.9410136057245,
            "rating_q025": 1258.6138557649178
        },
        "hunyuan-turbos-20250226": {
            "rating": 1278.5387211905977,
            "rating_q975": 1301.5543935804394,
            "rating_q025": 1255.5230488007558
        },
        "hunyuan-turbo-0110": {
            "rating": 1277.705660043879,
            "rating_q975": 1299.974390409114,
            "rating_q025": 1255.4369296786442
        },
        "gpt-4-turbo-2024-04-09": {
            "rating": 1276.6089168206227,
            "rating_q975": 1283.5169162887266,
            "rating_q025": 1269.700917352519
        },
        "llama-3.1-nemotron-70b-instruct": {
            "rating": 1276.1653152758777,
            "rating_q975": 1293.833218807571,
            "rating_q025": 1258.497411744184
        },
        "gpt-4o-mini-2024-07-18": {
            "rating": 1275.982027450549,
            "rating_q975": 1282.037875882195,
            "rating_q025": 1269.9261790189025
        },
        "gpt-5-nano-high": {
            "rating": 1272.2512200078413,
            "rating_q975": 1296.9728622239757,
            "rating_q025": 1247.5295777917067
        },
        "hunyuan-large-2025-02-10": {
            "rating": 1272.220897196226,
            "rating_q975": 1295.045877911785,
            "rating_q025": 1249.3959164806665
        },
        "glm-4-plus": {
            "rating": 1271.0271850309032,
            "rating_q975": 1280.444549348262,
            "rating_q025": 1261.6098207135449
        },
        "hunyuan-large-vision": {
            "rating": 1270.0394887975333,
            "rating_q975": 1292.0546098516634,
            "rating_q025": 1248.0243677434032
        },
        "llama-3.1-405b-instruct-fp8": {
            "rating": 1269.877471795929,
            "rating_q975": 1276.6971727897885,
            "rating_q025": 1263.0577708020696
        },
        "llama-4-maverick-17b-128e-instruct": {
            "rating": 1268.996092550335,
            "rating_q975": 1278.502473871889,
            "rating_q025": 1259.4897112287817
        },
        "llama-3.1-405b-instruct-bf16": {
            "rating": 1267.4509651737458,
            "rating_q975": 1274.297902735169,
            "rating_q025": 1260.6040276123229
        },
        "gpt-4.1-nano-2025-04-14": {
            "rating": 1266.7201958553092,
            "rating_q975": 1284.4422027813227,
            "rating_q025": 1248.9981889292956
        },
        "qwen2.5-plus-1127": {
            "rating": 1266.5989701764038,
            "rating_q975": 1280.079988651697,
            "rating_q025": 1253.1179517011105
        },
        "mistral-small-3.1-24b-instruct-2503": {
            "rating": 1263.9117110570885,
            "rating_q975": 1275.531444196327,
            "rating_q025": 1252.29197791785
        },
        "llama-3.3-70b-instruct": {
            "rating": 1259.3644655351115,
            "rating_q975": 1265.8716515391984,
            "rating_q025": 1252.8572795310247
        },
        "qwen-max-0919": {
            "rating": 1256.8490510789406,
            "rating_q975": 1267.998754451765,
            "rating_q025": 1245.6993477061162
        },
        "magistral-medium-2506": {
            "rating": 1255.3612529812522,
            "rating_q975": 1272.153621282245,
            "rating_q025": 1238.5688846802593
        },
        "gpt-4-1106-preview": {
            "rating": 1253.7274512155197,
            "rating_q975": 1260.8263451582077,
            "rating_q025": 1246.6285572728318
        },
        "llama-4-scout-17b-16e-instruct": {
            "rating": 1253.445700478361,
            "rating_q975": 1265.0316121469828,
            "rating_q025": 1241.8597888097393
        },
        "mistral-large-2407": {
            "rating": 1252.4949293143914,
            "rating_q975": 1260.1976314225192,
            "rating_q025": 1244.7922272062633
        },
        "o1-mini": {
            "rating": 1252.4100946985209,
            "rating_q975": 1259.196692686127,
            "rating_q025": 1245.6234967109149
        },
        "grok-2-mini-2024-08-13": {
            "rating": 1250.8280082781898,
            "rating_q975": 1257.6471390895035,
            "rating_q025": 1244.0088774668761
        },
        "mistral-large-2411": {
            "rating": 1250.3505505891346,
            "rating_q975": 1258.6299860384127,
            "rating_q025": 1242.0711151398566
        },
        "gemma-2-27b-it": {
            "rating": 1249.9933872678816,
            "rating_q975": 1255.9372054129083,
            "rating_q025": 1244.0495691228552
        },
        "gemma-2-9b-it-simpo": {
            "rating": 1249.863460768135,
            "rating_q975": 1263.4864604331942,
            "rating_q025": 1236.2404611030756
        },
        "hunyuan-standard-2025-02-10": {
            "rating": 1248.4970171488235,
            "rating_q975": 1271.3096485710778,
            "rating_q025": 1225.6843857265692
        },
        "athene-70b-0725": {
            "rating": 1248.0462121757323,
            "rating_q975": 1258.6180221069624,
            "rating_q025": 1237.4744022445022
        },
        "deepseek-v2.5": {
            "rating": 1245.967050765003,
            "rating_q975": 1255.5453466766492,
            "rating_q025": 1236.388754853357
        },
        "claude-3-5-sonnet-20240620": {
            "rating": 1245.952747829273,
            "rating_q975": 1252.689816854903,
            "rating_q025": 1239.215678803643
        },
        "reka-core-20240904": {
            "rating": 1244.98619829798,
            "rating_q975": 1261.68234336645,
            "rating_q025": 1228.2900532295105
        },
        "claude-3-opus-20240229": {
            "rating": 1244.6704595036022,
            "rating_q975": 1250.2454919951713,
            "rating_q025": 1239.0954270120328
        },
        "athene-v2-chat": {
            "rating": 1243.4823439178558,
            "rating_q975": 1252.4651629497914,
            "rating_q025": 1234.49952488592
        },
        "llama-3.1-70b-instruct": {
            "rating": 1242.416369051245,
            "rating_q975": 1249.346815229446,
            "rating_q025": 1235.485922873044
        },
        "command-r-plus-08-2024": {
            "rating": 1242.377928006349,
            "rating_q975": 1256.3730325593472,
            "rating_q025": 1228.382823453351
        },
        "gpt-4-0125-preview": {
            "rating": 1242.1947994113134,
            "rating_q975": 1249.5342620873312,
            "rating_q025": 1234.8553367352959
        },
        "llama-3.1-tulu-3-70b": {
            "rating": 1241.909955356884,
            "rating_q975": 1265.5854941791074,
            "rating_q025": 1218.2344165346608
        },
        "claude-3-5-haiku-20241022": {
            "rating": 1237.7376918226466,
            "rating_q975": 1244.1573241611597,
            "rating_q025": 1231.3180594841338
        },
        "gemini-1.5-flash-001": {
            "rating": 1232.4289569191815,
            "rating_q975": 1239.9993697828695,
            "rating_q025": 1224.8585440554937
        },
        "qwen2.5-72b-instruct": {
            "rating": 1232.1015637493356,
            "rating_q975": 1239.7057982053084,
            "rating_q025": 1224.4973292933626
        },
        "gpt-oss-20b": {
            "rating": 1228.5330293569073,
            "rating_q975": 1247.819178365591,
            "rating_q025": 1209.2468803482234
        },
        "gemini-1.5-flash-8b-001": {
            "rating": 1228.479494222293,
            "rating_q975": 1236.4912821767355,
            "rating_q025": 1220.4677062678506
        },
        "amazon-nova-pro-v1.0": {
            "rating": 1222.7059258232775,
            "rating_q975": 1231.420299636074,
            "rating_q025": 1213.991552010481
        },
        "jamba-1.5-large": {
            "rating": 1222.4326922956693,
            "rating_q975": 1237.3034170001206,
            "rating_q025": 1207.5619675912183
        },
        "llama-3.1-nemotron-51b-instruct": {
            "rating": 1220.0720400533714,
            "rating_q975": 1244.868197541664,
            "rating_q025": 1195.2758825650792
        },
        "llama-3-70b-instruct": {
            "rating": 1219.9369123898277,
            "rating_q975": 1226.6963699819942,
            "rating_q025": 1213.177454797661
        },
        "gemma-2-9b-it": {
            "rating": 1216.618253036219,
            "rating_q975": 1223.235416244555,
            "rating_q025": 1210.0010898278824
        },
        "nemotron-4-340b-instruct": {
            "rating": 1213.2948518658768,
            "rating_q975": 1224.0857472608097,
            "rating_q025": 1202.503956470944
        },
        "reka-flash-20240904": {
            "rating": 1212.770593114577,
            "rating_q975": 1229.2056664208733,
            "rating_q025": 1196.3355198082807
        },
        "command-r-plus": {
            "rating": 1211.4052453721479,
            "rating_q975": 1219.2111066772268,
            "rating_q025": 1203.5993840670692
        },
        "c4ai-aya-expanse-32b": {
            "rating": 1210.934087131845,
            "rating_q975": 1219.9581039683535,
            "rating_q025": 1201.9100702953363
        },
        "glm-4-0520": {
            "rating": 1210.223537456352,
            "rating_q975": 1224.3941273865732,
            "rating_q025": 1196.0529475261312
        },
        "amazon-nova-lite-v1.0": {
            "rating": 1209.6927553217092,
            "rating_q975": 1219.3110312747306,
            "rating_q025": 1200.074479368688
        },
        "mistral-small-24b-instruct-2501": {
            "rating": 1207.758507054092,
            "rating_q975": 1219.1309025290582,
            "rating_q025": 1196.3861115791258
        },
        "olmo-2-0325-32b-instruct": {
            "rating": 1207.5147609582418,
            "rating_q975": 1231.4874038523617,
            "rating_q025": 1183.5421180641222
        },
        "gpt-4-0613": {
            "rating": 1202.4448243645693,
            "rating_q975": 1210.0100837797402,
            "rating_q025": 1194.8795649493982
        },
        "gpt-4-0314": {
            "rating": 1200.980073041651,
            "rating_q975": 1210.253528307455,
            "rating_q025": 1191.7066177758466
        },
        "claude-3-sonnet-20240229": {
            "rating": 1197.4640714409688,
            "rating_q975": 1204.942309080044,
            "rating_q025": 1189.985833801894
        },
        "phi-4": {
            "rating": 1195.6793813799557,
            "rating_q975": 1204.5591958659581,
            "rating_q025": 1186.7995668939532
        },
        "qwen2-72b-instruct": {
            "rating": 1192.384499770552,
            "rating_q975": 1201.082605497613,
            "rating_q025": 1183.6863940434912
        },
        "llama-3.1-tulu-3-8b": {
            "rating": 1189.0803643799495,
            "rating_q975": 1213.216451384061,
            "rating_q025": 1164.944277375838
        },
        "amazon-nova-micro-v1.0": {
            "rating": 1186.2914598888192,
            "rating_q975": 1196.1490097502458,
            "rating_q025": 1176.4339100273924
        },
        "ministral-8b-2410": {
            "rating": 1185.4940778710597,
            "rating_q975": 1205.7539962071278,
            "rating_q025": 1165.2341595349915
        },
        "c4ai-aya-expanse-8b": {
            "rating": 1185.1906685436406,
            "rating_q975": 1199.0660337547192,
            "rating_q025": 1171.315303332562
        },
        "command-r-08-2024": {
            "rating": 1184.9829661444423,
            "rating_q975": 1199.1862463571538,
            "rating_q025": 1170.779685931731
        },
        "hunyuan-standard-256k": {
            "rating": 1183.873001513304,
            "rating_q975": 1210.505762642994,
            "rating_q025": 1157.240240383614
        },
        "qwen2.5-coder-32b-instruct": {
            "rating": 1183.3129140260853,
            "rating_q975": 1201.8437186017122,
            "rating_q025": 1164.7821094504586
        },
        "jamba-1.5-mini": {
            "rating": 1176.4017951960313,
            "rating_q975": 1191.0162631827495,
            "rating_q025": 1161.7873272093134
        },
        "mistral-large-2402": {
            "rating": 1171.7190322840004,
            "rating_q975": 1180.3830861256083,
            "rating_q025": 1163.0549784423924
        },
        "mistral-medium": {
            "rating": 1170.8335378829192,
            "rating_q975": 1181.05695681032,
            "rating_q025": 1160.6101189555188
        },
        "claude-3-haiku-20240307": {
            "rating": 1170.012170328325,
            "rating_q975": 1176.7350047929529,
            "rating_q025": 1163.2893358636973
        },
        "llama-3.1-8b-instruct": {
            "rating": 1168.0588808910938,
            "rating_q975": 1175.4899886189544,
            "rating_q025": 1160.6277731632329
        },
        "command-r": {
            "rating": 1166.277961245393,
            "rating_q975": 1175.2527790200284,
            "rating_q025": 1157.303143470758
        },
        "wizardlm-70b": {
            "rating": 1162.332976551648,
            "rating_q975": 1178.8337510632455,
            "rating_q025": 1145.8322020400506
        },
        "llama-3-8b-instruct": {
            "rating": 1162.0079906347542,
            "rating_q975": 1169.3252500006747,
            "rating_q025": 1154.6907312688338
        },
        "gemma-2-2b-it": {
            "rating": 1161.3274209464562,
            "rating_q975": 1168.6326241480722,
            "rating_q025": 1154.0222177448404
        },
        "qwen1.5-110b-chat": {
            "rating": 1160.7264003990972,
            "rating_q975": 1171.5933239294375,
            "rating_q025": 1149.859476868757
        },
        "mixtral-8x22b-instruct-v0.1": {
            "rating": 1154.301999996013,
            "rating_q975": 1162.7830515149362,
            "rating_q025": 1145.82094847709
        },
        "qwq-32b-preview": {
            "rating": 1150.3603009273804,
            "rating_q975": 1177.4616879408322,
            "rating_q025": 1123.2589139139286
        },
        "qwen1.5-72b-chat": {
            "rating": 1148.7364419424368,
            "rating_q975": 1158.1581523022628,
            "rating_q025": 1139.3147315826109
        },
        "yi-1.5-34b-chat": {
            "rating": 1147.914994463172,
            "rating_q975": 1158.2665927415983,
            "rating_q025": 1137.5633961847457
        },
        "granite-3.1-8b-instruct": {
            "rating": 1146.1271116067555,
            "rating_q975": 1171.115906061711,
            "rating_q025": 1121.1383171517996
        },
        "reka-flash-21b-20240226-online": {
            "rating": 1144.5963707668252,
            "rating_q975": 1158.2620294399178,
            "rating_q025": 1130.9307120937324
        },
        "gemini-pro-dev-api": {
            "rating": 1142.9631770295568,
            "rating_q975": 1156.2743875708031,
            "rating_q025": 1129.651966488311
        },
        "openchat-3.5": {
            "rating": 1139.1436819150765,
            "rating_q975": 1156.8829837316355,
            "rating_q025": 1121.4043800985175
        },
        "vicuna-33b": {
            "rating": 1138.8008589664216,
            "rating_q975": 1150.238505275591,
            "rating_q025": 1127.3632126572522
        },
        "internlm2_5-20b-chat": {
            "rating": 1138.6105695045326,
            "rating_q975": 1153.4266733520678,
            "rating_q025": 1123.794465656997
        },
        "reka-flash-21b-20240226": {
            "rating": 1137.5294495168237,
            "rating_q975": 1149.019765521206,
            "rating_q025": 1126.0391335124411
        },
        "deepseek-coder-v2": {
            "rating": 1136.6925703891548,
            "rating_q975": 1149.127417797438,
            "rating_q025": 1124.2577229808712
        },
        "granite-3.1-2b-instruct": {
            "rating": 1132.3737208376024,
            "rating_q975": 1159.3274428035174,
            "rating_q025": 1105.4199988716873
        },
        "zephyr-orpo-141b-A35b-v0.1": {
            "rating": 1126.5471925878433,
            "rating_q975": 1148.571986890653,
            "rating_q025": 1104.5223982850334
        },
        "mixtral-8x7b-instruct-v0.1": {
            "rating": 1122.4449597624598,
            "rating_q975": 1130.3173133515145,
            "rating_q025": 1114.572606173405
        },
        "yi-34b-chat": {
            "rating": 1120.964809758656,
            "rating_q975": 1134.095740020927,
            "rating_q025": 1107.833879496385
        },
        "phi-3-medium-4k-instruct": {
            "rating": 1119.9187061387483,
            "rating_q975": 1129.9204866896612,
            "rating_q025": 1109.9169255878355
        },
        "dbrx-instruct-preview": {
            "rating": 1117.4560936264813,
            "rating_q975": 1128.3111282277732,
            "rating_q025": 1106.6010590251894
        },
        "tulu-2-dpo-70b": {
            "rating": 1117.345341347195,
            "rating_q975": 1136.332050054271,
            "rating_q025": 1098.3586326401191
        },
        "gemini-pro": {
            "rating": 1116.2917754659761,
            "rating_q975": 1136.8943080136935,
            "rating_q025": 1095.6892429182585
        },
        "zephyr-7b-beta": {
            "rating": 1114.6141648661155,
            "rating_q975": 1130.2143158629922,
            "rating_q025": 1099.0140138692386
        },
        "nous-hermes-2-mixtral-8x7b-dpo": {
            "rating": 1114.0573543960263,
            "rating_q975": 1137.1386502910686,
            "rating_q025": 1090.976058500984
        },
        "starling-lm-7b-alpha": {
            "rating": 1110.9562770168238,
            "rating_q975": 1125.9474144934557,
            "rating_q025": 1095.965139540192
        },
        "openhermes-2.5-mistral-7b": {
            "rating": 1110.2472440384936,
            "rating_q975": 1131.7064944445663,
            "rating_q025": 1088.7879936324207
        },
        "starling-lm-7b-beta": {
            "rating": 1108.7269443899777,
            "rating_q975": 1122.5332091665887,
            "rating_q025": 1094.9206796133665
        },
        "gpt-3.5-turbo-0125": {
            "rating": 1106.6069813397094,
            "rating_q975": 1114.7300437092752,
            "rating_q025": 1098.4839189701438
        },
        "llama-3.2-3b-instruct": {
            "rating": 1106.4524989704803,
            "rating_q975": 1124.2973116830394,
            "rating_q025": 1088.6076862579214
        },
        "openchat-3.5-0106": {
            "rating": 1105.32929915573,
            "rating_q975": 1119.6996955405994,
            "rating_q025": 1090.958902770861
        },
        "llama2-70b-steerlm-chat": {
            "rating": 1104.6207416923417,
            "rating_q975": 1128.9848909118257,
            "rating_q025": 1080.2565924728574
        },
        "qwen1.5-14b-chat": {
            "rating": 1104.6047911292553,
            "rating_q975": 1118.0091317034887,
            "rating_q025": 1091.200450555022
        },
        "falcon-180b-chat": {
            "rating": 1103.6795740459484,
            "rating_q975": 1140.5815433709608,
            "rating_q025": 1066.777604720936
        },
        "wizardlm-13b": {
            "rating": 1103.154391667951,
            "rating_q975": 1120.8166889539025,
            "rating_q025": 1085.4920943819993
        },
        "solar-10.7b-instruct-v1.0": {
            "rating": 1103.0781472416681,
            "rating_q975": 1126.9923015678391,
            "rating_q025": 1079.1639929154971
        },
        "dolphin-2.2.1-mistral-7b": {
            "rating": 1099.003054118364,
            "rating_q975": 1132.4794884420503,
            "rating_q025": 1065.5266197946776
        },
        "qwen1.5-32b-chat": {
            "rating": 1098.4728029061794,
            "rating_q975": 1110.0288364595945,
            "rating_q025": 1086.9167693527645
        },
        "phi-3-small-8k-instruct": {
            "rating": 1098.347950146255,
            "rating_q975": 1110.5237700312093,
            "rating_q025": 1086.1721302613007
        },
        "snowflake-arctic-instruct": {
            "rating": 1095.5923459782111,
            "rating_q975": 1106.9361697660001,
            "rating_q025": 1084.2485221904221
        },
        "guanaco-33b": {
            "rating": 1090.9734241695166,
            "rating_q975": 1118.4821411422565,
            "rating_q025": 1063.464707196777
        },
        "llama-2-70b-chat": {
            "rating": 1089.5830006568317,
            "rating_q975": 1099.0957938829097,
            "rating_q025": 1080.070207430754
        },
        "mpt-30b-chat": {
            "rating": 1087.9677230750099,
            "rating_q975": 1116.8679954236245,
            "rating_q025": 1059.0674507263952
        },
        "granite-3.0-8b-instruct": {
            "rating": 1087.5650930939591,
            "rating_q975": 1107.038915724907,
            "rating_q025": 1068.0912704630116
        },
        "zephyr-7b-alpha": {
            "rating": 1083.7692834863633,
            "rating_q975": 1114.0395568605595,
            "rating_q025": 1053.499010112167
        },
        "mistral-7b-instruct-v0.2": {
            "rating": 1082.3441386458544,
            "rating_q975": 1094.3218012866114,
            "rating_q025": 1070.3664760050972
        },
        "deepseek-llm-67b-chat": {
            "rating": 1078.1096932834064,
            "rating_q975": 1099.9560151362596,
            "rating_q025": 1056.2633714305534
        },
        "gemma-1.1-7b-it": {
            "rating": 1075.0582549558535,
            "rating_q975": 1085.9811544374197,
            "rating_q025": 1064.1353554742873
        },
        "vicuna-13b": {
            "rating": 1070.6698625255372,
            "rating_q975": 1082.8538866997847,
            "rating_q025": 1058.4858383512897
        },
        "granite-3.0-2b-instruct": {
            "rating": 1064.4964892235728,
            "rating_q975": 1084.4471348439968,
            "rating_q025": 1044.5458436031488
        },
        "llama-2-13b-chat": {
            "rating": 1062.1787215354357,
            "rating_q975": 1074.1441642035327,
            "rating_q025": 1050.2132788673387
        },
        "phi-3-mini-4k-instruct-june-2024": {
            "rating": 1061.7486777979157,
            "rating_q975": 1075.2315941135494,
            "rating_q025": 1048.265761482282
        },
        "smollm2-1.7b-instruct": {
            "rating": 1055.8649135076212,
            "rating_q975": 1088.3258573354885,
            "rating_q025": 1023.4039696797536
        },
        "llama-3.2-1b-instruct": {
            "rating": 1052.3831237432987,
            "rating_q975": 1070.8753107008347,
            "rating_q025": 1033.890936785763
        },
        "phi-3-mini-4k-instruct": {
            "rating": 1049.9663681851625,
            "rating_q975": 1061.9282394947104,
            "rating_q025": 1038.0044968756147
        },
        "llama-2-7b-chat": {
            "rating": 1048.7328948233298,
            "rating_q975": 1061.8115129781272,
            "rating_q025": 1035.6542766685325
        },
        "gpt-3.5-turbo-1106": {
            "rating": 1048.5630271569353,
            "rating_q975": 1063.5131713677104,
            "rating_q025": 1033.6128829461604
        },
        "qwen1.5-7b-chat": {
            "rating": 1048.0497355917505,
            "rating_q975": 1069.702668945929,
            "rating_q025": 1026.3968022375718
        },
        "codellama-34b-instruct": {
            "rating": 1045.5749654527879,
            "rating_q975": 1061.8556178435315,
            "rating_q025": 1029.2943130620445
        },
        "mistral-7b-instruct": {
            "rating": 1045.421597973391,
            "rating_q975": 1061.9476233244736,
            "rating_q025": 1028.8955726223085
        },
        "stripedhyena-nous-7b": {
            "rating": 1043.7162002127557,
            "rating_q975": 1064.1719057914293,
            "rating_q025": 1023.2604946340823
        },
        "phi-3-mini-128k-instruct": {
            "rating": 1043.383257809198,
            "rating_q975": 1056.4860205452321,
            "rating_q025": 1030.280495073164
        },
        "qwen-14b-chat": {
            "rating": 1040.635566336861,
            "rating_q975": 1061.069662830566,
            "rating_q025": 1020.2014698431562
        },
        "gemma-7b-it": {
            "rating": 1037.5933797703672,
            "rating_q975": 1054.8274092082816,
            "rating_q025": 1020.3593503324529
        },
        "vicuna-7b": {
            "rating": 1034.8442318890866,
            "rating_q975": 1052.5705309841064,
            "rating_q025": 1017.1179327940671
        },
        "gemma-1.1-2b-it": {
            "rating": 1015.182222884354,
            "rating_q975": 1031.2221839999966,
            "rating_q025": 999.1422617687117
        },
        "palm-2": {
            "rating": 1004.87699078794,
            "rating_q975": 1021.9634204526911,
            "rating_q025": 987.7905611231889
        },
        "olmo-7b-instruct": {
            "rating": 1002.8035176868948,
            "rating_q975": 1022.7307644557327,
            "rating_q025": 982.8762709180568
        },
        "gemma-2b-it": {
            "rating": 1001.5630988854718,
            "rating_q975": 1024.4342145559751,
            "rating_q025": 978.6919832149683
        },
        "koala-13b": {
            "rating": 984.9718197135853,
            "rating_q975": 1005.4185544007593,
            "rating_q025": 964.5250850264115
        },
        "qwen1.5-4b-chat": {
            "rating": 983.4272173838546,
            "rating_q975": 1001.6423968335185,
            "rating_q025": 965.2120379341904
        },
        "gpt4all-13b-snoozy": {
            "rating": 983.2224323925427,
            "rating_q975": 1020.9959619058516,
            "rating_q025": 945.4489028792339
        },
        "chatglm3-6b": {
            "rating": 982.6705238129052,
            "rating_q975": 1005.4627961298316,
            "rating_q025": 959.8782514959787
        },
        "alpaca-13b": {
            "rating": 981.0203368581299,
            "rating_q975": 1003.1765660500691,
            "rating_q025": 958.8641076661906
        },
        "mpt-7b-chat": {
            "rating": 968.8673352726547,
            "rating_q975": 992.6862855762438,
            "rating_q025": 945.0483849690656
        },
        "chatglm2-6b": {
            "rating": 958.222462927634,
            "rating_q975": 984.2756615294519,
            "rating_q025": 932.169264325816
        },
        "RWKV-4-Raven-14B": {
            "rating": 946.641032574197,
            "rating_q975": 968.9422878237676,
            "rating_q025": 924.3397773246262
        },
        "oasst-pythia-12b": {
            "rating": 934.8064080837439,
            "rating_q975": 954.8428602663058,
            "rating_q025": 914.769955901182
        },
        "fastchat-t5-3b": {
            "rating": 913.3255624785689,
            "rating_q975": 936.7875000572891,
            "rating_q025": 889.8636248998487
        },
        "chatglm-6b": {
            "rating": 912.9854183516621,
            "rating_q975": 937.1321396758676,
            "rating_q025": 888.8386970274566
        },
        "stablelm-tuned-alpha-7b": {
            "rating": 880.3572136252632,
            "rating_q975": 908.2066630349418,
            "rating_q025": 852.5077642155846
        },
        "dolly-v2-12b": {
            "rating": 875.6929692394168,
            "rating_q975": 903.0468717864683,
            "rating_q025": 848.3390666923652
        },
        "llama-13b": {
            "rating": 807.77149261254,
            "rating_q975": 840.4247741586385,
            "rating_q025": 775.1182110664415
        }
    },
    "english": {
        "gemini-2.5-pro": {
            "rating": 1463.1229864011261,
            "rating_q975": 1469.0834388177595,
            "rating_q025": 1457.1625339844925
        },
        "mistral-medium-2508": {
            "rating": 1444.586982830281,
            "rating_q975": 1454.5902911872859,
            "rating_q025": 1434.5836744732762
        },
        "grok-4-0709": {
            "rating": 1436.9533079657583,
            "rating_q975": 1443.8671842611311,
            "rating_q025": 1430.0394316703855
        },
        "glm-4.5": {
            "rating": 1434.9570375734484,
            "rating_q975": 1443.2054266857695,
            "rating_q025": 1426.7086484611275
        },
        "grok-3-preview-02-24": {
            "rating": 1433.6446957766582,
            "rating_q975": 1438.7007745192545,
            "rating_q025": 1428.5886170340616
        },
        "claude-opus-4-1-20250805-thinking-16k": {
            "rating": 1432.791102807754,
            "rating_q975": 1442.2076083209763,
            "rating_q025": 1423.3745972945317
        },
        "deepseek-r1-0528": {
            "rating": 1432.004591568621,
            "rating_q975": 1438.8449200425423,
            "rating_q025": 1425.1642630946997
        },
        "deepseek-v3.1": {
            "rating": 1429.597787063335,
            "rating_q975": 1441.7098973904544,
            "rating_q025": 1417.4856767362155
        },
        "chatgpt-4o-latest-20250326": {
            "rating": 1429.2954899241636,
            "rating_q975": 1434.6908484287128,
            "rating_q025": 1423.9001314196144
        },
        "gpt-5-high": {
            "rating": 1427.9271115785323,
            "rating_q975": 1436.1710008521513,
            "rating_q025": 1419.683222304913
        },
        "qwen3-235b-a22b-thinking-2507": {
            "rating": 1427.270788407929,
            "rating_q975": 1436.3565549345858,
            "rating_q025": 1418.1850218812726
        },
        "qwen-max-2025-08-15": {
            "rating": 1426.830092908084,
            "rating_q975": 1438.1440131121735,
            "rating_q025": 1415.5161727039942
        },
        "o3-2025-04-16": {
            "rating": 1422.602275988363,
            "rating_q975": 1428.0589805746529,
            "rating_q025": 1417.145571402073
        },
        "deepseek-v3.1-thinking": {
            "rating": 1421.0847477739576,
            "rating_q975": 1433.9064722583248,
            "rating_q025": 1408.2630232895904
        },
        "claude-opus-4-1-20250805": {
            "rating": 1419.3049510149622,
            "rating_q975": 1427.5341745971277,
            "rating_q025": 1411.0757274327966
        },
        "qwen3-235b-a22b-instruct-2507": {
            "rating": 1417.039976667886,
            "rating_q975": 1424.7456979017304,
            "rating_q025": 1409.3342554340418
        },
        "gpt-4.5-preview-2025-02-27": {
            "rating": 1416.2027587873752,
            "rating_q975": 1422.9780307312976,
            "rating_q025": 1409.4274868434527
        },
        "gpt-5-chat": {
            "rating": 1411.3314803051023,
            "rating_q975": 1420.5236192333996,
            "rating_q025": 1402.1393413768053
        },
        "gemini-2.5-flash": {
            "rating": 1408.8577443843392,
            "rating_q975": 1414.5493571303116,
            "rating_q025": 1403.1661316383668
        },
        "mai-1-preview": {
            "rating": 1406.4218777981264,
            "rating_q975": 1418.8014602988799,
            "rating_q025": 1394.0422952973727
        },
        "glm-4.5-air": {
            "rating": 1398.7693230456944,
            "rating_q975": 1407.2629851548334,
            "rating_q025": 1390.2756609365554
        },
        "qwen-vl-max-2025-08-13": {
            "rating": 1397.1543861159726,
            "rating_q975": 1418.7961892411492,
            "rating_q025": 1375.5125829907956
        },
        "hunyuan-t1-20250711": {
            "rating": 1396.3842158433276,
            "rating_q975": 1407.342453211496,
            "rating_q025": 1385.4259784751596
        },
        "qwen3-235b-a22b-no-thinking": {
            "rating": 1391.3569094054174,
            "rating_q975": 1397.4330979569136,
            "rating_q025": 1385.2807208539211
        },
        "gpt-4.1-2025-04-14": {
            "rating": 1388.5774043017502,
            "rating_q975": 1394.3505348897138,
            "rating_q025": 1382.8042737137864
        },
        "deepseek-v3-0324": {
            "rating": 1387.3190161614266,
            "rating_q975": 1392.7631328063255,
            "rating_q025": 1381.8748995165274
        },
        "hunyuan-turbos-20250416": {
            "rating": 1384.6373199209054,
            "rating_q975": 1392.443022063155,
            "rating_q025": 1376.8316177786558
        },
        "qwen3-30b-a3b-instruct-2507": {
            "rating": 1384.257676100749,
            "rating_q975": 1393.2566609698692,
            "rating_q025": 1375.2586912316285
        },
        "gpt-5-mini-high": {
            "rating": 1384.2006547018714,
            "rating_q975": 1394.1570022466342,
            "rating_q025": 1374.2443071571086
        },
        "gpt-5-old": {
            "rating": 1383.9367290985467,
            "rating_q975": 1412.6287022289628,
            "rating_q025": 1355.2447559681307
        },
        "claude-opus-4-20250514-thinking-16k": {
            "rating": 1383.765847224718,
            "rating_q975": 1390.2746200711606,
            "rating_q025": 1377.2570743782755
        },
        "deepseek-r1": {
            "rating": 1383.7529451484415,
            "rating_q975": 1389.5756687846233,
            "rating_q025": 1377.93022151226
        },
        "o1-preview": {
            "rating": 1382.328644637047,
            "rating_q975": 1388.203089785871,
            "rating_q025": 1376.4541994882231
        },
        "kimi-k2-0711-preview": {
            "rating": 1382.1806986197776,
            "rating_q975": 1388.9525233773384,
            "rating_q025": 1375.408873862217
        },
        "step-3": {
            "rating": 1382.1084769373172,
            "rating_q975": 1396.3672515035146,
            "rating_q025": 1367.84970237112
        },
        "mistral-medium-2505": {
            "rating": 1381.2175915218747,
            "rating_q975": 1387.0551131357645,
            "rating_q025": 1375.3800699079848
        },
        "qwen3-235b-a22b": {
            "rating": 1376.8634787147769,
            "rating_q975": 1382.854925625358,
            "rating_q025": 1370.8720318041956
        },
        "grok-3-mini-high": {
            "rating": 1375.2869370784301,
            "rating_q975": 1382.4130497545136,
            "rating_q025": 1368.1608244023466
        },
        "qwen2.5-max": {
            "rating": 1374.8297071581173,
            "rating_q975": 1379.6121838730428,
            "rating_q025": 1370.0472304431921
        },
        "gpt-oss-120b": {
            "rating": 1373.9877952826555,
            "rating_q975": 1383.258811189047,
            "rating_q025": 1364.7167793762637
        },
        "minimax-m1": {
            "rating": 1373.9051383386702,
            "rating_q975": 1380.2455121003104,
            "rating_q025": 1367.5647645770302
        },
        "claude-opus-4-20250514": {
            "rating": 1372.4139470868438,
            "rating_q975": 1378.5593948122346,
            "rating_q025": 1366.268499361453
        },
        "o4-mini-2025-04-16": {
            "rating": 1371.80748115434,
            "rating_q975": 1377.610277870916,
            "rating_q025": 1366.0046844377641
        },
        "gemma-3-27b-it": {
            "rating": 1371.29402269622,
            "rating_q975": 1376.3073312037338,
            "rating_q025": 1366.2807141887063
        },
        "o1-2024-12-17": {
            "rating": 1371.1719120415673,
            "rating_q975": 1376.388676197994,
            "rating_q025": 1365.9551478851408
        },
        "grok-3-mini-beta": {
            "rating": 1370.774550772757,
            "rating_q975": 1377.210821900746,
            "rating_q025": 1364.3382796447684
        },
        "gemini-2.0-flash-001": {
            "rating": 1367.2375493553234,
            "rating_q975": 1371.773658990042,
            "rating_q025": 1362.7014397206049
        },
        "qwen3-coder-480b-a35b-instruct": {
            "rating": 1363.229296444871,
            "rating_q975": 1370.8792828994815,
            "rating_q025": 1355.5793099902605
        },
        "claude-sonnet-4-20250514-thinking-32k": {
            "rating": 1362.976171907566,
            "rating_q975": 1369.5086866487743,
            "rating_q025": 1356.4436571663573
        },
        "qwen3-32b": {
            "rating": 1359.760167565839,
            "rating_q975": 1371.9229716649284,
            "rating_q025": 1347.5973634667498
        },
        "mistral-small-2506": {
            "rating": 1357.9214838490752,
            "rating_q975": 1365.086748736298,
            "rating_q025": 1350.7562189618527
        },
        "nvidia-llama-3.3-nemotron-super-49b-v1.5": {
            "rating": 1357.9147621982493,
            "rating_q975": 1371.16548046368,
            "rating_q025": 1344.6640439328187
        },
        "glm-4.5v": {
            "rating": 1356.3178473949863,
            "rating_q975": 1379.6341874274879,
            "rating_q025": 1333.0015073624847
        },
        "gpt-4.1-mini-2025-04-14": {
            "rating": 1354.9513286698195,
            "rating_q975": 1360.7463322639094,
            "rating_q025": 1349.1563250757297
        },
        "step-1o-turbo-202506": {
            "rating": 1354.4016389469975,
            "rating_q975": 1362.9243336310356,
            "rating_q025": 1345.8789442629595
        },
        "llama-3.3-nemotron-49b-super-v1": {
            "rating": 1352.1940651920459,
            "rating_q975": 1367.0208067719802,
            "rating_q025": 1337.3673236121117
        },
        "o3-mini-high": {
            "rating": 1351.1102379793915,
            "rating_q975": 1357.3184924983243,
            "rating_q025": 1344.901983460459
        },
        "qwq-32b": {
            "rating": 1349.5197759551497,
            "rating_q975": 1355.1857502072107,
            "rating_q025": 1343.8538017030887
        },
        "gemma-3-12b-it": {
            "rating": 1348.195707269842,
            "rating_q975": 1359.7791966041632,
            "rating_q025": 1336.6122179355207
        },
        "deepseek-v3": {
            "rating": 1346.7427134428108,
            "rating_q975": 1352.3169897571047,
            "rating_q025": 1341.1684371285169
        },
        "llama-3.1-nemotron-ultra-253b-v1": {
            "rating": 1344.3277357063625,
            "rating_q975": 1358.8255705928138,
            "rating_q025": 1329.829900819911
        },
        "claude-sonnet-4-20250514": {
            "rating": 1343.7017296491356,
            "rating_q975": 1349.9586856539815,
            "rating_q025": 1337.4447736442894
        },
        "step-2-16k-exp-202412": {
            "rating": 1343.4004571562125,
            "rating_q975": 1353.666412995942,
            "rating_q025": 1333.1345013164828
        },
        "o1-mini": {
            "rating": 1340.9002852991673,
            "rating_q975": 1345.2214489007495,
            "rating_q025": 1336.5791216975852
        },
        "glm-4-plus-0111": {
            "rating": 1340.2234913539726,
            "rating_q975": 1350.174849308681,
            "rating_q025": 1330.2721333992642
        },
        "command-a-03-2025": {
            "rating": 1339.3397807828126,
            "rating_q975": 1344.4496680830057,
            "rating_q025": 1334.2298934826192
        },
        "qwen-plus-0125": {
            "rating": 1338.0516783574237,
            "rating_q975": 1348.2152888092055,
            "rating_q025": 1327.8880679056417
        },
        "gpt-5-nano-high": {
            "rating": 1337.5017232775538,
            "rating_q975": 1349.2924954486818,
            "rating_q025": 1325.7109511064257
        },
        "qwen3-30b-a3b": {
            "rating": 1335.6561246201004,
            "rating_q975": 1341.7584473508934,
            "rating_q025": 1329.5538018893076
        },
        "o3-mini": {
            "rating": 1335.4563374797056,
            "rating_q975": 1339.897896149517,
            "rating_q025": 1331.0147788098943
        },
        "hunyuan-turbos-20250226": {
            "rating": 1334.0950207689184,
            "rating_q975": 1347.6233137169213,
            "rating_q025": 1320.5667278209157
        },
        "gemini-2.0-flash-lite-preview-02-05": {
            "rating": 1332.9822227323862,
            "rating_q975": 1338.1307607822841,
            "rating_q025": 1327.8336846824884
        },
        "amazon-nova-experimental-chat-05-14": {
            "rating": 1332.675466308699,
            "rating_q975": 1339.3216344134332,
            "rating_q025": 1326.0292982039648
        },
        "hunyuan-turbo-0110": {
            "rating": 1330.404694453353,
            "rating_q975": 1343.5077164640643,
            "rating_q025": 1317.3016724426413
        },
        "yi-lightning": {
            "rating": 1330.129685431403,
            "rating_q975": 1336.2251190442507,
            "rating_q025": 1324.0342518185553
        },
        "claude-3-7-sonnet-20250219-thinking-32k": {
            "rating": 1329.770430671168,
            "rating_q975": 1335.0378152223664,
            "rating_q025": 1324.5030461199697
        },
        "gemini-1.5-pro-002": {
            "rating": 1323.3216845007946,
            "rating_q975": 1327.3108943595353,
            "rating_q025": 1319.3324746420537
        },
        "qwen2.5-plus-1127": {
            "rating": 1322.631177714869,
            "rating_q975": 1330.0786276442375,
            "rating_q025": 1315.1837277855004
        },
        "grok-2-2024-08-13": {
            "rating": 1321.5704988039704,
            "rating_q975": 1325.6428108370726,
            "rating_q025": 1317.4981867708682
        },
        "gemma-3n-e4b-it": {
            "rating": 1319.6923524462645,
            "rating_q975": 1326.5229343781696,
            "rating_q025": 1312.8617705143593
        },
        "gpt-oss-20b": {
            "rating": 1319.6292327206702,
            "rating_q975": 1329.2893307928298,
            "rating_q025": 1309.9691346485106
        },
        "llama-3.1-nemotron-70b-instruct": {
            "rating": 1315.7025766584698,
            "rating_q975": 1325.1735143444018,
            "rating_q025": 1306.231638972538
        },
        "gpt-4o-2024-05-13": {
            "rating": 1313.6815445084003,
            "rating_q975": 1317.7791746281794,
            "rating_q025": 1309.5839143886215
        },
        "llama-3.1-405b-instruct-bf16": {
            "rating": 1312.6545592379262,
            "rating_q975": 1316.8262336822904,
            "rating_q025": 1308.4828847935619
        },
        "claude-3-7-sonnet-20250219": {
            "rating": 1311.7217810794368,
            "rating_q975": 1316.6016519729785,
            "rating_q025": 1306.8419101858954
        },
        "deepseek-v2.5-1210": {
            "rating": 1310.9457023748291,
            "rating_q975": 1320.8255556302154,
            "rating_q025": 1301.0658491194429
        },
        "llama-3.1-405b-instruct-fp8": {
            "rating": 1309.1223039906954,
            "rating_q975": 1313.3931515380107,
            "rating_q025": 1304.8514564433801
        },
        "athene-v2-chat": {
            "rating": 1308.6297380941223,
            "rating_q975": 1313.9441911138165,
            "rating_q025": 1303.3152850744282
        },
        "claude-3-5-sonnet-20241022": {
            "rating": 1308.5947838370175,
            "rating_q975": 1312.1387533197133,
            "rating_q025": 1305.0508143543218
        },
        "hunyuan-large-2025-02-10": {
            "rating": 1307.2416869638707,
            "rating_q975": 1319.3261744464646,
            "rating_q025": 1295.1571994812768
        },
        "llama-3.3-70b-instruct": {
            "rating": 1305.503484209708,
            "rating_q975": 1309.5573588524007,
            "rating_q025": 1301.4496095670154
        },
        "llama-4-maverick-17b-128e-instruct": {
            "rating": 1304.5163780369548,
            "rating_q975": 1310.2103692120024,
            "rating_q025": 1298.8223868619075
        },
        "gpt-4.1-nano-2025-04-14": {
            "rating": 1303.8636129291729,
            "rating_q975": 1313.5391050968494,
            "rating_q025": 1294.188120761496
        },
        "gpt-4o-mini-2024-07-18": {
            "rating": 1301.7813310834158,
            "rating_q975": 1305.5853362687062,
            "rating_q025": 1297.9773258981252
        },
        "gemma-3-4b-it": {
            "rating": 1301.350609778357,
            "rating_q975": 1312.671547972458,
            "rating_q025": 1290.029671584256
        },
        "llama-4-scout-17b-16e-instruct": {
            "rating": 1301.1014265589429,
            "rating_q975": 1307.6678405411863,
            "rating_q025": 1294.5350125766995
        },
        "grok-2-mini-2024-08-13": {
            "rating": 1299.5830943597248,
            "rating_q975": 1303.9330632948615,
            "rating_q025": 1295.233125424588
        },
        "mistral-small-3.1-24b-instruct-2503": {
            "rating": 1299.0687220412308,
            "rating_q975": 1305.7372781330532,
            "rating_q025": 1292.4001659494083
        },
        "gpt-4o-2024-08-06": {
            "rating": 1299.0254221882878,
            "rating_q975": 1303.903707652639,
            "rating_q025": 1294.1471367239367
        },
        "glm-4-plus": {
            "rating": 1297.6412014377565,
            "rating_q975": 1303.61619972773,
            "rating_q025": 1291.6662031477833
        },
        "llama-3.1-70b-instruct": {
            "rating": 1295.7822921361758,
            "rating_q975": 1300.1114673609263,
            "rating_q025": 1291.4531169114252
        },
        "qwen-max-0919": {
            "rating": 1294.8843027432022,
            "rating_q975": 1301.753637308483,
            "rating_q025": 1288.0149681779212
        },
        "gpt-4-turbo-2024-04-09": {
            "rating": 1293.4578521435242,
            "rating_q975": 1297.897104635648,
            "rating_q025": 1289.0185996514006
        },
        "gemini-1.5-flash-002": {
            "rating": 1291.7539907755627,
            "rating_q975": 1296.7360044971028,
            "rating_q025": 1286.771977054023
        },
        "mistral-large-2407": {
            "rating": 1290.8659706311323,
            "rating_q975": 1295.4903248002913,
            "rating_q025": 1286.2416164619733
        },
        "athene-70b-0725": {
            "rating": 1289.7159297094063,
            "rating_q975": 1296.2210075360526,
            "rating_q025": 1283.2108518827597
        },
        "claude-3-5-sonnet-20240620": {
            "rating": 1288.8062192376597,
            "rating_q975": 1292.824739118462,
            "rating_q025": 1284.787699356857
        },
        "hunyuan-large-vision": {
            "rating": 1287.8461920614045,
            "rating_q975": 1299.0822524904383,
            "rating_q025": 1276.6101316323704
        },
        "deepseek-v2.5": {
            "rating": 1287.4361970014945,
            "rating_q975": 1293.1098113648484,
            "rating_q025": 1281.7625826381409
        },
        "mistral-large-2411": {
            "rating": 1285.9360839343208,
            "rating_q975": 1290.980545740058,
            "rating_q025": 1280.8916221285835
        },
        "qwen2.5-72b-instruct": {
            "rating": 1285.4172394048328,
            "rating_q975": 1290.1142793079937,
            "rating_q025": 1280.7201995016721
        },
        "gemini-advanced-0514": {
            "rating": 1283.7316158373178,
            "rating_q975": 1289.441241849667,
            "rating_q025": 1278.0219898249688
        },
        "hunyuan-standard-2025-02-10": {
            "rating": 1283.460287372935,
            "rating_q975": 1295.6810577869608,
            "rating_q025": 1271.239516958909
        },
        "gemini-1.5-pro-001": {
            "rating": 1282.0691222468429,
            "rating_q975": 1286.7405208866703,
            "rating_q025": 1277.3977236070155
        },
        "gpt-4-1106-preview": {
            "rating": 1279.726873357481,
            "rating_q975": 1284.1721346456234,
            "rating_q025": 1275.2816120693385
        },
        "llama-3-70b-instruct": {
            "rating": 1279.1522380531437,
            "rating_q975": 1283.3968503323733,
            "rating_q025": 1274.9076257739143
        },
        "gpt-4-0125-preview": {
            "rating": 1278.9412613667935,
            "rating_q975": 1283.612679032314,
            "rating_q025": 1274.269843701273
        },
        "amazon-nova-pro-v1.0": {
            "rating": 1277.5037451198857,
            "rating_q975": 1282.660041498415,
            "rating_q025": 1272.3474487413564
        },
        "magistral-medium-2506": {
            "rating": 1276.1883180583598,
            "rating_q975": 1285.6200750081853,
            "rating_q025": 1266.7565611085342
        },
        "llama-3.1-tulu-3-70b": {
            "rating": 1275.3105247591743,
            "rating_q975": 1288.06558002942,
            "rating_q025": 1262.5554694889283
        },
        "jamba-1.5-large": {
            "rating": 1269.8556344494973,
            "rating_q975": 1278.6718524149103,
            "rating_q025": 1261.0394164840843
        },
        "claude-3-5-haiku-20241022": {
            "rating": 1269.7933300556979,
            "rating_q975": 1273.7652999438196,
            "rating_q025": 1265.8213601675761
        },
        "llama-3.1-nemotron-51b-instruct": {
            "rating": 1268.7420347550003,
            "rating_q975": 1281.9114664106398,
            "rating_q025": 1255.572603099361
        },
        "claude-3-opus-20240229": {
            "rating": 1265.706779342388,
            "rating_q975": 1269.1640107420626,
            "rating_q025": 1262.2495479427137
        },
        "mistral-small-24b-instruct-2501": {
            "rating": 1259.4216318155293,
            "rating_q975": 1266.1579608116276,
            "rating_q025": 1252.685302819431
        },
        "reka-core-20240904": {
            "rating": 1258.2085201358225,
            "rating_q975": 1266.8803387915075,
            "rating_q025": 1249.5367014801375
        },
        "olmo-2-0325-32b-instruct": {
            "rating": 1257.904053648857,
            "rating_q975": 1270.6649886113967,
            "rating_q025": 1245.1431186863174
        },
        "qwen2.5-coder-32b-instruct": {
            "rating": 1251.8797341402114,
            "rating_q975": 1262.5487512682973,
            "rating_q025": 1241.2107170121255
        },
        "gemma-2-9b-it-simpo": {
            "rating": 1246.8510733713877,
            "rating_q975": 1255.1577323035922,
            "rating_q025": 1238.5444144391831
        },
        "gemini-1.5-flash-001": {
            "rating": 1246.811373081916,
            "rating_q975": 1251.7554110729182,
            "rating_q025": 1241.8673350909137
        },
        "amazon-nova-lite-v1.0": {
            "rating": 1246.5783730820663,
            "rating_q975": 1252.4797901724219,
            "rating_q025": 1240.6769559917104
        },
        "gemma-2-27b-it": {
            "rating": 1245.2412920507004,
            "rating_q975": 1249.0423524525445,
            "rating_q025": 1241.4402316488563
        },
        "glm-4-0520": {
            "rating": 1245.0760878597748,
            "rating_q975": 1253.9312214699166,
            "rating_q025": 1236.2209542496332
        },
        "command-r-plus-08-2024": {
            "rating": 1240.6705654493874,
            "rating_q975": 1248.4744954710084,
            "rating_q025": 1232.8666354277664
        },
        "nemotron-4-340b-instruct": {
            "rating": 1239.6537461310868,
            "rating_q975": 1246.5290267295104,
            "rating_q025": 1232.778465532663
        },
        "phi-4": {
            "rating": 1235.6640512990025,
            "rating_q975": 1241.071826127183,
            "rating_q025": 1230.2562764708218
        },
        "gemini-1.5-flash-8b-001": {
            "rating": 1235.6148368641739,
            "rating_q975": 1240.698404734418,
            "rating_q025": 1230.5312689939296
        },
        "c4ai-aya-expanse-32b": {
            "rating": 1232.7316091753778,
            "rating_q975": 1238.4293192610314,
            "rating_q025": 1227.0338990897242
        },
        "claude-3-sonnet-20240229": {
            "rating": 1229.1962617292438,
            "rating_q975": 1233.7141814371364,
            "rating_q025": 1224.678342021351
        },
        "amazon-nova-micro-v1.0": {
            "rating": 1228.9972387661637,
            "rating_q975": 1234.8320831320782,
            "rating_q025": 1223.162394400249
        },
        "reka-flash-20240904": {
            "rating": 1228.8999377975397,
            "rating_q975": 1237.4843652247625,
            "rating_q025": 1220.315510370317
        },
        "jamba-1.5-mini": {
            "rating": 1227.983500563833,
            "rating_q975": 1236.6256431845297,
            "rating_q025": 1219.3413579431367
        },
        "qwen2-72b-instruct": {
            "rating": 1225.7278095505194,
            "rating_q975": 1231.3683369332045,
            "rating_q025": 1220.087282167834
        },
        "gemma-2-9b-it": {
            "rating": 1223.8822673742723,
            "rating_q975": 1228.1809133535726,
            "rating_q025": 1219.583621394972
        },
        "gpt-4-0314": {
            "rating": 1223.17284264368,
            "rating_q975": 1228.6468944871422,
            "rating_q025": 1217.6987908002181
        },
        "llama-3.1-8b-instruct": {
            "rating": 1222.4255621364632,
            "rating_q975": 1227.0984902611335,
            "rating_q025": 1217.7526340117927
        },
        "hunyuan-standard-256k": {
            "rating": 1221.896704627364,
            "rating_q975": 1237.522753353076,
            "rating_q025": 1206.270655901652
        },
        "llama-3.1-tulu-3-8b": {
            "rating": 1219.0612897245423,
            "rating_q975": 1232.0696456889832,
            "rating_q025": 1206.0529337601013
        },
        "yi-1.5-34b-chat": {
            "rating": 1218.0202219776902,
            "rating_q975": 1224.5368003134358,
            "rating_q025": 1211.5036436419448
        },
        "ministral-8b-2410": {
            "rating": 1216.764832110577,
            "rating_q975": 1228.224201637372,
            "rating_q025": 1205.3054625837815
        },
        "llama-3-8b-instruct": {
            "rating": 1216.7350374744547,
            "rating_q975": 1221.196536715106,
            "rating_q025": 1212.2735382338028
        },
        "command-r-plus": {
            "rating": 1216.6512624676225,
            "rating_q975": 1221.563852341019,
            "rating_q025": 1211.7386725942263
        },
        "internlm2_5-20b-chat": {
            "rating": 1211.1742685941804,
            "rating_q975": 1219.8766371864297,
            "rating_q025": 1202.4719000019315
        },
        "claude-3-haiku-20240307": {
            "rating": 1210.087264649461,
            "rating_q975": 1214.4732577724374,
            "rating_q025": 1205.7012715264848
        },
        "gpt-4-0613": {
            "rating": 1208.7889976871784,
            "rating_q975": 1213.4401799810503,
            "rating_q025": 1204.1378153933067
        },
        "command-r-08-2024": {
            "rating": 1204.0968382539804,
            "rating_q975": 1211.8581052540183,
            "rating_q025": 1196.3355712539424
        },
        "mistral-large-2402": {
            "rating": 1203.119379903462,
            "rating_q975": 1208.5731901085537,
            "rating_q025": 1197.6655696983703
        },
        "qwen1.5-110b-chat": {
            "rating": 1202.0330684011965,
            "rating_q975": 1208.9930626030975,
            "rating_q025": 1195.0730741992954
        },
        "deepseek-coder-v2": {
            "rating": 1198.3713101630397,
            "rating_q975": 1206.1246514086108,
            "rating_q025": 1190.6179689174687
        },
        "c4ai-aya-expanse-8b": {
            "rating": 1198.2405970069003,
            "rating_q975": 1206.4597133105262,
            "rating_q025": 1190.0214807032746
        },
        "granite-3.1-8b-instruct": {
            "rating": 1196.2051566170899,
            "rating_q975": 1209.3703536716625,
            "rating_q025": 1183.0399595625172
        },
        "mistral-medium": {
            "rating": 1194.5627431932808,
            "rating_q975": 1200.7075746707064,
            "rating_q025": 1188.4179117158549
        },
        "mixtral-8x22b-instruct-v0.1": {
            "rating": 1191.0860208481045,
            "rating_q975": 1196.350064365216,
            "rating_q025": 1185.821977330993
        },
        "qwq-32b-preview": {
            "rating": 1190.8470943932161,
            "rating_q975": 1204.9522569670512,
            "rating_q025": 1176.7419318193813
        },
        "qwen1.5-72b-chat": {
            "rating": 1190.7214303004407,
            "rating_q975": 1196.643207352648,
            "rating_q025": 1184.7996532482334
        },
        "gemma-2-2b-it": {
            "rating": 1187.4613107920404,
            "rating_q975": 1192.020033029537,
            "rating_q025": 1182.9025885545439
        },
        "llama-3.2-3b-instruct": {
            "rating": 1185.7176751748648,
            "rating_q975": 1194.8580493279603,
            "rating_q025": 1176.577301021769
        },
        "reka-flash-21b-20240226-online": {
            "rating": 1185.6800922610573,
            "rating_q975": 1194.4470974224505,
            "rating_q025": 1176.9130870996644
        },
        "reka-flash-21b-20240226": {
            "rating": 1183.1864104547863,
            "rating_q975": 1190.2575318856814,
            "rating_q025": 1176.1152890238911
        },
        "granite-3.1-2b-instruct": {
            "rating": 1178.956887223727,
            "rating_q975": 1192.5011295826125,
            "rating_q025": 1165.4126448648417
        },
        "command-r": {
            "rating": 1178.5425428584995,
            "rating_q975": 1184.1052323811289,
            "rating_q025": 1172.97985333587
        },
        "zephyr-orpo-141b-A35b-v0.1": {
            "rating": 1177.9741802953913,
            "rating_q975": 1190.904033000401,
            "rating_q025": 1165.0443275903817
        },
        "phi-3-medium-4k-instruct": {
            "rating": 1173.4767823131801,
            "rating_q975": 1179.7143308963007,
            "rating_q025": 1167.2392337300596
        },
        "mixtral-8x7b-instruct-v0.1": {
            "rating": 1172.1077618566444,
            "rating_q975": 1176.9971177514294,
            "rating_q025": 1167.2184059618596
        },
        "starling-lm-7b-beta": {
            "rating": 1166.4559865178162,
            "rating_q975": 1175.0142700314893,
            "rating_q025": 1157.897703004143
        },
        "gemini-pro-dev-api": {
            "rating": 1166.1833713996107,
            "rating_q975": 1174.357657467245,
            "rating_q025": 1158.0090853319766
        },
        "qwen1.5-32b-chat": {
            "rating": 1164.4181234971363,
            "rating_q975": 1171.7522503188873,
            "rating_q025": 1157.0839966753854
        },
        "yi-34b-chat": {
            "rating": 1163.0182857046884,
            "rating_q975": 1170.690005733583,
            "rating_q025": 1155.346565675794
        },
        "llama-2-70b-chat": {
            "rating": 1160.6015623274193,
            "rating_q975": 1166.7733625977642,
            "rating_q025": 1154.4297620570742
        },
        "dbrx-instruct-preview": {
            "rating": 1159.7877663373768,
            "rating_q975": 1167.0368050238296,
            "rating_q025": 1152.5387276509239
        },
        "gemini-pro": {
            "rating": 1158.2360664496982,
            "rating_q975": 1170.7451889572455,
            "rating_q025": 1145.7269439421507
        },
        "granite-3.0-8b-instruct": {
            "rating": 1156.722184848476,
            "rating_q975": 1167.6675184874882,
            "rating_q025": 1145.7768512094638
        },
        "phi-3-small-8k-instruct": {
            "rating": 1155.6679282072128,
            "rating_q975": 1163.2614271872953,
            "rating_q025": 1148.0744292271304
        },
        "wizardlm-70b": {
            "rating": 1154.6961067519305,
            "rating_q975": 1164.7965358551032,
            "rating_q025": 1144.5956776487576
        },
        "tulu-2-dpo-70b": {
            "rating": 1154.49000551963,
            "rating_q975": 1165.1169530838515,
            "rating_q025": 1143.863057955408
        },
        "qwen1.5-14b-chat": {
            "rating": 1153.5936610379913,
            "rating_q975": 1162.104232147733,
            "rating_q025": 1145.0830899282498
        },
        "nous-hermes-2-mixtral-8x7b-dpo": {
            "rating": 1145.045033417716,
            "rating_q975": 1157.7604584039966,
            "rating_q025": 1132.3296084314354
        },
        "gpt-3.5-turbo-0125": {
            "rating": 1144.718091281667,
            "rating_q975": 1149.9496763271861,
            "rating_q025": 1139.486506236148
        },
        "starling-lm-7b-alpha": {
            "rating": 1143.6252399649152,
            "rating_q975": 1152.4517990326153,
            "rating_q025": 1134.7986808972153
        },
        "vicuna-33b": {
            "rating": 1138.5710151077524,
            "rating_q975": 1145.5794847983818,
            "rating_q025": 1131.5625454171227
        },
        "mistral-7b-instruct-v0.2": {
            "rating": 1138.3343890286365,
            "rating_q975": 1145.7325106552867,
            "rating_q025": 1130.9362674019862
        },
        "openchat-3.5-0106": {
            "rating": 1136.24537205546,
            "rating_q975": 1144.7921008007254,
            "rating_q025": 1127.6986433101945
        },
        "phi-3-mini-4k-instruct-june-2024": {
            "rating": 1134.3275799426883,
            "rating_q975": 1142.2046255460618,
            "rating_q025": 1126.450534339315
        },
        "deepseek-llm-67b-chat": {
            "rating": 1131.1032323632132,
            "rating_q975": 1143.8249788592275,
            "rating_q025": 1118.381485867199
        },
        "openhermes-2.5-mistral-7b": {
            "rating": 1130.7971908459294,
            "rating_q975": 1142.161094327439,
            "rating_q025": 1119.4332873644198
        },
        "gemma-1.1-7b-it": {
            "rating": 1130.2942431192778,
            "rating_q975": 1137.1212099345137,
            "rating_q025": 1123.467276304042
        },
        "granite-3.0-2b-instruct": {
            "rating": 1129.4693482761022,
            "rating_q975": 1140.2906715381064,
            "rating_q025": 1118.648025014098
        },
        "llama-3.2-1b-instruct": {
            "rating": 1126.9770914260655,
            "rating_q975": 1136.169210268744,
            "rating_q025": 1117.7849725833871
        },
        "snowflake-arctic-instruct": {
            "rating": 1126.9357613421357,
            "rating_q975": 1134.1021019988036,
            "rating_q025": 1119.7694206854678
        },
        "llama-2-13b-chat": {
            "rating": 1125.9769878988839,
            "rating_q975": 1133.4213867209207,
            "rating_q025": 1118.5325890768472
        },
        "llama2-70b-steerlm-chat": {
            "rating": 1125.6702005400775,
            "rating_q975": 1139.3318927413204,
            "rating_q025": 1112.0085083388349
        },
        "solar-10.7b-instruct-v1.0": {
            "rating": 1123.1440355289626,
            "rating_q975": 1137.4674186723764,
            "rating_q025": 1108.820652385549
        },
        "phi-3-mini-4k-instruct": {
            "rating": 1121.8999712885197,
            "rating_q975": 1129.7051299602404,
            "rating_q025": 1114.0948126167993
        },
        "openchat-3.5": {
            "rating": 1121.718589363089,
            "rating_q975": 1132.25494936601,
            "rating_q025": 1111.1822293601679
        },
        "gpt-3.5-turbo-1106": {
            "rating": 1117.7686189439698,
            "rating_q975": 1127.2163665332077,
            "rating_q025": 1108.320871354732
        },
        "dolphin-2.2.1-mistral-7b": {
            "rating": 1116.9826923651963,
            "rating_q975": 1133.8460340338327,
            "rating_q025": 1100.11935069656
        },
        "zephyr-7b-beta": {
            "rating": 1111.6403028306663,
            "rating_q975": 1121.0877157340021,
            "rating_q025": 1102.1928899273307
        },
        "qwen1.5-7b-chat": {
            "rating": 1109.8230087013578,
            "rating_q975": 1120.8155122288085,
            "rating_q025": 1098.830505173907
        },
        "smollm2-1.7b-instruct": {
            "rating": 1108.1643580274913,
            "rating_q975": 1125.8608204351062,
            "rating_q025": 1090.4678956198766
        },
        "wizardlm-13b": {
            "rating": 1106.9019167356973,
            "rating_q975": 1117.207599977757,
            "rating_q025": 1096.596233493638
        },
        "mpt-30b-chat": {
            "rating": 1106.8564403926057,
            "rating_q975": 1120.4315839867409,
            "rating_q025": 1093.2812967984705
        },
        "codellama-70b-instruct": {
            "rating": 1102.442757839753,
            "rating_q975": 1124.0990078129028,
            "rating_q025": 1080.7865078666036
        },
        "llama-2-7b-chat": {
            "rating": 1101.2594155147378,
            "rating_q975": 1108.9379803127867,
            "rating_q025": 1093.580850716689
        },
        "zephyr-7b-alpha": {
            "rating": 1097.769743698083,
            "rating_q975": 1115.3028388491352,
            "rating_q025": 1080.2366485470307
        },
        "codellama-34b-instruct": {
            "rating": 1096.7792008969673,
            "rating_q975": 1106.3040912357412,
            "rating_q025": 1087.2543105581933
        },
        "gemma-7b-it": {
            "rating": 1095.487510280704,
            "rating_q975": 1106.4137221842661,
            "rating_q025": 1084.5612983771423
        },
        "guanaco-33b": {
            "rating": 1090.782675431265,
            "rating_q975": 1104.1290836695896,
            "rating_q025": 1077.4362671929407
        },
        "phi-3-mini-128k-instruct": {
            "rating": 1090.4628502412288,
            "rating_q975": 1099.1163639992606,
            "rating_q025": 1081.8093364831968
        },
        "vicuna-13b": {
            "rating": 1086.4266764333465,
            "rating_q975": 1093.6925233894688,
            "rating_q025": 1079.1608294772245
        },
        "falcon-180b-chat": {
            "rating": 1085.4310082514721,
            "rating_q975": 1104.2827586753276,
            "rating_q025": 1066.5792578276169
        },
        "stripedhyena-nous-7b": {
            "rating": 1074.761887404783,
            "rating_q975": 1086.5904105231305,
            "rating_q025": 1062.9333642864353
        },
        "qwen-14b-chat": {
            "rating": 1072.582866615403,
            "rating_q975": 1084.3659976189701,
            "rating_q025": 1060.7997356118356
        },
        "olmo-7b-instruct": {
            "rating": 1071.4391633506125,
            "rating_q975": 1084.1893192972723,
            "rating_q025": 1058.6890074039525
        },
        "palm-2": {
            "rating": 1068.2911385577893,
            "rating_q975": 1078.2004085400536,
            "rating_q025": 1058.381868575525
        },
        "mistral-7b-instruct": {
            "rating": 1064.7928268548017,
            "rating_q975": 1074.8076971608486,
            "rating_q025": 1054.7779565487544
        },
        "gemma-1.1-2b-it": {
            "rating": 1058.0939321454139,
            "rating_q975": 1067.4993527645738,
            "rating_q025": 1048.688511526254
        },
        "vicuna-7b": {
            "rating": 1057.1318133216744,
            "rating_q975": 1066.9934737936371,
            "rating_q025": 1047.2701528497114
        },
        "gemma-2b-it": {
            "rating": 1037.3223971056466,
            "rating_q975": 1050.4451304240715,
            "rating_q025": 1024.1996637872214
        },
        "koala-13b": {
            "rating": 1027.1797159856997,
            "rating_q975": 1038.3246571839463,
            "rating_q025": 1016.0347747874533
        },
        "qwen1.5-4b-chat": {
            "rating": 1021.0648233769068,
            "rating_q975": 1031.690130258532,
            "rating_q025": 1010.4395164952816
        },
        "chatglm3-6b": {
            "rating": 1007.5158176354911,
            "rating_q975": 1020.1589108401853,
            "rating_q025": 994.8727244307969
        },
        "gpt4all-13b-snoozy": {
            "rating": 993.9054796122136,
            "rating_q975": 1010.9466132002722,
            "rating_q025": 976.8643460241551
        },
        "mpt-7b-chat": {
            "rating": 986.6990743833854,
            "rating_q975": 999.6487404109535,
            "rating_q025": 973.7494083558174
        },
        "chatglm2-6b": {
            "rating": 979.7939216652719,
            "rating_q975": 994.7207331223442,
            "rating_q025": 964.8671102081996
        },
        "RWKV-4-Raven-14B": {
            "rating": 974.2420179653104,
            "rating_q975": 986.8346198602665,
            "rating_q025": 961.6494160703544
        },
        "alpaca-13b": {
            "rating": 963.4544767045982,
            "rating_q975": 975.7393036829262,
            "rating_q025": 951.16964972627
        },
        "oasst-pythia-12b": {
            "rating": 950.6808556161513,
            "rating_q975": 962.5174203519905,
            "rating_q025": 938.844290880312
        },
        "chatglm-6b": {
            "rating": 943.7860069896897,
            "rating_q975": 957.3253850113138,
            "rating_q025": 930.2466289680658
        },
        "fastchat-t5-3b": {
            "rating": 940.8377326502055,
            "rating_q975": 954.2710958578587,
            "rating_q025": 927.4043694425521
        },
        "stablelm-tuned-alpha-7b": {
            "rating": 895.5867974825132,
            "rating_q975": 909.7470146165542,
            "rating_q025": 881.426580348472
        },
        "dolly-v2-12b": {
            "rating": 872.5215674590778,
            "rating_q975": 887.4616264648648,
            "rating_q025": 857.5815084532908
        },
        "llama-13b": {
            "rating": 851.186339458881,
            "rating_q975": 868.4776525407688,
            "rating_q025": 833.8950263769933
        }
    },
    "french": {
        "gemini-2.5-pro": {
            "rating": 1510.4456165376362,
            "rating_q975": 1543.8369744189463,
            "rating_q025": 1477.054258656326
        },
        "grok-3-preview-02-24": {
            "rating": 1471.526756272468,
            "rating_q975": 1504.3130127286092,
            "rating_q025": 1438.7404998163267
        },
        "o3-2025-04-16": {
            "rating": 1468.1130335651299,
            "rating_q975": 1500.3275479806755,
            "rating_q025": 1435.898519149584
        },
        "qwen3-235b-a22b-instruct-2507": {
            "rating": 1466.2776254883372,
            "rating_q975": 1524.3859696543345,
            "rating_q025": 1408.1692813223399
        },
        "grok-4-0709": {
            "rating": 1462.5839474404765,
            "rating_q975": 1513.6197651736925,
            "rating_q025": 1411.5481297072608
        },
        "chatgpt-4o-latest-20250326": {
            "rating": 1456.7520572248036,
            "rating_q975": 1487.6626437504742,
            "rating_q025": 1425.841470699133
        },
        "gemini-2.5-flash": {
            "rating": 1444.1427026046067,
            "rating_q975": 1474.606102518437,
            "rating_q025": 1413.6793026907765
        },
        "claude-opus-4-1-20250805": {
            "rating": 1440.9932782985697,
            "rating_q975": 1495.0100772252258,
            "rating_q025": 1386.9764793719137
        },
        "glm-4.5": {
            "rating": 1432.1944249169417,
            "rating_q975": 1489.7733930958448,
            "rating_q025": 1374.6154567380383
        },
        "gpt-4.5-preview-2025-02-27": {
            "rating": 1429.1912636783495,
            "rating_q975": 1484.9620527384866,
            "rating_q025": 1373.4204746182127
        },
        "deepseek-r1-0528": {
            "rating": 1426.906257822939,
            "rating_q975": 1466.7557680408956,
            "rating_q025": 1387.0567476049825
        },
        "gpt-4.1-2025-04-14": {
            "rating": 1407.361648832271,
            "rating_q975": 1442.778655939283,
            "rating_q025": 1371.944641725259
        },
        "qwen2.5-max": {
            "rating": 1406.596105824414,
            "rating_q975": 1438.8540255214975,
            "rating_q025": 1374.3381861273308
        },
        "claude-opus-4-20250514-thinking-16k": {
            "rating": 1405.972607035047,
            "rating_q975": 1447.1065552019868,
            "rating_q025": 1364.8386588681074
        },
        "minimax-m1": {
            "rating": 1400.3795082741278,
            "rating_q975": 1442.43993137209,
            "rating_q025": 1358.3190851761658
        },
        "deepseek-v3-0324": {
            "rating": 1398.90586365146,
            "rating_q975": 1431.528538522676,
            "rating_q025": 1366.2831887802442
        },
        "gemini-2.0-flash-001": {
            "rating": 1396.5362099179133,
            "rating_q975": 1424.094021464356,
            "rating_q025": 1368.9783983714708
        },
        "hunyuan-turbos-20250416": {
            "rating": 1393.0168891263097,
            "rating_q975": 1442.6831954316724,
            "rating_q025": 1343.3505828209472
        },
        "gemma-3-27b-it": {
            "rating": 1391.5475093054397,
            "rating_q975": 1421.7170633473308,
            "rating_q025": 1361.3779552635488
        },
        "qwen3-235b-a22b-no-thinking": {
            "rating": 1387.8025764084066,
            "rating_q975": 1423.0015897118524,
            "rating_q025": 1352.603563104961
        },
        "kimi-k2-0711-preview": {
            "rating": 1383.4777713042097,
            "rating_q975": 1429.2041926164993,
            "rating_q025": 1337.75134999192
        },
        "claude-sonnet-4-20250514-thinking-32k": {
            "rating": 1379.0708732507255,
            "rating_q975": 1417.7338796011295,
            "rating_q025": 1340.4078669003216
        },
        "mistral-medium-2505": {
            "rating": 1378.972178663795,
            "rating_q975": 1410.58371616132,
            "rating_q025": 1347.3606411662697
        },
        "deepseek-r1": {
            "rating": 1377.9078417172127,
            "rating_q975": 1417.665735532814,
            "rating_q025": 1338.1499479016115
        },
        "qwen3-235b-a22b": {
            "rating": 1373.9580672474888,
            "rating_q975": 1410.489974977252,
            "rating_q025": 1337.4261595177259
        },
        "qwen3-30b-a3b": {
            "rating": 1373.3330279794955,
            "rating_q975": 1409.0226689510032,
            "rating_q025": 1337.6433870079877
        },
        "gpt-4.1-mini-2025-04-14": {
            "rating": 1367.8096233844776,
            "rating_q975": 1402.5121315296085,
            "rating_q025": 1333.1071152393465
        },
        "gemini-2.0-flash-lite-preview-02-05": {
            "rating": 1360.2145344092846,
            "rating_q975": 1396.6889747105536,
            "rating_q025": 1323.7400941080157
        },
        "amazon-nova-experimental-chat-05-14": {
            "rating": 1360.1745256392903,
            "rating_q975": 1404.9499170808306,
            "rating_q025": 1315.39913419775
        },
        "o4-mini-2025-04-16": {
            "rating": 1356.6372624594142,
            "rating_q975": 1391.5850860095693,
            "rating_q025": 1321.6894389092593
        },
        "o1-2024-12-17": {
            "rating": 1355.1368503650167,
            "rating_q975": 1390.798345436108,
            "rating_q025": 1319.4753552939253
        },
        "command-a-03-2025": {
            "rating": 1354.7890443825636,
            "rating_q975": 1387.5813797988244,
            "rating_q025": 1321.9967089663028
        },
        "grok-3-mini-beta": {
            "rating": 1353.67095643887,
            "rating_q975": 1396.0962451832747,
            "rating_q025": 1311.245667694465
        },
        "o1-preview": {
            "rating": 1353.384848399427,
            "rating_q975": 1383.5070490895903,
            "rating_q025": 1323.2626477092638
        },
        "qwq-32b": {
            "rating": 1352.6747780304863,
            "rating_q975": 1389.9490515083444,
            "rating_q025": 1315.4005045526285
        },
        "deepseek-v3": {
            "rating": 1350.2427951845036,
            "rating_q975": 1385.1274677301367,
            "rating_q025": 1315.3581226388706
        },
        "claude-sonnet-4-20250514": {
            "rating": 1349.9269778599396,
            "rating_q975": 1386.571795998239,
            "rating_q025": 1313.2821597216403
        },
        "o3-mini-high": {
            "rating": 1347.2479025577118,
            "rating_q975": 1390.720062300443,
            "rating_q025": 1303.7757428149803
        },
        "gemma-3n-e4b-it": {
            "rating": 1343.1116910088767,
            "rating_q975": 1385.726757701646,
            "rating_q025": 1300.4966243161075
        },
        "qwen-max-0919": {
            "rating": 1343.036743676314,
            "rating_q975": 1380.9203205614513,
            "rating_q025": 1305.153166791177
        },
        "athene-v2-chat": {
            "rating": 1342.7134630259216,
            "rating_q975": 1376.650305020602,
            "rating_q025": 1308.776621031241
        },
        "mistral-large-2411": {
            "rating": 1332.7360848935102,
            "rating_q975": 1369.7499223451412,
            "rating_q025": 1295.7222474418793
        },
        "mistral-small-2506": {
            "rating": 1328.3989239476045,
            "rating_q975": 1382.5720124076436,
            "rating_q025": 1274.2258354875653
        },
        "grok-3-mini-high": {
            "rating": 1328.1867710328854,
            "rating_q975": 1384.3454265538608,
            "rating_q025": 1272.02811551191
        },
        "claude-opus-4-20250514": {
            "rating": 1328.058599493324,
            "rating_q975": 1362.673545833684,
            "rating_q025": 1293.4436531529639
        },
        "grok-2-2024-08-13": {
            "rating": 1326.8050582515716,
            "rating_q975": 1348.0742999175236,
            "rating_q025": 1305.5358165856194
        },
        "o3-mini": {
            "rating": 1326.085662959365,
            "rating_q975": 1353.9522434013802,
            "rating_q025": 1298.2190825173495
        },
        "gemini-advanced-0514": {
            "rating": 1322.0640594640363,
            "rating_q975": 1344.6642196823507,
            "rating_q025": 1299.463899245722
        },
        "gpt-4o-2024-05-13": {
            "rating": 1318.497927633132,
            "rating_q975": 1335.1537020899027,
            "rating_q025": 1301.8421531763609
        },
        "glm-4-plus": {
            "rating": 1318.3212865673281,
            "rating_q975": 1350.8739164328042,
            "rating_q025": 1285.768656701852
        },
        "claude-3-7-sonnet-20250219": {
            "rating": 1317.8432184197975,
            "rating_q975": 1348.023326021093,
            "rating_q025": 1287.6631108185022
        },
        "gemini-1.5-pro-002": {
            "rating": 1317.2389084042468,
            "rating_q975": 1342.0329098680288,
            "rating_q025": 1292.4449069404645
        },
        "claude-3-5-sonnet-20241022": {
            "rating": 1310.7213409051126,
            "rating_q975": 1331.356611126294,
            "rating_q025": 1290.0860706839314
        },
        "yi-lightning": {
            "rating": 1308.557470958158,
            "rating_q975": 1340.4258886031307,
            "rating_q025": 1276.6890533131857
        },
        "gpt-4o-mini-2024-07-18": {
            "rating": 1308.0833905473153,
            "rating_q975": 1328.8999775716966,
            "rating_q025": 1287.2668035229342
        },
        "o1-mini": {
            "rating": 1307.3213515530535,
            "rating_q975": 1332.4987888655987,
            "rating_q025": 1282.1439142405086
        },
        "claude-3-5-sonnet-20240620": {
            "rating": 1306.9003696321658,
            "rating_q975": 1325.9447914550522,
            "rating_q025": 1287.8559478092795
        },
        "athene-70b-0725": {
            "rating": 1302.9964561736106,
            "rating_q975": 1339.8911184980032,
            "rating_q025": 1266.1017938492175
        },
        "claude-3-7-sonnet-20250219-thinking-32k": {
            "rating": 1301.8374975859097,
            "rating_q975": 1333.5369804433976,
            "rating_q025": 1270.1380147284212
        },
        "gpt-4-1106-preview": {
            "rating": 1299.4507797583656,
            "rating_q975": 1316.046580077846,
            "rating_q025": 1282.8549794388853
        },
        "grok-2-mini-2024-08-13": {
            "rating": 1297.5557091604082,
            "rating_q975": 1321.3920753425227,
            "rating_q025": 1273.7193429782938
        },
        "gpt-4-0125-preview": {
            "rating": 1297.5352732175647,
            "rating_q975": 1315.2160029465795,
            "rating_q025": 1279.8545434885496
        },
        "deepseek-v2.5": {
            "rating": 1297.0812333862914,
            "rating_q975": 1330.1109756366134,
            "rating_q025": 1264.0514911359696
        },
        "llama-3.3-70b-instruct": {
            "rating": 1296.701315852834,
            "rating_q975": 1322.6144397265455,
            "rating_q025": 1270.7881919791225
        },
        "qwen2.5-72b-instruct": {
            "rating": 1293.6324092564405,
            "rating_q975": 1322.0235006348057,
            "rating_q025": 1265.2413178780755
        },
        "llama-4-scout-17b-16e-instruct": {
            "rating": 1293.4071056332468,
            "rating_q975": 1338.2300142005797,
            "rating_q025": 1248.5841970659137
        },
        "llama-3.1-405b-instruct-bf16": {
            "rating": 1291.5510562626753,
            "rating_q975": 1319.1489541993344,
            "rating_q025": 1263.9531583260161
        },
        "gpt-4-turbo-2024-04-09": {
            "rating": 1290.2526833333343,
            "rating_q975": 1307.576697497329,
            "rating_q025": 1272.9286691693396
        },
        "claude-3-opus-20240229": {
            "rating": 1290.2365075421471,
            "rating_q975": 1303.8856246522637,
            "rating_q025": 1276.5873904320304
        },
        "mistral-large-2407": {
            "rating": 1289.7245899446875,
            "rating_q975": 1314.8966479632477,
            "rating_q025": 1264.5525319261274
        },
        "gemini-1.5-pro-001": {
            "rating": 1289.3126889543885,
            "rating_q975": 1307.8652888651907,
            "rating_q025": 1270.7600890435863
        },
        "llama-3.1-405b-instruct-fp8": {
            "rating": 1287.605880583319,
            "rating_q975": 1310.8914013071594,
            "rating_q025": 1264.320359859479
        },
        "amazon-nova-pro-v1.0": {
            "rating": 1286.4021515989682,
            "rating_q975": 1321.7956165673918,
            "rating_q025": 1251.0086866305446
        },
        "mistral-small-3.1-24b-instruct-2503": {
            "rating": 1284.635420627436,
            "rating_q975": 1328.5879969876273,
            "rating_q025": 1240.6828442672445
        },
        "llama-3.1-70b-instruct": {
            "rating": 1279.899185250657,
            "rating_q975": 1303.9356446430952,
            "rating_q025": 1255.862725858219
        },
        "gpt-4o-2024-08-06": {
            "rating": 1279.764718536521,
            "rating_q975": 1303.0797437893114,
            "rating_q025": 1256.4496932837308
        },
        "claude-3-5-haiku-20241022": {
            "rating": 1276.6060729849576,
            "rating_q975": 1302.179990640571,
            "rating_q025": 1251.032155329344
        },
        "gemini-1.5-flash-002": {
            "rating": 1270.9849040819804,
            "rating_q975": 1300.9302461355624,
            "rating_q025": 1241.039562028399
        },
        "llama-4-maverick-17b-128e-instruct": {
            "rating": 1263.8396270714334,
            "rating_q975": 1296.8781063435354,
            "rating_q025": 1230.8011477993316
        },
        "c4ai-aya-expanse-32b": {
            "rating": 1262.6795078932264,
            "rating_q975": 1294.3146518758901,
            "rating_q025": 1231.0443639105624
        },
        "gemma-2-27b-it": {
            "rating": 1261.5944877217842,
            "rating_q975": 1280.9450253189045,
            "rating_q025": 1242.2439501246636
        },
        "gemini-1.5-flash-001": {
            "rating": 1258.3155299117175,
            "rating_q975": 1278.3459697790593,
            "rating_q025": 1238.285090044376
        },
        "amazon-nova-micro-v1.0": {
            "rating": 1255.5446802939973,
            "rating_q975": 1296.097428871942,
            "rating_q025": 1214.991931716053
        },
        "amazon-nova-lite-v1.0": {
            "rating": 1253.52710113483,
            "rating_q975": 1295.1970222763678,
            "rating_q025": 1211.8571799932924
        },
        "gemini-1.5-flash-8b-001": {
            "rating": 1252.1718207119654,
            "rating_q975": 1281.2065259871467,
            "rating_q025": 1223.137115436784
        },
        "llama-3-70b-instruct": {
            "rating": 1248.5313935991403,
            "rating_q975": 1263.4316761193659,
            "rating_q025": 1233.6311110789147
        },
        "claude-3-sonnet-20240229": {
            "rating": 1246.1437968691425,
            "rating_q975": 1262.56332389352,
            "rating_q025": 1229.7242698447649
        },
        "phi-4": {
            "rating": 1238.4246832602162,
            "rating_q975": 1277.1544619074364,
            "rating_q025": 1199.6949046129957
        },
        "gpt-4-0314": {
            "rating": 1235.2516589093482,
            "rating_q975": 1257.6410934225628,
            "rating_q025": 1212.8622243961336
        },
        "mistral-large-2402": {
            "rating": 1226.3459847743889,
            "rating_q975": 1246.23552140995,
            "rating_q025": 1206.4564481388275
        },
        "command-r-plus": {
            "rating": 1224.6349339655703,
            "rating_q975": 1243.3694268569332,
            "rating_q025": 1205.9004410742077
        },
        "mistral-small-24b-instruct-2501": {
            "rating": 1217.9058936971978,
            "rating_q975": 1267.227699912137,
            "rating_q025": 1168.5840874822584
        },
        "nemotron-4-340b-instruct": {
            "rating": 1213.496853691209,
            "rating_q975": 1245.0449015159888,
            "rating_q025": 1181.948805866429
        },
        "claude-3-haiku-20240307": {
            "rating": 1211.4144738325897,
            "rating_q975": 1227.607899916963,
            "rating_q025": 1195.2210477482163
        },
        "gemma-2-9b-it": {
            "rating": 1207.4835790855568,
            "rating_q975": 1230.2212742102663,
            "rating_q025": 1184.745883960847
        },
        "llama-3.1-8b-instruct": {
            "rating": 1205.1079503720382,
            "rating_q975": 1229.7026742295147,
            "rating_q025": 1180.5132265145617
        },
        "deepseek-coder-v2": {
            "rating": 1200.1651775869527,
            "rating_q975": 1239.101549633687,
            "rating_q025": 1161.2288055402182
        },
        "mistral-medium": {
            "rating": 1196.4265954378316,
            "rating_q975": 1220.2942897485227,
            "rating_q025": 1172.5589011271404
        },
        "reka-flash-21b-20240226": {
            "rating": 1189.278192554331,
            "rating_q975": 1217.5892620954814,
            "rating_q025": 1160.967123013181
        },
        "qwen2-72b-instruct": {
            "rating": 1188.1048778935656,
            "rating_q975": 1211.08041578224,
            "rating_q025": 1165.1293400048914
        },
        "gpt-4-0613": {
            "rating": 1187.269565975519,
            "rating_q975": 1205.0061545734775,
            "rating_q025": 1169.5329773775609
        },
        "mixtral-8x22b-instruct-v0.1": {
            "rating": 1183.4892025532486,
            "rating_q975": 1205.5675659655417,
            "rating_q025": 1161.4108391409557
        },
        "mixtral-8x7b-instruct-v0.1": {
            "rating": 1183.03950441284,
            "rating_q975": 1201.6404488654446,
            "rating_q025": 1164.4385599602351
        },
        "gemma-2-2b-it": {
            "rating": 1180.8982090397099,
            "rating_q975": 1207.2134749583,
            "rating_q025": 1154.5829431211198
        },
        "command-r": {
            "rating": 1179.0683295674967,
            "rating_q975": 1200.7009610531422,
            "rating_q025": 1157.435698081851
        },
        "qwen1.5-72b-chat": {
            "rating": 1176.9748298017148,
            "rating_q975": 1198.4756051511054,
            "rating_q025": 1155.4740544523243
        },
        "reka-flash-21b-20240226-online": {
            "rating": 1176.5819620960299,
            "rating_q975": 1215.0536588283055,
            "rating_q025": 1138.1102653637543
        },
        "llama-3-8b-instruct": {
            "rating": 1176.0364046766642,
            "rating_q975": 1193.338590144807,
            "rating_q025": 1158.7342192085214
        },
        "yi-1.5-34b-chat": {
            "rating": 1172.545355804899,
            "rating_q975": 1201.8893765148634,
            "rating_q025": 1143.2013350949344
        },
        "qwen1.5-110b-chat": {
            "rating": 1168.2108143038542,
            "rating_q975": 1198.1760405128587,
            "rating_q025": 1138.2455880948498
        },
        "gemini-pro-dev-api": {
            "rating": 1162.5099950050035,
            "rating_q975": 1192.2839804071136,
            "rating_q025": 1132.7360096028935
        },
        "snowflake-arctic-instruct": {
            "rating": 1152.772654120189,
            "rating_q975": 1180.0149207001734,
            "rating_q025": 1125.5303875402044
        },
        "phi-3-small-8k-instruct": {
            "rating": 1151.993541749292,
            "rating_q975": 1185.7436819766385,
            "rating_q025": 1118.2434015219455
        },
        "gpt-3.5-turbo-0125": {
            "rating": 1135.7031675043786,
            "rating_q975": 1154.6805785874874,
            "rating_q025": 1116.7257564212698
        },
        "phi-3-medium-4k-instruct": {
            "rating": 1133.7350913614755,
            "rating_q975": 1165.040459870073,
            "rating_q025": 1102.429722852878
        },
        "starling-lm-7b-beta": {
            "rating": 1133.200629993376,
            "rating_q975": 1170.4088175010506,
            "rating_q025": 1095.9924424857013
        },
        "qwen1.5-14b-chat": {
            "rating": 1132.722175874756,
            "rating_q975": 1169.253319698447,
            "rating_q025": 1096.1910320510647
        },
        "qwen1.5-32b-chat": {
            "rating": 1118.2303654271689,
            "rating_q975": 1150.969376652519,
            "rating_q025": 1085.4913542018187
        },
        "dbrx-instruct-preview": {
            "rating": 1114.4339681245588,
            "rating_q975": 1141.6337075958797,
            "rating_q025": 1087.234228653238
        },
        "openchat-3.5-0106": {
            "rating": 1109.8094486867083,
            "rating_q975": 1150.962513264944,
            "rating_q025": 1068.6563841084726
        },
        "llama-2-70b-chat": {
            "rating": 1107.6639046538376,
            "rating_q975": 1132.3780215448671,
            "rating_q025": 1082.949787762808
        },
        "starling-lm-7b-alpha": {
            "rating": 1104.821222495977,
            "rating_q975": 1146.2468723570423,
            "rating_q025": 1063.3955726349122
        },
        "vicuna-33b": {
            "rating": 1104.2270516525218,
            "rating_q975": 1140.033711339669,
            "rating_q025": 1068.4203919653746
        },
        "yi-34b-chat": {
            "rating": 1096.9709676209563,
            "rating_q975": 1135.965644119293,
            "rating_q025": 1057.9762911226198
        },
        "phi-3-mini-4k-instruct": {
            "rating": 1090.8301284200438,
            "rating_q975": 1124.5448721407681,
            "rating_q025": 1057.1153846993195
        },
        "gemma-1.1-7b-it": {
            "rating": 1082.7039740790685,
            "rating_q975": 1112.3165179872792,
            "rating_q025": 1053.091430170858
        },
        "gpt-3.5-turbo-1106": {
            "rating": 1082.2901367255927,
            "rating_q975": 1119.5402588127558,
            "rating_q025": 1045.0400146384297
        },
        "llama-2-13b-chat": {
            "rating": 1066.20748440162,
            "rating_q975": 1103.633170630716,
            "rating_q025": 1028.7817981725238
        },
        "phi-3-mini-128k-instruct": {
            "rating": 1054.4445631338622,
            "rating_q975": 1086.9709418394589,
            "rating_q025": 1021.9181844282655
        },
        "mistral-7b-instruct-v0.2": {
            "rating": 1054.35346509916,
            "rating_q975": 1083.8173189818256,
            "rating_q025": 1024.8896112164946
        },
        "zephyr-7b-beta": {
            "rating": 1050.0081212992718,
            "rating_q975": 1097.1983446910194,
            "rating_q025": 1002.8178979075246
        },
        "stripedhyena-nous-7b": {
            "rating": 1048.7692047391588,
            "rating_q975": 1096.8502257584942,
            "rating_q025": 1000.6881837198232
        },
        "vicuna-13b": {
            "rating": 1040.6231081814622,
            "rating_q975": 1083.8737037081542,
            "rating_q025": 997.3725126547704
        },
        "gemma-7b-it": {
            "rating": 1039.1203579064763,
            "rating_q975": 1085.3682625567415,
            "rating_q025": 992.8724532562114
        },
        "llama-2-7b-chat": {
            "rating": 989.1515010463747,
            "rating_q975": 1030.2990810881236,
            "rating_q025": 948.0039210046259
        },
        "mistral-7b-instruct": {
            "rating": 964.5396549942703,
            "rating_q975": 1011.5204157222561,
            "rating_q025": 917.5588942662846
        }
    },
    "full": {
        "gemini-2.5-pro": {
            "rating": 1466.2449319357888,
            "rating_q975": 1470.9870316303545,
            "rating_q025": 1461.502832241223
        },
        "mistral-medium-2508": {
            "rating": 1433.4008835768732,
            "rating_q975": 1440.6749760775108,
            "rating_q025": 1426.1267910762358
        },
        "grok-4-0709": {
            "rating": 1430.5057975316654,
            "rating_q975": 1435.942108580908,
            "rating_q025": 1425.0694864824225
        },
        "chatgpt-4o-latest-20250326": {
            "rating": 1429.3784880709006,
            "rating_q975": 1433.695966927121,
            "rating_q025": 1425.0610092146803
        },
        "glm-4.5": {
            "rating": 1429.0835090080654,
            "rating_q975": 1435.2245604595191,
            "rating_q025": 1422.9424575566118
        },
        "qwen-max-2025-08-15": {
            "rating": 1428.9845440105557,
            "rating_q975": 1437.1716133367547,
            "rating_q025": 1420.797474684357
        },
        "deepseek-r1-0528": {
            "rating": 1424.3669811230845,
            "rating_q975": 1429.80127039741,
            "rating_q025": 1418.932691848759
        },
        "grok-3-preview-02-24": {
            "rating": 1423.1029663770807,
            "rating_q975": 1427.1902054613452,
            "rating_q025": 1419.015727292816
        },
        "gpt-5-high": {
            "rating": 1420.910740549526,
            "rating_q975": 1427.3306723613784,
            "rating_q025": 1414.4908087376737
        },
        "o3-2025-04-16": {
            "rating": 1420.7282166569546,
            "rating_q975": 1425.0515388407653,
            "rating_q025": 1416.404894473144
        },
        "deepseek-v3.1": {
            "rating": 1417.7252859443245,
            "rating_q975": 1426.2232534146456,
            "rating_q025": 1409.2273184740034
        },
        "claude-opus-4-1-20250805-thinking-16k": {
            "rating": 1416.5721133786938,
            "rating_q975": 1423.3444127898342,
            "rating_q025": 1409.7998139675533
        },
        "gpt-4.5-preview-2025-02-27": {
            "rating": 1415.63200046145,
            "rating_q975": 1421.0795501102448,
            "rating_q025": 1410.1844508126553
        },
        "qwen3-235b-a22b-thinking-2507": {
            "rating": 1415.390241792794,
            "rating_q975": 1422.0218058891078,
            "rating_q025": 1408.7586776964806
        },
        "qwen3-235b-a22b-instruct-2507": {
            "rating": 1414.389126513848,
            "rating_q975": 1420.1532927857174,
            "rating_q025": 1408.6249602419782
        },
        "deepseek-v3.1-thinking": {
            "rating": 1412.9126325308996,
            "rating_q975": 1421.9483972568196,
            "rating_q025": 1403.8768678049798
        },
        "gpt-5-chat": {
            "rating": 1408.975058808343,
            "rating_q975": 1415.700335954689,
            "rating_q025": 1402.2497816619966
        },
        "gemini-2.5-flash": {
            "rating": 1408.8813986353036,
            "rating_q975": 1413.4798045863415,
            "rating_q025": 1404.282992684266
        },
        "claude-opus-4-1-20250805": {
            "rating": 1406.3414807646886,
            "rating_q975": 1412.6507593077438,
            "rating_q025": 1400.0322022216335
        },
        "gpt-5-old": {
            "rating": 1405.8885541662894,
            "rating_q975": 1426.6655864485938,
            "rating_q025": 1385.111521883985
        },
        "mai-1-preview": {
            "rating": 1403.0412199362547,
            "rating_q975": 1411.6661913224166,
            "rating_q025": 1394.4162485500929
        },
        "hunyuan-t1-20250711": {
            "rating": 1399.1062230899572,
            "rating_q975": 1406.8581864531457,
            "rating_q025": 1391.3542597267685
        },
        "qwen3-235b-a22b-no-thinking": {
            "rating": 1391.6429206661337,
            "rating_q975": 1396.580064197283,
            "rating_q025": 1386.7057771349844
        },
        "glm-4.5-air": {
            "rating": 1389.858268635106,
            "rating_q975": 1396.0874830794712,
            "rating_q025": 1383.6290541907408
        },
        "qwen-vl-max-2025-08-13": {
            "rating": 1381.4353615018529,
            "rating_q975": 1396.4218676409348,
            "rating_q025": 1366.448855362771
        },
        "qwen3-30b-a3b-instruct-2507": {
            "rating": 1381.0765351051687,
            "rating_q975": 1387.602369196121,
            "rating_q025": 1374.5507010142167
        },
        "gpt-4.1-2025-04-14": {
            "rating": 1380.652017373763,
            "rating_q975": 1385.2967732049021,
            "rating_q025": 1376.0072615426243
        },
        "kimi-k2-0711-preview": {
            "rating": 1379.3329635518317,
            "rating_q975": 1384.573141668225,
            "rating_q025": 1374.0927854354381
        },
        "gpt-5-mini-high": {
            "rating": 1377.0750011160362,
            "rating_q975": 1384.3858578587842,
            "rating_q025": 1369.7641443732884
        },
        "deepseek-v3-0324": {
            "rating": 1376.6457671463797,
            "rating_q975": 1380.975623114886,
            "rating_q025": 1372.3159111778737
        },
        "hunyuan-turbos-20250416": {
            "rating": 1376.3669620546552,
            "rating_q975": 1382.4976330588959,
            "rating_q025": 1370.2362910504146
        },
        "deepseek-r1": {
            "rating": 1373.190254672511,
            "rating_q975": 1377.8175382908976,
            "rating_q025": 1368.562971054124
        },
        "claude-opus-4-20250514-thinking-16k": {
            "rating": 1371.7294770778094,
            "rating_q975": 1376.789526562527,
            "rating_q025": 1366.6694275930915
        },
        "mistral-medium-2505": {
            "rating": 1371.1452676780593,
            "rating_q975": 1375.8521139870359,
            "rating_q025": 1366.438421369083
        },
        "qwen3-235b-a22b": {
            "rating": 1368.0048933107191,
            "rating_q975": 1372.7685128831058,
            "rating_q025": 1363.2412737383324
        },
        "qwen2.5-max": {
            "rating": 1366.8007247276162,
            "rating_q975": 1370.6542608771279,
            "rating_q025": 1362.9471885781045
        },
        "grok-3-mini-high": {
            "rating": 1366.4321629264762,
            "rating_q975": 1371.9567838746048,
            "rating_q025": 1360.9075419783476
        },
        "gpt-oss-120b": {
            "rating": 1365.960115714145,
            "rating_q975": 1372.842749325276,
            "rating_q025": 1359.0774821030143
        },
        "o1-2024-12-17": {
            "rating": 1365.9353513239232,
            "rating_q975": 1370.1587766418954,
            "rating_q025": 1361.7119260059508
        },
        "grok-3-mini-beta": {
            "rating": 1364.9835834309101,
            "rating_q975": 1370.1324768118893,
            "rating_q025": 1359.8346900499312
        },
        "claude-opus-4-20250514": {
            "rating": 1362.4424517747946,
            "rating_q975": 1367.3695665267976,
            "rating_q025": 1357.5153370227913
        },
        "o4-mini-2025-04-16": {
            "rating": 1359.020902481086,
            "rating_q975": 1363.6557460605927,
            "rating_q025": 1354.3860589015796
        },
        "step-3": {
            "rating": 1359.009847582963,
            "rating_q975": 1369.177363328709,
            "rating_q025": 1348.842331837217
        },
        "gemma-3-27b-it": {
            "rating": 1358.3955692803715,
            "rating_q975": 1362.4483571984422,
            "rating_q025": 1354.342781362301
        },
        "gemini-2.0-flash-001": {
            "rating": 1358.1537148544166,
            "rating_q975": 1361.8544852460436,
            "rating_q025": 1354.4529444627897
        },
        "qwen3-coder-480b-a35b-instruct": {
            "rating": 1354.4257890589,
            "rating_q975": 1360.3370055314938,
            "rating_q025": 1348.5145725863058
        },
        "o1-preview": {
            "rating": 1353.8539566855077,
            "rating_q975": 1358.5089986498335,
            "rating_q025": 1349.1989147211818
        },
        "minimax-m1": {
            "rating": 1349.8295586822455,
            "rating_q975": 1354.896648384536,
            "rating_q025": 1344.762468979955
        },
        "claude-sonnet-4-20250514-thinking-32k": {
            "rating": 1347.959476517151,
            "rating_q975": 1353.0871337472834,
            "rating_q025": 1342.8318192870188
        },
        "qwen3-32b": {
            "rating": 1342.167437107052,
            "rating_q975": 1351.3733996143228,
            "rating_q025": 1332.961474599781
        },
        "gpt-4.1-mini-2025-04-14": {
            "rating": 1341.5091474567093,
            "rating_q975": 1346.1572122615405,
            "rating_q025": 1336.861082651878
        },
        "mistral-small-2506": {
            "rating": 1341.058794724784,
            "rating_q975": 1346.557434089504,
            "rating_q025": 1335.560155360064
        },
        "step-1o-turbo-202506": {
            "rating": 1339.1615218371865,
            "rating_q975": 1345.5815291415975,
            "rating_q025": 1332.7415145327757
        },
        "nvidia-llama-3.3-nemotron-super-49b-v1.5": {
            "rating": 1338.9873452238867,
            "rating_q975": 1348.2830841409545,
            "rating_q025": 1329.691606306819
        },
        "o3-mini-high": {
            "rating": 1338.3248566404127,
            "rating_q975": 1343.3358149638243,
            "rating_q025": 1333.313898317001
        },
        "gemma-3-12b-it": {
            "rating": 1335.3304642871612,
            "rating_q975": 1344.5549251022537,
            "rating_q025": 1326.1060034720686
        },
        "deepseek-v3": {
            "rating": 1334.149395011491,
            "rating_q975": 1338.6197234224223,
            "rating_q025": 1329.6790666005595
        },
        "claude-sonnet-4-20250514": {
            "rating": 1333.750019442709,
            "rating_q975": 1338.7793098894654,
            "rating_q025": 1328.7207289959522
        },
        "qwq-32b": {
            "rating": 1333.1043906834145,
            "rating_q975": 1337.6111718382135,
            "rating_q025": 1328.5976095286157
        },
        "gpt-5-nano-high": {
            "rating": 1332.6650055714338,
            "rating_q975": 1341.1128497239179,
            "rating_q025": 1324.2171614189497
        },
        "glm-4-plus-0111": {
            "rating": 1332.4110567233295,
            "rating_q975": 1340.5513501028624,
            "rating_q025": 1324.2707633437963
        },
        "gemini-2.0-flash-lite-preview-02-05": {
            "rating": 1330.8463804815503,
            "rating_q975": 1334.9380366017954,
            "rating_q025": 1326.7547243613053
        },
        "glm-4.5v": {
            "rating": 1328.0078804015486,
            "rating_q975": 1344.0538286138574,
            "rating_q025": 1311.96193218924
        },
        "qwen-plus-0125": {
            "rating": 1327.903612175644,
            "rating_q975": 1336.0349884030923,
            "rating_q025": 1319.7722359481957
        },
        "command-a-03-2025": {
            "rating": 1327.4481396996455,
            "rating_q975": 1331.5421105643875,
            "rating_q025": 1323.3541688349035
        },
        "amazon-nova-experimental-chat-05-14": {
            "rating": 1326.6051503443932,
            "rating_q975": 1331.786909467308,
            "rating_q025": 1321.4233912214784
        },
        "step-2-16k-exp-202412": {
            "rating": 1321.4115650745046,
            "rating_q975": 1329.6061677416862,
            "rating_q025": 1313.2169624073229
        },
        "o3-mini": {
            "rating": 1321.38074706757,
            "rating_q975": 1324.9745042355144,
            "rating_q025": 1317.7869898996257
        },
        "qwen3-30b-a3b": {
            "rating": 1321.1938733711484,
            "rating_q975": 1326.0005665249007,
            "rating_q025": 1316.3871802173958
        },
        "llama-3.1-nemotron-ultra-253b-v1": {
            "rating": 1320.7845018895569,
            "rating_q975": 1332.1260924805072,
            "rating_q025": 1309.4429112986065
        },
        "gemini-1.5-pro-002": {
            "rating": 1320.4794058644725,
            "rating_q975": 1323.5063256369633,
            "rating_q025": 1317.4524860919814
        },
        "hunyuan-turbos-20250226": {
            "rating": 1320.3852544104934,
            "rating_q975": 1331.3348381699689,
            "rating_q025": 1309.4356706510177
        },
        "o1-mini": {
            "rating": 1319.0739423954149,
            "rating_q975": 1322.358665972428,
            "rating_q025": 1315.7892188184017
        },
        "claude-3-7-sonnet-20250219-thinking-32k": {
            "rating": 1316.012331811221,
            "rating_q975": 1320.235335064233,
            "rating_q025": 1311.7893285582093
        },
        "hunyuan-turbo-0110": {
            "rating": 1314.258498017147,
            "rating_q975": 1325.0137593571505,
            "rating_q025": 1303.5032366771434
        },
        "llama-3.3-nemotron-49b-super-v1": {
            "rating": 1310.3007515015859,
            "rating_q975": 1321.7872247965,
            "rating_q025": 1298.8142782066718
        },
        "gemma-3n-e4b-it": {
            "rating": 1307.4313899848707,
            "rating_q975": 1312.841613615323,
            "rating_q025": 1302.0211663544185
        },
        "gpt-oss-20b": {
            "rating": 1307.3530229799078,
            "rating_q975": 1314.4663793398038,
            "rating_q025": 1300.2396666200118
        },
        "grok-2-2024-08-13": {
            "rating": 1306.265491328891,
            "rating_q975": 1309.5497680713506,
            "rating_q025": 1302.9812145864314
        },
        "yi-lightning": {
            "rating": 1303.8196925004158,
            "rating_q975": 1308.380175834834,
            "rating_q025": 1299.259209165998
        },
        "gpt-4o-2024-05-13": {
            "rating": 1302.7000862172588,
            "rating_q975": 1305.7528028907113,
            "rating_q025": 1299.6473695438065
        },
        "qwen2.5-plus-1127": {
            "rating": 1301.1051724818926,
            "rating_q975": 1307.1243719624283,
            "rating_q025": 1295.0859730013572
        },
        "claude-3-7-sonnet-20250219": {
            "rating": 1300.5939796274545,
            "rating_q975": 1304.4936046105454,
            "rating_q025": 1296.6943546443638
        },
        "claude-3-5-sonnet-20241022": {
            "rating": 1299.7314918218146,
            "rating_q975": 1302.6118922734474,
            "rating_q025": 1296.8510913701818
        },
        "deepseek-v2.5-1210": {
            "rating": 1296.1654129340282,
            "rating_q975": 1303.9798236274412,
            "rating_q025": 1288.351002240615
        },
        "athene-v2-chat": {
            "rating": 1294.0165295755778,
            "rating_q975": 1298.2428481363065,
            "rating_q025": 1289.7902110148489
        },
        "gemma-3-4b-it": {
            "rating": 1293.3101140666447,
            "rating_q975": 1302.388758855136,
            "rating_q025": 1284.2314692781533
        },
        "glm-4-plus": {
            "rating": 1292.1991884062206,
            "rating_q975": 1296.7661072210385,
            "rating_q025": 1287.6322695914027
        },
        "hunyuan-large-2025-02-10": {
            "rating": 1291.0493797476022,
            "rating_q975": 1300.636417307891,
            "rating_q025": 1281.4623421873134
        },
        "gemini-1.5-flash-002": {
            "rating": 1290.031973111556,
            "rating_q975": 1293.889693721523,
            "rating_q025": 1286.1742525015893
        },
        "gpt-4o-mini-2024-07-18": {
            "rating": 1289.172561844771,
            "rating_q975": 1292.325126918178,
            "rating_q025": 1286.0199967713638
        },
        "llama-4-maverick-17b-128e-instruct": {
            "rating": 1288.0478900949752,
            "rating_q975": 1292.628276351254,
            "rating_q025": 1283.4675038386963
        },
        "gpt-4.1-nano-2025-04-14": {
            "rating": 1287.5027256081469,
            "rating_q975": 1295.0575674768684,
            "rating_q025": 1279.9478837394252
        },
        "llama-3.1-405b-instruct-bf16": {
            "rating": 1286.494778823677,
            "rating_q975": 1289.867248640198,
            "rating_q025": 1283.122309007156
        },
        "gpt-4o-2024-08-06": {
            "rating": 1285.5243209687944,
            "rating_q975": 1289.3472034169993,
            "rating_q025": 1281.7014385205896
        },
        "llama-3.1-nemotron-70b-instruct": {
            "rating": 1285.3368167462722,
            "rating_q975": 1292.7320650079632,
            "rating_q025": 1277.941568484581
        },
        "qwen-max-0919": {
            "rating": 1284.8538447418282,
            "rating_q975": 1290.1721778489389,
            "rating_q025": 1279.5355116347173
        },
        "llama-3.1-405b-instruct-fp8": {
            "rating": 1284.8038319543575,
            "rating_q975": 1287.9835709243162,
            "rating_q025": 1281.6240929843987
        },
        "grok-2-mini-2024-08-13": {
            "rating": 1283.7016659647534,
            "rating_q975": 1287.0420968296946,
            "rating_q025": 1280.3612350998117
        },
        "claude-3-5-sonnet-20240620": {
            "rating": 1283.5550439482463,
            "rating_q975": 1286.595435433108,
            "rating_q025": 1280.5146524633844
        },
        "gemini-advanced-0514": {
            "rating": 1281.120149293267,
            "rating_q975": 1285.997622106952,
            "rating_q025": 1276.2426764795823
        },
        "llama-4-scout-17b-16e-instruct": {
            "rating": 1281.0069515313676,
            "rating_q975": 1286.22121459442,
            "rating_q025": 1275.7926884683154
        },
        "llama-3.3-70b-instruct": {
            "rating": 1278.472867347656,
            "rating_q975": 1281.7818127958183,
            "rating_q025": 1275.1639218994935
        },
        "mistral-small-3.1-24b-instruct-2503": {
            "rating": 1277.5819038454965,
            "rating_q975": 1282.8781449837431,
            "rating_q025": 1272.28566270725
        },
        "gemini-1.5-pro-001": {
            "rating": 1276.9256227159324,
            "rating_q975": 1280.5550137136374,
            "rating_q025": 1273.2962317182273
        },
        "hunyuan-standard-2025-02-10": {
            "rating": 1276.5837697457073,
            "rating_q975": 1286.1020858926286,
            "rating_q025": 1267.0654535987858
        },
        "gpt-4-turbo-2024-04-09": {
            "rating": 1275.2455357809058,
            "rating_q975": 1278.7738218390098,
            "rating_q025": 1271.7172497228019
        },
        "deepseek-v2.5": {
            "rating": 1274.9858926169215,
            "rating_q975": 1279.2885575500407,
            "rating_q025": 1270.6832276838022
        },
        "qwen2.5-72b-instruct": {
            "rating": 1272.8351916758909,
            "rating_q975": 1276.5563920157028,
            "rating_q025": 1269.113991336079
        },
        "mistral-large-2407": {
            "rating": 1269.9152954613655,
            "rating_q975": 1273.4633510608674,
            "rating_q025": 1266.3672398618637
        },
        "hunyuan-large-vision": {
            "rating": 1269.37320439088,
            "rating_q975": 1278.240462918749,
            "rating_q025": 1260.5059458630103
        },
        "mistral-large-2411": {
            "rating": 1269.1235089151596,
            "rating_q975": 1273.2708435432278,
            "rating_q025": 1264.9761742870917
        },
        "athene-70b-0725": {
            "rating": 1268.4389148414327,
            "rating_q975": 1273.71814659882,
            "rating_q025": 1263.1596830840454
        },
        "gpt-4-1106-preview": {
            "rating": 1267.073818686441,
            "rating_q975": 1270.586626447699,
            "rating_q025": 1263.5610109251827
        },
        "gpt-4-0125-preview": {
            "rating": 1266.3518715897126,
            "rating_q975": 1270.095622934926,
            "rating_q025": 1262.6081202444993
        },
        "claude-3-opus-20240229": {
            "rating": 1265.8074718058224,
            "rating_q975": 1268.446815147131,
            "rating_q025": 1263.1681284645138
        },
        "llama-3.1-70b-instruct": {
            "rating": 1265.1233638266858,
            "rating_q975": 1268.4494962408705,
            "rating_q025": 1261.7972314125009
        },
        "amazon-nova-pro-v1.0": {
            "rating": 1261.978687450495,
            "rating_q975": 1266.243549079173,
            "rating_q025": 1257.7138258218174
        },
        "llama-3.1-tulu-3-70b": {
            "rating": 1260.1324414476485,
            "rating_q975": 1270.2105534870577,
            "rating_q025": 1250.054329408239
        },
        "claude-3-5-haiku-20241022": {
            "rating": 1256.4088959529067,
            "rating_q975": 1259.5719167140596,
            "rating_q025": 1253.2458751917536
        },
        "magistral-medium-2506": {
            "rating": 1254.4031962916415,
            "rating_q975": 1261.2715751828891,
            "rating_q025": 1247.5348174003934
        },
        "reka-core-20240904": {
            "rating": 1252.1869887118,
            "rating_q975": 1258.7512163806912,
            "rating_q025": 1245.622761042909
        },
        "gemini-1.5-flash-001": {
            "rating": 1243.6037546761063,
            "rating_q975": 1247.7333614307688,
            "rating_q025": 1239.474147921444
        },
        "jamba-1.5-large": {
            "rating": 1242.0020560002636,
            "rating_q975": 1248.9463250863946,
            "rating_q025": 1235.0577869141327
        },
        "mistral-small-24b-instruct-2501": {
            "rating": 1238.5621311417763,
            "rating_q975": 1244.1886309106455,
            "rating_q025": 1232.9356313729072
        },
        "gemma-2-27b-it": {
            "rating": 1236.107702540182,
            "rating_q975": 1239.105985877124,
            "rating_q025": 1233.1094192032397
        },
        "qwen2.5-coder-32b-instruct": {
            "rating": 1235.1499959151995,
            "rating_q975": 1242.829872755013,
            "rating_q025": 1227.470119075386
        },
        "command-r-plus-08-2024": {
            "rating": 1233.6967076897395,
            "rating_q975": 1239.8616795928758,
            "rating_q025": 1227.5317357866033
        },
        "amazon-nova-lite-v1.0": {
            "rating": 1233.5435881660924,
            "rating_q975": 1238.3715643193332,
            "rating_q025": 1228.7156120128516
        },
        "gemma-2-9b-it-simpo": {
            "rating": 1233.149976881823,
            "rating_q975": 1239.667675995296,
            "rating_q025": 1226.6322777683501
        },
        "llama-3.1-nemotron-51b-instruct": {
            "rating": 1231.8537325252091,
            "rating_q975": 1241.5002194798174,
            "rating_q025": 1222.2072455706011
        },
        "gemini-1.5-flash-8b-001": {
            "rating": 1231.379054780939,
            "rating_q975": 1235.3033462751112,
            "rating_q025": 1227.454763286767
        },
        "glm-4-0520": {
            "rating": 1230.898975435845,
            "rating_q975": 1237.6067519643261,
            "rating_q025": 1224.1911989073637
        },
        "nemotron-4-340b-instruct": {
            "rating": 1229.513776831032,
            "rating_q975": 1234.5205879082087,
            "rating_q025": 1224.506965753855
        },
        "c4ai-aya-expanse-32b": {
            "rating": 1229.3492546968096,
            "rating_q975": 1233.8765862188545,
            "rating_q025": 1224.8219231747646
        },
        "reka-flash-20240904": {
            "rating": 1224.9778306600824,
            "rating_q975": 1231.4212109460884,
            "rating_q025": 1218.5344503740764
        },
        "llama-3-70b-instruct": {
            "rating": 1224.9466196011142,
            "rating_q975": 1228.2182183252266,
            "rating_q025": 1221.6750208770015
        },
        "olmo-2-0325-32b-instruct": {
            "rating": 1223.7296936805487,
            "rating_q975": 1234.252194067601,
            "rating_q025": 1213.2071932934962
        },
        "claude-3-sonnet-20240229": {
            "rating": 1223.0814166413957,
            "rating_q975": 1226.7858693575656,
            "rating_q025": 1219.3769639252257
        },
        "phi-4": {
            "rating": 1222.5848583256243,
            "rating_q975": 1226.8973756737205,
            "rating_q025": 1218.2723409775285
        },
        "amazon-nova-micro-v1.0": {
            "rating": 1215.0706573248478,
            "rating_q975": 1219.8725403778365,
            "rating_q025": 1210.2687742718592
        },
        "gemma-2-9b-it": {
            "rating": 1213.1643043935535,
            "rating_q975": 1216.6106042434747,
            "rating_q025": 1209.7180045436323
        },
        "gpt-4-0314": {
            "rating": 1210.7411287694322,
            "rating_q975": 1215.2826203425068,
            "rating_q025": 1206.1996371963576
        },
        "command-r-plus": {
            "rating": 1209.3792447862006,
            "rating_q975": 1213.4094113047859,
            "rating_q025": 1205.3490782676156
        },
        "hunyuan-standard-256k": {
            "rating": 1209.0973761363634,
            "rating_q975": 1220.1687419699417,
            "rating_q025": 1198.026010302785
        },
        "qwen2-72b-instruct": {
            "rating": 1208.6456293667725,
            "rating_q975": 1213.2652322420436,
            "rating_q025": 1204.0260264915014
        },
        "claude-3-haiku-20240307": {
            "rating": 1200.7873967161377,
            "rating_q975": 1204.1653333351205,
            "rating_q025": 1197.4094600971546
        },
        "llama-3.1-tulu-3-8b": {
            "rating": 1200.0329918958823,
            "rating_q975": 1210.1591996279722,
            "rating_q025": 1189.906784163792
        },
        "ministral-8b-2410": {
            "rating": 1198.5234640187314,
            "rating_q975": 1207.115325191591,
            "rating_q025": 1189.9316028458716
        },
        "deepseek-coder-v2": {
            "rating": 1196.9251701952096,
            "rating_q975": 1203.0114920049928,
            "rating_q025": 1190.8388483854264
        },
        "command-r-08-2024": {
            "rating": 1195.5482630279043,
            "rating_q975": 1201.6468901171227,
            "rating_q025": 1189.449635938686
        },
        "c4ai-aya-expanse-8b": {
            "rating": 1193.567624554837,
            "rating_q975": 1200.140975874841,
            "rating_q025": 1186.9942732348336
        },
        "llama-3.1-8b-instruct": {
            "rating": 1193.5124798763727,
            "rating_q975": 1197.234645712358,
            "rating_q025": 1189.790314040387
        },
        "jamba-1.5-mini": {
            "rating": 1193.493914655606,
            "rating_q975": 1200.310772479576,
            "rating_q025": 1186.6770568316363
        },
        "gpt-4-0613": {
            "rating": 1191.6959816108179,
            "rating_q975": 1195.4724897982805,
            "rating_q025": 1187.9194734233552
        },
        "mistral-large-2402": {
            "rating": 1181.6678785346417,
            "rating_q975": 1186.1179641686083,
            "rating_q025": 1177.217792900675
        },
        "qwen1.5-110b-chat": {
            "rating": 1180.6404509939528,
            "rating_q975": 1185.880882954154,
            "rating_q025": 1175.4000190337517
        },
        "yi-1.5-34b-chat": {
            "rating": 1178.4938400779006,
            "rating_q975": 1183.2353417507827,
            "rating_q025": 1173.7523384050182
        },
        "reka-flash-21b-20240226-online": {
            "rating": 1176.8980369255946,
            "rating_q975": 1183.9905821006494,
            "rating_q025": 1169.8054917505399
        },
        "qwen1.5-72b-chat": {
            "rating": 1172.379360120032,
            "rating_q975": 1177.3516537320245,
            "rating_q025": 1167.4070665080396
        },
        "llama-3-8b-instruct": {
            "rating": 1171.6359059359274,
            "rating_q975": 1175.0407159723654,
            "rating_q025": 1168.2310958994897
        },
        "mistral-medium": {
            "rating": 1171.27729384259,
            "rating_q975": 1176.4993360837782,
            "rating_q025": 1166.0552516014022
        },
        "reka-flash-21b-20240226": {
            "rating": 1171.165048112255,
            "rating_q975": 1176.8223009356736,
            "rating_q025": 1165.5077952888362
        },
        "qwq-32b-preview": {
            "rating": 1170.8455163227195,
            "rating_q975": 1181.8170447597379,
            "rating_q025": 1159.8739878857011
        },
        "command-r": {
            "rating": 1169.8678889907178,
            "rating_q975": 1174.3507688611353,
            "rating_q025": 1165.3850091203005
        },
        "internlm2_5-20b-chat": {
            "rating": 1168.68480500759,
            "rating_q975": 1175.3476408265942,
            "rating_q025": 1162.0219691885861
        },
        "mixtral-8x22b-instruct-v0.1": {
            "rating": 1168.1050152901466,
            "rating_q975": 1172.3332563244726,
            "rating_q025": 1163.8767742558207
        },
        "gemma-2-2b-it": {
            "rating": 1163.8044741937927,
            "rating_q975": 1167.4981810034974,
            "rating_q025": 1160.110767384088
        },
        "granite-3.1-8b-instruct": {
            "rating": 1158.3426219774917,
            "rating_q975": 1168.6999813498771,
            "rating_q025": 1147.9852626051065
        },
        "gemini-pro-dev-api": {
            "rating": 1155.3326519729526,
            "rating_q975": 1162.3933827665521,
            "rating_q025": 1148.2719211793533
        },
        "zephyr-orpo-141b-A35b-v0.1": {
            "rating": 1150.7608888748198,
            "rating_q975": 1161.246624859782,
            "rating_q025": 1140.2751528898573
        },
        "qwen1.5-32b-chat": {
            "rating": 1144.745310737268,
            "rating_q975": 1150.5622834125163,
            "rating_q025": 1138.9283380620197
        },
        "phi-3-medium-4k-instruct": {
            "rating": 1144.2104105406588,
            "rating_q975": 1149.0460397327138,
            "rating_q025": 1139.3747813486036
        },
        "starling-lm-7b-beta": {
            "rating": 1139.3806607174017,
            "rating_q975": 1146.4740214276544,
            "rating_q025": 1132.287300007149
        },
        "mixtral-8x7b-instruct-v0.1": {
            "rating": 1138.5957955514928,
            "rating_q975": 1142.5804781418167,
            "rating_q025": 1134.611112961169
        },
        "gemini-pro": {
            "rating": 1137.843328444053,
            "rating_q975": 1149.1766343399042,
            "rating_q025": 1126.5100225482017
        },
        "granite-3.1-2b-instruct": {
            "rating": 1136.2650662898113,
            "rating_q975": 1146.8451551246553,
            "rating_q025": 1125.684977454967
        },
        "qwen1.5-14b-chat": {
            "rating": 1135.558464296681,
            "rating_q975": 1142.3194116417544,
            "rating_q025": 1128.7975169516078
        },
        "yi-34b-chat": {
            "rating": 1134.7929958187938,
            "rating_q975": 1141.389292514767,
            "rating_q025": 1128.1966991228207
        },
        "gpt-3.5-turbo-0125": {
            "rating": 1132.2843584462576,
            "rating_q975": 1136.7062612687944,
            "rating_q025": 1127.862455623721
        },
        "tulu-2-dpo-70b": {
            "rating": 1127.7639346077658,
            "rating_q975": 1137.3858133609185,
            "rating_q025": 1118.142055854613
        },
        "dbrx-instruct-preview": {
            "rating": 1126.3437979777123,
            "rating_q975": 1132.1337720059535,
            "rating_q025": 1120.553823949471
        },
        "wizardlm-70b": {
            "rating": 1126.1316673339775,
            "rating_q975": 1135.4128775296056,
            "rating_q025": 1116.8504571383492
        },
        "llama-2-70b-chat": {
            "rating": 1122.5484786863478,
            "rating_q975": 1127.8261286325132,
            "rating_q025": 1117.2708287401822
        },
        "nous-hermes-2-mixtral-8x7b-dpo": {
            "rating": 1119.65214466873,
            "rating_q975": 1131.3960909926702,
            "rating_q025": 1107.9081983447898
        },
        "llama-3.2-3b-instruct": {
            "rating": 1118.1163530112908,
            "rating_q975": 1125.322912064451,
            "rating_q025": 1110.9097939581304
        },
        "phi-3-small-8k-instruct": {
            "rating": 1117.5661375070736,
            "rating_q975": 1123.163010465989,
            "rating_q025": 1111.9692645481584
        },
        "starling-lm-7b-alpha": {
            "rating": 1114.6693148727215,
            "rating_q975": 1122.4840577593102,
            "rating_q025": 1106.854571986133
        },
        "openchat-3.5-0106": {
            "rating": 1114.2479626863292,
            "rating_q975": 1122.0260570880096,
            "rating_q025": 1106.4698682846486
        },
        "vicuna-33b": {
            "rating": 1113.0696670255204,
            "rating_q975": 1119.036930251604,
            "rating_q025": 1107.1024037994368
        },
        "deepseek-llm-67b-chat": {
            "rating": 1111.3496484676562,
            "rating_q975": 1122.906194504072,
            "rating_q025": 1099.7931024312406
        },
        "snowflake-arctic-instruct": {
            "rating": 1109.2578720419342,
            "rating_q975": 1114.8738201441217,
            "rating_q025": 1103.6419239397467
        },
        "granite-3.0-8b-instruct": {
            "rating": 1108.1564761559457,
            "rating_q975": 1116.2962727858612,
            "rating_q025": 1100.01667952603
        },
        "llama2-70b-steerlm-chat": {
            "rating": 1106.147935506676,
            "rating_q975": 1118.6179903497202,
            "rating_q025": 1093.6778806636319
        },
        "openchat-3.5": {
            "rating": 1103.5125245945655,
            "rating_q975": 1113.0870370888379,
            "rating_q025": 1093.938012100293
        },
        "gemma-1.1-7b-it": {
            "rating": 1102.932194401009,
            "rating_q975": 1108.6948682666696,
            "rating_q025": 1097.1695205353485
        },
        "gpt-3.5-turbo-1106": {
            "rating": 1100.943641410153,
            "rating_q975": 1109.5536695938224,
            "rating_q025": 1092.3336132264837
        },
        "openhermes-2.5-mistral-7b": {
            "rating": 1100.6130744097443,
            "rating_q975": 1110.8703321101561,
            "rating_q025": 1090.3558167093327
        },
        "mistral-7b-instruct-v0.2": {
            "rating": 1097.4542504795645,
            "rating_q975": 1103.8122008493426,
            "rating_q025": 1091.0963001097864
        },
        "llama-2-13b-chat": {
            "rating": 1093.0204930105729,
            "rating_q975": 1099.4929680488783,
            "rating_q025": 1086.5480179722672
        },
        "solar-10.7b-instruct-v1.0": {
            "rating": 1091.933775619269,
            "rating_q975": 1104.9255097027597,
            "rating_q025": 1078.9420415357786
        },
        "granite-3.0-2b-instruct": {
            "rating": 1091.0858838053564,
            "rating_q975": 1098.9092729719296,
            "rating_q025": 1083.2624946387834
        },
        "qwen1.5-7b-chat": {
            "rating": 1090.5134333043552,
            "rating_q975": 1100.069061183635,
            "rating_q025": 1080.957805425075
        },
        "dolphin-2.2.1-mistral-7b": {
            "rating": 1088.740210836792,
            "rating_q975": 1104.134136402861,
            "rating_q025": 1073.3462852707232
        },
        "phi-3-mini-4k-instruct-june-2024": {
            "rating": 1088.4365255412908,
            "rating_q975": 1094.4685049288616,
            "rating_q025": 1082.40454615372
        },
        "wizardlm-13b": {
            "rating": 1084.5938503199818,
            "rating_q975": 1093.8369964552617,
            "rating_q025": 1075.3507041847017
        },
        "phi-3-mini-4k-instruct": {
            "rating": 1082.1966432448253,
            "rating_q975": 1088.2015358377366,
            "rating_q025": 1076.191750651914
        },
        "zephyr-7b-beta": {
            "rating": 1076.745333150959,
            "rating_q975": 1085.4047635834545,
            "rating_q025": 1068.0859027184633
        },
        "mpt-30b-chat": {
            "rating": 1076.3059570735418,
            "rating_q975": 1088.400075222919,
            "rating_q025": 1064.211838924165
        },
        "codellama-34b-instruct": {
            "rating": 1073.2664100791947,
            "rating_q975": 1081.955639137065,
            "rating_q025": 1064.5771810213243
        },
        "llama-3.2-1b-instruct": {
            "rating": 1067.4348646816593,
            "rating_q975": 1074.7243872723045,
            "rating_q025": 1060.145342091014
        },
        "zephyr-7b-alpha": {
            "rating": 1066.536492384653,
            "rating_q975": 1082.4197733874048,
            "rating_q025": 1050.6532113819012
        },
        "vicuna-13b": {
            "rating": 1066.3703784298866,
            "rating_q975": 1072.8452599482557,
            "rating_q025": 1059.8954969115175
        },
        "codellama-70b-instruct": {
            "rating": 1066.3008218869104,
            "rating_q975": 1084.096483216591,
            "rating_q025": 1048.5051605572296
        },
        "gemma-7b-it": {
            "rating": 1063.7042996612997,
            "rating_q975": 1073.1253568143752,
            "rating_q025": 1054.2832425082245
        },
        "smollm2-1.7b-instruct": {
            "rating": 1062.298401200184,
            "rating_q975": 1075.6374267735189,
            "rating_q025": 1048.9593756268487
        },
        "falcon-180b-chat": {
            "rating": 1061.8977429972274,
            "rating_q975": 1079.0452071352286,
            "rating_q025": 1044.7502788592262
        },
        "phi-3-mini-128k-instruct": {
            "rating": 1061.7659042653538,
            "rating_q975": 1068.7272896973636,
            "rating_q025": 1054.804518833344
        },
        "llama-2-7b-chat": {
            "rating": 1061.4206085171845,
            "rating_q975": 1068.2272591624428,
            "rating_q025": 1054.6139578719265
        },
        "guanaco-33b": {
            "rating": 1061.0340136118693,
            "rating_q975": 1073.1019098808943,
            "rating_q025": 1048.9661173428442
        },
        "qwen-14b-chat": {
            "rating": 1058.4662005891255,
            "rating_q975": 1069.3100317306926,
            "rating_q025": 1047.6223694475582
        },
        "stripedhyena-nous-7b": {
            "rating": 1045.4480231048672,
            "rating_q975": 1056.3729697808706,
            "rating_q025": 1034.5230764288635
        },
        "vicuna-7b": {
            "rating": 1039.2023409135672,
            "rating_q975": 1048.343701632765,
            "rating_q025": 1030.0609801943697
        },
        "olmo-7b-instruct": {
            "rating": 1038.29285063083,
            "rating_q975": 1049.2615933857603,
            "rating_q025": 1027.3241078758992
        },
        "palm-2": {
            "rating": 1034.8848554469107,
            "rating_q975": 1044.1181183357771,
            "rating_q025": 1025.6515925580443
        },
        "gemma-1.1-2b-it": {
            "rating": 1033.3138454560026,
            "rating_q975": 1040.7261556801063,
            "rating_q025": 1025.9015352318988
        },
        "mistral-7b-instruct": {
            "rating": 1032.2348805651636,
            "rating_q975": 1041.3596320876052,
            "rating_q025": 1023.1101290427221
        },
        "gemma-2b-it": {
            "rating": 1011.7405090671136,
            "rating_q975": 1023.1718300392724,
            "rating_q025": 1000.3091880949547
        },
        "qwen1.5-4b-chat": {
            "rating": 1006.5310446902732,
            "rating_q975": 1015.6223260444904,
            "rating_q025": 997.4397633360561
        },
        "koala-13b": {
            "rating": 997.1103921907393,
            "rating_q975": 1007.0394420840462,
            "rating_q025": 987.1813422974325
        },
        "chatglm3-6b": {
            "rating": 979.4046060892757,
            "rating_q975": 990.9353560476677,
            "rating_q025": 967.8738561308837
        },
        "mpt-7b-chat": {
            "rating": 963.8087780624705,
            "rating_q975": 975.7340062654198,
            "rating_q025": 951.8835498595213
        },
        "gpt4all-13b-snoozy": {
            "rating": 962.7941973287225,
            "rating_q975": 978.0461649313658,
            "rating_q025": 947.5422297260791
        },
        "RWKV-4-Raven-14B": {
            "rating": 956.9034024415766,
            "rating_q975": 968.3590194674604,
            "rating_q025": 945.4477854156929
        },
        "chatglm2-6b": {
            "rating": 948.2229938554055,
            "rating_q975": 961.7187756065521,
            "rating_q025": 934.7272121042589
        },
        "alpaca-13b": {
            "rating": 940.5680128136421,
            "rating_q975": 951.9910477821835,
            "rating_q025": 929.1449778451008
        },
        "chatglm-6b": {
            "rating": 926.122958516921,
            "rating_q975": 938.5910111046438,
            "rating_q025": 913.6549059291981
        },
        "oasst-pythia-12b": {
            "rating": 923.8076521949451,
            "rating_q975": 934.7641711953911,
            "rating_q025": 912.8511331944992
        },
        "fastchat-t5-3b": {
            "rating": 902.0900350924704,
            "rating_q975": 914.5270055548747,
            "rating_q025": 889.6530646300662
        },
        "stablelm-tuned-alpha-7b": {
            "rating": 874.2316116801692,
            "rating_q975": 887.2009976293707,
            "rating_q025": 861.2622257309678
        },
        "dolly-v2-12b": {
            "rating": 858.3583447807655,
            "rating_q975": 871.9988509908815,
            "rating_q025": 844.7178385706495
        },
        "llama-13b": {
            "rating": 841.3293162207231,
            "rating_q975": 857.4078851206017,
            "rating_q025": 825.2507473208445
        }
    },
    "german": {
        "gemini-2.5-pro": {
            "rating": 1471.3158586324178,
            "rating_q975": 1493.3660125529427,
            "rating_q025": 1449.2657047118928
        },
        "grok-4-0709": {
            "rating": 1457.3470726033431,
            "rating_q975": 1489.6118544490603,
            "rating_q025": 1425.0822907576257
        },
        "gpt-4.5-preview-2025-02-27": {
            "rating": 1451.3065167027871,
            "rating_q975": 1483.782555887733,
            "rating_q025": 1418.8304775178412
        },
        "qwen3-235b-a22b-instruct-2507": {
            "rating": 1444.5822984593021,
            "rating_q975": 1481.6616151123674,
            "rating_q025": 1407.502981806237
        },
        "gpt-5-chat": {
            "rating": 1438.151330229665,
            "rating_q975": 1489.186296342662,
            "rating_q025": 1387.1163641166681
        },
        "gpt-5-high": {
            "rating": 1430.4936466378854,
            "rating_q975": 1474.0187028111638,
            "rating_q025": 1386.9685904646067
        },
        "o3-2025-04-16": {
            "rating": 1426.3009962414924,
            "rating_q975": 1446.1607894881042,
            "rating_q025": 1406.4412029948805
        },
        "grok-3-preview-02-24": {
            "rating": 1423.9621378149466,
            "rating_q975": 1445.8768168564823,
            "rating_q025": 1402.047458773411
        },
        "claude-opus-4-1-20250805": {
            "rating": 1417.8367179710283,
            "rating_q975": 1461.7281140425748,
            "rating_q025": 1373.945321899482
        },
        "chatgpt-4o-latest-20250326": {
            "rating": 1417.637704564833,
            "rating_q975": 1438.6528681204531,
            "rating_q025": 1396.622541009213
        },
        "gemini-2.5-flash": {
            "rating": 1409.4180354467703,
            "rating_q975": 1428.814968028819,
            "rating_q025": 1390.0211028647213
        },
        "claude-opus-4-1-20250805-thinking-16k": {
            "rating": 1408.5086638908401,
            "rating_q975": 1454.5032381837816,
            "rating_q025": 1362.5140895978986
        },
        "glm-4.5": {
            "rating": 1401.9300315014777,
            "rating_q975": 1442.1858256045755,
            "rating_q025": 1361.6742373983802
        },
        "qwen3-235b-a22b-thinking-2507": {
            "rating": 1395.7799106927753,
            "rating_q975": 1441.507693508566,
            "rating_q025": 1350.0521278769843
        },
        "glm-4.5-air": {
            "rating": 1392.1934624598343,
            "rating_q975": 1430.927587310501,
            "rating_q025": 1353.4593376091677
        },
        "deepseek-r1-0528": {
            "rating": 1391.2671224209073,
            "rating_q975": 1416.8355580504683,
            "rating_q025": 1365.6986867913465
        },
        "qwen3-235b-a22b": {
            "rating": 1382.0470928958553,
            "rating_q975": 1405.087621938637,
            "rating_q025": 1359.0065638530737
        },
        "qwen3-235b-a22b-no-thinking": {
            "rating": 1378.612563751099,
            "rating_q975": 1400.6044468313864,
            "rating_q025": 1356.6206806708115
        },
        "deepseek-r1": {
            "rating": 1377.9985631115399,
            "rating_q975": 1405.0958252208773,
            "rating_q025": 1350.9013010022024
        },
        "mistral-medium-2505": {
            "rating": 1377.5491604755875,
            "rating_q975": 1397.52119791226,
            "rating_q025": 1357.5771230389148
        },
        "mistral-small-2506": {
            "rating": 1375.7008866779734,
            "rating_q975": 1409.628197324947,
            "rating_q025": 1341.7735760309997
        },
        "claude-opus-4-20250514-thinking-16k": {
            "rating": 1374.9466850770336,
            "rating_q975": 1400.91820074307,
            "rating_q025": 1348.9751694109975
        },
        "deepseek-v3-0324": {
            "rating": 1370.4268214019949,
            "rating_q975": 1391.6506886493398,
            "rating_q025": 1349.2029541546501
        },
        "kimi-k2-0711-preview": {
            "rating": 1369.263505317953,
            "rating_q975": 1400.4639621640615,
            "rating_q025": 1338.0630484718447
        },
        "gemma-3-12b-it": {
            "rating": 1368.534251069992,
            "rating_q975": 1410.2974879499702,
            "rating_q025": 1326.7710141900138
        },
        "claude-opus-4-20250514": {
            "rating": 1368.519835238197,
            "rating_q975": 1389.5323163828066,
            "rating_q025": 1347.5073540935878
        },
        "gpt-4.1-2025-04-14": {
            "rating": 1368.0343885176762,
            "rating_q975": 1389.0894726657675,
            "rating_q025": 1346.979304369585
        },
        "gemma-3-27b-it": {
            "rating": 1364.2196751146464,
            "rating_q975": 1384.4586065243645,
            "rating_q025": 1343.980743704928
        },
        "grok-3-mini-high": {
            "rating": 1351.9627623252518,
            "rating_q975": 1383.3545926780168,
            "rating_q025": 1320.5709319724867
        },
        "qwen3-coder-480b-a35b-instruct": {
            "rating": 1347.5708574556938,
            "rating_q975": 1389.5291822990619,
            "rating_q025": 1305.6125326123256
        },
        "gemini-2.0-flash-001": {
            "rating": 1346.6303379699384,
            "rating_q975": 1365.1085322258568,
            "rating_q025": 1328.1521437140202
        },
        "minimax-m1": {
            "rating": 1346.1371649180246,
            "rating_q975": 1372.886330605569,
            "rating_q025": 1319.3879992304805
        },
        "qwen2.5-max": {
            "rating": 1341.7079405011048,
            "rating_q975": 1362.5103851052081,
            "rating_q025": 1320.9054958970012
        },
        "hunyuan-turbos-20250416": {
            "rating": 1340.9989995028357,
            "rating_q975": 1372.935965395276,
            "rating_q025": 1309.0620336103952
        },
        "grok-3-mini-beta": {
            "rating": 1338.9909696616598,
            "rating_q975": 1365.2816731040791,
            "rating_q025": 1312.7002662192408
        },
        "gpt-4.1-mini-2025-04-14": {
            "rating": 1337.92546144727,
            "rating_q975": 1359.7406446325874,
            "rating_q025": 1316.1102782619525
        },
        "qwen3-32b": {
            "rating": 1336.5221913520886,
            "rating_q975": 1376.1903532612396,
            "rating_q025": 1296.8540294429376
        },
        "command-a-03-2025": {
            "rating": 1335.8688731079828,
            "rating_q975": 1355.4743776559653,
            "rating_q025": 1316.2633685600001
        },
        "amazon-nova-experimental-chat-05-14": {
            "rating": 1335.837456524379,
            "rating_q975": 1361.9963236910498,
            "rating_q025": 1309.6785893577082
        },
        "glm-4-plus-0111": {
            "rating": 1331.850309149817,
            "rating_q975": 1370.4688742736537,
            "rating_q025": 1293.2317440259799
        },
        "o1-2024-12-17": {
            "rating": 1329.7047009853677,
            "rating_q975": 1352.9687825849333,
            "rating_q025": 1306.4406193858024
        },
        "claude-sonnet-4-20250514": {
            "rating": 1329.543512398466,
            "rating_q975": 1352.4155765291368,
            "rating_q025": 1306.6714482677953
        },
        "o4-mini-2025-04-16": {
            "rating": 1328.361596327385,
            "rating_q975": 1350.4220716118002,
            "rating_q025": 1306.3011210429697
        },
        "qwen3-30b-a3b-instruct-2507": {
            "rating": 1328.1792668783098,
            "rating_q975": 1372.468771379704,
            "rating_q025": 1283.8897623769155
        },
        "gemma-3n-e4b-it": {
            "rating": 1322.911063640354,
            "rating_q975": 1347.6817443651007,
            "rating_q025": 1298.1403829156077
        },
        "deepseek-v3": {
            "rating": 1317.5639156417183,
            "rating_q975": 1341.8508551355344,
            "rating_q025": 1293.2769761479021
        },
        "claude-sonnet-4-20250514-thinking-32k": {
            "rating": 1312.576596137661,
            "rating_q975": 1338.4932108545522,
            "rating_q025": 1286.65998142077
        },
        "step-1o-turbo-202506": {
            "rating": 1312.5701066798135,
            "rating_q975": 1343.8281382520076,
            "rating_q025": 1281.3120751076194
        },
        "qwen3-30b-a3b": {
            "rating": 1308.19626174864,
            "rating_q975": 1331.308566757315,
            "rating_q025": 1285.0839567399648
        },
        "qwq-32b": {
            "rating": 1304.479884248983,
            "rating_q975": 1328.2362274275542,
            "rating_q025": 1280.7235410704118
        },
        "o1-preview": {
            "rating": 1303.636337810821,
            "rating_q975": 1324.1263769587522,
            "rating_q025": 1283.1462986628896
        },
        "o3-mini-high": {
            "rating": 1300.826368087752,
            "rating_q975": 1329.482833705799,
            "rating_q025": 1272.169902469705
        },
        "gemini-2.0-flash-lite-preview-02-05": {
            "rating": 1299.7413402906068,
            "rating_q975": 1321.6516175158517,
            "rating_q025": 1277.831063065362
        },
        "claude-3-7-sonnet-20250219-thinking-32k": {
            "rating": 1299.5337426568196,
            "rating_q975": 1320.2016085758817,
            "rating_q025": 1278.8658767377578
        },
        "o3-mini": {
            "rating": 1298.8563627508167,
            "rating_q975": 1317.241814904215,
            "rating_q025": 1280.4709105974182
        },
        "claude-3-5-sonnet-20241022": {
            "rating": 1291.2188411177885,
            "rating_q975": 1304.2297018021668,
            "rating_q025": 1278.2079804334105
        },
        "gpt-4.1-nano-2025-04-14": {
            "rating": 1285.465927513292,
            "rating_q975": 1321.922886212013,
            "rating_q025": 1249.0089688145708
        },
        "gemini-1.5-pro-002": {
            "rating": 1280.9796904686154,
            "rating_q975": 1296.5178000329379,
            "rating_q025": 1265.441580904293
        },
        "grok-2-2024-08-13": {
            "rating": 1280.8534959247834,
            "rating_q975": 1295.116178213127,
            "rating_q025": 1266.5908136364396
        },
        "llama-4-maverick-17b-128e-instruct": {
            "rating": 1280.2602981271186,
            "rating_q975": 1302.492856356479,
            "rating_q025": 1258.0277398977582
        },
        "gpt-4o-2024-05-13": {
            "rating": 1276.3109957482322,
            "rating_q975": 1287.6249392655604,
            "rating_q025": 1264.997052230904
        },
        "gemma-3-4b-it": {
            "rating": 1275.4060938883274,
            "rating_q975": 1316.4388979599485,
            "rating_q025": 1234.3732898167063
        },
        "claude-3-7-sonnet-20250219": {
            "rating": 1274.38962092479,
            "rating_q975": 1294.7037953280008,
            "rating_q025": 1254.0754465215791
        },
        "o1-mini": {
            "rating": 1273.7879102064232,
            "rating_q975": 1290.4714764950465,
            "rating_q025": 1257.1043439178002
        },
        "glm-4-plus": {
            "rating": 1272.9679085486778,
            "rating_q975": 1294.783046846162,
            "rating_q025": 1251.1527702511935
        },
        "gemini-advanced-0514": {
            "rating": 1268.3247368469838,
            "rating_q975": 1283.8663055686152,
            "rating_q025": 1252.7831681253524
        },
        "grok-2-mini-2024-08-13": {
            "rating": 1267.94899003594,
            "rating_q975": 1283.555149360995,
            "rating_q025": 1252.342830710885
        },
        "gpt-4o-mini-2024-07-18": {
            "rating": 1265.5885183604507,
            "rating_q975": 1279.1094273409785,
            "rating_q025": 1252.067609379923
        },
        "claude-3-5-sonnet-20240620": {
            "rating": 1264.65234162244,
            "rating_q975": 1277.3529299512118,
            "rating_q025": 1251.9517532936682
        },
        "yi-lightning": {
            "rating": 1260.9868136516893,
            "rating_q975": 1281.6577849198693,
            "rating_q025": 1240.3158423835096
        },
        "gemini-1.5-flash-002": {
            "rating": 1257.9895708720378,
            "rating_q975": 1278.243490342218,
            "rating_q025": 1237.735651401858
        },
        "athene-v2-chat": {
            "rating": 1255.5227528949922,
            "rating_q975": 1277.1143678335613,
            "rating_q025": 1233.931137956423
        },
        "gpt-4-turbo-2024-04-09": {
            "rating": 1253.9236914857738,
            "rating_q975": 1266.0863777668749,
            "rating_q025": 1241.7610052046728
        },
        "claude-3-opus-20240229": {
            "rating": 1252.1877138601112,
            "rating_q975": 1262.3417518998344,
            "rating_q025": 1242.033675820388
        },
        "gpt-4o-2024-08-06": {
            "rating": 1251.9288764497499,
            "rating_q975": 1267.990274970277,
            "rating_q025": 1235.8674779292226
        },
        "llama-4-scout-17b-16e-instruct": {
            "rating": 1251.8840077616715,
            "rating_q975": 1279.8434950422563,
            "rating_q025": 1223.9245204810868
        },
        "deepseek-v2.5-1210": {
            "rating": 1251.187785844092,
            "rating_q975": 1296.1630099142103,
            "rating_q025": 1206.2125617739741
        },
        "qwen-max-0919": {
            "rating": 1248.6579720890652,
            "rating_q975": 1273.889648147482,
            "rating_q025": 1223.4262960306485
        },
        "mistral-large-2407": {
            "rating": 1248.087954590261,
            "rating_q975": 1264.2220654786015,
            "rating_q025": 1231.9538437019203
        },
        "llama-3.1-405b-instruct-bf16": {
            "rating": 1246.7833804669017,
            "rating_q975": 1265.1333541837741,
            "rating_q025": 1228.433406750029
        },
        "athene-70b-0725": {
            "rating": 1246.5164456589098,
            "rating_q975": 1269.0086535787473,
            "rating_q025": 1224.0242377390723
        },
        "gpt-4-1106-preview": {
            "rating": 1244.7552194378445,
            "rating_q975": 1258.0430683465272,
            "rating_q025": 1231.4673705291618
        },
        "llama-3.1-405b-instruct-fp8": {
            "rating": 1244.3162695004817,
            "rating_q975": 1258.8079030846404,
            "rating_q025": 1229.8246359163231
        },
        "llama-3.3-70b-instruct": {
            "rating": 1244.015744909278,
            "rating_q975": 1261.4214286201618,
            "rating_q025": 1226.6100611983943
        },
        "gemini-1.5-pro-001": {
            "rating": 1243.1936287108747,
            "rating_q975": 1256.0261920656362,
            "rating_q025": 1230.3610653561134
        },
        "gpt-4-0125-preview": {
            "rating": 1239.4335682653145,
            "rating_q975": 1252.491443150458,
            "rating_q025": 1226.3756933801708
        },
        "reka-core-20240904": {
            "rating": 1238.5641896964678,
            "rating_q975": 1277.5037834245459,
            "rating_q025": 1199.6245959683897
        },
        "mistral-small-3.1-24b-instruct-2503": {
            "rating": 1238.2044557561112,
            "rating_q975": 1266.2596750222879,
            "rating_q025": 1210.1492364899348
        },
        "mistral-large-2411": {
            "rating": 1238.1849920913578,
            "rating_q975": 1260.0671307664463,
            "rating_q025": 1216.3028534162693
        },
        "magistral-medium-2506": {
            "rating": 1236.1975313013609,
            "rating_q975": 1272.661351407917,
            "rating_q025": 1199.7337111948048
        },
        "amazon-nova-pro-v1.0": {
            "rating": 1232.9891634898086,
            "rating_q975": 1255.5780211655617,
            "rating_q025": 1210.4003058140554
        },
        "claude-3-5-haiku-20241022": {
            "rating": 1232.811045510697,
            "rating_q975": 1248.9900358553,
            "rating_q025": 1216.6320551660942
        },
        "qwen2.5-72b-instruct": {
            "rating": 1228.452053188258,
            "rating_q975": 1246.343603090378,
            "rating_q025": 1210.5605032861379
        },
        "qwen2.5-plus-1127": {
            "rating": 1224.4406565329173,
            "rating_q975": 1258.8838866390452,
            "rating_q025": 1189.9974264267896
        },
        "amazon-nova-lite-v1.0": {
            "rating": 1223.0719311210146,
            "rating_q975": 1248.5357803596328,
            "rating_q025": 1197.608081882396
        },
        "deepseek-v2.5": {
            "rating": 1222.0399638487283,
            "rating_q975": 1245.4366016059198,
            "rating_q025": 1198.6433260915371
        },
        "phi-4": {
            "rating": 1218.2414959572488,
            "rating_q975": 1243.2774507116003,
            "rating_q025": 1193.2055412028974
        },
        "llama-3.1-70b-instruct": {
            "rating": 1216.1084047520194,
            "rating_q975": 1231.5307516147902,
            "rating_q025": 1200.6860578892488
        },
        "gemma-2-9b-it-simpo": {
            "rating": 1215.579983609698,
            "rating_q975": 1245.7477356640072,
            "rating_q025": 1185.412231555389
        },
        "gemini-1.5-flash-001": {
            "rating": 1211.0038783710734,
            "rating_q975": 1224.4299827734046,
            "rating_q025": 1197.577773968742
        },
        "command-r-plus-08-2024": {
            "rating": 1209.9180275639683,
            "rating_q975": 1242.2970414056365,
            "rating_q025": 1177.5390137223
        },
        "mistral-small-24b-instruct-2501": {
            "rating": 1206.5344954384495,
            "rating_q975": 1239.435612480323,
            "rating_q025": 1173.6333783965758
        },
        "gemma-2-27b-it": {
            "rating": 1203.9533130937646,
            "rating_q975": 1216.563327283911,
            "rating_q025": 1191.3432989036182
        },
        "claude-3-sonnet-20240229": {
            "rating": 1199.5563740677098,
            "rating_q975": 1212.4105177655933,
            "rating_q025": 1186.702230369826
        },
        "gemini-1.5-flash-8b-001": {
            "rating": 1199.5473751008453,
            "rating_q975": 1219.3364444846577,
            "rating_q025": 1179.758305717033
        },
        "jamba-1.5-large": {
            "rating": 1194.025724142843,
            "rating_q975": 1229.9789707790198,
            "rating_q025": 1158.0724775066665
        },
        "gpt-4-0314": {
            "rating": 1193.6885790259257,
            "rating_q975": 1211.0191517595604,
            "rating_q025": 1176.3580062922913
        },
        "c4ai-aya-expanse-32b": {
            "rating": 1193.546271525171,
            "rating_q975": 1216.253015773022,
            "rating_q025": 1170.8395272773203
        },
        "command-r-plus": {
            "rating": 1189.8322949225615,
            "rating_q975": 1202.9097604374167,
            "rating_q025": 1176.7548294077064
        },
        "amazon-nova-micro-v1.0": {
            "rating": 1187.1505232672334,
            "rating_q975": 1213.5014326518544,
            "rating_q025": 1160.7996138826122
        },
        "nemotron-4-340b-instruct": {
            "rating": 1187.1041342860658,
            "rating_q975": 1208.887016264787,
            "rating_q025": 1165.3212523073448
        },
        "c4ai-aya-expanse-8b": {
            "rating": 1184.1277109051766,
            "rating_q975": 1219.9697092704257,
            "rating_q025": 1148.2857125399278
        },
        "gemma-2-9b-it": {
            "rating": 1180.9789884976833,
            "rating_q975": 1195.4129659905225,
            "rating_q025": 1166.5450110048441
        },
        "glm-4-0520": {
            "rating": 1177.3317421485747,
            "rating_q975": 1206.00806926549,
            "rating_q025": 1148.6554150316595
        },
        "reka-flash-20240904": {
            "rating": 1175.6207786056332,
            "rating_q975": 1213.5443958098851,
            "rating_q025": 1137.6971614013814
        },
        "mistral-large-2402": {
            "rating": 1174.093045360053,
            "rating_q975": 1189.2322969620097,
            "rating_q025": 1158.9537937580965
        },
        "command-r-08-2024": {
            "rating": 1170.6937864160504,
            "rating_q975": 1202.6632747798164,
            "rating_q025": 1138.7242980522847
        },
        "claude-3-haiku-20240307": {
            "rating": 1168.5316241927126,
            "rating_q975": 1180.2618764688757,
            "rating_q025": 1156.8013719165494
        },
        "llama-3-70b-instruct": {
            "rating": 1164.3203771529306,
            "rating_q975": 1175.612520785112,
            "rating_q025": 1153.0282335207494
        },
        "deepseek-coder-v2": {
            "rating": 1159.1060330183082,
            "rating_q975": 1184.118879038636,
            "rating_q025": 1134.0931869979804
        },
        "jamba-1.5-mini": {
            "rating": 1158.4824522348392,
            "rating_q975": 1195.5506497222377,
            "rating_q025": 1121.4142547474407
        },
        "gpt-4-0613": {
            "rating": 1157.7045626121062,
            "rating_q975": 1171.6668484864867,
            "rating_q025": 1143.7422767377257
        },
        "mistral-medium": {
            "rating": 1151.372408822167,
            "rating_q975": 1172.304213161012,
            "rating_q025": 1130.440604483322
        },
        "reka-flash-21b-20240226": {
            "rating": 1149.6219718590642,
            "rating_q975": 1169.642233796511,
            "rating_q025": 1129.6017099216174
        },
        "reka-flash-21b-20240226-online": {
            "rating": 1146.7285960993313,
            "rating_q975": 1172.085433075141,
            "rating_q025": 1121.3717591235218
        },
        "qwen2-72b-instruct": {
            "rating": 1145.3155964758964,
            "rating_q975": 1161.2373114384336,
            "rating_q025": 1129.3938815133592
        },
        "llama-3.1-8b-instruct": {
            "rating": 1140.9347920486305,
            "rating_q975": 1157.1632243192246,
            "rating_q025": 1124.7063597780364
        },
        "mixtral-8x22b-instruct-v0.1": {
            "rating": 1135.690248117747,
            "rating_q975": 1151.0183102110514,
            "rating_q025": 1120.3621860244425
        },
        "command-r": {
            "rating": 1121.6876482407497,
            "rating_q975": 1138.1715204272145,
            "rating_q025": 1105.2037760542848
        },
        "gemini-pro-dev-api": {
            "rating": 1120.6432363986805,
            "rating_q975": 1148.8573620091493,
            "rating_q025": 1092.4291107882118
        },
        "qwen1.5-110b-chat": {
            "rating": 1119.6580663551538,
            "rating_q975": 1138.7886251283785,
            "rating_q025": 1100.527507581929
        },
        "mixtral-8x7b-instruct-v0.1": {
            "rating": 1110.1436314141674,
            "rating_q975": 1124.4247385208935,
            "rating_q025": 1095.8625243074414
        },
        "gemma-2-2b-it": {
            "rating": 1110.1117259130742,
            "rating_q975": 1127.452361387474,
            "rating_q025": 1092.7710904386745
        },
        "yi-1.5-34b-chat": {
            "rating": 1106.882396275672,
            "rating_q975": 1126.059970932796,
            "rating_q025": 1087.704821618548
        },
        "llama-3-8b-instruct": {
            "rating": 1101.2803159552095,
            "rating_q975": 1113.719914783914,
            "rating_q025": 1088.840717126505
        },
        "phi-3-medium-4k-instruct": {
            "rating": 1100.0863900826648,
            "rating_q975": 1119.4597143453366,
            "rating_q025": 1080.7130658199933
        },
        "gpt-3.5-turbo-0125": {
            "rating": 1088.0405780124174,
            "rating_q975": 1103.0550337237746,
            "rating_q025": 1073.0261223010602
        },
        "qwen1.5-72b-chat": {
            "rating": 1081.5882941357513,
            "rating_q975": 1099.6822836959816,
            "rating_q025": 1063.494304575521
        },
        "wizardlm-70b": {
            "rating": 1079.044731666293,
            "rating_q975": 1122.1651833454978,
            "rating_q025": 1035.9242799870885
        },
        "starling-lm-7b-beta": {
            "rating": 1076.872795900318,
            "rating_q975": 1105.2935572531837,
            "rating_q025": 1048.4520345474523
        },
        "phi-3-small-8k-instruct": {
            "rating": 1075.0568857215994,
            "rating_q975": 1098.0319117614097,
            "rating_q025": 1052.0818596817892
        },
        "snowflake-arctic-instruct": {
            "rating": 1072.0734093961119,
            "rating_q975": 1092.8026979509837,
            "rating_q025": 1051.3441208412398
        },
        "openchat-3.5-0106": {
            "rating": 1063.1054477059743,
            "rating_q975": 1095.0545619857944,
            "rating_q025": 1031.1563334261539
        },
        "dbrx-instruct-preview": {
            "rating": 1060.2175805013298,
            "rating_q975": 1081.096551148244,
            "rating_q025": 1039.3386098544156
        },
        "internlm2_5-20b-chat": {
            "rating": 1058.7779167574947,
            "rating_q975": 1095.0525692078565,
            "rating_q025": 1022.5032643071327
        },
        "vicuna-33b": {
            "rating": 1057.0701334427722,
            "rating_q975": 1085.170746455214,
            "rating_q025": 1028.9695204303307
        },
        "gpt-3.5-turbo-1106": {
            "rating": 1056.519317170755,
            "rating_q975": 1090.486908341988,
            "rating_q025": 1022.5517259995219
        },
        "qwen1.5-32b-chat": {
            "rating": 1055.2425252258306,
            "rating_q975": 1076.2044104381391,
            "rating_q025": 1034.280640013522
        },
        "llama-3.2-3b-instruct": {
            "rating": 1050.938264052345,
            "rating_q975": 1090.9166618343575,
            "rating_q025": 1010.9598662703323
        },
        "gemma-1.1-7b-it": {
            "rating": 1050.0483672961973,
            "rating_q975": 1070.2877804270342,
            "rating_q025": 1029.8089541653603
        },
        "qwen1.5-14b-chat": {
            "rating": 1042.4617326133316,
            "rating_q975": 1066.2502216251635,
            "rating_q025": 1018.6732436015
        },
        "yi-34b-chat": {
            "rating": 1039.344095068456,
            "rating_q975": 1070.056873643873,
            "rating_q025": 1008.6313164930391
        },
        "phi-3-mini-4k-instruct": {
            "rating": 1038.5855739218657,
            "rating_q975": 1060.9872638464076,
            "rating_q025": 1016.1838839973238
        },
        "llama-2-70b-chat": {
            "rating": 1037.1052178532652,
            "rating_q975": 1057.4791721792747,
            "rating_q025": 1016.7312635272558
        },
        "phi-3-mini-4k-instruct-june-2024": {
            "rating": 1030.1718008128285,
            "rating_q975": 1060.5542791887449,
            "rating_q025": 999.7893224369122
        },
        "starling-lm-7b-alpha": {
            "rating": 1025.723381937311,
            "rating_q975": 1066.3407480898966,
            "rating_q025": 985.1060157847255
        },
        "llama-3.2-1b-instruct": {
            "rating": 1008.3688325967936,
            "rating_q975": 1047.6473271214265,
            "rating_q025": 969.0903380721606
        },
        "phi-3-mini-128k-instruct": {
            "rating": 1003.5508664797711,
            "rating_q975": 1026.652833141216,
            "rating_q025": 980.4488998183263
        },
        "llama-2-13b-chat": {
            "rating": 1002.6499311810404,
            "rating_q975": 1030.9623071164956,
            "rating_q025": 974.3375552455853
        },
        "vicuna-13b": {
            "rating": 991.559962783817,
            "rating_q975": 1026.0735883765174,
            "rating_q025": 957.0463371911167
        },
        "zephyr-7b-beta": {
            "rating": 987.9692247293195,
            "rating_q975": 1035.0080358413338,
            "rating_q025": 940.9304136173052
        },
        "mistral-7b-instruct-v0.2": {
            "rating": 985.055864969491,
            "rating_q975": 1010.8321262175646,
            "rating_q025": 959.2796037214177
        },
        "gemma-7b-it": {
            "rating": 980.5103786272343,
            "rating_q975": 1023.1140696276303,
            "rating_q025": 937.9066876268382
        },
        "llama-2-7b-chat": {
            "rating": 969.5253213671635,
            "rating_q975": 1002.768270736052,
            "rating_q025": 936.2823719982752
        },
        "gemma-1.1-2b-it": {
            "rating": 946.6032490572998,
            "rating_q975": 979.6279789060754,
            "rating_q025": 913.5785192085239
        },
        "palm-2": {
            "rating": 934.0744240782591,
            "rating_q975": 993.1504392207041,
            "rating_q025": 874.998408935814
        },
        "mistral-7b-instruct": {
            "rating": 930.3992413379904,
            "rating_q975": 974.6353101090947,
            "rating_q025": 886.163172566886
        },
        "qwen1.5-4b-chat": {
            "rating": 904.3286957666057,
            "rating_q975": 941.2341305487536,
            "rating_q025": 867.423260984458
        }
    },
    "hard_6": {
        "gemini-2.5-pro": {
            "rating": 1463.7703519667027,
            "rating_q975": 1470.302088923524,
            "rating_q025": 1457.2386150098814
        },
        "claude-opus-4-1-20250805-thinking-16k": {
            "rating": 1446.6289710074493,
            "rating_q975": 1457.1965422776084,
            "rating_q025": 1436.06139973729
        },
        "qwen-max-2025-08-15": {
            "rating": 1439.166742231121,
            "rating_q975": 1451.8403038656452,
            "rating_q025": 1426.4931805965966
        },
        "qwen3-235b-a22b-instruct-2507": {
            "rating": 1438.5805308942315,
            "rating_q975": 1446.9694291128012,
            "rating_q025": 1430.1916326756618
        },
        "mistral-medium-2508": {
            "rating": 1434.5103802194446,
            "rating_q975": 1445.5407666987649,
            "rating_q025": 1423.4799937401244
        },
        "claude-opus-4-1-20250805": {
            "rating": 1433.817454650646,
            "rating_q975": 1442.9901217683107,
            "rating_q025": 1424.644787532981
        },
        "grok-3-preview-02-24": {
            "rating": 1431.6745409079128,
            "rating_q975": 1437.8282030482067,
            "rating_q025": 1425.5208787676193
        },
        "gpt-5-high": {
            "rating": 1431.381608482496,
            "rating_q975": 1440.7198431579232,
            "rating_q025": 1422.043373807069
        },
        "glm-4.5": {
            "rating": 1430.011798766833,
            "rating_q975": 1439.0974161593747,
            "rating_q025": 1420.9261813742912
        },
        "gpt-5-old": {
            "rating": 1424.6232904158633,
            "rating_q975": 1459.2031895769624,
            "rating_q025": 1390.0433912547644
        },
        "grok-4-0709": {
            "rating": 1423.6860768808115,
            "rating_q975": 1431.1300961958025,
            "rating_q025": 1416.2420575658207
        },
        "chatgpt-4o-latest-20250326": {
            "rating": 1418.7407602018247,
            "rating_q975": 1424.9557208040662,
            "rating_q025": 1412.5257995995833
        },
        "deepseek-r1-0528": {
            "rating": 1417.6936791205535,
            "rating_q975": 1425.2359659390318,
            "rating_q025": 1410.1513923020752
        },
        "qwen3-235b-a22b-thinking-2507": {
            "rating": 1417.4468691161412,
            "rating_q975": 1427.3890889908432,
            "rating_q025": 1407.5046492414392
        },
        "deepseek-v3.1-thinking": {
            "rating": 1416.3977817261944,
            "rating_q975": 1430.5767031867347,
            "rating_q025": 1402.2188602656543
        },
        "o3-2025-04-16": {
            "rating": 1413.74905848452,
            "rating_q975": 1419.9305089005468,
            "rating_q025": 1407.5676080684934
        },
        "gemini-2.5-flash": {
            "rating": 1412.1516309219483,
            "rating_q975": 1418.4553335777705,
            "rating_q025": 1405.8479282661258
        },
        "deepseek-v3.1": {
            "rating": 1411.993793519742,
            "rating_q975": 1425.1353317787816,
            "rating_q025": 1398.8522552607026
        },
        "gpt-5-chat": {
            "rating": 1409.4945131386114,
            "rating_q975": 1419.8348034545975,
            "rating_q025": 1399.1542228226256
        },
        "gpt-4.5-preview-2025-02-27": {
            "rating": 1403.4047342860722,
            "rating_q975": 1413.0003823415736,
            "rating_q025": 1393.8090862305708
        },
        "qwen-vl-max-2025-08-13": {
            "rating": 1398.4495406558895,
            "rating_q975": 1422.5676305796312,
            "rating_q025": 1374.3314507321477
        },
        "mai-1-preview": {
            "rating": 1397.3507137511915,
            "rating_q975": 1411.6133376430892,
            "rating_q025": 1383.0880898592936
        },
        "qwen3-30b-a3b-instruct-2507": {
            "rating": 1397.1743190449117,
            "rating_q975": 1406.9402332988493,
            "rating_q025": 1387.4084047909741
        },
        "hunyuan-t1-20250711": {
            "rating": 1396.8894708267276,
            "rating_q975": 1408.9482717756268,
            "rating_q025": 1384.830669877828
        },
        "claude-opus-4-20250514-thinking-16k": {
            "rating": 1392.5567773534551,
            "rating_q975": 1399.615173592907,
            "rating_q025": 1385.4983811140035
        },
        "qwen3-235b-a22b-no-thinking": {
            "rating": 1389.534911521923,
            "rating_q975": 1396.1438313102385,
            "rating_q025": 1382.9259917336076
        },
        "gpt-5-mini-high": {
            "rating": 1387.8262066179645,
            "rating_q975": 1399.0281240799586,
            "rating_q025": 1376.6242891559707
        },
        "glm-4.5-air": {
            "rating": 1386.3619426048044,
            "rating_q975": 1395.5908977864829,
            "rating_q025": 1377.1329874231258
        },
        "gpt-4.1-2025-04-14": {
            "rating": 1384.6617860910255,
            "rating_q975": 1391.219996533106,
            "rating_q025": 1378.1035756489453
        },
        "kimi-k2-0711-preview": {
            "rating": 1377.1550334969427,
            "rating_q975": 1384.4575493616826,
            "rating_q025": 1369.8525176322028
        },
        "claude-opus-4-20250514": {
            "rating": 1376.399730827477,
            "rating_q975": 1383.0623086240794,
            "rating_q025": 1369.7371530308747
        },
        "qwen3-coder-480b-a35b-instruct": {
            "rating": 1376.271619844334,
            "rating_q975": 1384.6589459057084,
            "rating_q025": 1367.8842937829595
        },
        "o1-2024-12-17": {
            "rating": 1371.7829173263171,
            "rating_q975": 1379.0925954498039,
            "rating_q025": 1364.4732392028302
        },
        "hunyuan-turbos-20250416": {
            "rating": 1371.5822058322176,
            "rating_q975": 1380.715113985474,
            "rating_q025": 1362.449297678961
        },
        "claude-sonnet-4-20250514-thinking-32k": {
            "rating": 1371.0716502976536,
            "rating_q975": 1378.18150654479,
            "rating_q025": 1363.9617940505173
        },
        "grok-3-mini-high": {
            "rating": 1367.8210799310207,
            "rating_q975": 1375.6047588880547,
            "rating_q025": 1360.037400973987
        },
        "mistral-medium-2505": {
            "rating": 1365.9588542355725,
            "rating_q975": 1372.284507310824,
            "rating_q025": 1359.6332011603208
        },
        "deepseek-v3-0324": {
            "rating": 1365.6091063948525,
            "rating_q975": 1371.907527532558,
            "rating_q025": 1359.3106852571468
        },
        "o3-mini-high": {
            "rating": 1365.338494540815,
            "rating_q975": 1374.0921335174605,
            "rating_q025": 1356.5848555641696
        },
        "gpt-oss-120b": {
            "rating": 1364.9531017128534,
            "rating_q975": 1375.4247272719217,
            "rating_q025": 1354.481476153785
        },
        "step-3": {
            "rating": 1364.7612719947726,
            "rating_q975": 1380.9317078131203,
            "rating_q025": 1348.590836176425
        },
        "qwen3-235b-a22b": {
            "rating": 1364.1978071781598,
            "rating_q975": 1370.9296450208321,
            "rating_q025": 1357.4659693354877
        },
        "deepseek-r1": {
            "rating": 1361.802916315747,
            "rating_q975": 1370.3660675053318,
            "rating_q025": 1353.2397651261624
        },
        "grok-3-mini-beta": {
            "rating": 1361.6370433021566,
            "rating_q975": 1368.7454683264768,
            "rating_q025": 1354.5286182778364
        },
        "qwen2.5-max": {
            "rating": 1358.8244290302598,
            "rating_q975": 1364.8332253643146,
            "rating_q025": 1352.8156326962048
        },
        "o4-mini-2025-04-16": {
            "rating": 1356.5600591126008,
            "rating_q975": 1363.0672615650524,
            "rating_q025": 1350.0528566601492
        },
        "o1-preview": {
            "rating": 1356.19741122954,
            "rating_q975": 1363.2718932690811,
            "rating_q025": 1349.1229291899988
        },
        "gemini-2.0-flash-001": {
            "rating": 1350.1018453824247,
            "rating_q975": 1355.6953353129593,
            "rating_q025": 1344.5083554518899
        },
        "claude-sonnet-4-20250514": {
            "rating": 1348.4749487398553,
            "rating_q975": 1355.276131727107,
            "rating_q025": 1341.6737657526035
        },
        "gpt-4.1-mini-2025-04-14": {
            "rating": 1348.3582464982928,
            "rating_q975": 1354.880389016369,
            "rating_q025": 1341.8361039802164
        },
        "minimax-m1": {
            "rating": 1342.6391151359173,
            "rating_q975": 1349.6012378912683,
            "rating_q025": 1335.6769923805662
        },
        "gpt-5-nano-high": {
            "rating": 1340.3425589869425,
            "rating_q975": 1353.321674784205,
            "rating_q025": 1327.36344318968
        },
        "gemma-3-27b-it": {
            "rating": 1338.9985748093588,
            "rating_q975": 1345.143436032195,
            "rating_q025": 1332.8537135865224
        },
        "nvidia-llama-3.3-nemotron-super-49b-v1.5": {
            "rating": 1338.031136659117,
            "rating_q975": 1351.888621431059,
            "rating_q025": 1324.1736518871749
        },
        "o3-mini": {
            "rating": 1336.542280464105,
            "rating_q975": 1341.9271422466195,
            "rating_q025": 1331.1574186815903
        },
        "step-1o-turbo-202506": {
            "rating": 1335.700932804646,
            "rating_q975": 1345.1738050851213,
            "rating_q025": 1326.228060524171
        },
        "qwen3-32b": {
            "rating": 1335.596912082818,
            "rating_q975": 1351.425029669645,
            "rating_q025": 1319.768794495991
        },
        "o1-mini": {
            "rating": 1335.2104702707265,
            "rating_q975": 1340.6602416046455,
            "rating_q025": 1329.7606989368076
        },
        "claude-3-7-sonnet-20250219-thinking-32k": {
            "rating": 1334.2703662095255,
            "rating_q975": 1340.5633678349864,
            "rating_q025": 1327.9773645840646
        },
        "mistral-small-2506": {
            "rating": 1333.4241299906714,
            "rating_q975": 1341.1736258478566,
            "rating_q025": 1325.6746341334863
        },
        "qwq-32b": {
            "rating": 1330.5432162158409,
            "rating_q975": 1337.4556786336293,
            "rating_q025": 1323.6307537980522
        },
        "hunyuan-turbos-20250226": {
            "rating": 1326.3364031374751,
            "rating_q975": 1347.803866327598,
            "rating_q025": 1304.8689399473526
        },
        "gemini-2.0-flash-lite-preview-02-05": {
            "rating": 1326.052960450283,
            "rating_q975": 1333.1556536880507,
            "rating_q025": 1318.9502672125154
        },
        "glm-4.5v": {
            "rating": 1323.4506475102698,
            "rating_q975": 1349.3534043729803,
            "rating_q025": 1297.5478906475594
        },
        "command-a-03-2025": {
            "rating": 1321.0240780407905,
            "rating_q975": 1327.0796830391755,
            "rating_q025": 1314.9684730424055
        },
        "qwen-plus-0125": {
            "rating": 1319.1269033499493,
            "rating_q975": 1332.9828102772253,
            "rating_q025": 1305.2709964226733
        },
        "qwen3-30b-a3b": {
            "rating": 1316.8485208816073,
            "rating_q975": 1323.679597886951,
            "rating_q025": 1310.0174438762635
        },
        "amazon-nova-experimental-chat-05-14": {
            "rating": 1316.6685946711495,
            "rating_q975": 1324.0430538394362,
            "rating_q025": 1309.294135502863
        },
        "llama-3.1-nemotron-ultra-253b-v1": {
            "rating": 1315.481541936156,
            "rating_q975": 1336.2791872542123,
            "rating_q025": 1294.6838966180997
        },
        "deepseek-v3": {
            "rating": 1314.0866509534173,
            "rating_q975": 1321.7719296839005,
            "rating_q025": 1306.4013722229342
        },
        "claude-3-7-sonnet-20250219": {
            "rating": 1313.4719869884127,
            "rating_q975": 1319.3295915099668,
            "rating_q025": 1307.6143824668584
        },
        "llama-3.3-nemotron-49b-super-v1": {
            "rating": 1312.001923485157,
            "rating_q975": 1335.1429450756164,
            "rating_q025": 1288.8609018946975
        },
        "gemma-3-12b-it": {
            "rating": 1311.5427909393093,
            "rating_q975": 1329.1042470738678,
            "rating_q025": 1293.9813348047505
        },
        "hunyuan-turbo-0110": {
            "rating": 1311.438255116668,
            "rating_q975": 1333.3589389428648,
            "rating_q025": 1289.5175712904709
        },
        "claude-3-5-sonnet-20241022": {
            "rating": 1308.321612971152,
            "rating_q975": 1312.4279027098717,
            "rating_q025": 1304.2153232324324
        },
        "gpt-oss-20b": {
            "rating": 1306.474258817539,
            "rating_q975": 1317.2885018796553,
            "rating_q025": 1295.660015755423
        },
        "yi-lightning": {
            "rating": 1302.8399519093805,
            "rating_q975": 1310.1067254467937,
            "rating_q025": 1295.5731783719675
        },
        "qwen2.5-plus-1127": {
            "rating": 1301.4975940228921,
            "rating_q975": 1311.5441386609891,
            "rating_q025": 1291.4510493847952
        },
        "step-2-16k-exp-202412": {
            "rating": 1299.4913333204843,
            "rating_q975": 1314.118042446383,
            "rating_q025": 1284.8646241945855
        },
        "gemini-1.5-pro-002": {
            "rating": 1299.005202340665,
            "rating_q975": 1304.0570338724174,
            "rating_q025": 1293.9533708089125
        },
        "athene-v2-chat": {
            "rating": 1295.692404428423,
            "rating_q975": 1302.5169478615164,
            "rating_q025": 1288.86786099533
        },
        "glm-4-plus-0111": {
            "rating": 1294.8797623012556,
            "rating_q975": 1308.678719417236,
            "rating_q025": 1281.080805185275
        },
        "deepseek-v2.5-1210": {
            "rating": 1291.9352048139826,
            "rating_q975": 1304.3809433525275,
            "rating_q025": 1279.4894662754377
        },
        "hunyuan-large-2025-02-10": {
            "rating": 1288.6180421656136,
            "rating_q975": 1307.123614819954,
            "rating_q025": 1270.1124695112735
        },
        "gemma-3n-e4b-it": {
            "rating": 1287.7920818898065,
            "rating_q975": 1295.6015871143256,
            "rating_q025": 1279.982576665287
        },
        "gpt-4.1-nano-2025-04-14": {
            "rating": 1286.8532167042752,
            "rating_q975": 1300.314668295973,
            "rating_q025": 1273.3917651125773
        },
        "gpt-4o-2024-05-13": {
            "rating": 1284.5957559588578,
            "rating_q975": 1289.416618271855,
            "rating_q025": 1279.7748936458604
        },
        "llama-4-maverick-17b-128e-instruct": {
            "rating": 1280.7508744119486,
            "rating_q975": 1287.390861292814,
            "rating_q025": 1274.1108875310833
        },
        "claude-3-5-sonnet-20240620": {
            "rating": 1278.821226004086,
            "rating_q975": 1283.872429784362,
            "rating_q025": 1273.7700222238095
        },
        "mistral-small-3.1-24b-instruct-2503": {
            "rating": 1277.2609129040532,
            "rating_q975": 1284.6683510331252,
            "rating_q025": 1269.853474774981
        },
        "glm-4-plus": {
            "rating": 1276.0050075349832,
            "rating_q975": 1283.0511999164648,
            "rating_q025": 1268.9588151535017
        },
        "grok-2-2024-08-13": {
            "rating": 1275.7609254803042,
            "rating_q975": 1280.7670992139108,
            "rating_q025": 1270.7547517466976
        },
        "qwen2.5-72b-instruct": {
            "rating": 1275.1039095821654,
            "rating_q975": 1280.91223623855,
            "rating_q025": 1269.295582925781
        },
        "deepseek-v2.5": {
            "rating": 1275.0306768803066,
            "rating_q975": 1281.876591745048,
            "rating_q025": 1268.1847620155652
        },
        "qwen-max-0919": {
            "rating": 1273.738023345111,
            "rating_q975": 1282.2621691288443,
            "rating_q025": 1265.2138775613778
        },
        "llama-3.1-405b-instruct-bf16": {
            "rating": 1272.7165413846767,
            "rating_q975": 1278.223310327843,
            "rating_q025": 1267.2097724415105
        },
        "gpt-4o-mini-2024-07-18": {
            "rating": 1271.1287451008538,
            "rating_q975": 1275.8799914415517,
            "rating_q025": 1266.377498760156
        },
        "llama-3.1-nemotron-70b-instruct": {
            "rating": 1270.3344718824155,
            "rating_q975": 1282.0438896061796,
            "rating_q025": 1258.6250541586514
        },
        "llama-3.1-405b-instruct-fp8": {
            "rating": 1268.3991836203509,
            "rating_q975": 1273.685223633415,
            "rating_q025": 1263.1131436072865
        },
        "gpt-4o-2024-08-06": {
            "rating": 1267.803959936868,
            "rating_q975": 1273.6534308206194,
            "rating_q025": 1261.9544890531167
        },
        "hunyuan-standard-2025-02-10": {
            "rating": 1267.7433618538926,
            "rating_q975": 1286.272708863786,
            "rating_q025": 1249.2140148439994
        },
        "llama-4-scout-17b-16e-instruct": {
            "rating": 1265.234610470621,
            "rating_q975": 1272.5830451876882,
            "rating_q025": 1257.8861757535537
        },
        "magistral-medium-2506": {
            "rating": 1264.9802108598483,
            "rating_q975": 1274.2649082850096,
            "rating_q025": 1255.6955134346872
        },
        "gemini-1.5-flash-002": {
            "rating": 1262.7183447560865,
            "rating_q975": 1268.8134051411566,
            "rating_q025": 1256.6232843710163
        },
        "llama-3.3-70b-instruct": {
            "rating": 1261.905811077423,
            "rating_q975": 1266.8664557419847,
            "rating_q025": 1256.9451664128615
        },
        "mistral-large-2407": {
            "rating": 1261.6616329422313,
            "rating_q975": 1267.3875002595125,
            "rating_q025": 1255.93576562495
        },
        "hunyuan-large-vision": {
            "rating": 1260.7262897595954,
            "rating_q975": 1273.524027623875,
            "rating_q025": 1247.9285518953156
        },
        "mistral-large-2411": {
            "rating": 1260.6081865516744,
            "rating_q975": 1267.1781747572377,
            "rating_q025": 1254.038198346111
        },
        "grok-2-mini-2024-08-13": {
            "rating": 1259.432655648939,
            "rating_q975": 1264.7489883632813,
            "rating_q025": 1254.1163229345966
        },
        "gemini-1.5-pro-001": {
            "rating": 1259.4078385449975,
            "rating_q975": 1265.1209033959074,
            "rating_q025": 1253.6947736940874
        },
        "qwen2.5-coder-32b-instruct": {
            "rating": 1257.3086042557138,
            "rating_q975": 1270.6318073975572,
            "rating_q025": 1243.9854011138707
        },
        "gpt-4-turbo-2024-04-09": {
            "rating": 1256.515526577868,
            "rating_q975": 1261.9075535574818,
            "rating_q025": 1251.123499598254
        },
        "gemma-3-4b-it": {
            "rating": 1254.467224997949,
            "rating_q975": 1271.4627172381327,
            "rating_q025": 1237.4717327577653
        },
        "gemini-advanced-0514": {
            "rating": 1253.3302020791975,
            "rating_q975": 1260.1768591427558,
            "rating_q025": 1246.483545015639
        },
        "claude-3-5-haiku-20241022": {
            "rating": 1252.613333933779,
            "rating_q975": 1257.4282851665541,
            "rating_q025": 1247.798382701004
        },
        "claude-3-opus-20240229": {
            "rating": 1250.1381769248314,
            "rating_q975": 1254.3770633426757,
            "rating_q025": 1245.8992905069872
        },
        "amazon-nova-pro-v1.0": {
            "rating": 1249.4470980441747,
            "rating_q975": 1256.265710226144,
            "rating_q025": 1242.628485862206
        },
        "athene-70b-0725": {
            "rating": 1248.9000350372426,
            "rating_q975": 1257.0955249910992,
            "rating_q025": 1240.7045450833857
        },
        "gpt-4-1106-preview": {
            "rating": 1247.1199041786026,
            "rating_q975": 1252.6653665133167,
            "rating_q025": 1241.5744418438883
        },
        "llama-3.1-70b-instruct": {
            "rating": 1246.4626106072592,
            "rating_q975": 1251.731014873259,
            "rating_q025": 1241.1942063412591
        },
        "gpt-4-0125-preview": {
            "rating": 1244.1133269135753,
            "rating_q975": 1249.775664704157,
            "rating_q025": 1238.4509891229936
        },
        "mistral-small-24b-instruct-2501": {
            "rating": 1236.1485566497308,
            "rating_q975": 1245.4286612042658,
            "rating_q025": 1226.8684520951958
        },
        "llama-3.1-tulu-3-70b": {
            "rating": 1227.7306288480754,
            "rating_q975": 1245.6446364400408,
            "rating_q025": 1209.81662125611
        },
        "amazon-nova-lite-v1.0": {
            "rating": 1226.4248303784448,
            "rating_q975": 1234.226100423328,
            "rating_q025": 1218.6235603335613
        },
        "phi-4": {
            "rating": 1225.6521047932026,
            "rating_q975": 1233.0889341610289,
            "rating_q025": 1218.2152754253764
        },
        "gemini-1.5-flash-001": {
            "rating": 1225.5882841567136,
            "rating_q975": 1231.384881101481,
            "rating_q025": 1219.791687211946
        },
        "hunyuan-standard-256k": {
            "rating": 1224.4970559619242,
            "rating_q975": 1243.9529538958336,
            "rating_q025": 1205.0411580280143
        },
        "jamba-1.5-large": {
            "rating": 1223.8839365477315,
            "rating_q975": 1235.1056736868636,
            "rating_q025": 1212.6621994085997
        },
        "glm-4-0520": {
            "rating": 1218.0436417522592,
            "rating_q975": 1228.782502416952,
            "rating_q025": 1207.3047810875664
        },
        "reka-core-20240904": {
            "rating": 1217.3563321499732,
            "rating_q975": 1228.1124745435172,
            "rating_q025": 1206.6001897564295
        },
        "gemini-1.5-flash-8b-001": {
            "rating": 1216.4707937800506,
            "rating_q975": 1222.5415461596565,
            "rating_q025": 1210.4000414004447
        },
        "deepseek-coder-v2": {
            "rating": 1213.6234326474394,
            "rating_q975": 1223.0994900816067,
            "rating_q025": 1204.147375213272
        },
        "olmo-2-0325-32b-instruct": {
            "rating": 1212.7958790293603,
            "rating_q975": 1232.3629995751603,
            "rating_q025": 1193.2287584835606
        },
        "llama-3.1-nemotron-51b-instruct": {
            "rating": 1209.4195448782511,
            "rating_q975": 1225.9363363772288,
            "rating_q025": 1192.9027533792735
        },
        "nemotron-4-340b-instruct": {
            "rating": 1207.655211494728,
            "rating_q975": 1216.2036985671882,
            "rating_q025": 1199.1067244222681
        },
        "gpt-4-0314": {
            "rating": 1206.7700383167466,
            "rating_q975": 1214.1995568683474,
            "rating_q025": 1199.340519765146
        },
        "gemma-2-27b-it": {
            "rating": 1205.1500236875133,
            "rating_q975": 1209.8156744426813,
            "rating_q025": 1200.4843729323452
        },
        "claude-3-sonnet-20240229": {
            "rating": 1203.5169579283552,
            "rating_q975": 1209.0808359044345,
            "rating_q025": 1197.9530799522759
        },
        "gemma-2-9b-it-simpo": {
            "rating": 1203.1116760537584,
            "rating_q975": 1214.1289778970922,
            "rating_q025": 1192.0943742104243
        },
        "ministral-8b-2410": {
            "rating": 1201.9810041056783,
            "rating_q975": 1215.9259827751387,
            "rating_q025": 1188.0360254362179
        },
        "llama-3-70b-instruct": {
            "rating": 1201.5329483288274,
            "rating_q975": 1206.7124639923122,
            "rating_q025": 1196.353432665343
        },
        "c4ai-aya-expanse-32b": {
            "rating": 1201.3504315612277,
            "rating_q975": 1208.3099194608844,
            "rating_q025": 1194.3909436615706
        },
        "amazon-nova-micro-v1.0": {
            "rating": 1198.7023106237698,
            "rating_q975": 1206.4530149409177,
            "rating_q025": 1190.9516063066224
        },
        "qwen2-72b-instruct": {
            "rating": 1196.1328361566225,
            "rating_q975": 1203.0380794552136,
            "rating_q025": 1189.2275928580316
        },
        "command-r-plus-08-2024": {
            "rating": 1192.721020684337,
            "rating_q975": 1202.6248216233314,
            "rating_q025": 1182.8172197453428
        },
        "reka-flash-20240904": {
            "rating": 1189.7675438127696,
            "rating_q975": 1200.290045930447,
            "rating_q025": 1179.2450416950924
        },
        "llama-3.1-tulu-3-8b": {
            "rating": 1183.4874901696953,
            "rating_q975": 1202.5432438823702,
            "rating_q025": 1164.4317364570206
        },
        "llama-3.1-8b-instruct": {
            "rating": 1183.3303207342706,
            "rating_q975": 1188.883831107993,
            "rating_q025": 1177.776810360548
        },
        "gpt-4-0613": {
            "rating": 1181.5596626956194,
            "rating_q975": 1187.6664051911598,
            "rating_q025": 1175.452920200079
        },
        "claude-3-haiku-20240307": {
            "rating": 1181.48359876995,
            "rating_q975": 1186.6596117753227,
            "rating_q025": 1176.3075857645774
        },
        "gemma-2-9b-it": {
            "rating": 1180.0589456950092,
            "rating_q975": 1185.392929578298,
            "rating_q025": 1174.7249618117203
        },
        "qwq-32b-preview": {
            "rating": 1176.6911880178295,
            "rating_q975": 1194.611056998398,
            "rating_q025": 1158.7713190372608
        },
        "qwen1.5-110b-chat": {
            "rating": 1175.3682168758405,
            "rating_q975": 1183.7970051289758,
            "rating_q025": 1166.9394286227052
        },
        "mistral-large-2402": {
            "rating": 1174.0248746003192,
            "rating_q975": 1180.6247508703796,
            "rating_q025": 1167.4249983302589
        },
        "command-r-plus": {
            "rating": 1173.6132408282315,
            "rating_q975": 1179.5943458460054,
            "rating_q025": 1167.6321358104576
        },
        "jamba-1.5-mini": {
            "rating": 1173.2906467826426,
            "rating_q975": 1184.7815186790224,
            "rating_q025": 1161.7997748862629
        },
        "command-r-08-2024": {
            "rating": 1173.0286659186406,
            "rating_q975": 1182.6995276162852,
            "rating_q025": 1163.357804220996
        },
        "internlm2_5-20b-chat": {
            "rating": 1170.7199527480557,
            "rating_q975": 1181.1364915758336,
            "rating_q025": 1160.3034139202775
        },
        "yi-1.5-34b-chat": {
            "rating": 1166.4035179739267,
            "rating_q975": 1174.3631239843785,
            "rating_q025": 1158.4439119634746
        },
        "c4ai-aya-expanse-8b": {
            "rating": 1166.26536021269,
            "rating_q975": 1176.9462279490454,
            "rating_q025": 1155.5844924763346
        },
        "mixtral-8x22b-instruct-v0.1": {
            "rating": 1156.7090011312348,
            "rating_q975": 1163.2626925022194,
            "rating_q025": 1150.15530976025
        },
        "mistral-medium": {
            "rating": 1156.562742703968,
            "rating_q975": 1164.9442871200936,
            "rating_q025": 1148.1811982878426
        },
        "qwen1.5-72b-chat": {
            "rating": 1154.5838946812828,
            "rating_q975": 1162.076241137424,
            "rating_q025": 1147.0915482251419
        },
        "granite-3.1-8b-instruct": {
            "rating": 1151.5906828100524,
            "rating_q975": 1170.6248473768353,
            "rating_q025": 1132.5565182432697
        },
        "granite-3.1-2b-instruct": {
            "rating": 1146.976967451299,
            "rating_q975": 1165.3423104669973,
            "rating_q025": 1128.6116244356006
        },
        "reka-flash-21b-20240226-online": {
            "rating": 1145.98892098035,
            "rating_q975": 1156.425083727422,
            "rating_q025": 1135.5527582332782
        },
        "reka-flash-21b-20240226": {
            "rating": 1144.310226657717,
            "rating_q975": 1152.8236254944661,
            "rating_q025": 1135.7968278209682
        },
        "llama-3-8b-instruct": {
            "rating": 1141.5118406255185,
            "rating_q975": 1147.205538921223,
            "rating_q025": 1135.8181423298138
        },
        "qwen1.5-32b-chat": {
            "rating": 1138.7393255796876,
            "rating_q975": 1147.6932838301163,
            "rating_q025": 1129.7853673292589
        },
        "phi-3-medium-4k-instruct": {
            "rating": 1134.2254898921371,
            "rating_q975": 1141.8894896019735,
            "rating_q025": 1126.5614901823008
        },
        "starling-lm-7b-beta": {
            "rating": 1127.1104077481777,
            "rating_q975": 1137.5255360740096,
            "rating_q025": 1116.695279422346
        },
        "zephyr-orpo-141b-A35b-v0.1": {
            "rating": 1125.4319466308975,
            "rating_q975": 1141.8946712494615,
            "rating_q025": 1108.9692220123338
        },
        "gemma-2-2b-it": {
            "rating": 1124.2874268075789,
            "rating_q975": 1130.0797519995303,
            "rating_q025": 1118.4951016156274
        },
        "mixtral-8x7b-instruct-v0.1": {
            "rating": 1123.3704560712379,
            "rating_q975": 1129.7247146668792,
            "rating_q025": 1117.0161974755965
        },
        "command-r": {
            "rating": 1123.3091165216529,
            "rating_q975": 1130.1228342759919,
            "rating_q025": 1116.4953987673139
        },
        "dbrx-instruct-preview": {
            "rating": 1121.785586280494,
            "rating_q975": 1130.4820220136048,
            "rating_q025": 1113.089150547383
        },
        "qwen1.5-14b-chat": {
            "rating": 1121.6990557734607,
            "rating_q975": 1132.0147981803386,
            "rating_q025": 1111.3833133665828
        },
        "gemini-pro-dev-api": {
            "rating": 1117.859575004367,
            "rating_q975": 1128.8365410710173,
            "rating_q025": 1106.8826089377164
        },
        "gpt-3.5-turbo-0125": {
            "rating": 1116.9310237553968,
            "rating_q975": 1123.2441024008658,
            "rating_q025": 1110.6179451099276
        },
        "yi-34b-chat": {
            "rating": 1111.9951203460294,
            "rating_q975": 1122.301516349345,
            "rating_q025": 1101.6887243427136
        },
        "tulu-2-dpo-70b": {
            "rating": 1111.4680662181077,
            "rating_q975": 1127.579232248364,
            "rating_q025": 1095.3569001878514
        },
        "granite-3.0-8b-instruct": {
            "rating": 1110.165490233047,
            "rating_q975": 1123.5997090452038,
            "rating_q025": 1096.73127142089
        },
        "phi-3-small-8k-instruct": {
            "rating": 1109.246285700899,
            "rating_q975": 1118.3357032335628,
            "rating_q025": 1100.1568681682356
        },
        "gpt-3.5-turbo-1106": {
            "rating": 1107.429071749028,
            "rating_q975": 1120.0943591792643,
            "rating_q025": 1094.763784318792
        },
        "llama-3.2-3b-instruct": {
            "rating": 1104.5502856511669,
            "rating_q975": 1116.1830511600763,
            "rating_q025": 1092.9175201422577
        },
        "gemini-pro": {
            "rating": 1101.692558594811,
            "rating_q975": 1119.3227612951714,
            "rating_q025": 1084.0623558944505
        },
        "phi-3-mini-4k-instruct-june-2024": {
            "rating": 1097.1350477565252,
            "rating_q975": 1107.4819581542529,
            "rating_q025": 1086.788137358798
        },
        "openchat-3.5-0106": {
            "rating": 1093.4090999004766,
            "rating_q975": 1104.288090441156,
            "rating_q025": 1082.5301093597973
        },
        "granite-3.0-2b-instruct": {
            "rating": 1091.0366177907258,
            "rating_q975": 1104.412216819531,
            "rating_q025": 1077.6610187619203
        },
        "wizardlm-70b": {
            "rating": 1087.2497536354144,
            "rating_q975": 1102.3954275473839,
            "rating_q025": 1072.1040797234452
        },
        "starling-lm-7b-alpha": {
            "rating": 1084.2497786785118,
            "rating_q975": 1096.6218671931565,
            "rating_q025": 1071.877690163867
        },
        "llama-2-70b-chat": {
            "rating": 1082.3031023540696,
            "rating_q975": 1090.2233025016722,
            "rating_q025": 1074.382902206467
        },
        "snowflake-arctic-instruct": {
            "rating": 1081.8827257057333,
            "rating_q975": 1090.6848747107838,
            "rating_q025": 1073.0805767006825
        },
        "phi-3-mini-4k-instruct": {
            "rating": 1080.6006577689277,
            "rating_q975": 1089.7098896060766,
            "rating_q025": 1071.4914259317788
        },
        "openhermes-2.5-mistral-7b": {
            "rating": 1080.466588354161,
            "rating_q975": 1097.3171948555457,
            "rating_q025": 1063.6159818527765
        },
        "gemma-1.1-7b-it": {
            "rating": 1080.3220824977395,
            "rating_q975": 1088.4833279615007,
            "rating_q025": 1072.1608370339784
        },
        "smollm2-1.7b-instruct": {
            "rating": 1080.1672778063946,
            "rating_q975": 1102.4812470283014,
            "rating_q025": 1057.853308584488
        },
        "deepseek-llm-67b-chat": {
            "rating": 1077.9080176070179,
            "rating_q975": 1096.4430068543895,
            "rating_q025": 1059.373028359646
        },
        "mistral-7b-instruct-v0.2": {
            "rating": 1077.1597290270274,
            "rating_q975": 1086.4595940316874,
            "rating_q025": 1067.8598640223674
        },
        "vicuna-33b": {
            "rating": 1076.2939143566534,
            "rating_q975": 1086.033000018042,
            "rating_q025": 1066.5548286952649
        },
        "qwen1.5-7b-chat": {
            "rating": 1074.7238585155576,
            "rating_q975": 1089.9777231387893,
            "rating_q025": 1059.4699938923259
        },
        "openchat-3.5": {
            "rating": 1073.6090466820547,
            "rating_q975": 1089.0747825901237,
            "rating_q025": 1058.1433107739856
        },
        "solar-10.7b-instruct-v1.0": {
            "rating": 1069.1515275025695,
            "rating_q975": 1088.7712090538578,
            "rating_q025": 1049.5318459512814
        },
        "nous-hermes-2-mixtral-8x7b-dpo": {
            "rating": 1063.84509127618,
            "rating_q975": 1081.2882670967836,
            "rating_q025": 1046.4019154555763
        },
        "dolphin-2.2.1-mistral-7b": {
            "rating": 1062.9055917339988,
            "rating_q975": 1091.152390968533,
            "rating_q025": 1034.6587924994647
        },
        "llama-2-13b-chat": {
            "rating": 1061.0139050417433,
            "rating_q975": 1070.9413979248368,
            "rating_q025": 1051.0864121586503
        },
        "mpt-30b-chat": {
            "rating": 1059.2649623771954,
            "rating_q975": 1086.6225429580059,
            "rating_q025": 1031.9073817963847
        },
        "llama-3.2-1b-instruct": {
            "rating": 1058.9561701897528,
            "rating_q975": 1070.7526999646852,
            "rating_q025": 1047.1596404148206
        },
        "codellama-70b-instruct": {
            "rating": 1058.3280276147761,
            "rating_q975": 1090.0205903107048,
            "rating_q025": 1026.6354649188477
        },
        "llama2-70b-steerlm-chat": {
            "rating": 1055.2840082885264,
            "rating_q975": 1075.8789256755786,
            "rating_q025": 1034.6890909014744
        },
        "gemma-7b-it": {
            "rating": 1050.908157154888,
            "rating_q975": 1064.1502345490396,
            "rating_q025": 1037.6660797607362
        },
        "codellama-34b-instruct": {
            "rating": 1039.8407231461017,
            "rating_q975": 1054.4133016848548,
            "rating_q025": 1025.2681446073486
        },
        "phi-3-mini-128k-instruct": {
            "rating": 1039.0063262738938,
            "rating_q975": 1049.4461002974929,
            "rating_q025": 1028.5665522502948
        },
        "qwen-14b-chat": {
            "rating": 1035.865693878959,
            "rating_q975": 1054.8436813370804,
            "rating_q025": 1016.887706420838
        },
        "zephyr-7b-beta": {
            "rating": 1035.8465807008392,
            "rating_q975": 1050.0956490657236,
            "rating_q025": 1021.5975123359548
        },
        "zephyr-7b-alpha": {
            "rating": 1033.7117174704513,
            "rating_q975": 1063.8655422904321,
            "rating_q025": 1003.5578926504703
        },
        "vicuna-13b": {
            "rating": 1031.936945204293,
            "rating_q975": 1042.4104168593221,
            "rating_q025": 1021.4634735492639
        },
        "wizardlm-13b": {
            "rating": 1025.973718329172,
            "rating_q975": 1042.4363129717362,
            "rating_q025": 1009.5111236866078
        },
        "llama-2-7b-chat": {
            "rating": 1018.6292166307654,
            "rating_q975": 1029.2562888627904,
            "rating_q025": 1008.0021443987405
        },
        "gemma-1.1-2b-it": {
            "rating": 1017.2161142630712,
            "rating_q975": 1028.584079848108,
            "rating_q025": 1005.8481486780342
        },
        "guanaco-33b": {
            "rating": 1013.1814328402229,
            "rating_q975": 1038.5393129346755,
            "rating_q025": 987.8235527457705
        },
        "palm-2": {
            "rating": 1012.836294134901,
            "rating_q975": 1028.4596720564955,
            "rating_q025": 997.2129162133067
        },
        "falcon-180b-chat": {
            "rating": 1012.8209067404789,
            "rating_q975": 1048.7745316216815,
            "rating_q025": 976.8672818592763
        },
        "mistral-7b-instruct": {
            "rating": 1010.7295381264613,
            "rating_q975": 1025.9009667255684,
            "rating_q025": 995.5581095273542
        },
        "stripedhyena-nous-7b": {
            "rating": 1006.8509383346978,
            "rating_q975": 1023.6793322252258,
            "rating_q025": 990.0225444441699
        },
        "vicuna-7b": {
            "rating": 1003.6409228272007,
            "rating_q975": 1020.5482005138647,
            "rating_q025": 986.7336451405367
        },
        "olmo-7b-instruct": {
            "rating": 1003.0067031543019,
            "rating_q975": 1019.6321320780312,
            "rating_q025": 986.3812742305727
        },
        "gemma-2b-it": {
            "rating": 998.2562456435024,
            "rating_q975": 1015.4824142920913,
            "rating_q025": 981.0300769949135
        },
        "qwen1.5-4b-chat": {
            "rating": 985.0267411403715,
            "rating_q975": 998.8561979882278,
            "rating_q025": 971.1972842925154
        },
        "chatglm3-6b": {
            "rating": 960.3180176473104,
            "rating_q975": 980.2268402687178,
            "rating_q025": 940.409195025903
        },
        "gpt4all-13b-snoozy": {
            "rating": 944.4456442927799,
            "rating_q975": 975.3595636924188,
            "rating_q025": 913.5317248931409
        },
        "koala-13b": {
            "rating": 937.3664682019757,
            "rating_q975": 955.8466757249175,
            "rating_q025": 918.886260679034
        },
        "chatglm2-6b": {
            "rating": 925.543248367917,
            "rating_q975": 952.4179750897429,
            "rating_q025": 898.6685216460912
        },
        "chatglm-6b": {
            "rating": 908.6601298655692,
            "rating_q975": 930.4288041925045,
            "rating_q025": 886.8914555386341
        },
        "mpt-7b-chat": {
            "rating": 904.6363944064453,
            "rating_q975": 927.1268426015552,
            "rating_q025": 882.1459462113355
        },
        "RWKV-4-Raven-14B": {
            "rating": 904.0744453296109,
            "rating_q975": 924.7929692525861,
            "rating_q025": 883.3559214066357
        },
        "oasst-pythia-12b": {
            "rating": 891.5519501749611,
            "rating_q975": 910.9340980618786,
            "rating_q025": 872.1698022880436
        },
        "stablelm-tuned-alpha-7b": {
            "rating": 842.2855857896138,
            "rating_q975": 867.5292897990255,
            "rating_q025": 817.0418817802022
        },
        "alpaca-13b": {
            "rating": 833.2119386899021,
            "rating_q975": 853.2204459287468,
            "rating_q025": 813.2034314510576
        },
        "fastchat-t5-3b": {
            "rating": 821.9829250934447,
            "rating_q975": 843.6934630825292,
            "rating_q025": 800.27238710436
        },
        "dolly-v2-12b": {
            "rating": 811.1957328590097,
            "rating_q975": 836.0982768150923,
            "rating_q025": 786.2931889029272
        },
        "llama-13b": {
            "rating": 735.3055362720517,
            "rating_q975": 766.4578969860645,
            "rating_q025": 704.1531755580387
        }
    },
    "hard_english_6": {
        "claude-opus-4-1-20250805-thinking-16k": {
            "rating": 1462.0764902737528,
            "rating_q975": 1476.9197276235243,
            "rating_q025": 1447.2332529239814
        },
        "gemini-2.5-pro": {
            "rating": 1460.8649691310313,
            "rating_q975": 1468.846991059921,
            "rating_q025": 1452.8829472021416
        },
        "gpt-5-high": {
            "rating": 1446.850861914522,
            "rating_q975": 1458.9709781659685,
            "rating_q025": 1434.7307456630756
        },
        "claude-opus-4-1-20250805": {
            "rating": 1440.241339916875,
            "rating_q975": 1452.5494114356097,
            "rating_q025": 1427.9332683981402
        },
        "grok-3-preview-02-24": {
            "rating": 1440.0486411825245,
            "rating_q975": 1447.6434021016337,
            "rating_q025": 1432.4538802634156
        },
        "mistral-medium-2508": {
            "rating": 1436.888006913331,
            "rating_q975": 1451.861156581137,
            "rating_q025": 1421.9148572455251
        },
        "qwen3-235b-a22b-instruct-2507": {
            "rating": 1435.6436299708812,
            "rating_q975": 1447.2062090063482,
            "rating_q025": 1424.0810509354144
        },
        "qwen3-235b-a22b-thinking-2507": {
            "rating": 1432.0242932398783,
            "rating_q975": 1445.6537857281055,
            "rating_q025": 1418.394800751651
        },
        "qwen-max-2025-08-15": {
            "rating": 1431.7502420726512,
            "rating_q975": 1449.2963663024589,
            "rating_q025": 1414.2041178428435
        },
        "grok-4-0709": {
            "rating": 1428.5373826214247,
            "rating_q975": 1438.1009850311207,
            "rating_q025": 1418.9737802117286
        },
        "glm-4.5": {
            "rating": 1422.0604988708064,
            "rating_q975": 1434.5039051670306,
            "rating_q025": 1409.6170925745826
        },
        "deepseek-v3.1-thinking": {
            "rating": 1421.3001572775743,
            "rating_q975": 1441.5423791846965,
            "rating_q025": 1401.057935370452
        },
        "deepseek-r1-0528": {
            "rating": 1421.1026233912387,
            "rating_q975": 1430.897896675905,
            "rating_q025": 1411.3073501065721
        },
        "deepseek-v3.1": {
            "rating": 1419.8704794200103,
            "rating_q975": 1438.3595213593999,
            "rating_q025": 1401.381437480621
        },
        "chatgpt-4o-latest-20250326": {
            "rating": 1418.7924804375682,
            "rating_q975": 1426.3731742173693,
            "rating_q025": 1411.2117866577669
        },
        "o3-2025-04-16": {
            "rating": 1416.9435035598826,
            "rating_q975": 1424.4116223995336,
            "rating_q025": 1409.475384720232
        },
        "gemini-2.5-flash": {
            "rating": 1412.124220675715,
            "rating_q975": 1419.7374032342984,
            "rating_q025": 1404.5110381171316
        },
        "gpt-4.5-preview-2025-02-27": {
            "rating": 1405.8479601874237,
            "rating_q975": 1417.5806233408093,
            "rating_q025": 1394.1152970340381
        },
        "claude-opus-4-20250514-thinking-16k": {
            "rating": 1405.1966745077623,
            "rating_q975": 1414.179193603635,
            "rating_q025": 1396.2141554118896
        },
        "gpt-5-chat": {
            "rating": 1404.5534044045874,
            "rating_q975": 1418.8077127477968,
            "rating_q025": 1390.299096061378
        },
        "mai-1-preview": {
            "rating": 1401.0305850983727,
            "rating_q975": 1421.4451937627293,
            "rating_q025": 1380.6159764340161
        },
        "qwen-vl-max-2025-08-13": {
            "rating": 1398.9308792542292,
            "rating_q975": 1432.5597620699796,
            "rating_q025": 1365.3019964384791
        },
        "qwen3-30b-a3b-instruct-2507": {
            "rating": 1397.5940926209341,
            "rating_q975": 1411.2228846169144,
            "rating_q025": 1383.9653006249541
        },
        "gpt-4.1-2025-04-14": {
            "rating": 1391.4504525962725,
            "rating_q975": 1399.4606290508827,
            "rating_q025": 1383.4402761416623
        },
        "gpt-5-mini-high": {
            "rating": 1390.2065294799863,
            "rating_q975": 1405.4357485775217,
            "rating_q025": 1374.977310382451
        },
        "glm-4.5-air": {
            "rating": 1389.7546457739966,
            "rating_q975": 1402.4166470589514,
            "rating_q025": 1377.092644489042
        },
        "claude-sonnet-4-20250514-thinking-32k": {
            "rating": 1389.2144744663578,
            "rating_q975": 1398.272602272417,
            "rating_q025": 1380.1563466602984
        },
        "hunyuan-t1-20250711": {
            "rating": 1387.642041430072,
            "rating_q975": 1404.856263768508,
            "rating_q025": 1370.427819091636
        },
        "qwen3-235b-a22b-no-thinking": {
            "rating": 1387.2644546162671,
            "rating_q975": 1395.3883279375125,
            "rating_q025": 1379.1405812950215
        },
        "qwen3-coder-480b-a35b-instruct": {
            "rating": 1386.7170414607058,
            "rating_q975": 1397.7148759077786,
            "rating_q025": 1375.719207013633
        },
        "claude-opus-4-20250514": {
            "rating": 1383.965291363901,
            "rating_q975": 1392.144769961219,
            "rating_q025": 1375.785812766583
        },
        "step-3": {
            "rating": 1381.5244471019867,
            "rating_q975": 1403.8117513481448,
            "rating_q025": 1359.2371428558286
        },
        "o1-preview": {
            "rating": 1378.0010825651682,
            "rating_q975": 1386.7201482267928,
            "rating_q025": 1369.2820169035435
        },
        "deepseek-v3-0324": {
            "rating": 1377.506538400948,
            "rating_q975": 1385.230264695561,
            "rating_q025": 1369.7828121063353
        },
        "kimi-k2-0711-preview": {
            "rating": 1375.9902975918023,
            "rating_q975": 1385.4798225825803,
            "rating_q025": 1366.5007726010244
        },
        "deepseek-r1": {
            "rating": 1374.6612881994904,
            "rating_q975": 1385.3266019648868,
            "rating_q025": 1363.995974434094
        },
        "o3-mini-high": {
            "rating": 1374.1667237161666,
            "rating_q975": 1384.6710617203887,
            "rating_q025": 1363.6623857119444
        },
        "mistral-medium-2505": {
            "rating": 1373.8728393199483,
            "rating_q975": 1381.6112859652324,
            "rating_q025": 1366.1343926746642
        },
        "hunyuan-turbos-20250416": {
            "rating": 1373.6461461032593,
            "rating_q975": 1385.612694691476,
            "rating_q025": 1361.6795975150428
        },
        "qwen3-235b-a22b": {
            "rating": 1373.549935884247,
            "rating_q975": 1381.9594261900145,
            "rating_q025": 1365.1404455784793
        },
        "grok-3-mini-high": {
            "rating": 1372.7049370580833,
            "rating_q975": 1382.8326371360877,
            "rating_q025": 1362.5772369800786
        },
        "o1-2024-12-17": {
            "rating": 1372.618551844695,
            "rating_q975": 1381.5062576813564,
            "rating_q025": 1363.7308460080337
        },
        "grok-3-mini-beta": {
            "rating": 1371.4848517593948,
            "rating_q975": 1380.360639606229,
            "rating_q025": 1362.609063912561
        },
        "gpt-oss-120b": {
            "rating": 1370.6207481889114,
            "rating_q975": 1384.7712724185646,
            "rating_q025": 1356.4702239592584
        },
        "o4-mini-2025-04-16": {
            "rating": 1369.031379386459,
            "rating_q975": 1377.0522240866999,
            "rating_q025": 1361.0105346862185
        },
        "qwen2.5-max": {
            "rating": 1361.8868299760347,
            "rating_q975": 1369.2325131494233,
            "rating_q025": 1354.5411468026462
        },
        "gpt-4.1-mini-2025-04-14": {
            "rating": 1359.0154743551898,
            "rating_q975": 1366.9899748895486,
            "rating_q025": 1351.040973820831
        },
        "gemini-2.0-flash-001": {
            "rating": 1357.3120576419342,
            "rating_q975": 1364.1002324241053,
            "rating_q025": 1350.523882859763
        },
        "minimax-m1": {
            "rating": 1357.2545158289054,
            "rating_q975": 1366.0416709862534,
            "rating_q025": 1348.4673606715573
        },
        "claude-sonnet-4-20250514": {
            "rating": 1355.9574328871254,
            "rating_q975": 1364.3970870396815,
            "rating_q025": 1347.5177787345694
        },
        "o1-mini": {
            "rating": 1353.3724124875403,
            "rating_q975": 1360.0641047070787,
            "rating_q025": 1346.680720268002
        },
        "mistral-small-2506": {
            "rating": 1353.1788337318346,
            "rating_q975": 1363.4324226820067,
            "rating_q025": 1342.9252447816625
        },
        "gpt-5-nano-high": {
            "rating": 1352.0243112709954,
            "rating_q975": 1369.8968013961705,
            "rating_q025": 1334.1518211458203
        },
        "glm-4.5v": {
            "rating": 1351.4703539466057,
            "rating_q975": 1387.570554979073,
            "rating_q025": 1315.3701529141385
        },
        "step-1o-turbo-202506": {
            "rating": 1351.1800676239359,
            "rating_q975": 1363.814142659973,
            "rating_q025": 1338.5459925878988
        },
        "qwen3-32b": {
            "rating": 1350.3665424790206,
            "rating_q975": 1370.9043236671778,
            "rating_q025": 1329.8287612908637
        },
        "nvidia-llama-3.3-nemotron-super-49b-v1.5": {
            "rating": 1347.4643015799934,
            "rating_q975": 1366.814110133355,
            "rating_q025": 1328.1144930266316
        },
        "o3-mini": {
            "rating": 1347.3025052500918,
            "rating_q975": 1353.84757222596,
            "rating_q025": 1340.7574382742237
        },
        "gemma-3-27b-it": {
            "rating": 1346.7657950224143,
            "rating_q975": 1354.1987740095096,
            "rating_q025": 1339.3328160353192
        },
        "claude-3-7-sonnet-20250219-thinking-32k": {
            "rating": 1344.8812753618065,
            "rating_q975": 1352.52883534057,
            "rating_q025": 1337.2337153830433
        },
        "qwq-32b": {
            "rating": 1341.0023997276624,
            "rating_q975": 1349.605270051828,
            "rating_q025": 1332.3995294034964
        },
        "hunyuan-turbos-20250226": {
            "rating": 1337.8453421496204,
            "rating_q975": 1363.8504384081339,
            "rating_q025": 1311.8402458911069
        },
        "llama-3.3-nemotron-49b-super-v1": {
            "rating": 1337.0641147693752,
            "rating_q975": 1364.5839105189248,
            "rating_q025": 1309.544319019826
        },
        "llama-3.1-nemotron-ultra-253b-v1": {
            "rating": 1334.9409570998025,
            "rating_q975": 1361.2240160742924,
            "rating_q025": 1308.6578981253126
        },
        "qwen-plus-0125": {
            "rating": 1334.9141171526908,
            "rating_q975": 1351.713257540979,
            "rating_q025": 1318.1149767644026
        },
        "gemini-2.0-flash-lite-preview-02-05": {
            "rating": 1331.0494014931069,
            "rating_q975": 1339.6019566674374,
            "rating_q025": 1322.4968463187763
        },
        "qwen3-30b-a3b": {
            "rating": 1328.9482235001324,
            "rating_q975": 1337.524458643749,
            "rating_q025": 1320.3719883565157
        },
        "command-a-03-2025": {
            "rating": 1328.4140905578097,
            "rating_q975": 1335.8211132843628,
            "rating_q025": 1321.0070678312566
        },
        "hunyuan-turbo-0110": {
            "rating": 1327.7563089747728,
            "rating_q975": 1353.223688923048,
            "rating_q025": 1302.2889290264977
        },
        "deepseek-v3": {
            "rating": 1325.2225122753157,
            "rating_q975": 1334.3283701438554,
            "rating_q025": 1316.1166544067762
        },
        "gpt-oss-20b": {
            "rating": 1322.8691679335227,
            "rating_q975": 1337.5613176387176,
            "rating_q025": 1308.1770182283278
        },
        "amazon-nova-experimental-chat-05-14": {
            "rating": 1321.8947179247589,
            "rating_q975": 1331.3378907641397,
            "rating_q025": 1312.4515450853778
        },
        "yi-lightning": {
            "rating": 1321.8765079081986,
            "rating_q975": 1330.873792754574,
            "rating_q025": 1312.8792230618235
        },
        "gemma-3-12b-it": {
            "rating": 1320.4694335073887,
            "rating_q975": 1341.0543469517784,
            "rating_q025": 1299.884520062999
        },
        "claude-3-7-sonnet-20250219": {
            "rating": 1320.1777849030536,
            "rating_q975": 1327.2983932368402,
            "rating_q025": 1313.0571765692669
        },
        "qwen2.5-plus-1127": {
            "rating": 1320.0909629518162,
            "rating_q975": 1332.3456521789078,
            "rating_q025": 1307.8362737247248
        },
        "claude-3-5-sonnet-20241022": {
            "rating": 1316.706262450624,
            "rating_q975": 1321.6674092049548,
            "rating_q025": 1311.7451156962932
        },
        "step-2-16k-exp-202412": {
            "rating": 1310.3371292105244,
            "rating_q975": 1328.1238690056489,
            "rating_q025": 1292.5503894153996
        },
        "athene-v2-chat": {
            "rating": 1307.7376268254013,
            "rating_q975": 1316.1602321149708,
            "rating_q025": 1299.3150215358319
        },
        "gemini-1.5-pro-002": {
            "rating": 1301.8605632216172,
            "rating_q975": 1307.9461072685308,
            "rating_q025": 1295.7750191747036
        },
        "deepseek-v2.5-1210": {
            "rating": 1301.2196293980878,
            "rating_q975": 1316.783985313629,
            "rating_q025": 1285.6552734825466
        },
        "llama-4-maverick-17b-128e-instruct": {
            "rating": 1299.0903201672206,
            "rating_q975": 1307.1767075927569,
            "rating_q025": 1291.0039327416844
        },
        "gemma-3n-e4b-it": {
            "rating": 1296.1471335812457,
            "rating_q975": 1306.1513231302279,
            "rating_q025": 1286.142944032264
        },
        "gpt-4o-2024-05-13": {
            "rating": 1295.7854492409688,
            "rating_q975": 1301.4608095872115,
            "rating_q025": 1290.1100888947258
        },
        "hunyuan-large-2025-02-10": {
            "rating": 1293.922055818933,
            "rating_q975": 1316.1005215566572,
            "rating_q025": 1271.7435900812086
        },
        "mistral-small-3.1-24b-instruct-2503": {
            "rating": 1293.6546337217526,
            "rating_q975": 1303.0552253967444,
            "rating_q025": 1284.254042046761
        },
        "llama-3.1-405b-instruct-bf16": {
            "rating": 1293.4353836853247,
            "rating_q975": 1300.103213343129,
            "rating_q025": 1286.7675540275206
        },
        "glm-4-plus-0111": {
            "rating": 1293.1031000128207,
            "rating_q975": 1310.0812388192107,
            "rating_q025": 1276.1249612064307
        },
        "gpt-4.1-nano-2025-04-14": {
            "rating": 1292.6439001494052,
            "rating_q975": 1309.5949292762596,
            "rating_q025": 1275.692871022551
        },
        "llama-4-scout-17b-16e-instruct": {
            "rating": 1287.6573482079098,
            "rating_q975": 1296.9800906859,
            "rating_q025": 1278.3346057299198
        },
        "llama-3.1-405b-instruct-fp8": {
            "rating": 1286.9110030046063,
            "rating_q975": 1293.2708111123804,
            "rating_q025": 1280.5511948968324
        },
        "llama-3.1-nemotron-70b-instruct": {
            "rating": 1286.6341302401386,
            "rating_q975": 1302.072758899784,
            "rating_q025": 1271.195501580493
        },
        "claude-3-5-sonnet-20240620": {
            "rating": 1285.099666587711,
            "rating_q975": 1291.222471022838,
            "rating_q025": 1278.976862152584
        },
        "deepseek-v2.5": {
            "rating": 1284.9180823727884,
            "rating_q975": 1293.4130393712524,
            "rating_q025": 1276.4231253743242
        },
        "qwen-max-0919": {
            "rating": 1284.371681300412,
            "rating_q975": 1294.8059293661875,
            "rating_q025": 1273.9374332346367
        },
        "qwen2.5-72b-instruct": {
            "rating": 1283.8917647346052,
            "rating_q975": 1290.975972835143,
            "rating_q025": 1276.8075566340674
        },
        "grok-2-2024-08-13": {
            "rating": 1283.705776829067,
            "rating_q975": 1289.7485211903963,
            "rating_q025": 1277.6630324677376
        },
        "glm-4-plus": {
            "rating": 1282.5663230536957,
            "rating_q975": 1291.3973435962587,
            "rating_q025": 1273.7353025111324
        },
        "hunyuan-large-vision": {
            "rating": 1282.138411915674,
            "rating_q975": 1298.382018602148,
            "rating_q025": 1265.8948052291996
        },
        "gpt-4o-mini-2024-07-18": {
            "rating": 1281.8183955694294,
            "rating_q975": 1287.4938328767075,
            "rating_q025": 1276.1429582621515
        },
        "magistral-medium-2506": {
            "rating": 1280.8782027713094,
            "rating_q975": 1293.600393044154,
            "rating_q025": 1268.1560124984646
        },
        "gpt-4o-2024-08-06": {
            "rating": 1280.0453840733517,
            "rating_q975": 1287.0309864158733,
            "rating_q025": 1273.05978173083
        },
        "llama-3.3-70b-instruct": {
            "rating": 1278.2139961429216,
            "rating_q975": 1284.2232267677018,
            "rating_q025": 1272.2047655181411
        },
        "hunyuan-standard-2025-02-10": {
            "rating": 1276.9250761698122,
            "rating_q975": 1299.9273016708248,
            "rating_q025": 1253.9228506687996
        },
        "qwen2.5-coder-32b-instruct": {
            "rating": 1275.0441828632388,
            "rating_q975": 1293.3367927836048,
            "rating_q025": 1256.7515729428726
        },
        "mistral-large-2407": {
            "rating": 1273.819987382257,
            "rating_q975": 1280.7982123524132,
            "rating_q025": 1266.841762412101
        },
        "mistral-large-2411": {
            "rating": 1270.9064744571033,
            "rating_q975": 1278.9094825840166,
            "rating_q025": 1262.9034663301902
        },
        "grok-2-mini-2024-08-13": {
            "rating": 1270.5466918102975,
            "rating_q975": 1276.9434001652446,
            "rating_q025": 1264.1499834553506
        },
        "gemini-1.5-flash-002": {
            "rating": 1270.3361380823717,
            "rating_q975": 1277.7731994285268,
            "rating_q025": 1262.8990767362168
        },
        "gpt-4-turbo-2024-04-09": {
            "rating": 1270.2057710914683,
            "rating_q975": 1276.5337709600042,
            "rating_q025": 1263.8777712229326
        },
        "claude-3-5-haiku-20241022": {
            "rating": 1266.6275101254955,
            "rating_q975": 1272.5586850741247,
            "rating_q025": 1260.6963351768663
        },
        "llama-3.1-70b-instruct": {
            "rating": 1265.2863022669208,
            "rating_q975": 1271.6959763725615,
            "rating_q025": 1258.87662816128
        },
        "gemini-1.5-pro-001": {
            "rating": 1262.861903293875,
            "rating_q975": 1269.5134682809344,
            "rating_q025": 1256.2103383068156
        },
        "amazon-nova-pro-v1.0": {
            "rating": 1261.9279781595442,
            "rating_q975": 1270.225506430398,
            "rating_q025": 1253.6304498886907
        },
        "athene-70b-0725": {
            "rating": 1259.812279691003,
            "rating_q975": 1269.3643566935114,
            "rating_q025": 1250.2602026884947
        },
        "gpt-4-1106-preview": {
            "rating": 1258.9614718868684,
            "rating_q975": 1265.4160961987902,
            "rating_q025": 1252.5068475749467
        },
        "gpt-4-0125-preview": {
            "rating": 1255.8480290374707,
            "rating_q975": 1262.4650340449302,
            "rating_q025": 1249.2310240300112
        },
        "gemma-3-4b-it": {
            "rating": 1255.1778393988877,
            "rating_q975": 1275.3132310665655,
            "rating_q025": 1235.04244773121
        },
        "gemini-advanced-0514": {
            "rating": 1254.11868565386,
            "rating_q975": 1262.2863789326595,
            "rating_q025": 1245.9509923750604
        },
        "claude-3-opus-20240229": {
            "rating": 1248.0373600160221,
            "rating_q975": 1253.073707374135,
            "rating_q025": 1243.0010126579093
        },
        "olmo-2-0325-32b-instruct": {
            "rating": 1247.463247949508,
            "rating_q975": 1270.9381701056882,
            "rating_q025": 1223.9883257933277
        },
        "mistral-small-24b-instruct-2501": {
            "rating": 1245.137956544141,
            "rating_q975": 1256.459035593734,
            "rating_q025": 1233.816877494548
        },
        "llama-3.1-tulu-3-70b": {
            "rating": 1242.0503645440226,
            "rating_q975": 1264.7469638146902,
            "rating_q025": 1219.3537652733553
        },
        "jamba-1.5-large": {
            "rating": 1236.3611301917672,
            "rating_q975": 1249.801516188459,
            "rating_q025": 1222.9207441950755
        },
        "phi-4": {
            "rating": 1236.0860661770796,
            "rating_q975": 1245.0080446747772,
            "rating_q025": 1227.164087679382
        },
        "llama-3-70b-instruct": {
            "rating": 1235.358512050113,
            "rating_q975": 1241.4605060910262,
            "rating_q025": 1229.2565180091995
        },
        "hunyuan-standard-256k": {
            "rating": 1235.1880065737578,
            "rating_q975": 1262.2434695412112,
            "rating_q025": 1208.1325436063044
        },
        "amazon-nova-lite-v1.0": {
            "rating": 1231.7824656191833,
            "rating_q975": 1241.3700334661842,
            "rating_q025": 1222.1948977721822
        },
        "gemini-1.5-flash-001": {
            "rating": 1229.8050282622035,
            "rating_q975": 1236.5845408478121,
            "rating_q025": 1223.025515676595
        },
        "glm-4-0520": {
            "rating": 1223.3105662744429,
            "rating_q975": 1236.3301003718848,
            "rating_q025": 1210.291032177001
        },
        "deepseek-coder-v2": {
            "rating": 1222.7458287377176,
            "rating_q975": 1234.1956076858262,
            "rating_q025": 1211.296049789609
        },
        "gemini-1.5-flash-8b-001": {
            "rating": 1221.231341445483,
            "rating_q975": 1228.702828768279,
            "rating_q025": 1213.7598541226866
        },
        "reka-core-20240904": {
            "rating": 1219.762149910956,
            "rating_q975": 1232.9939617469377,
            "rating_q025": 1206.5303380749742
        },
        "ministral-8b-2410": {
            "rating": 1214.5414347805618,
            "rating_q975": 1233.630300611406,
            "rating_q025": 1195.4525689497173
        },
        "gpt-4-0314": {
            "rating": 1214.4886878336529,
            "rating_q975": 1222.8728509208704,
            "rating_q025": 1206.1045247464351
        },
        "gemma-2-27b-it": {
            "rating": 1211.4702728966126,
            "rating_q975": 1217.0687139806635,
            "rating_q025": 1205.8718318125616
        },
        "amazon-nova-micro-v1.0": {
            "rating": 1211.0958987370866,
            "rating_q975": 1220.536740611273,
            "rating_q025": 1201.6550568629002
        },
        "qwen2-72b-instruct": {
            "rating": 1210.6473887531686,
            "rating_q975": 1218.818830458321,
            "rating_q025": 1202.4759470480165
        },
        "llama-3.1-nemotron-51b-instruct": {
            "rating": 1210.278034193818,
            "rating_q975": 1231.9917739978334,
            "rating_q025": 1188.5642943898026
        },
        "nemotron-4-340b-instruct": {
            "rating": 1207.7992002241149,
            "rating_q975": 1218.3419365876393,
            "rating_q025": 1197.2564638605904
        },
        "claude-3-sonnet-20240229": {
            "rating": 1207.718975166012,
            "rating_q975": 1214.3890725707633,
            "rating_q025": 1201.0488777612602
        },
        "gemma-2-9b-it-simpo": {
            "rating": 1206.9693230279695,
            "rating_q975": 1220.231467906127,
            "rating_q025": 1193.7071781498123
        },
        "llama-3.1-8b-instruct": {
            "rating": 1202.4220046254345,
            "rating_q975": 1209.2471492247053,
            "rating_q025": 1195.5968600261638
        },
        "c4ai-aya-expanse-32b": {
            "rating": 1202.0665029789898,
            "rating_q975": 1210.652008790453,
            "rating_q025": 1193.4809971675265
        },
        "command-r-plus-08-2024": {
            "rating": 1199.739596663961,
            "rating_q975": 1212.125601887876,
            "rating_q025": 1187.3535914400463
        },
        "internlm2_5-20b-chat": {
            "rating": 1199.6634013485266,
            "rating_q975": 1212.8879295799807,
            "rating_q025": 1186.4388731170725
        },
        "gpt-4-0613": {
            "rating": 1194.149988214764,
            "rating_q975": 1201.1883044309145,
            "rating_q025": 1187.1116719986137
        },
        "reka-flash-20240904": {
            "rating": 1193.011626902951,
            "rating_q975": 1205.9532030017458,
            "rating_q025": 1180.0700508041566
        },
        "qwen1.5-110b-chat": {
            "rating": 1190.6271703143116,
            "rating_q975": 1200.577194079514,
            "rating_q025": 1180.677146549109
        },
        "llama-3.1-tulu-3-8b": {
            "rating": 1187.784927777052,
            "rating_q975": 1212.1226971148037,
            "rating_q025": 1163.4471584393
        },
        "claude-3-haiku-20240307": {
            "rating": 1187.2172594897033,
            "rating_q975": 1193.2540395367357,
            "rating_q025": 1181.1804794426712
        },
        "jamba-1.5-mini": {
            "rating": 1186.7363845557409,
            "rating_q975": 1200.5685679412143,
            "rating_q025": 1172.9042011702672
        },
        "gemma-2-9b-it": {
            "rating": 1185.1872999092516,
            "rating_q975": 1191.6156445677432,
            "rating_q025": 1178.7589552507595
        },
        "yi-1.5-34b-chat": {
            "rating": 1184.6046495959256,
            "rating_q975": 1194.1846259465904,
            "rating_q025": 1175.0246732452608
        },
        "mistral-large-2402": {
            "rating": 1184.2352557683498,
            "rating_q975": 1191.9990154745785,
            "rating_q025": 1176.471496062121
        },
        "qwq-32b-preview": {
            "rating": 1182.9055733485118,
            "rating_q975": 1206.328572379984,
            "rating_q025": 1159.4825743170395
        },
        "command-r-08-2024": {
            "rating": 1179.5495580259242,
            "rating_q975": 1191.6307858154412,
            "rating_q025": 1167.4683302364072
        },
        "command-r-plus": {
            "rating": 1177.3474456629228,
            "rating_q975": 1184.41540659823,
            "rating_q025": 1170.2794847276157
        },
        "granite-3.1-8b-instruct": {
            "rating": 1171.0345173313765,
            "rating_q975": 1194.1135477392206,
            "rating_q025": 1147.9554869235324
        },
        "llama-3-8b-instruct": {
            "rating": 1170.2143330977215,
            "rating_q975": 1176.8331712777247,
            "rating_q025": 1163.5954949177185
        },
        "mixtral-8x22b-instruct-v0.1": {
            "rating": 1169.3123022710884,
            "rating_q975": 1177.0427795176859,
            "rating_q025": 1161.581825024491
        },
        "qwen1.5-72b-chat": {
            "rating": 1167.801269317765,
            "rating_q975": 1176.2152289379774,
            "rating_q025": 1159.3873096975524
        },
        "granite-3.1-2b-instruct": {
            "rating": 1165.1277911600287,
            "rating_q975": 1188.5171432149064,
            "rating_q025": 1141.738439105151
        },
        "mistral-medium": {
            "rating": 1164.2832709553336,
            "rating_q975": 1173.6408096513262,
            "rating_q025": 1154.9257322593412
        },
        "c4ai-aya-expanse-8b": {
            "rating": 1163.2891605565992,
            "rating_q975": 1176.9533666044063,
            "rating_q025": 1149.6249545087921
        },
        "reka-flash-21b-20240226-online": {
            "rating": 1154.2578080758672,
            "rating_q975": 1166.408529752601,
            "rating_q025": 1142.1070863991336
        },
        "qwen1.5-32b-chat": {
            "rating": 1152.8950654861692,
            "rating_q975": 1163.491237196734,
            "rating_q025": 1142.2988937756043
        },
        "reka-flash-21b-20240226": {
            "rating": 1150.8636807266676,
            "rating_q975": 1160.8701733660123,
            "rating_q025": 1140.8571880873226
        },
        "phi-3-medium-4k-instruct": {
            "rating": 1149.1372843503464,
            "rating_q975": 1158.3885359064,
            "rating_q025": 1139.8860327942925
        },
        "llama-3.2-3b-instruct": {
            "rating": 1148.8211486752984,
            "rating_q975": 1163.0564341251488,
            "rating_q025": 1134.5858632254478
        },
        "dbrx-instruct-preview": {
            "rating": 1145.3647103337848,
            "rating_q975": 1155.6410398375447,
            "rating_q025": 1135.0883808300252
        },
        "mixtral-8x7b-instruct-v0.1": {
            "rating": 1142.3372076589242,
            "rating_q975": 1149.5582486812666,
            "rating_q025": 1135.1161666365817
        },
        "zephyr-orpo-141b-A35b-v0.1": {
            "rating": 1139.3646562414724,
            "rating_q975": 1159.318134656378,
            "rating_q025": 1119.4111778265665
        },
        "gemma-2-2b-it": {
            "rating": 1137.5976580564236,
            "rating_q975": 1144.6375012456865,
            "rating_q025": 1130.557814867161
        },
        "starling-lm-7b-beta": {
            "rating": 1137.1495551972423,
            "rating_q975": 1149.3461134712213,
            "rating_q025": 1124.9529969232633
        },
        "granite-3.0-8b-instruct": {
            "rating": 1135.6446451681693,
            "rating_q975": 1153.7068335210417,
            "rating_q025": 1117.5824568152968
        },
        "phi-3-small-8k-instruct": {
            "rating": 1132.9342604407373,
            "rating_q975": 1144.022158375086,
            "rating_q025": 1121.8463625063885
        },
        "qwen1.5-14b-chat": {
            "rating": 1130.4760753937069,
            "rating_q975": 1142.7062678361808,
            "rating_q025": 1118.2458829512327
        },
        "tulu-2-dpo-70b": {
            "rating": 1130.1517931067074,
            "rating_q975": 1147.3982640221966,
            "rating_q025": 1112.905322191218
        },
        "gpt-3.5-turbo-0125": {
            "rating": 1129.8440459856151,
            "rating_q975": 1137.0364859030321,
            "rating_q025": 1122.6516060681984
        },
        "command-r": {
            "rating": 1129.4629274784782,
            "rating_q975": 1137.5551687312238,
            "rating_q025": 1121.3706862257325
        },
        "yi-34b-chat": {
            "rating": 1127.112292998285,
            "rating_q975": 1138.7631193319207,
            "rating_q025": 1115.4614666646494
        },
        "gemini-pro-dev-api": {
            "rating": 1124.0556414270277,
            "rating_q975": 1136.2322992878403,
            "rating_q025": 1111.878983566215
        },
        "phi-3-mini-4k-instruct-june-2024": {
            "rating": 1122.7933992615062,
            "rating_q975": 1135.103131761675,
            "rating_q025": 1110.4836667613376
        },
        "gpt-3.5-turbo-1106": {
            "rating": 1121.7017959300765,
            "rating_q975": 1135.2618445574642,
            "rating_q025": 1108.1417473026888
        },
        "gemini-pro": {
            "rating": 1117.3166885880764,
            "rating_q975": 1136.1119488025497,
            "rating_q025": 1098.5214283736036
        },
        "granite-3.0-2b-instruct": {
            "rating": 1105.1583913666072,
            "rating_q975": 1122.8112469108332,
            "rating_q025": 1087.5055358223813
        },
        "phi-3-mini-4k-instruct": {
            "rating": 1102.8462001933035,
            "rating_q975": 1113.8497623815513,
            "rating_q025": 1091.842638005056
        },
        "wizardlm-70b": {
            "rating": 1102.590365776467,
            "rating_q975": 1118.7496296014501,
            "rating_q025": 1086.431101951484
        },
        "openchat-3.5-0106": {
            "rating": 1102.3766550864982,
            "rating_q975": 1114.3903509912163,
            "rating_q025": 1090.36295918178
        },
        "starling-lm-7b-alpha": {
            "rating": 1101.9328756653408,
            "rating_q975": 1115.7526286064124,
            "rating_q025": 1088.1131227242695
        },
        "llama-2-70b-chat": {
            "rating": 1099.104130347855,
            "rating_q975": 1107.8927053764567,
            "rating_q025": 1090.3155553192537
        },
        "gemma-1.1-7b-it": {
            "rating": 1098.7000129856947,
            "rating_q975": 1108.495741714077,
            "rating_q025": 1088.9042842573122
        },
        "llama-3.2-1b-instruct": {
            "rating": 1098.4648148365002,
            "rating_q975": 1112.4687473154768,
            "rating_q025": 1084.4608823575236
        },
        "mistral-7b-instruct-v0.2": {
            "rating": 1097.8351317843858,
            "rating_q975": 1108.344244067114,
            "rating_q025": 1087.3260195016576
        },
        "snowflake-arctic-instruct": {
            "rating": 1096.5849331516984,
            "rating_q975": 1106.8819219496922,
            "rating_q025": 1086.2879443537047
        },
        "openhermes-2.5-mistral-7b": {
            "rating": 1093.958339470188,
            "rating_q975": 1112.3818798862687,
            "rating_q025": 1075.5347990541075
        },
        "deepseek-llm-67b-chat": {
            "rating": 1092.0287846329152,
            "rating_q975": 1111.9225840913123,
            "rating_q025": 1072.134985174518
        },
        "smollm2-1.7b-instruct": {
            "rating": 1091.0999010713276,
            "rating_q975": 1121.0408434566102,
            "rating_q025": 1061.158958686045
        },
        "mpt-30b-chat": {
            "rating": 1088.6382320286812,
            "rating_q975": 1118.7301932567725,
            "rating_q025": 1058.54627080059
        },
        "vicuna-33b": {
            "rating": 1088.1313035129083,
            "rating_q975": 1099.0014519256574,
            "rating_q025": 1077.2611551001592
        },
        "qwen1.5-7b-chat": {
            "rating": 1083.036512905413,
            "rating_q975": 1100.2102174616568,
            "rating_q025": 1065.8628083491692
        },
        "llama-2-13b-chat": {
            "rating": 1081.8086968342086,
            "rating_q975": 1093.2424415638984,
            "rating_q025": 1070.3749521045188
        },
        "solar-10.7b-instruct-v1.0": {
            "rating": 1080.9048150304727,
            "rating_q975": 1102.4033154934987,
            "rating_q025": 1059.406314567447
        },
        "codellama-70b-instruct": {
            "rating": 1080.5342213480965,
            "rating_q975": 1117.9829917529062,
            "rating_q025": 1043.0854509432868
        },
        "openchat-3.5": {
            "rating": 1078.378982249951,
            "rating_q975": 1094.9127378302194,
            "rating_q025": 1061.8452266696825
        },
        "nous-hermes-2-mixtral-8x7b-dpo": {
            "rating": 1075.7460553539213,
            "rating_q975": 1094.1016546709886,
            "rating_q025": 1057.3904560368537
        },
        "dolphin-2.2.1-mistral-7b": {
            "rating": 1075.1700113015786,
            "rating_q975": 1107.0644379037105,
            "rating_q025": 1043.2755846994464
        },
        "gemma-7b-it": {
            "rating": 1069.7521061838875,
            "rating_q975": 1084.5989251812928,
            "rating_q025": 1054.9052871864824
        },
        "llama2-70b-steerlm-chat": {
            "rating": 1063.6004013068637,
            "rating_q975": 1086.3132856337202,
            "rating_q025": 1040.8875169800071
        },
        "phi-3-mini-128k-instruct": {
            "rating": 1059.9954442688077,
            "rating_q975": 1071.9444336533056,
            "rating_q025": 1048.0464548843097
        },
        "zephyr-7b-beta": {
            "rating": 1055.5271419867165,
            "rating_q975": 1070.7796706238548,
            "rating_q025": 1040.2746133495784
        },
        "codellama-34b-instruct": {
            "rating": 1053.4663929111762,
            "rating_q975": 1069.262208061701,
            "rating_q025": 1037.6705777606512
        },
        "zephyr-7b-alpha": {
            "rating": 1050.921026032453,
            "rating_q975": 1084.4151770080769,
            "rating_q025": 1017.4268750568294
        },
        "qwen-14b-chat": {
            "rating": 1048.0397499960548,
            "rating_q975": 1068.3815340112715,
            "rating_q025": 1027.697965980838
        },
        "vicuna-13b": {
            "rating": 1042.7689077682728,
            "rating_q975": 1054.4804145586145,
            "rating_q025": 1031.0574009779311
        },
        "palm-2": {
            "rating": 1042.0106728694343,
            "rating_q975": 1058.493996712943,
            "rating_q025": 1025.5273490259256
        },
        "wizardlm-13b": {
            "rating": 1041.1185212064236,
            "rating_q975": 1059.2160226793549,
            "rating_q025": 1023.0210197334923
        },
        "llama-2-7b-chat": {
            "rating": 1040.070501702762,
            "rating_q975": 1052.078605015056,
            "rating_q025": 1028.062398390468
        },
        "gemma-1.1-2b-it": {
            "rating": 1036.232408637084,
            "rating_q975": 1050.0985625718952,
            "rating_q025": 1022.3662547022727
        },
        "mistral-7b-instruct": {
            "rating": 1029.7062362470285,
            "rating_q975": 1045.966111717883,
            "rating_q025": 1013.4463607761738
        },
        "guanaco-33b": {
            "rating": 1027.1863557823633,
            "rating_q975": 1055.2178475388953,
            "rating_q025": 999.1548640258313
        },
        "stripedhyena-nous-7b": {
            "rating": 1022.2651807553491,
            "rating_q975": 1040.1877939313567,
            "rating_q025": 1004.3425675793412
        },
        "olmo-7b-instruct": {
            "rating": 1018.5508476167281,
            "rating_q975": 1037.0416065428135,
            "rating_q025": 1000.0600886906427
        },
        "vicuna-7b": {
            "rating": 1011.7679467694986,
            "rating_q975": 1030.2070535395544,
            "rating_q025": 993.3288399994428
        },
        "gemma-2b-it": {
            "rating": 1003.2819900137233,
            "rating_q975": 1023.0519793625588,
            "rating_q025": 983.5120006648881
        },
        "qwen1.5-4b-chat": {
            "rating": 990.8638434980721,
            "rating_q975": 1006.6453229474653,
            "rating_q025": 975.0823640486789
        },
        "chatglm3-6b": {
            "rating": 983.9230793520312,
            "rating_q975": 1005.0422161806666,
            "rating_q025": 962.8039425233958
        },
        "gpt4all-13b-snoozy": {
            "rating": 962.4925562018437,
            "rating_q975": 996.3558863278904,
            "rating_q025": 928.6292260757971
        },
        "koala-13b": {
            "rating": 949.3965442907386,
            "rating_q975": 969.1350773261835,
            "rating_q025": 929.6580112552938
        },
        "chatglm2-6b": {
            "rating": 946.2721368511216,
            "rating_q975": 975.3367030480247,
            "rating_q025": 917.2075706542184
        },
        "mpt-7b-chat": {
            "rating": 916.583771420729,
            "rating_q975": 940.884934572373,
            "rating_q025": 892.282608269085
        },
        "RWKV-4-Raven-14B": {
            "rating": 908.276043154216,
            "rating_q975": 930.5341229435439,
            "rating_q025": 886.0179633648883
        },
        "oasst-pythia-12b": {
            "rating": 903.1955302838812,
            "rating_q975": 923.9683590764732,
            "rating_q025": 882.4227014912894
        },
        "chatglm-6b": {
            "rating": 902.7312709446173,
            "rating_q975": 926.2370876451928,
            "rating_q025": 879.2254542440419
        },
        "stablelm-tuned-alpha-7b": {
            "rating": 855.341839872546,
            "rating_q975": 882.8404302728493,
            "rating_q025": 827.8432494722426
        },
        "alpaca-13b": {
            "rating": 845.7914084047663,
            "rating_q975": 867.4549958048527,
            "rating_q025": 824.1278210046798
        },
        "fastchat-t5-3b": {
            "rating": 836.2807005826916,
            "rating_q975": 859.5833878811177,
            "rating_q025": 812.9780132842654
        },
        "dolly-v2-12b": {
            "rating": 815.6221841678181,
            "rating_q975": 842.7097698472681,
            "rating_q025": 788.534598488368
        },
        "llama-13b": {
            "rating": 740.5232313338313,
            "rating_q975": 774.6697547523725,
            "rating_q025": 706.37670791529
        }
    },
    "if": {
        "gemini-2.5-pro": {
            "rating": 1441.0470614870494,
            "rating_q975": 1448.5376757097567,
            "rating_q025": 1433.556447264342
        },
        "claude-opus-4-1-20250805-thinking-16k": {
            "rating": 1430.5914692977362,
            "rating_q975": 1443.7103671298064,
            "rating_q025": 1417.4725714656663
        },
        "claude-opus-4-1-20250805": {
            "rating": 1422.7880582943374,
            "rating_q975": 1434.2584471609684,
            "rating_q025": 1411.317669427706
        },
        "qwen-max-2025-08-15": {
            "rating": 1409.608140010409,
            "rating_q975": 1425.347378260788,
            "rating_q025": 1393.86890176003
        },
        "grok-3-preview-02-24": {
            "rating": 1406.6179773232363,
            "rating_q975": 1412.7675208588732,
            "rating_q025": 1400.4684337875995
        },
        "gpt-5-high": {
            "rating": 1406.4163614629206,
            "rating_q975": 1417.5875639670783,
            "rating_q025": 1395.2451589587629
        },
        "qwen3-235b-a22b-instruct-2507": {
            "rating": 1406.3288812867909,
            "rating_q975": 1416.547862854173,
            "rating_q025": 1396.1098997194088
        },
        "mistral-medium-2508": {
            "rating": 1404.1749357128579,
            "rating_q975": 1417.7389437900915,
            "rating_q025": 1390.6109276356242
        },
        "gpt-4.5-preview-2025-02-27": {
            "rating": 1401.5472763416058,
            "rating_q975": 1409.4582843625049,
            "rating_q025": 1393.6362683207064
        },
        "grok-4-0709": {
            "rating": 1401.4745855983153,
            "rating_q975": 1410.307532558187,
            "rating_q025": 1392.6416386384435
        },
        "glm-4.5": {
            "rating": 1399.586774277999,
            "rating_q975": 1410.784424639984,
            "rating_q025": 1388.3891239160137
        },
        "deepseek-v3.1-thinking": {
            "rating": 1397.942629945129,
            "rating_q975": 1415.5091107850108,
            "rating_q025": 1380.3761491052471
        },
        "gemini-2.5-flash": {
            "rating": 1397.5639887486366,
            "rating_q975": 1404.6792242194472,
            "rating_q025": 1390.4487532778262
        },
        "chatgpt-4o-latest-20250326": {
            "rating": 1397.3355203964156,
            "rating_q975": 1403.816097502624,
            "rating_q025": 1390.8549432902073
        },
        "claude-opus-4-20250514-thinking-16k": {
            "rating": 1397.157885938121,
            "rating_q975": 1405.4876831037718,
            "rating_q025": 1388.82808877247
        },
        "qwen3-235b-a22b-thinking-2507": {
            "rating": 1396.0848211284347,
            "rating_q975": 1408.6243537384387,
            "rating_q025": 1383.5452885184304
        },
        "qwen-vl-max-2025-08-13": {
            "rating": 1390.9891677410194,
            "rating_q975": 1420.7089550430733,
            "rating_q025": 1361.2693804389655
        },
        "gpt-5-chat": {
            "rating": 1390.6160860813247,
            "rating_q975": 1403.71319107659,
            "rating_q025": 1377.5189810860597
        },
        "deepseek-v3.1": {
            "rating": 1385.0064047532567,
            "rating_q975": 1401.149927381794,
            "rating_q025": 1368.8628821247194
        },
        "deepseek-r1-0528": {
            "rating": 1383.3299672927296,
            "rating_q975": 1392.270959714096,
            "rating_q025": 1374.3889748713634
        },
        "o3-2025-04-16": {
            "rating": 1378.4701090342242,
            "rating_q975": 1385.2097697201766,
            "rating_q025": 1371.7304483482717
        },
        "claude-opus-4-20250514": {
            "rating": 1373.984251737739,
            "rating_q975": 1381.673224655042,
            "rating_q025": 1366.2952788204361
        },
        "claude-sonnet-4-20250514-thinking-32k": {
            "rating": 1372.7382221127468,
            "rating_q975": 1381.2251695531513,
            "rating_q025": 1364.251274672342
        },
        "hunyuan-t1-20250711": {
            "rating": 1371.5138100963934,
            "rating_q975": 1386.7198519240465,
            "rating_q025": 1356.3077682687401
        },
        "gpt-4.1-2025-04-14": {
            "rating": 1368.3307696323825,
            "rating_q975": 1375.5453873614138,
            "rating_q025": 1361.1161519033515
        },
        "mai-1-preview": {
            "rating": 1367.2758994500139,
            "rating_q975": 1384.7359372494473,
            "rating_q025": 1349.8158616505805
        },
        "o1-2024-12-17": {
            "rating": 1365.389311372432,
            "rating_q975": 1371.4904138266486,
            "rating_q025": 1359.2882089182156
        },
        "glm-4.5-air": {
            "rating": 1365.1237670235967,
            "rating_q975": 1376.576165562491,
            "rating_q025": 1353.671368484702
        },
        "gpt-5-mini-high": {
            "rating": 1365.0476628990125,
            "rating_q975": 1379.2920105943879,
            "rating_q025": 1350.8033152036373
        },
        "qwen3-30b-a3b-instruct-2507": {
            "rating": 1362.3998927188065,
            "rating_q975": 1374.90556574268,
            "rating_q025": 1349.8942196949329
        },
        "qwen3-235b-a22b-no-thinking": {
            "rating": 1358.355528884656,
            "rating_q975": 1365.8951262263668,
            "rating_q025": 1350.815931542945
        },
        "deepseek-r1": {
            "rating": 1356.8961645226,
            "rating_q975": 1363.9402632420597,
            "rating_q025": 1349.8520658031402
        },
        "qwen3-coder-480b-a35b-instruct": {
            "rating": 1354.3452443181454,
            "rating_q975": 1364.5149538924543,
            "rating_q025": 1344.1755347438366
        },
        "grok-3-mini-high": {
            "rating": 1351.0228434540202,
            "rating_q975": 1360.4157312840791,
            "rating_q025": 1341.6299556239615
        },
        "claude-3-7-sonnet-20250219-thinking-32k": {
            "rating": 1348.4565840566224,
            "rating_q975": 1354.8754013075184,
            "rating_q025": 1342.0377668057265
        },
        "deepseek-v3-0324": {
            "rating": 1347.333454279493,
            "rating_q975": 1353.9761060887267,
            "rating_q025": 1340.690802470259
        },
        "grok-3-mini-beta": {
            "rating": 1343.793085965769,
            "rating_q975": 1352.0503323280163,
            "rating_q025": 1335.5358396035217
        },
        "claude-sonnet-4-20250514": {
            "rating": 1343.130385366483,
            "rating_q975": 1350.9464464746309,
            "rating_q025": 1335.3143242583353
        },
        "hunyuan-turbos-20250416": {
            "rating": 1342.9728202208119,
            "rating_q975": 1353.9666177746271,
            "rating_q025": 1331.9790226669966
        },
        "o1-preview": {
            "rating": 1342.8348446176446,
            "rating_q975": 1349.108658155809,
            "rating_q025": 1336.5610310794802
        },
        "step-3": {
            "rating": 1340.1434784092223,
            "rating_q975": 1361.0019167900152,
            "rating_q025": 1319.2850400284292
        },
        "mistral-medium-2505": {
            "rating": 1339.4832073696996,
            "rating_q975": 1346.623029978677,
            "rating_q025": 1332.3433847607218
        },
        "kimi-k2-0711-preview": {
            "rating": 1338.5399731996042,
            "rating_q975": 1347.2119587086067,
            "rating_q025": 1329.8679876906017
        },
        "o3-mini-high": {
            "rating": 1337.002621334535,
            "rating_q975": 1344.2760507128103,
            "rating_q025": 1329.7291919562597
        },
        "gemini-2.0-flash-001": {
            "rating": 1336.327480273526,
            "rating_q975": 1341.6914298304675,
            "rating_q025": 1330.9635307165843
        },
        "qwen3-235b-a22b": {
            "rating": 1335.2741238138476,
            "rating_q975": 1343.109614361271,
            "rating_q025": 1327.4386332664244
        },
        "qwen2.5-max": {
            "rating": 1335.036140319313,
            "rating_q975": 1340.669135687997,
            "rating_q025": 1329.4031449506292
        },
        "gpt-4.1-mini-2025-04-14": {
            "rating": 1330.7873798523171,
            "rating_q975": 1337.8991605058914,
            "rating_q025": 1323.6755991987427
        },
        "o4-mini-2025-04-16": {
            "rating": 1327.9518983816756,
            "rating_q975": 1335.1755157454081,
            "rating_q025": 1320.7282810179431
        },
        "gpt-oss-120b": {
            "rating": 1324.7173636849564,
            "rating_q975": 1338.1311137819453,
            "rating_q025": 1311.3036135879674
        },
        "gemma-3-27b-it": {
            "rating": 1322.6131906476346,
            "rating_q975": 1328.8494597008664,
            "rating_q025": 1316.3769215944026
        },
        "gpt-5-nano-high": {
            "rating": 1321.468069734397,
            "rating_q975": 1338.282659169181,
            "rating_q025": 1304.6534802996127
        },
        "claude-3-7-sonnet-20250219": {
            "rating": 1319.833130923945,
            "rating_q975": 1325.6383912639271,
            "rating_q025": 1314.027870583963
        },
        "o3-mini": {
            "rating": 1318.839873547249,
            "rating_q975": 1324.1149089504606,
            "rating_q025": 1313.5648381440376
        },
        "deepseek-v3": {
            "rating": 1316.7060290415866,
            "rating_q975": 1323.099939253574,
            "rating_q025": 1310.312118829599
        },
        "minimax-m1": {
            "rating": 1316.2437848731943,
            "rating_q975": 1324.381855233637,
            "rating_q025": 1308.1057145127513
        },
        "hunyuan-turbos-20250226": {
            "rating": 1315.6498659578042,
            "rating_q975": 1332.3282152266875,
            "rating_q025": 1298.971516688921
        },
        "mistral-small-2506": {
            "rating": 1315.4313641761937,
            "rating_q975": 1324.9387883428758,
            "rating_q025": 1305.9239400095116
        },
        "step-1o-turbo-202506": {
            "rating": 1310.8000112275122,
            "rating_q975": 1322.5564862037675,
            "rating_q025": 1299.0435362512571
        },
        "nvidia-llama-3.3-nemotron-super-49b-v1.5": {
            "rating": 1307.3538028931177,
            "rating_q975": 1325.0083009608024,
            "rating_q025": 1289.6993048254333
        },
        "command-a-03-2025": {
            "rating": 1306.3251481883335,
            "rating_q975": 1312.562531597936,
            "rating_q025": 1300.087764778731
        },
        "gemini-2.0-flash-lite-preview-02-05": {
            "rating": 1306.1107088821543,
            "rating_q975": 1312.0645021017644,
            "rating_q025": 1300.1569156625444
        },
        "o1-mini": {
            "rating": 1306.0708782699614,
            "rating_q975": 1310.74095249767,
            "rating_q025": 1301.4008040422527
        },
        "qwen3-32b": {
            "rating": 1306.01100917568,
            "rating_q975": 1324.5049268620564,
            "rating_q025": 1287.5170914893038
        },
        "qwq-32b": {
            "rating": 1305.8059494191978,
            "rating_q975": 1312.8614878248532,
            "rating_q025": 1298.7504110135424
        },
        "llama-3.1-nemotron-ultra-253b-v1": {
            "rating": 1305.4851645303575,
            "rating_q975": 1326.1203798721872,
            "rating_q025": 1284.8499491885277
        },
        "qwen-plus-0125": {
            "rating": 1303.525037962006,
            "rating_q975": 1315.2265647644838,
            "rating_q025": 1291.8235111595284
        },
        "glm-4.5v": {
            "rating": 1303.1055711768283,
            "rating_q975": 1336.0267751116246,
            "rating_q025": 1270.1843672420323
        },
        "gemma-3-12b-it": {
            "rating": 1299.87890216404,
            "rating_q975": 1315.7097459138613,
            "rating_q025": 1284.0480584142188
        },
        "claude-3-5-sonnet-20241022": {
            "rating": 1299.005020903849,
            "rating_q975": 1302.9822034576555,
            "rating_q025": 1295.0278383500424
        },
        "gemini-1.5-pro-002": {
            "rating": 1298.1508846998026,
            "rating_q975": 1302.5484720276907,
            "rating_q025": 1293.7532973719146
        },
        "llama-3.3-nemotron-49b-super-v1": {
            "rating": 1294.5258532303963,
            "rating_q975": 1312.9193270027556,
            "rating_q025": 1276.132379458037
        },
        "glm-4-plus-0111": {
            "rating": 1294.242727147247,
            "rating_q975": 1306.0782653986314,
            "rating_q025": 1282.4071888958626
        },
        "amazon-nova-experimental-chat-05-14": {
            "rating": 1293.942788572486,
            "rating_q975": 1302.7064062571906,
            "rating_q025": 1285.1791708877818
        },
        "step-2-16k-exp-202412": {
            "rating": 1288.4769100827014,
            "rating_q975": 1300.3555848346168,
            "rating_q025": 1276.5982353307859
        },
        "qwen3-30b-a3b": {
            "rating": 1286.4431390109055,
            "rating_q975": 1294.413267390869,
            "rating_q025": 1278.473010630942
        },
        "hunyuan-turbo-0110": {
            "rating": 1282.8545510327601,
            "rating_q975": 1299.6896311982598,
            "rating_q025": 1266.0194708672605
        },
        "deepseek-v2.5-1210": {
            "rating": 1282.1214644963777,
            "rating_q975": 1292.5101174091938,
            "rating_q025": 1271.7328115835614
        },
        "yi-lightning": {
            "rating": 1280.3899443979067,
            "rating_q975": 1286.648100040583,
            "rating_q025": 1274.1317887552307
        },
        "gpt-4o-2024-05-13": {
            "rating": 1279.9270372320839,
            "rating_q975": 1284.2800950522885,
            "rating_q025": 1275.5739794118792
        },
        "hunyuan-large-2025-02-10": {
            "rating": 1279.6091506130579,
            "rating_q975": 1294.7322005055553,
            "rating_q025": 1264.4861007205604
        },
        "qwen2.5-plus-1127": {
            "rating": 1276.6494478250872,
            "rating_q975": 1285.1164285581813,
            "rating_q025": 1268.1824670919932
        },
        "athene-v2-chat": {
            "rating": 1274.0542901656318,
            "rating_q975": 1279.8034924773178,
            "rating_q025": 1268.305087853946
        },
        "claude-3-5-sonnet-20240620": {
            "rating": 1272.2043991568116,
            "rating_q975": 1276.6690735570746,
            "rating_q025": 1267.7397247565489
        },
        "grok-2-2024-08-13": {
            "rating": 1272.0256915667335,
            "rating_q975": 1276.3787742923328,
            "rating_q025": 1267.6726088411342
        },
        "gpt-4o-2024-08-06": {
            "rating": 1269.6017467120073,
            "rating_q975": 1274.7840936456676,
            "rating_q025": 1264.4193997783468
        },
        "gpt-4.1-nano-2025-04-14": {
            "rating": 1268.3500074899837,
            "rating_q975": 1280.54176109218,
            "rating_q025": 1256.1582538877874
        },
        "glm-4-plus": {
            "rating": 1266.336515736224,
            "rating_q975": 1272.565734616091,
            "rating_q025": 1260.107296856357
        },
        "gpt-oss-20b": {
            "rating": 1265.9053363958692,
            "rating_q975": 1279.6630194189142,
            "rating_q025": 1252.1476533728242
        },
        "qwen-max-0919": {
            "rating": 1265.7299188715956,
            "rating_q975": 1272.9663681102136,
            "rating_q025": 1258.4934696329778
        },
        "gemma-3n-e4b-it": {
            "rating": 1264.6831610408844,
            "rating_q975": 1273.730626257999,
            "rating_q025": 1255.6356958237698
        },
        "llama-4-maverick-17b-128e-instruct": {
            "rating": 1264.6535921701498,
            "rating_q975": 1271.7479125146197,
            "rating_q025": 1257.5592718256796
        },
        "llama-3.1-405b-instruct-bf16": {
            "rating": 1262.1148761168442,
            "rating_q975": 1266.8272554966625,
            "rating_q025": 1257.4024967370258
        },
        "llama-3.1-405b-instruct-fp8": {
            "rating": 1261.9242151189999,
            "rating_q975": 1266.564032841355,
            "rating_q025": 1257.2843973966449
        },
        "gemini-1.5-flash-002": {
            "rating": 1261.6954434185832,
            "rating_q975": 1266.9598596633891,
            "rating_q025": 1256.4310271737775
        },
        "gpt-4o-mini-2024-07-18": {
            "rating": 1261.443014078834,
            "rating_q975": 1265.6423011153704,
            "rating_q025": 1257.2437270422977
        },
        "qwen2.5-72b-instruct": {
            "rating": 1258.728734774703,
            "rating_q975": 1263.7769410683138,
            "rating_q025": 1253.680528481092
        },
        "hunyuan-large-vision": {
            "rating": 1257.910018993201,
            "rating_q975": 1273.7378396613833,
            "rating_q025": 1242.082198325019
        },
        "mistral-small-3.1-24b-instruct-2503": {
            "rating": 1257.6108057738966,
            "rating_q975": 1266.3844981605866,
            "rating_q025": 1248.8371133872063
        },
        "gemini-1.5-pro-001": {
            "rating": 1257.5119534836538,
            "rating_q975": 1262.7364761176675,
            "rating_q025": 1252.28743084964
        },
        "gemini-advanced-0514": {
            "rating": 1257.0445663574596,
            "rating_q975": 1263.2669658174411,
            "rating_q025": 1250.8221668974784
        },
        "llama-3.1-nemotron-70b-instruct": {
            "rating": 1254.9685864651992,
            "rating_q975": 1265.0136617406126,
            "rating_q025": 1244.9235111897858
        },
        "gpt-4-turbo-2024-04-09": {
            "rating": 1253.8822534663677,
            "rating_q975": 1258.7851583142199,
            "rating_q025": 1248.9793486185156
        },
        "deepseek-v2.5": {
            "rating": 1253.63679420189,
            "rating_q975": 1259.6176619785256,
            "rating_q025": 1247.6559264252548
        },
        "magistral-medium-2506": {
            "rating": 1253.0522293513209,
            "rating_q975": 1264.6851430614554,
            "rating_q025": 1241.4193156411864
        },
        "mistral-large-2407": {
            "rating": 1252.4108138799256,
            "rating_q975": 1257.413116208188,
            "rating_q025": 1247.4085115516632
        },
        "mistral-large-2411": {
            "rating": 1252.383266383129,
            "rating_q975": 1257.935684094353,
            "rating_q025": 1246.8308486719054
        },
        "claude-3-opus-20240229": {
            "rating": 1251.9284245147114,
            "rating_q975": 1255.7431294195803,
            "rating_q025": 1248.1137196098423
        },
        "llama-4-scout-17b-16e-instruct": {
            "rating": 1250.3290958350926,
            "rating_q975": 1258.8520269695587,
            "rating_q025": 1241.8061647006266
        },
        "grok-2-mini-2024-08-13": {
            "rating": 1248.9737085590791,
            "rating_q975": 1253.6231099079928,
            "rating_q025": 1244.3243072101657
        },
        "hunyuan-standard-2025-02-10": {
            "rating": 1247.5966393572048,
            "rating_q975": 1262.4379667910614,
            "rating_q025": 1232.755311923348
        },
        "llama-3.3-70b-instruct": {
            "rating": 1245.6249787910515,
            "rating_q975": 1250.3143021870349,
            "rating_q025": 1240.935655395068
        },
        "gpt-4-1106-preview": {
            "rating": 1244.9082195686556,
            "rating_q975": 1249.946652176349,
            "rating_q025": 1239.8697869609618
        },
        "gemma-3-4b-it": {
            "rating": 1243.4198377342304,
            "rating_q975": 1259.1039043986564,
            "rating_q025": 1227.7357710698045
        },
        "claude-3-5-haiku-20241022": {
            "rating": 1240.4103849889148,
            "rating_q975": 1244.9520162617616,
            "rating_q025": 1235.8687537160679
        },
        "gpt-4-0125-preview": {
            "rating": 1239.5062770774482,
            "rating_q975": 1244.7031201832067,
            "rating_q025": 1234.3094339716895
        },
        "amazon-nova-pro-v1.0": {
            "rating": 1239.3927821510397,
            "rating_q975": 1245.1946801954841,
            "rating_q025": 1233.5908841065955
        },
        "llama-3.1-tulu-3-70b": {
            "rating": 1238.9081458791443,
            "rating_q975": 1253.6658565864932,
            "rating_q025": 1224.1504351717952
        },
        "llama-3.1-70b-instruct": {
            "rating": 1236.3943141879936,
            "rating_q975": 1241.057847049508,
            "rating_q025": 1231.730781326479
        },
        "athene-70b-0725": {
            "rating": 1231.0754039282492,
            "rating_q975": 1238.293103727775,
            "rating_q025": 1223.8577041287235
        },
        "qwen2.5-coder-32b-instruct": {
            "rating": 1228.7192162570448,
            "rating_q975": 1239.6260055458472,
            "rating_q025": 1217.8124269682423
        },
        "mistral-small-24b-instruct-2501": {
            "rating": 1218.8152925166273,
            "rating_q975": 1226.59341672825,
            "rating_q025": 1211.0371683050048
        },
        "jamba-1.5-large": {
            "rating": 1218.3329422348954,
            "rating_q975": 1228.4934125913628,
            "rating_q025": 1208.172471878428
        },
        "reka-core-20240904": {
            "rating": 1217.4337707515276,
            "rating_q975": 1226.6766087326398,
            "rating_q025": 1208.1909327704157
        },
        "gemini-1.5-flash-001": {
            "rating": 1216.969466523992,
            "rating_q975": 1222.3938799081495,
            "rating_q025": 1211.5450531398346
        },
        "gemma-2-27b-it": {
            "rating": 1212.0325886118326,
            "rating_q975": 1216.1556449695854,
            "rating_q025": 1207.9095322540793
        },
        "amazon-nova-lite-v1.0": {
            "rating": 1211.996424218264,
            "rating_q975": 1218.5094257242042,
            "rating_q025": 1205.4834227123235
        },
        "glm-4-0520": {
            "rating": 1208.9479027040786,
            "rating_q975": 1218.7069897533931,
            "rating_q025": 1199.188815654764
        },
        "nemotron-4-340b-instruct": {
            "rating": 1208.6221589606753,
            "rating_q975": 1216.2594968330907,
            "rating_q025": 1200.98482108826
        },
        "hunyuan-standard-256k": {
            "rating": 1208.3374768019657,
            "rating_q975": 1224.1496973934595,
            "rating_q025": 1192.525256210472
        },
        "phi-4": {
            "rating": 1207.1869677442744,
            "rating_q975": 1213.345526001556,
            "rating_q025": 1201.0284094869928
        },
        "gpt-4-0314": {
            "rating": 1206.2516836792092,
            "rating_q975": 1213.0734886195655,
            "rating_q025": 1199.4298787388527
        },
        "llama-3.1-nemotron-51b-instruct": {
            "rating": 1205.9629339309072,
            "rating_q975": 1219.8693098593799,
            "rating_q025": 1192.0565580024343
        },
        "gemini-1.5-flash-8b-001": {
            "rating": 1205.727160101521,
            "rating_q975": 1211.0434350541236,
            "rating_q025": 1200.4108851489182
        },
        "claude-3-sonnet-20240229": {
            "rating": 1204.6157011933992,
            "rating_q975": 1209.7464503651108,
            "rating_q025": 1199.4849520216878
        },
        "c4ai-aya-expanse-32b": {
            "rating": 1203.015109496498,
            "rating_q975": 1209.0832946578453,
            "rating_q025": 1196.946924335151
        },
        "command-r-plus-08-2024": {
            "rating": 1202.084137477517,
            "rating_q975": 1210.7387934473659,
            "rating_q025": 1193.4294815076682
        },
        "llama-3-70b-instruct": {
            "rating": 1200.0129898449484,
            "rating_q975": 1204.7790654111857,
            "rating_q025": 1195.246914278711
        },
        "gemma-2-9b-it-simpo": {
            "rating": 1197.6426742836684,
            "rating_q975": 1207.1880023040774,
            "rating_q025": 1188.0973462632592
        },
        "gpt-4-0613": {
            "rating": 1194.5963635296162,
            "rating_q975": 1200.1283996531522,
            "rating_q025": 1189.0643274060803
        },
        "reka-flash-20240904": {
            "rating": 1192.5006273500333,
            "rating_q975": 1201.7868144046543,
            "rating_q025": 1183.2144402954123
        },
        "olmo-2-0325-32b-instruct": {
            "rating": 1192.1872478049888,
            "rating_q975": 1208.989002432728,
            "rating_q025": 1175.3854931772496
        },
        "qwen2-72b-instruct": {
            "rating": 1186.9383762934153,
            "rating_q975": 1193.2146755878916,
            "rating_q025": 1180.6620769989388
        },
        "deepseek-coder-v2": {
            "rating": 1186.8009845464635,
            "rating_q975": 1195.453136382761,
            "rating_q025": 1178.1488327101663
        },
        "command-r-plus": {
            "rating": 1185.6117156504106,
            "rating_q975": 1191.1630559488951,
            "rating_q025": 1180.060375351926
        },
        "gemma-2-9b-it": {
            "rating": 1185.4869180860903,
            "rating_q975": 1190.1429157746113,
            "rating_q025": 1180.8309203975693
        },
        "amazon-nova-micro-v1.0": {
            "rating": 1183.387553622282,
            "rating_q975": 1189.891329272991,
            "rating_q025": 1176.8837779715727
        },
        "llama-3.1-tulu-3-8b": {
            "rating": 1181.296769010285,
            "rating_q975": 1196.0537183412603,
            "rating_q025": 1166.5398196793094
        },
        "claude-3-haiku-20240307": {
            "rating": 1180.1058327865974,
            "rating_q975": 1184.823815245353,
            "rating_q025": 1175.3878503278415
        },
        "command-r-08-2024": {
            "rating": 1175.3104730854752,
            "rating_q975": 1183.7768397923915,
            "rating_q025": 1166.8441063785588
        },
        "mistral-large-2402": {
            "rating": 1175.0969274329175,
            "rating_q975": 1181.2329243212346,
            "rating_q025": 1168.9609305446004
        },
        "ministral-8b-2410": {
            "rating": 1170.5565753096093,
            "rating_q975": 1182.1959232499237,
            "rating_q025": 1158.9172273692952
        },
        "qwq-32b-preview": {
            "rating": 1168.6884897278674,
            "rating_q975": 1183.6221479904816,
            "rating_q025": 1153.7548314652533
        },
        "llama-3.1-8b-instruct": {
            "rating": 1167.4155505915487,
            "rating_q975": 1172.3150082916814,
            "rating_q025": 1162.516092891416
        },
        "c4ai-aya-expanse-8b": {
            "rating": 1165.1544499338893,
            "rating_q975": 1174.0368680235736,
            "rating_q025": 1156.272031844205
        },
        "qwen1.5-110b-chat": {
            "rating": 1164.6714238815644,
            "rating_q975": 1172.3027907496878,
            "rating_q025": 1157.0400570134407
        },
        "mistral-medium": {
            "rating": 1158.8007869097114,
            "rating_q975": 1166.5343038619599,
            "rating_q025": 1151.0672699574627
        },
        "jamba-1.5-mini": {
            "rating": 1154.8721079184913,
            "rating_q975": 1164.9621687701717,
            "rating_q025": 1144.782047066811
        },
        "mixtral-8x22b-instruct-v0.1": {
            "rating": 1153.4994042402107,
            "rating_q975": 1159.4958897500878,
            "rating_q025": 1147.5029187303335
        },
        "internlm2_5-20b-chat": {
            "rating": 1148.6194104748206,
            "rating_q975": 1157.8185526822424,
            "rating_q025": 1139.4202682673986
        },
        "qwen1.5-72b-chat": {
            "rating": 1148.0401596091501,
            "rating_q975": 1154.9697397669158,
            "rating_q025": 1141.1105794513846
        },
        "yi-1.5-34b-chat": {
            "rating": 1146.1517413223783,
            "rating_q975": 1153.376843391905,
            "rating_q025": 1138.9266392528518
        },
        "granite-3.1-8b-instruct": {
            "rating": 1141.1447777788017,
            "rating_q975": 1156.5175741926646,
            "rating_q025": 1125.7719813649387
        },
        "reka-flash-21b-20240226-online": {
            "rating": 1137.7367257630583,
            "rating_q975": 1147.5872014904216,
            "rating_q025": 1127.886250035695
        },
        "llama-3-8b-instruct": {
            "rating": 1134.4923559114604,
            "rating_q975": 1139.638912927584,
            "rating_q025": 1129.3457988953369
        },
        "command-r": {
            "rating": 1132.4590101038089,
            "rating_q975": 1138.7244856451541,
            "rating_q025": 1126.1935345624634
        },
        "reka-flash-21b-20240226": {
            "rating": 1128.744048143744,
            "rating_q975": 1136.7477527428587,
            "rating_q025": 1120.7403435446295
        },
        "gemma-2-2b-it": {
            "rating": 1128.284803398082,
            "rating_q975": 1133.2259647738863,
            "rating_q025": 1123.3436420222777
        },
        "gpt-3.5-turbo-0125": {
            "rating": 1126.3272248652536,
            "rating_q975": 1132.2227439499934,
            "rating_q025": 1120.4317057805138
        },
        "zephyr-orpo-141b-A35b-v0.1": {
            "rating": 1125.5090684540576,
            "rating_q975": 1140.616978883093,
            "rating_q025": 1110.4011580250221
        },
        "granite-3.1-2b-instruct": {
            "rating": 1124.2105513068552,
            "rating_q975": 1139.510255209913,
            "rating_q025": 1108.9108474037973
        },
        "qwen1.5-32b-chat": {
            "rating": 1123.3463530903473,
            "rating_q975": 1131.4482025521997,
            "rating_q025": 1115.2445036284944
        },
        "gemini-pro-dev-api": {
            "rating": 1121.261218145038,
            "rating_q975": 1131.4502925624427,
            "rating_q025": 1111.072143727633
        },
        "phi-3-medium-4k-instruct": {
            "rating": 1121.0739532335201,
            "rating_q975": 1127.9092886467874,
            "rating_q025": 1114.238617820253
        },
        "dbrx-instruct-preview": {
            "rating": 1119.3351539685807,
            "rating_q975": 1127.3518118469367,
            "rating_q025": 1111.318496090225
        },
        "gemini-pro": {
            "rating": 1117.7079391224722,
            "rating_q975": 1134.0012440679388,
            "rating_q025": 1101.4146341770054
        },
        "tulu-2-dpo-70b": {
            "rating": 1117.2962032397663,
            "rating_q975": 1131.7193812849011,
            "rating_q025": 1102.8730251946317
        },
        "mixtral-8x7b-instruct-v0.1": {
            "rating": 1117.2713023905453,
            "rating_q975": 1123.081354956342,
            "rating_q025": 1111.4612498247486
        },
        "qwen1.5-14b-chat": {
            "rating": 1108.8949635498711,
            "rating_q975": 1118.3610004496477,
            "rating_q025": 1099.4289266500946
        },
        "starling-lm-7b-beta": {
            "rating": 1104.4989081828178,
            "rating_q975": 1114.085316750558,
            "rating_q025": 1094.9124996150776
        },
        "granite-3.0-8b-instruct": {
            "rating": 1101.5087901197753,
            "rating_q975": 1112.8283969189988,
            "rating_q025": 1090.1891833205516
        },
        "wizardlm-70b": {
            "rating": 1099.970477466823,
            "rating_q975": 1113.1386751975667,
            "rating_q025": 1086.8022797360798
        },
        "gpt-3.5-turbo-1106": {
            "rating": 1099.7959404772514,
            "rating_q975": 1111.7500263983497,
            "rating_q025": 1087.841854556153
        },
        "llama-3.2-3b-instruct": {
            "rating": 1099.5435001954104,
            "rating_q975": 1109.6709802091077,
            "rating_q025": 1089.416020181713
        },
        "yi-34b-chat": {
            "rating": 1098.3632588018806,
            "rating_q975": 1107.7092722173384,
            "rating_q025": 1089.017245386423
        },
        "phi-3-small-8k-instruct": {
            "rating": 1094.9637000682205,
            "rating_q975": 1103.1435219560617,
            "rating_q025": 1086.7838781803794
        },
        "deepseek-llm-67b-chat": {
            "rating": 1085.9904411771668,
            "rating_q975": 1102.7857479055776,
            "rating_q025": 1069.1951344487557
        },
        "openchat-3.5-0106": {
            "rating": 1084.5432898995891,
            "rating_q975": 1094.641233832333,
            "rating_q025": 1074.445345966845
        },
        "llama-2-70b-chat": {
            "rating": 1079.4259192310524,
            "rating_q975": 1086.710601872872,
            "rating_q025": 1072.141236589233
        },
        "openhermes-2.5-mistral-7b": {
            "rating": 1078.0438973665587,
            "rating_q975": 1093.197196362485,
            "rating_q025": 1062.8905983706327
        },
        "starling-lm-7b-alpha": {
            "rating": 1077.7161128938899,
            "rating_q975": 1088.7899052860378,
            "rating_q025": 1066.642320501742
        },
        "openchat-3.5": {
            "rating": 1077.4502688784373,
            "rating_q975": 1091.3275699420194,
            "rating_q025": 1063.5729678148555
        },
        "snowflake-arctic-instruct": {
            "rating": 1075.1134852943692,
            "rating_q975": 1083.1448129908276,
            "rating_q025": 1067.082157597911
        },
        "vicuna-33b": {
            "rating": 1072.781841892519,
            "rating_q975": 1081.3866301174235,
            "rating_q025": 1064.1770536676142
        },
        "granite-3.0-2b-instruct": {
            "rating": 1071.927536916176,
            "rating_q975": 1083.3970109202007,
            "rating_q025": 1060.4580629121515
        },
        "llama2-70b-steerlm-chat": {
            "rating": 1068.9350528678708,
            "rating_q975": 1086.8604273479873,
            "rating_q025": 1051.0096783877543
        },
        "mistral-7b-instruct-v0.2": {
            "rating": 1068.755713852263,
            "rating_q975": 1077.321085056131,
            "rating_q025": 1060.1903426483948
        },
        "phi-3-mini-4k-instruct-june-2024": {
            "rating": 1067.899666421963,
            "rating_q975": 1076.990314088158,
            "rating_q025": 1058.8090187557684
        },
        "qwen1.5-7b-chat": {
            "rating": 1065.7756523062553,
            "rating_q975": 1079.3932735747107,
            "rating_q025": 1052.1580310378001
        },
        "gemma-1.1-7b-it": {
            "rating": 1065.729931181057,
            "rating_q975": 1073.2198220476084,
            "rating_q025": 1058.2400403145054
        },
        "nous-hermes-2-mixtral-8x7b-dpo": {
            "rating": 1064.5792939749567,
            "rating_q975": 1080.6254637579882,
            "rating_q025": 1048.5331241919253
        },
        "mpt-30b-chat": {
            "rating": 1062.055923654549,
            "rating_q975": 1083.1522209786283,
            "rating_q025": 1040.9596263304695
        },
        "phi-3-mini-4k-instruct": {
            "rating": 1061.214791240506,
            "rating_q975": 1069.5296060087271,
            "rating_q025": 1052.8999764722848
        },
        "dolphin-2.2.1-mistral-7b": {
            "rating": 1060.7583233999312,
            "rating_q975": 1085.4403613326347,
            "rating_q025": 1036.0762854672275
        },
        "smollm2-1.7b-instruct": {
            "rating": 1057.4727484630682,
            "rating_q975": 1076.4626708701373,
            "rating_q025": 1038.482826055999
        },
        "falcon-180b-chat": {
            "rating": 1056.5866464481574,
            "rating_q975": 1085.247871972596,
            "rating_q025": 1027.9254209237188
        },
        "solar-10.7b-instruct-v1.0": {
            "rating": 1056.2571601201598,
            "rating_q975": 1074.4255561847156,
            "rating_q025": 1038.0887640556043
        },
        "wizardlm-13b": {
            "rating": 1055.7515828615706,
            "rating_q975": 1069.4931665978984,
            "rating_q025": 1042.0099991252428
        },
        "llama-2-13b-chat": {
            "rating": 1054.4388471525876,
            "rating_q975": 1063.3521427174815,
            "rating_q025": 1045.525551587694
        },
        "llama-3.2-1b-instruct": {
            "rating": 1045.5602395106494,
            "rating_q975": 1055.939463205383,
            "rating_q025": 1035.1810158159158
        },
        "vicuna-13b": {
            "rating": 1043.6484356433616,
            "rating_q975": 1052.848852829315,
            "rating_q025": 1034.4480184574084
        },
        "zephyr-7b-alpha": {
            "rating": 1042.7779721296738,
            "rating_q975": 1067.6461412907495,
            "rating_q025": 1017.9098029685985
        },
        "zephyr-7b-beta": {
            "rating": 1039.338997893764,
            "rating_q975": 1051.8432199631645,
            "rating_q025": 1026.834775824363
        },
        "qwen-14b-chat": {
            "rating": 1039.1157009115636,
            "rating_q975": 1055.4151389095186,
            "rating_q025": 1022.8162629136087
        },
        "codellama-34b-instruct": {
            "rating": 1036.0117513961127,
            "rating_q975": 1048.665670491338,
            "rating_q025": 1023.3578323008873
        },
        "phi-3-mini-128k-instruct": {
            "rating": 1033.9264876034022,
            "rating_q975": 1043.609407581349,
            "rating_q025": 1024.2435676254554
        },
        "codellama-70b-instruct": {
            "rating": 1032.9546001945002,
            "rating_q975": 1062.4437586243782,
            "rating_q025": 1003.4654417646223
        },
        "gemma-7b-it": {
            "rating": 1025.5392233194552,
            "rating_q975": 1038.0556768140166,
            "rating_q025": 1013.022769824894
        },
        "stripedhyena-nous-7b": {
            "rating": 1017.9450439612251,
            "rating_q975": 1033.027601928974,
            "rating_q025": 1002.8624859934762
        },
        "palm-2": {
            "rating": 1016.9879572015196,
            "rating_q975": 1030.2418181052687,
            "rating_q025": 1003.7340962977704
        },
        "llama-2-7b-chat": {
            "rating": 1014.3867870500769,
            "rating_q975": 1023.8711632325242,
            "rating_q025": 1004.9024108676298
        },
        "mistral-7b-instruct": {
            "rating": 1012.5539860278889,
            "rating_q975": 1025.9231167759747,
            "rating_q025": 999.1848552798031
        },
        "vicuna-7b": {
            "rating": 1003.1913491792428,
            "rating_q975": 1017.0613317610309,
            "rating_q025": 989.3213665974547
        },
        "gemma-1.1-2b-it": {
            "rating": 1002.4299512363772,
            "rating_q975": 1012.8701270467702,
            "rating_q025": 991.9897754259841
        },
        "guanaco-33b": {
            "rating": 999.4551214616843,
            "rating_q975": 1020.0823440783438,
            "rating_q025": 978.8278988450247
        },
        "olmo-7b-instruct": {
            "rating": 988.2181085537995,
            "rating_q975": 1003.7629451655736,
            "rating_q025": 972.6732719420254
        },
        "qwen1.5-4b-chat": {
            "rating": 987.4765630874342,
            "rating_q975": 1000.0144632703607,
            "rating_q025": 974.9386629045079
        },
        "gemma-2b-it": {
            "rating": 980.1863323087741,
            "rating_q975": 996.0116905530227,
            "rating_q025": 964.3609740645256
        },
        "chatglm3-6b": {
            "rating": 962.7926098912135,
            "rating_q975": 980.167719885912,
            "rating_q025": 945.417499896515
        },
        "gpt4all-13b-snoozy": {
            "rating": 954.6678202414746,
            "rating_q975": 979.5020003606105,
            "rating_q025": 929.8336401223388
        },
        "koala-13b": {
            "rating": 952.4155695170805,
            "rating_q975": 967.5961569484607,
            "rating_q025": 937.2349820857004
        },
        "mpt-7b-chat": {
            "rating": 917.47916805432,
            "rating_q975": 935.6838602804501,
            "rating_q025": 899.2744758281899
        },
        "chatglm2-6b": {
            "rating": 911.9794279334994,
            "rating_q975": 934.4378290670837,
            "rating_q025": 889.5210267999153
        },
        "chatglm-6b": {
            "rating": 910.7298956661858,
            "rating_q975": 928.4147640191975,
            "rating_q025": 893.0450273131742
        },
        "alpaca-13b": {
            "rating": 899.8019483018306,
            "rating_q975": 916.116035438689,
            "rating_q025": 883.4878611649722
        },
        "oasst-pythia-12b": {
            "rating": 894.4335532587639,
            "rating_q975": 910.2129667432146,
            "rating_q025": 878.6541397743133
        },
        "RWKV-4-Raven-14B": {
            "rating": 891.7120136406418,
            "rating_q975": 908.3887587122504,
            "rating_q025": 875.0352685690333
        },
        "fastchat-t5-3b": {
            "rating": 866.177703891648,
            "rating_q975": 884.664978109338,
            "rating_q025": 847.6904296739581
        },
        "stablelm-tuned-alpha-7b": {
            "rating": 839.8883645023768,
            "rating_q975": 860.2572652809558,
            "rating_q025": 819.5194637237976
        },
        "dolly-v2-12b": {
            "rating": 823.0500132871016,
            "rating_q975": 844.182471827568,
            "rating_q025": 801.9175547466352
        },
        "llama-13b": {
            "rating": 788.9659169685606,
            "rating_q975": 813.8604400998981,
            "rating_q025": 764.071393837223
        }
    },
    "japanese": {
        "gemini-2.5-pro": {
            "rating": 1472.9009117948115,
            "rating_q975": 1494.0702527415028,
            "rating_q025": 1451.7315708481203
        },
        "gpt-5-high": {
            "rating": 1435.5563576954519,
            "rating_q975": 1461.4240993088224,
            "rating_q025": 1409.6886160820814
        },
        "o3-2025-04-16": {
            "rating": 1420.6473518210612,
            "rating_q975": 1440.1251849573541,
            "rating_q025": 1401.1695186847683
        },
        "gpt-4.5-preview-2025-02-27": {
            "rating": 1415.6164122819755,
            "rating_q975": 1452.1680775574123,
            "rating_q025": 1379.0647470065387
        },
        "chatgpt-4o-latest-20250326": {
            "rating": 1408.9142323858805,
            "rating_q975": 1430.8482131562864,
            "rating_q025": 1386.9802516154746
        },
        "glm-4.5": {
            "rating": 1408.89854934371,
            "rating_q975": 1435.7155260633583,
            "rating_q025": 1382.0815726240617
        },
        "gpt-5-chat": {
            "rating": 1402.422116911654,
            "rating_q975": 1450.7626730493105,
            "rating_q025": 1354.0815607739978
        },
        "claude-opus-4-1-20250805-thinking-16k": {
            "rating": 1400.8966819938992,
            "rating_q975": 1449.008590241211,
            "rating_q025": 1352.7847737465872
        },
        "grok-4-0709": {
            "rating": 1399.7456089987636,
            "rating_q975": 1423.6721362756875,
            "rating_q025": 1375.81908172184
        },
        "gemini-2.5-flash": {
            "rating": 1397.5251281829642,
            "rating_q975": 1416.6433765689278,
            "rating_q025": 1378.4068797970006
        },
        "grok-3-preview-02-24": {
            "rating": 1394.7835846806497,
            "rating_q975": 1414.7410786578052,
            "rating_q025": 1374.8260907034942
        },
        "deepseek-r1-0528": {
            "rating": 1383.271015763615,
            "rating_q975": 1407.3336892810398,
            "rating_q025": 1359.20834224619
        },
        "qwen3-235b-a22b-thinking-2507": {
            "rating": 1381.1647054659431,
            "rating_q975": 1410.1999906101337,
            "rating_q025": 1352.1294203217524
        },
        "qwen3-235b-a22b-no-thinking": {
            "rating": 1378.3029099553823,
            "rating_q975": 1401.546785549063,
            "rating_q025": 1355.0590343617016
        },
        "qwen3-235b-a22b-instruct-2507": {
            "rating": 1371.5909464854299,
            "rating_q975": 1397.4899517553288,
            "rating_q025": 1345.691941215531
        },
        "qwen3-30b-a3b-instruct-2507": {
            "rating": 1367.6182575873152,
            "rating_q975": 1395.049850454335,
            "rating_q025": 1340.1866647202953
        },
        "claude-opus-4-1-20250805": {
            "rating": 1355.7215207286545,
            "rating_q975": 1389.3630221819856,
            "rating_q025": 1322.0800192753234
        },
        "gpt-oss-120b": {
            "rating": 1352.9307183768017,
            "rating_q975": 1394.0005372540006,
            "rating_q025": 1311.860899499603
        },
        "kimi-k2-0711-preview": {
            "rating": 1351.2846308279898,
            "rating_q975": 1373.6576513960727,
            "rating_q025": 1328.9116102599069
        },
        "o1-2024-12-17": {
            "rating": 1349.8740735192769,
            "rating_q975": 1374.1957812912094,
            "rating_q025": 1325.5523657473445
        },
        "glm-4.5-air": {
            "rating": 1347.146115814487,
            "rating_q975": 1373.1426591348502,
            "rating_q025": 1321.1495724941237
        },
        "hunyuan-turbos-20250416": {
            "rating": 1342.5381757525388,
            "rating_q975": 1373.7241130384018,
            "rating_q025": 1311.3522384666758
        },
        "claude-opus-4-20250514-thinking-16k": {
            "rating": 1337.1882239387974,
            "rating_q975": 1362.4806774865222,
            "rating_q025": 1311.8957703910728
        },
        "grok-3-mini-beta": {
            "rating": 1334.4230192334605,
            "rating_q975": 1357.9877274330647,
            "rating_q025": 1310.858311033856
        },
        "deepseek-r1": {
            "rating": 1331.597116910481,
            "rating_q975": 1355.8314764464262,
            "rating_q025": 1307.3627573745357
        },
        "grok-3-mini-high": {
            "rating": 1329.6456352219636,
            "rating_q975": 1356.2388857386,
            "rating_q025": 1303.0523847053273
        },
        "gpt-4.1-2025-04-14": {
            "rating": 1325.1492035990045,
            "rating_q975": 1346.7943895983296,
            "rating_q025": 1303.5040175996796
        },
        "deepseek-v3-0324": {
            "rating": 1324.2740690009055,
            "rating_q975": 1344.964275564282,
            "rating_q025": 1303.583862437529
        },
        "claude-opus-4-20250514": {
            "rating": 1320.9213565665405,
            "rating_q975": 1342.327278951473,
            "rating_q025": 1299.5154341816076
        },
        "o4-mini-2025-04-16": {
            "rating": 1320.0607697992232,
            "rating_q975": 1341.2748721890614,
            "rating_q025": 1298.8466674093847
        },
        "mistral-medium-2505": {
            "rating": 1318.5947756910914,
            "rating_q975": 1339.020614426823,
            "rating_q025": 1298.1689369553599
        },
        "qwen3-235b-a22b": {
            "rating": 1318.3316083728478,
            "rating_q975": 1340.7465389033478,
            "rating_q025": 1295.9166778423476
        },
        "qwen3-coder-480b-a35b-instruct": {
            "rating": 1314.2081319105216,
            "rating_q975": 1336.5323125670232,
            "rating_q025": 1291.88395125402
        },
        "o1-preview": {
            "rating": 1313.930727250181,
            "rating_q975": 1335.2806758514253,
            "rating_q025": 1292.5807786489368
        },
        "qwen2.5-max": {
            "rating": 1311.0107396023413,
            "rating_q975": 1331.3126542901493,
            "rating_q025": 1290.7088249145334
        },
        "gemini-2.0-flash-lite-preview-02-05": {
            "rating": 1309.3645523592559,
            "rating_q975": 1332.5025229112907,
            "rating_q025": 1286.2265818072208
        },
        "gemini-2.0-flash-001": {
            "rating": 1302.2522405746124,
            "rating_q975": 1320.2258148529759,
            "rating_q025": 1284.278666296249
        },
        "gemini-1.5-pro-002": {
            "rating": 1299.1541381587106,
            "rating_q975": 1314.5118923708671,
            "rating_q025": 1283.7963839465538
        },
        "mistral-small-2506": {
            "rating": 1296.6327611931797,
            "rating_q975": 1322.0860434285078,
            "rating_q025": 1271.1794789578516
        },
        "gpt-4.1-mini-2025-04-14": {
            "rating": 1296.3632139645222,
            "rating_q975": 1317.4171604595922,
            "rating_q025": 1275.309267469452
        },
        "command-a-03-2025": {
            "rating": 1296.019192102502,
            "rating_q975": 1316.1185895943524,
            "rating_q025": 1275.919794610652
        },
        "claude-sonnet-4-20250514": {
            "rating": 1295.971077390287,
            "rating_q975": 1318.083752885874,
            "rating_q025": 1273.8584018947001
        },
        "nvidia-llama-3.3-nemotron-super-49b-v1.5": {
            "rating": 1293.4490782832902,
            "rating_q975": 1322.656435461393,
            "rating_q025": 1264.2417211051877
        },
        "gemma-3-27b-it": {
            "rating": 1292.4562261183517,
            "rating_q975": 1312.5543020922014,
            "rating_q025": 1272.358150144502
        },
        "o3-mini-high": {
            "rating": 1289.6294505316862,
            "rating_q975": 1317.5335826076368,
            "rating_q025": 1261.7253184557355
        },
        "claude-sonnet-4-20250514-thinking-32k": {
            "rating": 1283.123460555594,
            "rating_q975": 1308.4003351721428,
            "rating_q025": 1257.8465859390449
        },
        "amazon-nova-experimental-chat-05-14": {
            "rating": 1282.7801004435937,
            "rating_q975": 1308.3184637219385,
            "rating_q025": 1257.2417371652489
        },
        "gemma-3n-e4b-it": {
            "rating": 1282.407267552128,
            "rating_q975": 1306.7596421000044,
            "rating_q025": 1258.0548930042514
        },
        "step-1o-turbo-202506": {
            "rating": 1278.8412949346227,
            "rating_q975": 1318.6517602245226,
            "rating_q025": 1239.0308296447226
        },
        "deepseek-v3": {
            "rating": 1278.7744867065744,
            "rating_q975": 1300.8468745410512,
            "rating_q025": 1256.7020988720976
        },
        "claude-3-7-sonnet-20250219-thinking-32k": {
            "rating": 1277.6816814787944,
            "rating_q975": 1297.218072198924,
            "rating_q025": 1258.1452907586647
        },
        "o3-mini": {
            "rating": 1273.4856329078639,
            "rating_q975": 1290.2748873924556,
            "rating_q025": 1256.696378423272
        },
        "claude-3-7-sonnet-20250219": {
            "rating": 1264.2145169709765,
            "rating_q975": 1283.3367918192685,
            "rating_q025": 1245.0922421226844
        },
        "gpt-oss-20b": {
            "rating": 1263.093271954423,
            "rating_q975": 1305.6524625749294,
            "rating_q025": 1220.534081333917
        },
        "gpt-4o-2024-05-13": {
            "rating": 1263.0925055700052,
            "rating_q975": 1275.3258518605082,
            "rating_q025": 1250.859159279502
        },
        "gemini-1.5-flash-002": {
            "rating": 1262.817068855697,
            "rating_q975": 1282.2683574616594,
            "rating_q025": 1243.3657802497346
        },
        "qwq-32b": {
            "rating": 1262.4846121129167,
            "rating_q975": 1286.7594648882553,
            "rating_q025": 1238.2097593375784
        },
        "qwen3-30b-a3b": {
            "rating": 1258.5377444221683,
            "rating_q975": 1280.9169491527755,
            "rating_q025": 1236.158539691561
        },
        "qwen-plus-0125": {
            "rating": 1256.6223748472191,
            "rating_q975": 1293.4566900601922,
            "rating_q025": 1219.788059634246
        },
        "o1-mini": {
            "rating": 1255.5766135533502,
            "rating_q975": 1271.5387089185713,
            "rating_q025": 1239.614518188129
        },
        "grok-2-2024-08-13": {
            "rating": 1252.61335812626,
            "rating_q975": 1266.3303508813015,
            "rating_q025": 1238.8963653712185
        },
        "gemini-advanced-0514": {
            "rating": 1248.32680018052,
            "rating_q975": 1266.1157840115816,
            "rating_q025": 1230.5378163494581
        },
        "gemini-1.5-pro-001": {
            "rating": 1245.0047971641998,
            "rating_q975": 1258.7853645456737,
            "rating_q025": 1231.2242297827256
        },
        "gpt-4o-2024-08-06": {
            "rating": 1243.345370438703,
            "rating_q975": 1259.4934530677097,
            "rating_q025": 1227.1972878096958
        },
        "claude-3-5-sonnet-20241022": {
            "rating": 1242.7312407507707,
            "rating_q975": 1255.2835343853735,
            "rating_q025": 1230.1789471161678
        },
        "yi-lightning": {
            "rating": 1239.8057378595568,
            "rating_q975": 1261.2607501133,
            "rating_q025": 1218.3507256058138
        },
        "glm-4-plus-0111": {
            "rating": 1238.995175620394,
            "rating_q975": 1274.9752699088408,
            "rating_q025": 1203.0150813319472
        },
        "claude-3-5-sonnet-20240620": {
            "rating": 1237.2378957107644,
            "rating_q975": 1250.0589132424388,
            "rating_q025": 1224.41687817909
        },
        "deepseek-v2.5-1210": {
            "rating": 1232.8068756965104,
            "rating_q975": 1270.4921120943468,
            "rating_q025": 1195.1216392986737
        },
        "minimax-m1": {
            "rating": 1230.6896118921513,
            "rating_q975": 1254.5917935535551,
            "rating_q025": 1206.7874302307473
        },
        "mistral-small-3.1-24b-instruct-2503": {
            "rating": 1226.4654273713525,
            "rating_q975": 1251.1807119655953,
            "rating_q025": 1201.7501427771097
        },
        "athene-v2-chat": {
            "rating": 1226.4211471888302,
            "rating_q975": 1248.0183095350435,
            "rating_q025": 1204.823984842617
        },
        "gpt-4o-mini-2024-07-18": {
            "rating": 1224.3741956028002,
            "rating_q975": 1236.9632188506428,
            "rating_q025": 1211.7851723549577
        },
        "grok-2-mini-2024-08-13": {
            "rating": 1222.247033651428,
            "rating_q975": 1237.1002075042225,
            "rating_q025": 1207.3938597986337
        },
        "glm-4-plus": {
            "rating": 1218.864814739342,
            "rating_q975": 1243.011025077622,
            "rating_q025": 1194.7186044010618
        },
        "llama-3.1-405b-instruct-bf16": {
            "rating": 1217.2057193767387,
            "rating_q975": 1235.5272308501128,
            "rating_q025": 1198.8842079033645
        },
        "qwen2.5-plus-1127": {
            "rating": 1216.6821672624292,
            "rating_q975": 1247.2669828687601,
            "rating_q025": 1186.097351656098
        },
        "qwen-max-0919": {
            "rating": 1215.1373723772817,
            "rating_q975": 1244.9494246938784,
            "rating_q025": 1185.3253200606846
        },
        "llama-4-scout-17b-16e-instruct": {
            "rating": 1214.9005308196852,
            "rating_q975": 1239.3031544747655,
            "rating_q025": 1190.497907164605
        },
        "claude-3-opus-20240229": {
            "rating": 1213.8926025223054,
            "rating_q975": 1224.871203474626,
            "rating_q025": 1202.9140015699845
        },
        "amazon-nova-pro-v1.0": {
            "rating": 1211.7311101165146,
            "rating_q975": 1235.1684967337194,
            "rating_q025": 1188.2937234993096
        },
        "llama-4-maverick-17b-128e-instruct": {
            "rating": 1208.8506409769361,
            "rating_q975": 1232.3060803407352,
            "rating_q025": 1185.3952016131373
        },
        "gpt-4.1-nano-2025-04-14": {
            "rating": 1208.798893082259,
            "rating_q975": 1252.915329790193,
            "rating_q025": 1164.6824563743248
        },
        "gpt-4-1106-preview": {
            "rating": 1207.3999458733838,
            "rating_q975": 1221.9584621565211,
            "rating_q025": 1192.8414295902462
        },
        "reka-core-20240904": {
            "rating": 1204.4781674366475,
            "rating_q975": 1238.0666074260514,
            "rating_q025": 1170.8897274472438
        },
        "deepseek-v2.5": {
            "rating": 1203.9129138139647,
            "rating_q975": 1226.5983197809062,
            "rating_q025": 1181.2275078470227
        },
        "gpt-4-turbo-2024-04-09": {
            "rating": 1203.4073458230428,
            "rating_q975": 1216.565968000773,
            "rating_q025": 1190.2487236453128
        },
        "gpt-4-0125-preview": {
            "rating": 1203.371336384037,
            "rating_q975": 1218.606591594353,
            "rating_q025": 1188.136081173721
        },
        "mistral-large-2407": {
            "rating": 1201.565847541398,
            "rating_q975": 1216.1311172988812,
            "rating_q025": 1187.0005777839147
        },
        "gemini-1.5-flash-001": {
            "rating": 1195.2208652889547,
            "rating_q975": 1209.9588314605746,
            "rating_q025": 1180.482899117335
        },
        "qwen2.5-72b-instruct": {
            "rating": 1191.5218202958965,
            "rating_q975": 1210.1739367888265,
            "rating_q025": 1172.8697038029668
        },
        "claude-3-5-haiku-20241022": {
            "rating": 1189.3661651262166,
            "rating_q975": 1205.282324698635,
            "rating_q025": 1173.4500055537983
        },
        "magistral-medium-2506": {
            "rating": 1187.2818832625744,
            "rating_q975": 1221.2340772410312,
            "rating_q025": 1153.3296892841179
        },
        "gemma-2-27b-it": {
            "rating": 1186.4644091390505,
            "rating_q975": 1199.113803441338,
            "rating_q025": 1173.8150148367629
        },
        "llama-3.1-405b-instruct-fp8": {
            "rating": 1183.9896680017453,
            "rating_q975": 1197.6391869714917,
            "rating_q025": 1170.3401490319986
        },
        "mistral-large-2411": {
            "rating": 1182.1572365606346,
            "rating_q975": 1202.9382933374934,
            "rating_q025": 1161.376179783776
        },
        "c4ai-aya-expanse-32b": {
            "rating": 1176.9049874807981,
            "rating_q975": 1197.8718546526907,
            "rating_q025": 1155.9381203089058
        },
        "command-r-plus-08-2024": {
            "rating": 1174.6340008785753,
            "rating_q975": 1206.2882828366503,
            "rating_q025": 1142.9797189205003
        },
        "phi-4": {
            "rating": 1171.7827781809806,
            "rating_q975": 1197.0974872343413,
            "rating_q025": 1146.4680691276196
        },
        "command-r-plus": {
            "rating": 1168.623778834141,
            "rating_q975": 1184.251273048098,
            "rating_q025": 1152.9962846201838
        },
        "amazon-nova-micro-v1.0": {
            "rating": 1167.3307650738548,
            "rating_q975": 1192.0825984215057,
            "rating_q025": 1142.578931726204
        },
        "amazon-nova-lite-v1.0": {
            "rating": 1165.814581751196,
            "rating_q975": 1191.2446892705777,
            "rating_q025": 1140.3844742318145
        },
        "reka-flash-20240904": {
            "rating": 1163.2388372040439,
            "rating_q975": 1195.419179522775,
            "rating_q025": 1131.0584948853127
        },
        "llama-3.3-70b-instruct": {
            "rating": 1163.2025796677358,
            "rating_q975": 1180.0752259910314,
            "rating_q025": 1146.3299333444402
        },
        "gemini-1.5-flash-8b-001": {
            "rating": 1161.58188222624,
            "rating_q975": 1181.7198519164099,
            "rating_q025": 1141.4439125360698
        },
        "command-r-08-2024": {
            "rating": 1161.5467395822948,
            "rating_q975": 1189.760091334888,
            "rating_q025": 1133.3333878297015
        },
        "gemma-2-9b-it": {
            "rating": 1157.8056572706007,
            "rating_q975": 1172.2494983416632,
            "rating_q025": 1143.361816199538
        },
        "gemma-2-9b-it-simpo": {
            "rating": 1155.6806585781055,
            "rating_q975": 1184.4266746861817,
            "rating_q025": 1126.934642470029
        },
        "athene-70b-0725": {
            "rating": 1151.5543318213088,
            "rating_q975": 1171.6194225489871,
            "rating_q025": 1131.4892410936304
        },
        "claude-3-sonnet-20240229": {
            "rating": 1149.7894913317618,
            "rating_q975": 1164.7283923951657,
            "rating_q025": 1134.850590268358
        },
        "llama-3.1-70b-instruct": {
            "rating": 1148.4696354300108,
            "rating_q975": 1162.5807858872156,
            "rating_q025": 1134.3584849728059
        },
        "deepseek-coder-v2": {
            "rating": 1148.2465819638264,
            "rating_q975": 1174.6180116998098,
            "rating_q025": 1121.875152227843
        },
        "c4ai-aya-expanse-8b": {
            "rating": 1144.4570104248435,
            "rating_q975": 1176.1382865307662,
            "rating_q025": 1112.7757343189207
        },
        "nemotron-4-340b-instruct": {
            "rating": 1143.0875515783466,
            "rating_q975": 1166.4577608499112,
            "rating_q025": 1119.717342306782
        },
        "gpt-4-0314": {
            "rating": 1140.3606169736322,
            "rating_q975": 1160.4059543700232,
            "rating_q025": 1120.3152795772412
        },
        "glm-4-0520": {
            "rating": 1137.5574664649794,
            "rating_q975": 1174.7521058414316,
            "rating_q025": 1100.3628270885272
        },
        "jamba-1.5-large": {
            "rating": 1133.0918951688914,
            "rating_q975": 1166.1646350373717,
            "rating_q025": 1100.019155300411
        },
        "gpt-4-0613": {
            "rating": 1128.8774653098683,
            "rating_q975": 1144.7304856132805,
            "rating_q025": 1113.024445006456
        },
        "qwen2-72b-instruct": {
            "rating": 1128.484466457859,
            "rating_q975": 1146.7799940612554,
            "rating_q025": 1110.1889388544625
        },
        "mistral-small-24b-instruct-2501": {
            "rating": 1123.501080655147,
            "rating_q975": 1158.0055195393884,
            "rating_q025": 1088.9966417709056
        },
        "claude-3-haiku-20240307": {
            "rating": 1119.7432258768595,
            "rating_q975": 1133.1958508547125,
            "rating_q025": 1106.2906008990067
        },
        "command-r": {
            "rating": 1112.140656347767,
            "rating_q975": 1131.0203836731512,
            "rating_q025": 1093.2609290223827
        },
        "gemma-2-2b-it": {
            "rating": 1100.788930818725,
            "rating_q975": 1116.3965162284094,
            "rating_q025": 1085.1813454090407
        },
        "reka-flash-21b-20240226-online": {
            "rating": 1094.5979376949942,
            "rating_q975": 1124.88670091466,
            "rating_q025": 1064.3091744753287
        },
        "qwen1.5-110b-chat": {
            "rating": 1091.1740354340473,
            "rating_q975": 1115.440373726772,
            "rating_q025": 1066.9076971413224
        },
        "qwen1.5-72b-chat": {
            "rating": 1081.7767202612322,
            "rating_q975": 1106.4359604059298,
            "rating_q025": 1057.1174801165344
        },
        "llama-3.1-8b-instruct": {
            "rating": 1078.5389881522144,
            "rating_q975": 1094.5859650548355,
            "rating_q025": 1062.4920112495934
        },
        "reka-flash-21b-20240226": {
            "rating": 1074.6644480926916,
            "rating_q975": 1098.9735635015884,
            "rating_q025": 1050.3553326837948
        },
        "gpt-3.5-turbo-1106": {
            "rating": 1069.8551790319261,
            "rating_q975": 1101.9895540194282,
            "rating_q025": 1037.720804044424
        },
        "gpt-3.5-turbo-0125": {
            "rating": 1066.8712149599187,
            "rating_q975": 1085.555633960469,
            "rating_q025": 1048.1867959593678
        },
        "phi-3-medium-4k-instruct": {
            "rating": 1063.4525432808096,
            "rating_q975": 1084.6738954264954,
            "rating_q025": 1042.2311911351237
        },
        "gemini-pro-dev-api": {
            "rating": 1059.4466705922553,
            "rating_q975": 1094.6912222382357,
            "rating_q025": 1024.2021189462748
        },
        "mixtral-8x22b-instruct-v0.1": {
            "rating": 1057.651317087564,
            "rating_q975": 1075.6125968746064,
            "rating_q025": 1039.6900373005217
        },
        "qwen1.5-32b-chat": {
            "rating": 1052.9075505193412,
            "rating_q975": 1082.544534154672,
            "rating_q025": 1023.2705668840102
        },
        "qwen1.5-14b-chat": {
            "rating": 1049.3590424960103,
            "rating_q975": 1083.6700881117183,
            "rating_q025": 1015.0479968803025
        },
        "mistral-medium": {
            "rating": 1044.8986313120677,
            "rating_q975": 1071.3890781020407,
            "rating_q025": 1018.4081845220944
        },
        "yi-1.5-34b-chat": {
            "rating": 1043.946736292946,
            "rating_q975": 1068.2920623490986,
            "rating_q025": 1019.6014102367938
        },
        "jamba-1.5-mini": {
            "rating": 1041.5445308608787,
            "rating_q975": 1073.723003833359,
            "rating_q025": 1009.3660578883986
        },
        "llama-3-70b-instruct": {
            "rating": 1040.7792557448652,
            "rating_q975": 1053.1913719922309,
            "rating_q025": 1028.3671394974995
        },
        "mistral-large-2402": {
            "rating": 1034.5378276942554,
            "rating_q975": 1053.8970458362096,
            "rating_q025": 1015.1786095523012
        },
        "yi-34b-chat": {
            "rating": 1032.6459642667342,
            "rating_q975": 1068.5457160639157,
            "rating_q025": 996.7462124695526
        },
        "starling-lm-7b-beta": {
            "rating": 1025.950702566032,
            "rating_q975": 1065.269087909829,
            "rating_q025": 986.632317222235
        },
        "dbrx-instruct-preview": {
            "rating": 1016.381588583587,
            "rating_q975": 1042.933412272998,
            "rating_q025": 989.829764894176
        },
        "vicuna-33b": {
            "rating": 1005.3946238526653,
            "rating_q975": 1039.5947610271048,
            "rating_q025": 971.1944866782258
        },
        "llama-3-8b-instruct": {
            "rating": 1000.000026595711,
            "rating_q975": 1014.415557620431,
            "rating_q025": 985.5844955709911
        },
        "snowflake-arctic-instruct": {
            "rating": 999.0657007945434,
            "rating_q975": 1020.9763389113259,
            "rating_q025": 977.1550626777611
        },
        "gemma-1.1-7b-it": {
            "rating": 996.8980861483243,
            "rating_q975": 1023.0124917748278,
            "rating_q025": 970.7836805218207
        },
        "phi-3-small-8k-instruct": {
            "rating": 990.8706010496336,
            "rating_q975": 1019.5903048509033,
            "rating_q025": 962.1508972483639
        },
        "phi-3-mini-4k-instruct-june-2024": {
            "rating": 989.5536608184465,
            "rating_q975": 1018.0211545302386,
            "rating_q025": 961.0861671066542
        },
        "vicuna-13b": {
            "rating": 973.3946121541874,
            "rating_q975": 1016.1990946898926,
            "rating_q025": 930.5901296184823
        },
        "mixtral-8x7b-instruct-v0.1": {
            "rating": 973.1585748359432,
            "rating_q975": 991.0506967042338,
            "rating_q025": 955.2664529676524
        },
        "llama-2-70b-chat": {
            "rating": 968.4417432127104,
            "rating_q975": 995.9793114710628,
            "rating_q025": 940.9041749543579
        },
        "phi-3-mini-4k-instruct": {
            "rating": 961.7084597436547,
            "rating_q975": 992.3051116933125,
            "rating_q025": 931.1118077939967
        },
        "llama-3.2-3b-instruct": {
            "rating": 950.6567168720601,
            "rating_q975": 991.596618877869,
            "rating_q025": 909.7168148662513
        },
        "phi-3-mini-128k-instruct": {
            "rating": 941.1134032229418,
            "rating_q975": 967.9418712659656,
            "rating_q025": 914.2849351799179
        },
        "llama-3.2-1b-instruct": {
            "rating": 938.9608799479079,
            "rating_q975": 978.6237985050859,
            "rating_q025": 899.2979613907297
        },
        "gemma-1.1-2b-it": {
            "rating": 934.1666674806811,
            "rating_q975": 973.9365024293695,
            "rating_q025": 894.3968325319927
        },
        "llama-2-13b-chat": {
            "rating": 932.0947294916153,
            "rating_q975": 971.2720773548562,
            "rating_q025": 892.9173816283745
        },
        "mistral-7b-instruct-v0.2": {
            "rating": 922.3765712396632,
            "rating_q975": 962.3940328403955,
            "rating_q025": 882.3591096389308
        },
        "llama-2-7b-chat": {
            "rating": 913.9521786847743,
            "rating_q975": 957.4438410093621,
            "rating_q025": 870.4605163601864
        }
    },
    "korean": {
        "gemini-2.5-pro": {
            "rating": 1438.9052920058143,
            "rating_q975": 1461.1927737478145,
            "rating_q025": 1416.617810263814
        },
        "chatgpt-4o-latest-20250326": {
            "rating": 1406.579799537142,
            "rating_q975": 1429.563370503013,
            "rating_q025": 1383.5962285712708
        },
        "o1-2024-12-17": {
            "rating": 1403.0176794910717,
            "rating_q975": 1431.6050394964718,
            "rating_q025": 1374.4303194856714
        },
        "mistral-medium-2508": {
            "rating": 1401.3349292406183,
            "rating_q975": 1428.6597116215837,
            "rating_q025": 1374.0101468596529
        },
        "gpt-4.5-preview-2025-02-27": {
            "rating": 1396.9976541389099,
            "rating_q975": 1437.7576074111937,
            "rating_q025": 1356.237700866626
        },
        "hunyuan-t1-20250711": {
            "rating": 1388.5329091342237,
            "rating_q975": 1422.837971101034,
            "rating_q025": 1354.2278471674133
        },
        "grok-4-0709": {
            "rating": 1387.670957663242,
            "rating_q975": 1418.4641406019832,
            "rating_q025": 1356.8777747245008
        },
        "glm-4.5": {
            "rating": 1385.2942669287638,
            "rating_q975": 1417.400470160318,
            "rating_q025": 1353.1880636972096
        },
        "gpt-5-high": {
            "rating": 1384.0364246588379,
            "rating_q975": 1413.9129654503015,
            "rating_q025": 1354.159883867374
        },
        "qwen-max-2025-08-15": {
            "rating": 1383.248598000973,
            "rating_q975": 1417.1235830517435,
            "rating_q025": 1349.3736129502024
        },
        "gemini-2.5-flash": {
            "rating": 1380.8702935317228,
            "rating_q975": 1403.134302613186,
            "rating_q025": 1358.6062844502599
        },
        "qwen3-235b-a22b-instruct-2507": {
            "rating": 1373.044580795286,
            "rating_q975": 1401.8681417753423,
            "rating_q025": 1344.2210198152295
        },
        "deepseek-v3.1-thinking": {
            "rating": 1364.0888083260825,
            "rating_q975": 1401.5920786831261,
            "rating_q025": 1326.585537969039
        },
        "grok-3-preview-02-24": {
            "rating": 1361.6251503530332,
            "rating_q975": 1385.4031820836067,
            "rating_q025": 1337.8471186224597
        },
        "glm-4.5-air": {
            "rating": 1361.0036530284572,
            "rating_q975": 1395.0663298077257,
            "rating_q025": 1326.940976249189
        },
        "qwen3-235b-a22b-no-thinking": {
            "rating": 1360.2845010829926,
            "rating_q975": 1387.2499741704119,
            "rating_q025": 1333.3190279955734
        },
        "o3-2025-04-16": {
            "rating": 1358.2370454321622,
            "rating_q975": 1379.9101681592717,
            "rating_q025": 1336.5639227050526
        },
        "gpt-5-chat": {
            "rating": 1358.125228966143,
            "rating_q975": 1389.2846564364897,
            "rating_q025": 1326.9658014957959
        },
        "gpt-5-mini-high": {
            "rating": 1357.0586237236234,
            "rating_q975": 1390.9246775993229,
            "rating_q025": 1323.192569847924
        },
        "deepseek-r1-0528": {
            "rating": 1353.859275339258,
            "rating_q975": 1384.6285428473095,
            "rating_q025": 1323.090007831206
        },
        "mai-1-preview": {
            "rating": 1353.2748128213445,
            "rating_q975": 1391.2453651474386,
            "rating_q025": 1315.3042604952507
        },
        "deepseek-v3.1": {
            "rating": 1351.0625323351412,
            "rating_q975": 1385.0699003467641,
            "rating_q025": 1317.0551643235185
        },
        "gpt-4.1-2025-04-14": {
            "rating": 1350.831135049318,
            "rating_q975": 1375.4310784142012,
            "rating_q025": 1326.2311916844344
        },
        "qwen3-235b-a22b-thinking-2507": {
            "rating": 1348.5927115994982,
            "rating_q975": 1386.83937220929,
            "rating_q025": 1310.346050989706
        },
        "claude-opus-4-1-20250805-thinking-16k": {
            "rating": 1348.3452277488584,
            "rating_q975": 1377.2704445466807,
            "rating_q025": 1319.420010951036
        },
        "hunyuan-turbos-20250416": {
            "rating": 1346.6211031743683,
            "rating_q975": 1395.4500539509315,
            "rating_q025": 1297.792152397805
        },
        "claude-opus-4-1-20250805": {
            "rating": 1338.1936524492614,
            "rating_q975": 1368.0020526893118,
            "rating_q025": 1308.3852522092113
        },
        "deepseek-r1": {
            "rating": 1335.2243938235194,
            "rating_q975": 1371.2228503004837,
            "rating_q025": 1299.2259373465552
        },
        "grok-3-mini-high": {
            "rating": 1332.7287768796766,
            "rating_q975": 1366.136584425758,
            "rating_q025": 1299.3209693335955
        },
        "gemini-2.0-flash-001": {
            "rating": 1325.882899805229,
            "rating_q975": 1348.3204673006142,
            "rating_q025": 1303.4453323098442
        },
        "gemini-2.0-flash-lite-preview-02-05": {
            "rating": 1325.77185644435,
            "rating_q975": 1355.0126343193813,
            "rating_q025": 1296.5310785693189
        },
        "deepseek-v3-0324": {
            "rating": 1325.3500647087515,
            "rating_q975": 1348.6916817656256,
            "rating_q025": 1302.0084476518773
        },
        "o3-mini-high": {
            "rating": 1323.053298588328,
            "rating_q975": 1361.126519458403,
            "rating_q025": 1284.9800777182531
        },
        "qwen3-235b-a22b": {
            "rating": 1322.4305061893222,
            "rating_q975": 1348.2499294366735,
            "rating_q025": 1296.6110829419708
        },
        "qwen2.5-max": {
            "rating": 1312.9386513828356,
            "rating_q975": 1338.54248908789,
            "rating_q025": 1287.3348136777809
        },
        "qwen3-30b-a3b-instruct-2507": {
            "rating": 1312.8047274312578,
            "rating_q975": 1346.6545824223813,
            "rating_q025": 1278.9548724401345
        },
        "kimi-k2-0711-preview": {
            "rating": 1312.1453193804673,
            "rating_q975": 1341.1834273780003,
            "rating_q025": 1283.1072113829343
        },
        "grok-3-mini-beta": {
            "rating": 1311.9255739547157,
            "rating_q975": 1340.0442991436141,
            "rating_q025": 1283.8068487658174
        },
        "o4-mini-2025-04-16": {
            "rating": 1310.572233435254,
            "rating_q975": 1333.6817315089734,
            "rating_q025": 1287.4627353615347
        },
        "gpt-oss-120b": {
            "rating": 1307.4549456430375,
            "rating_q975": 1342.4577672469086,
            "rating_q025": 1272.4521240391666
        },
        "claude-opus-4-20250514-thinking-16k": {
            "rating": 1306.9252903751815,
            "rating_q975": 1336.3648729600243,
            "rating_q025": 1277.4857077903384
        },
        "gemma-3-27b-it": {
            "rating": 1306.898632004076,
            "rating_q975": 1329.7259912717223,
            "rating_q025": 1284.0712727364298
        },
        "gemini-1.5-pro-002": {
            "rating": 1306.4100798876323,
            "rating_q975": 1326.2058713586193,
            "rating_q025": 1286.6142884166454
        },
        "mistral-small-2506": {
            "rating": 1306.3671913268772,
            "rating_q975": 1338.2552802840494,
            "rating_q025": 1274.4791023697053
        },
        "mistral-medium-2505": {
            "rating": 1301.2512597767798,
            "rating_q975": 1324.640250899658,
            "rating_q025": 1277.8622686539015
        },
        "claude-sonnet-4-20250514-thinking-32k": {
            "rating": 1298.477259253306,
            "rating_q975": 1327.6062963415734,
            "rating_q025": 1269.3482221650388
        },
        "o1-preview": {
            "rating": 1296.5516449213465,
            "rating_q975": 1320.9893793754209,
            "rating_q025": 1272.1139104672718
        },
        "qwen3-coder-480b-a35b-instruct": {
            "rating": 1294.6551412966146,
            "rating_q975": 1328.2858369488831,
            "rating_q025": 1261.0244456443459
        },
        "claude-opus-4-20250514": {
            "rating": 1290.9315823740324,
            "rating_q975": 1313.9128696395383,
            "rating_q025": 1267.9502951085265
        },
        "gpt-5-nano-high": {
            "rating": 1290.3006571452909,
            "rating_q975": 1332.6308671328738,
            "rating_q025": 1247.970447157708
        },
        "gpt-4.1-mini-2025-04-14": {
            "rating": 1286.6921290888326,
            "rating_q975": 1310.972024805559,
            "rating_q025": 1262.4122333721064
        },
        "qwq-32b": {
            "rating": 1282.2513106442125,
            "rating_q975": 1313.3199514512035,
            "rating_q025": 1251.1826698372217
        },
        "amazon-nova-experimental-chat-05-14": {
            "rating": 1281.7951431010872,
            "rating_q975": 1311.8174821079333,
            "rating_q025": 1251.7728040942413
        },
        "command-a-03-2025": {
            "rating": 1281.751956241595,
            "rating_q975": 1304.0586855739084,
            "rating_q025": 1259.4452269092817
        },
        "o3-mini": {
            "rating": 1280.9881607384623,
            "rating_q975": 1300.8495017301989,
            "rating_q025": 1261.1268197467257
        },
        "qwen3-30b-a3b": {
            "rating": 1274.9215383326034,
            "rating_q975": 1302.0775392237877,
            "rating_q025": 1247.7655374414192
        },
        "claude-sonnet-4-20250514": {
            "rating": 1273.9088883781174,
            "rating_q975": 1298.266431452352,
            "rating_q025": 1249.5513453038827
        },
        "gemma-3n-e4b-it": {
            "rating": 1272.685213346685,
            "rating_q975": 1302.10804790395,
            "rating_q025": 1243.2623787894202
        },
        "step-3": {
            "rating": 1270.1590845635092,
            "rating_q975": 1313.518367540572,
            "rating_q025": 1226.7998015864462
        },
        "gpt-oss-20b": {
            "rating": 1268.9036674924523,
            "rating_q975": 1306.2019547014747,
            "rating_q025": 1231.60538028343
        },
        "glm-4-plus": {
            "rating": 1259.9433637237007,
            "rating_q975": 1287.248440826112,
            "rating_q025": 1232.6382866212891
        },
        "deepseek-v3": {
            "rating": 1258.6030966833532,
            "rating_q975": 1290.172146324128,
            "rating_q025": 1227.034047042578
        },
        "minimax-m1": {
            "rating": 1258.0086488187883,
            "rating_q975": 1287.5882400424143,
            "rating_q025": 1228.4290575951622
        },
        "claude-3-7-sonnet-20250219-thinking-32k": {
            "rating": 1255.2987053133616,
            "rating_q975": 1277.2050125485248,
            "rating_q025": 1233.3923980781985
        },
        "grok-2-2024-08-13": {
            "rating": 1252.4103768689824,
            "rating_q975": 1269.7718286639877,
            "rating_q025": 1235.048925073977
        },
        "gpt-4o-2024-05-13": {
            "rating": 1251.7173773364689,
            "rating_q975": 1264.9859562331146,
            "rating_q025": 1238.4487984398236
        },
        "gemini-advanced-0514": {
            "rating": 1248.7596415216312,
            "rating_q975": 1265.930029798445,
            "rating_q025": 1231.5892532448174
        },
        "gpt-4o-2024-08-06": {
            "rating": 1239.296177439127,
            "rating_q975": 1259.7476549461435,
            "rating_q025": 1218.8446999321102
        },
        "gemini-1.5-pro-001": {
            "rating": 1237.9267901814083,
            "rating_q975": 1252.8132531975841,
            "rating_q025": 1223.0403271652322
        },
        "claude-3-7-sonnet-20250219": {
            "rating": 1237.0869867694269,
            "rating_q975": 1259.8096173832962,
            "rating_q025": 1214.3643561555577
        },
        "gemini-1.5-flash-002": {
            "rating": 1236.9174032892856,
            "rating_q975": 1260.750221001913,
            "rating_q025": 1213.0845855766581
        },
        "o1-mini": {
            "rating": 1236.6531200377763,
            "rating_q975": 1256.3905853464523,
            "rating_q025": 1216.9156547291004
        },
        "athene-v2-chat": {
            "rating": 1224.7562354712195,
            "rating_q975": 1253.9220978687235,
            "rating_q025": 1195.5903730737152
        },
        "mistral-small-3.1-24b-instruct-2503": {
            "rating": 1219.7126772696552,
            "rating_q975": 1250.4691963108382,
            "rating_q025": 1188.9561582284723
        },
        "llama-4-maverick-17b-128e-instruct": {
            "rating": 1218.8453596817935,
            "rating_q975": 1242.9981210379349,
            "rating_q025": 1194.692598325652
        },
        "yi-lightning": {
            "rating": 1218.4227003509222,
            "rating_q975": 1244.794171912805,
            "rating_q025": 1192.0512287890394
        },
        "claude-3-5-sonnet-20240620": {
            "rating": 1217.99568738575,
            "rating_q975": 1233.2942573245964,
            "rating_q025": 1202.6971174469031
        },
        "mistral-large-2411": {
            "rating": 1216.948049194455,
            "rating_q975": 1243.0664835826044,
            "rating_q025": 1190.829614806306
        },
        "gemini-1.5-flash-001": {
            "rating": 1216.7919363749274,
            "rating_q975": 1232.165223122174,
            "rating_q025": 1201.418649627681
        },
        "grok-2-mini-2024-08-13": {
            "rating": 1216.0072895175047,
            "rating_q975": 1234.718466901626,
            "rating_q025": 1197.2961121333833
        },
        "gpt-4o-mini-2024-07-18": {
            "rating": 1215.3301206499593,
            "rating_q975": 1232.1337423737104,
            "rating_q025": 1198.526498926208
        },
        "claude-3-5-sonnet-20241022": {
            "rating": 1214.6092925089833,
            "rating_q975": 1230.7304715886112,
            "rating_q025": 1198.4881134293553
        },
        "amazon-nova-pro-v1.0": {
            "rating": 1214.5174237356932,
            "rating_q975": 1241.9600104094316,
            "rating_q025": 1187.074837061955
        },
        "deepseek-v2.5": {
            "rating": 1212.6770743799993,
            "rating_q975": 1239.6460556698967,
            "rating_q025": 1185.708093090102
        },
        "mistral-small-24b-instruct-2501": {
            "rating": 1211.172695315505,
            "rating_q975": 1247.7177762754147,
            "rating_q025": 1174.6276143555954
        },
        "llama-4-scout-17b-16e-instruct": {
            "rating": 1209.247441187687,
            "rating_q975": 1240.1219397640323,
            "rating_q025": 1178.3729426113418
        },
        "qwen2.5-72b-instruct": {
            "rating": 1206.4064346749697,
            "rating_q975": 1229.9229941455244,
            "rating_q025": 1182.889875204415
        },
        "claude-3-opus-20240229": {
            "rating": 1206.1353070616688,
            "rating_q975": 1218.7977082534762,
            "rating_q025": 1193.4729058698613
        },
        "gpt-4-turbo-2024-04-09": {
            "rating": 1205.7454571977598,
            "rating_q975": 1220.3178658128857,
            "rating_q025": 1191.173048582634
        },
        "llama-3.1-405b-instruct-fp8": {
            "rating": 1202.276277451967,
            "rating_q975": 1219.9759642385604,
            "rating_q025": 1184.5765906653737
        },
        "mistral-large-2407": {
            "rating": 1198.4335178985873,
            "rating_q975": 1217.3479408916915,
            "rating_q025": 1179.5190949054831
        },
        "gpt-4-1106-preview": {
            "rating": 1197.5923715325912,
            "rating_q975": 1214.8326234921053,
            "rating_q025": 1180.3521195730773
        },
        "gemma-2-27b-it": {
            "rating": 1193.3753333083964,
            "rating_q975": 1208.6373862388052,
            "rating_q025": 1178.1132803779872
        },
        "gpt-4-0125-preview": {
            "rating": 1193.19368508516,
            "rating_q975": 1210.1812303472138,
            "rating_q025": 1176.2061398231062
        },
        "command-r-plus-08-2024": {
            "rating": 1189.3749417155364,
            "rating_q975": 1228.7987084571637,
            "rating_q025": 1149.951174973909
        },
        "llama-3.1-405b-instruct-bf16": {
            "rating": 1188.8643300411243,
            "rating_q975": 1210.0023576900055,
            "rating_q025": 1167.726302392243
        },
        "command-r-08-2024": {
            "rating": 1183.9552713258045,
            "rating_q975": 1224.1711319838557,
            "rating_q025": 1143.739410667753
        },
        "c4ai-aya-expanse-32b": {
            "rating": 1177.4633385146326,
            "rating_q975": 1203.3663316781574,
            "rating_q025": 1151.560345351108
        },
        "athene-70b-0725": {
            "rating": 1177.050338761308,
            "rating_q975": 1204.042752092158,
            "rating_q025": 1150.057925430458
        },
        "gemini-1.5-flash-8b-001": {
            "rating": 1174.7470517585177,
            "rating_q975": 1198.884444746502,
            "rating_q025": 1150.6096587705335
        },
        "amazon-nova-micro-v1.0": {
            "rating": 1172.649988312887,
            "rating_q975": 1205.5391286936976,
            "rating_q025": 1139.7608479320766
        },
        "claude-3-5-haiku-20241022": {
            "rating": 1171.994755512044,
            "rating_q975": 1191.4134453071151,
            "rating_q025": 1152.576065716973
        },
        "llama-3.1-70b-instruct": {
            "rating": 1169.2077752382093,
            "rating_q975": 1187.224703796111,
            "rating_q025": 1151.1908466803072
        },
        "amazon-nova-lite-v1.0": {
            "rating": 1169.1699521809362,
            "rating_q975": 1200.101344458285,
            "rating_q025": 1138.2385599035874
        },
        "llama-3.3-70b-instruct": {
            "rating": 1168.6968712387338,
            "rating_q975": 1188.2114589761252,
            "rating_q025": 1149.182283501343
        },
        "phi-4": {
            "rating": 1167.5205327500921,
            "rating_q975": 1198.149385064615,
            "rating_q025": 1136.8916804355692
        },
        "qwen-max-0919": {
            "rating": 1166.7638240112788,
            "rating_q975": 1197.6211950184918,
            "rating_q025": 1135.9064530040655
        },
        "nemotron-4-340b-instruct": {
            "rating": 1165.5747899300957,
            "rating_q975": 1189.0736689685841,
            "rating_q025": 1142.0759108916072
        },
        "jamba-1.5-large": {
            "rating": 1163.1574893109141,
            "rating_q975": 1201.1401661708996,
            "rating_q025": 1125.1748124509281
        },
        "command-r-plus": {
            "rating": 1158.3431095547435,
            "rating_q975": 1174.7055182568504,
            "rating_q025": 1141.9807008526363
        },
        "gemma-2-9b-it": {
            "rating": 1158.183589010469,
            "rating_q975": 1175.6373994162645,
            "rating_q025": 1140.7297786046736
        },
        "qwen2.5-plus-1127": {
            "rating": 1150.8369792397946,
            "rating_q975": 1199.216656856093,
            "rating_q025": 1102.4573016234963
        },
        "claude-3-sonnet-20240229": {
            "rating": 1149.400151163586,
            "rating_q975": 1165.0761151110255,
            "rating_q025": 1133.7241872161467
        },
        "gemma-2-9b-it-simpo": {
            "rating": 1143.4477134290655,
            "rating_q975": 1181.3782980240267,
            "rating_q025": 1105.5171288341046
        },
        "claude-3-haiku-20240307": {
            "rating": 1133.8316196070518,
            "rating_q975": 1148.4955440238227,
            "rating_q025": 1119.1676951902807
        },
        "c4ai-aya-expanse-8b": {
            "rating": 1131.9831834059637,
            "rating_q975": 1175.051786100932,
            "rating_q025": 1088.9145807109953
        },
        "deepseek-coder-v2": {
            "rating": 1127.0569503673669,
            "rating_q975": 1155.5194967973193,
            "rating_q025": 1098.5944039374142
        },
        "reka-flash-21b-20240226-online": {
            "rating": 1125.5829494103405,
            "rating_q975": 1157.0262981463932,
            "rating_q025": 1094.1396006742882
        },
        "command-r": {
            "rating": 1119.4041935600835,
            "rating_q975": 1137.5267732121256,
            "rating_q025": 1101.2816139080417
        },
        "gpt-4-0314": {
            "rating": 1115.1796044644864,
            "rating_q975": 1143.3252864207448,
            "rating_q025": 1087.033922508228
        },
        "qwen2-72b-instruct": {
            "rating": 1108.829053064178,
            "rating_q975": 1126.438366951813,
            "rating_q025": 1091.219739176543
        },
        "reka-flash-21b-20240226": {
            "rating": 1097.9076558582176,
            "rating_q975": 1121.0017094620262,
            "rating_q025": 1074.813602254409
        },
        "llama-3.1-8b-instruct": {
            "rating": 1087.8848034414702,
            "rating_q975": 1106.930259423356,
            "rating_q025": 1068.8393474595848
        },
        "gpt-4-0613": {
            "rating": 1085.6602935094875,
            "rating_q975": 1104.279240697919,
            "rating_q025": 1067.041346321056
        },
        "mixtral-8x22b-instruct-v0.1": {
            "rating": 1082.2065406277543,
            "rating_q975": 1100.262000031393,
            "rating_q025": 1064.1510812241154
        },
        "gemma-2-2b-it": {
            "rating": 1080.2814988093544,
            "rating_q975": 1101.1144831735216,
            "rating_q025": 1059.4485144451871
        },
        "qwen1.5-72b-chat": {
            "rating": 1075.1181747115197,
            "rating_q975": 1099.9815616248034,
            "rating_q025": 1050.2547877982363
        },
        "qwen1.5-110b-chat": {
            "rating": 1071.0028603365163,
            "rating_q975": 1088.4024481755505,
            "rating_q025": 1053.603272497482
        },
        "glm-4-0520": {
            "rating": 1070.367725216809,
            "rating_q975": 1103.475982409417,
            "rating_q025": 1037.2594680242012
        },
        "jamba-1.5-mini": {
            "rating": 1061.5462162065667,
            "rating_q975": 1101.6650402945365,
            "rating_q025": 1021.4273921185968
        },
        "mistral-medium": {
            "rating": 1057.2050551831042,
            "rating_q975": 1089.4156542173946,
            "rating_q025": 1024.994456148814
        },
        "internlm2_5-20b-chat": {
            "rating": 1051.4338953974423,
            "rating_q975": 1094.1138793404677,
            "rating_q025": 1008.7539114544169
        },
        "gpt-3.5-turbo-0125": {
            "rating": 1049.5620339414872,
            "rating_q975": 1068.114479123832,
            "rating_q025": 1031.0095887591426
        },
        "llama-3-70b-instruct": {
            "rating": 1042.8361736842623,
            "rating_q975": 1055.8267796187133,
            "rating_q025": 1029.8455677498114
        },
        "mistral-large-2402": {
            "rating": 1041.740645056015,
            "rating_q975": 1061.0845319615933,
            "rating_q025": 1022.3967581504367
        },
        "qwen1.5-32b-chat": {
            "rating": 1034.5927012545471,
            "rating_q975": 1062.173129683321,
            "rating_q025": 1007.0122728257734
        },
        "yi-1.5-34b-chat": {
            "rating": 1032.6010665085478,
            "rating_q975": 1053.7701597218738,
            "rating_q025": 1011.431973295222
        },
        "llama-3-8b-instruct": {
            "rating": 1029.7154836945037,
            "rating_q975": 1044.8595040285916,
            "rating_q025": 1014.5714633604158
        },
        "gemma-1.1-7b-it": {
            "rating": 1021.9092086961444,
            "rating_q975": 1043.2129245693836,
            "rating_q025": 1000.6054928229051
        },
        "dbrx-instruct-preview": {
            "rating": 1018.025649503178,
            "rating_q975": 1046.2133076973805,
            "rating_q025": 989.8379913089756
        },
        "mixtral-8x7b-instruct-v0.1": {
            "rating": 999.2565211242777,
            "rating_q975": 1020.8343769880306,
            "rating_q025": 977.6786652605248
        },
        "llama-2-70b-chat": {
            "rating": 994.9430179080466,
            "rating_q975": 1031.701118050875,
            "rating_q025": 958.1849177652182
        },
        "phi-3-medium-4k-instruct": {
            "rating": 989.7747831012059,
            "rating_q975": 1010.7657905466001,
            "rating_q025": 968.7837756558116
        },
        "yi-34b-chat": {
            "rating": 988.2367626790744,
            "rating_q975": 1025.0161877569349,
            "rating_q025": 951.4573376012139
        },
        "llama-2-13b-chat": {
            "rating": 988.0889125217093,
            "rating_q975": 1033.5150022798978,
            "rating_q025": 942.662822763521
        },
        "snowflake-arctic-instruct": {
            "rating": 972.6841194631841,
            "rating_q975": 998.1691219538828,
            "rating_q025": 947.1991169724853
        },
        "phi-3-mini-4k-instruct": {
            "rating": 946.017612204218,
            "rating_q975": 966.5593705562667,
            "rating_q025": 925.4758538521693
        },
        "phi-3-small-8k-instruct": {
            "rating": 936.8500823106979,
            "rating_q975": 958.162897418437,
            "rating_q025": 915.5372672029588
        },
        "gemma-1.1-2b-it": {
            "rating": 932.7022250842626,
            "rating_q975": 961.4240240977599,
            "rating_q025": 903.9804260707652
        },
        "phi-3-mini-4k-instruct-june-2024": {
            "rating": 916.1550430595829,
            "rating_q975": 951.5533712070521,
            "rating_q025": 880.7567149121137
        },
        "phi-3-mini-128k-instruct": {
            "rating": 911.6943973782313,
            "rating_q975": 944.1602318406524,
            "rating_q025": 879.2285629158102
        }
    },
    "long_user": {
        "gemini-2.5-pro": {
            "rating": 1454.8305577048964,
            "rating_q975": 1463.3057097790154,
            "rating_q025": 1446.3554056307776
        },
        "claude-opus-4-1-20250805": {
            "rating": 1447.332012607727,
            "rating_q975": 1460.8603505869278,
            "rating_q025": 1433.803674628526
        },
        "claude-opus-4-1-20250805-thinking-16k": {
            "rating": 1446.5123416928552,
            "rating_q975": 1461.8368785654027,
            "rating_q025": 1431.1878048203075
        },
        "qwen3-235b-a22b-instruct-2507": {
            "rating": 1438.7284481363158,
            "rating_q975": 1451.0360586281856,
            "rating_q025": 1426.4208376444458
        },
        "grok-3-preview-02-24": {
            "rating": 1436.4356053008564,
            "rating_q975": 1444.598223760042,
            "rating_q025": 1428.272986841671
        },
        "qwen-max-2025-08-15": {
            "rating": 1433.5818049527568,
            "rating_q975": 1452.3523362259775,
            "rating_q025": 1414.811273679536
        },
        "mistral-medium-2508": {
            "rating": 1423.7312352966958,
            "rating_q975": 1439.8465510412782,
            "rating_q025": 1407.6159195521134
        },
        "gemini-2.5-flash": {
            "rating": 1422.1568913527783,
            "rating_q975": 1430.2854041289647,
            "rating_q025": 1414.028378576592
        },
        "grok-4-0709": {
            "rating": 1420.1801932689602,
            "rating_q975": 1430.3391056489397,
            "rating_q025": 1410.021280888981
        },
        "chatgpt-4o-latest-20250326": {
            "rating": 1418.7410824268663,
            "rating_q975": 1426.9680765207088,
            "rating_q025": 1410.514088333024
        },
        "deepseek-v3.1-thinking": {
            "rating": 1416.9188108866892,
            "rating_q975": 1437.6012811492512,
            "rating_q025": 1396.236340624127
        },
        "glm-4.5": {
            "rating": 1416.7994553415706,
            "rating_q975": 1429.9361916311443,
            "rating_q025": 1403.6627190519969
        },
        "gpt-5-chat": {
            "rating": 1415.0266047300056,
            "rating_q975": 1430.507413307528,
            "rating_q025": 1399.5457961524835
        },
        "claude-opus-4-20250514-thinking-16k": {
            "rating": 1413.6943299572797,
            "rating_q975": 1423.3694337448162,
            "rating_q025": 1404.0192261697434
        },
        "deepseek-v3.1": {
            "rating": 1413.6811556590828,
            "rating_q975": 1432.2509276926048,
            "rating_q025": 1395.1113836255606
        },
        "qwen3-235b-a22b-thinking-2507": {
            "rating": 1408.229461829025,
            "rating_q975": 1423.055430260749,
            "rating_q025": 1393.403493397301
        },
        "gpt-4.5-preview-2025-02-27": {
            "rating": 1407.3417787517726,
            "rating_q975": 1420.1373926776603,
            "rating_q025": 1394.5461648258852
        },
        "gpt-5-high": {
            "rating": 1401.700980368174,
            "rating_q975": 1414.8992369607704,
            "rating_q025": 1388.5027237755778
        },
        "claude-opus-4-20250514": {
            "rating": 1401.3074298499107,
            "rating_q975": 1410.0051582072333,
            "rating_q025": 1392.609701492588
        },
        "claude-sonnet-4-20250514-thinking-32k": {
            "rating": 1396.9940414822545,
            "rating_q975": 1406.766736129452,
            "rating_q025": 1387.2213468350567
        },
        "deepseek-r1-0528": {
            "rating": 1395.6046788252747,
            "rating_q975": 1405.7076235292311,
            "rating_q025": 1385.5017341213183
        },
        "qwen-vl-max-2025-08-13": {
            "rating": 1394.545227849854,
            "rating_q975": 1430.926573614178,
            "rating_q025": 1358.1638820855296
        },
        "gpt-4.1-2025-04-14": {
            "rating": 1390.6840949407742,
            "rating_q975": 1399.3196071424468,
            "rating_q025": 1382.0485827391014
        },
        "glm-4.5-air": {
            "rating": 1387.2912204787947,
            "rating_q975": 1400.5938868377182,
            "rating_q025": 1373.9885541198714
        },
        "hunyuan-t1-20250711": {
            "rating": 1386.9294667416416,
            "rating_q975": 1405.1809925037112,
            "rating_q025": 1368.677940979572
        },
        "qwen3-30b-a3b-instruct-2507": {
            "rating": 1382.330493979477,
            "rating_q975": 1396.6223489335935,
            "rating_q025": 1368.0386390253607
        },
        "o3-2025-04-16": {
            "rating": 1381.454602346151,
            "rating_q975": 1389.2965676191309,
            "rating_q025": 1373.612637073171
        },
        "qwen3-235b-a22b-no-thinking": {
            "rating": 1381.2345981300305,
            "rating_q975": 1389.9349215133052,
            "rating_q025": 1372.5342747467555
        },
        "o1-2024-12-17": {
            "rating": 1378.7373127528595,
            "rating_q975": 1387.9722582292795,
            "rating_q025": 1369.5023672764396
        },
        "qwen3-coder-480b-a35b-instruct": {
            "rating": 1374.8118660196872,
            "rating_q975": 1387.1097650658774,
            "rating_q025": 1362.513966973497
        },
        "grok-3-mini-high": {
            "rating": 1374.6460174610309,
            "rating_q975": 1385.6340993137076,
            "rating_q025": 1363.6579356083544
        },
        "claude-sonnet-4-20250514": {
            "rating": 1373.5719771811603,
            "rating_q975": 1382.5197758936777,
            "rating_q025": 1364.624178468643
        },
        "mai-1-preview": {
            "rating": 1373.0608324979057,
            "rating_q975": 1394.0305414821896,
            "rating_q025": 1352.0911235136218
        },
        "claude-3-7-sonnet-20250219-thinking-32k": {
            "rating": 1372.210567567287,
            "rating_q975": 1380.3579349959887,
            "rating_q025": 1364.0632001385852
        },
        "gpt-5-mini-high": {
            "rating": 1371.2420705722782,
            "rating_q975": 1388.0336272277348,
            "rating_q025": 1354.4505139168218
        },
        "hunyuan-turbos-20250416": {
            "rating": 1369.40204224582,
            "rating_q975": 1383.0898908118538,
            "rating_q025": 1355.7141936797864
        },
        "mistral-medium-2505": {
            "rating": 1363.251411984169,
            "rating_q975": 1371.492539546629,
            "rating_q025": 1355.0102844217088
        },
        "grok-3-mini-beta": {
            "rating": 1362.3791236022876,
            "rating_q975": 1372.0885919193079,
            "rating_q025": 1352.6696552852673
        },
        "qwen2.5-max": {
            "rating": 1361.035273515195,
            "rating_q975": 1369.0614181255023,
            "rating_q025": 1353.0091289048878
        },
        "deepseek-v3-0324": {
            "rating": 1359.428800233736,
            "rating_q975": 1367.5747368079833,
            "rating_q025": 1351.2828636594886
        },
        "deepseek-r1": {
            "rating": 1357.7212235251595,
            "rating_q975": 1368.7537703960427,
            "rating_q025": 1346.6886766542764
        },
        "claude-3-7-sonnet-20250219": {
            "rating": 1357.0441252177818,
            "rating_q975": 1364.707958327137,
            "rating_q025": 1349.3802921084264
        },
        "qwen3-235b-a22b": {
            "rating": 1355.2098349206885,
            "rating_q975": 1364.2699176880892,
            "rating_q025": 1346.1497521532879
        },
        "step-3": {
            "rating": 1351.601349559929,
            "rating_q975": 1376.4018067295954,
            "rating_q025": 1326.8008923902626
        },
        "step-1o-turbo-202506": {
            "rating": 1350.3192296191694,
            "rating_q975": 1365.2219485611145,
            "rating_q025": 1335.4165106772246
        },
        "gemini-2.0-flash-001": {
            "rating": 1348.9764206813736,
            "rating_q975": 1356.4663001186418,
            "rating_q025": 1341.4865412441054
        },
        "kimi-k2-0711-preview": {
            "rating": 1348.1222201015862,
            "rating_q975": 1358.1768721857607,
            "rating_q025": 1338.067568017412
        },
        "gpt-4.1-mini-2025-04-14": {
            "rating": 1347.8348430680346,
            "rating_q975": 1356.5673305592727,
            "rating_q025": 1339.1023555767965
        },
        "o1-preview": {
            "rating": 1347.6929799491081,
            "rating_q975": 1356.4694026284494,
            "rating_q025": 1338.9165572697668
        },
        "hunyuan-large-2025-02-10": {
            "rating": 1345.9811890289125,
            "rating_q975": 1373.1105291301433,
            "rating_q025": 1318.8518489276817
        },
        "deepseek-v3": {
            "rating": 1345.530586106771,
            "rating_q975": 1355.3971042277847,
            "rating_q025": 1335.664067985757
        },
        "o3-mini-high": {
            "rating": 1344.6248244975825,
            "rating_q975": 1355.977294815376,
            "rating_q025": 1333.2723541797889
        },
        "gemma-3-27b-it": {
            "rating": 1339.4466431608691,
            "rating_q975": 1348.008068537689,
            "rating_q025": 1330.8852177840492
        },
        "qwen3-32b": {
            "rating": 1337.596582138709,
            "rating_q975": 1360.6130696161424,
            "rating_q025": 1314.5800946612756
        },
        "o3-mini": {
            "rating": 1333.1582165279258,
            "rating_q975": 1340.202225396984,
            "rating_q025": 1326.1142076588678
        },
        "mistral-small-2506": {
            "rating": 1332.5043922012221,
            "rating_q975": 1343.6084944803245,
            "rating_q025": 1321.4002899221196
        },
        "minimax-m1": {
            "rating": 1332.479331707274,
            "rating_q975": 1341.8525022548156,
            "rating_q025": 1323.1061611597327
        },
        "command-a-03-2025": {
            "rating": 1329.7185440468559,
            "rating_q975": 1337.645038170402,
            "rating_q025": 1321.7920499233096
        },
        "gpt-oss-120b": {
            "rating": 1328.7368918399536,
            "rating_q975": 1344.3882748350036,
            "rating_q025": 1313.0855088449036
        },
        "o4-mini-2025-04-16": {
            "rating": 1325.1973604471816,
            "rating_q975": 1333.8539369495845,
            "rating_q025": 1316.5407839447785
        },
        "gemini-2.0-flash-lite-preview-02-05": {
            "rating": 1324.7538100993052,
            "rating_q975": 1334.4653707521816,
            "rating_q025": 1315.042249446429
        },
        "nvidia-llama-3.3-nemotron-super-49b-v1.5": {
            "rating": 1324.3753061423706,
            "rating_q975": 1344.2286178012466,
            "rating_q025": 1304.5219944834948
        },
        "hunyuan-turbos-20250226": {
            "rating": 1324.252563554124,
            "rating_q975": 1355.2750576989386,
            "rating_q025": 1293.2300694093094
        },
        "gemma-3-12b-it": {
            "rating": 1324.006404605605,
            "rating_q975": 1351.0009862615598,
            "rating_q025": 1297.0118229496504
        },
        "o1-mini": {
            "rating": 1323.4463410899082,
            "rating_q975": 1330.2412768939726,
            "rating_q025": 1316.6514052858438
        },
        "qwen-plus-0125": {
            "rating": 1322.293063143166,
            "rating_q975": 1342.032644894094,
            "rating_q025": 1302.5534813922382
        },
        "amazon-nova-experimental-chat-05-14": {
            "rating": 1318.6329035587764,
            "rating_q975": 1329.25172606475,
            "rating_q025": 1308.0140810528026
        },
        "qwq-32b": {
            "rating": 1316.3323126765545,
            "rating_q975": 1325.7867113716402,
            "rating_q025": 1306.8779139814687
        },
        "gpt-5-nano-high": {
            "rating": 1315.2528090435092,
            "rating_q975": 1335.1601799546966,
            "rating_q025": 1295.3454381323218
        },
        "hunyuan-turbo-0110": {
            "rating": 1314.8679725274958,
            "rating_q975": 1343.7599998313117,
            "rating_q025": 1285.9759452236801
        },
        "qwen3-30b-a3b": {
            "rating": 1314.7293002830538,
            "rating_q975": 1323.9326342956174,
            "rating_q025": 1305.52596627049
        },
        "claude-3-5-sonnet-20241022": {
            "rating": 1314.5816697952187,
            "rating_q975": 1319.8127013008552,
            "rating_q025": 1309.350638289582
        },
        "glm-4-plus-0111": {
            "rating": 1313.5844508336809,
            "rating_q975": 1332.5115862085659,
            "rating_q025": 1294.6573154587957
        },
        "gemini-1.5-pro-002": {
            "rating": 1312.4948084190123,
            "rating_q975": 1318.8552592095295,
            "rating_q025": 1306.134357628495
        },
        "step-2-16k-exp-202412": {
            "rating": 1312.0852511368087,
            "rating_q975": 1332.323288838642,
            "rating_q025": 1291.8472134349752
        },
        "deepseek-v2.5-1210": {
            "rating": 1305.2742510221224,
            "rating_q975": 1321.0413754703552,
            "rating_q025": 1289.507126573889
        },
        "hunyuan-standard-2025-02-10": {
            "rating": 1302.4626865884125,
            "rating_q975": 1328.2099152977996,
            "rating_q025": 1276.7154578790253
        },
        "yi-lightning": {
            "rating": 1300.9535421795154,
            "rating_q975": 1310.6161462399764,
            "rating_q025": 1291.290938119054
        },
        "llama-3.3-nemotron-49b-super-v1": {
            "rating": 1300.3723679498526,
            "rating_q975": 1329.7824743025308,
            "rating_q025": 1270.9622615971746
        },
        "glm-4.5v": {
            "rating": 1297.719490170225,
            "rating_q975": 1336.9672982565753,
            "rating_q025": 1258.471682083875
        },
        "qwen2.5-plus-1127": {
            "rating": 1297.0902188006298,
            "rating_q975": 1310.396852452526,
            "rating_q025": 1283.7835851487334
        },
        "gemini-1.5-pro-001": {
            "rating": 1296.8960830011963,
            "rating_q975": 1304.5917851357735,
            "rating_q025": 1289.200380866619
        },
        "llama-3.1-nemotron-ultra-253b-v1": {
            "rating": 1296.707051245983,
            "rating_q975": 1325.3911481421678,
            "rating_q025": 1268.022954349798
        },
        "athene-v2-chat": {
            "rating": 1296.3541716092338,
            "rating_q975": 1305.078114734499,
            "rating_q025": 1287.6302284839685
        },
        "qwen-max-0919": {
            "rating": 1294.3316640495877,
            "rating_q975": 1305.251173936929,
            "rating_q025": 1283.4121541622467
        },
        "mistral-small-3.1-24b-instruct-2503": {
            "rating": 1294.13796075458,
            "rating_q975": 1304.3199553253428,
            "rating_q025": 1283.955966183817
        },
        "gpt-4o-2024-05-13": {
            "rating": 1294.0642928051175,
            "rating_q975": 1300.1819479507333,
            "rating_q025": 1287.946637659502
        },
        "gpt-4o-mini-2024-07-18": {
            "rating": 1293.8958017829636,
            "rating_q975": 1300.133610477527,
            "rating_q025": 1287.6579930884004
        },
        "magistral-medium-2506": {
            "rating": 1292.9006334056915,
            "rating_q975": 1306.232161973214,
            "rating_q025": 1279.5691048381689
        },
        "glm-4-plus": {
            "rating": 1291.3952594385373,
            "rating_q975": 1300.5194753935396,
            "rating_q025": 1282.271043483535
        },
        "gemini-1.5-flash-002": {
            "rating": 1290.9313075801062,
            "rating_q975": 1298.4863012334522,
            "rating_q025": 1283.3763139267603
        },
        "gpt-4o-2024-08-06": {
            "rating": 1289.6839768494287,
            "rating_q975": 1297.2633371358525,
            "rating_q025": 1282.104616563005
        },
        "qwen2.5-72b-instruct": {
            "rating": 1288.9174621777383,
            "rating_q975": 1296.1479084598964,
            "rating_q025": 1281.6870158955803
        },
        "hunyuan-large-vision": {
            "rating": 1288.4371290401796,
            "rating_q975": 1307.1133146149534,
            "rating_q025": 1269.760943465406
        },
        "gpt-4.1-nano-2025-04-14": {
            "rating": 1288.052297547507,
            "rating_q975": 1307.2136781356537,
            "rating_q025": 1268.8909169593603
        },
        "gemma-3n-e4b-it": {
            "rating": 1287.5242260905634,
            "rating_q975": 1299.5945288866371,
            "rating_q025": 1275.4539232944899
        },
        "gemma-3-4b-it": {
            "rating": 1284.4340209168367,
            "rating_q975": 1309.6681450794808,
            "rating_q025": 1259.1998967541922
        },
        "grok-2-2024-08-13": {
            "rating": 1282.2775867076455,
            "rating_q975": 1288.6843039397688,
            "rating_q025": 1275.870869475522
        },
        "claude-3-5-sonnet-20240620": {
            "rating": 1281.4191294657394,
            "rating_q975": 1288.3782462837398,
            "rating_q025": 1274.4600126477392
        },
        "deepseek-v2.5": {
            "rating": 1280.9850450100225,
            "rating_q975": 1290.160810501702,
            "rating_q025": 1271.8092795183431
        },
        "llama-4-maverick-17b-128e-instruct": {
            "rating": 1278.4179415111926,
            "rating_q975": 1287.0991590915303,
            "rating_q025": 1269.736723930855
        },
        "gpt-oss-20b": {
            "rating": 1275.7968231642972,
            "rating_q975": 1291.966148256622,
            "rating_q025": 1259.627498071972
        },
        "grok-2-mini-2024-08-13": {
            "rating": 1273.1202016779453,
            "rating_q975": 1279.9415918115956,
            "rating_q025": 1266.2988115442952
        },
        "llama-3.1-405b-instruct-bf16": {
            "rating": 1272.0483798150865,
            "rating_q975": 1279.3105044225763,
            "rating_q025": 1264.7862552075965
        },
        "mistral-large-2411": {
            "rating": 1267.91708874679,
            "rating_q975": 1276.674010314497,
            "rating_q025": 1259.1601671790827
        },
        "llama-3.1-405b-instruct-fp8": {
            "rating": 1267.0745454833082,
            "rating_q975": 1273.80194162705,
            "rating_q025": 1260.3471493395664
        },
        "claude-3-opus-20240229": {
            "rating": 1266.522761678933,
            "rating_q975": 1272.1023522001026,
            "rating_q025": 1260.9431711577631
        },
        "llama-4-scout-17b-16e-instruct": {
            "rating": 1266.5221550107385,
            "rating_q975": 1277.0735424194725,
            "rating_q025": 1255.9707676020048
        },
        "mistral-large-2407": {
            "rating": 1265.6095485733074,
            "rating_q975": 1273.3811136892487,
            "rating_q025": 1257.8379834573661
        },
        "llama-3.3-70b-instruct": {
            "rating": 1263.2608710834104,
            "rating_q975": 1269.6634906924726,
            "rating_q025": 1256.8582514743482
        },
        "amazon-nova-pro-v1.0": {
            "rating": 1262.98534783596,
            "rating_q975": 1271.8899443857404,
            "rating_q025": 1254.0807512861795
        },
        "claude-3-5-haiku-20241022": {
            "rating": 1262.813489440129,
            "rating_q975": 1269.1653943763922,
            "rating_q025": 1256.4615845038657
        },
        "gpt-4-turbo-2024-04-09": {
            "rating": 1261.702546433749,
            "rating_q975": 1268.8229206967108,
            "rating_q025": 1254.582172170787
        },
        "gemini-advanced-0514": {
            "rating": 1260.520581101169,
            "rating_q975": 1270.2657967416374,
            "rating_q025": 1250.7753654607009
        },
        "gemini-1.5-flash-001": {
            "rating": 1259.8513004210567,
            "rating_q975": 1267.8444797206134,
            "rating_q025": 1251.8581211215003
        },
        "qwen2.5-coder-32b-instruct": {
            "rating": 1259.1361207958037,
            "rating_q975": 1276.473663410627,
            "rating_q025": 1241.79857818098
        },
        "mistral-small-24b-instruct-2501": {
            "rating": 1255.1073170144718,
            "rating_q975": 1267.9057756556829,
            "rating_q025": 1242.3088583732608
        },
        "gpt-4-0125-preview": {
            "rating": 1252.2011422658848,
            "rating_q975": 1260.006140962911,
            "rating_q025": 1244.3961435688586
        },
        "llama-3.1-70b-instruct": {
            "rating": 1250.1405403441938,
            "rating_q975": 1256.9247408338408,
            "rating_q025": 1243.3563398545466
        },
        "llama-3.1-nemotron-70b-instruct": {
            "rating": 1247.2927499047837,
            "rating_q975": 1263.2734393642327,
            "rating_q025": 1231.312060445335
        },
        "amazon-nova-lite-v1.0": {
            "rating": 1244.3880782641054,
            "rating_q975": 1254.1831989550549,
            "rating_q025": 1234.592957573156
        },
        "gpt-4-1106-preview": {
            "rating": 1243.6665920788032,
            "rating_q975": 1251.3548474158836,
            "rating_q025": 1235.978336741723
        },
        "athene-70b-0725": {
            "rating": 1240.5518021936846,
            "rating_q975": 1252.0967571205667,
            "rating_q025": 1229.0068472668024
        },
        "gemma-2-27b-it": {
            "rating": 1240.3829200692057,
            "rating_q975": 1246.511427169439,
            "rating_q025": 1234.2544129689727
        },
        "command-r-plus-08-2024": {
            "rating": 1239.6718722283736,
            "rating_q975": 1254.0260270414153,
            "rating_q025": 1225.3177174153316
        },
        "c4ai-aya-expanse-32b": {
            "rating": 1237.0626977372715,
            "rating_q975": 1245.4895446307053,
            "rating_q025": 1228.6358508438377
        },
        "gemma-2-9b-it-simpo": {
            "rating": 1236.3967542020455,
            "rating_q975": 1254.2416977084229,
            "rating_q025": 1218.551810695668
        },
        "hunyuan-standard-256k": {
            "rating": 1235.6880894209507,
            "rating_q975": 1259.957585377476,
            "rating_q025": 1211.4185934644252
        },
        "llama-3.1-tulu-3-70b": {
            "rating": 1234.2790073684214,
            "rating_q975": 1257.9196575821884,
            "rating_q025": 1210.6383571546546
        },
        "nemotron-4-340b-instruct": {
            "rating": 1232.786272464644,
            "rating_q975": 1245.4575284458103,
            "rating_q025": 1220.115016483478
        },
        "reka-core-20240904": {
            "rating": 1231.1200831355657,
            "rating_q975": 1247.840995838946,
            "rating_q025": 1214.3991704321854
        },
        "phi-4": {
            "rating": 1229.2745042796928,
            "rating_q975": 1239.2759480872471,
            "rating_q025": 1219.2730604721387
        },
        "gemini-1.5-flash-8b-001": {
            "rating": 1229.0267418825724,
            "rating_q975": 1236.622962009775,
            "rating_q025": 1221.43052175537
        },
        "deepseek-coder-v2": {
            "rating": 1229.015022332279,
            "rating_q975": 1242.4016488449404,
            "rating_q025": 1215.6283958196175
        },
        "ministral-8b-2410": {
            "rating": 1223.6162580066423,
            "rating_q975": 1241.9789983055216,
            "rating_q025": 1205.253517707763
        },
        "claude-3-sonnet-20240229": {
            "rating": 1221.5469699210225,
            "rating_q975": 1229.6008658272613,
            "rating_q025": 1213.4930740147838
        },
        "amazon-nova-micro-v1.0": {
            "rating": 1216.7062233722274,
            "rating_q975": 1227.008484705657,
            "rating_q025": 1206.4039620387978
        },
        "glm-4-0520": {
            "rating": 1215.869432016328,
            "rating_q975": 1231.6847511300564,
            "rating_q025": 1200.0541129025994
        },
        "jamba-1.5-large": {
            "rating": 1214.8123013365646,
            "rating_q975": 1231.3504331394015,
            "rating_q025": 1198.2741695337277
        },
        "llama-3.1-nemotron-51b-instruct": {
            "rating": 1213.2680547531477,
            "rating_q975": 1235.3204565540389,
            "rating_q025": 1191.2156529522565
        },
        "command-r-plus": {
            "rating": 1212.2693932504776,
            "rating_q975": 1220.6196016179026,
            "rating_q025": 1203.9191848830526
        },
        "gemma-2-9b-it": {
            "rating": 1209.5545706611279,
            "rating_q975": 1216.5536958945252,
            "rating_q025": 1202.5554454277305
        },
        "command-r-08-2024": {
            "rating": 1209.037049009828,
            "rating_q975": 1222.7515147009099,
            "rating_q025": 1195.322583318746
        },
        "olmo-2-0325-32b-instruct": {
            "rating": 1207.6840255972986,
            "rating_q975": 1240.6723078128512,
            "rating_q025": 1174.695743381746
        },
        "c4ai-aya-expanse-8b": {
            "rating": 1206.7227338706612,
            "rating_q975": 1220.1487102188871,
            "rating_q025": 1193.2967575224354
        },
        "reka-flash-20240904": {
            "rating": 1204.2444795141887,
            "rating_q975": 1220.5759064730266,
            "rating_q025": 1187.9130525553505
        },
        "qwen2-72b-instruct": {
            "rating": 1202.4905170993989,
            "rating_q975": 1212.0286579452127,
            "rating_q025": 1192.9523762535848
        },
        "claude-3-haiku-20240307": {
            "rating": 1201.5944491355863,
            "rating_q975": 1208.4982624740464,
            "rating_q025": 1194.6906357971263
        },
        "gpt-4-0314": {
            "rating": 1200.5366559031822,
            "rating_q975": 1211.4945526958957,
            "rating_q025": 1189.578759110469
        },
        "gpt-4-0613": {
            "rating": 1198.8953866620286,
            "rating_q975": 1207.6345050236193,
            "rating_q025": 1190.1562683004381
        },
        "llama-3.1-8b-instruct": {
            "rating": 1193.5218247501039,
            "rating_q975": 1200.688663332442,
            "rating_q025": 1186.354986167766
        },
        "llama-3.1-tulu-3-8b": {
            "rating": 1190.9254499389394,
            "rating_q975": 1215.8383714312706,
            "rating_q025": 1166.0125284466083
        },
        "llama-3-70b-instruct": {
            "rating": 1184.8091127127773,
            "rating_q975": 1191.7914157501173,
            "rating_q025": 1177.8268096754373
        },
        "mistral-large-2402": {
            "rating": 1182.6615790265403,
            "rating_q975": 1191.9650677102752,
            "rating_q025": 1173.358090342805
        },
        "qwq-32b-preview": {
            "rating": 1182.0689015799394,
            "rating_q975": 1206.2405456697768,
            "rating_q025": 1157.8972574901022
        },
        "granite-3.1-8b-instruct": {
            "rating": 1174.7063611752274,
            "rating_q975": 1200.6428457859151,
            "rating_q025": 1148.7698765645396
        },
        "qwen1.5-110b-chat": {
            "rating": 1168.8934087017624,
            "rating_q975": 1180.0836914296751,
            "rating_q025": 1157.7031259738494
        },
        "granite-3.1-2b-instruct": {
            "rating": 1168.8785981225142,
            "rating_q975": 1193.7934887597253,
            "rating_q025": 1143.963707485303
        },
        "command-r": {
            "rating": 1168.6686341332063,
            "rating_q975": 1177.981438205698,
            "rating_q025": 1159.3558300607147
        },
        "jamba-1.5-mini": {
            "rating": 1168.5227480507785,
            "rating_q975": 1184.9004493057403,
            "rating_q025": 1152.1450467958168
        },
        "qwen1.5-72b-chat": {
            "rating": 1166.456470357679,
            "rating_q975": 1177.3171209133502,
            "rating_q025": 1155.5958198020082
        },
        "internlm2_5-20b-chat": {
            "rating": 1166.2632336793454,
            "rating_q975": 1181.2011496112473,
            "rating_q025": 1151.3253177474435
        },
        "mistral-medium": {
            "rating": 1165.2345500281413,
            "rating_q975": 1177.488943036366,
            "rating_q025": 1152.9801570199165
        },
        "qwen1.5-32b-chat": {
            "rating": 1158.6088574798187,
            "rating_q975": 1170.5697435270138,
            "rating_q025": 1146.6479714326235
        },
        "yi-1.5-34b-chat": {
            "rating": 1154.9111825070115,
            "rating_q975": 1167.4996908728904,
            "rating_q025": 1142.3226741411327
        },
        "mixtral-8x22b-instruct-v0.1": {
            "rating": 1154.5261953131976,
            "rating_q975": 1163.636902816051,
            "rating_q025": 1145.4154878103443
        },
        "reka-flash-21b-20240226": {
            "rating": 1153.1296764170243,
            "rating_q975": 1165.3829060237276,
            "rating_q025": 1140.876446810321
        },
        "reka-flash-21b-20240226-online": {
            "rating": 1152.0549638300004,
            "rating_q975": 1167.0792964877987,
            "rating_q025": 1137.0306311722018
        },
        "gemma-2-2b-it": {
            "rating": 1147.226368974889,
            "rating_q975": 1154.900547721104,
            "rating_q025": 1139.5521902286741
        },
        "gemini-pro-dev-api": {
            "rating": 1143.6415029482419,
            "rating_q975": 1160.7607709590432,
            "rating_q025": 1126.5222349374405
        },
        "llama-3-8b-instruct": {
            "rating": 1139.7224012999734,
            "rating_q975": 1147.6804727647773,
            "rating_q025": 1131.7643298351695
        },
        "granite-3.0-8b-instruct": {
            "rating": 1135.629160813179,
            "rating_q975": 1157.5169780547485,
            "rating_q025": 1113.7413435716094
        },
        "gpt-3.5-turbo-0125": {
            "rating": 1135.4282359172585,
            "rating_q975": 1144.0152210469946,
            "rating_q025": 1126.8412507875225
        },
        "phi-3-medium-4k-instruct": {
            "rating": 1133.5808991719193,
            "rating_q975": 1145.7194050281273,
            "rating_q025": 1121.4423933157111
        },
        "gemini-pro": {
            "rating": 1132.026468881473,
            "rating_q975": 1170.408200959745,
            "rating_q025": 1093.6447368032009
        },
        "qwen1.5-14b-chat": {
            "rating": 1126.944308842807,
            "rating_q975": 1141.1599332154258,
            "rating_q025": 1112.7286844701885
        },
        "dbrx-instruct-preview": {
            "rating": 1125.5034443770264,
            "rating_q975": 1137.4211889236776,
            "rating_q025": 1113.5856998303752
        },
        "starling-lm-7b-beta": {
            "rating": 1119.6020924197871,
            "rating_q975": 1134.380206597399,
            "rating_q025": 1104.8239782421754
        },
        "zephyr-orpo-141b-A35b-v0.1": {
            "rating": 1118.764169796814,
            "rating_q975": 1145.9388835385078,
            "rating_q025": 1091.5894560551203
        },
        "mixtral-8x7b-instruct-v0.1": {
            "rating": 1117.3924413966984,
            "rating_q975": 1126.3262594092685,
            "rating_q025": 1108.458623384128
        },
        "llama-3.2-3b-instruct": {
            "rating": 1117.0949466034292,
            "rating_q975": 1133.7693197926073,
            "rating_q025": 1100.420573414251
        },
        "tulu-2-dpo-70b": {
            "rating": 1116.591898715895,
            "rating_q975": 1149.6811978884496,
            "rating_q025": 1083.5025995433402
        },
        "wizardlm-70b": {
            "rating": 1112.167733692806,
            "rating_q975": 1143.610750199312,
            "rating_q025": 1080.7247171862998
        },
        "openchat-3.5": {
            "rating": 1107.8627254697535,
            "rating_q975": 1135.9233386784767,
            "rating_q025": 1079.8021122610298
        },
        "yi-34b-chat": {
            "rating": 1107.3792112563701,
            "rating_q975": 1124.7735075149792,
            "rating_q025": 1089.9849149977613
        },
        "deepseek-llm-67b-chat": {
            "rating": 1101.596537162398,
            "rating_q975": 1138.5161541547805,
            "rating_q025": 1064.6769201700156
        },
        "qwen1.5-7b-chat": {
            "rating": 1101.2709028243983,
            "rating_q975": 1131.5165355434367,
            "rating_q025": 1071.0252701053598
        },
        "phi-3-small-8k-instruct": {
            "rating": 1101.2421454401876,
            "rating_q975": 1113.728688189975,
            "rating_q025": 1088.7556026904006
        },
        "openchat-3.5-0106": {
            "rating": 1100.013564664122,
            "rating_q975": 1117.7912010078053,
            "rating_q025": 1082.2359283204385
        },
        "granite-3.0-2b-instruct": {
            "rating": 1099.3356776480318,
            "rating_q975": 1121.5494891354265,
            "rating_q025": 1077.1218661606372
        },
        "starling-lm-7b-alpha": {
            "rating": 1093.5486329827954,
            "rating_q975": 1115.9702625589282,
            "rating_q025": 1071.1270034066627
        },
        "smollm2-1.7b-instruct": {
            "rating": 1093.5144150361416,
            "rating_q975": 1122.6256557334086,
            "rating_q025": 1064.4031743388748
        },
        "gpt-3.5-turbo-1106": {
            "rating": 1082.7631907026484,
            "rating_q975": 1103.3159480653878,
            "rating_q025": 1062.2104333399093
        },
        "llama-2-13b-chat": {
            "rating": 1080.2076871566805,
            "rating_q975": 1096.8681093303708,
            "rating_q025": 1063.5472649829908
        },
        "llama-2-70b-chat": {
            "rating": 1075.8254751070588,
            "rating_q975": 1087.977555923896,
            "rating_q025": 1063.6733942902215
        },
        "mistral-7b-instruct-v0.2": {
            "rating": 1074.1273607068226,
            "rating_q975": 1088.5136295587781,
            "rating_q025": 1059.7410918548671
        },
        "openhermes-2.5-mistral-7b": {
            "rating": 1071.2617943223463,
            "rating_q975": 1104.3470196388578,
            "rating_q025": 1038.176569005835
        },
        "gemma-1.1-7b-it": {
            "rating": 1070.5081537520477,
            "rating_q975": 1082.3982436587205,
            "rating_q025": 1058.6180638453752
        },
        "llama-3.2-1b-instruct": {
            "rating": 1068.2950778171423,
            "rating_q975": 1085.7144772271863,
            "rating_q025": 1050.8756784070981
        },
        "wizardlm-13b": {
            "rating": 1066.1237083235128,
            "rating_q975": 1107.55089789372,
            "rating_q025": 1024.6965187533056
        },
        "vicuna-13b": {
            "rating": 1063.8504611950575,
            "rating_q975": 1084.8282259302314,
            "rating_q025": 1042.8726964598839
        },
        "nous-hermes-2-mixtral-8x7b-dpo": {
            "rating": 1060.6846773396064,
            "rating_q975": 1096.0155003262876,
            "rating_q025": 1025.3538543529253
        },
        "phi-3-mini-4k-instruct-june-2024": {
            "rating": 1055.781075139551,
            "rating_q975": 1073.6832687273684,
            "rating_q025": 1037.8788815517335
        },
        "vicuna-7b": {
            "rating": 1055.5407370515686,
            "rating_q975": 1100.3744827692638,
            "rating_q025": 1010.7069913338737
        },
        "zephyr-7b-beta": {
            "rating": 1054.76092899039,
            "rating_q975": 1081.483163367051,
            "rating_q025": 1028.0386946137291
        },
        "phi-3-mini-4k-instruct": {
            "rating": 1054.4469882265043,
            "rating_q975": 1068.6833151545004,
            "rating_q025": 1040.2106612985085
        },
        "vicuna-33b": {
            "rating": 1044.260660860839,
            "rating_q975": 1062.6645749916484,
            "rating_q025": 1025.85674673003
        },
        "qwen-14b-chat": {
            "rating": 1042.0285793919966,
            "rating_q975": 1080.73333736643,
            "rating_q025": 1003.323821417563
        },
        "gemma-7b-it": {
            "rating": 1038.852072854162,
            "rating_q975": 1060.7211437636824,
            "rating_q025": 1016.9830019446417
        },
        "codellama-34b-instruct": {
            "rating": 1022.1139426442837,
            "rating_q975": 1054.8811512961238,
            "rating_q025": 989.3467339924434
        },
        "palm-2": {
            "rating": 1019.7187211039725,
            "rating_q975": 1057.220388977275,
            "rating_q025": 982.2170532306702
        },
        "gemma-1.1-2b-it": {
            "rating": 1019.3840729638471,
            "rating_q975": 1036.423538495781,
            "rating_q025": 1002.3446074319131
        },
        "snowflake-arctic-instruct": {
            "rating": 1018.723275126982,
            "rating_q975": 1032.3748401599769,
            "rating_q025": 1005.0717100939871
        },
        "mistral-7b-instruct": {
            "rating": 1015.1599714253041,
            "rating_q975": 1041.7690468862697,
            "rating_q025": 988.5508959643385
        },
        "llama-2-7b-chat": {
            "rating": 1015.1271082531943,
            "rating_q975": 1034.3933815887613,
            "rating_q025": 995.8608349176274
        },
        "llama2-70b-steerlm-chat": {
            "rating": 1014.3269330930432,
            "rating_q975": 1056.0003070856005,
            "rating_q025": 972.6535591004858
        },
        "phi-3-mini-128k-instruct": {
            "rating": 1013.795228217196,
            "rating_q975": 1029.009432326282,
            "rating_q025": 998.5810241081101
        },
        "qwen1.5-4b-chat": {
            "rating": 1005.1902026559776,
            "rating_q975": 1028.394909159525,
            "rating_q025": 981.9854961524304
        },
        "gemma-2b-it": {
            "rating": 999.2287979679311,
            "rating_q975": 1029.0266170442028,
            "rating_q025": 969.4309788916596
        },
        "stripedhyena-nous-7b": {
            "rating": 995.8979514514053,
            "rating_q975": 1027.4399939470761,
            "rating_q025": 964.3559089557345
        },
        "chatglm3-6b": {
            "rating": 972.96400009912,
            "rating_q975": 1011.849827252139,
            "rating_q025": 934.078172946101
        }
    },
    "math": {
        "gemini-2.5-pro": {
            "rating": 1480.9373576303433,
            "rating_q975": 1494.1542861659786,
            "rating_q025": 1467.7204290947082
        },
        "grok-4-0709": {
            "rating": 1475.7668650499322,
            "rating_q975": 1496.0397932216406,
            "rating_q025": 1455.4939368782238
        },
        "qwen-max-2025-08-15": {
            "rating": 1474.453738990987,
            "rating_q975": 1511.7700187168143,
            "rating_q025": 1437.1374592651598
        },
        "claude-opus-4-1-20250805-thinking-16k": {
            "rating": 1465.9502784745484,
            "rating_q975": 1492.8237127330744,
            "rating_q025": 1439.0768442160224
        },
        "qwen3-235b-a22b-instruct-2507": {
            "rating": 1456.8835571575632,
            "rating_q975": 1478.2665650062652,
            "rating_q025": 1435.5005493088613
        },
        "deepseek-v3.1": {
            "rating": 1444.5686704061773,
            "rating_q975": 1483.0928749732188,
            "rating_q025": 1406.0444658391357
        },
        "o3-2025-04-16": {
            "rating": 1441.8133468305273,
            "rating_q975": 1453.5543313672777,
            "rating_q025": 1430.0723622937767
        },
        "gpt-5-high": {
            "rating": 1439.0393510106398,
            "rating_q975": 1461.4428710792165,
            "rating_q025": 1416.6358309420632
        },
        "claude-opus-4-1-20250805": {
            "rating": 1437.7475416387088,
            "rating_q975": 1459.1387036862493,
            "rating_q025": 1416.3563795911682
        },
        "gemini-2.5-flash": {
            "rating": 1428.9838737114592,
            "rating_q975": 1440.6359941165113,
            "rating_q025": 1417.331753306407
        },
        "mistral-medium-2508": {
            "rating": 1426.7964263111587,
            "rating_q975": 1458.941469109928,
            "rating_q025": 1394.6513835123897
        },
        "glm-4.5": {
            "rating": 1426.7843815620186,
            "rating_q975": 1451.569489882489,
            "rating_q025": 1401.999273241548
        },
        "qwen3-235b-a22b-thinking-2507": {
            "rating": 1422.6388383987967,
            "rating_q975": 1449.3750278859793,
            "rating_q025": 1395.902648911614
        },
        "glm-4.5-air": {
            "rating": 1420.5323893036034,
            "rating_q975": 1446.4524813584774,
            "rating_q025": 1394.6122972487292
        },
        "gpt-oss-120b": {
            "rating": 1419.4973818346282,
            "rating_q975": 1446.023613980225,
            "rating_q025": 1392.9711496890313
        },
        "gpt-4.5-preview-2025-02-27": {
            "rating": 1415.756587440829,
            "rating_q975": 1430.1584754821622,
            "rating_q025": 1401.3546993994955
        },
        "mai-1-preview": {
            "rating": 1412.9738280484514,
            "rating_q975": 1452.6698887854823,
            "rating_q025": 1373.2777673114206
        },
        "gpt-5-mini-high": {
            "rating": 1410.0217648560244,
            "rating_q975": 1440.924581199069,
            "rating_q025": 1379.11894851298
        },
        "gpt-5-chat": {
            "rating": 1409.8532393901103,
            "rating_q975": 1436.3436691580685,
            "rating_q025": 1383.3628096221523
        },
        "qwen3-235b-a22b": {
            "rating": 1409.0468996462898,
            "rating_q975": 1423.7949114206785,
            "rating_q025": 1394.2988878719011
        },
        "hunyuan-t1-20250711": {
            "rating": 1407.4488377377372,
            "rating_q975": 1445.3992389169748,
            "rating_q025": 1369.4984365584999
        },
        "minimax-m1": {
            "rating": 1407.2311461635222,
            "rating_q975": 1424.1477508411256,
            "rating_q025": 1390.3145414859189
        },
        "deepseek-r1-0528": {
            "rating": 1406.4788326892515,
            "rating_q975": 1425.2696648842186,
            "rating_q025": 1387.6880004942846
        },
        "qwen3-235b-a22b-no-thinking": {
            "rating": 1406.321138924872,
            "rating_q975": 1419.970179667687,
            "rating_q025": 1392.672098182057
        },
        "o4-mini-2025-04-16": {
            "rating": 1405.2368490729039,
            "rating_q975": 1418.0261384152172,
            "rating_q025": 1392.4475597305905
        },
        "qwen3-32b": {
            "rating": 1404.9465159385563,
            "rating_q975": 1434.9646318990954,
            "rating_q025": 1374.9283999780173
        },
        "claude-opus-4-20250514-thinking-16k": {
            "rating": 1404.4286208016867,
            "rating_q975": 1420.022967283501,
            "rating_q025": 1388.8342743198723
        },
        "nvidia-llama-3.3-nemotron-super-49b-v1.5": {
            "rating": 1399.771001106905,
            "rating_q975": 1436.3384933297114,
            "rating_q025": 1363.203508884099
        },
        "qwen3-30b-a3b-instruct-2507": {
            "rating": 1399.39171384904,
            "rating_q975": 1424.9080630532103,
            "rating_q025": 1373.8753646448693
        },
        "o3-mini-high": {
            "rating": 1398.6416692305856,
            "rating_q975": 1411.3052092104065,
            "rating_q025": 1385.978129250765
        },
        "deepseek-r1": {
            "rating": 1398.4495951455037,
            "rating_q975": 1411.7895580331408,
            "rating_q025": 1385.1096322578667
        },
        "grok-3-preview-02-24": {
            "rating": 1396.1592380252398,
            "rating_q975": 1406.6710598180466,
            "rating_q025": 1385.647416232433
        },
        "chatgpt-4o-latest-20250326": {
            "rating": 1395.8462619816962,
            "rating_q975": 1406.4444811604385,
            "rating_q025": 1385.248042802954
        },
        "o1-2024-12-17": {
            "rating": 1392.0878783275075,
            "rating_q975": 1402.0980225149726,
            "rating_q025": 1382.0777341400424
        },
        "claude-sonnet-4-20250514-thinking-32k": {
            "rating": 1386.5963943046495,
            "rating_q975": 1402.9935796290792,
            "rating_q025": 1370.1992089802197
        },
        "grok-3-mini-high": {
            "rating": 1386.2844351830056,
            "rating_q975": 1405.8138819717237,
            "rating_q025": 1366.7549883942875
        },
        "o3-mini": {
            "rating": 1382.7444817937323,
            "rating_q975": 1391.4859430093845,
            "rating_q025": 1374.0030205780802
        },
        "claude-opus-4-20250514": {
            "rating": 1381.6524955027417,
            "rating_q975": 1394.6711140042833,
            "rating_q025": 1368.6338770011998
        },
        "kimi-k2-0711-preview": {
            "rating": 1378.3169584189948,
            "rating_q975": 1395.9388891007545,
            "rating_q025": 1360.695027737235
        },
        "o1-preview": {
            "rating": 1378.3067628105716,
            "rating_q975": 1386.7883258057948,
            "rating_q025": 1369.8251998153487
        },
        "qwen2.5-max": {
            "rating": 1373.3387367254925,
            "rating_q975": 1382.5363921007652,
            "rating_q025": 1364.1410813502196
        },
        "qwen3-30b-a3b": {
            "rating": 1372.6656621381433,
            "rating_q975": 1386.7141866657805,
            "rating_q025": 1358.6171376105062
        },
        "grok-3-mini-beta": {
            "rating": 1371.4720295099883,
            "rating_q975": 1386.3955934859155,
            "rating_q025": 1356.548465534061
        },
        "deepseek-v3-0324": {
            "rating": 1370.951995460732,
            "rating_q975": 1382.7082038012304,
            "rating_q025": 1359.1957871202333
        },
        "qwen3-coder-480b-a35b-instruct": {
            "rating": 1367.0471312259,
            "rating_q975": 1388.3518738467442,
            "rating_q025": 1345.7423886050558
        },
        "llama-3.1-nemotron-ultra-253b-v1": {
            "rating": 1366.064429508561,
            "rating_q975": 1403.474088321189,
            "rating_q025": 1328.6547706959332
        },
        "claude-sonnet-4-20250514": {
            "rating": 1363.25520507555,
            "rating_q975": 1377.2721633387127,
            "rating_q025": 1349.2382468123874
        },
        "hunyuan-turbos-20250416": {
            "rating": 1363.1191062877044,
            "rating_q975": 1381.6544190503114,
            "rating_q025": 1344.5837935250977
        },
        "o1-mini": {
            "rating": 1362.815551919234,
            "rating_q975": 1369.4601940380858,
            "rating_q025": 1356.170909800382
        },
        "qwq-32b": {
            "rating": 1362.6651556676456,
            "rating_q975": 1376.1231717574803,
            "rating_q025": 1349.2071395778112
        },
        "gemini-2.0-flash-001": {
            "rating": 1357.5520374230466,
            "rating_q975": 1366.1210084398338,
            "rating_q025": 1348.9830664062592
        },
        "gpt-4.1-2025-04-14": {
            "rating": 1356.595361616206,
            "rating_q975": 1368.7907157189736,
            "rating_q025": 1344.4000075134384
        },
        "mistral-medium-2505": {
            "rating": 1355.2122274941821,
            "rating_q975": 1367.4117986826861,
            "rating_q025": 1343.0126563056779
        },
        "claude-3-7-sonnet-20250219-thinking-32k": {
            "rating": 1346.0673150293444,
            "rating_q975": 1357.1603529537222,
            "rating_q025": 1334.9742771049666
        },
        "mistral-small-2506": {
            "rating": 1344.5498348021647,
            "rating_q975": 1364.503466149166,
            "rating_q025": 1324.5962034551637
        },
        "gpt-4.1-mini-2025-04-14": {
            "rating": 1342.404865476326,
            "rating_q975": 1354.9765490713485,
            "rating_q025": 1329.8331818813035
        },
        "gpt-5-nano-high": {
            "rating": 1338.8146701202652,
            "rating_q975": 1373.0825017628058,
            "rating_q025": 1304.5468384777244
        },
        "llama-3.3-nemotron-49b-super-v1": {
            "rating": 1331.9596572872404,
            "rating_q975": 1368.7809067656026,
            "rating_q025": 1295.138407808878
        },
        "gpt-oss-20b": {
            "rating": 1331.0175488821778,
            "rating_q975": 1358.4834353052865,
            "rating_q025": 1303.5516624590691
        },
        "qwen-plus-0125": {
            "rating": 1330.7199705077307,
            "rating_q975": 1349.4994457126102,
            "rating_q025": 1311.9404953028516
        },
        "step-1o-turbo-202506": {
            "rating": 1326.8353213314426,
            "rating_q975": 1348.6002702106255,
            "rating_q025": 1305.0703724522598
        },
        "claude-3-7-sonnet-20250219": {
            "rating": 1322.9770866550468,
            "rating_q975": 1332.7544467187267,
            "rating_q025": 1313.1997265913667
        },
        "gemma-3-27b-it": {
            "rating": 1319.8170277366726,
            "rating_q975": 1330.0541118750807,
            "rating_q025": 1309.5799435982644
        },
        "gemini-1.5-pro-002": {
            "rating": 1319.383655539744,
            "rating_q975": 1325.5417927576736,
            "rating_q025": 1313.2255183218144
        },
        "deepseek-v3": {
            "rating": 1317.8313798534718,
            "rating_q975": 1327.661715349054,
            "rating_q025": 1308.0010443578894
        },
        "gemini-2.0-flash-lite-preview-02-05": {
            "rating": 1316.004965744575,
            "rating_q975": 1325.6898831199594,
            "rating_q025": 1306.3200483691905
        },
        "gemma-3-12b-it": {
            "rating": 1314.578952448471,
            "rating_q975": 1341.2444055977717,
            "rating_q025": 1287.9134992991706
        },
        "amazon-nova-experimental-chat-05-14": {
            "rating": 1312.688645297635,
            "rating_q975": 1329.1125589654862,
            "rating_q025": 1296.2647316297841
        },
        "llama-4-maverick-17b-128e-instruct": {
            "rating": 1312.3548906031044,
            "rating_q975": 1324.2333128597754,
            "rating_q025": 1300.4764683464334
        },
        "claude-3-5-sonnet-20241022": {
            "rating": 1311.400193027412,
            "rating_q975": 1317.0183754036493,
            "rating_q025": 1305.7820106511742
        },
        "step-2-16k-exp-202412": {
            "rating": 1308.6768787249232,
            "rating_q975": 1327.0008927914278,
            "rating_q025": 1290.3528646584186
        },
        "claude-3-5-sonnet-20240620": {
            "rating": 1307.8158836419584,
            "rating_q975": 1314.0139033582855,
            "rating_q025": 1301.6178639256314
        },
        "athene-v2-chat": {
            "rating": 1305.3835641150108,
            "rating_q975": 1313.6991218656292,
            "rating_q025": 1297.0680063643924
        },
        "yi-lightning": {
            "rating": 1304.9988089539038,
            "rating_q975": 1313.3889400253418,
            "rating_q025": 1296.6086778824658
        },
        "qwen2.5-plus-1127": {
            "rating": 1303.6869105227524,
            "rating_q975": 1316.1598581832254,
            "rating_q025": 1291.2139628622795
        },
        "hunyuan-turbos-20250226": {
            "rating": 1303.4472918594765,
            "rating_q975": 1332.7121754715865,
            "rating_q025": 1274.1824082473668
        },
        "command-a-03-2025": {
            "rating": 1298.0585338252108,
            "rating_q975": 1308.6304588771172,
            "rating_q025": 1287.4866087733042
        },
        "deepseek-v2.5-1210": {
            "rating": 1293.5611113489738,
            "rating_q975": 1308.7241307124548,
            "rating_q025": 1278.3980919854928
        },
        "llama-4-scout-17b-16e-instruct": {
            "rating": 1291.8328711455215,
            "rating_q975": 1308.0433460408892,
            "rating_q025": 1275.6223962501535
        },
        "gpt-4o-2024-05-13": {
            "rating": 1291.1412670517998,
            "rating_q975": 1296.7013695453957,
            "rating_q025": 1285.5811645582037
        },
        "gpt-4o-2024-08-06": {
            "rating": 1290.5327265697804,
            "rating_q975": 1297.3387656680886,
            "rating_q025": 1283.7266874714721
        },
        "glm-4-plus-0111": {
            "rating": 1290.2031410967518,
            "rating_q975": 1308.4034418733338,
            "rating_q025": 1272.0028403201698
        },
        "qwen2.5-72b-instruct": {
            "rating": 1289.2845284351752,
            "rating_q975": 1296.283547358268,
            "rating_q025": 1282.2855095120824
        },
        "grok-2-2024-08-13": {
            "rating": 1288.433198780523,
            "rating_q975": 1294.4122815573708,
            "rating_q025": 1282.4541160036752
        },
        "llama-3.1-405b-instruct-fp8": {
            "rating": 1287.7229065417578,
            "rating_q975": 1293.9933653407124,
            "rating_q025": 1281.452447742803
        },
        "hunyuan-large-2025-02-10": {
            "rating": 1286.6994025154413,
            "rating_q975": 1310.1266422415838,
            "rating_q025": 1263.2721627892986
        },
        "hunyuan-large-vision": {
            "rating": 1285.4671464030819,
            "rating_q975": 1313.4130481536306,
            "rating_q025": 1257.5212446525331
        },
        "llama-3.1-405b-instruct-bf16": {
            "rating": 1284.665830182012,
            "rating_q975": 1291.6750718687256,
            "rating_q025": 1277.6565884952988
        },
        "qwen-max-0919": {
            "rating": 1282.382014098661,
            "rating_q975": 1292.6205994363268,
            "rating_q025": 1272.1434287609954
        },
        "hunyuan-turbo-0110": {
            "rating": 1281.3147623683176,
            "rating_q975": 1310.4882381413663,
            "rating_q025": 1252.1412865952686
        },
        "glm-4-plus": {
            "rating": 1281.0594719399019,
            "rating_q975": 1289.6177960538998,
            "rating_q025": 1272.5011478259037
        },
        "hunyuan-standard-2025-02-10": {
            "rating": 1280.2329698955084,
            "rating_q975": 1303.8065102984153,
            "rating_q025": 1256.6594294926015
        },
        "gpt-4.1-nano-2025-04-14": {
            "rating": 1280.161143341671,
            "rating_q975": 1303.1157499005021,
            "rating_q025": 1257.2065367828402
        },
        "gpt-4-turbo-2024-04-09": {
            "rating": 1279.103469477815,
            "rating_q975": 1285.4884101804244,
            "rating_q025": 1272.7185287752056
        },
        "claude-3-opus-20240229": {
            "rating": 1278.9690042381553,
            "rating_q975": 1284.0209051397226,
            "rating_q025": 1273.9171033365878
        },
        "deepseek-v2.5": {
            "rating": 1278.6003562354356,
            "rating_q975": 1286.9624863162248,
            "rating_q025": 1270.2382261546463
        },
        "gemini-advanced-0514": {
            "rating": 1278.3495185705337,
            "rating_q975": 1286.8421699226726,
            "rating_q025": 1269.8568672183949
        },
        "gemini-1.5-flash-002": {
            "rating": 1277.7785161120964,
            "rating_q975": 1285.06660944289,
            "rating_q025": 1270.4904227813029
        },
        "llama-3.1-nemotron-70b-instruct": {
            "rating": 1277.533610229897,
            "rating_q975": 1292.290766325987,
            "rating_q025": 1262.7764541338067
        },
        "gemini-1.5-pro-001": {
            "rating": 1277.047355883084,
            "rating_q975": 1283.8319259113207,
            "rating_q025": 1270.2627858548474
        },
        "gpt-4-1106-preview": {
            "rating": 1276.8536105606618,
            "rating_q975": 1283.4648332884613,
            "rating_q025": 1270.2423878328623
        },
        "gpt-4-0125-preview": {
            "rating": 1275.134150814576,
            "rating_q975": 1281.8268180763562,
            "rating_q025": 1268.4414835527955
        },
        "gpt-4o-mini-2024-07-18": {
            "rating": 1274.2979203080286,
            "rating_q975": 1280.0573155612778,
            "rating_q025": 1268.5385250547795
        },
        "llama-3.3-70b-instruct": {
            "rating": 1273.7829103889608,
            "rating_q975": 1280.8180096467386,
            "rating_q025": 1266.7478111311827
        },
        "grok-2-mini-2024-08-13": {
            "rating": 1272.0684549063744,
            "rating_q975": 1278.4383201549826,
            "rating_q025": 1265.6985896577662
        },
        "mistral-large-2407": {
            "rating": 1270.0025283413243,
            "rating_q975": 1276.8533438840525,
            "rating_q025": 1263.1517127985958
        },
        "mistral-large-2411": {
            "rating": 1267.7146766587086,
            "rating_q975": 1276.0578727287968,
            "rating_q025": 1259.3714805886202
        },
        "gemma-3n-e4b-it": {
            "rating": 1264.0229685364397,
            "rating_q975": 1280.612064634381,
            "rating_q025": 1247.4338724384984
        },
        "qwen2.5-coder-32b-instruct": {
            "rating": 1261.303231856275,
            "rating_q975": 1278.152855852308,
            "rating_q025": 1244.453607860242
        },
        "llama-3.1-70b-instruct": {
            "rating": 1260.0581135981965,
            "rating_q975": 1266.3573614827612,
            "rating_q025": 1253.7588657136318
        },
        "amazon-nova-pro-v1.0": {
            "rating": 1258.3403881286815,
            "rating_q975": 1267.2375877946015,
            "rating_q025": 1249.4431884627616
        },
        "mistral-small-3.1-24b-instruct-2503": {
            "rating": 1258.2882594691403,
            "rating_q975": 1274.9897753523373,
            "rating_q025": 1241.5867435859432
        },
        "phi-4": {
            "rating": 1253.435104113938,
            "rating_q975": 1263.2516888504094,
            "rating_q025": 1243.6185193774663
        },
        "deepseek-coder-v2": {
            "rating": 1250.075252195502,
            "rating_q975": 1262.6602006451394,
            "rating_q025": 1237.4903037458641
        },
        "claude-3-5-haiku-20241022": {
            "rating": 1248.8533030574042,
            "rating_q975": 1256.042876379217,
            "rating_q025": 1241.6637297355915
        },
        "llama-3.1-tulu-3-70b": {
            "rating": 1247.7417178925182,
            "rating_q975": 1270.934035005215,
            "rating_q025": 1224.5494007798213
        },
        "mistral-small-24b-instruct-2501": {
            "rating": 1247.5265004729165,
            "rating_q975": 1260.1902746857986,
            "rating_q025": 1234.8627262600344
        },
        "hunyuan-standard-256k": {
            "rating": 1245.997271906555,
            "rating_q975": 1272.2827009216155,
            "rating_q025": 1219.711842891494
        },
        "gemma-3-4b-it": {
            "rating": 1245.309282843576,
            "rating_q975": 1273.273780868674,
            "rating_q025": 1217.3447848184783
        },
        "qwen2-72b-instruct": {
            "rating": 1242.4514026661586,
            "rating_q975": 1250.8291620612524,
            "rating_q025": 1234.073643271065
        },
        "athene-70b-0725": {
            "rating": 1239.6246970858483,
            "rating_q975": 1249.0535246189968,
            "rating_q025": 1230.1958695526998
        },
        "magistral-medium-2506": {
            "rating": 1239.1908807032876,
            "rating_q975": 1267.9856786195935,
            "rating_q025": 1210.3960827869817
        },
        "gpt-4-0314": {
            "rating": 1238.8651023451594,
            "rating_q975": 1247.6046855707657,
            "rating_q025": 1230.1255191195535
        },
        "llama-3.1-nemotron-51b-instruct": {
            "rating": 1238.4261258983802,
            "rating_q975": 1259.6615947597538,
            "rating_q025": 1217.1906570370065
        },
        "gemini-1.5-flash-001": {
            "rating": 1237.8577382241385,
            "rating_q975": 1244.758135244631,
            "rating_q025": 1230.9573412036461
        },
        "amazon-nova-lite-v1.0": {
            "rating": 1234.7197640331103,
            "rating_q975": 1244.553649149694,
            "rating_q025": 1224.8858789165267
        },
        "reka-core-20240904": {
            "rating": 1231.4292099203908,
            "rating_q975": 1244.3210274873072,
            "rating_q025": 1218.5373923534742
        },
        "jamba-1.5-large": {
            "rating": 1229.5861680175285,
            "rating_q975": 1244.1112840785213,
            "rating_q025": 1215.0610519565357
        },
        "qwq-32b-preview": {
            "rating": 1229.2295664236367,
            "rating_q975": 1251.6726003006236,
            "rating_q025": 1206.7865325466496
        },
        "glm-4-0520": {
            "rating": 1228.08704423431,
            "rating_q975": 1242.4034805010065,
            "rating_q025": 1213.7706079676136
        },
        "llama-3-70b-instruct": {
            "rating": 1226.9679724462735,
            "rating_q975": 1233.2363648804424,
            "rating_q025": 1220.6995800121044
        },
        "gpt-4-0613": {
            "rating": 1226.0841214765103,
            "rating_q975": 1233.4025653311828,
            "rating_q025": 1218.7656776218378
        },
        "nemotron-4-340b-instruct": {
            "rating": 1223.98669901844,
            "rating_q975": 1234.9252553188733,
            "rating_q025": 1213.0481427180066
        },
        "claude-3-sonnet-20240229": {
            "rating": 1222.1965053039394,
            "rating_q975": 1229.1229234423988,
            "rating_q025": 1215.2700871654797
        },
        "gemma-2-27b-it": {
            "rating": 1221.5602316504805,
            "rating_q975": 1227.1115027070334,
            "rating_q025": 1216.0089605939274
        },
        "gemini-1.5-flash-8b-001": {
            "rating": 1218.6500402332372,
            "rating_q975": 1225.8070483879474,
            "rating_q025": 1211.4930320785268
        },
        "amazon-nova-micro-v1.0": {
            "rating": 1215.6524882739575,
            "rating_q975": 1225.3682365337506,
            "rating_q025": 1205.9367400141643
        },
        "olmo-2-0325-32b-instruct": {
            "rating": 1215.3041872897415,
            "rating_q975": 1243.16126726822,
            "rating_q025": 1187.447107311263
        },
        "c4ai-aya-expanse-32b": {
            "rating": 1211.2184791399454,
            "rating_q975": 1219.6323509372498,
            "rating_q025": 1202.8046073426408
        },
        "mistral-large-2402": {
            "rating": 1208.6812320658983,
            "rating_q975": 1216.6632918747916,
            "rating_q025": 1200.699172257005
        },
        "reka-flash-20240904": {
            "rating": 1208.175066303095,
            "rating_q975": 1220.7684932264203,
            "rating_q025": 1195.5816393797697
        },
        "llama-3.1-tulu-3-8b": {
            "rating": 1207.936937113141,
            "rating_q975": 1231.285932084093,
            "rating_q025": 1184.5879421421894
        },
        "ministral-8b-2410": {
            "rating": 1202.2106129391798,
            "rating_q975": 1219.5724096317408,
            "rating_q025": 1184.8488162466188
        },
        "command-r-plus-08-2024": {
            "rating": 1198.5678589921386,
            "rating_q975": 1210.9936193614913,
            "rating_q025": 1186.1420986227856
        },
        "claude-3-haiku-20240307": {
            "rating": 1198.398882371944,
            "rating_q975": 1204.5842689664303,
            "rating_q025": 1192.2134957774579
        },
        "internlm2_5-20b-chat": {
            "rating": 1197.0402164770037,
            "rating_q975": 1209.9586799521078,
            "rating_q025": 1184.1217530018996
        },
        "qwen1.5-110b-chat": {
            "rating": 1195.2334422810768,
            "rating_q975": 1205.5528994725294,
            "rating_q025": 1184.9139850896245
        },
        "mixtral-8x22b-instruct-v0.1": {
            "rating": 1194.0160190358752,
            "rating_q975": 1201.8973317342554,
            "rating_q025": 1186.1347063374944
        },
        "gemma-2-9b-it": {
            "rating": 1193.9850093614573,
            "rating_q975": 1200.4023245884443,
            "rating_q025": 1187.5676941344702
        },
        "llama-3.1-8b-instruct": {
            "rating": 1191.7703215261695,
            "rating_q975": 1198.4755163077295,
            "rating_q025": 1185.0651267446092
        },
        "yi-1.5-34b-chat": {
            "rating": 1190.9740549184498,
            "rating_q975": 1201.0196080865603,
            "rating_q025": 1180.9285017503398
        },
        "mistral-medium": {
            "rating": 1188.9028708853245,
            "rating_q975": 1198.7673250866044,
            "rating_q025": 1179.0384166840447
        },
        "gemma-2-9b-it-simpo": {
            "rating": 1183.8461004118394,
            "rating_q975": 1197.9757638851563,
            "rating_q025": 1169.7164369385225
        },
        "phi-3-medium-4k-instruct": {
            "rating": 1183.613549458649,
            "rating_q975": 1193.1539561931959,
            "rating_q025": 1174.0731427241021
        },
        "c4ai-aya-expanse-8b": {
            "rating": 1180.4486025773767,
            "rating_q975": 1194.1451389679792,
            "rating_q025": 1166.7520661867748
        },
        "reka-flash-21b-20240226-online": {
            "rating": 1178.589681608749,
            "rating_q975": 1191.4945152030593,
            "rating_q025": 1165.6848480144388
        },
        "command-r-plus": {
            "rating": 1174.611578004625,
            "rating_q975": 1181.9646989164376,
            "rating_q025": 1167.2584570928125
        },
        "qwen1.5-72b-chat": {
            "rating": 1173.2154749032477,
            "rating_q975": 1181.945840760212,
            "rating_q025": 1164.4851090462835
        },
        "jamba-1.5-mini": {
            "rating": 1171.5063004097701,
            "rating_q975": 1186.5852488926262,
            "rating_q025": 1156.4273519269138
        },
        "command-r-08-2024": {
            "rating": 1167.7630708293254,
            "rating_q975": 1179.9512799518532,
            "rating_q025": 1155.5748617067977
        },
        "granite-3.1-2b-instruct": {
            "rating": 1167.4077023246427,
            "rating_q975": 1191.9890464934122,
            "rating_q025": 1142.8263581558735
        },
        "reka-flash-21b-20240226": {
            "rating": 1165.536705128662,
            "rating_q975": 1175.9398664090613,
            "rating_q025": 1155.1335438482631
        },
        "qwen1.5-32b-chat": {
            "rating": 1165.4292903889998,
            "rating_q975": 1176.1821594579503,
            "rating_q025": 1154.6764213200493
        },
        "granite-3.1-8b-instruct": {
            "rating": 1164.1089416882305,
            "rating_q975": 1190.3472382315508,
            "rating_q025": 1137.87064514491
        },
        "phi-3-mini-4k-instruct-june-2024": {
            "rating": 1162.3692646576903,
            "rating_q975": 1175.0470762614525,
            "rating_q025": 1149.6914530539282
        },
        "llama-3-8b-instruct": {
            "rating": 1162.0940664827858,
            "rating_q975": 1168.7959528588817,
            "rating_q025": 1155.3921801066904
        },
        "granite-3.0-8b-instruct": {
            "rating": 1161.4458536616153,
            "rating_q975": 1178.0421640895602,
            "rating_q025": 1144.8495432336701
        },
        "phi-3-small-8k-instruct": {
            "rating": 1160.9319866997716,
            "rating_q975": 1172.659264090572,
            "rating_q025": 1149.2047093089716
        },
        "zephyr-orpo-141b-A35b-v0.1": {
            "rating": 1160.2141590940669,
            "rating_q975": 1181.691963110565,
            "rating_q025": 1138.736355077569
        },
        "mixtral-8x7b-instruct-v0.1": {
            "rating": 1157.6251868287231,
            "rating_q975": 1165.1335173209725,
            "rating_q025": 1150.116856336474
        },
        "dbrx-instruct-preview": {
            "rating": 1157.1735941478635,
            "rating_q975": 1167.685036156057,
            "rating_q025": 1146.6621521396698
        },
        "gpt-3.5-turbo-0125": {
            "rating": 1152.66151788774,
            "rating_q975": 1160.0482323464462,
            "rating_q025": 1145.274803429034
        },
        "gpt-3.5-turbo-1106": {
            "rating": 1151.874551759698,
            "rating_q975": 1166.3780065949227,
            "rating_q025": 1137.3710969244732
        },
        "gemma-2-2b-it": {
            "rating": 1148.7764750834008,
            "rating_q975": 1155.569242027598,
            "rating_q025": 1141.9837081392036
        },
        "gemini-pro-dev-api": {
            "rating": 1142.0191580124788,
            "rating_q975": 1155.1322964684155,
            "rating_q025": 1128.9060195565417
        },
        "gemini-pro": {
            "rating": 1139.5835489707167,
            "rating_q975": 1158.2520269475722,
            "rating_q025": 1120.9150709938613
        },
        "granite-3.0-2b-instruct": {
            "rating": 1137.757975528733,
            "rating_q975": 1154.509253916573,
            "rating_q025": 1121.0066971408928
        },
        "starling-lm-7b-beta": {
            "rating": 1136.910802990194,
            "rating_q975": 1149.8369148261381,
            "rating_q025": 1123.98469115425
        },
        "qwen1.5-14b-chat": {
            "rating": 1135.826722983593,
            "rating_q975": 1148.4870110234654,
            "rating_q025": 1123.1664349437206
        },
        "llama-3.2-3b-instruct": {
            "rating": 1135.7473501817221,
            "rating_q975": 1150.5497310447206,
            "rating_q025": 1120.9449693187237
        },
        "command-r": {
            "rating": 1132.849412946126,
            "rating_q975": 1141.2822601436965,
            "rating_q025": 1124.4165657485553
        },
        "smollm2-1.7b-instruct": {
            "rating": 1128.8132210019735,
            "rating_q975": 1157.930679599516,
            "rating_q025": 1099.6957624044308
        },
        "yi-34b-chat": {
            "rating": 1125.1752634794348,
            "rating_q975": 1137.5719846530603,
            "rating_q025": 1112.7785423058092
        },
        "phi-3-mini-4k-instruct": {
            "rating": 1124.6387220345832,
            "rating_q975": 1135.8131653618595,
            "rating_q025": 1113.464278707307
        },
        "wizardlm-70b": {
            "rating": 1122.3958161460382,
            "rating_q975": 1140.7117871078428,
            "rating_q025": 1104.0798451842338
        },
        "snowflake-arctic-instruct": {
            "rating": 1121.6048807352104,
            "rating_q975": 1131.9151621573883,
            "rating_q025": 1111.2945993130324
        },
        "gemma-1.1-7b-it": {
            "rating": 1118.6029409297416,
            "rating_q975": 1128.9726847189272,
            "rating_q025": 1108.233197140556
        },
        "openchat-3.5-0106": {
            "rating": 1117.8574639238407,
            "rating_q975": 1130.6686088650606,
            "rating_q025": 1105.0463189826207
        },
        "tulu-2-dpo-70b": {
            "rating": 1117.1646000279827,
            "rating_q975": 1135.6251039667193,
            "rating_q025": 1098.7040960892464
        },
        "deepseek-llm-67b-chat": {
            "rating": 1117.0674266164979,
            "rating_q975": 1140.0815924605774,
            "rating_q025": 1094.053260772418
        },
        "openhermes-2.5-mistral-7b": {
            "rating": 1108.4744210371434,
            "rating_q975": 1128.0333407575226,
            "rating_q025": 1088.9155013167642
        },
        "phi-3-mini-128k-instruct": {
            "rating": 1102.4010985256941,
            "rating_q975": 1114.6764812833599,
            "rating_q025": 1090.1257157680284
        },
        "llama-2-70b-chat": {
            "rating": 1101.8369838126268,
            "rating_q975": 1111.1687329333452,
            "rating_q025": 1092.5052346919083
        },
        "llama-3.2-1b-instruct": {
            "rating": 1100.972768550088,
            "rating_q975": 1115.923568774741,
            "rating_q025": 1086.0219683254354
        },
        "mistral-7b-instruct-v0.2": {
            "rating": 1097.8169769021733,
            "rating_q975": 1109.0097616080855,
            "rating_q025": 1086.6241921962612
        },
        "starling-lm-7b-alpha": {
            "rating": 1092.4954224988578,
            "rating_q975": 1107.4707924021109,
            "rating_q025": 1077.5200525956047
        },
        "qwen1.5-7b-chat": {
            "rating": 1090.8261722125947,
            "rating_q975": 1110.5626279503208,
            "rating_q025": 1071.0897164748685
        },
        "dolphin-2.2.1-mistral-7b": {
            "rating": 1087.183185996135,
            "rating_q975": 1119.6275287161798,
            "rating_q025": 1054.7388432760904
        },
        "llama2-70b-steerlm-chat": {
            "rating": 1081.645467812014,
            "rating_q975": 1107.8690629361872,
            "rating_q025": 1055.4218726878407
        },
        "vicuna-33b": {
            "rating": 1081.589758623486,
            "rating_q975": 1093.394600631193,
            "rating_q025": 1069.7849166157791
        },
        "openchat-3.5": {
            "rating": 1080.4622601165083,
            "rating_q975": 1098.3333570013265,
            "rating_q025": 1062.5911632316904
        },
        "llama-2-13b-chat": {
            "rating": 1079.153386699468,
            "rating_q975": 1091.6465821454897,
            "rating_q025": 1066.6601912534463
        },
        "qwen-14b-chat": {
            "rating": 1078.5155101384125,
            "rating_q975": 1101.7264252838568,
            "rating_q025": 1055.3045949929685
        },
        "gemma-7b-it": {
            "rating": 1076.6105677769244,
            "rating_q975": 1092.381923453561,
            "rating_q025": 1060.8392121002876
        },
        "solar-10.7b-instruct-v1.0": {
            "rating": 1074.122896592261,
            "rating_q975": 1095.4268750777785,
            "rating_q025": 1052.8189181067435
        },
        "nous-hermes-2-mixtral-8x7b-dpo": {
            "rating": 1073.8328881359805,
            "rating_q975": 1094.7562906412318,
            "rating_q025": 1052.9094856307293
        },
        "codellama-34b-instruct": {
            "rating": 1067.8459084152869,
            "rating_q975": 1086.1076689698448,
            "rating_q025": 1049.5841478607292
        },
        "gemma-1.1-2b-it": {
            "rating": 1062.160496296292,
            "rating_q975": 1077.1222236771412,
            "rating_q025": 1047.198768915443
        },
        "palm-2": {
            "rating": 1059.4503567964566,
            "rating_q975": 1078.1651861432267,
            "rating_q025": 1040.7355274496863
        },
        "mpt-30b-chat": {
            "rating": 1058.0391410846032,
            "rating_q975": 1091.4247269310586,
            "rating_q025": 1024.6535552381479
        },
        "llama-2-7b-chat": {
            "rating": 1053.9379282168159,
            "rating_q975": 1067.0870753297058,
            "rating_q025": 1040.7887811039259
        },
        "zephyr-7b-beta": {
            "rating": 1051.741378450528,
            "rating_q975": 1068.161131960633,
            "rating_q025": 1035.3216249404227
        },
        "stripedhyena-nous-7b": {
            "rating": 1043.5193237281665,
            "rating_q975": 1063.29144981401,
            "rating_q025": 1023.7471976423228
        },
        "vicuna-13b": {
            "rating": 1041.7633397942154,
            "rating_q975": 1054.7570523736304,
            "rating_q025": 1028.7696272148007
        },
        "mistral-7b-instruct": {
            "rating": 1039.852773950296,
            "rating_q975": 1058.1282296563654,
            "rating_q025": 1021.5773182442266
        },
        "guanaco-33b": {
            "rating": 1039.383542608462,
            "rating_q975": 1071.501214624135,
            "rating_q025": 1007.265870592789
        },
        "qwen1.5-4b-chat": {
            "rating": 1037.657742400319,
            "rating_q975": 1054.6741334857813,
            "rating_q025": 1020.6413513148568
        },
        "olmo-7b-instruct": {
            "rating": 1030.4268935831487,
            "rating_q975": 1048.7067848070087,
            "rating_q025": 1012.1470023592888
        },
        "wizardlm-13b": {
            "rating": 1030.370616958682,
            "rating_q975": 1050.267572363791,
            "rating_q025": 1010.4736615535727
        },
        "gemma-2b-it": {
            "rating": 1022.9424693126005,
            "rating_q975": 1044.095799235876,
            "rating_q025": 1001.789139389325
        },
        "vicuna-7b": {
            "rating": 1008.4169021256189,
            "rating_q975": 1029.3129373933914,
            "rating_q025": 987.5208668578464
        },
        "chatglm3-6b": {
            "rating": 1000.5926744118046,
            "rating_q975": 1023.6122752051024,
            "rating_q025": 977.5730736185069
        },
        "gpt4all-13b-snoozy": {
            "rating": 949.6661499865677,
            "rating_q975": 986.9494963988818,
            "rating_q025": 912.3828035742536
        },
        "koala-13b": {
            "rating": 943.0765457413873,
            "rating_q975": 964.0006210813691,
            "rating_q025": 922.1524704014055
        },
        "chatglm2-6b": {
            "rating": 937.7944128502807,
            "rating_q975": 970.8269342385025,
            "rating_q025": 904.7618914620589
        },
        "chatglm-6b": {
            "rating": 936.5097398183643,
            "rating_q975": 961.67297000661,
            "rating_q025": 911.3465096301187
        },
        "RWKV-4-Raven-14B": {
            "rating": 933.3866669280718,
            "rating_q975": 957.4158635896038,
            "rating_q025": 909.3574702665398
        },
        "mpt-7b-chat": {
            "rating": 931.403370137693,
            "rating_q975": 956.663564727555,
            "rating_q025": 906.1431755478308
        },
        "alpaca-13b": {
            "rating": 918.5092988659799,
            "rating_q975": 941.0108279959929,
            "rating_q025": 896.0077697359668
        },
        "oasst-pythia-12b": {
            "rating": 901.6633364172217,
            "rating_q975": 923.4632106414307,
            "rating_q025": 879.8634621930125
        },
        "dolly-v2-12b": {
            "rating": 882.1887406916878,
            "rating_q975": 910.8837182298862,
            "rating_q025": 853.4937631534895
        },
        "fastchat-t5-3b": {
            "rating": 872.7652098283193,
            "rating_q975": 898.4451309401968,
            "rating_q025": 847.0852887164418
        },
        "stablelm-tuned-alpha-7b": {
            "rating": 848.9159061380517,
            "rating_q975": 877.718201529284,
            "rating_q025": 820.1136107468194
        },
        "llama-13b": {
            "rating": 846.865571163039,
            "rating_q975": 879.8766601266152,
            "rating_q025": 813.8544821994631
        }
    },
    "multiturn": {
        "gemini-2.5-pro": {
            "rating": 1468.3504015733797,
            "rating_q975": 1477.2525402047725,
            "rating_q025": 1459.4482629419872
        },
        "chatgpt-4o-latest-20250326": {
            "rating": 1459.0204215509136,
            "rating_q975": 1467.4033901970304,
            "rating_q025": 1450.6374529047969
        },
        "qwen-max-2025-08-15": {
            "rating": 1448.891681077053,
            "rating_q975": 1469.6056935538793,
            "rating_q025": 1428.1776686002268
        },
        "gpt-4.5-preview-2025-02-27": {
            "rating": 1444.3647549332397,
            "rating_q975": 1457.5482830076178,
            "rating_q025": 1431.181226858862
        },
        "claude-opus-4-1-20250805-thinking-16k": {
            "rating": 1442.6886441888846,
            "rating_q975": 1458.8034533878647,
            "rating_q025": 1426.5738349899045
        },
        "claude-opus-4-1-20250805": {
            "rating": 1437.7302468121752,
            "rating_q975": 1452.0775170197157,
            "rating_q025": 1423.3829766046345
        },
        "gpt-5-chat": {
            "rating": 1435.6638235618152,
            "rating_q975": 1451.0902645966896,
            "rating_q025": 1420.2373825269408
        },
        "grok-4-0709": {
            "rating": 1435.0014031583328,
            "rating_q975": 1447.019350341278,
            "rating_q025": 1422.9834559753874
        },
        "qwen3-235b-a22b-instruct-2507": {
            "rating": 1431.6081564704518,
            "rating_q975": 1444.9154644673617,
            "rating_q025": 1418.3008484735417
        },
        "mistral-medium-2508": {
            "rating": 1424.6291673771184,
            "rating_q975": 1442.57306780458,
            "rating_q025": 1406.6852669496568
        },
        "grok-3-preview-02-24": {
            "rating": 1424.4708138431968,
            "rating_q975": 1433.1626894233652,
            "rating_q025": 1415.778938263028
        },
        "glm-4.5": {
            "rating": 1418.7352633471714,
            "rating_q975": 1433.3803631254113,
            "rating_q025": 1404.0901635689318
        },
        "gpt-5-high": {
            "rating": 1418.1522377594852,
            "rating_q975": 1433.0950862796255,
            "rating_q025": 1403.2093892393445
        },
        "o3-2025-04-16": {
            "rating": 1412.5299072462572,
            "rating_q975": 1420.8309419113339,
            "rating_q025": 1404.2288725811804
        },
        "deepseek-v3.1-thinking": {
            "rating": 1408.6692126642265,
            "rating_q975": 1433.0363793264303,
            "rating_q025": 1384.302046002023
        },
        "qwen3-235b-a22b-thinking-2507": {
            "rating": 1405.842256094827,
            "rating_q975": 1421.985674864912,
            "rating_q025": 1389.698837324742
        },
        "deepseek-r1-0528": {
            "rating": 1404.551884441557,
            "rating_q975": 1414.9759099110163,
            "rating_q025": 1394.1278589720976
        },
        "qwen-vl-max-2025-08-13": {
            "rating": 1404.4711778583314,
            "rating_q975": 1444.9680146820576,
            "rating_q025": 1363.9743410346052
        },
        "deepseek-v3.1": {
            "rating": 1402.4968106310148,
            "rating_q975": 1423.5457943173476,
            "rating_q025": 1381.447826944682
        },
        "gemini-2.5-flash": {
            "rating": 1401.8832739944153,
            "rating_q975": 1410.3200226890203,
            "rating_q025": 1393.4465252998102
        },
        "qwen3-235b-a22b-no-thinking": {
            "rating": 1395.6438415612388,
            "rating_q975": 1404.7049951772967,
            "rating_q025": 1386.5826879451806
        },
        "gpt-4.1-2025-04-14": {
            "rating": 1394.4599617193073,
            "rating_q975": 1403.2761725656746,
            "rating_q025": 1385.64375087294
        },
        "deepseek-v3-0324": {
            "rating": 1391.7795586033642,
            "rating_q975": 1400.3123045860737,
            "rating_q025": 1383.246812620655
        },
        "hunyuan-t1-20250711": {
            "rating": 1390.485109247456,
            "rating_q975": 1410.4360685809816,
            "rating_q025": 1370.5341499139304
        },
        "claude-opus-4-20250514-thinking-16k": {
            "rating": 1390.3461430454452,
            "rating_q975": 1400.4368074937163,
            "rating_q025": 1380.255478597174
        },
        "deepseek-r1": {
            "rating": 1389.1530631172093,
            "rating_q975": 1400.6096767144181,
            "rating_q025": 1377.6964495200002
        },
        "hunyuan-turbos-20250416": {
            "rating": 1388.2393632904311,
            "rating_q975": 1401.9029707670795,
            "rating_q025": 1374.575755813783
        },
        "claude-opus-4-20250514": {
            "rating": 1385.3317448014623,
            "rating_q975": 1394.3879931145414,
            "rating_q025": 1376.2754964883832
        },
        "glm-4.5-air": {
            "rating": 1384.8101420516305,
            "rating_q975": 1399.3610647175294,
            "rating_q025": 1370.2592193857313
        },
        "kimi-k2-0711-preview": {
            "rating": 1381.7379274398959,
            "rating_q975": 1392.967530114063,
            "rating_q025": 1370.508324765729
        },
        "gpt-5-mini-high": {
            "rating": 1380.9055096496259,
            "rating_q975": 1398.3588153917517,
            "rating_q025": 1363.4522039074998
        },
        "mistral-medium-2505": {
            "rating": 1379.392250797909,
            "rating_q975": 1388.052771617785,
            "rating_q025": 1370.7317299780325
        },
        "mai-1-preview": {
            "rating": 1377.8618148394225,
            "rating_q975": 1401.903789218366,
            "rating_q025": 1353.819840460479
        },
        "qwen3-30b-a3b-instruct-2507": {
            "rating": 1377.1472460448692,
            "rating_q975": 1392.5736996654662,
            "rating_q025": 1361.7207924242725
        },
        "claude-sonnet-4-20250514-thinking-32k": {
            "rating": 1368.8113798951151,
            "rating_q975": 1378.9800016092586,
            "rating_q025": 1358.642758180972
        },
        "o1-preview": {
            "rating": 1368.4980252207993,
            "rating_q975": 1377.2601221701866,
            "rating_q025": 1359.7359282714117
        },
        "qwen3-235b-a22b": {
            "rating": 1366.9059927213302,
            "rating_q975": 1376.5858503430984,
            "rating_q025": 1357.226135099562
        },
        "qwen2.5-max": {
            "rating": 1364.8749140748064,
            "rating_q975": 1373.105701775097,
            "rating_q025": 1356.644126374516
        },
        "gpt-4.1-mini-2025-04-14": {
            "rating": 1356.5634772437684,
            "rating_q975": 1365.3674930885088,
            "rating_q025": 1347.759461399028
        },
        "grok-3-mini-beta": {
            "rating": 1356.5315109191397,
            "rating_q975": 1366.8073626375008,
            "rating_q025": 1346.2556592007784
        },
        "o1-2024-12-17": {
            "rating": 1355.1530492910942,
            "rating_q975": 1363.9573337684872,
            "rating_q025": 1346.3487648137013
        },
        "o4-mini-2025-04-16": {
            "rating": 1354.4350875896137,
            "rating_q975": 1363.32780311477,
            "rating_q025": 1345.5423720644574
        },
        "claude-sonnet-4-20250514": {
            "rating": 1354.160965673579,
            "rating_q975": 1363.4700513097555,
            "rating_q025": 1344.8518800374027
        },
        "qwen3-coder-480b-a35b-instruct": {
            "rating": 1353.6984102086017,
            "rating_q975": 1368.2152934572741,
            "rating_q025": 1339.181526959929
        },
        "mistral-small-2506": {
            "rating": 1351.7479920828644,
            "rating_q975": 1363.7229759362035,
            "rating_q025": 1339.773008229525
        },
        "gemini-2.0-flash-001": {
            "rating": 1351.4392171550803,
            "rating_q975": 1358.9108312284477,
            "rating_q025": 1343.967603081713
        },
        "grok-3-mini-high": {
            "rating": 1351.2261784932548,
            "rating_q975": 1363.2360340486232,
            "rating_q025": 1339.2163229378862
        },
        "gemma-3-27b-it": {
            "rating": 1350.8150252238995,
            "rating_q975": 1359.2228959199,
            "rating_q025": 1342.407154527899
        },
        "deepseek-v3": {
            "rating": 1347.5787008026357,
            "rating_q975": 1356.9485043392945,
            "rating_q025": 1338.208897265977
        },
        "step-3": {
            "rating": 1346.1287737291739,
            "rating_q975": 1370.7098249161847,
            "rating_q025": 1321.5477225421628
        },
        "step-1o-turbo-202506": {
            "rating": 1338.9461378782812,
            "rating_q975": 1354.1031614020153,
            "rating_q025": 1323.789114354547
        },
        "claude-3-7-sonnet-20250219-thinking-32k": {
            "rating": 1338.6791368813294,
            "rating_q975": 1347.0712687771181,
            "rating_q025": 1330.2870049855408
        },
        "claude-3-7-sonnet-20250219": {
            "rating": 1338.5079171856087,
            "rating_q975": 1346.3832371063634,
            "rating_q025": 1330.632597264854
        },
        "qwen-plus-0125": {
            "rating": 1336.6836791103065,
            "rating_q975": 1355.4183653870055,
            "rating_q025": 1317.9489928336072
        },
        "command-a-03-2025": {
            "rating": 1336.3654306503329,
            "rating_q975": 1344.6554923378933,
            "rating_q025": 1328.0753689627727
        },
        "minimax-m1": {
            "rating": 1336.2190952728963,
            "rating_q975": 1346.4934391676607,
            "rating_q025": 1325.944751378132
        },
        "gpt-oss-120b": {
            "rating": 1335.2901107779721,
            "rating_q975": 1351.7599223750503,
            "rating_q025": 1318.820299180894
        },
        "gemma-3-12b-it": {
            "rating": 1334.4686503132218,
            "rating_q975": 1360.1393652836014,
            "rating_q025": 1308.7979353428423
        },
        "qwen3-32b": {
            "rating": 1333.8063345619053,
            "rating_q975": 1356.7412053060916,
            "rating_q025": 1310.871463817719
        },
        "nvidia-llama-3.3-nemotron-super-49b-v1.5": {
            "rating": 1332.9917620642266,
            "rating_q975": 1355.4616876930777,
            "rating_q025": 1310.5218364353752
        },
        "glm-4.5v": {
            "rating": 1328.4472602418432,
            "rating_q975": 1370.6302388385532,
            "rating_q025": 1286.2642816451332
        },
        "claude-3-5-sonnet-20241022": {
            "rating": 1324.9181294716234,
            "rating_q975": 1330.1747984284189,
            "rating_q025": 1319.6614605148277
        },
        "glm-4-plus-0111": {
            "rating": 1322.67762976619,
            "rating_q975": 1341.5495834607505,
            "rating_q025": 1303.8056760716293
        },
        "gpt-5-nano-high": {
            "rating": 1321.579461093199,
            "rating_q975": 1342.04306981745,
            "rating_q025": 1301.1158523689478
        },
        "o3-mini-high": {
            "rating": 1320.9947188643869,
            "rating_q975": 1332.5251926231178,
            "rating_q025": 1309.464245105656
        },
        "llama-3.1-nemotron-ultra-253b-v1": {
            "rating": 1318.6314408159299,
            "rating_q975": 1348.7459247563372,
            "rating_q025": 1288.5169568755223
        },
        "llama-3.3-nemotron-49b-super-v1": {
            "rating": 1317.0923117450848,
            "rating_q975": 1348.4635309894109,
            "rating_q025": 1285.7210925007585
        },
        "qwq-32b": {
            "rating": 1316.9577297254154,
            "rating_q975": 1326.935012833184,
            "rating_q025": 1306.980446617647
        },
        "hunyuan-turbos-20250226": {
            "rating": 1315.376919488428,
            "rating_q975": 1348.0946457487532,
            "rating_q025": 1282.659193228103
        },
        "o1-mini": {
            "rating": 1313.0584396654344,
            "rating_q975": 1319.8159518300884,
            "rating_q025": 1306.3009275007805
        },
        "o3-mini": {
            "rating": 1312.0230579348495,
            "rating_q975": 1319.2217572790883,
            "rating_q025": 1304.8243585906105
        },
        "yi-lightning": {
            "rating": 1311.8782454943387,
            "rating_q975": 1321.2484934398105,
            "rating_q025": 1302.5079975488668
        },
        "qwen3-30b-a3b": {
            "rating": 1310.0389282079534,
            "rating_q975": 1319.62772219226,
            "rating_q025": 1300.4501342236467
        },
        "gemini-2.0-flash-lite-preview-02-05": {
            "rating": 1308.2719867101046,
            "rating_q975": 1317.6935883273554,
            "rating_q025": 1298.8503850928535
        },
        "hunyuan-turbo-0110": {
            "rating": 1306.1343216127027,
            "rating_q975": 1335.4816474471165,
            "rating_q025": 1276.7869957782887
        },
        "gpt-4o-2024-05-13": {
            "rating": 1300.9780074772063,
            "rating_q975": 1306.933647332901,
            "rating_q025": 1295.0223676215116
        },
        "claude-3-5-sonnet-20240620": {
            "rating": 1299.3633557346504,
            "rating_q975": 1305.8567452163766,
            "rating_q025": 1292.8699662529243
        },
        "qwen2.5-plus-1127": {
            "rating": 1298.6038271719376,
            "rating_q975": 1311.4151851670997,
            "rating_q025": 1285.7924691767755
        },
        "llama-3.1-405b-instruct-bf16": {
            "rating": 1297.0409213675932,
            "rating_q975": 1304.134899730281,
            "rating_q025": 1289.9469430049053
        },
        "gemini-1.5-pro-002": {
            "rating": 1296.5694819099033,
            "rating_q975": 1302.8802968554658,
            "rating_q025": 1290.2586669643408
        },
        "amazon-nova-experimental-chat-05-14": {
            "rating": 1296.4390214687778,
            "rating_q975": 1307.507946952806,
            "rating_q025": 1285.3700959847497
        },
        "deepseek-v2.5-1210": {
            "rating": 1296.3888826643702,
            "rating_q975": 1312.1631157688116,
            "rating_q025": 1280.6146495599287
        },
        "step-2-16k-exp-202412": {
            "rating": 1292.019340932533,
            "rating_q975": 1311.444273398817,
            "rating_q025": 1272.594408466249
        },
        "grok-2-2024-08-13": {
            "rating": 1290.69313495597,
            "rating_q975": 1297.1268753173554,
            "rating_q025": 1284.2593945945846
        },
        "gpt-oss-20b": {
            "rating": 1289.8861375663319,
            "rating_q975": 1306.7733969274668,
            "rating_q025": 1272.9988782051971
        },
        "glm-4-plus": {
            "rating": 1288.7280234771372,
            "rating_q975": 1297.62190788608,
            "rating_q025": 1279.8341390681944
        },
        "llama-3.1-405b-instruct-fp8": {
            "rating": 1288.3326500213984,
            "rating_q975": 1294.8676886347694,
            "rating_q025": 1281.7976114080273
        },
        "athene-v2-chat": {
            "rating": 1286.6333659724041,
            "rating_q975": 1295.3067593778112,
            "rating_q025": 1277.9599725669973
        },
        "llama-4-maverick-17b-128e-instruct": {
            "rating": 1285.6651740185857,
            "rating_q975": 1294.7263334307581,
            "rating_q025": 1276.6040146064136
        },
        "gemma-3n-e4b-it": {
            "rating": 1285.2705577267884,
            "rating_q975": 1297.0145089872535,
            "rating_q025": 1273.5266064663233
        },
        "hunyuan-large-2025-02-10": {
            "rating": 1284.9429680884764,
            "rating_q975": 1309.9792029533312,
            "rating_q025": 1259.9067332236218
        },
        "gpt-4o-mini-2024-07-18": {
            "rating": 1284.5743103004097,
            "rating_q975": 1290.5840400784593,
            "rating_q025": 1278.5645805223603
        },
        "llama-4-scout-17b-16e-instruct": {
            "rating": 1282.0493603154205,
            "rating_q975": 1292.76595471607,
            "rating_q025": 1271.3327659147708
        },
        "llama-3.3-70b-instruct": {
            "rating": 1281.3718391594207,
            "rating_q975": 1287.8724797088294,
            "rating_q025": 1274.8711986100122
        },
        "gpt-4o-2024-08-06": {
            "rating": 1279.0313009184324,
            "rating_q975": 1286.3168968773414,
            "rating_q025": 1271.7457049595237
        },
        "gpt-4.1-nano-2025-04-14": {
            "rating": 1278.6446709299726,
            "rating_q975": 1296.4990428830786,
            "rating_q025": 1260.7902989768666
        },
        "qwen-max-0919": {
            "rating": 1275.9863699757964,
            "rating_q975": 1286.5332869257286,
            "rating_q025": 1265.4394530258644
        },
        "claude-3-opus-20240229": {
            "rating": 1275.9253647272785,
            "rating_q975": 1281.292828179908,
            "rating_q025": 1270.5579012746493
        },
        "llama-3.1-nemotron-70b-instruct": {
            "rating": 1275.6310617762292,
            "rating_q975": 1291.8540883577275,
            "rating_q025": 1259.408035194731
        },
        "hunyuan-standard-2025-02-10": {
            "rating": 1275.3578218610141,
            "rating_q975": 1299.0621202901345,
            "rating_q025": 1251.6535234318937
        },
        "magistral-medium-2506": {
            "rating": 1273.4127890831246,
            "rating_q975": 1289.6354346675434,
            "rating_q025": 1257.1901434987055
        },
        "qwen2.5-72b-instruct": {
            "rating": 1272.1558643507055,
            "rating_q975": 1279.4378943810084,
            "rating_q025": 1264.8738343204027
        },
        "gemini-advanced-0514": {
            "rating": 1270.13340467772,
            "rating_q975": 1279.1530316610563,
            "rating_q025": 1261.1137776943835
        },
        "gpt-4-turbo-2024-04-09": {
            "rating": 1268.2295624548665,
            "rating_q975": 1275.0406181246083,
            "rating_q025": 1261.4185067851245
        },
        "gemini-1.5-pro-001": {
            "rating": 1268.2006769230327,
            "rating_q975": 1275.34179640731,
            "rating_q025": 1261.0595574387553
        },
        "grok-2-mini-2024-08-13": {
            "rating": 1266.1468507482637,
            "rating_q975": 1272.8995338165084,
            "rating_q025": 1259.3941676800189
        },
        "claude-3-5-haiku-20241022": {
            "rating": 1262.5861715269639,
            "rating_q975": 1269.0125033058994,
            "rating_q025": 1256.1598397480284
        },
        "deepseek-v2.5": {
            "rating": 1261.7685880831032,
            "rating_q975": 1270.8473038312588,
            "rating_q025": 1252.6898723349477
        },
        "mistral-large-2411": {
            "rating": 1261.1146631607955,
            "rating_q975": 1269.6364579908743,
            "rating_q025": 1252.5928683307168
        },
        "mistral-large-2407": {
            "rating": 1258.4404325291782,
            "rating_q975": 1265.7178887350826,
            "rating_q025": 1251.1629763232738
        },
        "gemma-3-4b-it": {
            "rating": 1258.0811266193311,
            "rating_q975": 1281.5022329257795,
            "rating_q025": 1234.6600203128828
        },
        "mistral-small-3.1-24b-instruct-2503": {
            "rating": 1257.4117094831404,
            "rating_q975": 1268.66357089508,
            "rating_q025": 1246.159848071201
        },
        "athene-70b-0725": {
            "rating": 1257.4056247944309,
            "rating_q975": 1267.7565071955637,
            "rating_q025": 1247.0547423932978
        },
        "gpt-4-1106-preview": {
            "rating": 1257.3246123918468,
            "rating_q975": 1264.4694539423817,
            "rating_q025": 1250.1797708413121
        },
        "hunyuan-large-vision": {
            "rating": 1257.09580515564,
            "rating_q975": 1276.1045576449892,
            "rating_q025": 1238.0870526662904
        },
        "llama-3.1-70b-instruct": {
            "rating": 1257.0788612506597,
            "rating_q975": 1263.6125717159825,
            "rating_q025": 1250.5451507853368
        },
        "gemini-1.5-flash-002": {
            "rating": 1253.8725247973368,
            "rating_q975": 1261.5820778354528,
            "rating_q025": 1246.1629717592207
        },
        "llama-3.1-tulu-3-70b": {
            "rating": 1252.7551623135623,
            "rating_q975": 1275.526965433641,
            "rating_q025": 1229.983359193484
        },
        "gpt-4-0125-preview": {
            "rating": 1251.916090968559,
            "rating_q975": 1259.1053882618323,
            "rating_q025": 1244.726793675286
        },
        "amazon-nova-pro-v1.0": {
            "rating": 1246.8347710861635,
            "rating_q975": 1255.6434230283958,
            "rating_q025": 1238.026119143931
        },
        "gemini-1.5-flash-001": {
            "rating": 1229.0088648143565,
            "rating_q975": 1236.3087413031835,
            "rating_q025": 1221.7089883255296
        },
        "claude-3-sonnet-20240229": {
            "rating": 1228.8667068697036,
            "rating_q975": 1236.2421039398614,
            "rating_q025": 1221.491309799546
        },
        "llama-3.1-nemotron-51b-instruct": {
            "rating": 1227.705186908924,
            "rating_q975": 1247.3581991379112,
            "rating_q025": 1208.0521746799366
        },
        "olmo-2-0325-32b-instruct": {
            "rating": 1227.1255739962812,
            "rating_q975": 1255.8665111511193,
            "rating_q025": 1198.3846368414431
        },
        "reka-core-20240904": {
            "rating": 1225.9399530229412,
            "rating_q975": 1241.6304326895097,
            "rating_q025": 1210.2494733563722
        },
        "gemma-2-27b-it": {
            "rating": 1225.2306933465227,
            "rating_q975": 1231.0610951306671,
            "rating_q025": 1219.4002915623782
        },
        "qwen2.5-coder-32b-instruct": {
            "rating": 1224.28567418249,
            "rating_q975": 1241.6682219687434,
            "rating_q025": 1206.9031263962368
        },
        "llama-3-70b-instruct": {
            "rating": 1224.1799244337644,
            "rating_q975": 1230.9057210253582,
            "rating_q025": 1217.454127842171
        },
        "jamba-1.5-large": {
            "rating": 1221.420202437028,
            "rating_q975": 1235.4005845842116,
            "rating_q025": 1207.439820289844
        },
        "gemma-2-9b-it-simpo": {
            "rating": 1220.3321748446385,
            "rating_q975": 1234.340782865631,
            "rating_q025": 1206.3235668236462
        },
        "glm-4-0520": {
            "rating": 1219.6243463165374,
            "rating_q975": 1233.770589085217,
            "rating_q025": 1205.4781035478582
        },
        "mistral-small-24b-instruct-2501": {
            "rating": 1218.6310169952358,
            "rating_q975": 1231.2020998694466,
            "rating_q025": 1206.059934121025
        },
        "nemotron-4-340b-instruct": {
            "rating": 1216.4870620502902,
            "rating_q975": 1227.4693106198226,
            "rating_q025": 1205.504813480758
        },
        "command-r-plus-08-2024": {
            "rating": 1214.7813831883877,
            "rating_q975": 1227.9234617148068,
            "rating_q025": 1201.6393046619685
        },
        "phi-4": {
            "rating": 1207.2929622649117,
            "rating_q975": 1217.139920532585,
            "rating_q025": 1197.4460039972382
        },
        "gpt-4-0314": {
            "rating": 1206.6765095573946,
            "rating_q975": 1216.0174819330746,
            "rating_q025": 1197.335537181715
        },
        "amazon-nova-lite-v1.0": {
            "rating": 1200.9464269346583,
            "rating_q975": 1211.0184013910027,
            "rating_q025": 1190.874452478314
        },
        "qwen2-72b-instruct": {
            "rating": 1196.7427514401081,
            "rating_q975": 1205.3604198728058,
            "rating_q025": 1188.1250830074102
        },
        "gemma-2-9b-it": {
            "rating": 1195.860582097099,
            "rating_q975": 1202.471640550631,
            "rating_q025": 1189.249523643567
        },
        "command-r-plus": {
            "rating": 1194.3390051441952,
            "rating_q975": 1202.2160172885892,
            "rating_q025": 1186.4619929998012
        },
        "claude-3-haiku-20240307": {
            "rating": 1191.8501363080131,
            "rating_q975": 1198.4132331817736,
            "rating_q025": 1185.2870394342528
        },
        "c4ai-aya-expanse-32b": {
            "rating": 1190.9949055599834,
            "rating_q975": 1199.5302874506074,
            "rating_q025": 1182.4595236693597
        },
        "reka-flash-20240904": {
            "rating": 1190.8673096654725,
            "rating_q975": 1206.351330530177,
            "rating_q025": 1175.3832888007678
        },
        "gemini-1.5-flash-8b-001": {
            "rating": 1188.1798922763091,
            "rating_q975": 1196.005134214616,
            "rating_q025": 1180.3546503380026
        },
        "gpt-4-0613": {
            "rating": 1185.1813150361113,
            "rating_q975": 1192.9474135319456,
            "rating_q025": 1177.415216540277
        },
        "amazon-nova-micro-v1.0": {
            "rating": 1181.6833511035752,
            "rating_q975": 1192.017613402485,
            "rating_q025": 1171.3490888046651
        },
        "deepseek-coder-v2": {
            "rating": 1179.5646339555424,
            "rating_q975": 1191.5389487919533,
            "rating_q025": 1167.5903191191314
        },
        "hunyuan-standard-256k": {
            "rating": 1177.6988276723014,
            "rating_q975": 1201.9296555003227,
            "rating_q025": 1153.4679998442798
        },
        "llama-3.1-8b-instruct": {
            "rating": 1174.0062516646717,
            "rating_q975": 1181.0534332668585,
            "rating_q025": 1166.9590700624851
        },
        "mistral-large-2402": {
            "rating": 1173.3031443588206,
            "rating_q975": 1181.9463983185858,
            "rating_q025": 1164.6598903990557
        },
        "ministral-8b-2410": {
            "rating": 1168.3800093089224,
            "rating_q975": 1186.908535610844,
            "rating_q025": 1149.851483007001
        },
        "command-r-08-2024": {
            "rating": 1165.3017761002716,
            "rating_q975": 1178.474940276042,
            "rating_q025": 1152.1286119245012
        },
        "qwen1.5-110b-chat": {
            "rating": 1163.0466940585316,
            "rating_q975": 1173.9751695642603,
            "rating_q025": 1152.1182185528025
        },
        "c4ai-aya-expanse-8b": {
            "rating": 1161.767412546305,
            "rating_q975": 1175.671644312541,
            "rating_q025": 1147.8631807800687
        },
        "qwen1.5-72b-chat": {
            "rating": 1161.0717171348253,
            "rating_q975": 1170.8835413297434,
            "rating_q025": 1151.2598929399073
        },
        "jamba-1.5-mini": {
            "rating": 1159.3342620125954,
            "rating_q975": 1173.4782909466985,
            "rating_q025": 1145.1902330784924
        },
        "llama-3.1-tulu-3-8b": {
            "rating": 1155.4184773737047,
            "rating_q975": 1180.4680933939626,
            "rating_q025": 1130.3688613534473
        },
        "yi-1.5-34b-chat": {
            "rating": 1155.0842650131535,
            "rating_q975": 1165.8250347304997,
            "rating_q025": 1144.3434952958075
        },
        "llama-3-8b-instruct": {
            "rating": 1154.1805278703198,
            "rating_q975": 1161.6781819912462,
            "rating_q025": 1146.6828737493934
        },
        "reka-flash-21b-20240226-online": {
            "rating": 1153.429454619004,
            "rating_q975": 1167.8393006648666,
            "rating_q025": 1139.0196085731413
        },
        "command-r": {
            "rating": 1150.297077658969,
            "rating_q975": 1159.190529798218,
            "rating_q025": 1141.4036255197202
        },
        "mistral-medium": {
            "rating": 1149.5132333636004,
            "rating_q975": 1160.3479673139059,
            "rating_q025": 1138.678499413295
        },
        "qwq-32b-preview": {
            "rating": 1148.2558086845795,
            "rating_q975": 1174.239857238408,
            "rating_q025": 1122.2717601307513
        },
        "gemini-pro": {
            "rating": 1146.2084524360992,
            "rating_q975": 1170.7737902552665,
            "rating_q025": 1121.6431146169318
        },
        "reka-flash-21b-20240226": {
            "rating": 1143.2541869644706,
            "rating_q975": 1154.7787804574282,
            "rating_q025": 1131.729593471513
        },
        "qwen1.5-32b-chat": {
            "rating": 1141.4026850273647,
            "rating_q975": 1153.2399817418602,
            "rating_q025": 1129.5653883128691
        },
        "internlm2_5-20b-chat": {
            "rating": 1138.4609504257064,
            "rating_q975": 1152.4872086892115,
            "rating_q025": 1124.4346921622014
        },
        "mixtral-8x22b-instruct-v0.1": {
            "rating": 1131.9708656795085,
            "rating_q975": 1140.3829551433614,
            "rating_q025": 1123.5587762156556
        },
        "gemini-pro-dev-api": {
            "rating": 1127.0258130561788,
            "rating_q975": 1141.1862107638976,
            "rating_q025": 1112.8654153484597
        },
        "gemma-2-2b-it": {
            "rating": 1121.1244627993456,
            "rating_q975": 1128.6137233002821,
            "rating_q025": 1113.6352022984088
        },
        "gpt-3.5-turbo-0125": {
            "rating": 1120.239635772585,
            "rating_q975": 1128.2686382123038,
            "rating_q025": 1112.2106333328663
        },
        "mixtral-8x7b-instruct-v0.1": {
            "rating": 1117.9221186844454,
            "rating_q975": 1125.945298737971,
            "rating_q025": 1109.89893863092
        },
        "yi-34b-chat": {
            "rating": 1114.8419427381843,
            "rating_q975": 1129.3034677621165,
            "rating_q025": 1100.3804177142524
        },
        "granite-3.1-8b-instruct": {
            "rating": 1114.1698853849912,
            "rating_q975": 1139.2727270389573,
            "rating_q025": 1089.0670437310248
        },
        "dbrx-instruct-preview": {
            "rating": 1113.9405578990525,
            "rating_q975": 1125.155712270777,
            "rating_q025": 1102.725403527328
        },
        "qwen1.5-14b-chat": {
            "rating": 1112.3718212721144,
            "rating_q975": 1126.2937097557863,
            "rating_q025": 1098.4499327884425
        },
        "starling-lm-7b-beta": {
            "rating": 1112.205581283053,
            "rating_q975": 1126.8988016706444,
            "rating_q025": 1097.5123608954618
        },
        "wizardlm-70b": {
            "rating": 1111.6921396442845,
            "rating_q975": 1130.8501677876177,
            "rating_q025": 1092.534111500951
        },
        "llama-3.2-3b-instruct": {
            "rating": 1109.2393558565439,
            "rating_q975": 1125.6172727991616,
            "rating_q025": 1092.861438913926
        },
        "granite-3.1-2b-instruct": {
            "rating": 1104.232324784942,
            "rating_q975": 1130.6634115425525,
            "rating_q025": 1077.8012380273317
        },
        "zephyr-orpo-141b-A35b-v0.1": {
            "rating": 1103.5754423092037,
            "rating_q975": 1127.5246736912952,
            "rating_q025": 1079.626210927112
        },
        "openchat-3.5-0106": {
            "rating": 1095.007267484386,
            "rating_q975": 1109.6561249774538,
            "rating_q025": 1080.3584099913182
        },
        "llama-2-70b-chat": {
            "rating": 1091.0710479343304,
            "rating_q975": 1101.097933710464,
            "rating_q025": 1081.0441621581967
        },
        "phi-3-medium-4k-instruct": {
            "rating": 1090.4195819530232,
            "rating_q975": 1100.8124776951677,
            "rating_q025": 1080.0266862108788
        },
        "starling-lm-7b-alpha": {
            "rating": 1088.455716430648,
            "rating_q975": 1105.6358290253158,
            "rating_q025": 1071.2756038359798
        },
        "tulu-2-dpo-70b": {
            "rating": 1088.1481512432797,
            "rating_q975": 1109.2791664306008,
            "rating_q025": 1067.0171360559586
        },
        "openchat-3.5": {
            "rating": 1088.0870274279946,
            "rating_q975": 1106.6245855294312,
            "rating_q025": 1069.549469326558
        },
        "nous-hermes-2-mixtral-8x7b-dpo": {
            "rating": 1084.4011075433882,
            "rating_q975": 1110.0435664617746,
            "rating_q025": 1058.758648625002
        },
        "deepseek-llm-67b-chat": {
            "rating": 1084.360814982725,
            "rating_q975": 1108.3829208947116,
            "rating_q025": 1060.3387090707383
        },
        "vicuna-33b": {
            "rating": 1082.9733344353854,
            "rating_q975": 1095.5790018627315,
            "rating_q025": 1070.3676670080395
        },
        "gpt-3.5-turbo-1106": {
            "rating": 1082.0220945165443,
            "rating_q975": 1097.6112825872851,
            "rating_q025": 1066.4329064458036
        },
        "snowflake-arctic-instruct": {
            "rating": 1075.6691178003357,
            "rating_q975": 1087.761284377995,
            "rating_q025": 1063.5769512226766
        },
        "phi-3-small-8k-instruct": {
            "rating": 1071.2269728740212,
            "rating_q975": 1082.9033029152633,
            "rating_q025": 1059.5506428327787
        },
        "mistral-7b-instruct-v0.2": {
            "rating": 1067.5722015151682,
            "rating_q975": 1080.249768499418,
            "rating_q025": 1054.8946345309184
        },
        "openhermes-2.5-mistral-7b": {
            "rating": 1066.894050192445,
            "rating_q975": 1089.3585168276566,
            "rating_q025": 1044.4295835572336
        },
        "granite-3.0-8b-instruct": {
            "rating": 1065.9696223636156,
            "rating_q975": 1085.3136976528863,
            "rating_q025": 1046.6255470743447
        },
        "llama2-70b-steerlm-chat": {
            "rating": 1065.2549106065435,
            "rating_q975": 1093.3695834350265,
            "rating_q025": 1037.1402377780605
        },
        "qwen1.5-7b-chat": {
            "rating": 1062.8288839333838,
            "rating_q975": 1087.6627674026217,
            "rating_q025": 1037.995000464146
        },
        "granite-3.0-2b-instruct": {
            "rating": 1060.7564401084705,
            "rating_q975": 1079.0690585829057,
            "rating_q025": 1042.4438216340354
        },
        "mpt-30b-chat": {
            "rating": 1057.5634204175817,
            "rating_q975": 1089.7132853248784,
            "rating_q025": 1025.4135555102846
        },
        "llama-2-13b-chat": {
            "rating": 1053.9096762882118,
            "rating_q975": 1067.4390242342906,
            "rating_q025": 1040.3803283421328
        },
        "phi-3-mini-4k-instruct-june-2024": {
            "rating": 1052.2533678544935,
            "rating_q975": 1066.4525531589743,
            "rating_q025": 1038.0541825500127
        },
        "solar-10.7b-instruct-v1.0": {
            "rating": 1048.6305060945992,
            "rating_q975": 1073.6602772356148,
            "rating_q025": 1023.6007349535835
        },
        "wizardlm-13b": {
            "rating": 1047.80348534611,
            "rating_q975": 1067.722627185562,
            "rating_q025": 1027.8843435066576
        },
        "gemma-1.1-7b-it": {
            "rating": 1043.1626170228183,
            "rating_q975": 1054.299290873673,
            "rating_q025": 1032.0259431719635
        },
        "zephyr-7b-beta": {
            "rating": 1039.7062400992459,
            "rating_q975": 1057.074718718054,
            "rating_q025": 1022.3377614804378
        },
        "llama-3.2-1b-instruct": {
            "rating": 1036.053516782128,
            "rating_q975": 1054.0320267100396,
            "rating_q025": 1018.0750068542166
        },
        "vicuna-13b": {
            "rating": 1033.2577644766563,
            "rating_q975": 1046.99176999642,
            "rating_q025": 1019.5237589568924
        },
        "llama-2-7b-chat": {
            "rating": 1031.1456163849061,
            "rating_q975": 1045.8529240383618,
            "rating_q025": 1016.4383087314505
        },
        "qwen-14b-chat": {
            "rating": 1024.1102676595146,
            "rating_q975": 1047.2423647162507,
            "rating_q025": 1000.9781706027786
        },
        "dolphin-2.2.1-mistral-7b": {
            "rating": 1023.1554596470985,
            "rating_q975": 1065.107138299197,
            "rating_q025": 981.203780995
        },
        "phi-3-mini-4k-instruct": {
            "rating": 1022.1937950936915,
            "rating_q975": 1035.0394728349188,
            "rating_q025": 1009.3481173524642
        },
        "zephyr-7b-alpha": {
            "rating": 1018.5386289535991,
            "rating_q975": 1053.585090849879,
            "rating_q025": 983.4921670573191
        },
        "codellama-34b-instruct": {
            "rating": 1018.2315442150477,
            "rating_q975": 1036.465882717272,
            "rating_q025": 999.9972057128233
        },
        "falcon-180b-chat": {
            "rating": 1017.5753958696221,
            "rating_q975": 1058.3275361668843,
            "rating_q025": 976.8232555723598
        },
        "stripedhyena-nous-7b": {
            "rating": 1013.5680992813814,
            "rating_q975": 1036.4142444858567,
            "rating_q025": 990.7219540769058
        },
        "mistral-7b-instruct": {
            "rating": 1012.456767711333,
            "rating_q975": 1031.5741423402796,
            "rating_q025": 993.3393930823863
        },
        "guanaco-33b": {
            "rating": 1010.0797445132005,
            "rating_q975": 1044.0167978431898,
            "rating_q025": 976.1426911832109
        },
        "olmo-7b-instruct": {
            "rating": 1009.4204478147806,
            "rating_q975": 1036.889278245269,
            "rating_q025": 981.9516173842923
        },
        "smollm2-1.7b-instruct": {
            "rating": 997.400997896317,
            "rating_q975": 1035.3675318091325,
            "rating_q025": 959.4344639835014
        },
        "palm-2": {
            "rating": 997.3822458161317,
            "rating_q975": 1016.9049529767228,
            "rating_q025": 977.8595386555405
        },
        "phi-3-mini-128k-instruct": {
            "rating": 993.6096442163366,
            "rating_q975": 1008.7456961465762,
            "rating_q025": 978.4735922860973
        },
        "vicuna-7b": {
            "rating": 992.1166211111645,
            "rating_q975": 1013.0869424897983,
            "rating_q025": 971.1462997325307
        },
        "qwen1.5-4b-chat": {
            "rating": 979.7414574194446,
            "rating_q975": 998.3282870956564,
            "rating_q025": 961.1546277432328
        },
        "gemma-7b-it": {
            "rating": 969.1039498649382,
            "rating_q975": 987.5119792824669,
            "rating_q025": 950.6959204474094
        },
        "chatglm3-6b": {
            "rating": 967.2648299740691,
            "rating_q975": 992.8929023220645,
            "rating_q025": 941.6367576260739
        },
        "gemma-1.1-2b-it": {
            "rating": 963.4315711166514,
            "rating_q975": 980.8648865820894,
            "rating_q025": 945.9982556512135
        },
        "gemma-2b-it": {
            "rating": 945.9988594950686,
            "rating_q975": 969.3287645292235,
            "rating_q025": 922.6689544609137
        },
        "gpt4all-13b-snoozy": {
            "rating": 926.664660742953,
            "rating_q975": 965.4802195111658,
            "rating_q025": 887.84910197474
        },
        "koala-13b": {
            "rating": 924.8273741036246,
            "rating_q975": 949.2097397296351,
            "rating_q025": 900.4450084776142
        },
        "chatglm2-6b": {
            "rating": 907.5327693531241,
            "rating_q975": 939.974136530829,
            "rating_q025": 875.0914021754191
        },
        "mpt-7b-chat": {
            "rating": 904.0970897968468,
            "rating_q975": 933.2696221389915,
            "rating_q025": 874.9245574547023
        },
        "RWKV-4-Raven-14B": {
            "rating": 897.496551591937,
            "rating_q975": 924.8854621051225,
            "rating_q025": 870.1076410787514
        },
        "alpaca-13b": {
            "rating": 888.3455037866163,
            "rating_q975": 914.2131612059502,
            "rating_q025": 862.4778463672824
        },
        "oasst-pythia-12b": {
            "rating": 872.5388586744298,
            "rating_q975": 898.0743922148156,
            "rating_q025": 847.003325134044
        },
        "chatglm-6b": {
            "rating": 859.3713238502148,
            "rating_q975": 888.8693686754538,
            "rating_q025": 829.873279024976
        },
        "fastchat-t5-3b": {
            "rating": 855.9621365915116,
            "rating_q975": 886.3870363885565,
            "rating_q025": 825.5372367944667
        },
        "stablelm-tuned-alpha-7b": {
            "rating": 825.0766465962355,
            "rating_q975": 859.5896628514504,
            "rating_q025": 790.5636303410206
        },
        "llama-13b": {
            "rating": 757.3296625326453,
            "rating_q975": 800.0787758761551,
            "rating_q025": 714.5805491891356
        },
        "dolly-v2-12b": {
            "rating": 743.1098244849925,
            "rating_q975": 779.0565478253332,
            "rating_q025": 707.1631011446518
        }
    },
    "no_refusal": {
        "gemini-2.5-pro": {
            "rating": 1465.3114476301384,
            "rating_q975": 1470.0747281918666,
            "rating_q025": 1460.5481670684105
        },
        "mistral-medium-2508": {
            "rating": 1432.8964711805772,
            "rating_q975": 1440.2097661592686,
            "rating_q025": 1425.5831762018859
        },
        "grok-4-0709": {
            "rating": 1430.229811288049,
            "rating_q975": 1435.7023885570366,
            "rating_q025": 1424.7572340190611
        },
        "chatgpt-4o-latest-20250326": {
            "rating": 1429.6775723832795,
            "rating_q975": 1434.018278558643,
            "rating_q025": 1425.3368662079158
        },
        "qwen-max-2025-08-15": {
            "rating": 1427.8959610424026,
            "rating_q975": 1436.1544580564275,
            "rating_q025": 1419.6374640283777
        },
        "glm-4.5": {
            "rating": 1427.7869767083353,
            "rating_q975": 1433.9566868966965,
            "rating_q025": 1421.6172665199742
        },
        "deepseek-r1-0528": {
            "rating": 1423.3653933146552,
            "rating_q975": 1428.8257616182677,
            "rating_q025": 1417.9050250110427
        },
        "grok-3-preview-02-24": {
            "rating": 1421.9139315318723,
            "rating_q975": 1426.0202377829337,
            "rating_q025": 1417.807625280811
        },
        "o3-2025-04-16": {
            "rating": 1420.8667956481554,
            "rating_q975": 1425.2150472675546,
            "rating_q025": 1416.518544028756
        },
        "gpt-5-high": {
            "rating": 1419.6401003075828,
            "rating_q975": 1426.0846309876051,
            "rating_q025": 1413.1955696275604
        },
        "deepseek-v3.1": {
            "rating": 1417.46708981566,
            "rating_q975": 1426.0350464062658,
            "rating_q025": 1408.8991332250544
        },
        "gpt-4.5-preview-2025-02-27": {
            "rating": 1417.0912140341206,
            "rating_q975": 1422.5869686076433,
            "rating_q025": 1411.595459460598
        },
        "qwen3-235b-a22b-instruct-2507": {
            "rating": 1416.7137898056894,
            "rating_q975": 1422.5306802143355,
            "rating_q025": 1410.8968993970434
        },
        "claude-opus-4-1-20250805-thinking-16k": {
            "rating": 1415.3649802073926,
            "rating_q975": 1422.1785287127611,
            "rating_q025": 1408.5514317020243
        },
        "qwen3-235b-a22b-thinking-2507": {
            "rating": 1414.7295880720883,
            "rating_q975": 1421.3932605103982,
            "rating_q025": 1408.0659156337786
        },
        "deepseek-v3.1-thinking": {
            "rating": 1411.477408766218,
            "rating_q975": 1420.577279520658,
            "rating_q025": 1402.3775380117781
        },
        "gemini-2.5-flash": {
            "rating": 1408.404936731669,
            "rating_q975": 1413.0279391432682,
            "rating_q025": 1403.78193432007
        },
        "gpt-5-chat": {
            "rating": 1407.9132459280454,
            "rating_q975": 1414.6697629792,
            "rating_q025": 1401.1567288768908
        },
        "claude-opus-4-1-20250805": {
            "rating": 1404.9827565777148,
            "rating_q975": 1411.3268304713372,
            "rating_q025": 1398.6386826840926
        },
        "gpt-5-old": {
            "rating": 1404.698946902703,
            "rating_q975": 1425.4990939769582,
            "rating_q025": 1383.898799828448
        },
        "mai-1-preview": {
            "rating": 1401.7057668419568,
            "rating_q975": 1410.4152029755064,
            "rating_q025": 1392.9963307084072
        },
        "hunyuan-t1-20250711": {
            "rating": 1399.0010046116001,
            "rating_q975": 1406.8486407243322,
            "rating_q025": 1391.153368498868
        },
        "qwen3-235b-a22b-no-thinking": {
            "rating": 1391.8233072103287,
            "rating_q975": 1396.791661362714,
            "rating_q025": 1386.8549530579437
        },
        "glm-4.5-air": {
            "rating": 1389.0426139762972,
            "rating_q975": 1395.2989020310124,
            "rating_q025": 1382.786325921582
        },
        "qwen3-30b-a3b-instruct-2507": {
            "rating": 1382.303469767102,
            "rating_q975": 1388.8885992136877,
            "rating_q025": 1375.7183403205163
        },
        "qwen-vl-max-2025-08-13": {
            "rating": 1381.4561565530926,
            "rating_q975": 1396.6112486538457,
            "rating_q025": 1366.3010644523392
        },
        "gpt-4.1-2025-04-14": {
            "rating": 1380.6646614953468,
            "rating_q975": 1385.343135331646,
            "rating_q025": 1375.9861876590476
        },
        "kimi-k2-0711-preview": {
            "rating": 1378.2394777444333,
            "rating_q975": 1383.5010366810027,
            "rating_q025": 1372.9779188078637
        },
        "gpt-5-mini-high": {
            "rating": 1376.749879671273,
            "rating_q975": 1384.1127950437967,
            "rating_q025": 1369.386964298749
        },
        "hunyuan-turbos-20250416": {
            "rating": 1376.4060467730985,
            "rating_q975": 1382.5711903374213,
            "rating_q025": 1370.240903208776
        },
        "deepseek-v3-0324": {
            "rating": 1375.9013546797048,
            "rating_q975": 1380.2531713740784,
            "rating_q025": 1371.5495379853312
        },
        "deepseek-r1": {
            "rating": 1372.7453885347988,
            "rating_q975": 1377.3978011221125,
            "rating_q025": 1368.092975947485
        },
        "claude-opus-4-20250514-thinking-16k": {
            "rating": 1370.5487107891609,
            "rating_q975": 1375.6392020141188,
            "rating_q025": 1365.4582195642026
        },
        "mistral-medium-2505": {
            "rating": 1369.8907617543532,
            "rating_q975": 1374.618376604942,
            "rating_q025": 1365.1631469037645
        },
        "qwen2.5-max": {
            "rating": 1367.1015555353554,
            "rating_q975": 1370.9898616824448,
            "rating_q025": 1363.213249388266
        },
        "qwen3-235b-a22b": {
            "rating": 1367.0376491523702,
            "rating_q975": 1371.822178275862,
            "rating_q025": 1362.2531200288786
        },
        "grok-3-mini-high": {
            "rating": 1366.3939211645393,
            "rating_q975": 1371.9724638819469,
            "rating_q025": 1360.815378447132
        },
        "o1-2024-12-17": {
            "rating": 1366.3579476501252,
            "rating_q975": 1370.61578511725,
            "rating_q025": 1362.1001101830007
        },
        "gpt-oss-120b": {
            "rating": 1365.285949065241,
            "rating_q975": 1372.2007416132678,
            "rating_q025": 1358.3711565172143
        },
        "grok-3-mini-beta": {
            "rating": 1364.3139943764438,
            "rating_q975": 1369.499695244056,
            "rating_q025": 1359.1282935088316
        },
        "claude-opus-4-20250514": {
            "rating": 1361.11225332813,
            "rating_q975": 1366.065194256271,
            "rating_q025": 1356.1593123999887
        },
        "o1-preview": {
            "rating": 1359.65679973182,
            "rating_q975": 1364.4152554745149,
            "rating_q025": 1354.898343989125
        },
        "o4-mini-2025-04-16": {
            "rating": 1358.5103147904974,
            "rating_q975": 1363.1682434249915,
            "rating_q025": 1353.8523861560034
        },
        "gemma-3-27b-it": {
            "rating": 1357.58656225511,
            "rating_q975": 1361.6687151857468,
            "rating_q025": 1353.504409324473
        },
        "step-3": {
            "rating": 1357.5220403618237,
            "rating_q975": 1367.7322971049316,
            "rating_q025": 1347.3117836187157
        },
        "gemini-2.0-flash-001": {
            "rating": 1357.3062990220735,
            "rating_q975": 1361.0351421126336,
            "rating_q025": 1353.5774559315134
        },
        "qwen3-coder-480b-a35b-instruct": {
            "rating": 1353.6351976022784,
            "rating_q975": 1359.5841555675365,
            "rating_q025": 1347.68623963702
        },
        "minimax-m1": {
            "rating": 1348.9534193508405,
            "rating_q975": 1354.0455105655637,
            "rating_q025": 1343.8613281361172
        },
        "claude-sonnet-4-20250514-thinking-32k": {
            "rating": 1346.7647827378516,
            "rating_q975": 1351.9213275476534,
            "rating_q025": 1341.60823792805
        },
        "qwen3-32b": {
            "rating": 1341.2474720697064,
            "rating_q975": 1350.523443113355,
            "rating_q025": 1331.971501026058
        },
        "gpt-4.1-mini-2025-04-14": {
            "rating": 1340.8479898025773,
            "rating_q975": 1345.5170363272225,
            "rating_q025": 1336.178943277932
        },
        "o3-mini-high": {
            "rating": 1340.4735239306253,
            "rating_q975": 1345.5479137446139,
            "rating_q025": 1335.3991341166368
        },
        "mistral-small-2506": {
            "rating": 1340.0744791097682,
            "rating_q975": 1345.5938821755087,
            "rating_q025": 1334.5550760440274
        },
        "nvidia-llama-3.3-nemotron-super-49b-v1.5": {
            "rating": 1338.5769036921397,
            "rating_q975": 1347.9338688592563,
            "rating_q025": 1329.2199385250233
        },
        "step-1o-turbo-202506": {
            "rating": 1337.9109294299953,
            "rating_q975": 1344.3622797299233,
            "rating_q025": 1331.4595791300671
        },
        "gemma-3-12b-it": {
            "rating": 1335.2522696075032,
            "rating_q975": 1344.5302887623743,
            "rating_q025": 1325.974250452632
        },
        "claude-sonnet-4-20250514": {
            "rating": 1332.5614410154449,
            "rating_q975": 1337.6101954029405,
            "rating_q025": 1327.5126866279493
        },
        "deepseek-v3": {
            "rating": 1332.3210109781942,
            "rating_q975": 1336.8316671110665,
            "rating_q025": 1327.8103548453219
        },
        "qwq-32b": {
            "rating": 1332.1151644263107,
            "rating_q975": 1336.6519214372124,
            "rating_q025": 1327.5784074154092
        },
        "gpt-5-nano-high": {
            "rating": 1331.9805135716304,
            "rating_q975": 1340.4708487102089,
            "rating_q025": 1323.4901784330516
        },
        "glm-4-plus-0111": {
            "rating": 1331.5547266966958,
            "rating_q975": 1339.7709740692167,
            "rating_q025": 1323.3384793241748
        },
        "gemini-2.0-flash-lite-preview-02-05": {
            "rating": 1330.3162647588033,
            "rating_q975": 1334.4328047311296,
            "rating_q025": 1326.199724786477
        },
        "qwen-plus-0125": {
            "rating": 1327.6170969964178,
            "rating_q975": 1335.860447636985,
            "rating_q025": 1319.3737463558502
        },
        "command-a-03-2025": {
            "rating": 1326.455412634096,
            "rating_q975": 1330.573004256681,
            "rating_q025": 1322.337821011511
        },
        "amazon-nova-experimental-chat-05-14": {
            "rating": 1325.480627924921,
            "rating_q975": 1330.6830754612054,
            "rating_q025": 1320.2781803886367
        },
        "glm-4.5v": {
            "rating": 1325.1620676163525,
            "rating_q975": 1341.3090912430391,
            "rating_q025": 1309.0150439896656
        },
        "o3-mini": {
            "rating": 1323.009642728099,
            "rating_q975": 1326.6391292818466,
            "rating_q025": 1319.3801561743512
        },
        "hunyuan-turbos-20250226": {
            "rating": 1322.6766967022197,
            "rating_q975": 1333.688917551635,
            "rating_q025": 1311.6644758528046
        },
        "step-2-16k-exp-202412": {
            "rating": 1321.8894425856502,
            "rating_q975": 1330.1902425115882,
            "rating_q025": 1313.5886426597124
        },
        "o1-mini": {
            "rating": 1321.6910750300744,
            "rating_q975": 1325.0196105675918,
            "rating_q025": 1318.3625394925573
        },
        "qwen3-30b-a3b": {
            "rating": 1320.6203205672955,
            "rating_q975": 1325.4547931620305,
            "rating_q025": 1315.7858479725608
        },
        "llama-3.1-nemotron-ultra-253b-v1": {
            "rating": 1320.4836892142052,
            "rating_q975": 1331.8932935687915,
            "rating_q025": 1309.074084859619
        },
        "gemini-1.5-pro-002": {
            "rating": 1319.5377795348575,
            "rating_q975": 1322.5922627144819,
            "rating_q025": 1316.4832963552333
        },
        "claude-3-7-sonnet-20250219-thinking-32k": {
            "rating": 1314.7317313184985,
            "rating_q975": 1318.9810001132903,
            "rating_q025": 1310.4824625237068
        },
        "hunyuan-turbo-0110": {
            "rating": 1313.1710434549364,
            "rating_q975": 1324.0760089006976,
            "rating_q025": 1302.2660780091753
        },
        "llama-3.3-nemotron-49b-super-v1": {
            "rating": 1310.4729015529535,
            "rating_q975": 1322.1115173483956,
            "rating_q025": 1298.8342857575112
        },
        "gemma-3n-e4b-it": {
            "rating": 1306.5946433128404,
            "rating_q975": 1312.0368193088395,
            "rating_q025": 1301.1524673168412
        },
        "gpt-oss-20b": {
            "rating": 1305.8864405591237,
            "rating_q975": 1313.0375006714821,
            "rating_q025": 1298.7353804467652
        },
        "grok-2-2024-08-13": {
            "rating": 1304.9666904604228,
            "rating_q975": 1308.279846410071,
            "rating_q025": 1301.6535345107745
        },
        "yi-lightning": {
            "rating": 1302.1882046181843,
            "rating_q975": 1306.7734791075795,
            "rating_q025": 1297.602930128789
        },
        "qwen2.5-plus-1127": {
            "rating": 1301.7736241765463,
            "rating_q975": 1307.852884318418,
            "rating_q025": 1295.6943640346747
        },
        "gpt-4o-2024-05-13": {
            "rating": 1301.5462900772825,
            "rating_q975": 1304.6374749276506,
            "rating_q025": 1298.4551052269144
        },
        "claude-3-5-sonnet-20241022": {
            "rating": 1300.1672667944663,
            "rating_q975": 1303.0862918427365,
            "rating_q025": 1297.248241746196
        },
        "claude-3-7-sonnet-20250219": {
            "rating": 1298.988092240261,
            "rating_q975": 1302.9154958259182,
            "rating_q025": 1295.060688654604
        },
        "deepseek-v2.5-1210": {
            "rating": 1296.1438707274247,
            "rating_q975": 1304.0323242153268,
            "rating_q025": 1288.2554172395223
        },
        "athene-v2-chat": {
            "rating": 1292.5928368437658,
            "rating_q975": 1296.8558406654647,
            "rating_q025": 1288.3298330220673
        },
        "gemma-3-4b-it": {
            "rating": 1292.5505433268072,
            "rating_q975": 1301.680485855333,
            "rating_q025": 1283.4206007982812
        },
        "hunyuan-large-2025-02-10": {
            "rating": 1292.1004038615727,
            "rating_q975": 1301.9164418159953,
            "rating_q025": 1282.28436590715
        },
        "glm-4-plus": {
            "rating": 1291.6933678868577,
            "rating_q975": 1296.3083828316783,
            "rating_q025": 1287.0783529420373
        },
        "gemini-1.5-flash-002": {
            "rating": 1289.1966349930203,
            "rating_q975": 1293.0893496721071,
            "rating_q025": 1285.3039203139338
        },
        "gpt-4o-mini-2024-07-18": {
            "rating": 1288.4172425665092,
            "rating_q975": 1291.6007681697058,
            "rating_q025": 1285.2337169633124
        },
        "gpt-4.1-nano-2025-04-14": {
            "rating": 1287.9163996156653,
            "rating_q975": 1295.5433263866487,
            "rating_q025": 1280.2894728446822
        },
        "llama-4-maverick-17b-128e-instruct": {
            "rating": 1286.704762170073,
            "rating_q975": 1291.3059326196696,
            "rating_q025": 1282.1035917204765
        },
        "claude-3-5-sonnet-20240620": {
            "rating": 1286.3172512546237,
            "rating_q975": 1289.4593189908335,
            "rating_q025": 1283.1751835184139
        },
        "gpt-4o-2024-08-06": {
            "rating": 1285.077636919587,
            "rating_q975": 1288.9430731133648,
            "rating_q025": 1281.212200725809
        },
        "qwen-max-0919": {
            "rating": 1284.8340663905685,
            "rating_q975": 1290.2197418240462,
            "rating_q025": 1279.448390957091
        },
        "llama-3.1-405b-instruct-bf16": {
            "rating": 1284.5715770905101,
            "rating_q975": 1287.9657082516221,
            "rating_q025": 1281.177445929398
        },
        "llama-3.1-nemotron-70b-instruct": {
            "rating": 1283.8429110319216,
            "rating_q975": 1291.2900369931103,
            "rating_q025": 1276.3957850707327
        },
        "llama-3.1-405b-instruct-fp8": {
            "rating": 1283.2138496789967,
            "rating_q975": 1286.4309329451985,
            "rating_q025": 1279.996766412795
        },
        "grok-2-mini-2024-08-13": {
            "rating": 1282.7781514796281,
            "rating_q975": 1286.1467304960029,
            "rating_q025": 1279.4095724632532
        },
        "llama-4-scout-17b-16e-instruct": {
            "rating": 1279.9673883331168,
            "rating_q975": 1285.2097949399842,
            "rating_q025": 1274.7249817262493
        },
        "gemini-advanced-0514": {
            "rating": 1278.6716803438044,
            "rating_q975": 1283.5852052800574,
            "rating_q025": 1273.7581554075516
        },
        "hunyuan-standard-2025-02-10": {
            "rating": 1278.2870712238803,
            "rating_q975": 1287.9390216055199,
            "rating_q025": 1268.6351208422407
        },
        "gemini-1.5-pro-001": {
            "rating": 1277.6312670727393,
            "rating_q975": 1281.309609271963,
            "rating_q025": 1273.9529248735155
        },
        "llama-3.3-70b-instruct": {
            "rating": 1276.9473239466377,
            "rating_q975": 1280.2779451142617,
            "rating_q025": 1273.6167027790136
        },
        "mistral-small-3.1-24b-instruct-2503": {
            "rating": 1276.7549316317748,
            "rating_q975": 1282.0918853864737,
            "rating_q025": 1271.4179778770758
        },
        "gpt-4-turbo-2024-04-09": {
            "rating": 1274.1419260363418,
            "rating_q975": 1277.7031645327656,
            "rating_q025": 1270.5806875399182
        },
        "deepseek-v2.5": {
            "rating": 1273.996021731356,
            "rating_q975": 1278.3517159476173,
            "rating_q025": 1269.6403275150947
        },
        "claude-3-opus-20240229": {
            "rating": 1272.865779994898,
            "rating_q975": 1275.600262035339,
            "rating_q025": 1270.131297954457
        },
        "qwen2.5-72b-instruct": {
            "rating": 1272.0981185005207,
            "rating_q975": 1275.85360520372,
            "rating_q025": 1268.3426317973215
        },
        "hunyuan-large-vision": {
            "rating": 1271.1718802433688,
            "rating_q975": 1280.1801310385156,
            "rating_q025": 1262.1636294482223
        },
        "mistral-large-2407": {
            "rating": 1268.461965723809,
            "rating_q975": 1272.0533688189075,
            "rating_q025": 1264.8705626287108
        },
        "gpt-4-1106-preview": {
            "rating": 1268.331770028136,
            "rating_q975": 1271.9282418758298,
            "rating_q025": 1264.735298180442
        },
        "mistral-large-2411": {
            "rating": 1268.0966116538543,
            "rating_q975": 1272.2807076513072,
            "rating_q025": 1263.9125156564014
        },
        "gpt-4-0125-preview": {
            "rating": 1267.6953159248403,
            "rating_q975": 1271.5070099761501,
            "rating_q025": 1263.8836218735303
        },
        "athene-70b-0725": {
            "rating": 1266.6947590137347,
            "rating_q975": 1272.0300140239126,
            "rating_q025": 1261.3595040035568
        },
        "llama-3.1-70b-instruct": {
            "rating": 1263.0806088475629,
            "rating_q975": 1266.438197401461,
            "rating_q025": 1259.7230202936646
        },
        "claude-3-5-haiku-20241022": {
            "rating": 1261.1946951108553,
            "rating_q975": 1264.4720452533343,
            "rating_q025": 1257.9173449683765
        },
        "amazon-nova-pro-v1.0": {
            "rating": 1261.1210134312569,
            "rating_q975": 1265.4174802034556,
            "rating_q025": 1256.824546659058
        },
        "llama-3.1-tulu-3-70b": {
            "rating": 1257.7769643190209,
            "rating_q975": 1268.006824675229,
            "rating_q025": 1247.5471039628128
        },
        "magistral-medium-2506": {
            "rating": 1253.4511657153153,
            "rating_q975": 1260.3489919149656,
            "rating_q025": 1246.5533395156647
        },
        "reka-core-20240904": {
            "rating": 1250.4805333356358,
            "rating_q975": 1257.10524725522,
            "rating_q025": 1243.8558194160512
        },
        "gemini-1.5-flash-001": {
            "rating": 1243.431238212613,
            "rating_q975": 1247.624455702287,
            "rating_q025": 1239.238020722939
        },
        "jamba-1.5-large": {
            "rating": 1240.0711732084712,
            "rating_q975": 1247.1256097055286,
            "rating_q025": 1233.016736711414
        },
        "mistral-small-24b-instruct-2501": {
            "rating": 1238.4712697112611,
            "rating_q975": 1244.159160159538,
            "rating_q025": 1232.7833792629842
        },
        "gemma-2-27b-it": {
            "rating": 1235.3618261130032,
            "rating_q975": 1238.4047473127998,
            "rating_q025": 1232.3189049132068
        },
        "command-r-plus-08-2024": {
            "rating": 1235.3412397814218,
            "rating_q975": 1241.6266900960507,
            "rating_q025": 1229.055789466793
        },
        "qwen2.5-coder-32b-instruct": {
            "rating": 1234.0742921521248,
            "rating_q975": 1241.8290157997196,
            "rating_q025": 1226.31956850453
        },
        "amazon-nova-lite-v1.0": {
            "rating": 1233.2115018501954,
            "rating_q975": 1238.0791895681086,
            "rating_q025": 1228.3438141322824
        },
        "gemini-1.5-flash-8b-001": {
            "rating": 1231.3212229772416,
            "rating_q975": 1235.28701051136,
            "rating_q025": 1227.3554354431233
        },
        "llama-3.1-nemotron-51b-instruct": {
            "rating": 1230.6068992830446,
            "rating_q975": 1240.3727371438047,
            "rating_q025": 1220.8410614222848
        },
        "gemma-2-9b-it-simpo": {
            "rating": 1230.590970069808,
            "rating_q975": 1237.206607449651,
            "rating_q025": 1223.9753326899652
        },
        "c4ai-aya-expanse-32b": {
            "rating": 1228.6745349881078,
            "rating_q975": 1233.2628050541884,
            "rating_q025": 1224.086264922027
        },
        "glm-4-0520": {
            "rating": 1228.4937509538956,
            "rating_q975": 1235.3005729308727,
            "rating_q025": 1221.6869289769186
        },
        "nemotron-4-340b-instruct": {
            "rating": 1228.121172762057,
            "rating_q975": 1233.2622757416402,
            "rating_q025": 1222.9800697824735
        },
        "claude-3-sonnet-20240229": {
            "rating": 1225.548735476851,
            "rating_q975": 1229.3288678895933,
            "rating_q025": 1221.7686030641087
        },
        "reka-flash-20240904": {
            "rating": 1222.9209829571378,
            "rating_q975": 1229.4307386471137,
            "rating_q025": 1216.4112272671616
        },
        "phi-4": {
            "rating": 1222.4231850867768,
            "rating_q975": 1226.8016282906435,
            "rating_q025": 1218.0447418829099
        },
        "llama-3-70b-instruct": {
            "rating": 1221.5643254268186,
            "rating_q975": 1224.8888789179468,
            "rating_q025": 1218.2397719356902
        },
        "olmo-2-0325-32b-instruct": {
            "rating": 1221.4609594728076,
            "rating_q975": 1232.1121315231335,
            "rating_q025": 1210.809787422482
        },
        "deepseek-coder-v2": {
            "rating": 1217.3807379997063,
            "rating_q975": 1223.7432496269005,
            "rating_q025": 1211.0182263725121
        },
        "amazon-nova-micro-v1.0": {
            "rating": 1213.798010639182,
            "rating_q975": 1218.6349211727768,
            "rating_q025": 1208.961100105587
        },
        "gemma-2-9b-it": {
            "rating": 1211.970253309913,
            "rating_q975": 1215.4566440876538,
            "rating_q025": 1208.483862532172
        },
        "hunyuan-standard-256k": {
            "rating": 1209.006403219023,
            "rating_q975": 1220.253438844603,
            "rating_q025": 1197.759367593443
        },
        "command-r-plus": {
            "rating": 1208.5980983247373,
            "rating_q975": 1212.7029195296425,
            "rating_q025": 1204.493277119832
        },
        "gpt-4-0314": {
            "rating": 1208.4099200243886,
            "rating_q975": 1213.0482169437746,
            "rating_q025": 1203.7716231050024
        },
        "qwen2-72b-instruct": {
            "rating": 1208.1419290219596,
            "rating_q975": 1212.8168382928434,
            "rating_q025": 1203.467019751076
        },
        "claude-3-haiku-20240307": {
            "rating": 1204.062176616565,
            "rating_q975": 1207.5224818151744,
            "rating_q025": 1200.6018714179556
        },
        "llama-3.1-tulu-3-8b": {
            "rating": 1198.8346539615359,
            "rating_q975": 1209.1295194700351,
            "rating_q025": 1188.5397884530364
        },
        "ministral-8b-2410": {
            "rating": 1196.958776329479,
            "rating_q975": 1205.6276365997962,
            "rating_q025": 1188.289916059162
        },
        "command-r-08-2024": {
            "rating": 1195.3452095800849,
            "rating_q975": 1201.5420085516726,
            "rating_q025": 1189.148410608497
        },
        "c4ai-aya-expanse-8b": {
            "rating": 1192.5790759843526,
            "rating_q975": 1199.2200603788358,
            "rating_q025": 1185.9380915898694
        },
        "jamba-1.5-mini": {
            "rating": 1192.2273291383744,
            "rating_q975": 1199.1542327028492,
            "rating_q025": 1185.3004255739
        },
        "gpt-4-0613": {
            "rating": 1191.799585500114,
            "rating_q975": 1195.6835205408413,
            "rating_q025": 1187.9156504593866
        },
        "llama-3.1-8b-instruct": {
            "rating": 1191.6369118241103,
            "rating_q975": 1195.3966786959172,
            "rating_q025": 1187.8771449523033
        },
        "mistral-large-2402": {
            "rating": 1178.8157036671992,
            "rating_q975": 1183.3589440762782,
            "rating_q025": 1174.27246325812
        },
        "qwen1.5-110b-chat": {
            "rating": 1178.4112497989634,
            "rating_q975": 1183.7527162690617,
            "rating_q025": 1173.0697833288652
        },
        "yi-1.5-34b-chat": {
            "rating": 1176.111549812705,
            "rating_q975": 1180.9503575989863,
            "rating_q025": 1171.2727420264237
        },
        "reka-flash-21b-20240226-online": {
            "rating": 1173.3328002011456,
            "rating_q975": 1180.5303289439876,
            "rating_q025": 1166.1352714583036
        },
        "qwq-32b-preview": {
            "rating": 1173.1141751837176,
            "rating_q975": 1184.3251674371486,
            "rating_q025": 1161.903182930287
        },
        "qwen1.5-72b-chat": {
            "rating": 1170.553818254684,
            "rating_q975": 1175.6501245407205,
            "rating_q025": 1165.4575119686476
        },
        "llama-3-8b-instruct": {
            "rating": 1168.3526637687646,
            "rating_q975": 1171.8208517905741,
            "rating_q025": 1164.8844757469549
        },
        "internlm2_5-20b-chat": {
            "rating": 1167.8742155720377,
            "rating_q975": 1174.6440149184511,
            "rating_q025": 1161.1044162256242
        },
        "reka-flash-21b-20240226": {
            "rating": 1167.8418938937282,
            "rating_q975": 1173.596060656577,
            "rating_q025": 1162.0877271308793
        },
        "command-r": {
            "rating": 1167.1804475097474,
            "rating_q975": 1171.7269793647658,
            "rating_q025": 1162.6339156547292
        },
        "mistral-medium": {
            "rating": 1166.828461410175,
            "rating_q975": 1172.1973307556568,
            "rating_q025": 1161.4595920646932
        },
        "mixtral-8x22b-instruct-v0.1": {
            "rating": 1164.9799515636955,
            "rating_q975": 1169.294077765157,
            "rating_q025": 1160.6658253622338
        },
        "gemma-2-2b-it": {
            "rating": 1162.1330966535636,
            "rating_q975": 1165.8689434537919,
            "rating_q025": 1158.3972498533353
        },
        "granite-3.1-8b-instruct": {
            "rating": 1157.0482018223702,
            "rating_q975": 1167.6373243808198,
            "rating_q025": 1146.4590792639206
        },
        "gemini-pro-dev-api": {
            "rating": 1152.3835504139865,
            "rating_q975": 1159.6432726378125,
            "rating_q025": 1145.1238281901606
        },
        "zephyr-orpo-141b-A35b-v0.1": {
            "rating": 1146.664763651265,
            "rating_q975": 1157.330971576301,
            "rating_q025": 1135.9985557262291
        },
        "qwen1.5-32b-chat": {
            "rating": 1142.369883691647,
            "rating_q975": 1148.31560321567,
            "rating_q025": 1136.424164167624
        },
        "phi-3-medium-4k-instruct": {
            "rating": 1142.3264688780769,
            "rating_q975": 1147.2209743224537,
            "rating_q025": 1137.4319634337
        },
        "gemini-pro": {
            "rating": 1136.6142197973654,
            "rating_q975": 1148.245760961818,
            "rating_q025": 1124.9826786329131
        },
        "starling-lm-7b-beta": {
            "rating": 1135.0463996350318,
            "rating_q975": 1142.240160011515,
            "rating_q025": 1127.8526392585486
        },
        "yi-34b-chat": {
            "rating": 1134.722641215107,
            "rating_q975": 1141.5157064209068,
            "rating_q025": 1127.9295760093073
        },
        "mixtral-8x7b-instruct-v0.1": {
            "rating": 1133.5987345570675,
            "rating_q975": 1137.6701500344514,
            "rating_q025": 1129.5273190796838
        },
        "granite-3.1-2b-instruct": {
            "rating": 1133.0481453416635,
            "rating_q975": 1143.787705068133,
            "rating_q025": 1122.308585615194
        },
        "qwen1.5-14b-chat": {
            "rating": 1132.9030253724313,
            "rating_q975": 1139.844464505233,
            "rating_q025": 1125.9615862396295
        },
        "gpt-3.5-turbo-0125": {
            "rating": 1132.502384263984,
            "rating_q975": 1137.0457900600777,
            "rating_q025": 1127.9589784678901
        },
        "dbrx-instruct-preview": {
            "rating": 1122.735109192681,
            "rating_q975": 1128.683612036457,
            "rating_q025": 1116.7866063489053
        },
        "tulu-2-dpo-70b": {
            "rating": 1122.6853975864888,
            "rating_q975": 1132.6245162667565,
            "rating_q025": 1112.7462789062208
        },
        "wizardlm-70b": {
            "rating": 1119.6644594058046,
            "rating_q975": 1129.1883495523634,
            "rating_q025": 1110.1405692592457
        },
        "llama-2-70b-chat": {
            "rating": 1118.815743240687,
            "rating_q975": 1124.2129785765233,
            "rating_q025": 1113.4185079048507
        },
        "llama-3.2-3b-instruct": {
            "rating": 1116.0287662145215,
            "rating_q975": 1123.3339089399653,
            "rating_q025": 1108.723623489078
        },
        "phi-3-small-8k-instruct": {
            "rating": 1115.6520691851156,
            "rating_q975": 1121.395027081369,
            "rating_q025": 1109.909111288862
        },
        "nous-hermes-2-mixtral-8x7b-dpo": {
            "rating": 1115.1599430764315,
            "rating_q975": 1127.1495191474232,
            "rating_q025": 1103.1703670054396
        },
        "gpt-3.5-turbo-1106": {
            "rating": 1111.6152217469746,
            "rating_q975": 1120.633156063219,
            "rating_q025": 1102.5972874307304
        },
        "openchat-3.5-0106": {
            "rating": 1109.0638153346074,
            "rating_q975": 1116.9494032645123,
            "rating_q025": 1101.1782274047025
        },
        "deepseek-llm-67b-chat": {
            "rating": 1107.6182016040968,
            "rating_q975": 1119.442346792273,
            "rating_q025": 1095.7940564159207
        },
        "starling-lm-7b-alpha": {
            "rating": 1106.2695087016136,
            "rating_q975": 1114.2624536242229,
            "rating_q025": 1098.2765637790042
        },
        "granite-3.0-8b-instruct": {
            "rating": 1105.9694915050673,
            "rating_q975": 1114.3016779365912,
            "rating_q025": 1097.6373050735433
        },
        "snowflake-arctic-instruct": {
            "rating": 1105.2873705521995,
            "rating_q975": 1111.0303180002302,
            "rating_q025": 1099.5444231041686
        },
        "vicuna-33b": {
            "rating": 1105.2335375486484,
            "rating_q975": 1111.3481723620166,
            "rating_q025": 1099.1189027352805
        },
        "gemma-1.1-7b-it": {
            "rating": 1099.3309279181026,
            "rating_q975": 1105.1414806334346,
            "rating_q025": 1093.5203752027705
        },
        "llama2-70b-steerlm-chat": {
            "rating": 1098.6210552734553,
            "rating_q975": 1111.397300932643,
            "rating_q025": 1085.8448096142677
        },
        "llama-2-13b-chat": {
            "rating": 1092.838669415663,
            "rating_q975": 1099.4428416227083,
            "rating_q025": 1086.2344972086175
        },
        "mistral-7b-instruct-v0.2": {
            "rating": 1092.1118559128577,
            "rating_q975": 1098.6551079493254,
            "rating_q025": 1085.5686038763897
        },
        "openchat-3.5": {
            "rating": 1091.9328740996712,
            "rating_q975": 1101.834726044572,
            "rating_q025": 1082.03102215477
        },
        "openhermes-2.5-mistral-7b": {
            "rating": 1091.819013032839,
            "rating_q975": 1102.3034566196134,
            "rating_q025": 1081.334569446064
        },
        "granite-3.0-2b-instruct": {
            "rating": 1088.3244931425763,
            "rating_q975": 1096.3396618072927,
            "rating_q025": 1080.30932447786
        },
        "phi-3-mini-4k-instruct-june-2024": {
            "rating": 1085.4346352224266,
            "rating_q975": 1091.6182075083566,
            "rating_q025": 1079.2510629364965
        },
        "qwen1.5-7b-chat": {
            "rating": 1084.9604772531613,
            "rating_q975": 1094.754041005971,
            "rating_q025": 1075.1669135003517
        },
        "solar-10.7b-instruct-v1.0": {
            "rating": 1083.7178569378848,
            "rating_q975": 1096.9676600367393,
            "rating_q025": 1070.4680538390303
        },
        "phi-3-mini-4k-instruct": {
            "rating": 1080.1991083089802,
            "rating_q975": 1086.374054444915,
            "rating_q025": 1074.0241621730454
        },
        "dolphin-2.2.1-mistral-7b": {
            "rating": 1079.4388954040696,
            "rating_q975": 1095.0834760147598,
            "rating_q025": 1063.7943147933797
        },
        "wizardlm-13b": {
            "rating": 1079.0307023289956,
            "rating_q975": 1088.57549531538,
            "rating_q025": 1069.4859093426112
        },
        "codellama-70b-instruct": {
            "rating": 1071.7775172092352,
            "rating_q975": 1090.4986231905186,
            "rating_q025": 1053.0564112279515
        },
        "codellama-34b-instruct": {
            "rating": 1068.752736228831,
            "rating_q975": 1077.7411948088188,
            "rating_q025": 1059.7642776488433
        },
        "zephyr-7b-beta": {
            "rating": 1067.5900239048826,
            "rating_q975": 1076.4971708979838,
            "rating_q025": 1058.6828769117815
        },
        "llama-3.2-1b-instruct": {
            "rating": 1065.6883595775148,
            "rating_q975": 1073.0592744763082,
            "rating_q025": 1058.3174446787214
        },
        "mpt-30b-chat": {
            "rating": 1065.397581458286,
            "rating_q975": 1077.977110651275,
            "rating_q025": 1052.8180522652965
        },
        "llama-2-7b-chat": {
            "rating": 1062.6643086857791,
            "rating_q975": 1069.686899528067,
            "rating_q025": 1055.6417178434913
        },
        "vicuna-13b": {
            "rating": 1062.294903411328,
            "rating_q975": 1068.9542637856862,
            "rating_q025": 1055.6355430369697
        },
        "smollm2-1.7b-instruct": {
            "rating": 1062.230799038017,
            "rating_q975": 1075.8467964803745,
            "rating_q025": 1048.6148015956596
        },
        "gemma-7b-it": {
            "rating": 1059.9415449736625,
            "rating_q975": 1069.5072022406046,
            "rating_q025": 1050.3758877067203
        },
        "guanaco-33b": {
            "rating": 1059.6449510639598,
            "rating_q975": 1072.3442634738735,
            "rating_q025": 1046.945638654046
        },
        "phi-3-mini-128k-instruct": {
            "rating": 1058.312081255922,
            "rating_q975": 1065.4279100021372,
            "rating_q025": 1051.196252509707
        },
        "qwen-14b-chat": {
            "rating": 1054.2143362733182,
            "rating_q975": 1065.49131979309,
            "rating_q025": 1042.9373527535463
        },
        "falcon-180b-chat": {
            "rating": 1053.158723438577,
            "rating_q975": 1071.2976765715343,
            "rating_q025": 1035.0197703056194
        },
        "zephyr-7b-alpha": {
            "rating": 1052.0197419140188,
            "rating_q975": 1068.402392645781,
            "rating_q025": 1035.6370911822567
        },
        "stripedhyena-nous-7b": {
            "rating": 1039.7944580907194,
            "rating_q975": 1051.0079130795086,
            "rating_q025": 1028.5810031019303
        },
        "vicuna-7b": {
            "rating": 1033.6775425010624,
            "rating_q975": 1043.119676404546,
            "rating_q025": 1024.2354085975787
        },
        "olmo-7b-instruct": {
            "rating": 1030.5122568873037,
            "rating_q975": 1041.757590982565,
            "rating_q025": 1019.2669227920424
        },
        "gemma-1.1-2b-it": {
            "rating": 1030.384478709027,
            "rating_q975": 1037.8972524647809,
            "rating_q025": 1022.8717049532729
        },
        "palm-2": {
            "rating": 1022.7761417811776,
            "rating_q975": 1032.353325604921,
            "rating_q025": 1013.198957957434
        },
        "mistral-7b-instruct": {
            "rating": 1017.8802587953994,
            "rating_q975": 1027.2850329168543,
            "rating_q025": 1008.4754846739445
        },
        "gemma-2b-it": {
            "rating": 1007.8115901879212,
            "rating_q975": 1019.5053888830483,
            "rating_q025": 996.1177914927939
        },
        "qwen1.5-4b-chat": {
            "rating": 1000.1217140435474,
            "rating_q975": 1009.4900603737194,
            "rating_q025": 990.7533677133755
        },
        "koala-13b": {
            "rating": 990.4823147683048,
            "rating_q975": 1001.0220967129706,
            "rating_q025": 979.9425328236391
        },
        "chatglm3-6b": {
            "rating": 968.5360520022567,
            "rating_q975": 980.7628551626303,
            "rating_q025": 956.3092488418831
        },
        "mpt-7b-chat": {
            "rating": 957.7998949128544,
            "rating_q975": 970.2222086682493,
            "rating_q025": 945.3775811574594
        },
        "gpt4all-13b-snoozy": {
            "rating": 954.5220097477609,
            "rating_q975": 970.6728317339193,
            "rating_q025": 938.3711877616024
        },
        "RWKV-4-Raven-14B": {
            "rating": 942.9632436712798,
            "rating_q975": 954.780088312621,
            "rating_q025": 931.1463990299384
        },
        "chatglm2-6b": {
            "rating": 930.5167128769751,
            "rating_q975": 945.06965988857,
            "rating_q025": 915.9637658653803
        },
        "alpaca-13b": {
            "rating": 923.2565178935813,
            "rating_q975": 935.0589949787634,
            "rating_q025": 911.4540408083992
        },
        "oasst-pythia-12b": {
            "rating": 909.7739289490162,
            "rating_q975": 921.1292480743555,
            "rating_q025": 898.4186098236767
        },
        "chatglm-6b": {
            "rating": 909.0537664566752,
            "rating_q975": 922.2200811737846,
            "rating_q025": 895.8874517395659
        },
        "fastchat-t5-3b": {
            "rating": 885.2203101700194,
            "rating_q975": 898.2406401354131,
            "rating_q025": 872.1999802046256
        },
        "stablelm-tuned-alpha-7b": {
            "rating": 859.4446660607182,
            "rating_q975": 873.1132914196877,
            "rating_q025": 845.7760407017488
        },
        "dolly-v2-12b": {
            "rating": 838.2490562526502,
            "rating_q975": 852.2472482770238,
            "rating_q025": 824.2508642282767
        },
        "llama-13b": {
            "rating": 823.1134269776703,
            "rating_q975": 839.6490884796801,
            "rating_q025": 806.5777654756604
        }
    },
    "no_short": {
        "gemini-2.5-pro": {
            "rating": 1467.3542139863328,
            "rating_q975": 1472.132488295756,
            "rating_q025": 1462.5759396769095
        },
        "mistral-medium-2508": {
            "rating": 1434.0417150850799,
            "rating_q975": 1441.403004739564,
            "rating_q025": 1426.6804254305955
        },
        "grok-4-0709": {
            "rating": 1430.9838847588785,
            "rating_q975": 1436.4632786007633,
            "rating_q025": 1425.5044909169937
        },
        "qwen-max-2025-08-15": {
            "rating": 1429.8615807065942,
            "rating_q975": 1438.124365073676,
            "rating_q025": 1421.5987963395125
        },
        "chatgpt-4o-latest-20250326": {
            "rating": 1429.2085329466854,
            "rating_q975": 1433.5530185075554,
            "rating_q025": 1424.8640473858159
        },
        "glm-4.5": {
            "rating": 1429.150441310014,
            "rating_q975": 1435.3472828367612,
            "rating_q025": 1422.9535997832668
        },
        "deepseek-r1-0528": {
            "rating": 1423.7254780469648,
            "rating_q975": 1429.1981931934843,
            "rating_q025": 1418.2527629004455
        },
        "grok-3-preview-02-24": {
            "rating": 1422.9361354693956,
            "rating_q975": 1427.0498911591594,
            "rating_q025": 1418.8223797796318
        },
        "o3-2025-04-16": {
            "rating": 1420.895466342005,
            "rating_q975": 1425.2567342842433,
            "rating_q025": 1416.5341983997664
        },
        "gpt-5-high": {
            "rating": 1420.7389828845812,
            "rating_q975": 1427.2206583231234,
            "rating_q025": 1414.257307446039
        },
        "deepseek-v3.1": {
            "rating": 1418.1892298025668,
            "rating_q975": 1426.7608371786894,
            "rating_q025": 1409.617622426444
        },
        "claude-opus-4-1-20250805-thinking-16k": {
            "rating": 1417.4751569851123,
            "rating_q975": 1424.31969202201,
            "rating_q025": 1410.6306219482149
        },
        "gpt-4.5-preview-2025-02-27": {
            "rating": 1416.224776107722,
            "rating_q975": 1421.720839376793,
            "rating_q025": 1410.7287128386506
        },
        "qwen3-235b-a22b-instruct-2507": {
            "rating": 1415.6768977221511,
            "rating_q975": 1421.4931120697306,
            "rating_q025": 1409.8606833745714
        },
        "qwen3-235b-a22b-thinking-2507": {
            "rating": 1414.7588476236403,
            "rating_q975": 1421.4430310367184,
            "rating_q025": 1408.0746642105626
        },
        "deepseek-v3.1-thinking": {
            "rating": 1411.9088349674862,
            "rating_q975": 1421.049807459391,
            "rating_q025": 1402.767862475581
        },
        "gemini-2.5-flash": {
            "rating": 1409.1270737149762,
            "rating_q975": 1413.760738229972,
            "rating_q025": 1404.4934091999805
        },
        "gpt-5-chat": {
            "rating": 1409.0714161420988,
            "rating_q975": 1415.8513433669305,
            "rating_q025": 1402.2914889172669
        },
        "gpt-5-old": {
            "rating": 1408.385884070098,
            "rating_q975": 1429.4116194511128,
            "rating_q025": 1387.3601486890832
        },
        "claude-opus-4-1-20250805": {
            "rating": 1407.2603480157725,
            "rating_q975": 1413.6347400181967,
            "rating_q025": 1400.8859560133483
        },
        "mai-1-preview": {
            "rating": 1401.7213884329071,
            "rating_q975": 1410.446596304231,
            "rating_q025": 1392.996180561583
        },
        "hunyuan-t1-20250711": {
            "rating": 1398.7681671565233,
            "rating_q975": 1406.6042162226172,
            "rating_q025": 1390.9321180904294
        },
        "qwen3-235b-a22b-no-thinking": {
            "rating": 1391.8278663771684,
            "rating_q975": 1396.7992654236496,
            "rating_q025": 1386.856467330687
        },
        "glm-4.5-air": {
            "rating": 1389.32671924898,
            "rating_q975": 1395.6052832231253,
            "rating_q025": 1383.0481552748347
        },
        "qwen-vl-max-2025-08-13": {
            "rating": 1382.4959556634271,
            "rating_q975": 1397.6631595333904,
            "rating_q025": 1367.3287517934637
        },
        "qwen3-30b-a3b-instruct-2507": {
            "rating": 1382.4720871434615,
            "rating_q975": 1389.0436397473047,
            "rating_q025": 1375.900534539618
        },
        "gpt-4.1-2025-04-14": {
            "rating": 1380.3112366274977,
            "rating_q975": 1384.985380267959,
            "rating_q025": 1375.6370929870363
        },
        "kimi-k2-0711-preview": {
            "rating": 1378.245633737766,
            "rating_q975": 1383.5343740646551,
            "rating_q025": 1372.956893410877
        },
        "hunyuan-turbos-20250416": {
            "rating": 1376.43438300116,
            "rating_q975": 1382.619133038568,
            "rating_q025": 1370.2496329637522
        },
        "deepseek-v3-0324": {
            "rating": 1375.7784523130924,
            "rating_q975": 1380.1354988901658,
            "rating_q025": 1371.4214057360193
        },
        "gpt-5-mini-high": {
            "rating": 1375.4388409110043,
            "rating_q975": 1382.8254147918458,
            "rating_q025": 1368.0522670301627
        },
        "deepseek-r1": {
            "rating": 1372.5886509951056,
            "rating_q975": 1377.2513769957393,
            "rating_q025": 1367.9259249944719
        },
        "claude-opus-4-20250514-thinking-16k": {
            "rating": 1371.982273727127,
            "rating_q975": 1377.0887608205064,
            "rating_q025": 1366.8757866337476
        },
        "mistral-medium-2505": {
            "rating": 1370.9893735488354,
            "rating_q975": 1375.7218868271952,
            "rating_q025": 1366.2568602704755
        },
        "qwen3-235b-a22b": {
            "rating": 1367.950297014842,
            "rating_q975": 1372.7502192925335,
            "rating_q025": 1363.15037473715
        },
        "o1-2024-12-17": {
            "rating": 1366.0674569773842,
            "rating_q975": 1370.3252590876891,
            "rating_q025": 1361.8096548670792
        },
        "grok-3-mini-high": {
            "rating": 1366.0319237604463,
            "rating_q975": 1371.5956075951146,
            "rating_q025": 1360.468239925778
        },
        "qwen2.5-max": {
            "rating": 1365.9857682775437,
            "rating_q975": 1369.8648403085667,
            "rating_q025": 1362.1066962465204
        },
        "grok-3-mini-beta": {
            "rating": 1365.0329407178506,
            "rating_q975": 1370.2225115710698,
            "rating_q025": 1359.8433698646313
        },
        "gpt-oss-120b": {
            "rating": 1364.7800651232094,
            "rating_q975": 1371.7164692968818,
            "rating_q025": 1357.8436609495373
        },
        "claude-opus-4-20250514": {
            "rating": 1361.8760393310267,
            "rating_q975": 1366.8410675771493,
            "rating_q025": 1356.9110110849042
        },
        "step-3": {
            "rating": 1358.9839060703514,
            "rating_q975": 1369.27679462663,
            "rating_q025": 1348.6910175140729
        },
        "o4-mini-2025-04-16": {
            "rating": 1358.045262272656,
            "rating_q975": 1362.7145888573607,
            "rating_q025": 1353.3759356879514
        },
        "gemini-2.0-flash-001": {
            "rating": 1357.802256291426,
            "rating_q975": 1361.5249067887187,
            "rating_q025": 1354.079605794133
        },
        "gemma-3-27b-it": {
            "rating": 1357.7326383433901,
            "rating_q975": 1361.8143160118993,
            "rating_q025": 1353.6509606748807
        },
        "qwen3-coder-480b-a35b-instruct": {
            "rating": 1353.0974063571625,
            "rating_q975": 1359.0507757399985,
            "rating_q025": 1347.1440369743268
        },
        "o1-preview": {
            "rating": 1353.0007683598144,
            "rating_q975": 1357.6778680801908,
            "rating_q025": 1348.3236686394378
        },
        "minimax-m1": {
            "rating": 1349.1809940472695,
            "rating_q975": 1354.2727443822348,
            "rating_q025": 1344.0892437123043
        },
        "claude-sonnet-4-20250514-thinking-32k": {
            "rating": 1348.2628560097137,
            "rating_q975": 1353.4252557381772,
            "rating_q025": 1343.1004562812502
        },
        "qwen3-32b": {
            "rating": 1342.084095229561,
            "rating_q975": 1351.3626800255472,
            "rating_q025": 1332.8055104335745
        },
        "gpt-4.1-mini-2025-04-14": {
            "rating": 1340.7470224276044,
            "rating_q975": 1345.4311592953036,
            "rating_q025": 1336.0628855599055
        },
        "mistral-small-2506": {
            "rating": 1339.6902914956838,
            "rating_q975": 1345.2290572923941,
            "rating_q025": 1334.1515256989733
        },
        "step-1o-turbo-202506": {
            "rating": 1338.55361809864,
            "rating_q975": 1345.0276490171937,
            "rating_q025": 1332.0795871800865
        },
        "o3-mini-high": {
            "rating": 1337.9076947656854,
            "rating_q975": 1342.9541315714428,
            "rating_q025": 1332.8612579599283
        },
        "nvidia-llama-3.3-nemotron-super-49b-v1.5": {
            "rating": 1337.8039930389828,
            "rating_q975": 1347.1714148190938,
            "rating_q025": 1328.436571258872
        },
        "gemma-3-12b-it": {
            "rating": 1335.293273078997,
            "rating_q975": 1344.587808945076,
            "rating_q025": 1325.998737212918
        },
        "claude-sonnet-4-20250514": {
            "rating": 1333.7952442862484,
            "rating_q975": 1338.8601627158419,
            "rating_q025": 1328.7303258566549
        },
        "deepseek-v3": {
            "rating": 1332.9801600020967,
            "rating_q975": 1337.4833840865324,
            "rating_q025": 1328.4769359176612
        },
        "qwq-32b": {
            "rating": 1332.482300575043,
            "rating_q975": 1337.014069941645,
            "rating_q025": 1327.9505312084407
        },
        "glm-4-plus-0111": {
            "rating": 1331.6237208916991,
            "rating_q975": 1339.8140061741417,
            "rating_q025": 1323.4334356092568
        },
        "gpt-5-nano-high": {
            "rating": 1331.3254036512292,
            "rating_q975": 1339.8535340103604,
            "rating_q025": 1322.7972732920982
        },
        "gemini-2.0-flash-lite-preview-02-05": {
            "rating": 1329.493488257155,
            "rating_q975": 1333.6089614068806,
            "rating_q025": 1325.3780151074293
        },
        "glm-4.5v": {
            "rating": 1328.0405157024893,
            "rating_q975": 1344.274560119935,
            "rating_q025": 1311.8064712850437
        },
        "qwen-plus-0125": {
            "rating": 1327.0041960188587,
            "rating_q975": 1335.1779368938726,
            "rating_q025": 1318.8304551438446
        },
        "command-a-03-2025": {
            "rating": 1326.6984723313662,
            "rating_q975": 1330.8241662853704,
            "rating_q025": 1322.5727783773618
        },
        "amazon-nova-experimental-chat-05-14": {
            "rating": 1326.616379568566,
            "rating_q975": 1331.8345146389333,
            "rating_q025": 1321.3982444981982
        },
        "o3-mini": {
            "rating": 1320.7759355603437,
            "rating_q975": 1324.3964196356956,
            "rating_q025": 1317.155451484992
        },
        "llama-3.1-nemotron-ultra-253b-v1": {
            "rating": 1320.337178475393,
            "rating_q975": 1331.739007806749,
            "rating_q025": 1308.9353491440372
        },
        "qwen3-30b-a3b": {
            "rating": 1320.0206192357743,
            "rating_q975": 1324.8672451022283,
            "rating_q025": 1315.1739933693204
        },
        "hunyuan-turbos-20250226": {
            "rating": 1319.9412032457635,
            "rating_q975": 1330.93047228725,
            "rating_q025": 1308.9519342042768
        },
        "step-2-16k-exp-202412": {
            "rating": 1319.676780910277,
            "rating_q975": 1327.9190895381353,
            "rating_q025": 1311.4344722824192
        },
        "gemini-1.5-pro-002": {
            "rating": 1319.35406050464,
            "rating_q975": 1322.4028476586998,
            "rating_q025": 1316.3052733505806
        },
        "o1-mini": {
            "rating": 1317.7265285969515,
            "rating_q975": 1321.032620540161,
            "rating_q025": 1314.4204366537422
        },
        "claude-3-7-sonnet-20250219-thinking-32k": {
            "rating": 1315.5433160581924,
            "rating_q975": 1319.8018949664215,
            "rating_q025": 1311.2847371499631
        },
        "hunyuan-turbo-0110": {
            "rating": 1314.1229624450475,
            "rating_q975": 1324.9366742495877,
            "rating_q025": 1303.3092506405073
        },
        "llama-3.3-nemotron-49b-super-v1": {
            "rating": 1311.1522367589057,
            "rating_q975": 1322.7042281034398,
            "rating_q025": 1299.6002454143716
        },
        "gemma-3n-e4b-it": {
            "rating": 1306.0370974481687,
            "rating_q975": 1311.4818702655139,
            "rating_q025": 1300.5923246308234
        },
        "grok-2-2024-08-13": {
            "rating": 1305.705758789479,
            "rating_q975": 1309.010077416081,
            "rating_q025": 1302.4014401628772
        },
        "gpt-oss-20b": {
            "rating": 1305.0799238182055,
            "rating_q975": 1312.2748763332806,
            "rating_q025": 1297.8849713031304
        },
        "yi-lightning": {
            "rating": 1303.0743355131704,
            "rating_q975": 1307.6443425085954,
            "rating_q025": 1298.5043285177453
        },
        "gpt-4o-2024-05-13": {
            "rating": 1301.9192286496327,
            "rating_q975": 1304.9884580315936,
            "rating_q025": 1298.849999267672
        },
        "claude-3-7-sonnet-20250219": {
            "rating": 1299.8572420031787,
            "rating_q975": 1303.7855234240183,
            "rating_q025": 1295.9289605823392
        },
        "qwen2.5-plus-1127": {
            "rating": 1299.5458825665205,
            "rating_q975": 1305.5961969589525,
            "rating_q025": 1293.4955681740885
        },
        "claude-3-5-sonnet-20241022": {
            "rating": 1298.7861887176648,
            "rating_q975": 1301.6827094255225,
            "rating_q025": 1295.889668009807
        },
        "deepseek-v2.5-1210": {
            "rating": 1294.6173965819225,
            "rating_q975": 1302.4633685520926,
            "rating_q025": 1286.7714246117523
        },
        "athene-v2-chat": {
            "rating": 1292.3390363827152,
            "rating_q975": 1296.5890907160478,
            "rating_q025": 1288.0889820493824
        },
        "glm-4-plus": {
            "rating": 1290.7318255384225,
            "rating_q975": 1295.3215379222427,
            "rating_q025": 1286.1421131546024
        },
        "gemma-3-4b-it": {
            "rating": 1290.5647677532215,
            "rating_q975": 1299.7247112883917,
            "rating_q025": 1281.4048242180513
        },
        "hunyuan-large-2025-02-10": {
            "rating": 1290.3608677210218,
            "rating_q975": 1300.0571103190287,
            "rating_q025": 1280.664625123015
        },
        "gemini-1.5-flash-002": {
            "rating": 1289.082528802419,
            "rating_q975": 1292.9599588314966,
            "rating_q025": 1285.205098773341
        },
        "gpt-4o-mini-2024-07-18": {
            "rating": 1287.2890526502442,
            "rating_q975": 1290.4576103564932,
            "rating_q025": 1284.1204949439955
        },
        "gpt-4.1-nano-2025-04-14": {
            "rating": 1286.8442856744975,
            "rating_q975": 1294.4790725327862,
            "rating_q025": 1279.209498816209
        },
        "llama-4-maverick-17b-128e-instruct": {
            "rating": 1286.7484573748832,
            "rating_q975": 1291.3573818904965,
            "rating_q025": 1282.1395328592698
        },
        "llama-3.1-405b-instruct-bf16": {
            "rating": 1284.8286320789962,
            "rating_q975": 1288.2225484466244,
            "rating_q025": 1281.4347157113682
        },
        "gpt-4o-2024-08-06": {
            "rating": 1284.523144049441,
            "rating_q975": 1288.3659898244375,
            "rating_q025": 1280.6802982744446
        },
        "qwen-max-0919": {
            "rating": 1284.1093640859035,
            "rating_q975": 1289.462058383469,
            "rating_q025": 1278.756669788338
        },
        "llama-3.1-nemotron-70b-instruct": {
            "rating": 1283.977396187746,
            "rating_q975": 1291.3942811397746,
            "rating_q025": 1276.5605112357175
        },
        "llama-3.1-405b-instruct-fp8": {
            "rating": 1283.566347765849,
            "rating_q975": 1286.766147271659,
            "rating_q025": 1280.366548260039
        },
        "grok-2-mini-2024-08-13": {
            "rating": 1282.4603695269627,
            "rating_q975": 1285.8148504349185,
            "rating_q025": 1279.105888619007
        },
        "claude-3-5-sonnet-20240620": {
            "rating": 1282.380125802199,
            "rating_q975": 1285.4458803505865,
            "rating_q025": 1279.3143712538117
        },
        "gemini-advanced-0514": {
            "rating": 1279.9048732310357,
            "rating_q975": 1284.811673037769,
            "rating_q025": 1274.9980734243022
        },
        "llama-4-scout-17b-16e-instruct": {
            "rating": 1279.4127017063197,
            "rating_q975": 1284.664132657802,
            "rating_q025": 1274.1612707548372
        },
        "mistral-small-3.1-24b-instruct-2503": {
            "rating": 1276.7567224854974,
            "rating_q975": 1282.090640771029,
            "rating_q025": 1271.4228041999656
        },
        "llama-3.3-70b-instruct": {
            "rating": 1276.6458858061128,
            "rating_q975": 1279.974903957721,
            "rating_q025": 1273.3168676545044
        },
        "hunyuan-standard-2025-02-10": {
            "rating": 1275.7718388806998,
            "rating_q975": 1285.3949666991016,
            "rating_q025": 1266.148711062298
        },
        "gemini-1.5-pro-001": {
            "rating": 1275.2080983401677,
            "rating_q975": 1278.8575404738597,
            "rating_q025": 1271.5586562064757
        },
        "gpt-4-turbo-2024-04-09": {
            "rating": 1274.4884508273694,
            "rating_q975": 1278.0358757929178,
            "rating_q025": 1270.9410258618216
        },
        "deepseek-v2.5": {
            "rating": 1273.4067794727873,
            "rating_q975": 1277.7247175130276,
            "rating_q025": 1269.088841432547
        },
        "qwen2.5-72b-instruct": {
            "rating": 1271.8586447738662,
            "rating_q975": 1275.5953844323294,
            "rating_q025": 1268.1219051154033
        },
        "hunyuan-large-vision": {
            "rating": 1268.8272257032459,
            "rating_q975": 1277.7466812964049,
            "rating_q025": 1259.9077701100869
        },
        "mistral-large-2407": {
            "rating": 1268.7835953807512,
            "rating_q975": 1272.3440304551034,
            "rating_q025": 1265.223160306399
        },
        "mistral-large-2411": {
            "rating": 1268.1399419083357,
            "rating_q975": 1272.3071343793722,
            "rating_q025": 1263.9727494372992
        },
        "athene-70b-0725": {
            "rating": 1266.5398970758351,
            "rating_q975": 1271.8401339709656,
            "rating_q025": 1261.239660180705
        },
        "gpt-4-1106-preview": {
            "rating": 1266.0751622983073,
            "rating_q975": 1269.622447090453,
            "rating_q025": 1262.5278775061615
        },
        "claude-3-opus-20240229": {
            "rating": 1264.8619550314697,
            "rating_q975": 1267.5190310201624,
            "rating_q025": 1262.2048790427768
        },
        "gpt-4-0125-preview": {
            "rating": 1264.7311732359804,
            "rating_q975": 1268.5123410229362,
            "rating_q025": 1260.9500054490243
        },
        "llama-3.1-70b-instruct": {
            "rating": 1263.5468130128345,
            "rating_q975": 1266.892104068007,
            "rating_q025": 1260.201521957662
        },
        "amazon-nova-pro-v1.0": {
            "rating": 1260.8050774802853,
            "rating_q975": 1265.0975449090372,
            "rating_q025": 1256.5126100515333
        },
        "llama-3.1-tulu-3-70b": {
            "rating": 1259.6672731959893,
            "rating_q975": 1269.7857104949335,
            "rating_q025": 1249.548835897045
        },
        "claude-3-5-haiku-20241022": {
            "rating": 1255.0754996589362,
            "rating_q975": 1258.2613307855481,
            "rating_q025": 1251.8896685323243
        },
        "magistral-medium-2506": {
            "rating": 1253.8706960577642,
            "rating_q975": 1260.773396352165,
            "rating_q025": 1246.9679957633637
        },
        "reka-core-20240904": {
            "rating": 1249.71705547914,
            "rating_q975": 1256.3360803478306,
            "rating_q025": 1243.0980306104498
        },
        "gemini-1.5-flash-001": {
            "rating": 1241.7833122768563,
            "rating_q975": 1245.9245815231702,
            "rating_q025": 1237.6420430305425
        },
        "jamba-1.5-large": {
            "rating": 1240.132788851778,
            "rating_q975": 1247.1219515692776,
            "rating_q025": 1233.1436261342787
        },
        "mistral-small-24b-instruct-2501": {
            "rating": 1237.1189988073506,
            "rating_q975": 1242.787113079127,
            "rating_q025": 1231.4508845355745
        },
        "gemma-2-27b-it": {
            "rating": 1234.579991086589,
            "rating_q975": 1237.5974883637302,
            "rating_q025": 1231.5624938094475
        },
        "qwen2.5-coder-32b-instruct": {
            "rating": 1233.6485037449074,
            "rating_q975": 1241.3576364273913,
            "rating_q025": 1225.9393710624236
        },
        "command-r-plus-08-2024": {
            "rating": 1232.6980708368087,
            "rating_q975": 1238.8828570342896,
            "rating_q025": 1226.5132846393276
        },
        "amazon-nova-lite-v1.0": {
            "rating": 1231.6838600305691,
            "rating_q975": 1236.5376366561204,
            "rating_q025": 1226.830083405018
        },
        "gemma-2-9b-it-simpo": {
            "rating": 1231.4241908436325,
            "rating_q975": 1237.9834571198019,
            "rating_q025": 1224.8649245674628
        },
        "llama-3.1-nemotron-51b-instruct": {
            "rating": 1230.6123900669272,
            "rating_q975": 1240.291656199367,
            "rating_q025": 1220.9331239344876
        },
        "glm-4-0520": {
            "rating": 1229.6504238644334,
            "rating_q975": 1236.3967742011803,
            "rating_q025": 1222.9040735276865
        },
        "gemini-1.5-flash-8b-001": {
            "rating": 1229.5792007407408,
            "rating_q975": 1233.5077315789706,
            "rating_q025": 1225.650669902511
        },
        "c4ai-aya-expanse-32b": {
            "rating": 1228.3417055452655,
            "rating_q975": 1232.896387921741,
            "rating_q025": 1223.7870231687898
        },
        "nemotron-4-340b-instruct": {
            "rating": 1228.169742162855,
            "rating_q975": 1233.2117700066808,
            "rating_q025": 1223.127714319029
        },
        "reka-flash-20240904": {
            "rating": 1223.184257355348,
            "rating_q975": 1229.6577904739438,
            "rating_q025": 1216.7107242367522
        },
        "llama-3-70b-instruct": {
            "rating": 1223.058518798076,
            "rating_q975": 1226.358193447631,
            "rating_q025": 1219.758844148521
        },
        "olmo-2-0325-32b-instruct": {
            "rating": 1222.0780053485566,
            "rating_q975": 1232.6504000922453,
            "rating_q025": 1211.5056106048678
        },
        "claude-3-sonnet-20240229": {
            "rating": 1221.7439847649484,
            "rating_q975": 1225.4798754715541,
            "rating_q025": 1218.008094058343
        },
        "phi-4": {
            "rating": 1220.7276101570328,
            "rating_q975": 1225.067775761226,
            "rating_q025": 1216.38744455284
        },
        "amazon-nova-micro-v1.0": {
            "rating": 1213.0479517845174,
            "rating_q975": 1217.8749102757483,
            "rating_q025": 1208.2209932932867
        },
        "gemma-2-9b-it": {
            "rating": 1211.1921969363698,
            "rating_q975": 1214.6585405097176,
            "rating_q025": 1207.7258533630218
        },
        "gpt-4-0314": {
            "rating": 1209.7120032082366,
            "rating_q975": 1214.3041868315897,
            "rating_q025": 1205.1198195848835
        },
        "hunyuan-standard-256k": {
            "rating": 1209.541689901862,
            "rating_q975": 1220.6706568639324,
            "rating_q025": 1198.4127229397916
        },
        "command-r-plus": {
            "rating": 1208.8067780193396,
            "rating_q975": 1212.8537414272782,
            "rating_q025": 1204.759814611401
        },
        "qwen2-72b-instruct": {
            "rating": 1206.8000158905375,
            "rating_q975": 1211.4387763749742,
            "rating_q025": 1202.161255406101
        },
        "llama-3.1-tulu-3-8b": {
            "rating": 1199.2115043314138,
            "rating_q975": 1209.368859416953,
            "rating_q025": 1189.0541492458747
        },
        "claude-3-haiku-20240307": {
            "rating": 1198.765586591348,
            "rating_q975": 1202.169079751936,
            "rating_q025": 1195.3620934307603
        },
        "ministral-8b-2410": {
            "rating": 1196.4250596344682,
            "rating_q975": 1205.057117712253,
            "rating_q025": 1187.7930015566833
        },
        "deepseek-coder-v2": {
            "rating": 1195.804157896835,
            "rating_q975": 1201.9280678008533,
            "rating_q025": 1189.680247992817
        },
        "command-r-08-2024": {
            "rating": 1194.011461421555,
            "rating_q975": 1200.1349755895974,
            "rating_q025": 1187.8879472535127
        },
        "c4ai-aya-expanse-8b": {
            "rating": 1192.262780885888,
            "rating_q975": 1198.8720312556923,
            "rating_q025": 1185.653530516084
        },
        "llama-3.1-8b-instruct": {
            "rating": 1191.5402271132875,
            "rating_q975": 1195.2837131164515,
            "rating_q025": 1187.7967411101233
        },
        "jamba-1.5-mini": {
            "rating": 1191.4143341679837,
            "rating_q975": 1198.2766132837085,
            "rating_q025": 1184.5520550522592
        },
        "gpt-4-0613": {
            "rating": 1190.7556431989951,
            "rating_q975": 1194.5696210974934,
            "rating_q025": 1186.9416653004967
        },
        "mistral-large-2402": {
            "rating": 1180.3539437560687,
            "rating_q975": 1184.8320866267973,
            "rating_q025": 1175.8758008853401
        },
        "qwen1.5-110b-chat": {
            "rating": 1178.8017033077076,
            "rating_q975": 1184.123975332069,
            "rating_q025": 1173.4794312833465
        },
        "yi-1.5-34b-chat": {
            "rating": 1176.2480155353662,
            "rating_q975": 1181.0320791813067,
            "rating_q025": 1171.4639518894257
        },
        "reka-flash-21b-20240226-online": {
            "rating": 1174.7481737156036,
            "rating_q975": 1181.9349145625597,
            "rating_q025": 1167.561432868648
        },
        "qwen1.5-72b-chat": {
            "rating": 1169.9363414154873,
            "rating_q975": 1174.9516480444245,
            "rating_q025": 1164.92103478655
        },
        "mistral-medium": {
            "rating": 1169.1809945746604,
            "rating_q975": 1174.4594881606547,
            "rating_q025": 1163.9025009886664
        },
        "qwq-32b-preview": {
            "rating": 1168.7522064312789,
            "rating_q975": 1179.7637550905354,
            "rating_q025": 1157.7406577720224
        },
        "llama-3-8b-instruct": {
            "rating": 1168.2365615233846,
            "rating_q975": 1171.6813231520616,
            "rating_q025": 1164.7917998947075
        },
        "reka-flash-21b-20240226": {
            "rating": 1168.0050563018794,
            "rating_q975": 1173.7225952913332,
            "rating_q025": 1162.287517312426
        },
        "command-r": {
            "rating": 1167.4422433682244,
            "rating_q975": 1171.9550528525842,
            "rating_q025": 1162.9294338838647
        },
        "mixtral-8x22b-instruct-v0.1": {
            "rating": 1166.946827143288,
            "rating_q975": 1171.210908292168,
            "rating_q025": 1162.6827459944082
        },
        "internlm2_5-20b-chat": {
            "rating": 1166.7462122523466,
            "rating_q975": 1173.4460959234625,
            "rating_q025": 1160.0463285812307
        },
        "gemma-2-2b-it": {
            "rating": 1161.3166210600373,
            "rating_q975": 1165.0313115458962,
            "rating_q025": 1157.6019305741786
        },
        "granite-3.1-8b-instruct": {
            "rating": 1155.0594805366318,
            "rating_q975": 1165.486254862914,
            "rating_q025": 1144.6327062103496
        },
        "gemini-pro-dev-api": {
            "rating": 1152.6633716144033,
            "rating_q975": 1159.7986215420729,
            "rating_q025": 1145.528121686734
        },
        "zephyr-orpo-141b-A35b-v0.1": {
            "rating": 1149.6391221022832,
            "rating_q975": 1160.273183342509,
            "rating_q025": 1139.0050608620572
        },
        "qwen1.5-32b-chat": {
            "rating": 1142.206982672906,
            "rating_q975": 1148.0994083348894,
            "rating_q025": 1136.3145570109223
        },
        "phi-3-medium-4k-instruct": {
            "rating": 1141.948798594376,
            "rating_q975": 1146.8048310385684,
            "rating_q025": 1137.0927661501837
        },
        "mixtral-8x7b-instruct-v0.1": {
            "rating": 1136.5180191382874,
            "rating_q975": 1140.5293958475256,
            "rating_q025": 1132.5066424290492
        },
        "starling-lm-7b-beta": {
            "rating": 1136.3363025505469,
            "rating_q975": 1143.5150422579836,
            "rating_q025": 1129.15756284311
        },
        "granite-3.1-2b-instruct": {
            "rating": 1135.1543884518235,
            "rating_q975": 1145.7718081637765,
            "rating_q025": 1124.5369687398704
        },
        "gemini-pro": {
            "rating": 1135.0095820639074,
            "rating_q975": 1146.482555530211,
            "rating_q025": 1123.5366085976038
        },
        "qwen1.5-14b-chat": {
            "rating": 1132.9687178671345,
            "rating_q975": 1139.8343286948416,
            "rating_q025": 1126.1031070394274
        },
        "yi-34b-chat": {
            "rating": 1132.958681823086,
            "rating_q975": 1139.6210562374756,
            "rating_q025": 1126.296307408696
        },
        "gpt-3.5-turbo-0125": {
            "rating": 1129.5325320926818,
            "rating_q975": 1133.9984783739978,
            "rating_q025": 1125.0665858113657
        },
        "tulu-2-dpo-70b": {
            "rating": 1125.3107053803892,
            "rating_q975": 1135.0492745995002,
            "rating_q025": 1115.572136161278
        },
        "dbrx-instruct-preview": {
            "rating": 1124.2917879903207,
            "rating_q975": 1130.1566439612934,
            "rating_q025": 1118.426932019348
        },
        "wizardlm-70b": {
            "rating": 1122.5734766672665,
            "rating_q975": 1131.9308515228247,
            "rating_q025": 1113.2161018117083
        },
        "llama-2-70b-chat": {
            "rating": 1120.1814670752942,
            "rating_q975": 1125.519530064321,
            "rating_q025": 1114.8434040862671
        },
        "nous-hermes-2-mixtral-8x7b-dpo": {
            "rating": 1116.7423556593558,
            "rating_q975": 1128.549475112298,
            "rating_q025": 1104.9352362064133
        },
        "phi-3-small-8k-instruct": {
            "rating": 1115.4425015244387,
            "rating_q975": 1121.0772466159247,
            "rating_q025": 1109.8077564329528
        },
        "llama-3.2-3b-instruct": {
            "rating": 1115.4220278609307,
            "rating_q975": 1122.6574191863522,
            "rating_q025": 1108.1866365355093
        },
        "starling-lm-7b-alpha": {
            "rating": 1112.1490446510206,
            "rating_q975": 1120.0450243425914,
            "rating_q025": 1104.25306495945
        },
        "openchat-3.5-0106": {
            "rating": 1110.3859449410159,
            "rating_q975": 1118.2030684363983,
            "rating_q025": 1102.5688214456334
        },
        "vicuna-33b": {
            "rating": 1109.5373539501488,
            "rating_q975": 1115.5655858735163,
            "rating_q025": 1103.5091220267816
        },
        "deepseek-llm-67b-chat": {
            "rating": 1108.0648509002272,
            "rating_q975": 1119.7116025765338,
            "rating_q025": 1096.41809922392
        },
        "granite-3.0-8b-instruct": {
            "rating": 1106.9611888765162,
            "rating_q975": 1115.1391447504554,
            "rating_q025": 1098.7832330025772
        },
        "snowflake-arctic-instruct": {
            "rating": 1105.3748064019699,
            "rating_q975": 1111.0872681557162,
            "rating_q025": 1099.6623446482236
        },
        "llama2-70b-steerlm-chat": {
            "rating": 1102.7744739551063,
            "rating_q975": 1115.3482911317878,
            "rating_q025": 1090.200656778425
        },
        "openchat-3.5": {
            "rating": 1100.2263152586786,
            "rating_q975": 1109.878495743864,
            "rating_q025": 1090.5741347734931
        },
        "gemma-1.1-7b-it": {
            "rating": 1098.1184291111745,
            "rating_q975": 1103.9348356416033,
            "rating_q025": 1092.3020225807454
        },
        "gpt-3.5-turbo-1106": {
            "rating": 1097.6575642611404,
            "rating_q975": 1106.3541581234165,
            "rating_q025": 1088.9609703988642
        },
        "openhermes-2.5-mistral-7b": {
            "rating": 1097.3713799038092,
            "rating_q975": 1107.7221741283586,
            "rating_q025": 1087.02058567926
        },
        "mistral-7b-instruct-v0.2": {
            "rating": 1093.5251824201173,
            "rating_q975": 1099.9719012197222,
            "rating_q025": 1087.0784636205121
        },
        "llama-2-13b-chat": {
            "rating": 1089.8875935030055,
            "rating_q975": 1096.4323463562891,
            "rating_q025": 1083.3428406497217
        },
        "solar-10.7b-instruct-v1.0": {
            "rating": 1089.5599708647546,
            "rating_q975": 1102.629875236565,
            "rating_q025": 1076.4900664929444
        },
        "granite-3.0-2b-instruct": {
            "rating": 1088.731413991176,
            "rating_q975": 1096.6016932970379,
            "rating_q025": 1080.8611346853143
        },
        "qwen1.5-7b-chat": {
            "rating": 1086.7998677500723,
            "rating_q975": 1096.4460677316497,
            "rating_q025": 1077.1536677684946
        },
        "dolphin-2.2.1-mistral-7b": {
            "rating": 1086.689605230874,
            "rating_q975": 1102.1867864823914,
            "rating_q025": 1071.1924239793561
        },
        "phi-3-mini-4k-instruct-june-2024": {
            "rating": 1086.1182628865502,
            "rating_q975": 1092.190524774466,
            "rating_q025": 1080.0460009986346
        },
        "wizardlm-13b": {
            "rating": 1081.137419105959,
            "rating_q975": 1090.4949774159552,
            "rating_q025": 1071.7798607959628
        },
        "phi-3-mini-4k-instruct": {
            "rating": 1079.1279840968346,
            "rating_q975": 1085.1929296168043,
            "rating_q025": 1073.0630385768648
        },
        "mpt-30b-chat": {
            "rating": 1072.519454165868,
            "rating_q975": 1084.7968987402646,
            "rating_q025": 1060.2420095914713
        },
        "zephyr-7b-beta": {
            "rating": 1072.3938085321804,
            "rating_q975": 1081.1351062006993,
            "rating_q025": 1063.6525108636615
        },
        "codellama-34b-instruct": {
            "rating": 1069.2692479392101,
            "rating_q975": 1078.0531788814856,
            "rating_q025": 1060.4853169969347
        },
        "llama-3.2-1b-instruct": {
            "rating": 1063.821981868383,
            "rating_q975": 1071.167000519415,
            "rating_q025": 1056.476963217351
        },
        "zephyr-7b-alpha": {
            "rating": 1062.8778037381164,
            "rating_q975": 1079.019320998203,
            "rating_q025": 1046.7362864780296
        },
        "vicuna-13b": {
            "rating": 1062.8766226490034,
            "rating_q975": 1069.4050859600643,
            "rating_q025": 1056.3481593379424
        },
        "codellama-70b-instruct": {
            "rating": 1062.7342079325665,
            "rating_q975": 1080.8408435405343,
            "rating_q025": 1044.6275723245988
        },
        "falcon-180b-chat": {
            "rating": 1059.908525404684,
            "rating_q975": 1077.2806279613335,
            "rating_q025": 1042.5364228480346
        },
        "gemma-7b-it": {
            "rating": 1059.498668053828,
            "rating_q975": 1068.9924436464253,
            "rating_q025": 1050.0048924612306
        },
        "smollm2-1.7b-instruct": {
            "rating": 1058.5692681342273,
            "rating_q975": 1072.0263432597267,
            "rating_q025": 1045.1121930087281
        },
        "guanaco-33b": {
            "rating": 1058.1699857405306,
            "rating_q975": 1070.332926942451,
            "rating_q025": 1046.00704453861
        },
        "llama-2-7b-chat": {
            "rating": 1057.7481870317135,
            "rating_q975": 1064.6172544616288,
            "rating_q025": 1050.8791196017983
        },
        "phi-3-mini-128k-instruct": {
            "rating": 1056.8601397107527,
            "rating_q975": 1063.9346081368403,
            "rating_q025": 1049.785671284665
        },
        "qwen-14b-chat": {
            "rating": 1054.4912453412549,
            "rating_q975": 1065.4333352912463,
            "rating_q025": 1043.5491553912634
        },
        "stripedhyena-nous-7b": {
            "rating": 1042.3706089956477,
            "rating_q975": 1053.344234908993,
            "rating_q025": 1031.3969830823025
        },
        "vicuna-7b": {
            "rating": 1035.8188441480463,
            "rating_q975": 1045.0635583874327,
            "rating_q025": 1026.57412990866
        },
        "olmo-7b-instruct": {
            "rating": 1034.2592176690341,
            "rating_q975": 1045.3470159762892,
            "rating_q025": 1023.1714193617788
        },
        "palm-2": {
            "rating": 1030.023404622776,
            "rating_q975": 1039.4093334700717,
            "rating_q025": 1020.6374757754802
        },
        "mistral-7b-instruct": {
            "rating": 1028.342982284134,
            "rating_q975": 1037.5457971553803,
            "rating_q025": 1019.1401674128876
        },
        "gemma-1.1-2b-it": {
            "rating": 1027.269255274252,
            "rating_q975": 1034.7958388683423,
            "rating_q025": 1019.7426716801613
        },
        "gemma-2b-it": {
            "rating": 1006.1826066182721,
            "rating_q975": 1017.770638267541,
            "rating_q025": 994.5945749690031
        },
        "qwen1.5-4b-chat": {
            "rating": 1001.4876842779111,
            "rating_q975": 1010.7001411350893,
            "rating_q025": 992.2752274207328
        },
        "koala-13b": {
            "rating": 992.1038669800989,
            "rating_q975": 1002.1514691147959,
            "rating_q025": 982.056264845402
        },
        "chatglm3-6b": {
            "rating": 974.3869439792618,
            "rating_q975": 986.0182797319112,
            "rating_q025": 962.7556082266124
        },
        "gpt4all-13b-snoozy": {
            "rating": 958.945297385895,
            "rating_q975": 974.4225331127911,
            "rating_q025": 943.4680616589987
        },
        "mpt-7b-chat": {
            "rating": 958.0829448290136,
            "rating_q975": 970.1067329391708,
            "rating_q025": 946.0591567188565
        },
        "RWKV-4-Raven-14B": {
            "rating": 950.9331634870181,
            "rating_q975": 962.422041906919,
            "rating_q025": 939.4442850671171
        },
        "chatglm2-6b": {
            "rating": 941.1993447308317,
            "rating_q975": 954.9336499907462,
            "rating_q025": 927.4650394709173
        },
        "alpaca-13b": {
            "rating": 931.926200414415,
            "rating_q975": 943.4159979404355,
            "rating_q025": 920.4364028883945
        },
        "oasst-pythia-12b": {
            "rating": 919.1398132559386,
            "rating_q975": 930.1665652126826,
            "rating_q025": 908.1130612991949
        },
        "chatglm-6b": {
            "rating": 919.0101074399577,
            "rating_q975": 931.7116500803552,
            "rating_q025": 906.3085647995601
        },
        "fastchat-t5-3b": {
            "rating": 896.155406713091,
            "rating_q975": 908.7927375810416,
            "rating_q025": 883.5180758451402
        },
        "stablelm-tuned-alpha-7b": {
            "rating": 867.6833335764894,
            "rating_q975": 880.7769996634627,
            "rating_q025": 854.5896674895163
        },
        "dolly-v2-12b": {
            "rating": 851.5928374468133,
            "rating_q975": 865.314354200432,
            "rating_q025": 837.8713206931948
        },
        "llama-13b": {
            "rating": 837.3975660109487,
            "rating_q975": 853.5322369869948,
            "rating_q025": 821.2628950349025
        }
    },
    "no_tie": {
        "gemini-2.5-pro": {
            "rating": 1473.7534370536318,
            "rating_q975": 1480.5802332246371,
            "rating_q025": 1466.926640882626
        },
        "mistral-medium-2508": {
            "rating": 1427.1419223593016,
            "rating_q975": 1437.4905303121463,
            "rating_q025": 1416.7933144064566
        },
        "chatgpt-4o-latest-20250326": {
            "rating": 1422.5721919439686,
            "rating_q975": 1428.7520938162563,
            "rating_q025": 1416.392290071681
        },
        "grok-4-0709": {
            "rating": 1422.3041948573837,
            "rating_q975": 1429.8936445357642,
            "rating_q025": 1414.714745179003
        },
        "qwen-max-2025-08-15": {
            "rating": 1422.2590079443942,
            "rating_q975": 1434.075879214687,
            "rating_q025": 1410.4421366741017
        },
        "glm-4.5": {
            "rating": 1422.1033659667826,
            "rating_q975": 1430.90659838376,
            "rating_q025": 1413.3001335498052
        },
        "deepseek-r1-0528": {
            "rating": 1416.6726135470421,
            "rating_q975": 1424.326392102943,
            "rating_q025": 1409.0188349911411
        },
        "grok-3-preview-02-24": {
            "rating": 1416.347186922114,
            "rating_q975": 1422.258736702751,
            "rating_q025": 1410.4356371414765
        },
        "gpt-4.5-preview-2025-02-27": {
            "rating": 1410.3348128153812,
            "rating_q975": 1418.7195560581056,
            "rating_q025": 1401.950069572657
        },
        "o3-2025-04-16": {
            "rating": 1408.5886884165475,
            "rating_q975": 1414.733520956705,
            "rating_q025": 1402.4438558763898
        },
        "gpt-5-high": {
            "rating": 1407.9028729970223,
            "rating_q975": 1416.6284086292126,
            "rating_q025": 1399.1773373648323
        },
        "deepseek-v3.1": {
            "rating": 1405.2331087662055,
            "rating_q975": 1417.5003129594522,
            "rating_q025": 1392.965904572959
        },
        "claude-opus-4-1-20250805-thinking-16k": {
            "rating": 1402.6243568942093,
            "rating_q975": 1412.14937516261,
            "rating_q025": 1393.0993386258085
        },
        "qwen3-235b-a22b-instruct-2507": {
            "rating": 1402.1824418994843,
            "rating_q975": 1410.5045260987797,
            "rating_q025": 1393.8603577001888
        },
        "qwen3-235b-a22b-thinking-2507": {
            "rating": 1401.8031851497237,
            "rating_q975": 1411.3401474319662,
            "rating_q025": 1392.2662228674815
        },
        "deepseek-v3.1-thinking": {
            "rating": 1398.3091626684281,
            "rating_q975": 1411.2598883433361,
            "rating_q025": 1385.35843699352
        },
        "gemini-2.5-flash": {
            "rating": 1392.7824537706283,
            "rating_q975": 1399.1938874871103,
            "rating_q025": 1386.3710200541466
        },
        "gpt-5-chat": {
            "rating": 1390.9574590266977,
            "rating_q975": 1400.4722546668577,
            "rating_q025": 1381.4426633865378
        },
        "claude-opus-4-1-20250805": {
            "rating": 1387.487964517924,
            "rating_q975": 1396.0852631837427,
            "rating_q025": 1378.8906658521053
        },
        "mai-1-preview": {
            "rating": 1385.9840689790135,
            "rating_q975": 1398.6616629605187,
            "rating_q025": 1373.3064749975083
        },
        "gpt-5-old": {
            "rating": 1385.352095332319,
            "rating_q975": 1413.5068610075105,
            "rating_q025": 1357.1973296571277
        },
        "hunyuan-t1-20250711": {
            "rating": 1378.3291008985186,
            "rating_q975": 1389.4726110613458,
            "rating_q025": 1367.1855907356912
        },
        "glm-4.5-air": {
            "rating": 1368.2671690038699,
            "rating_q975": 1377.2112364983202,
            "rating_q025": 1359.3231015094195
        },
        "qwen3-235b-a22b-no-thinking": {
            "rating": 1367.8172800196753,
            "rating_q975": 1374.6454427558963,
            "rating_q025": 1360.9891172834543
        },
        "qwen3-30b-a3b-instruct-2507": {
            "rating": 1353.4334705561164,
            "rating_q975": 1362.7861572272027,
            "rating_q025": 1344.08078388503
        },
        "gpt-4.1-2025-04-14": {
            "rating": 1352.4793228782542,
            "rating_q975": 1358.9525444188007,
            "rating_q025": 1346.0061013377074
        },
        "qwen-vl-max-2025-08-13": {
            "rating": 1350.9348930622523,
            "rating_q975": 1372.7471115482713,
            "rating_q025": 1329.1226745762333
        },
        "kimi-k2-0711-preview": {
            "rating": 1349.1696072006362,
            "rating_q975": 1356.418127392617,
            "rating_q025": 1341.9210870086556
        },
        "deepseek-v3-0324": {
            "rating": 1347.914538080454,
            "rating_q975": 1354.1437466764626,
            "rating_q025": 1341.6853294844452
        },
        "hunyuan-turbos-20250416": {
            "rating": 1347.0945994671065,
            "rating_q975": 1355.7946069691207,
            "rating_q025": 1338.394591965092
        },
        "gpt-5-mini-high": {
            "rating": 1346.393625161299,
            "rating_q975": 1356.5594652120835,
            "rating_q025": 1336.2277851105146
        },
        "deepseek-r1": {
            "rating": 1346.08123925059,
            "rating_q975": 1353.1527896767823,
            "rating_q025": 1339.0096888243975
        },
        "mistral-medium-2505": {
            "rating": 1339.9305298505856,
            "rating_q975": 1346.6518237826042,
            "rating_q025": 1333.2092359185667
        },
        "claude-opus-4-20250514-thinking-16k": {
            "rating": 1339.058228771608,
            "rating_q975": 1345.9219713021967,
            "rating_q025": 1332.1944862410187
        },
        "qwen2.5-max": {
            "rating": 1336.5973048168014,
            "rating_q975": 1342.4037465121517,
            "rating_q025": 1330.790863121451
        },
        "qwen3-235b-a22b": {
            "rating": 1334.1436232993385,
            "rating_q975": 1341.0229288517019,
            "rating_q025": 1327.2643177469752
        },
        "o1-2024-12-17": {
            "rating": 1333.1459787412796,
            "rating_q975": 1339.3934783882041,
            "rating_q025": 1326.8984790943548
        },
        "gpt-oss-120b": {
            "rating": 1331.7903787743362,
            "rating_q975": 1341.4815736494459,
            "rating_q025": 1322.0991838992268
        },
        "grok-3-mini-high": {
            "rating": 1330.4562681762188,
            "rating_q975": 1338.164927294782,
            "rating_q025": 1322.7476090576556
        },
        "grok-3-mini-beta": {
            "rating": 1329.620816962682,
            "rating_q975": 1336.842641831017,
            "rating_q025": 1322.398992094347
        },
        "claude-opus-4-20250514": {
            "rating": 1325.90281374917,
            "rating_q975": 1332.6238068718087,
            "rating_q025": 1319.1818206265316
        },
        "o4-mini-2025-04-16": {
            "rating": 1322.827207167244,
            "rating_q975": 1329.3713871806324,
            "rating_q025": 1316.283027153856
        },
        "step-3": {
            "rating": 1322.7550070127913,
            "rating_q975": 1337.493347800556,
            "rating_q025": 1308.016666225027
        },
        "gemini-2.0-flash-001": {
            "rating": 1322.438183740178,
            "rating_q975": 1327.8470998827245,
            "rating_q025": 1317.0292675976314
        },
        "gemma-3-27b-it": {
            "rating": 1322.1276206904558,
            "rating_q975": 1327.9925060754933,
            "rating_q025": 1316.2627353054181
        },
        "o1-preview": {
            "rating": 1316.2937270678647,
            "rating_q975": 1323.3723867700141,
            "rating_q025": 1309.2150673657152
        },
        "qwen3-coder-480b-a35b-instruct": {
            "rating": 1314.893147707353,
            "rating_q975": 1323.2637278965233,
            "rating_q025": 1306.5225675181825
        },
        "minimax-m1": {
            "rating": 1309.3009816492515,
            "rating_q975": 1316.416446649946,
            "rating_q025": 1302.185516648557
        },
        "claude-sonnet-4-20250514-thinking-32k": {
            "rating": 1305.6394124517785,
            "rating_q975": 1312.5216962090367,
            "rating_q025": 1298.7571286945206
        },
        "qwen3-32b": {
            "rating": 1297.9285779628099,
            "rating_q975": 1312.2346211472677,
            "rating_q025": 1283.6225347783518
        },
        "gpt-4.1-mini-2025-04-14": {
            "rating": 1296.288914457775,
            "rating_q975": 1302.8338631553722,
            "rating_q025": 1289.7439657601776
        },
        "mistral-small-2506": {
            "rating": 1295.4722542860154,
            "rating_q975": 1303.433953475898,
            "rating_q025": 1287.5105550961327
        },
        "nvidia-llama-3.3-nemotron-super-49b-v1.5": {
            "rating": 1292.4755892014393,
            "rating_q975": 1306.3488068652264,
            "rating_q025": 1278.6023715376523
        },
        "o3-mini-high": {
            "rating": 1292.2211945207919,
            "rating_q975": 1299.7887938368312,
            "rating_q025": 1284.6535952047525
        },
        "step-1o-turbo-202506": {
            "rating": 1291.944830157031,
            "rating_q975": 1301.060830667232,
            "rating_q025": 1282.82882964683
        },
        "gemma-3-12b-it": {
            "rating": 1289.5487592498334,
            "rating_q975": 1303.6539077680113,
            "rating_q025": 1275.4436107316553
        },
        "deepseek-v3": {
            "rating": 1289.49891884654,
            "rating_q975": 1296.5994498000357,
            "rating_q025": 1282.3983878930442
        },
        "claude-sonnet-4-20250514": {
            "rating": 1286.8682559815898,
            "rating_q975": 1293.6548623931878,
            "rating_q025": 1280.0816495699917
        },
        "gpt-5-nano-high": {
            "rating": 1284.6982289939651,
            "rating_q975": 1296.6981118369335,
            "rating_q025": 1272.698346150997
        },
        "glm-4-plus-0111": {
            "rating": 1284.0486663139056,
            "rating_q975": 1296.4719353384853,
            "rating_q025": 1271.6253972893257
        },
        "qwq-32b": {
            "rating": 1283.4217742105227,
            "rating_q975": 1290.244432220759,
            "rating_q025": 1276.5991162002863
        },
        "gemini-2.0-flash-lite-preview-02-05": {
            "rating": 1280.879926236662,
            "rating_q975": 1287.3397518009883,
            "rating_q025": 1274.4201006723354
        },
        "qwen-plus-0125": {
            "rating": 1279.308861903208,
            "rating_q975": 1291.9677796132555,
            "rating_q025": 1266.6499441931605
        },
        "glm-4.5v": {
            "rating": 1277.0359815974614,
            "rating_q975": 1300.5499011053355,
            "rating_q025": 1253.5220620895873
        },
        "command-a-03-2025": {
            "rating": 1275.1799388782756,
            "rating_q975": 1281.2690496819603,
            "rating_q025": 1269.0908280745912
        },
        "amazon-nova-experimental-chat-05-14": {
            "rating": 1273.1546332522191,
            "rating_q975": 1280.5795035957665,
            "rating_q025": 1265.729762908672
        },
        "step-2-16k-exp-202412": {
            "rating": 1270.7244923527528,
            "rating_q975": 1284.3652700602743,
            "rating_q025": 1257.083714645231
        },
        "o3-mini": {
            "rating": 1266.7995929663698,
            "rating_q975": 1271.9852974910216,
            "rating_q025": 1261.6138884417182
        },
        "gemini-1.5-pro-002": {
            "rating": 1266.0516556614077,
            "rating_q975": 1270.9304669765388,
            "rating_q025": 1261.1728443462766
        },
        "qwen3-30b-a3b": {
            "rating": 1264.9557610821832,
            "rating_q975": 1271.9358090240414,
            "rating_q025": 1257.9757131403248
        },
        "o1-mini": {
            "rating": 1263.552556916473,
            "rating_q975": 1268.6947825566178,
            "rating_q025": 1258.410331276328
        },
        "hunyuan-turbos-20250226": {
            "rating": 1263.363948845915,
            "rating_q975": 1282.3103062606135,
            "rating_q025": 1244.4175914312168
        },
        "llama-3.1-nemotron-ultra-253b-v1": {
            "rating": 1262.9333067284344,
            "rating_q975": 1280.2385732655541,
            "rating_q025": 1245.6280401913148
        },
        "claude-3-7-sonnet-20250219-thinking-32k": {
            "rating": 1261.5170274690888,
            "rating_q975": 1267.353421217098,
            "rating_q025": 1255.6806337210799
        },
        "llama-3.3-nemotron-49b-super-v1": {
            "rating": 1251.955727424974,
            "rating_q975": 1270.8808238292763,
            "rating_q025": 1233.0306310206713
        },
        "hunyuan-turbo-0110": {
            "rating": 1248.3424681859285,
            "rating_q975": 1267.3857980765938,
            "rating_q025": 1229.2991382952632
        },
        "gpt-oss-20b": {
            "rating": 1247.5604634846673,
            "rating_q975": 1257.6415177350332,
            "rating_q025": 1237.4794092343013
        },
        "gemma-3n-e4b-it": {
            "rating": 1245.6647104984993,
            "rating_q975": 1253.3010937476495,
            "rating_q025": 1238.0283272493493
        },
        "grok-2-2024-08-13": {
            "rating": 1244.163017942473,
            "rating_q975": 1249.3345608184309,
            "rating_q025": 1238.9914750665152
        },
        "yi-lightning": {
            "rating": 1242.2561328591512,
            "rating_q975": 1249.5497728212106,
            "rating_q025": 1234.9624928970916
        },
        "claude-3-7-sonnet-20250219": {
            "rating": 1239.8617712632608,
            "rating_q975": 1245.311400039981,
            "rating_q025": 1234.4121424865405
        },
        "gpt-4o-2024-05-13": {
            "rating": 1238.4279128007663,
            "rating_q975": 1243.4941179001432,
            "rating_q025": 1233.3617077013894
        },
        "qwen2.5-plus-1127": {
            "rating": 1235.7517345221959,
            "rating_q975": 1245.6379413547315,
            "rating_q025": 1225.8655276896604
        },
        "claude-3-5-sonnet-20241022": {
            "rating": 1235.2101648961832,
            "rating_q975": 1239.2833869427564,
            "rating_q025": 1231.13694284961
        },
        "deepseek-v2.5-1210": {
            "rating": 1229.08031074785,
            "rating_q975": 1241.9970396135723,
            "rating_q025": 1216.1635818821276
        },
        "athene-v2-chat": {
            "rating": 1224.7034101032018,
            "rating_q975": 1231.4910142201268,
            "rating_q025": 1217.915805986277
        },
        "gemma-3-4b-it": {
            "rating": 1221.6082708181825,
            "rating_q975": 1235.4302022714755,
            "rating_q025": 1207.7863393648897
        },
        "glm-4-plus": {
            "rating": 1221.500871697799,
            "rating_q975": 1228.8899649523962,
            "rating_q025": 1214.111778443202
        },
        "llama-4-maverick-17b-128e-instruct": {
            "rating": 1219.5185007183975,
            "rating_q975": 1226.1404420366703,
            "rating_q025": 1212.896559400125
        },
        "hunyuan-large-2025-02-10": {
            "rating": 1218.197054330969,
            "rating_q975": 1233.2511696204485,
            "rating_q025": 1203.142939041489
        },
        "gemini-1.5-flash-002": {
            "rating": 1217.036482300035,
            "rating_q975": 1223.2150404722497,
            "rating_q025": 1210.8579241278203
        },
        "gpt-4o-mini-2024-07-18": {
            "rating": 1216.8980174859537,
            "rating_q975": 1221.7734878178826,
            "rating_q025": 1212.0225471540248
        },
        "llama-3.1-405b-instruct-bf16": {
            "rating": 1213.8721773619268,
            "rating_q975": 1219.1421942709085,
            "rating_q025": 1208.602160452945
        },
        "gpt-4.1-nano-2025-04-14": {
            "rating": 1211.2644825005345,
            "rating_q975": 1223.3425542114928,
            "rating_q025": 1199.1864107895765
        },
        "llama-3.1-nemotron-70b-instruct": {
            "rating": 1211.1597948864105,
            "rating_q975": 1222.381566434376,
            "rating_q025": 1199.9380233384447
        },
        "llama-3.1-405b-instruct-fp8": {
            "rating": 1210.0131167881839,
            "rating_q975": 1215.3790149657839,
            "rating_q025": 1204.6472186105839
        },
        "gpt-4o-2024-08-06": {
            "rating": 1209.9013466294655,
            "rating_q975": 1216.04263317606,
            "rating_q025": 1203.760060082871
        },
        "grok-2-mini-2024-08-13": {
            "rating": 1209.2505051086082,
            "rating_q975": 1214.6633713251626,
            "rating_q025": 1203.8376388920535
        },
        "llama-4-scout-17b-16e-instruct": {
            "rating": 1206.8781772964671,
            "rating_q975": 1214.4814973688822,
            "rating_q025": 1199.2748572240519
        },
        "qwen-max-0919": {
            "rating": 1206.631211951657,
            "rating_q975": 1214.9908455077837,
            "rating_q025": 1198.2715783955302
        },
        "claude-3-5-sonnet-20240620": {
            "rating": 1206.0136473706473,
            "rating_q975": 1210.8451453228745,
            "rating_q025": 1201.1821494184198
        },
        "gemini-advanced-0514": {
            "rating": 1203.585123779697,
            "rating_q975": 1210.6823094542744,
            "rating_q025": 1196.4879381051196
        },
        "llama-3.3-70b-instruct": {
            "rating": 1200.8949646325382,
            "rating_q975": 1205.881634556658,
            "rating_q025": 1195.908294708419
        },
        "hunyuan-standard-2025-02-10": {
            "rating": 1200.3737691843285,
            "rating_q975": 1215.5608592727094,
            "rating_q025": 1185.1866790959473
        },
        "mistral-small-3.1-24b-instruct-2503": {
            "rating": 1199.919098836779,
            "rating_q975": 1207.657511641495,
            "rating_q025": 1192.180686032063
        },
        "gemini-1.5-pro-001": {
            "rating": 1196.1478722163392,
            "rating_q975": 1202.0582010272738,
            "rating_q025": 1190.237543405405
        },
        "deepseek-v2.5": {
            "rating": 1194.2955411900107,
            "rating_q975": 1201.5045261275568,
            "rating_q025": 1187.0865562524646
        },
        "hunyuan-large-vision": {
            "rating": 1193.4972334075555,
            "rating_q975": 1205.933995604941,
            "rating_q025": 1181.06047121017
        },
        "gpt-4-turbo-2024-04-09": {
            "rating": 1191.1991333675637,
            "rating_q975": 1196.7353640224762,
            "rating_q025": 1185.6629027126514
        },
        "qwen2.5-72b-instruct": {
            "rating": 1190.6156042867767,
            "rating_q975": 1196.6961773172425,
            "rating_q025": 1184.5350312563107
        },
        "athene-70b-0725": {
            "rating": 1188.4660180640549,
            "rating_q975": 1197.0008065164495,
            "rating_q025": 1179.9312296116605
        },
        "mistral-large-2407": {
            "rating": 1186.7701736722659,
            "rating_q975": 1192.5554463970884,
            "rating_q025": 1180.9849009474435
        },
        "mistral-large-2411": {
            "rating": 1180.2106339418424,
            "rating_q975": 1186.8074679806552,
            "rating_q025": 1173.6137999030298
        },
        "llama-3.1-70b-instruct": {
            "rating": 1178.0219689462483,
            "rating_q975": 1183.5279461447358,
            "rating_q025": 1172.5159917477608
        },
        "claude-3-opus-20240229": {
            "rating": 1175.423987240954,
            "rating_q975": 1179.7113315683998,
            "rating_q025": 1171.1366429135076
        },
        "gpt-4-1106-preview": {
            "rating": 1174.1992486605418,
            "rating_q975": 1179.8261372967972,
            "rating_q025": 1168.5723600242861
        },
        "magistral-medium-2506": {
            "rating": 1173.6565680809736,
            "rating_q975": 1183.4605786651703,
            "rating_q025": 1163.8525574967769
        },
        "gpt-4-0125-preview": {
            "rating": 1172.4128257711727,
            "rating_q975": 1178.2884068866194,
            "rating_q025": 1166.537244655726
        },
        "llama-3.1-tulu-3-70b": {
            "rating": 1170.833868370868,
            "rating_q975": 1188.217993916671,
            "rating_q025": 1153.449742825065
        },
        "amazon-nova-pro-v1.0": {
            "rating": 1169.8025490445707,
            "rating_q975": 1176.6685417253996,
            "rating_q025": 1162.936556363742
        },
        "claude-3-5-haiku-20241022": {
            "rating": 1168.6190209817075,
            "rating_q975": 1173.4185136117949,
            "rating_q025": 1163.8195283516202
        },
        "reka-core-20240904": {
            "rating": 1155.9315769514296,
            "rating_q975": 1167.3458063933524,
            "rating_q025": 1144.5173475095066
        },
        "gemini-1.5-flash-001": {
            "rating": 1143.0948669532722,
            "rating_q975": 1149.536621890684,
            "rating_q025": 1136.6531120158604
        },
        "jamba-1.5-large": {
            "rating": 1140.7970873162456,
            "rating_q975": 1151.842212070835,
            "rating_q025": 1129.751962561656
        },
        "mistral-small-24b-instruct-2501": {
            "rating": 1131.0752085429347,
            "rating_q975": 1140.1650590980123,
            "rating_q025": 1121.985357987857
        },
        "gemma-2-27b-it": {
            "rating": 1129.8813296166786,
            "rating_q975": 1134.6880305957989,
            "rating_q025": 1125.0746286375586
        },
        "qwen2.5-coder-32b-instruct": {
            "rating": 1126.8809560291188,
            "rating_q975": 1140.0328750387555,
            "rating_q025": 1113.7290370194821
        },
        "gemma-2-9b-it-simpo": {
            "rating": 1125.4588738481161,
            "rating_q975": 1135.9629123358466,
            "rating_q025": 1114.954835360386
        },
        "command-r-plus-08-2024": {
            "rating": 1125.2009029205356,
            "rating_q975": 1135.2999212300667,
            "rating_q025": 1115.1018846110042
        },
        "glm-4-0520": {
            "rating": 1125.0659488054891,
            "rating_q975": 1135.7365582928896,
            "rating_q025": 1114.3953393180886
        },
        "nemotron-4-340b-instruct": {
            "rating": 1123.0523902374885,
            "rating_q975": 1131.1530395537804,
            "rating_q025": 1114.9517409211965
        },
        "llama-3.1-nemotron-51b-instruct": {
            "rating": 1121.7804932876816,
            "rating_q975": 1137.6766684342176,
            "rating_q025": 1105.8843181411457
        },
        "amazon-nova-lite-v1.0": {
            "rating": 1121.2971193632884,
            "rating_q975": 1129.2608581089428,
            "rating_q025": 1113.3333806176338
        },
        "gemini-1.5-flash-8b-001": {
            "rating": 1119.7449140124575,
            "rating_q975": 1126.2026509046925,
            "rating_q025": 1113.2871771202226
        },
        "c4ai-aya-expanse-32b": {
            "rating": 1116.1937107698373,
            "rating_q975": 1123.7362544274322,
            "rating_q025": 1108.651167112242
        },
        "llama-3-70b-instruct": {
            "rating": 1115.5006443683333,
            "rating_q975": 1120.7743537900658,
            "rating_q025": 1110.2269349466007
        },
        "claude-3-sonnet-20240229": {
            "rating": 1109.2576558063329,
            "rating_q975": 1114.8345867902417,
            "rating_q025": 1103.6807248224238
        },
        "olmo-2-0325-32b-instruct": {
            "rating": 1109.1344405124808,
            "rating_q975": 1126.315165227741,
            "rating_q025": 1091.9537157972204
        },
        "reka-flash-20240904": {
            "rating": 1105.7980579618747,
            "rating_q975": 1117.4994054759857,
            "rating_q025": 1094.0967104477636
        },
        "phi-4": {
            "rating": 1102.4593508607622,
            "rating_q975": 1109.9777468475895,
            "rating_q025": 1094.9409548739352
        },
        "command-r-plus": {
            "rating": 1092.5250164942004,
            "rating_q975": 1098.5818483436567,
            "rating_q025": 1086.4681846447438
        },
        "gemma-2-9b-it": {
            "rating": 1091.6042028613108,
            "rating_q975": 1097.1445823860108,
            "rating_q025": 1086.0638233366108
        },
        "qwen2-72b-instruct": {
            "rating": 1087.8399876503454,
            "rating_q975": 1094.9351578768078,
            "rating_q025": 1080.7448174238834
        },
        "amazon-nova-micro-v1.0": {
            "rating": 1086.783656340028,
            "rating_q975": 1094.948761006787,
            "rating_q025": 1078.6185516732692
        },
        "gpt-4-0314": {
            "rating": 1085.8750452090349,
            "rating_q975": 1092.7324516103292,
            "rating_q025": 1079.0176388077407
        },
        "hunyuan-standard-256k": {
            "rating": 1082.2627806458922,
            "rating_q975": 1100.4652284509584,
            "rating_q025": 1064.060332840826
        },
        "claude-3-haiku-20240307": {
            "rating": 1076.4404653913575,
            "rating_q975": 1081.9486581574004,
            "rating_q025": 1070.9322726253145
        },
        "deepseek-coder-v2": {
            "rating": 1071.533047743465,
            "rating_q975": 1080.851968922231,
            "rating_q025": 1062.2141265646987
        },
        "ministral-8b-2410": {
            "rating": 1061.706820628941,
            "rating_q975": 1076.4821601030137,
            "rating_q025": 1046.9314811548682
        },
        "llama-3.1-tulu-3-8b": {
            "rating": 1061.320508973508,
            "rating_q975": 1080.1781068997432,
            "rating_q025": 1042.4629110472724
        },
        "jamba-1.5-mini": {
            "rating": 1059.6265944064562,
            "rating_q975": 1071.197517153923,
            "rating_q025": 1048.0556716589897
        },
        "gpt-4-0613": {
            "rating": 1059.568547111342,
            "rating_q975": 1065.2739536392583,
            "rating_q025": 1053.8631405834258
        },
        "command-r-08-2024": {
            "rating": 1059.5312078898369,
            "rating_q975": 1069.9114558407348,
            "rating_q025": 1049.150959938939
        },
        "c4ai-aya-expanse-8b": {
            "rating": 1057.418400597694,
            "rating_q975": 1068.796642700226,
            "rating_q025": 1046.0401584951624
        },
        "llama-3.1-8b-instruct": {
            "rating": 1056.477281906385,
            "rating_q975": 1062.7426867535282,
            "rating_q025": 1050.211877059242
        },
        "mistral-large-2402": {
            "rating": 1046.6921955215053,
            "rating_q975": 1053.3709390678507,
            "rating_q025": 1040.0134519751596
        },
        "qwen1.5-110b-chat": {
            "rating": 1045.5749462142576,
            "rating_q975": 1054.0046196297444,
            "rating_q025": 1037.1452727987707
        },
        "yi-1.5-34b-chat": {
            "rating": 1043.2629276553494,
            "rating_q975": 1051.2842740965552,
            "rating_q025": 1035.2415812141437
        },
        "reka-flash-21b-20240226-online": {
            "rating": 1042.2478610212847,
            "rating_q975": 1053.0649583231964,
            "rating_q025": 1031.4307637193729
        },
        "qwen1.5-72b-chat": {
            "rating": 1033.8360300240315,
            "rating_q975": 1041.5342807755064,
            "rating_q025": 1026.1377792725566
        },
        "reka-flash-21b-20240226": {
            "rating": 1033.4877548100374,
            "rating_q975": 1042.5512322354489,
            "rating_q025": 1024.4242773846258
        },
        "mistral-medium": {
            "rating": 1031.227345088714,
            "rating_q975": 1039.0418017843183,
            "rating_q025": 1023.4128883931096
        },
        "llama-3-8b-instruct": {
            "rating": 1031.0907831158183,
            "rating_q975": 1036.7964511092337,
            "rating_q025": 1025.3851151224028
        },
        "command-r": {
            "rating": 1029.9689541622863,
            "rating_q975": 1036.8558306315444,
            "rating_q025": 1023.0820776930282
        },
        "qwq-32b-preview": {
            "rating": 1027.18606689819,
            "rating_q975": 1045.239242216519,
            "rating_q025": 1009.1328915798609
        },
        "mixtral-8x22b-instruct-v0.1": {
            "rating": 1024.4778535795897,
            "rating_q975": 1031.1963418302753,
            "rating_q025": 1017.759365328904
        },
        "internlm2_5-20b-chat": {
            "rating": 1014.9231483101879,
            "rating_q975": 1026.8123860634441,
            "rating_q025": 1003.0339105569318
        },
        "gemini-pro-dev-api": {
            "rating": 1009.2116962302574,
            "rating_q975": 1019.5972625499381,
            "rating_q025": 998.8261299105767
        },
        "gemma-2-2b-it": {
            "rating": 1006.6729514737651,
            "rating_q975": 1013.0278394460219,
            "rating_q025": 1000.3180635015083
        },
        "zephyr-orpo-141b-A35b-v0.1": {
            "rating": 1000.338586324337,
            "rating_q975": 1015.9779052210131,
            "rating_q025": 984.6992674276607
        },
        "granite-3.1-8b-instruct": {
            "rating": 994.2742600406654,
            "rating_q975": 1013.7697714725191,
            "rating_q025": 974.7787486088116
        },
        "qwen1.5-32b-chat": {
            "rating": 991.6676423732688,
            "rating_q975": 1000.8918473281426,
            "rating_q025": 982.4434374183949
        },
        "starling-lm-7b-beta": {
            "rating": 987.6367809603423,
            "rating_q975": 998.2942534454273,
            "rating_q025": 976.9793084752574
        },
        "gemini-pro": {
            "rating": 979.8369980423806,
            "rating_q975": 995.9260290970551,
            "rating_q025": 963.7479669877063
        },
        "mixtral-8x7b-instruct-v0.1": {
            "rating": 979.7675115151596,
            "rating_q975": 986.0254098494993,
            "rating_q025": 973.5096131808201
        },
        "phi-3-medium-4k-instruct": {
            "rating": 978.8777203483018,
            "rating_q975": 987.2049657382149,
            "rating_q025": 970.5504749583887
        },
        "qwen1.5-14b-chat": {
            "rating": 978.6550303027807,
            "rating_q975": 989.4167142659778,
            "rating_q025": 967.8933463395834
        },
        "yi-34b-chat": {
            "rating": 977.1713726613993,
            "rating_q975": 987.0061130179284,
            "rating_q025": 967.3366323048704
        },
        "gpt-3.5-turbo-0125": {
            "rating": 969.4225579996521,
            "rating_q975": 976.0812309279542,
            "rating_q025": 962.7638850713502
        },
        "wizardlm-70b": {
            "rating": 967.633240728545,
            "rating_q975": 980.6803257191569,
            "rating_q025": 954.5861557379333
        },
        "tulu-2-dpo-70b": {
            "rating": 964.2134053259908,
            "rating_q975": 978.0773118045805,
            "rating_q025": 950.3494988474012
        },
        "dbrx-instruct-preview": {
            "rating": 960.3813264173144,
            "rating_q975": 969.5079548466133,
            "rating_q025": 951.2546979880156
        },
        "llama-2-70b-chat": {
            "rating": 957.0799049815523,
            "rating_q975": 965.0138373305458,
            "rating_q025": 949.1459726325588
        },
        "nous-hermes-2-mixtral-8x7b-dpo": {
            "rating": 953.8113627242825,
            "rating_q975": 970.8192129755801,
            "rating_q025": 936.8035124729848
        },
        "granite-3.1-2b-instruct": {
            "rating": 947.7750865398757,
            "rating_q975": 968.7677008324331,
            "rating_q025": 926.7824722473181
        },
        "vicuna-33b": {
            "rating": 946.935592960845,
            "rating_q975": 955.9642035041084,
            "rating_q025": 937.9069824175817
        },
        "starling-lm-7b-alpha": {
            "rating": 946.6039868673706,
            "rating_q975": 958.1302200083857,
            "rating_q025": 935.0777537263557
        },
        "openchat-3.5-0106": {
            "rating": 946.2050837280535,
            "rating_q975": 957.663204357532,
            "rating_q025": 934.7469630985752
        },
        "deepseek-llm-67b-chat": {
            "rating": 942.6481763763991,
            "rating_q975": 959.4816089898671,
            "rating_q025": 925.8147437629311
        },
        "phi-3-small-8k-instruct": {
            "rating": 937.6894932413718,
            "rating_q975": 947.88514149028,
            "rating_q025": 927.4938449924637
        },
        "llama2-70b-steerlm-chat": {
            "rating": 933.7402416880618,
            "rating_q975": 951.1342625587587,
            "rating_q025": 916.3462208173648
        },
        "llama-3.2-3b-instruct": {
            "rating": 933.2391615182402,
            "rating_q975": 946.50802545507,
            "rating_q025": 919.9702975814103
        },
        "openchat-3.5": {
            "rating": 930.2071361209444,
            "rating_q975": 944.1619974044404,
            "rating_q025": 916.2522748374482
        },
        "snowflake-arctic-instruct": {
            "rating": 929.6440531570362,
            "rating_q975": 939.016088233712,
            "rating_q025": 920.2720180803603
        },
        "openhermes-2.5-mistral-7b": {
            "rating": 926.1414961571746,
            "rating_q975": 941.2441324340373,
            "rating_q025": 911.038859880312
        },
        "gpt-3.5-turbo-1106": {
            "rating": 923.8677114668785,
            "rating_q975": 936.054072874472,
            "rating_q025": 911.681350059285
        },
        "gemma-1.1-7b-it": {
            "rating": 921.0684151109251,
            "rating_q975": 929.9042689668577,
            "rating_q025": 912.2325612549926
        },
        "mistral-7b-instruct-v0.2": {
            "rating": 916.6080181931617,
            "rating_q975": 926.5026017334328,
            "rating_q025": 906.7134346528906
        },
        "granite-3.0-8b-instruct": {
            "rating": 914.914509601146,
            "rating_q975": 930.6167566172886,
            "rating_q025": 899.2122625850036
        },
        "solar-10.7b-instruct-v1.0": {
            "rating": 911.479280505068,
            "rating_q975": 930.472367449271,
            "rating_q025": 892.4861935608651
        },
        "llama-2-13b-chat": {
            "rating": 911.1695108193077,
            "rating_q975": 920.9729288018298,
            "rating_q025": 901.3660928367856
        },
        "qwen1.5-7b-chat": {
            "rating": 908.5961673091443,
            "rating_q975": 923.6453457537095,
            "rating_q025": 893.5469888645791
        },
        "dolphin-2.2.1-mistral-7b": {
            "rating": 908.0866405672093,
            "rating_q975": 930.5157955651122,
            "rating_q025": 885.6574855693066
        },
        "wizardlm-13b": {
            "rating": 907.2448654134257,
            "rating_q975": 920.6362316775242,
            "rating_q025": 893.8534991493274
        },
        "mpt-30b-chat": {
            "rating": 897.9797475974372,
            "rating_q975": 915.915854817548,
            "rating_q025": 880.043640377326
        },
        "zephyr-7b-beta": {
            "rating": 889.8633648840453,
            "rating_q975": 902.1942479652766,
            "rating_q025": 877.5324818028139
        },
        "codellama-34b-instruct": {
            "rating": 885.1213591722163,
            "rating_q975": 897.7486559146586,
            "rating_q025": 872.4940624297741
        },
        "zephyr-7b-alpha": {
            "rating": 878.5528209491254,
            "rating_q975": 901.3832887005545,
            "rating_q025": 855.7223531976961
        },
        "granite-3.0-2b-instruct": {
            "rating": 877.5594127613183,
            "rating_q975": 894.1489855899375,
            "rating_q025": 860.969839932699
        },
        "phi-3-mini-4k-instruct-june-2024": {
            "rating": 875.1497647541227,
            "rating_q975": 887.144445670609,
            "rating_q025": 863.1550838376363
        },
        "guanaco-33b": {
            "rating": 874.3506945990388,
            "rating_q975": 892.2999467625423,
            "rating_q025": 856.4014424355353
        },
        "codellama-70b-instruct": {
            "rating": 874.1186346171389,
            "rating_q975": 902.0137802301771,
            "rating_q025": 846.2234890041009
        },
        "phi-3-mini-4k-instruct": {
            "rating": 873.7567721091725,
            "rating_q975": 884.8952105225176,
            "rating_q025": 862.6183336958276
        },
        "vicuna-13b": {
            "rating": 870.9014296875259,
            "rating_q975": 880.7514730339783,
            "rating_q025": 861.0513863410735
        },
        "falcon-180b-chat": {
            "rating": 869.776698359828,
            "rating_q975": 893.8221586454949,
            "rating_q025": 845.731238074161
        },
        "qwen-14b-chat": {
            "rating": 866.7103107044712,
            "rating_q975": 882.4093942383927,
            "rating_q025": 851.0112271705498
        },
        "gemma-7b-it": {
            "rating": 865.0594112904752,
            "rating_q975": 879.3599353669053,
            "rating_q025": 850.758887214045
        },
        "llama-2-7b-chat": {
            "rating": 863.4530995636171,
            "rating_q975": 873.7245547815801,
            "rating_q025": 853.181644345654
        },
        "phi-3-mini-128k-instruct": {
            "rating": 849.4260119452501,
            "rating_q975": 861.8890259771858,
            "rating_q025": 836.9629979133144
        },
        "vicuna-7b": {
            "rating": 844.0227212326022,
            "rating_q975": 857.368572325405,
            "rating_q025": 830.6768701397995
        },
        "stripedhyena-nous-7b": {
            "rating": 840.9151936575207,
            "rating_q975": 857.527640815045,
            "rating_q025": 824.3027464999966
        },
        "palm-2": {
            "rating": 832.1466050009942,
            "rating_q975": 845.0127027359094,
            "rating_q025": 819.2805072660788
        },
        "llama-3.2-1b-instruct": {
            "rating": 827.4057959893387,
            "rating_q975": 842.9274813266343,
            "rating_q025": 811.8841106520431
        },
        "olmo-7b-instruct": {
            "rating": 826.5270766444589,
            "rating_q975": 843.9312804127446,
            "rating_q025": 809.1228728761732
        },
        "mistral-7b-instruct": {
            "rating": 821.7244885500951,
            "rating_q975": 835.2447434525014,
            "rating_q025": 808.2042336476887
        },
        "smollm2-1.7b-instruct": {
            "rating": 806.8909462722476,
            "rating_q975": 838.2849242758821,
            "rating_q025": 775.4969682686129
        },
        "gemma-1.1-2b-it": {
            "rating": 800.1571677475551,
            "rating_q975": 813.5732735665803,
            "rating_q025": 786.7410619285299
        },
        "koala-13b": {
            "rating": 783.5915872512035,
            "rating_q975": 798.9200047785279,
            "rating_q025": 768.263169723879
        },
        "gemma-2b-it": {
            "rating": 781.8570766957924,
            "rating_q975": 800.1494746115453,
            "rating_q025": 763.5646787800395
        },
        "qwen1.5-4b-chat": {
            "rating": 765.1840521520226,
            "rating_q975": 780.9346955602776,
            "rating_q025": 749.4334087437675
        },
        "chatglm3-6b": {
            "rating": 742.2928036095951,
            "rating_q975": 760.6137309391261,
            "rating_q025": 723.9718762800642
        },
        "mpt-7b-chat": {
            "rating": 730.2133315164917,
            "rating_q975": 748.3229507580808,
            "rating_q025": 712.1037122749028
        },
        "gpt4all-13b-snoozy": {
            "rating": 727.0787628677086,
            "rating_q975": 751.0814388660285,
            "rating_q025": 703.0760868693887
        },
        "RWKV-4-Raven-14B": {
            "rating": 724.2366022939871,
            "rating_q975": 741.7546021284224,
            "rating_q025": 706.7186024595517
        },
        "alpaca-13b": {
            "rating": 698.6667889867695,
            "rating_q975": 715.761318218612,
            "rating_q025": 681.572259754927
        },
        "chatglm2-6b": {
            "rating": 688.8983901094459,
            "rating_q975": 710.7372026560395,
            "rating_q025": 667.0595775628525
        },
        "oasst-pythia-12b": {
            "rating": 673.94267569429,
            "rating_q975": 690.3966193807,
            "rating_q025": 657.4887320078799
        },
        "chatglm-6b": {
            "rating": 663.6446637507545,
            "rating_q975": 682.9657975642704,
            "rating_q025": 644.3235299372386
        },
        "fastchat-t5-3b": {
            "rating": 636.8114192879253,
            "rating_q975": 656.0492908662354,
            "rating_q025": 617.5735477096152
        },
        "stablelm-tuned-alpha-7b": {
            "rating": 584.470647965833,
            "rating_q975": 606.0606838553811,
            "rating_q025": 562.8806120762849
        },
        "dolly-v2-12b": {
            "rating": 569.2907489310645,
            "rating_q975": 591.3354838707677,
            "rating_q025": 547.2460139913612
        },
        "llama-13b": {
            "rating": 534.5036138095625,
            "rating_q975": 560.4935808300654,
            "rating_q025": 508.5136467890594
        }
    },
    "russian": {
        "gemini-2.5-pro": {
            "rating": 1488.9471691791173,
            "rating_q975": 1502.709259553742,
            "rating_q025": 1475.1850788044924
        },
        "grok-4-0709": {
            "rating": 1449.1549095307064,
            "rating_q975": 1467.8990961330119,
            "rating_q025": 1430.410722928401
        },
        "glm-4.5": {
            "rating": 1435.85361327625,
            "rating_q975": 1461.8989980381782,
            "rating_q025": 1409.8082285143219
        },
        "qwen-max-2025-08-15": {
            "rating": 1430.6290799729552,
            "rating_q975": 1472.3523421301904,
            "rating_q025": 1388.9058178157202
        },
        "claude-opus-4-1-20250805": {
            "rating": 1424.3844476811594,
            "rating_q975": 1448.014651847333,
            "rating_q025": 1400.7542435149858
        },
        "gemini-2.5-flash": {
            "rating": 1423.874455159448,
            "rating_q975": 1435.8223901267963,
            "rating_q025": 1411.9265201920998
        },
        "chatgpt-4o-latest-20250326": {
            "rating": 1423.8394700801673,
            "rating_q975": 1435.4563972396802,
            "rating_q025": 1412.2225429206546
        },
        "mistral-medium-2508": {
            "rating": 1421.5953270157436,
            "rating_q975": 1456.6797793696169,
            "rating_q025": 1386.51087466187
        },
        "deepseek-r1-0528": {
            "rating": 1419.3106742757454,
            "rating_q975": 1434.8237118797003,
            "rating_q025": 1403.7976366717908
        },
        "gpt-4.5-preview-2025-02-27": {
            "rating": 1418.5819890194223,
            "rating_q975": 1433.06156663901,
            "rating_q025": 1404.1024113998346
        },
        "grok-3-preview-02-24": {
            "rating": 1417.2587875919555,
            "rating_q975": 1428.3119934016224,
            "rating_q025": 1406.2055817822886
        },
        "o3-2025-04-16": {
            "rating": 1414.9791081396595,
            "rating_q975": 1426.512706327979,
            "rating_q025": 1403.4455099513402
        },
        "gpt-5-high": {
            "rating": 1411.7062041958432,
            "rating_q975": 1438.2689624702105,
            "rating_q025": 1385.1434459214756
        },
        "qwen3-235b-a22b-instruct-2507": {
            "rating": 1411.152698969181,
            "rating_q975": 1433.3745399805107,
            "rating_q025": 1388.9308579578515
        },
        "qwen3-235b-a22b-thinking-2507": {
            "rating": 1406.1284532201184,
            "rating_q975": 1434.7932031321652,
            "rating_q025": 1377.4637033080714
        },
        "gpt-5-chat": {
            "rating": 1402.156299905431,
            "rating_q975": 1430.4661768580552,
            "rating_q025": 1373.8464229528067
        },
        "claude-opus-4-1-20250805-thinking-16k": {
            "rating": 1400.033076817168,
            "rating_q975": 1428.5036514884423,
            "rating_q025": 1371.5625021458939
        },
        "hunyuan-t1-20250711": {
            "rating": 1398.357308317284,
            "rating_q975": 1430.6382870731939,
            "rating_q025": 1366.0763295613742
        },
        "qwen3-235b-a22b-no-thinking": {
            "rating": 1395.2894698197763,
            "rating_q975": 1408.9873995729838,
            "rating_q025": 1381.591540066569
        },
        "claude-opus-4-20250514-thinking-16k": {
            "rating": 1391.1633063946738,
            "rating_q975": 1407.5645541872384,
            "rating_q025": 1374.7620586021094
        },
        "glm-4.5-air": {
            "rating": 1386.0617275573213,
            "rating_q975": 1411.614245830433,
            "rating_q025": 1360.5092092842094
        },
        "kimi-k2-0711-preview": {
            "rating": 1381.6098336510272,
            "rating_q975": 1400.2157158816374,
            "rating_q025": 1363.003951420417
        },
        "deepseek-v3-0324": {
            "rating": 1380.3255505367508,
            "rating_q975": 1391.8636705384413,
            "rating_q025": 1368.7874305350601
        },
        "claude-opus-4-20250514": {
            "rating": 1378.211013972755,
            "rating_q975": 1391.3489456838474,
            "rating_q025": 1365.0730822616624
        },
        "gpt-4.1-2025-04-14": {
            "rating": 1375.4517924879924,
            "rating_q975": 1388.223767949196,
            "rating_q025": 1362.6798170267891
        },
        "hunyuan-turbos-20250416": {
            "rating": 1370.9567678389824,
            "rating_q975": 1388.7327660803517,
            "rating_q025": 1353.1807695976133
        },
        "claude-sonnet-4-20250514-thinking-32k": {
            "rating": 1364.9435344581682,
            "rating_q975": 1381.9632003942093,
            "rating_q025": 1347.923868522127
        },
        "qwen3-30b-a3b-instruct-2507": {
            "rating": 1361.385439693063,
            "rating_q975": 1389.92031999342,
            "rating_q025": 1332.8505593927064
        },
        "gemma-3-27b-it": {
            "rating": 1357.9882829004305,
            "rating_q975": 1369.4883509733627,
            "rating_q025": 1346.4882148274985
        },
        "gemini-2.0-flash-001": {
            "rating": 1357.222374725496,
            "rating_q975": 1366.800391223994,
            "rating_q025": 1347.6443582269978
        },
        "mistral-medium-2505": {
            "rating": 1357.1875904147923,
            "rating_q975": 1369.3499705607537,
            "rating_q025": 1345.025210268831
        },
        "o1-2024-12-17": {
            "rating": 1356.447229488572,
            "rating_q975": 1366.1163692709536,
            "rating_q025": 1346.7780897061903
        },
        "deepseek-r1": {
            "rating": 1355.5450343982432,
            "rating_q975": 1367.5321305121015,
            "rating_q025": 1343.557938284385
        },
        "qwen3-coder-480b-a35b-instruct": {
            "rating": 1354.676953781817,
            "rating_q975": 1380.3017973089268,
            "rating_q025": 1329.052110254707
        },
        "grok-3-mini-beta": {
            "rating": 1354.542790131535,
            "rating_q975": 1370.9813016221192,
            "rating_q025": 1338.1042786409507
        },
        "qwen2.5-max": {
            "rating": 1353.8627881331147,
            "rating_q975": 1363.8155637892683,
            "rating_q025": 1343.9100124769614
        },
        "grok-3-mini-high": {
            "rating": 1352.9079706624727,
            "rating_q975": 1373.169070928563,
            "rating_q025": 1332.6468703963826
        },
        "claude-sonnet-4-20250514": {
            "rating": 1348.0932261195594,
            "rating_q975": 1361.7829759622923,
            "rating_q025": 1334.4034762768263
        },
        "gpt-5-mini-high": {
            "rating": 1347.4585181484224,
            "rating_q975": 1378.088875788434,
            "rating_q025": 1316.8281605084107
        },
        "qwen3-235b-a22b": {
            "rating": 1342.8081116388628,
            "rating_q975": 1356.4026989291742,
            "rating_q025": 1329.2135243485511
        },
        "gemma-3-12b-it": {
            "rating": 1341.0783990443008,
            "rating_q975": 1371.9222275230127,
            "rating_q025": 1310.2345705655891
        },
        "o4-mini-2025-04-16": {
            "rating": 1339.207369764799,
            "rating_q975": 1352.0473866692248,
            "rating_q025": 1326.3673528603733
        },
        "gpt-oss-120b": {
            "rating": 1338.4754150863896,
            "rating_q975": 1368.5095993578864,
            "rating_q025": 1308.4412308148928
        },
        "step-1o-turbo-202506": {
            "rating": 1337.7570368832064,
            "rating_q975": 1360.862084571485,
            "rating_q025": 1314.6519891949279
        },
        "minimax-m1": {
            "rating": 1331.8060791813166,
            "rating_q975": 1348.661321780113,
            "rating_q025": 1314.95083658252
        },
        "mistral-small-2506": {
            "rating": 1331.2443018683011,
            "rating_q975": 1352.0851317866307,
            "rating_q025": 1310.4034719499716
        },
        "gemini-2.0-flash-lite-preview-02-05": {
            "rating": 1331.1455495805021,
            "rating_q975": 1341.912144837636,
            "rating_q025": 1320.3789543233681
        },
        "nvidia-llama-3.3-nemotron-super-49b-v1.5": {
            "rating": 1329.5488285500371,
            "rating_q975": 1367.7064563671554,
            "rating_q025": 1291.391200732919
        },
        "step-2-16k-exp-202412": {
            "rating": 1326.6184257658042,
            "rating_q975": 1347.2263749351173,
            "rating_q025": 1306.0104765964913
        },
        "qwen-plus-0125": {
            "rating": 1325.8257902931637,
            "rating_q975": 1346.3787686679193,
            "rating_q025": 1305.272811918408
        },
        "deepseek-v3": {
            "rating": 1325.8035679788454,
            "rating_q975": 1336.3848286400537,
            "rating_q025": 1315.2223073176374
        },
        "amazon-nova-experimental-chat-05-14": {
            "rating": 1325.4380512145658,
            "rating_q975": 1341.6850757738976,
            "rating_q025": 1309.191026655234
        },
        "gemini-1.5-pro-002": {
            "rating": 1321.3093538835037,
            "rating_q975": 1327.7965428138054,
            "rating_q025": 1314.8221649532022
        },
        "o1-preview": {
            "rating": 1320.046297445533,
            "rating_q975": 1328.5530389767828,
            "rating_q025": 1311.539555914283
        },
        "gpt-4.1-mini-2025-04-14": {
            "rating": 1319.7915986559265,
            "rating_q975": 1332.8461361613856,
            "rating_q025": 1306.7370611504673
        },
        "hunyuan-turbos-20250226": {
            "rating": 1316.995503245206,
            "rating_q975": 1350.0325020736,
            "rating_q025": 1283.958504416812
        },
        "glm-4-plus-0111": {
            "rating": 1314.584429554742,
            "rating_q975": 1334.8495292951043,
            "rating_q025": 1294.3193298143797
        },
        "claude-3-7-sonnet-20250219": {
            "rating": 1313.7651750737673,
            "rating_q975": 1324.0975264698736,
            "rating_q025": 1303.4328236776607
        },
        "qwen3-32b": {
            "rating": 1313.0547260762835,
            "rating_q975": 1337.9492468365047,
            "rating_q025": 1288.160205316062
        },
        "claude-3-7-sonnet-20250219-thinking-32k": {
            "rating": 1312.9587269026345,
            "rating_q975": 1323.9807747261816,
            "rating_q025": 1301.9366790790875
        },
        "command-a-03-2025": {
            "rating": 1311.841229243358,
            "rating_q975": 1322.9269890384128,
            "rating_q025": 1300.7554694483028
        },
        "o3-mini-high": {
            "rating": 1309.207185060804,
            "rating_q975": 1321.804049802949,
            "rating_q025": 1296.610320318659
        },
        "claude-3-5-sonnet-20241022": {
            "rating": 1308.8120682949166,
            "rating_q975": 1314.7091984068497,
            "rating_q025": 1302.9149381829834
        },
        "hunyuan-turbo-0110": {
            "rating": 1308.635610528128,
            "rating_q975": 1339.778805069361,
            "rating_q025": 1277.4924159868951
        },
        "o3-mini": {
            "rating": 1301.4168518136971,
            "rating_q975": 1310.433735299844,
            "rating_q025": 1292.3999683275501
        },
        "qwq-32b": {
            "rating": 1301.257476591501,
            "rating_q975": 1314.5079033400148,
            "rating_q025": 1288.0070498429875
        },
        "gemma-3n-e4b-it": {
            "rating": 1300.7475072158022,
            "rating_q975": 1317.7214672602677,
            "rating_q025": 1283.7735471713365
        },
        "gpt-5-nano-high": {
            "rating": 1297.1568822124418,
            "rating_q975": 1332.4802588470698,
            "rating_q025": 1261.8335055778139
        },
        "gemma-3-4b-it": {
            "rating": 1296.860994024596,
            "rating_q975": 1327.2760341075013,
            "rating_q025": 1266.4459539416912
        },
        "qwen3-30b-a3b": {
            "rating": 1296.6583274416234,
            "rating_q975": 1310.4384561672036,
            "rating_q025": 1282.8781987160435
        },
        "deepseek-v2.5-1210": {
            "rating": 1293.539941202358,
            "rating_q975": 1309.4334884640555,
            "rating_q025": 1277.6463939406606
        },
        "gemini-1.5-flash-002": {
            "rating": 1291.2069855124282,
            "rating_q975": 1298.7962501607763,
            "rating_q025": 1283.6177208640804
        },
        "llama-4-maverick-17b-128e-instruct": {
            "rating": 1290.8038492306591,
            "rating_q975": 1303.2802054413473,
            "rating_q025": 1278.327493019971
        },
        "gpt-4o-2024-05-13": {
            "rating": 1290.3616279064681,
            "rating_q975": 1296.534254037744,
            "rating_q025": 1284.189001775192
        },
        "gpt-oss-20b": {
            "rating": 1290.1201614629665,
            "rating_q975": 1320.1860876966982,
            "rating_q025": 1260.054235229235
        },
        "grok-2-2024-08-13": {
            "rating": 1289.6545880730787,
            "rating_q975": 1296.1070208263268,
            "rating_q025": 1283.2021553198308
        },
        "llama-3.1-nemotron-ultra-253b-v1": {
            "rating": 1287.517263583646,
            "rating_q975": 1316.857632378999,
            "rating_q025": 1258.1768947882929
        },
        "claude-3-5-sonnet-20240620": {
            "rating": 1287.2974477262487,
            "rating_q975": 1294.1472100050737,
            "rating_q025": 1280.4476854474235
        },
        "o1-mini": {
            "rating": 1287.0854053520743,
            "rating_q975": 1293.7542963275723,
            "rating_q025": 1280.4165143765767
        },
        "gemini-advanced-0514": {
            "rating": 1286.8813267523765,
            "rating_q975": 1296.3250894492928,
            "rating_q025": 1277.4375640554601
        },
        "claude-3-opus-20240229": {
            "rating": 1285.0542010373167,
            "rating_q975": 1290.6185784659215,
            "rating_q025": 1279.489823608712
        },
        "athene-v2-chat": {
            "rating": 1284.950552717677,
            "rating_q975": 1293.7483120194825,
            "rating_q025": 1276.1527934158719
        },
        "gemini-1.5-pro-001": {
            "rating": 1281.799538334607,
            "rating_q975": 1289.4288976039823,
            "rating_q025": 1274.1701790652314
        },
        "gpt-4o-mini-2024-07-18": {
            "rating": 1280.6337045553407,
            "rating_q975": 1286.8538965564849,
            "rating_q025": 1274.4135125541966
        },
        "glm-4-plus": {
            "rating": 1280.601143232938,
            "rating_q975": 1289.3912124218275,
            "rating_q025": 1271.8110740440486
        },
        "qwen-max-0919": {
            "rating": 1279.7646672098822,
            "rating_q975": 1290.192550468648,
            "rating_q025": 1269.3367839511166
        },
        "gpt-4o-2024-08-06": {
            "rating": 1276.8251321901237,
            "rating_q975": 1284.3645806628438,
            "rating_q025": 1269.2856837174036
        },
        "llama-3.3-nemotron-49b-super-v1": {
            "rating": 1274.1048431521024,
            "rating_q975": 1306.9293334797032,
            "rating_q025": 1241.2803528245015
        },
        "qwen2.5-plus-1127": {
            "rating": 1273.5999900628171,
            "rating_q975": 1287.7247437237147,
            "rating_q025": 1259.4752364019196
        },
        "llama-3.1-405b-instruct-fp8": {
            "rating": 1271.9261458477606,
            "rating_q975": 1278.6116428173127,
            "rating_q025": 1265.2406488782085
        },
        "hunyuan-large-2025-02-10": {
            "rating": 1270.3146698475985,
            "rating_q975": 1298.1407847848097,
            "rating_q025": 1242.4885549103872
        },
        "qwen2.5-72b-instruct": {
            "rating": 1269.955788402065,
            "rating_q975": 1277.2294509311996,
            "rating_q025": 1262.6821258729306
        },
        "grok-2-mini-2024-08-13": {
            "rating": 1267.4992067000683,
            "rating_q975": 1274.2406787785883,
            "rating_q025": 1260.7577346215483
        },
        "gpt-4.1-nano-2025-04-14": {
            "rating": 1266.7570543589436,
            "rating_q975": 1287.1949947137716,
            "rating_q025": 1246.319114004116
        },
        "gpt-4-turbo-2024-04-09": {
            "rating": 1266.0259049514084,
            "rating_q975": 1273.1246203402964,
            "rating_q025": 1258.9271895625207
        },
        "hunyuan-standard-2025-02-10": {
            "rating": 1265.2800861455194,
            "rating_q975": 1291.2807217747645,
            "rating_q025": 1239.279450516274
        },
        "mistral-large-2407": {
            "rating": 1262.697716565266,
            "rating_q975": 1270.1700219393074,
            "rating_q025": 1255.2254111912252
        },
        "llama-3.1-405b-instruct-bf16": {
            "rating": 1262.5702652498471,
            "rating_q975": 1270.1548148009322,
            "rating_q025": 1254.9857156987616
        },
        "yi-lightning": {
            "rating": 1261.2753338525617,
            "rating_q975": 1269.953356869163,
            "rating_q025": 1252.5973108359606
        },
        "llama-4-scout-17b-16e-instruct": {
            "rating": 1261.0278539480864,
            "rating_q975": 1277.6042234424049,
            "rating_q025": 1244.451484453768
        },
        "deepseek-v2.5": {
            "rating": 1258.810380482399,
            "rating_q975": 1267.7050662493425,
            "rating_q025": 1249.9156947154556
        },
        "mistral-large-2411": {
            "rating": 1257.641891741554,
            "rating_q975": 1266.7334416002052,
            "rating_q025": 1248.550341882903
        },
        "claude-3-5-haiku-20241022": {
            "rating": 1256.8670467854843,
            "rating_q975": 1264.322033384295,
            "rating_q025": 1249.4120601866737
        },
        "mistral-small-3.1-24b-instruct-2503": {
            "rating": 1256.8620305738366,
            "rating_q975": 1273.9042808890968,
            "rating_q025": 1239.8197802585764
        },
        "gpt-4-1106-preview": {
            "rating": 1256.644184441427,
            "rating_q975": 1264.6678687695467,
            "rating_q025": 1248.6205001133073
        },
        "athene-70b-0725": {
            "rating": 1256.0915716369295,
            "rating_q975": 1268.2629730118592,
            "rating_q025": 1243.9201702619996
        },
        "reka-core-20240904": {
            "rating": 1255.9181098007075,
            "rating_q975": 1272.29138696561,
            "rating_q025": 1239.5448326358048
        },
        "hunyuan-large-vision": {
            "rating": 1254.6975693880872,
            "rating_q975": 1285.0396333832023,
            "rating_q025": 1224.355505392972
        },
        "llama-3.3-70b-instruct": {
            "rating": 1254.065542486117,
            "rating_q975": 1261.4993544335364,
            "rating_q025": 1246.6317305386974
        },
        "llama-3.1-tulu-3-70b": {
            "rating": 1252.7439923052311,
            "rating_q975": 1278.4682716072125,
            "rating_q025": 1227.0197130032495
        },
        "gpt-4-0125-preview": {
            "rating": 1248.5479828601942,
            "rating_q975": 1256.3108314918493,
            "rating_q025": 1240.785134228539
        },
        "gemini-1.5-flash-001": {
            "rating": 1246.4093211281076,
            "rating_q975": 1254.447834614611,
            "rating_q025": 1238.370807641604
        },
        "amazon-nova-pro-v1.0": {
            "rating": 1245.2272684801446,
            "rating_q975": 1254.6136454063712,
            "rating_q025": 1235.8408915539183
        },
        "gemini-1.5-flash-8b-001": {
            "rating": 1243.5262564359873,
            "rating_q975": 1250.9799737621938,
            "rating_q025": 1236.0725391097808
        },
        "llama-3.1-70b-instruct": {
            "rating": 1240.8549512172153,
            "rating_q975": 1247.6519385877386,
            "rating_q025": 1234.0579638466922
        },
        "gemma-2-27b-it": {
            "rating": 1240.677563217354,
            "rating_q975": 1246.6458398413415,
            "rating_q025": 1234.7092865933666
        },
        "claude-3-sonnet-20240229": {
            "rating": 1236.283136443042,
            "rating_q975": 1244.3861234454268,
            "rating_q025": 1228.180149440657
        },
        "c4ai-aya-expanse-32b": {
            "rating": 1235.5740318094236,
            "rating_q975": 1244.0488295616074,
            "rating_q025": 1227.0992340572395
        },
        "qwen2.5-coder-32b-instruct": {
            "rating": 1235.2133724261082,
            "rating_q975": 1251.8244912649361,
            "rating_q025": 1218.6022535872805
        },
        "llama-3.1-nemotron-70b-instruct": {
            "rating": 1234.8607234500414,
            "rating_q975": 1250.4206615154856,
            "rating_q025": 1219.300785384597
        },
        "command-r-plus-08-2024": {
            "rating": 1234.1544148707458,
            "rating_q975": 1248.0355488471519,
            "rating_q025": 1220.2732808943395
        },
        "gemma-2-9b-it-simpo": {
            "rating": 1231.9797308662014,
            "rating_q975": 1247.8133553103626,
            "rating_q025": 1216.14610642204
        },
        "nemotron-4-340b-instruct": {
            "rating": 1229.155775329085,
            "rating_q975": 1240.773333051838,
            "rating_q025": 1217.5382176063317
        },
        "magistral-medium-2506": {
            "rating": 1224.3245347095503,
            "rating_q975": 1249.6371454915422,
            "rating_q025": 1199.011923927558
        },
        "amazon-nova-lite-v1.0": {
            "rating": 1223.823915802689,
            "rating_q975": 1234.1961251180528,
            "rating_q025": 1213.451706487325
        },
        "glm-4-0520": {
            "rating": 1221.8977345536362,
            "rating_q975": 1237.18833775402,
            "rating_q025": 1206.607131353252
        },
        "mistral-small-24b-instruct-2501": {
            "rating": 1221.8111011099875,
            "rating_q975": 1235.4492053408928,
            "rating_q025": 1208.1729968790821
        },
        "reka-flash-20240904": {
            "rating": 1221.1605990135863,
            "rating_q975": 1237.278294300658,
            "rating_q025": 1205.0429037265144
        },
        "phi-4": {
            "rating": 1215.7834973176014,
            "rating_q975": 1226.0976271797695,
            "rating_q025": 1205.4693674554335
        },
        "claude-3-haiku-20240307": {
            "rating": 1214.4407641792252,
            "rating_q975": 1221.3882606380907,
            "rating_q025": 1207.4932677203597
        },
        "command-r-plus": {
            "rating": 1212.924088606906,
            "rating_q975": 1221.2054618938091,
            "rating_q025": 1204.6427153200025
        },
        "gemma-2-9b-it": {
            "rating": 1209.2423601731352,
            "rating_q975": 1216.1299120686485,
            "rating_q025": 1202.354808277622
        },
        "c4ai-aya-expanse-8b": {
            "rating": 1208.257259782444,
            "rating_q975": 1221.8019328648236,
            "rating_q025": 1194.7125867000643
        },
        "ministral-8b-2410": {
            "rating": 1207.5664192884,
            "rating_q975": 1224.78619932313,
            "rating_q025": 1190.3466392536702
        },
        "gpt-4-0314": {
            "rating": 1204.1306410171794,
            "rating_q975": 1215.3757462965573,
            "rating_q025": 1192.8855357378015
        },
        "jamba-1.5-large": {
            "rating": 1202.1577633559755,
            "rating_q975": 1219.1571392868864,
            "rating_q025": 1185.1583874250646
        },
        "olmo-2-0325-32b-instruct": {
            "rating": 1199.6555357870075,
            "rating_q975": 1231.5436097918862,
            "rating_q025": 1167.7674617821287
        },
        "llama-3.1-tulu-3-8b": {
            "rating": 1198.6778314785229,
            "rating_q975": 1222.3603586552847,
            "rating_q025": 1174.995304301761
        },
        "deepseek-coder-v2": {
            "rating": 1197.703199838739,
            "rating_q975": 1210.9777310532863,
            "rating_q025": 1184.4286686241917
        },
        "gemini-pro-dev-api": {
            "rating": 1196.3444772095559,
            "rating_q975": 1215.8310730691433,
            "rating_q025": 1176.8578813499687
        },
        "amazon-nova-micro-v1.0": {
            "rating": 1194.995660311119,
            "rating_q975": 1205.5547877455713,
            "rating_q025": 1184.436532876667
        },
        "llama-3.1-nemotron-51b-instruct": {
            "rating": 1192.687921529603,
            "rating_q975": 1213.9717608676492,
            "rating_q025": 1171.4040821915569
        },
        "mistral-large-2402": {
            "rating": 1187.0926167621988,
            "rating_q975": 1196.653767092453,
            "rating_q025": 1177.5314664319444
        },
        "command-r-08-2024": {
            "rating": 1186.3574716130709,
            "rating_q975": 1200.6579212715774,
            "rating_q025": 1172.0570219545643
        },
        "gpt-4-0613": {
            "rating": 1182.7287335254534,
            "rating_q975": 1191.8105087440183,
            "rating_q025": 1173.6469583068883
        },
        "mistral-medium": {
            "rating": 1178.0185453128329,
            "rating_q975": 1192.126320845091,
            "rating_q025": 1163.910769780575
        },
        "qwen2-72b-instruct": {
            "rating": 1177.1754916724876,
            "rating_q975": 1186.601862913043,
            "rating_q025": 1167.749120431932
        },
        "reka-flash-21b-20240226-online": {
            "rating": 1173.779956029127,
            "rating_q975": 1189.019798224443,
            "rating_q025": 1158.540113833811
        },
        "hunyuan-standard-256k": {
            "rating": 1172.757204006331,
            "rating_q975": 1196.4394236109156,
            "rating_q025": 1149.0749844017464
        },
        "llama-3.1-8b-instruct": {
            "rating": 1170.8883369256678,
            "rating_q975": 1178.0328057584447,
            "rating_q025": 1163.7438680928906
        },
        "reka-flash-21b-20240226": {
            "rating": 1169.4337001944564,
            "rating_q975": 1181.653048458404,
            "rating_q025": 1157.2143519305089
        },
        "command-r": {
            "rating": 1168.6253697006362,
            "rating_q975": 1178.1100138606796,
            "rating_q025": 1159.1407255405927
        },
        "llama-3-70b-instruct": {
            "rating": 1167.5283287346215,
            "rating_q975": 1174.7382175643215,
            "rating_q025": 1160.3184399049214
        },
        "jamba-1.5-mini": {
            "rating": 1166.585002415795,
            "rating_q975": 1183.3061992704588,
            "rating_q025": 1149.8638055611314
        },
        "mixtral-8x22b-instruct-v0.1": {
            "rating": 1166.230029018778,
            "rating_q975": 1175.3435737479717,
            "rating_q025": 1157.1164842895844
        },
        "wizardlm-70b": {
            "rating": 1155.5034277564137,
            "rating_q975": 1199.9482678968482,
            "rating_q025": 1111.0585876159791
        },
        "phi-3-medium-4k-instruct": {
            "rating": 1155.2317721344348,
            "rating_q975": 1165.6229286328737,
            "rating_q025": 1144.840615635996
        },
        "gpt-3.5-turbo-0125": {
            "rating": 1134.7071470519172,
            "rating_q975": 1143.9591503409495,
            "rating_q025": 1125.4551437628852
        },
        "gemma-2-2b-it": {
            "rating": 1132.118371643085,
            "rating_q975": 1139.6446368521745,
            "rating_q025": 1124.592106433996
        },
        "qwen1.5-110b-chat": {
            "rating": 1130.0282467301895,
            "rating_q975": 1141.2269573281985,
            "rating_q025": 1118.8295361321805
        },
        "zephyr-orpo-141b-A35b-v0.1": {
            "rating": 1127.7505302371144,
            "rating_q975": 1153.3155648106147,
            "rating_q025": 1102.1854956636143
        },
        "qwq-32b-preview": {
            "rating": 1127.0172339741118,
            "rating_q975": 1151.667829709175,
            "rating_q025": 1102.3666382390486
        },
        "internlm2_5-20b-chat": {
            "rating": 1123.1584770020563,
            "rating_q975": 1137.3189898435162,
            "rating_q025": 1108.9979641605964
        },
        "openchat-3.5": {
            "rating": 1122.5837114380902,
            "rating_q975": 1163.2870202881559,
            "rating_q025": 1081.8804025880247
        },
        "phi-3-small-8k-instruct": {
            "rating": 1122.254151628928,
            "rating_q975": 1134.4250530400466,
            "rating_q025": 1110.0832502178096
        },
        "llama-3-8b-instruct": {
            "rating": 1121.5167058157144,
            "rating_q975": 1129.4554026184217,
            "rating_q025": 1113.5780090130074
        },
        "qwen1.5-72b-chat": {
            "rating": 1116.0270552182476,
            "rating_q975": 1127.8497441186382,
            "rating_q025": 1104.204366317857
        },
        "snowflake-arctic-instruct": {
            "rating": 1114.1286091466998,
            "rating_q975": 1126.5399381651343,
            "rating_q025": 1101.7172801282654
        },
        "starling-lm-7b-beta": {
            "rating": 1111.9432100469508,
            "rating_q975": 1127.3568070567594,
            "rating_q025": 1096.5296130371419
        },
        "granite-3.1-8b-instruct": {
            "rating": 1106.0692417012451,
            "rating_q975": 1132.230048320361,
            "rating_q025": 1079.9084350821292
        },
        "starling-lm-7b-alpha": {
            "rating": 1105.6420328990605,
            "rating_q975": 1132.6886318057068,
            "rating_q025": 1078.5954339924142
        },
        "yi-1.5-34b-chat": {
            "rating": 1103.5779519978473,
            "rating_q975": 1114.4910911464365,
            "rating_q025": 1092.6648128492584
        },
        "mixtral-8x7b-instruct-v0.1": {
            "rating": 1101.5703628359488,
            "rating_q975": 1111.065001974112,
            "rating_q025": 1092.0757236977856
        },
        "openchat-3.5-0106": {
            "rating": 1096.6817005096252,
            "rating_q975": 1116.7753015144199,
            "rating_q025": 1076.5880995048308
        },
        "llama-2-70b-chat": {
            "rating": 1095.718617597925,
            "rating_q975": 1109.2945057815064,
            "rating_q025": 1082.1427294143434
        },
        "vicuna-33b": {
            "rating": 1094.8843527777872,
            "rating_q975": 1115.9037991238488,
            "rating_q025": 1073.8649064317258
        },
        "dbrx-instruct-preview": {
            "rating": 1089.0032452300961,
            "rating_q975": 1101.1198769013429,
            "rating_q025": 1076.8866135588494
        },
        "gpt-3.5-turbo-1106": {
            "rating": 1088.9486752504397,
            "rating_q975": 1117.8308696779748,
            "rating_q025": 1060.0664808229046
        },
        "codellama-34b-instruct": {
            "rating": 1087.4085698231283,
            "rating_q975": 1132.618080131448,
            "rating_q025": 1042.1990595148081
        },
        "qwen1.5-32b-chat": {
            "rating": 1085.5721650843375,
            "rating_q975": 1098.2260946170395,
            "rating_q025": 1072.9182355516357
        },
        "granite-3.0-8b-instruct": {
            "rating": 1085.3181998942075,
            "rating_q975": 1102.7102894411018,
            "rating_q025": 1067.9261103473132
        },
        "granite-3.1-2b-instruct": {
            "rating": 1075.6088854613113,
            "rating_q975": 1102.1767342944615,
            "rating_q025": 1049.0410366281612
        },
        "zephyr-7b-beta": {
            "rating": 1074.6206711533928,
            "rating_q975": 1113.1543064178368,
            "rating_q025": 1036.087035888949
        },
        "llama-2-13b-chat": {
            "rating": 1067.9012104128685,
            "rating_q975": 1087.7036012172944,
            "rating_q025": 1048.0988196084425
        },
        "granite-3.0-2b-instruct": {
            "rating": 1066.4590044034449,
            "rating_q975": 1083.9332476768395,
            "rating_q025": 1048.9847611300502
        },
        "yi-34b-chat": {
            "rating": 1062.7477348164657,
            "rating_q975": 1082.823489801766,
            "rating_q025": 1042.6719798311653
        },
        "qwen1.5-14b-chat": {
            "rating": 1060.69003883899,
            "rating_q975": 1075.3359891064129,
            "rating_q025": 1046.0440885715666
        },
        "gemma-1.1-7b-it": {
            "rating": 1059.9043183151384,
            "rating_q975": 1071.51822656791,
            "rating_q025": 1048.2904100623668
        },
        "vicuna-13b": {
            "rating": 1055.877738585832,
            "rating_q975": 1081.6139352268165,
            "rating_q025": 1030.1415419448474
        },
        "phi-3-mini-4k-instruct": {
            "rating": 1035.5760569201175,
            "rating_q975": 1047.8086942599584,
            "rating_q025": 1023.3434195802765
        },
        "mistral-7b-instruct-v0.2": {
            "rating": 1034.130169633052,
            "rating_q975": 1050.4709321210303,
            "rating_q025": 1017.7894071450735
        },
        "phi-3-mini-4k-instruct-june-2024": {
            "rating": 1031.1164454886928,
            "rating_q975": 1046.897216417024,
            "rating_q025": 1015.3356745603614
        },
        "qwen1.5-7b-chat": {
            "rating": 1023.4446153224806,
            "rating_q975": 1056.287718037846,
            "rating_q025": 990.6015126071153
        },
        "phi-3-mini-128k-instruct": {
            "rating": 1021.2757574104678,
            "rating_q975": 1036.1427170251281,
            "rating_q025": 1006.4087977958075
        },
        "smollm2-1.7b-instruct": {
            "rating": 1015.5123507336591,
            "rating_q975": 1043.9629151195154,
            "rating_q025": 987.0617863478028
        },
        "mistral-7b-instruct": {
            "rating": 1014.0918750983092,
            "rating_q975": 1055.234472754065,
            "rating_q025": 972.949277442553
        },
        "llama-2-7b-chat": {
            "rating": 1006.0598774174226,
            "rating_q975": 1028.666991762821,
            "rating_q025": 983.4527630720243
        },
        "gemma-1.1-2b-it": {
            "rating": 1004.8828870596253,
            "rating_q975": 1022.0480171157739,
            "rating_q025": 987.7177570034769
        },
        "gemma-7b-it": {
            "rating": 1003.876370881723,
            "rating_q975": 1026.7016655820335,
            "rating_q025": 981.0510761814124
        },
        "llama-3.2-3b-instruct": {
            "rating": 969.7980119175811,
            "rating_q975": 990.5686534123029,
            "rating_q025": 949.0273704228591
        },
        "qwen1.5-4b-chat": {
            "rating": 964.9075679602911,
            "rating_q975": 989.0935419832018,
            "rating_q025": 940.7215939373802
        },
        "llama-3.2-1b-instruct": {
            "rating": 959.7887979149493,
            "rating_q975": 980.7650783745769,
            "rating_q025": 938.812517455322
        },
        "olmo-7b-instruct": {
            "rating": 957.844217677311,
            "rating_q975": 985.2467776183491,
            "rating_q025": 930.441657736273
        },
        "gemma-2b-it": {
            "rating": 953.9233176836718,
            "rating_q975": 989.3263158325335,
            "rating_q025": 918.5203195348101
        }
    },
    "spanish": {
        "glm-4.5": {
            "rating": 1515.9336945859695,
            "rating_q975": 1574.1079237506183,
            "rating_q025": 1457.7594654213208
        },
        "gemini-2.5-pro": {
            "rating": 1479.5891220348212,
            "rating_q975": 1513.8621381100097,
            "rating_q025": 1445.3161059596328
        },
        "qwen3-235b-a22b-instruct-2507": {
            "rating": 1444.6322625510888,
            "rating_q975": 1502.936734855069,
            "rating_q025": 1386.3277902471089
        },
        "claude-opus-4-1-20250805": {
            "rating": 1432.4124400343685,
            "rating_q975": 1487.1602880618925,
            "rating_q025": 1377.6645920068445
        },
        "grok-4-0709": {
            "rating": 1427.718208301539,
            "rating_q975": 1471.892787652521,
            "rating_q025": 1383.5436289505571
        },
        "grok-3-preview-02-24": {
            "rating": 1426.2995750968848,
            "rating_q975": 1458.9106528597024,
            "rating_q025": 1393.688497334067
        },
        "o3-2025-04-16": {
            "rating": 1416.2755372529623,
            "rating_q975": 1448.7627270388596,
            "rating_q025": 1383.7883474670648
        },
        "deepseek-r1-0528": {
            "rating": 1413.5699049182645,
            "rating_q975": 1453.3606661081974,
            "rating_q025": 1373.7791437283315
        },
        "gpt-5-high": {
            "rating": 1407.8994486004785,
            "rating_q975": 1460.81449808288,
            "rating_q025": 1354.9843991180774
        },
        "qwen3-235b-a22b-no-thinking": {
            "rating": 1407.719592034102,
            "rating_q975": 1445.5752527113746,
            "rating_q025": 1369.8639313568297
        },
        "chatgpt-4o-latest-20250326": {
            "rating": 1403.6662753821447,
            "rating_q975": 1435.892869577283,
            "rating_q025": 1371.4396811870065
        },
        "o4-mini-2025-04-16": {
            "rating": 1391.4897349601542,
            "rating_q975": 1425.7277437930345,
            "rating_q025": 1357.251726127274
        },
        "gemini-2.5-flash": {
            "rating": 1391.4797649052032,
            "rating_q975": 1423.4508071584503,
            "rating_q025": 1359.508722651956
        },
        "qwen3-235b-a22b": {
            "rating": 1389.616458457834,
            "rating_q975": 1425.7646228838364,
            "rating_q025": 1353.4682940318314
        },
        "grok-3-mini-beta": {
            "rating": 1385.7291725719638,
            "rating_q975": 1423.7159299766208,
            "rating_q025": 1347.742415167307
        },
        "mistral-medium-2505": {
            "rating": 1384.7418135748658,
            "rating_q975": 1419.4363980746334,
            "rating_q025": 1350.0472290750984
        },
        "qwen2.5-max": {
            "rating": 1382.0047961411433,
            "rating_q975": 1418.2902674090235,
            "rating_q025": 1345.719324873263
        },
        "command-a-03-2025": {
            "rating": 1375.5203401452934,
            "rating_q975": 1406.0012278863653,
            "rating_q025": 1345.0394524042217
        },
        "claude-opus-4-20250514": {
            "rating": 1366.201964600722,
            "rating_q975": 1400.3422398323505,
            "rating_q025": 1332.0616893690935
        },
        "gemini-2.0-flash-001": {
            "rating": 1365.5011649069947,
            "rating_q975": 1395.5067772345428,
            "rating_q025": 1335.4955525794464
        },
        "gpt-4.1-2025-04-14": {
            "rating": 1365.1449606220472,
            "rating_q975": 1399.0106201223593,
            "rating_q025": 1331.279301121735
        },
        "claude-opus-4-20250514-thinking-16k": {
            "rating": 1365.1363191052144,
            "rating_q975": 1405.352758503677,
            "rating_q025": 1324.9198797067518
        },
        "claude-sonnet-4-20250514": {
            "rating": 1364.9328512379027,
            "rating_q975": 1400.215298295872,
            "rating_q025": 1329.6504041799335
        },
        "deepseek-r1": {
            "rating": 1364.6919902234586,
            "rating_q975": 1413.4810451377218,
            "rating_q025": 1315.9029353091953
        },
        "mistral-small-2506": {
            "rating": 1359.3797122039873,
            "rating_q975": 1412.4281119911673,
            "rating_q025": 1306.3313124168074
        },
        "minimax-m1": {
            "rating": 1342.7435451410915,
            "rating_q975": 1386.1787816041067,
            "rating_q025": 1299.3083086780764
        },
        "deepseek-v3": {
            "rating": 1341.6101497314364,
            "rating_q975": 1386.1337804749512,
            "rating_q025": 1297.0865189879214
        },
        "grok-3-mini-high": {
            "rating": 1333.5489610354928,
            "rating_q975": 1379.7040005821975,
            "rating_q025": 1287.393921488788
        },
        "deepseek-v3-0324": {
            "rating": 1332.9690839753512,
            "rating_q975": 1365.4914344257704,
            "rating_q025": 1300.4467335249317
        },
        "gemma-3-27b-it": {
            "rating": 1332.4030590399104,
            "rating_q975": 1364.4269395813283,
            "rating_q025": 1300.3791784984926
        },
        "o1-2024-12-17": {
            "rating": 1331.1961730930796,
            "rating_q975": 1377.0754214530439,
            "rating_q025": 1285.3169247331155
        },
        "qwq-32b": {
            "rating": 1328.447615168893,
            "rating_q975": 1369.4386452986582,
            "rating_q025": 1287.4565850391275
        },
        "o3-mini-high": {
            "rating": 1325.115355390693,
            "rating_q975": 1372.9649391901012,
            "rating_q025": 1277.2657715912849
        },
        "gpt-4.1-mini-2025-04-14": {
            "rating": 1317.9946182219269,
            "rating_q975": 1351.4474077206094,
            "rating_q025": 1284.5418287232444
        },
        "amazon-nova-experimental-chat-05-14": {
            "rating": 1316.9955737653215,
            "rating_q975": 1362.1345474826112,
            "rating_q025": 1271.8566000480319
        },
        "kimi-k2-0711-preview": {
            "rating": 1316.652473438516,
            "rating_q975": 1367.4178587713154,
            "rating_q025": 1265.8870881057164
        },
        "qwen3-30b-a3b": {
            "rating": 1314.4066416649719,
            "rating_q975": 1351.9854174304858,
            "rating_q025": 1276.8278658994582
        },
        "yi-lightning": {
            "rating": 1311.9557176941507,
            "rating_q975": 1339.4460471133111,
            "rating_q025": 1284.4653882749903
        },
        "claude-sonnet-4-20250514-thinking-32k": {
            "rating": 1311.4491737618293,
            "rating_q975": 1353.7549438287729,
            "rating_q025": 1269.1434036948856
        },
        "o3-mini": {
            "rating": 1309.3963433428469,
            "rating_q975": 1339.2960820666378,
            "rating_q025": 1279.4966046190557
        },
        "gemini-2.0-flash-lite-preview-02-05": {
            "rating": 1308.9010094219484,
            "rating_q975": 1351.7770629470251,
            "rating_q025": 1266.0249558968717
        },
        "glm-4-plus": {
            "rating": 1305.9245299563588,
            "rating_q975": 1332.949853718088,
            "rating_q025": 1278.8992061946296
        },
        "o1-preview": {
            "rating": 1301.908112296632,
            "rating_q975": 1329.18145318443,
            "rating_q025": 1274.634771408834
        },
        "o1-mini": {
            "rating": 1300.7404132095771,
            "rating_q975": 1324.2330527707966,
            "rating_q025": 1277.2477736483577
        },
        "gemini-1.5-pro-002": {
            "rating": 1297.60898708565,
            "rating_q975": 1321.817273717536,
            "rating_q025": 1273.4007004537639
        },
        "claude-3-7-sonnet-20250219-thinking-32k": {
            "rating": 1297.4664666119074,
            "rating_q975": 1330.6412328266479,
            "rating_q025": 1264.291700397167
        },
        "mistral-small-3.1-24b-instruct-2503": {
            "rating": 1294.6693567695415,
            "rating_q975": 1337.9831611301315,
            "rating_q025": 1251.3555524089518
        },
        "gpt-4o-2024-05-13": {
            "rating": 1289.6193295047592,
            "rating_q975": 1304.5492821055252,
            "rating_q025": 1274.6893769039934
        },
        "claude-3-7-sonnet-20250219": {
            "rating": 1289.3457515244309,
            "rating_q975": 1320.5797031035231,
            "rating_q025": 1258.1117999453386
        },
        "claude-3-5-sonnet-20240620": {
            "rating": 1287.232362418726,
            "rating_q975": 1304.5596964925633,
            "rating_q025": 1269.905028344889
        },
        "qwen-max-0919": {
            "rating": 1285.0490675899123,
            "rating_q975": 1319.8885141871365,
            "rating_q025": 1250.209620992688
        },
        "claude-3-5-sonnet-20241022": {
            "rating": 1281.0852013254105,
            "rating_q975": 1301.2158785608387,
            "rating_q025": 1260.9545240899824
        },
        "grok-2-2024-08-13": {
            "rating": 1278.6555912445756,
            "rating_q975": 1297.5476380115247,
            "rating_q025": 1259.7635444776265
        },
        "gpt-4o-mini-2024-07-18": {
            "rating": 1278.2886532456632,
            "rating_q975": 1296.864151694557,
            "rating_q025": 1259.7131547967697
        },
        "llama-4-maverick-17b-128e-instruct": {
            "rating": 1277.9918878013,
            "rating_q975": 1313.6978537077348,
            "rating_q025": 1242.2859218948654
        },
        "grok-2-mini-2024-08-13": {
            "rating": 1275.4036566406894,
            "rating_q975": 1295.338856115394,
            "rating_q025": 1255.4684571659848
        },
        "athene-v2-chat": {
            "rating": 1271.7937292046074,
            "rating_q975": 1306.3935131413095,
            "rating_q025": 1237.1939452679053
        },
        "gpt-4o-2024-08-06": {
            "rating": 1271.7068610699132,
            "rating_q975": 1293.8935116519467,
            "rating_q025": 1249.5202104878797
        },
        "llama-4-scout-17b-16e-instruct": {
            "rating": 1270.7110688702633,
            "rating_q975": 1314.1450584400677,
            "rating_q025": 1227.2770793004593
        },
        "mistral-small-24b-instruct-2501": {
            "rating": 1270.6935076309899,
            "rating_q975": 1324.448511971372,
            "rating_q025": 1216.9385032906077
        },
        "gpt-4-1106-preview": {
            "rating": 1265.1855527492623,
            "rating_q975": 1282.180394297695,
            "rating_q025": 1248.1907112008296
        },
        "mistral-large-2411": {
            "rating": 1262.3209943890097,
            "rating_q975": 1303.431368245824,
            "rating_q025": 1221.2106205321952
        },
        "gpt-4-turbo-2024-04-09": {
            "rating": 1261.8165835222553,
            "rating_q975": 1277.806259908,
            "rating_q025": 1245.8269071365107
        },
        "llama-3.3-70b-instruct": {
            "rating": 1261.1083197786052,
            "rating_q975": 1289.496584686118,
            "rating_q025": 1232.7200548710925
        },
        "llama-3.1-405b-instruct-bf16": {
            "rating": 1260.4103529600452,
            "rating_q975": 1285.8563045921871,
            "rating_q025": 1234.9644013279035
        },
        "athene-70b-0725": {
            "rating": 1255.5326435435568,
            "rating_q975": 1286.261404779004,
            "rating_q025": 1224.8038823081097
        },
        "qwen2.5-72b-instruct": {
            "rating": 1255.371863555009,
            "rating_q975": 1281.5354913265353,
            "rating_q025": 1229.2082357834831
        },
        "claude-3-5-haiku-20241022": {
            "rating": 1255.066028854007,
            "rating_q975": 1282.3670535986714,
            "rating_q025": 1227.765004109343
        },
        "llama-3.1-405b-instruct-fp8": {
            "rating": 1254.079156337436,
            "rating_q975": 1273.7168898066411,
            "rating_q025": 1234.4414228682308
        },
        "gpt-4-0125-preview": {
            "rating": 1252.466563146177,
            "rating_q975": 1270.1753623188013,
            "rating_q025": 1234.7577639735525
        },
        "deepseek-v2.5": {
            "rating": 1251.889117573558,
            "rating_q975": 1280.6920987843118,
            "rating_q025": 1223.086136362804
        },
        "gemma-3n-e4b-it": {
            "rating": 1251.6723560104865,
            "rating_q975": 1292.6595978740213,
            "rating_q025": 1210.6851141469517
        },
        "claude-3-opus-20240229": {
            "rating": 1251.1222857601733,
            "rating_q975": 1264.5829404940664,
            "rating_q025": 1237.66163102628
        },
        "llama-3.1-70b-instruct": {
            "rating": 1250.2915175213238,
            "rating_q975": 1270.1430518571783,
            "rating_q025": 1230.4399831854696
        },
        "llama-3-70b-instruct": {
            "rating": 1245.775874729039,
            "rating_q975": 1259.9929541812394,
            "rating_q025": 1231.558795276839
        },
        "gemini-1.5-pro-001": {
            "rating": 1244.320765626263,
            "rating_q975": 1261.1912770883077,
            "rating_q025": 1227.4502541642187
        },
        "gemini-advanced-0514": {
            "rating": 1243.3065996956966,
            "rating_q975": 1262.809398466547,
            "rating_q025": 1223.8038009248462
        },
        "gemini-1.5-flash-002": {
            "rating": 1238.3323474423282,
            "rating_q975": 1266.7073461116984,
            "rating_q025": 1209.957348772958
        },
        "mistral-large-2407": {
            "rating": 1238.2138699708134,
            "rating_q975": 1258.71261069447,
            "rating_q025": 1217.7151292471572
        },
        "amazon-nova-lite-v1.0": {
            "rating": 1234.0979251886893,
            "rating_q975": 1280.876111241782,
            "rating_q025": 1187.3197391355966
        },
        "phi-4": {
            "rating": 1228.3190182529781,
            "rating_q975": 1277.328983270675,
            "rating_q025": 1179.3090532352812
        },
        "gemini-1.5-flash-001": {
            "rating": 1228.3075772649586,
            "rating_q975": 1245.5069640467684,
            "rating_q025": 1211.1081904831487
        },
        "gemma-2-27b-it": {
            "rating": 1227.2891090658695,
            "rating_q975": 1245.09292212984,
            "rating_q025": 1209.4852960018993
        },
        "amazon-nova-micro-v1.0": {
            "rating": 1227.0032246910462,
            "rating_q975": 1268.8492289509913,
            "rating_q025": 1185.157220431101
        },
        "gemini-1.5-flash-8b-001": {
            "rating": 1217.343668765374,
            "rating_q975": 1243.9475038799644,
            "rating_q025": 1190.7398336507836
        },
        "claude-3-sonnet-20240229": {
            "rating": 1211.7337898920534,
            "rating_q975": 1228.8099782423653,
            "rating_q025": 1194.6576015417415
        },
        "gemma-2-9b-it": {
            "rating": 1204.0933531474057,
            "rating_q975": 1225.2183580393894,
            "rating_q025": 1182.968348255422
        },
        "gpt-4-0314": {
            "rating": 1202.770825391068,
            "rating_q975": 1226.521160181797,
            "rating_q025": 1179.0204906003387
        },
        "c4ai-aya-expanse-32b": {
            "rating": 1202.4664906464022,
            "rating_q975": 1232.8368758659992,
            "rating_q025": 1172.0961054268053
        },
        "nemotron-4-340b-instruct": {
            "rating": 1200.7525332569835,
            "rating_q975": 1228.0281385972373,
            "rating_q025": 1173.4769279167294
        },
        "mistral-large-2402": {
            "rating": 1199.473283143741,
            "rating_q975": 1219.814312056704,
            "rating_q025": 1179.1322542307773
        },
        "command-r-plus": {
            "rating": 1192.617638559348,
            "rating_q975": 1210.493780745681,
            "rating_q025": 1174.741496373015
        },
        "amazon-nova-pro-v1.0": {
            "rating": 1190.2956095357245,
            "rating_q975": 1234.058283567899,
            "rating_q025": 1146.5329355035497
        },
        "llama-3-8b-instruct": {
            "rating": 1180.2921778702264,
            "rating_q975": 1196.3511476143753,
            "rating_q025": 1164.2332081260777
        },
        "qwen2-72b-instruct": {
            "rating": 1177.2147018630662,
            "rating_q975": 1200.3973582065446,
            "rating_q025": 1154.032045519588
        },
        "gpt-4-0613": {
            "rating": 1176.2342773307432,
            "rating_q975": 1193.7591006590771,
            "rating_q025": 1158.7094540024093
        },
        "llama-3.1-8b-instruct": {
            "rating": 1174.3271130250841,
            "rating_q975": 1196.2019321982327,
            "rating_q025": 1152.4522938519358
        },
        "claude-3-haiku-20240307": {
            "rating": 1173.8766884539125,
            "rating_q975": 1189.220381807802,
            "rating_q025": 1158.532995100023
        },
        "command-r": {
            "rating": 1158.9868852947966,
            "rating_q975": 1181.4259744599924,
            "rating_q025": 1136.5477961296006
        },
        "deepseek-coder-v2": {
            "rating": 1157.05941081193,
            "rating_q975": 1188.9876796578765,
            "rating_q025": 1125.1311419659837
        },
        "reka-flash-21b-20240226-online": {
            "rating": 1156.6133335104155,
            "rating_q975": 1194.7957040260983,
            "rating_q025": 1118.430962994733
        },
        "mixtral-8x22b-instruct-v0.1": {
            "rating": 1156.392872874768,
            "rating_q975": 1177.3330297794644,
            "rating_q025": 1135.4527159700717
        },
        "gemma-2-2b-it": {
            "rating": 1152.8258670669773,
            "rating_q975": 1175.3846884898576,
            "rating_q025": 1130.267045644097
        },
        "llama-2-70b-chat": {
            "rating": 1151.2367633363583,
            "rating_q975": 1176.7583784787923,
            "rating_q025": 1125.715148193924
        },
        "mistral-medium": {
            "rating": 1150.9050887824383,
            "rating_q975": 1179.6709997391483,
            "rating_q025": 1122.1391778257284
        },
        "qwen1.5-110b-chat": {
            "rating": 1150.6622737241917,
            "rating_q975": 1177.0405761289999,
            "rating_q025": 1124.2839713193835
        },
        "reka-flash-21b-20240226": {
            "rating": 1140.4709184042079,
            "rating_q975": 1168.5062821751317,
            "rating_q025": 1112.4355546332838
        },
        "yi-1.5-34b-chat": {
            "rating": 1127.966569616366,
            "rating_q975": 1154.4571459169335,
            "rating_q025": 1101.4759933157989
        },
        "gpt-3.5-turbo-0125": {
            "rating": 1127.188642638732,
            "rating_q975": 1147.7400827614795,
            "rating_q025": 1106.6372025159844
        },
        "gemini-pro-dev-api": {
            "rating": 1125.684036821701,
            "rating_q975": 1164.2436506403606,
            "rating_q025": 1087.1244230030416
        },
        "mixtral-8x7b-instruct-v0.1": {
            "rating": 1119.5490066933544,
            "rating_q975": 1138.8810107157828,
            "rating_q025": 1100.2170026709261
        },
        "phi-3-small-8k-instruct": {
            "rating": 1118.6746293320596,
            "rating_q975": 1151.9421419505982,
            "rating_q025": 1085.407116713521
        },
        "qwen1.5-72b-chat": {
            "rating": 1116.690800059278,
            "rating_q975": 1143.0308587260902,
            "rating_q025": 1090.350741392466
        },
        "phi-3-medium-4k-instruct": {
            "rating": 1105.263785488074,
            "rating_q975": 1131.8886149863865,
            "rating_q025": 1078.6389559897614
        },
        "gpt-3.5-turbo-1106": {
            "rating": 1101.0781892901211,
            "rating_q975": 1139.2680118692456,
            "rating_q025": 1062.888366710997
        },
        "phi-3-mini-4k-instruct": {
            "rating": 1098.823962323263,
            "rating_q975": 1125.889740924003,
            "rating_q025": 1071.758183722523
        },
        "qwen1.5-32b-chat": {
            "rating": 1096.8937844032284,
            "rating_q975": 1124.5822744062307,
            "rating_q025": 1069.2052944002264
        },
        "snowflake-arctic-instruct": {
            "rating": 1096.8366470266023,
            "rating_q975": 1123.3911525685655,
            "rating_q025": 1070.2821414846392
        },
        "llama-2-13b-chat": {
            "rating": 1096.3831375493528,
            "rating_q975": 1133.0138677055213,
            "rating_q025": 1059.7524073931845
        },
        "qwen1.5-14b-chat": {
            "rating": 1092.815797920421,
            "rating_q975": 1125.2160508437114,
            "rating_q025": 1060.4155449971304
        },
        "vicuna-33b": {
            "rating": 1086.2588899006605,
            "rating_q975": 1121.2731885976618,
            "rating_q025": 1051.2445912036594
        },
        "vicuna-13b": {
            "rating": 1085.024772866324,
            "rating_q975": 1131.7828845124534,
            "rating_q025": 1038.2666612201945
        },
        "yi-34b-chat": {
            "rating": 1082.6685753711517,
            "rating_q975": 1121.0285461951735,
            "rating_q025": 1044.3086045471302
        },
        "zephyr-7b-beta": {
            "rating": 1081.779061763032,
            "rating_q975": 1135.8337798018185,
            "rating_q025": 1027.7243437242453
        },
        "dbrx-instruct-preview": {
            "rating": 1075.0493478654307,
            "rating_q975": 1103.975218379094,
            "rating_q025": 1046.1234773517674
        },
        "phi-3-mini-128k-instruct": {
            "rating": 1065.4870068031432,
            "rating_q975": 1096.9021145015865,
            "rating_q025": 1034.0718991047
        },
        "gemma-1.1-7b-it": {
            "rating": 1064.5948371169675,
            "rating_q975": 1092.9531735652915,
            "rating_q025": 1036.2365006686437
        },
        "mistral-7b-instruct-v0.2": {
            "rating": 1033.0798179156952,
            "rating_q975": 1076.0280878744388,
            "rating_q025": 990.1315479569516
        },
        "llama-2-7b-chat": {
            "rating": 1016.6439541482926,
            "rating_q975": 1065.6995044100995,
            "rating_q025": 967.5884038864854
        },
        "gemma-1.1-2b-it": {
            "rating": 992.8133900708785,
            "rating_q975": 1039.351816746985,
            "rating_q025": 946.2749633947722
        }
    }
}