{
    "chinese": {
        "gemini-3-pro": {
            "rating": 1521.5315484193638,
            "rating_q975": 1541.616721123487,
            "rating_q025": 1501.4463757152407
        },
        "grok-4.1": {
            "rating": 1517.141495225639,
            "rating_q975": 1536.6938197960528,
            "rating_q025": 1497.589170655225
        },
        "grok-4.1-thinking": {
            "rating": 1508.5118921251717,
            "rating_q975": 1528.7319539703992,
            "rating_q025": 1488.2918302799442
        },
        "gemini-2.5-pro": {
            "rating": 1497.2069336154111,
            "rating_q975": 1508.2103310079117,
            "rating_q025": 1486.2035362229105
        },
        "gpt-5.1-high": {
            "rating": 1494.9097467862316,
            "rating_q975": 1517.131639239902,
            "rating_q025": 1472.6878543325613
        },
        "claude-opus-4-5-20251101-thinking-32k": {
            "rating": 1489.501176040322,
            "rating_q975": 1514.03906093172,
            "rating_q025": 1464.9632911489239
        },
        "qwen3-max-preview": {
            "rating": 1488.6350832152777,
            "rating_q975": 1504.7481782237603,
            "rating_q025": 1472.5219882067952
        },
        "ernie-5.0-preview-1103": {
            "rating": 1487.8623675721535,
            "rating_q975": 1520.4764544378493,
            "rating_q025": 1455.2482807064578
        },
        "glm-4.6": {
            "rating": 1485.2838131248407,
            "rating_q975": 1504.218024895282,
            "rating_q025": 1466.3496013543993
        },
        "claude-opus-4-5-20251101": {
            "rating": 1481.3722580606593,
            "rating_q975": 1507.4885955481295,
            "rating_q025": 1455.255920573189
        },
        "grok-4-fast-chat": {
            "rating": 1474.904943791931,
            "rating_q975": 1506.0316304835515,
            "rating_q025": 1443.7782571003104
        },
        "deepseek-v3.1-thinking": {
            "rating": 1473.8832687745883,
            "rating_q975": 1494.469708832435,
            "rating_q025": 1453.2968287167416
        },
        "deepseek-v3.2-exp": {
            "rating": 1472.3968955131738,
            "rating_q975": 1495.9065390863364,
            "rating_q025": 1448.8872519400113
        },
        "claude-sonnet-4-5-20250929": {
            "rating": 1469.8347547916665,
            "rating_q975": 1489.3629550226046,
            "rating_q025": 1450.3065545607283
        },
        "gpt-5.1": {
            "rating": 1468.0618079820326,
            "rating_q975": 1489.4663705777114,
            "rating_q025": 1446.657245386354
        },
        "qwen3-235b-a22b-instruct-2507": {
            "rating": 1465.077608134235,
            "rating_q975": 1477.5005416547224,
            "rating_q025": 1452.6546746137478
        },
        "deepseek-v3.1": {
            "rating": 1463.144602457437,
            "rating_q975": 1481.3588899422657,
            "rating_q025": 1444.9303149726084
        },
        "chatgpt-4o-latest-20250326": {
            "rating": 1460.540670533252,
            "rating_q975": 1471.7346996622687,
            "rating_q025": 1449.3466414042355
        },
        "o3-2025-04-16": {
            "rating": 1458.9307444550554,
            "rating_q975": 1470.5755977398483,
            "rating_q025": 1447.2858911702626
        },
        "claude-sonnet-4-5-20250929-thinking-32k": {
            "rating": 1457.5007663421513,
            "rating_q975": 1475.217442270838,
            "rating_q025": 1439.7840904134646
        },
        "kimi-k2-thinking-turbo": {
            "rating": 1456.994072122257,
            "rating_q975": 1478.193019609476,
            "rating_q025": 1435.7951246350378
        },
        "qwen3-vl-235b-a22b-instruct": {
            "rating": 1456.0357768319204,
            "rating_q975": 1486.7573631816367,
            "rating_q025": 1425.3141904822041
        },
        "deepseek-v3.2-exp-thinking": {
            "rating": 1455.8694951132934,
            "rating_q975": 1490.3749414406675,
            "rating_q025": 1421.3640487859193
        },
        "gpt-5-high": {
            "rating": 1455.5997928940337,
            "rating_q975": 1471.832420100537,
            "rating_q025": 1439.3671656875304
        },
        "deepseek-v3.2-thinking": {
            "rating": 1452.5688611305081,
            "rating_q975": 1484.8243679590946,
            "rating_q025": 1420.3133543019217
        },
        "claude-opus-4-1-20250805": {
            "rating": 1452.0043487265084,
            "rating_q975": 1463.877093930101,
            "rating_q025": 1440.1316035229158
        },
        "qwen3-next-80b-a3b-instruct": {
            "rating": 1451.2569694559452,
            "rating_q975": 1469.4168759897098,
            "rating_q025": 1433.0970629221806
        },
        "kimi-k2-0711-preview": {
            "rating": 1449.0648183791093,
            "rating_q975": 1464.4012546410663,
            "rating_q025": 1433.7283821171523
        },
        "gpt-4.5-preview-2025-02-27": {
            "rating": 1448.0473051342542,
            "rating_q975": 1467.2787245104787,
            "rating_q025": 1428.8158857580297
        },
        "claude-opus-4-1-20250805-thinking-16k": {
            "rating": 1447.2514420918783,
            "rating_q975": 1460.550668714921,
            "rating_q025": 1433.9522154688357
        },
        "deepseek-v3.2": {
            "rating": 1446.4805799449814,
            "rating_q975": 1473.8992897359255,
            "rating_q025": 1419.0618701540373
        },
        "gemini-2.5-flash-preview-09-2025": {
            "rating": 1446.464411742906,
            "rating_q975": 1464.3403877636906,
            "rating_q025": 1428.5884357221212
        },
        "kimi-k2-0905-preview": {
            "rating": 1444.0730069943181,
            "rating_q975": 1466.1487256353178,
            "rating_q025": 1421.9972883533185
        },
        "qwen3-max-2025-09-23": {
            "rating": 1444.0444930750664,
            "rating_q975": 1474.345441524909,
            "rating_q025": 1413.7435446252239
        },
        "qwen3-235b-a22b-thinking-2507": {
            "rating": 1443.8051863748651,
            "rating_q975": 1472.158653714496,
            "rating_q025": 1415.4517190352342
        },
        "deepseek-r1-0528": {
            "rating": 1441.28530161479,
            "rating_q975": 1460.2963395789677,
            "rating_q025": 1422.274263650612
        },
        "claude-opus-4-20250514-thinking-16k": {
            "rating": 1440.7987628289497,
            "rating_q975": 1454.6754291262655,
            "rating_q025": 1426.922096531634
        },
        "qwen3-vl-235b-a22b-thinking": {
            "rating": 1440.1042498888444,
            "rating_q975": 1475.1215867825456,
            "rating_q025": 1405.0869129951432
        },
        "gpt-5-chat": {
            "rating": 1437.7673102488975,
            "rating_q975": 1453.0004461332069,
            "rating_q025": 1422.5341743645881
        },
        "grok-4-1-fast-reasoning": {
            "rating": 1437.6673153241582,
            "rating_q975": 1464.7785837473002,
            "rating_q025": 1410.556046901016
        },
        "gemini-2.5-flash": {
            "rating": 1437.177400080169,
            "rating_q975": 1447.7486119210585,
            "rating_q025": 1426.6061882392796
        },
        "claude-opus-4-20250514": {
            "rating": 1437.1058714222686,
            "rating_q975": 1449.4791007241636,
            "rating_q025": 1424.7326421203736
        },
        "glm-4.5": {
            "rating": 1435.780266648055,
            "rating_q975": 1452.6560064535595,
            "rating_q025": 1418.9045268425505
        },
        "qwen3-235b-a22b-no-thinking": {
            "rating": 1434.8890100636684,
            "rating_q975": 1448.5848033137706,
            "rating_q025": 1421.193216813566
        },
        "grok-4-0709": {
            "rating": 1432.1566377840502,
            "rating_q975": 1446.0448850162884,
            "rating_q025": 1418.268390551812
        },
        "qwen3-30b-a3b-instruct-2507": {
            "rating": 1432.0699599994048,
            "rating_q975": 1448.8441932314909,
            "rating_q025": 1415.2957267673187
        },
        "grok-4-fast-reasoning": {
            "rating": 1431.490243755304,
            "rating_q975": 1454.3464777578406,
            "rating_q025": 1408.6340097527673
        },
        "grok-3-preview-02-24": {
            "rating": 1427.9953070383604,
            "rating_q975": 1442.2259863744819,
            "rating_q025": 1413.7646277022388
        },
        "o1-2024-12-17": {
            "rating": 1425.595517587647,
            "rating_q975": 1439.3594642107903,
            "rating_q025": 1411.8315709645037
        },
        "hunyuan-turbos-20250416": {
            "rating": 1423.3672794246852,
            "rating_q975": 1450.173093056781,
            "rating_q025": 1396.5614657925894
        },
        "mistral-large-3": {
            "rating": 1421.8169028475738,
            "rating_q975": 1453.312461086478,
            "rating_q025": 1390.3213446086697
        },
        "claude-haiku-4-5-20251001": {
            "rating": 1421.2264192984173,
            "rating_q975": 1438.9494046581742,
            "rating_q025": 1403.5034339386605
        },
        "deepseek-r1": {
            "rating": 1420.1992043696584,
            "rating_q975": 1437.8144080781467,
            "rating_q025": 1402.5840006611702
        },
        "mistral-medium-2508": {
            "rating": 1419.9658967268922,
            "rating_q975": 1433.068473495556,
            "rating_q025": 1406.8633199582284
        },
        "hunyuan-t1-20250711": {
            "rating": 1414.248339808246,
            "rating_q975": 1451.3476169696878,
            "rating_q025": 1377.1490626468044
        },
        "longcat-flash-chat": {
            "rating": 1413.794745972475,
            "rating_q975": 1437.4013773944043,
            "rating_q025": 1390.1881145505458
        },
        "gpt-4.1-2025-04-14": {
            "rating": 1409.5064245749943,
            "rating_q975": 1421.832215628441,
            "rating_q025": 1397.1806335215476
        },
        "gpt-5-mini-high": {
            "rating": 1408.6077855139579,
            "rating_q975": 1425.7778222323948,
            "rating_q025": 1391.437748795521
        },
        "claude-sonnet-4-20250514-thinking-32k": {
            "rating": 1406.5119352119304,
            "rating_q975": 1420.5991016601577,
            "rating_q025": 1392.4247687637032
        },
        "deepseek-v3-0324": {
            "rating": 1406.3389100398608,
            "rating_q975": 1418.5699911560243,
            "rating_q025": 1394.1078289236973
        },
        "o3-mini-high": {
            "rating": 1406.2527931558398,
            "rating_q975": 1423.141004579184,
            "rating_q025": 1389.3645817324955
        },
        "glm-4.5-air": {
            "rating": 1405.5623945683262,
            "rating_q975": 1420.7976165716914,
            "rating_q025": 1390.327172564961
        },
        "qwen3-next-80b-a3b-thinking": {
            "rating": 1404.2900973020776,
            "rating_q975": 1426.214602567495,
            "rating_q025": 1382.3655920366602
        },
        "gemini-2.5-flash-lite-preview-09-2025-no-thinking": {
            "rating": 1398.9145698509299,
            "rating_q975": 1416.350296780011,
            "rating_q025": 1381.4788429218488
        },
        "glm-4-plus-0111": {
            "rating": 1398.1405898061607,
            "rating_q975": 1428.0730937761125,
            "rating_q025": 1368.208085836209
        },
        "gemini-2.5-flash-lite-preview-06-17-thinking": {
            "rating": 1397.8202332223104,
            "rating_q975": 1412.4478181021266,
            "rating_q025": 1383.1926483424943
        },
        "claude-sonnet-4-20250514": {
            "rating": 1395.971047639055,
            "rating_q975": 1408.99520467934,
            "rating_q025": 1382.94689059877
        },
        "qwen3-coder-480b-a35b-instruct": {
            "rating": 1395.3824381384443,
            "rating_q975": 1412.8288910737035,
            "rating_q025": 1377.935985203185
        },
        "o4-mini-2025-04-16": {
            "rating": 1394.453307240723,
            "rating_q975": 1407.161667025702,
            "rating_q025": 1381.744947455744
        },
        "hunyuan-turbo-0110": {
            "rating": 1389.9827529097229,
            "rating_q975": 1428.9003037868697,
            "rating_q025": 1351.065202032576
        },
        "qwen2.5-max": {
            "rating": 1389.750600250605,
            "rating_q975": 1402.4703041961307,
            "rating_q025": 1377.0308963050793
        },
        "claude-3-7-sonnet-20250219-thinking-32k": {
            "rating": 1389.5120946634845,
            "rating_q975": 1402.9504731822424,
            "rating_q025": 1376.0737161447266
        },
        "minimax-m2": {
            "rating": 1388.5939657337753,
            "rating_q975": 1423.28514985583,
            "rating_q025": 1353.9027816117207
        },
        "qwen3-235b-a22b": {
            "rating": 1388.5402425658021,
            "rating_q975": 1404.9351689504604,
            "rating_q025": 1372.145316181144
        },
        "grok-3-mini-high": {
            "rating": 1387.8035393835246,
            "rating_q975": 1409.8579180486397,
            "rating_q025": 1365.7491607184095
        },
        "mai-1-preview": {
            "rating": 1386.7546044012663,
            "rating_q975": 1405.379991873491,
            "rating_q025": 1368.1292169290416
        },
        "mistral-medium-2505": {
            "rating": 1384.336672395726,
            "rating_q975": 1398.8020223650472,
            "rating_q025": 1369.871322426405
        },
        "step-3": {
            "rating": 1383.7054781120632,
            "rating_q975": 1421.546396599251,
            "rating_q025": 1345.8645596248755
        },
        "gemini-2.0-flash-001": {
            "rating": 1383.353084387793,
            "rating_q975": 1395.3414448725894,
            "rating_q025": 1371.3647239029965
        },
        "hunyuan-large-2025-02-10": {
            "rating": 1380.4824923719873,
            "rating_q975": 1412.9727809866638,
            "rating_q025": 1347.9922037573108
        },
        "ling-flash-2.0": {
            "rating": 1380.3513307055944,
            "rating_q975": 1413.4833827090818,
            "rating_q025": 1347.219278702107
        },
        "o1-preview": {
            "rating": 1380.3436366945864,
            "rating_q975": 1392.1259836753113,
            "rating_q025": 1368.5612897138615
        },
        "minimax-m1": {
            "rating": 1378.9498824311959,
            "rating_q975": 1393.1170697164332,
            "rating_q025": 1364.7826951459585
        },
        "gpt-4.1-mini-2025-04-14": {
            "rating": 1378.6378543777412,
            "rating_q975": 1392.0625243622978,
            "rating_q025": 1365.2131843931845
        },
        "gpt-5-nano-high": {
            "rating": 1375.2650350918516,
            "rating_q975": 1405.2719333472257,
            "rating_q025": 1345.2581368364774
        },
        "claude-3-7-sonnet-20250219": {
            "rating": 1374.5039550307336,
            "rating_q975": 1387.00293446649,
            "rating_q025": 1362.0049755949772
        },
        "ring-flash-2.0": {
            "rating": 1373.9256442295723,
            "rating_q975": 1405.9688626802092,
            "rating_q025": 1341.8824257789354
        },
        "qwq-32b": {
            "rating": 1373.4123113771748,
            "rating_q975": 1389.1533286138163,
            "rating_q025": 1357.6712941405333
        },
        "grok-3-mini-beta": {
            "rating": 1371.0179490699784,
            "rating_q975": 1388.8083860328823,
            "rating_q025": 1353.2275121070745
        },
        "qwen-plus-0125": {
            "rating": 1369.299119840535,
            "rating_q975": 1396.11674003676,
            "rating_q025": 1342.4814996443101
        },
        "gemini-1.5-pro-002": {
            "rating": 1367.5370626717106,
            "rating_q975": 1376.7867225177301,
            "rating_q025": 1358.287402825691
        },
        "qwen3-30b-a3b": {
            "rating": 1366.6945433854687,
            "rating_q975": 1383.2798074670243,
            "rating_q025": 1350.1092793039131
        },
        "gemma-3-27b-it": {
            "rating": 1365.1738500030415,
            "rating_q975": 1377.7850771760052,
            "rating_q025": 1352.5626228300778
        },
        "deepseek-v3": {
            "rating": 1363.0486690313908,
            "rating_q975": 1377.9601425834596,
            "rating_q025": 1348.137195479322
        },
        "gemini-2.0-flash-lite-preview-02-05": {
            "rating": 1363.0484838213983,
            "rating_q975": 1377.5445210401638,
            "rating_q025": 1348.552446602633
        },
        "hunyuan-turbos-20250226": {
            "rating": 1362.2702749931518,
            "rating_q975": 1401.3063332378676,
            "rating_q025": 1323.234216748436
        },
        "gpt-oss-120b": {
            "rating": 1361.074016668626,
            "rating_q975": 1376.473507284427,
            "rating_q025": 1345.674526052825
        },
        "claude-3-5-sonnet-20241022": {
            "rating": 1359.0123114312767,
            "rating_q975": 1366.8384196005582,
            "rating_q025": 1351.1862032619952
        },
        "o3-mini": {
            "rating": 1358.058497842784,
            "rating_q975": 1368.3363188519818,
            "rating_q025": 1347.780676833586
        },
        "step-2-16k-exp-202412": {
            "rating": 1357.8463500936225,
            "rating_q975": 1391.3987719940662,
            "rating_q025": 1324.2939281931788
        },
        "qwen3-32b": {
            "rating": 1356.2766874456213,
            "rating_q975": 1394.561764197792,
            "rating_q025": 1317.9916106934506
        },
        "yi-lightning": {
            "rating": 1354.9622669918972,
            "rating_q975": 1366.5747845131339,
            "rating_q025": 1343.3497494706605
        },
        "hunyuan-standard-2025-02-10": {
            "rating": 1354.4672760266772,
            "rating_q975": 1385.5205291931113,
            "rating_q025": 1323.414022860243
        },
        "step-1o-turbo-202506": {
            "rating": 1353.336217362378,
            "rating_q975": 1379.714868537255,
            "rating_q025": 1326.957566187501
        },
        "command-a-03-2025": {
            "rating": 1350.5561193682208,
            "rating_q975": 1361.885837916209,
            "rating_q025": 1339.2264008202326
        },
        "deepseek-v2.5-1210": {
            "rating": 1348.739603089633,
            "rating_q975": 1374.8064485716461,
            "rating_q025": 1322.6727576076198
        },
        "gpt-oss-20b": {
            "rating": 1345.5300847068559,
            "rating_q975": 1372.554261394437,
            "rating_q025": 1318.5059080192748
        },
        "mistral-small-2506": {
            "rating": 1344.2767101985457,
            "rating_q975": 1363.9732313606032,
            "rating_q025": 1324.5801890364883
        },
        "amazon-nova-experimental-chat-10-09": {
            "rating": 1343.3742629034518,
            "rating_q975": 1372.2747791187408,
            "rating_q025": 1314.473746688163
        },
        "o1-mini": {
            "rating": 1342.8972570187384,
            "rating_q975": 1352.3436510095637,
            "rating_q025": 1333.450863027913
        },
        "glm-4.5v": {
            "rating": 1340.957995767945,
            "rating_q975": 1384.0856684405603,
            "rating_q025": 1297.8303230953297
        },
        "amazon-nova-experimental-chat-10-20": {
            "rating": 1340.4751560491734,
            "rating_q975": 1369.9297427735944,
            "rating_q025": 1311.0205693247524
        },
        "gemini-advanced-0514": {
            "rating": 1339.630237991989,
            "rating_q975": 1350.1071801476864,
            "rating_q025": 1329.1532958362914
        },
        "claude-3-5-sonnet-20240620": {
            "rating": 1338.6532536026011,
            "rating_q975": 1347.2223461575563,
            "rating_q025": 1330.084161047646
        },
        "glm-4-plus": {
            "rating": 1335.1326111129094,
            "rating_q975": 1347.492557246566,
            "rating_q025": 1322.7726649792528
        },
        "grok-2-2024-08-13": {
            "rating": 1334.1691247074814,
            "rating_q975": 1342.871602520568,
            "rating_q025": 1325.4666468943947
        },
        "gemini-1.5-pro-001": {
            "rating": 1334.0135239255715,
            "rating_q975": 1343.0440780743177,
            "rating_q025": 1324.9829697768253
        },
        "gpt-4o-2024-05-13": {
            "rating": 1331.681767699768,
            "rating_q975": 1339.3479036587592,
            "rating_q025": 1324.0156317407768
        },
        "athene-v2-chat": {
            "rating": 1327.6180954419583,
            "rating_q975": 1341.1159551495953,
            "rating_q025": 1314.1202357343213
        },
        "llama-4-maverick-17b-128e-instruct": {
            "rating": 1326.9726876656996,
            "rating_q975": 1340.3581582297136,
            "rating_q025": 1313.5872171016856
        },
        "deepseek-v2.5": {
            "rating": 1324.1951439972056,
            "rating_q975": 1336.7277363304845,
            "rating_q025": 1311.6625516639267
        },
        "qwen2.5-plus-1127": {
            "rating": 1323.541047843962,
            "rating_q975": 1345.9148721927268,
            "rating_q025": 1301.167223495197
        },
        "gemma-3n-e4b-it": {
            "rating": 1322.5380725828072,
            "rating_q975": 1340.1013091638433,
            "rating_q025": 1304.974836001771
        },
        "gpt-4o-2024-08-06": {
            "rating": 1322.4965209959755,
            "rating_q975": 1332.434808022466,
            "rating_q025": 1312.558233969485
        },
        "claude-3-opus-20240229": {
            "rating": 1318.9267020128445,
            "rating_q975": 1326.0020934629094,
            "rating_q025": 1311.8513105627796
        },
        "gemini-1.5-flash-002": {
            "rating": 1318.5757712441555,
            "rating_q975": 1329.3914962948963,
            "rating_q025": 1307.7600461934146
        },
        "llama-3.1-405b-instruct-bf16": {
            "rating": 1315.7257064905068,
            "rating_q975": 1326.201503599982,
            "rating_q025": 1305.2499093810316
        },
        "qwen2.5-72b-instruct": {
            "rating": 1315.5991216145053,
            "rating_q975": 1325.9257421688167,
            "rating_q025": 1305.272501060194
        },
        "gpt-4.1-nano-2025-04-14": {
            "rating": 1311.0056203563533,
            "rating_q975": 1347.1384618332552,
            "rating_q025": 1274.8727788794515
        },
        "gpt-4-turbo-2024-04-09": {
            "rating": 1309.9615226752335,
            "rating_q975": 1318.522175110558,
            "rating_q025": 1301.400870239909
        },
        "gpt-4-1106-preview": {
            "rating": 1308.9354744025386,
            "rating_q975": 1318.1215785056734,
            "rating_q025": 1299.7493702994038
        },
        "gpt-4o-mini-2024-07-18": {
            "rating": 1308.442375462841,
            "rating_q975": 1316.765361408059,
            "rating_q025": 1300.119389517623
        },
        "llama-3.1-405b-instruct-fp8": {
            "rating": 1308.3173821006033,
            "rating_q975": 1317.2297069733681,
            "rating_q025": 1299.4050572278384
        },
        "claude-3-5-haiku-20241022": {
            "rating": 1308.157514844122,
            "rating_q975": 1317.7045136027698,
            "rating_q025": 1298.6105160854743
        },
        "nova-2-lite": {
            "rating": 1305.817497600067,
            "rating_q975": 1340.7471343387033,
            "rating_q025": 1270.887860861431
        },
        "gpt-4-0125-preview": {
            "rating": 1305.426854975044,
            "rating_q975": 1314.3879906473762,
            "rating_q025": 1296.465719302712
        },
        "llama-4-scout-17b-16e-instruct": {
            "rating": 1305.2864588331536,
            "rating_q975": 1320.8559493414664,
            "rating_q025": 1289.7169683248408
        },
        "grok-2-mini-2024-08-13": {
            "rating": 1304.2382871768887,
            "rating_q975": 1313.4594804940855,
            "rating_q025": 1295.0170938596918
        },
        "qwen-max-0919": {
            "rating": 1304.2118768691485,
            "rating_q975": 1319.2276332703407,
            "rating_q025": 1289.1961204679562
        },
        "hunyuan-large-vision": {
            "rating": 1304.07660137702,
            "rating_q975": 1341.5763030892429,
            "rating_q025": 1266.5768996647973
        },
        "llama-3.3-nemotron-49b-super-v1": {
            "rating": 1303.2585776175567,
            "rating_q975": 1341.591199016127,
            "rating_q025": 1264.9259562189866
        },
        "reka-core-20240904": {
            "rating": 1299.572715180678,
            "rating_q975": 1322.2400914573836,
            "rating_q025": 1276.9053389039723
        },
        "glm-4-0520": {
            "rating": 1298.295545842262,
            "rating_q975": 1314.8730542904984,
            "rating_q025": 1281.7180373940257
        },
        "llama-3.1-nemotron-70b-instruct": {
            "rating": 1297.6000657326185,
            "rating_q975": 1318.8074329589087,
            "rating_q025": 1276.3926985063283
        },
        "mistral-large-2407": {
            "rating": 1297.2714665806066,
            "rating_q975": 1307.1791437259153,
            "rating_q025": 1287.3637894352978
        },
        "qwen2-72b-instruct": {
            "rating": 1293.1474358101996,
            "rating_q975": 1303.994339196908,
            "rating_q025": 1282.3005324234912
        },
        "athene-70b-0725": {
            "rating": 1292.997112794072,
            "rating_q975": 1307.1905206736828,
            "rating_q025": 1278.8037049144614
        },
        "llama-3.1-tulu-3-70b": {
            "rating": 1292.4602997485986,
            "rating_q975": 1328.5389356875364,
            "rating_q025": 1256.3816638096607
        },
        "mistral-large-2411": {
            "rating": 1291.7318670926911,
            "rating_q975": 1304.7200695500044,
            "rating_q025": 1278.7436646353779
        },
        "reka-flash-20240904": {
            "rating": 1291.6819617065617,
            "rating_q975": 1314.57599591748,
            "rating_q025": 1268.7879274956433
        },
        "gemma-2-27b-it": {
            "rating": 1291.348099055853,
            "rating_q975": 1299.289792420641,
            "rating_q025": 1283.406405691065
        },
        "olmo-3-32b-think": {
            "rating": 1289.8525891964696,
            "rating_q975": 1346.9335845082528,
            "rating_q025": 1232.7715938846864
        },
        "gemini-1.5-flash-001": {
            "rating": 1288.331970237359,
            "rating_q975": 1297.7376793586282,
            "rating_q025": 1278.9262611160898
        },
        "command-r-plus-08-2024": {
            "rating": 1288.1582600537367,
            "rating_q975": 1307.384059054982,
            "rating_q025": 1268.9324610524916
        },
        "hunyuan-standard-256k": {
            "rating": 1286.98144789558,
            "rating_q975": 1319.9960639793856,
            "rating_q025": 1253.9668318117745
        },
        "llama-3.3-70b-instruct": {
            "rating": 1286.0243229844023,
            "rating_q975": 1296.421739472009,
            "rating_q025": 1275.6269064967955
        },
        "mistral-small-3.1-24b-instruct-2503": {
            "rating": 1285.405328072461,
            "rating_q975": 1300.9245372881203,
            "rating_q025": 1269.8861188568019
        },
        "amazon-nova-pro-v1.0": {
            "rating": 1284.1364879366743,
            "rating_q975": 1297.989334728962,
            "rating_q025": 1270.2836411443866
        },
        "gemma-2-9b-it-simpo": {
            "rating": 1282.8341654337619,
            "rating_q975": 1303.4800942373436,
            "rating_q025": 1262.1882366301802
        },
        "deepseek-coder-v2": {
            "rating": 1282.7555311756728,
            "rating_q975": 1297.214160917872,
            "rating_q025": 1268.2969014334735
        },
        "nemotron-4-340b-instruct": {
            "rating": 1280.4347844294157,
            "rating_q975": 1293.1410758440175,
            "rating_q025": 1267.728493014814
        },
        "gpt-4-0314": {
            "rating": 1280.3007751917157,
            "rating_q975": 1291.418224024208,
            "rating_q025": 1269.1833263592234
        },
        "magistral-medium-2506": {
            "rating": 1279.0762934569652,
            "rating_q975": 1306.7932018102945,
            "rating_q025": 1251.359385103636
        },
        "qwen1.5-72b-chat": {
            "rating": 1276.5199883503553,
            "rating_q975": 1288.149085022326,
            "rating_q025": 1264.8908916783846
        },
        "qwen2.5-coder-32b-instruct": {
            "rating": 1272.8527002196147,
            "rating_q975": 1297.443281027537,
            "rating_q025": 1248.2621194116923
        },
        "qwen1.5-110b-chat": {
            "rating": 1272.7846668400252,
            "rating_q975": 1285.3839374929357,
            "rating_q025": 1260.1853961871147
        },
        "llama-3.1-nemotron-51b-instruct": {
            "rating": 1270.5597726053302,
            "rating_q975": 1298.1506667517742,
            "rating_q025": 1242.9688784588861
        },
        "claude-3-sonnet-20240229": {
            "rating": 1270.4351828802678,
            "rating_q975": 1278.8940695128413,
            "rating_q025": 1261.9762962476943
        },
        "llama-3.1-70b-instruct": {
            "rating": 1270.0889125731746,
            "rating_q975": 1279.1889277285238,
            "rating_q025": 1260.9888974178255
        },
        "jamba-1.5-large": {
            "rating": 1268.673173671026,
            "rating_q975": 1290.2105216287084,
            "rating_q025": 1247.1358257133436
        },
        "yi-1.5-34b-chat": {
            "rating": 1267.8092273697346,
            "rating_q975": 1280.0492434998432,
            "rating_q025": 1255.569211239626
        },
        "gemini-1.5-flash-8b-001": {
            "rating": 1266.9528022889883,
            "rating_q975": 1277.9967569594378,
            "rating_q025": 1255.9088476185389
        },
        "amazon-nova-lite-v1.0": {
            "rating": 1266.2011021078924,
            "rating_q975": 1281.8380377126707,
            "rating_q025": 1250.5641665031142
        },
        "c4ai-aya-expanse-32b": {
            "rating": 1264.6328999519833,
            "rating_q975": 1276.5434739730592,
            "rating_q025": 1252.7223259309073
        },
        "command-r-plus": {
            "rating": 1263.6065333978554,
            "rating_q975": 1272.6754330397173,
            "rating_q025": 1254.5376337559935
        },
        "phi-4": {
            "rating": 1262.4605102699222,
            "rating_q975": 1277.5311500763346,
            "rating_q025": 1247.3898704635099
        },
        "qwen1.5-32b-chat": {
            "rating": 1261.1215619609416,
            "rating_q975": 1273.8797747913054,
            "rating_q025": 1248.3633491305777
        },
        "mistral-small-24b-instruct-2501": {
            "rating": 1259.028059766708,
            "rating_q975": 1276.2733721357238,
            "rating_q025": 1241.7827473976924
        },
        "gemma-2-9b-it": {
            "rating": 1256.2672190723702,
            "rating_q975": 1265.1905783529928,
            "rating_q025": 1247.3438597917475
        },
        "command-r-08-2024": {
            "rating": 1255.9611487472882,
            "rating_q975": 1275.8531049036176,
            "rating_q025": 1236.069192590959
        },
        "amazon-nova-micro-v1.0": {
            "rating": 1255.651912540392,
            "rating_q975": 1271.4097247064722,
            "rating_q025": 1239.8941003743118
        },
        "gpt-4-0613": {
            "rating": 1249.4709375063512,
            "rating_q975": 1259.1676876317786,
            "rating_q025": 1239.7741873809239
        },
        "ministral-8b-2410": {
            "rating": 1248.9249148082235,
            "rating_q975": 1274.2042787194277,
            "rating_q025": 1223.6455508970193
        },
        "yi-34b-chat": {
            "rating": 1245.2773825451459,
            "rating_q975": 1263.064324017005,
            "rating_q025": 1227.4904410732868
        },
        "internlm2_5-20b-chat": {
            "rating": 1243.3903813483475,
            "rating_q975": 1261.6796836775593,
            "rating_q025": 1225.1010790191358
        },
        "claude-3-haiku-20240307": {
            "rating": 1242.740422011489,
            "rating_q975": 1250.8268020447247,
            "rating_q025": 1234.6540419782534
        },
        "qwen1.5-14b-chat": {
            "rating": 1237.1745049548554,
            "rating_q975": 1250.5274248289136,
            "rating_q025": 1223.8215850807971
        },
        "olmo-2-0325-32b-instruct": {
            "rating": 1236.5408464670477,
            "rating_q975": 1272.2941004417312,
            "rating_q025": 1200.7875924923642
        },
        "qwq-32b-preview": {
            "rating": 1235.0671994919637,
            "rating_q975": 1274.4893706304636,
            "rating_q025": 1195.6450283534639
        },
        "command-r": {
            "rating": 1233.1910351895722,
            "rating_q975": 1243.268656732162,
            "rating_q025": 1223.1134136469823
        },
        "reka-flash-21b-20240226-online": {
            "rating": 1229.9162778273353,
            "rating_q975": 1244.6454323370913,
            "rating_q025": 1215.1871233175793
        },
        "c4ai-aya-expanse-8b": {
            "rating": 1229.3484411584727,
            "rating_q975": 1252.3814715963192,
            "rating_q025": 1206.3154107206262
        },
        "deepseek-llm-67b-chat": {
            "rating": 1226.6237760416093,
            "rating_q975": 1267.9958215365507,
            "rating_q025": 1185.2517305466679
        },
        "gemini-pro-dev-api": {
            "rating": 1226.5271345664687,
            "rating_q975": 1243.743533858451,
            "rating_q025": 1209.3107352744864
        },
        "qwen1.5-7b-chat": {
            "rating": 1220.264053807874,
            "rating_q975": 1248.6087706237786,
            "rating_q025": 1191.9193369919694
        },
        "reka-flash-21b-20240226": {
            "rating": 1219.9463854164749,
            "rating_q975": 1233.0251765314804,
            "rating_q025": 1206.8675943014694
        },
        "llama-3.1-tulu-3-8b": {
            "rating": 1215.8893402291565,
            "rating_q975": 1252.2791242152596,
            "rating_q025": 1179.4995562430533
        },
        "granite-3.1-8b-instruct": {
            "rating": 1213.5188874188593,
            "rating_q975": 1252.7098909840208,
            "rating_q025": 1174.3278838536978
        },
        "gemini-pro": {
            "rating": 1211.5129615168364,
            "rating_q975": 1249.5800352452113,
            "rating_q025": 1173.4458877884615
        },
        "jamba-1.5-mini": {
            "rating": 1210.91219031315,
            "rating_q975": 1232.2927745061065,
            "rating_q025": 1189.5316061201934
        },
        "mixtral-8x22b-instruct-v0.1": {
            "rating": 1205.3797576432962,
            "rating_q975": 1215.7997371492097,
            "rating_q025": 1194.9597781373827
        },
        "mistral-large-2402": {
            "rating": 1203.3500836388748,
            "rating_q975": 1213.360474415905,
            "rating_q025": 1193.3396928618447
        },
        "gpt-3.5-turbo-0125": {
            "rating": 1202.7051489636738,
            "rating_q975": 1212.3676158565795,
            "rating_q025": 1193.042682070768
        },
        "granite-3.1-2b-instruct": {
            "rating": 1202.4598207647869,
            "rating_q975": 1240.6835638345644,
            "rating_q025": 1164.2360776950093
        },
        "qwen-14b-chat": {
            "rating": 1197.8520321583883,
            "rating_q975": 1240.683112070683,
            "rating_q025": 1155.0209522460937
        },
        "llama-3.1-8b-instruct": {
            "rating": 1197.753202072581,
            "rating_q975": 1207.5988530545749,
            "rating_q025": 1187.907551090587
        },
        "llama-3-70b-instruct": {
            "rating": 1196.5143471905888,
            "rating_q975": 1204.7426131966802,
            "rating_q025": 1188.2860811844973
        },
        "phi-3-medium-4k-instruct": {
            "rating": 1195.5857128396908,
            "rating_q975": 1207.8797896008894,
            "rating_q025": 1183.2916360784923
        },
        "gemma-2-2b-it": {
            "rating": 1191.7665072535965,
            "rating_q975": 1202.1478545507173,
            "rating_q025": 1181.3851599564757
        },
        "mistral-medium": {
            "rating": 1191.470700230157,
            "rating_q975": 1204.5338210275477,
            "rating_q025": 1178.4075794327664
        },
        "zephyr-orpo-141b-A35b-v0.1": {
            "rating": 1181.1921288977892,
            "rating_q975": 1203.5665460346504,
            "rating_q025": 1158.817711760928
        },
        "dbrx-instruct-preview": {
            "rating": 1173.7718876297226,
            "rating_q975": 1186.2817484101035,
            "rating_q025": 1161.2620268493417
        },
        "openchat-3.5-0106": {
            "rating": 1173.3965652487618,
            "rating_q975": 1190.5320090420955,
            "rating_q025": 1156.261121455428
        },
        "openchat-3.5": {
            "rating": 1173.248806824652,
            "rating_q975": 1205.179888200972,
            "rating_q025": 1141.317725448332
        },
        "starling-lm-7b-beta": {
            "rating": 1172.4779386348255,
            "rating_q975": 1186.957490660875,
            "rating_q025": 1157.998386608776
        },
        "snowflake-arctic-instruct": {
            "rating": 1172.427000653045,
            "rating_q975": 1185.6917028831379,
            "rating_q025": 1159.1622984229523
        },
        "granite-3.0-2b-instruct": {
            "rating": 1170.3669907771132,
            "rating_q975": 1193.516804592915,
            "rating_q025": 1147.2171769613115
        },
        "gemma-1.1-7b-it": {
            "rating": 1168.614332009508,
            "rating_q975": 1180.674366255536,
            "rating_q025": 1156.55429776348
        },
        "granite-3.0-8b-instruct": {
            "rating": 1164.5431097734838,
            "rating_q975": 1187.8624509125184,
            "rating_q025": 1141.2237686344492
        },
        "chatglm3-6b": {
            "rating": 1162.7282570802763,
            "rating_q975": 1205.5472092158648,
            "rating_q025": 1119.9093049446878
        },
        "llama-3-8b-instruct": {
            "rating": 1160.5255718594237,
            "rating_q975": 1169.4703599039917,
            "rating_q025": 1151.5807838148557
        },
        "chatglm-6b": {
            "rating": 1158.9858570546444,
            "rating_q975": 1197.9497082446328,
            "rating_q025": 1120.022005864656
        },
        "gpt-3.5-turbo-1106": {
            "rating": 1157.123172341148,
            "rating_q975": 1181.3074268497933,
            "rating_q025": 1132.9389178325025
        },
        "wizardlm-70b": {
            "rating": 1153.4438811262116,
            "rating_q975": 1185.7308131546358,
            "rating_q025": 1121.1569490977874
        },
        "mixtral-8x7b-instruct-v0.1": {
            "rating": 1149.276722815055,
            "rating_q975": 1159.0420964121956,
            "rating_q025": 1139.5113492179146
        },
        "phi-3-small-8k-instruct": {
            "rating": 1145.577359144701,
            "rating_q975": 1159.1253447748636,
            "rating_q025": 1132.0293735145383
        },
        "vicuna-13b": {
            "rating": 1140.4453034266999,
            "rating_q975": 1159.7231381977288,
            "rating_q025": 1121.167468655671
        },
        "qwen1.5-4b-chat": {
            "rating": 1140.4370605205977,
            "rating_q975": 1160.0188093542731,
            "rating_q025": 1120.8553116869223
        },
        "gemma-7b-it": {
            "rating": 1132.3248589943132,
            "rating_q975": 1151.8418627735402,
            "rating_q025": 1112.8078552150862
        },
        "starling-lm-7b-alpha": {
            "rating": 1131.9310270109281,
            "rating_q975": 1153.4258826395248,
            "rating_q025": 1110.4361713823314
        },
        "gemma-1.1-2b-it": {
            "rating": 1131.6684271375786,
            "rating_q975": 1149.1769756350286,
            "rating_q025": 1114.1598786401287
        },
        "vicuna-33b": {
            "rating": 1128.9527245684512,
            "rating_q975": 1145.670964259863,
            "rating_q025": 1112.2344848770394
        },
        "llama-3.2-3b-instruct": {
            "rating": 1125.98963315113,
            "rating_q975": 1150.9318184525202,
            "rating_q025": 1101.0474478497397
        },
        "phi-3-mini-128k-instruct": {
            "rating": 1122.736599874649,
            "rating_q975": 1138.2325383296215,
            "rating_q025": 1107.2406614196766
        },
        "phi-3-mini-4k-instruct-june-2024": {
            "rating": 1119.725710503731,
            "rating_q975": 1137.1520773239101,
            "rating_q025": 1102.299343683552
        },
        "wizardlm-13b": {
            "rating": 1116.3541011321595,
            "rating_q975": 1149.5805907439212,
            "rating_q025": 1083.1276115203977
        },
        "openhermes-2.5-mistral-7b": {
            "rating": 1111.0283034240056,
            "rating_q975": 1153.3058822051576,
            "rating_q025": 1068.7507246428536
        },
        "phi-3-mini-4k-instruct": {
            "rating": 1108.929261537146,
            "rating_q975": 1122.9063311258124,
            "rating_q025": 1094.9521919484796
        },
        "mistral-7b-instruct-v0.2": {
            "rating": 1096.0052539657884,
            "rating_q975": 1110.7355516272198,
            "rating_q025": 1081.274956304357
        },
        "gemma-2b-it": {
            "rating": 1095.9404022430822,
            "rating_q975": 1120.9150413858677,
            "rating_q025": 1070.9657631002967
        },
        "tulu-2-dpo-70b": {
            "rating": 1093.504206762982,
            "rating_q975": 1128.603265888715,
            "rating_q025": 1058.405147637249
        },
        "mpt-7b-chat": {
            "rating": 1087.9443778883106,
            "rating_q975": 1129.830448278187,
            "rating_q025": 1046.058307498434
        },
        "llama-2-13b-chat": {
            "rating": 1086.2034308719055,
            "rating_q975": 1104.8297274269128,
            "rating_q025": 1067.5771343168983
        },
        "vicuna-7b": {
            "rating": 1081.3035864735666,
            "rating_q975": 1114.968525733104,
            "rating_q025": 1047.6386472140293
        },
        "codellama-34b-instruct": {
            "rating": 1078.6200695116074,
            "rating_q975": 1117.0597673192185,
            "rating_q025": 1040.1803717039963
        },
        "llama-2-70b-chat": {
            "rating": 1077.3607478864474,
            "rating_q975": 1090.3135479871835,
            "rating_q025": 1064.4079477857113
        },
        "olmo-7b-instruct": {
            "rating": 1074.152256743488,
            "rating_q975": 1097.2621415868423,
            "rating_q025": 1051.0423719001335
        },
        "palm-2": {
            "rating": 1063.831371131782,
            "rating_q975": 1097.9809998070382,
            "rating_q025": 1029.6817424565256
        },
        "llama-2-7b-chat": {
            "rating": 1057.7018194937164,
            "rating_q975": 1077.2215632985874,
            "rating_q025": 1038.1820756888453
        },
        "zephyr-7b-beta": {
            "rating": 1046.0286560727752,
            "rating_q975": 1076.8709368704317,
            "rating_q025": 1015.1863752751187
        },
        "llama-3.2-1b-instruct": {
            "rating": 1043.118329607185,
            "rating_q975": 1071.0011345584721,
            "rating_q025": 1015.2355246558977
        },
        "mistral-7b-instruct": {
            "rating": 1038.8330086643498,
            "rating_q975": 1072.4673727254603,
            "rating_q025": 1005.1986446032391
        },
        "RWKV-4-Raven-14B": {
            "rating": 1019.5996523076674,
            "rating_q975": 1059.9160819142107,
            "rating_q025": 979.283222701124
        },
        "koala-13b": {
            "rating": 988.722158608557,
            "rating_q975": 1021.8345202983057,
            "rating_q025": 955.6097969188083
        },
        "dolly-v2-12b": {
            "rating": 981.7062568640772,
            "rating_q975": 1029.4391977806742,
            "rating_q025": 933.9733159474802
        },
        "fastchat-t5-3b": {
            "rating": 931.7454732212879,
            "rating_q975": 973.3415250633396,
            "rating_q025": 890.1494213792361
        },
        "oasst-pythia-12b": {
            "rating": 930.8679315522891,
            "rating_q975": 965.7494853535514,
            "rating_q025": 895.9863777510267
        },
        "alpaca-13b": {
            "rating": 905.4857274002713,
            "rating_q975": 947.3543724350935,
            "rating_q025": 863.6170823654492
        }
    },
    "coding": {
        "claude-opus-4-5-20251101-thinking-32k": {
            "rating": 1538.2049212548282,
            "rating_q975": 1551.9403943156597,
            "rating_q025": 1524.4694481939966
        },
        "claude-sonnet-4-5-20250929-thinking-32k": {
            "rating": 1525.5572199027845,
            "rating_q975": 1533.9850405563814,
            "rating_q025": 1517.1293992491876
        },
        "gemini-3-pro": {
            "rating": 1520.182360193323,
            "rating_q975": 1531.245786829256,
            "rating_q025": 1509.1189335573897
        },
        "claude-opus-4-5-20251101": {
            "rating": 1516.352327711548,
            "rating_q975": 1530.0061414164159,
            "rating_q025": 1502.6985140066802
        },
        "claude-opus-4-1-20250805-thinking-16k": {
            "rating": 1514.0271206056825,
            "rating_q975": 1521.1676209459106,
            "rating_q025": 1506.8866202654544
        },
        "grok-4.1-thinking": {
            "rating": 1506.6338235271267,
            "rating_q975": 1517.612998518842,
            "rating_q025": 1495.6546485354113
        },
        "claude-sonnet-4-5-20250929": {
            "rating": 1504.1350560838173,
            "rating_q975": 1513.4822065021958,
            "rating_q025": 1494.7879056654388
        },
        "claude-opus-4-1-20250805": {
            "rating": 1499.5073590582022,
            "rating_q975": 1506.1440331636368,
            "rating_q025": 1492.8706849527675
        },
        "claude-opus-4-20250514-thinking-16k": {
            "rating": 1495.174205196993,
            "rating_q975": 1503.0247334921128,
            "rating_q025": 1487.3236769018731
        },
        "grok-4.1": {
            "rating": 1489.414719986886,
            "rating_q975": 1500.3444094467748,
            "rating_q025": 1478.4850305269972
        },
        "gpt-5.1-high": {
            "rating": 1488.917214402589,
            "rating_q975": 1501.0388723266342,
            "rating_q025": 1476.7955564785439
        },
        "qwen3-max-preview": {
            "rating": 1481.04024952255,
            "rating_q975": 1489.5383958778782,
            "rating_q025": 1472.542103167222
        },
        "kimi-k2-thinking-turbo": {
            "rating": 1479.4068134635152,
            "rating_q975": 1490.366702737765,
            "rating_q025": 1468.4469241892652
        },
        "gpt-5.1": {
            "rating": 1477.7977068028038,
            "rating_q975": 1489.1406975060504,
            "rating_q025": 1466.4547160995571
        },
        "claude-haiku-4-5-20251001": {
            "rating": 1476.4965258510288,
            "rating_q975": 1484.9961689622382,
            "rating_q025": 1467.9968827398193
        },
        "longcat-flash-chat": {
            "rating": 1473.9486492733029,
            "rating_q975": 1486.616235767038,
            "rating_q025": 1461.2810627795677
        },
        "qwen3-max-2025-09-23": {
            "rating": 1473.906471733036,
            "rating_q975": 1486.8692865775213,
            "rating_q025": 1460.9436568885505
        },
        "deepseek-v3.2-exp-thinking": {
            "rating": 1470.2179601384585,
            "rating_q975": 1483.5974539167396,
            "rating_q025": 1456.8384663601773
        },
        "gpt-5-high": {
            "rating": 1470.0955809880631,
            "rating_q975": 1478.289248447003,
            "rating_q025": 1461.9019135291232
        },
        "gemini-2.5-pro": {
            "rating": 1469.7940532933974,
            "rating_q975": 1475.8321689117013,
            "rating_q025": 1463.7559376750935
        },
        "qwen3-235b-a22b-instruct-2507": {
            "rating": 1469.7575111902668,
            "rating_q975": 1476.382775775468,
            "rating_q025": 1463.1322466050656
        },
        "claude-sonnet-4-20250514-thinking-32k": {
            "rating": 1469.2059882452543,
            "rating_q975": 1477.0262114133025,
            "rating_q025": 1461.385765077206
        },
        "mistral-large-3": {
            "rating": 1468.6588500318871,
            "rating_q975": 1485.1260741997305,
            "rating_q025": 1452.1916258640438
        },
        "deepseek-v3.2-exp": {
            "rating": 1467.7384615998667,
            "rating_q975": 1479.6582122799996,
            "rating_q025": 1455.8187109197338
        },
        "kimi-k2-0905-preview": {
            "rating": 1466.3295861053523,
            "rating_q975": 1478.9765021663582,
            "rating_q025": 1453.6826700443464
        },
        "chatgpt-4o-latest-20250326": {
            "rating": 1464.5060761003035,
            "rating_q975": 1470.55447769093,
            "rating_q025": 1458.457674509677
        },
        "qwen3-vl-235b-a22b-instruct": {
            "rating": 1464.4808114303742,
            "rating_q975": 1478.1199566586579,
            "rating_q025": 1450.8416662020904
        },
        "glm-4.6": {
            "rating": 1463.7964732720116,
            "rating_q975": 1472.5304689852912,
            "rating_q025": 1455.0624775587319
        },
        "deepseek-v3.2-thinking": {
            "rating": 1462.7061790233265,
            "rating_q975": 1480.8666285107072,
            "rating_q025": 1444.5457295359458
        },
        "deepseek-r1-0528": {
            "rating": 1462.3507418669526,
            "rating_q975": 1473.5940969465819,
            "rating_q025": 1451.1073867873233
        },
        "ernie-5.0-preview-1103": {
            "rating": 1462.0252262351821,
            "rating_q975": 1479.7479329855094,
            "rating_q025": 1444.3025194848549
        },
        "claude-opus-4-20250514": {
            "rating": 1461.286302102592,
            "rating_q975": 1468.5920457355417,
            "rating_q025": 1453.9805584696421
        },
        "gpt-5-chat": {
            "rating": 1458.6884190396677,
            "rating_q975": 1466.6484547566422,
            "rating_q025": 1450.7283833226932
        },
        "kimi-k2-0711-preview": {
            "rating": 1457.969374165399,
            "rating_q975": 1466.4549792221108,
            "rating_q025": 1449.483769108687
        },
        "deepseek-v3.1-terminus-thinking": {
            "rating": 1457.2470037589578,
            "rating_q975": 1480.943579294446,
            "rating_q025": 1433.5504282234697
        },
        "o3-2025-04-16": {
            "rating": 1456.8185183432947,
            "rating_q975": 1463.1103802487914,
            "rating_q025": 1450.526656437798
        },
        "gpt-4.5-preview-2025-02-27": {
            "rating": 1456.4742681045068,
            "rating_q975": 1469.4289543424934,
            "rating_q025": 1443.5195818665202
        },
        "grok-4-1-fast-reasoning": {
            "rating": 1456.3354393739653,
            "rating_q975": 1470.1045122343446,
            "rating_q025": 1442.566366513586
        },
        "deepseek-v3.1-thinking": {
            "rating": 1455.7669056000043,
            "rating_q975": 1469.2517201162743,
            "rating_q025": 1442.2820910837343
        },
        "glm-4.5": {
            "rating": 1454.7717433566359,
            "rating_q975": 1463.6380596145302,
            "rating_q025": 1445.9054270987415
        },
        "deepseek-v3.2": {
            "rating": 1454.3177453584224,
            "rating_q975": 1470.7077399850969,
            "rating_q025": 1437.927750731748
        },
        "grok-4-fast-chat": {
            "rating": 1453.6720189015666,
            "rating_q975": 1470.0606109080795,
            "rating_q025": 1437.2834268950537
        },
        "qwen3-vl-235b-a22b-thinking": {
            "rating": 1453.5741466879638,
            "rating_q975": 1467.9838504493996,
            "rating_q025": 1439.164442926528
        },
        "gpt-4.1-2025-04-14": {
            "rating": 1453.5190757374735,
            "rating_q975": 1460.221360752665,
            "rating_q025": 1446.816790722282
        },
        "qwen3-coder-480b-a35b-instruct": {
            "rating": 1453.025200862072,
            "rating_q975": 1462.2283030193419,
            "rating_q025": 1443.8220987048023
        },
        "mistral-medium-2508": {
            "rating": 1452.274049609345,
            "rating_q975": 1459.1787739822166,
            "rating_q025": 1445.3693252364733
        },
        "claude-3-7-sonnet-20250219-thinking-32k": {
            "rating": 1449.1336118125312,
            "rating_q975": 1457.0362031929192,
            "rating_q025": 1441.2310204321432
        },
        "deepseek-v3.1": {
            "rating": 1446.6185095045516,
            "rating_q975": 1458.2403747205683,
            "rating_q025": 1434.996644288535
        },
        "claude-sonnet-4-20250514": {
            "rating": 1446.315439185746,
            "rating_q975": 1453.7271380768175,
            "rating_q025": 1438.9037402946747
        },
        "qwen3-next-80b-a3b-instruct": {
            "rating": 1445.402493102461,
            "rating_q975": 1454.2651157582882,
            "rating_q025": 1436.5398704466338
        },
        "qwen3-235b-a22b-no-thinking": {
            "rating": 1443.2493167359357,
            "rating_q975": 1450.8399452772,
            "rating_q025": 1435.6586881946714
        },
        "deepseek-r1": {
            "rating": 1443.2458315566682,
            "rating_q975": 1454.9449822688125,
            "rating_q025": 1431.546680844524
        },
        "grok-3-preview-02-24": {
            "rating": 1441.8642505967453,
            "rating_q975": 1450.169711179571,
            "rating_q025": 1433.5587900139194
        },
        "qwen3-235b-a22b-thinking-2507": {
            "rating": 1440.957083170007,
            "rating_q975": 1455.6123710953295,
            "rating_q025": 1426.3017952446846
        },
        "grok-4-fast-reasoning": {
            "rating": 1437.6350565371881,
            "rating_q975": 1447.17077635788,
            "rating_q025": 1428.0993367164963
        },
        "qwen3-30b-a3b-instruct-2507": {
            "rating": 1437.2677182090906,
            "rating_q975": 1446.2034799719543,
            "rating_q025": 1428.331956446227
        },
        "deepseek-v3.1-terminus": {
            "rating": 1436.9816934447028,
            "rating_q975": 1457.8648045676273,
            "rating_q025": 1416.0985823217784
        },
        "grok-4-0709": {
            "rating": 1433.0408675415963,
            "rating_q975": 1440.0255915830746,
            "rating_q025": 1426.056143500118
        },
        "hunyuan-vision-1.5-thinking": {
            "rating": 1432.9922203651156,
            "rating_q975": 1460.2768456980436,
            "rating_q025": 1405.7075950321876
        },
        "gpt-4.1-mini-2025-04-14": {
            "rating": 1432.3376284691965,
            "rating_q975": 1439.8444096860837,
            "rating_q025": 1424.8308472523092
        },
        "claude-3-5-sonnet-20241022": {
            "rating": 1431.9270156086532,
            "rating_q975": 1437.287618221671,
            "rating_q025": 1426.5664129956353
        },
        "o3-mini-high": {
            "rating": 1431.895523837278,
            "rating_q975": 1443.3405265315064,
            "rating_q025": 1420.4505211430496
        },
        "qwen3-235b-a22b": {
            "rating": 1431.6052492796268,
            "rating_q975": 1440.6233045810707,
            "rating_q025": 1422.587193978183
        },
        "o1-2024-12-17": {
            "rating": 1430.2428958849289,
            "rating_q975": 1439.6608225996135,
            "rating_q025": 1420.8249691702442
        },
        "gpt-5-mini-high": {
            "rating": 1429.593611506966,
            "rating_q975": 1438.2291937787402,
            "rating_q025": 1420.9580292351918
        },
        "o4-mini-2025-04-16": {
            "rating": 1429.4797933892944,
            "rating_q975": 1436.413096297508,
            "rating_q025": 1422.5464904810808
        },
        "mistral-medium-2505": {
            "rating": 1429.4221473784007,
            "rating_q975": 1437.4440363028912,
            "rating_q025": 1421.4002584539103
        },
        "mai-1-preview": {
            "rating": 1428.564602156889,
            "rating_q975": 1439.6321351872061,
            "rating_q025": 1417.4970691265717
        },
        "claude-3-7-sonnet-20250219": {
            "rating": 1427.3311610476808,
            "rating_q975": 1434.7357207410857,
            "rating_q025": 1419.9266013542758
        },
        "glm-4.5-air": {
            "rating": 1426.254915428658,
            "rating_q975": 1434.04036995056,
            "rating_q025": 1418.469460906756
        },
        "deepseek-v3-0324": {
            "rating": 1425.3130014944904,
            "rating_q975": 1432.152360174725,
            "rating_q025": 1418.473642814256
        },
        "intellect-3": {
            "rating": 1424.9749653114463,
            "rating_q975": 1454.671527266271,
            "rating_q025": 1395.2784033566218
        },
        "gemini-2.5-flash-preview-09-2025": {
            "rating": 1422.6962372078342,
            "rating_q975": 1430.865073835487,
            "rating_q025": 1414.5274005801814
        },
        "qwen3-next-80b-a3b-thinking": {
            "rating": 1422.6325969142463,
            "rating_q975": 1434.1179286608706,
            "rating_q025": 1411.147265167622
        },
        "gemini-2.5-flash": {
            "rating": 1421.6830685777666,
            "rating_q975": 1427.7088039383448,
            "rating_q025": 1415.6573332171884
        },
        "minimax-m1": {
            "rating": 1416.1838267554454,
            "rating_q975": 1423.8426837163565,
            "rating_q025": 1408.5249697945342
        },
        "o1-preview": {
            "rating": 1414.6003060190785,
            "rating_q975": 1423.7423396902293,
            "rating_q025": 1405.4582723479277
        },
        "o3-mini": {
            "rating": 1413.34562046169,
            "rating_q975": 1419.6944687793987,
            "rating_q025": 1406.9967721439814
        },
        "ling-flash-2.0": {
            "rating": 1412.569318096278,
            "rating_q975": 1427.27451254474,
            "rating_q025": 1397.864123647816
        },
        "mistral-small-2506": {
            "rating": 1411.3533969178188,
            "rating_q975": 1421.390457026418,
            "rating_q025": 1401.3163368092196
        },
        "amazon-nova-experimental-chat-10-20": {
            "rating": 1405.8966339833978,
            "rating_q975": 1420.4307604616804,
            "rating_q025": 1391.3625075051152
        },
        "nova-2-lite": {
            "rating": 1405.776525469358,
            "rating_q975": 1422.5886551513058,
            "rating_q025": 1388.96439578741
        },
        "qwen3-32b": {
            "rating": 1405.0092617680248,
            "rating_q975": 1429.6169920162083,
            "rating_q025": 1380.4015315198412
        },
        "step-3": {
            "rating": 1403.5298887250676,
            "rating_q975": 1420.1285080702492,
            "rating_q025": 1386.931269379886
        },
        "glm-4.5v": {
            "rating": 1402.269436179045,
            "rating_q975": 1420.824290198452,
            "rating_q025": 1383.714582159638
        },
        "qwen2.5-max": {
            "rating": 1400.2599583019187,
            "rating_q975": 1408.3232717222463,
            "rating_q025": 1392.196644881591
        },
        "amazon-nova-experimental-chat-10-09": {
            "rating": 1398.028269296151,
            "rating_q975": 1411.0731550106225,
            "rating_q025": 1384.9833835816794
        },
        "hunyuan-turbos-20250226": {
            "rating": 1397.2151568684403,
            "rating_q975": 1427.976852138548,
            "rating_q025": 1366.4534615983325
        },
        "hunyuan-t1-20250711": {
            "rating": 1396.4009932262977,
            "rating_q975": 1416.3315015533703,
            "rating_q025": 1376.470484899225
        },
        "claude-3-5-sonnet-20240620": {
            "rating": 1395.579067524444,
            "rating_q975": 1402.4570349610929,
            "rating_q025": 1388.7011000877953
        },
        "nvidia-llama-3.3-nemotron-super-49b-v1.5": {
            "rating": 1395.5104407464626,
            "rating_q975": 1417.2017557375145,
            "rating_q025": 1373.8191257554106
        },
        "hunyuan-turbos-20250416": {
            "rating": 1392.9075630598134,
            "rating_q975": 1406.6848369717554,
            "rating_q025": 1379.1302891478713
        },
        "gemini-2.5-flash-lite-preview-09-2025-no-thinking": {
            "rating": 1392.7748556834185,
            "rating_q975": 1401.0085425517334,
            "rating_q025": 1384.5411688151037
        },
        "ring-flash-2.0": {
            "rating": 1390.332738155167,
            "rating_q975": 1405.0757650928813,
            "rating_q025": 1375.5897112174525
        },
        "llama-3.1-nemotron-ultra-253b-v1": {
            "rating": 1389.5117832321394,
            "rating_q975": 1419.6104574698143,
            "rating_q025": 1359.4131089944644
        },
        "gpt-oss-120b": {
            "rating": 1388.452348806723,
            "rating_q975": 1396.2688803279655,
            "rating_q025": 1380.6358172854805
        },
        "command-a-03-2025": {
            "rating": 1387.5988732761743,
            "rating_q975": 1393.8642379692471,
            "rating_q025": 1381.3335085831015
        },
        "grok-3-mini-high": {
            "rating": 1386.7710805873057,
            "rating_q975": 1396.9656538416004,
            "rating_q025": 1376.576507333011
        },
        "deepseek-v3": {
            "rating": 1385.5982982856094,
            "rating_q975": 1395.5332267125357,
            "rating_q025": 1375.6633698586832
        },
        "o1-mini": {
            "rating": 1385.5362644174966,
            "rating_q975": 1392.7530669747907,
            "rating_q025": 1378.3194618602024
        },
        "magistral-medium-2506": {
            "rating": 1385.4680451468134,
            "rating_q975": 1397.7384565277862,
            "rating_q025": 1373.1976337658407
        },
        "qwq-32b": {
            "rating": 1384.277054437071,
            "rating_q975": 1393.2615890336267,
            "rating_q025": 1375.2925198405153
        },
        "grok-3-mini-beta": {
            "rating": 1384.2766416195068,
            "rating_q975": 1393.3216664632978,
            "rating_q025": 1375.2316167757158
        },
        "qwen3-30b-a3b": {
            "rating": 1384.2527360452364,
            "rating_q975": 1393.0766755520688,
            "rating_q025": 1375.428796538404
        },
        "gemini-2.5-flash-lite-preview-06-17-thinking": {
            "rating": 1383.988229897853,
            "rating_q975": 1392.0108715737886,
            "rating_q025": 1375.9655882219174
        },
        "claude-3-5-haiku-20241022": {
            "rating": 1382.9028008903056,
            "rating_q975": 1388.8663805538763,
            "rating_q025": 1376.9392212267348
        },
        "gpt-5-nano-high": {
            "rating": 1380.8202096089185,
            "rating_q975": 1395.519353051248,
            "rating_q025": 1366.1210661665891
        },
        "qwen-plus-0125": {
            "rating": 1377.196658362856,
            "rating_q975": 1395.5771739213992,
            "rating_q025": 1358.8161428043127
        },
        "minimax-m2": {
            "rating": 1374.9827729776898,
            "rating_q975": 1389.840617255804,
            "rating_q025": 1360.1249286995755
        },
        "deepseek-v2.5-1210": {
            "rating": 1372.4951140647613,
            "rating_q975": 1389.2796208869297,
            "rating_q025": 1355.710607242593
        },
        "llama-3.1-405b-instruct-bf16": {
            "rating": 1372.3940944999258,
            "rating_q975": 1379.7107345430247,
            "rating_q025": 1365.077454456827
        },
        "gpt-4.1-nano-2025-04-14": {
            "rating": 1372.277469621636,
            "rating_q975": 1391.6259216933572,
            "rating_q025": 1352.929017549915
        },
        "llama-4-maverick-17b-128e-instruct": {
            "rating": 1371.4481062591003,
            "rating_q975": 1378.9522478598412,
            "rating_q025": 1363.9439646583594
        },
        "hunyuan-turbo-0110": {
            "rating": 1369.4000349315952,
            "rating_q975": 1399.3422414735119,
            "rating_q025": 1339.4578283896785
        },
        "gpt-oss-20b": {
            "rating": 1368.809472980909,
            "rating_q975": 1381.9092793623204,
            "rating_q025": 1355.7096665994977
        },
        "step-2-16k-exp-202412": {
            "rating": 1368.0943808856725,
            "rating_q975": 1387.877718145039,
            "rating_q025": 1348.3110436263062
        },
        "yi-lightning": {
            "rating": 1366.694155212343,
            "rating_q975": 1376.204545608099,
            "rating_q025": 1357.1837648165872
        },
        "gpt-4o-2024-05-13": {
            "rating": 1366.61566572323,
            "rating_q975": 1372.7907876966356,
            "rating_q025": 1360.4405437498244
        },
        "athene-v2-chat": {
            "rating": 1366.5241621958749,
            "rating_q975": 1375.46894844915,
            "rating_q025": 1357.5793759425997
        },
        "mercury": {
            "rating": 1365.9086579937616,
            "rating_q975": 1394.111891777373,
            "rating_q025": 1337.70542421015
        },
        "deepseek-v2.5": {
            "rating": 1365.7330570168706,
            "rating_q975": 1374.9356517326744,
            "rating_q025": 1356.5304623010668
        },
        "llama-3.1-405b-instruct-fp8": {
            "rating": 1365.4317540160505,
            "rating_q975": 1372.376385416235,
            "rating_q025": 1358.487122615866
        },
        "hunyuan-large-2025-02-10": {
            "rating": 1364.4829966217262,
            "rating_q975": 1389.257938136074,
            "rating_q025": 1339.7080551073784
        },
        "olmo-3-32b-think": {
            "rating": 1363.2884108907515,
            "rating_q975": 1387.8658950912163,
            "rating_q025": 1338.7109266902867
        },
        "gemini-2.0-flash-001": {
            "rating": 1362.9560735883342,
            "rating_q975": 1370.2905542291815,
            "rating_q025": 1355.621592947487
        },
        "llama-3.3-nemotron-49b-super-v1": {
            "rating": 1361.7148007759301,
            "rating_q975": 1393.1938408997216,
            "rating_q025": 1330.2357606521387
        },
        "llama-4-scout-17b-16e-instruct": {
            "rating": 1360.7004610515135,
            "rating_q975": 1369.2402582872198,
            "rating_q025": 1352.160663815807
        },
        "mistral-small-3.1-24b-instruct-2503": {
            "rating": 1359.1978450124675,
            "rating_q975": 1367.1140773840261,
            "rating_q025": 1351.2816126409089
        },
        "gemma-3-27b-it": {
            "rating": 1358.9059180392649,
            "rating_q975": 1365.8364830383277,
            "rating_q025": 1351.975353040202
        },
        "gpt-4o-2024-08-06": {
            "rating": 1358.4699183596172,
            "rating_q975": 1366.153436564085,
            "rating_q025": 1350.7864001551493
        },
        "hunyuan-large-vision": {
            "rating": 1357.5380236839778,
            "rating_q975": 1376.1773147182307,
            "rating_q025": 1338.898732649725
        },
        "grok-2-2024-08-13": {
            "rating": 1356.903070105086,
            "rating_q975": 1363.593339342057,
            "rating_q025": 1350.212800868115
        },
        "qwen2.5-plus-1127": {
            "rating": 1354.8778004179399,
            "rating_q975": 1368.7301886751525,
            "rating_q025": 1341.0254121607272
        },
        "gemini-1.5-pro-002": {
            "rating": 1354.5507088963043,
            "rating_q975": 1361.1965310590867,
            "rating_q025": 1347.9048867335218
        },
        "step-1o-turbo-202506": {
            "rating": 1354.2573606899173,
            "rating_q975": 1368.8439257639475,
            "rating_q025": 1339.670795615887
        },
        "qwen2.5-72b-instruct": {
            "rating": 1353.2297487273397,
            "rating_q975": 1360.6544908597557,
            "rating_q025": 1345.8050065949237
        },
        "claude-3-opus-20240229": {
            "rating": 1350.9146965487116,
            "rating_q975": 1356.602720503782,
            "rating_q025": 1345.2266725936413
        },
        "mistral-large-2407": {
            "rating": 1350.5974269911906,
            "rating_q975": 1358.2436821720087,
            "rating_q025": 1342.9511718103724
        },
        "qwen-max-0919": {
            "rating": 1350.3588084577657,
            "rating_q975": 1361.3552489276003,
            "rating_q025": 1339.362367987931
        },
        "glm-4-plus": {
            "rating": 1349.9801669601154,
            "rating_q975": 1359.1932499191153,
            "rating_q025": 1340.7670840011156
        },
        "athene-70b-0725": {
            "rating": 1348.2415692302097,
            "rating_q975": 1358.9403485562852,
            "rating_q025": 1337.5427899041342
        },
        "gpt-4o-mini-2024-07-18": {
            "rating": 1346.6734900186498,
            "rating_q975": 1352.9625890850311,
            "rating_q025": 1340.3843909522684
        },
        "gemini-1.5-pro-001": {
            "rating": 1345.4407560201632,
            "rating_q975": 1352.7801505686948,
            "rating_q025": 1338.1013614716317
        },
        "gpt-4-turbo-2024-04-09": {
            "rating": 1344.3028449529,
            "rating_q975": 1351.1898389283851,
            "rating_q025": 1337.4158509774147
        },
        "mistral-large-2411": {
            "rating": 1343.3823675421772,
            "rating_q975": 1352.0657529152181,
            "rating_q025": 1334.6989821691363
        },
        "llama-3.3-70b-instruct": {
            "rating": 1343.0241437876,
            "rating_q975": 1349.3916912741802,
            "rating_q025": 1336.6565963010198
        },
        "gemini-2.0-flash-lite-preview-02-05": {
            "rating": 1342.030684620938,
            "rating_q975": 1351.7202442928476,
            "rating_q025": 1332.3411249490284
        },
        "qwen2.5-coder-32b-instruct": {
            "rating": 1340.2953717466376,
            "rating_q975": 1358.7886680810668,
            "rating_q025": 1321.8020754122083
        },
        "amazon-nova-pro-v1.0": {
            "rating": 1339.8956231211864,
            "rating_q975": 1348.8500563365747,
            "rating_q025": 1330.9411899057982
        },
        "deepseek-coder-v2": {
            "rating": 1339.3642428659332,
            "rating_q975": 1351.0925165694396,
            "rating_q025": 1327.6359691624268
        },
        "gemini-advanced-0514": {
            "rating": 1336.5230511788855,
            "rating_q975": 1345.3921451194656,
            "rating_q025": 1327.6539572383053
        },
        "gpt-4-1106-preview": {
            "rating": 1336.4485667531003,
            "rating_q975": 1343.6764910672214,
            "rating_q025": 1329.2206424389792
        },
        "grok-2-mini-2024-08-13": {
            "rating": 1333.3221724743507,
            "rating_q975": 1340.2739903926729,
            "rating_q025": 1326.3703545560286
        },
        "llama-3.1-70b-instruct": {
            "rating": 1330.4685777503448,
            "rating_q975": 1337.3723275421173,
            "rating_q025": 1323.5648279585723
        },
        "glm-4-plus-0111": {
            "rating": 1328.8805532323163,
            "rating_q975": 1346.9933239008058,
            "rating_q025": 1310.7677825638268
        },
        "hunyuan-standard-2025-02-10": {
            "rating": 1328.6134103828772,
            "rating_q975": 1352.2865488528494,
            "rating_q025": 1304.940271912905
        },
        "gpt-4-0125-preview": {
            "rating": 1328.1980773976165,
            "rating_q975": 1335.5666574860415,
            "rating_q025": 1320.8294973091915
        },
        "llama-3.1-nemotron-70b-instruct": {
            "rating": 1326.5881761967462,
            "rating_q975": 1341.9444507270598,
            "rating_q025": 1311.2319016664326
        },
        "gpt-4-0314": {
            "rating": 1324.6998548396987,
            "rating_q975": 1333.9977024269263,
            "rating_q025": 1315.402007252471
        },
        "gemma-3-12b-it": {
            "rating": 1316.6675063884002,
            "rating_q975": 1340.0980952683478,
            "rating_q025": 1293.2369175084525
        },
        "claude-3-sonnet-20240229": {
            "rating": 1314.3075131746145,
            "rating_q975": 1321.4632564737808,
            "rating_q025": 1307.1517698754483
        },
        "gemini-1.5-flash-002": {
            "rating": 1313.9941418706258,
            "rating_q975": 1321.8591560346667,
            "rating_q025": 1306.1291277065848
        },
        "reka-core-20240904": {
            "rating": 1312.4316743476525,
            "rating_q975": 1327.7513607606977,
            "rating_q025": 1297.1119879346072
        },
        "gemma-3n-e4b-it": {
            "rating": 1311.3267523567183,
            "rating_q975": 1321.4993304318677,
            "rating_q025": 1301.1541742815689
        },
        "mistral-small-24b-instruct-2501": {
            "rating": 1310.2288444408377,
            "rating_q975": 1322.6145650785477,
            "rating_q025": 1297.8431238031278
        },
        "gpt-4-0613": {
            "rating": 1309.5877329008576,
            "rating_q975": 1317.4580781085513,
            "rating_q025": 1301.717387693164
        },
        "jamba-1.5-large": {
            "rating": 1309.5010320290048,
            "rating_q975": 1323.9312313338423,
            "rating_q025": 1295.0708327241673
        },
        "gemini-1.5-flash-001": {
            "rating": 1308.1612499697417,
            "rating_q975": 1315.6351307852894,
            "rating_q025": 1300.687369154194
        },
        "llama-3.1-nemotron-51b-instruct": {
            "rating": 1308.0646709455336,
            "rating_q975": 1329.7293784241215,
            "rating_q025": 1286.3999634669458
        },
        "llama-3.1-tulu-3-70b": {
            "rating": 1304.9574506249155,
            "rating_q975": 1328.6271542515105,
            "rating_q025": 1281.2877469983205
        },
        "glm-4-0520": {
            "rating": 1304.889273909108,
            "rating_q975": 1318.7406212675899,
            "rating_q025": 1291.037926550626
        },
        "phi-4": {
            "rating": 1304.1233962632846,
            "rating_q975": 1313.9018367745593,
            "rating_q025": 1294.3449557520098
        },
        "nemotron-4-340b-instruct": {
            "rating": 1303.7457426757987,
            "rating_q975": 1314.9606815863394,
            "rating_q025": 1292.530803765258
        },
        "gemma-2-27b-it": {
            "rating": 1303.6117283986136,
            "rating_q975": 1309.7897877423177,
            "rating_q025": 1297.4336690549096
        },
        "llama-3-70b-instruct": {
            "rating": 1303.1747962299057,
            "rating_q975": 1309.94753494478,
            "rating_q025": 1296.4020575150314
        },
        "amazon-nova-lite-v1.0": {
            "rating": 1303.1105554921683,
            "rating_q975": 1313.2292476987764,
            "rating_q025": 1292.9918632855602
        },
        "claude-3-haiku-20240307": {
            "rating": 1297.7376050557486,
            "rating_q975": 1304.4175890462702,
            "rating_q025": 1291.057621065227
        },
        "hunyuan-standard-256k": {
            "rating": 1297.0223234745158,
            "rating_q975": 1321.619210768169,
            "rating_q025": 1272.4254361808626
        },
        "qwen2-72b-instruct": {
            "rating": 1292.5984814505114,
            "rating_q975": 1301.4090878787179,
            "rating_q025": 1283.787875022305
        },
        "mistral-large-2402": {
            "rating": 1291.069193590931,
            "rating_q975": 1299.4565023648138,
            "rating_q025": 1282.6818848170483
        },
        "c4ai-aya-expanse-32b": {
            "rating": 1289.8481033148018,
            "rating_q975": 1298.788823103717,
            "rating_q025": 1280.9073835258866
        },
        "reka-flash-20240904": {
            "rating": 1288.3090296266664,
            "rating_q975": 1303.5186014551923,
            "rating_q025": 1273.0994577981405
        },
        "amazon-nova-micro-v1.0": {
            "rating": 1285.51647851585,
            "rating_q975": 1295.6914021018074,
            "rating_q025": 1275.3415549298925
        },
        "granite-3.1-8b-instruct": {
            "rating": 1285.0231595631144,
            "rating_q975": 1310.5956290731522,
            "rating_q025": 1259.4506900530766
        },
        "command-r-08-2024": {
            "rating": 1277.34529954886,
            "rating_q975": 1290.7147470517525,
            "rating_q025": 1263.9758520459677
        },
        "olmo-2-0325-32b-instruct": {
            "rating": 1277.3141786487226,
            "rating_q975": 1304.3049296425718,
            "rating_q025": 1250.3234276548735
        },
        "command-r-plus-08-2024": {
            "rating": 1277.032709133286,
            "rating_q975": 1290.7910648441173,
            "rating_q025": 1263.2743534224549
        },
        "qwen1.5-110b-chat": {
            "rating": 1275.8827093483085,
            "rating_q975": 1286.0316996060765,
            "rating_q025": 1265.7337190905405
        },
        "gemma-3-4b-it": {
            "rating": 1274.029641174864,
            "rating_q975": 1297.756706532726,
            "rating_q025": 1250.3025758170022
        },
        "reka-flash-21b-20240226-online": {
            "rating": 1273.8651566207939,
            "rating_q975": 1286.4820561494523,
            "rating_q025": 1261.2482570921354
        },
        "mixtral-8x22b-instruct-v0.1": {
            "rating": 1273.0257918690731,
            "rating_q975": 1281.5152215962028,
            "rating_q025": 1264.5363621419435
        },
        "ministral-8b-2410": {
            "rating": 1271.7049335711945,
            "rating_q975": 1290.4277137989427,
            "rating_q025": 1252.9821533434463
        },
        "gemma-2-9b-it-simpo": {
            "rating": 1271.3755085806376,
            "rating_q975": 1286.2303014276447,
            "rating_q025": 1256.5207157336306
        },
        "qwen1.5-72b-chat": {
            "rating": 1270.5449849926167,
            "rating_q975": 1280.052521020756,
            "rating_q025": 1261.0374489644773
        },
        "gemini-1.5-flash-8b-001": {
            "rating": 1270.540360482335,
            "rating_q975": 1278.491838713739,
            "rating_q025": 1262.588882250931
        },
        "gpt-3.5-turbo-0125": {
            "rating": 1270.4444777999156,
            "rating_q975": 1278.4454745786163,
            "rating_q025": 1262.443481021215
        },
        "gemma-2-9b-it": {
            "rating": 1269.2189395459327,
            "rating_q975": 1276.2883219290063,
            "rating_q025": 1262.149557162859
        },
        "command-r-plus": {
            "rating": 1268.7956325491873,
            "rating_q975": 1276.376869667155,
            "rating_q025": 1261.2143954312196
        },
        "jamba-1.5-mini": {
            "rating": 1263.383252090805,
            "rating_q975": 1278.6518491038835,
            "rating_q025": 1248.1146550777264
        },
        "reka-flash-21b-20240226": {
            "rating": 1262.577939048836,
            "rating_q975": 1273.1285706162698,
            "rating_q025": 1252.0273074814022
        },
        "mistral-medium": {
            "rating": 1257.6784038181258,
            "rating_q975": 1268.0409974628915,
            "rating_q025": 1247.3158101733602
        },
        "qwen1.5-32b-chat": {
            "rating": 1257.4866855375285,
            "rating_q975": 1268.2766650012848,
            "rating_q025": 1246.6967060737722
        },
        "gpt-3.5-turbo-1106": {
            "rating": 1257.3939017548678,
            "rating_q975": 1272.9783177806637,
            "rating_q025": 1241.8094857290719
        },
        "llama-3.1-8b-instruct": {
            "rating": 1257.209468291162,
            "rating_q975": 1264.4620996285303,
            "rating_q025": 1249.9568369537938
        },
        "c4ai-aya-expanse-8b": {
            "rating": 1253.791154978036,
            "rating_q975": 1268.1990201637545,
            "rating_q025": 1239.3832897923176
        },
        "llama-3.1-tulu-3-8b": {
            "rating": 1250.5499645750058,
            "rating_q975": 1275.4007326039405,
            "rating_q025": 1225.699196546071
        },
        "llama-3-8b-instruct": {
            "rating": 1249.7201278350726,
            "rating_q975": 1257.1326363945589,
            "rating_q025": 1242.3076192755864
        },
        "granite-3.1-2b-instruct": {
            "rating": 1247.354919394525,
            "rating_q975": 1271.7724920152195,
            "rating_q025": 1222.9373467738305
        },
        "dbrx-instruct-preview": {
            "rating": 1246.8091497477722,
            "rating_q975": 1257.6255543737047,
            "rating_q025": 1235.9927451218396
        },
        "internlm2_5-20b-chat": {
            "rating": 1245.9035402265533,
            "rating_q975": 1260.0415758304512,
            "rating_q025": 1231.7655046226555
        },
        "gemini-pro": {
            "rating": 1244.6950142634762,
            "rating_q975": 1268.5146939202298,
            "rating_q025": 1220.8753346067226
        },
        "yi-1.5-34b-chat": {
            "rating": 1244.2567440530656,
            "rating_q975": 1254.5914509461638,
            "rating_q025": 1233.9220371599674
        },
        "zephyr-orpo-141b-A35b-v0.1": {
            "rating": 1240.8535164849884,
            "rating_q975": 1261.491683145286,
            "rating_q025": 1220.2153498246907
        },
        "command-r": {
            "rating": 1239.183482101091,
            "rating_q975": 1247.7670235973883,
            "rating_q025": 1230.5999406047936
        },
        "gemini-pro-dev-api": {
            "rating": 1235.9767756600954,
            "rating_q975": 1249.9788679137937,
            "rating_q025": 1221.9746834063972
        },
        "granite-3.0-8b-instruct": {
            "rating": 1235.9381832940644,
            "rating_q975": 1253.8468091812572,
            "rating_q025": 1218.0295574068716
        },
        "qwen1.5-14b-chat": {
            "rating": 1235.6590243770424,
            "rating_q975": 1248.408309605471,
            "rating_q025": 1222.9097391486139
        },
        "mixtral-8x7b-instruct-v0.1": {
            "rating": 1235.1624732560258,
            "rating_q975": 1243.108658067809,
            "rating_q025": 1227.2162884442425
        },
        "starling-lm-7b-beta": {
            "rating": 1231.8001673792196,
            "rating_q975": 1244.5435351046658,
            "rating_q025": 1219.0567996537734
        },
        "phi-3-medium-4k-instruct": {
            "rating": 1227.1028335441297,
            "rating_q975": 1237.2244495864823,
            "rating_q025": 1216.981217501777
        },
        "openchat-3.5-0106": {
            "rating": 1225.0435693974096,
            "rating_q975": 1239.0594307521437,
            "rating_q025": 1211.0277080426754
        },
        "snowflake-arctic-instruct": {
            "rating": 1220.368023906759,
            "rating_q975": 1231.4421968052638,
            "rating_q025": 1209.293851008254
        },
        "gemma-1.1-7b-it": {
            "rating": 1214.4142145980295,
            "rating_q975": 1224.648618680042,
            "rating_q025": 1204.179810516017
        },
        "deepseek-llm-67b-chat": {
            "rating": 1213.7653288452,
            "rating_q975": 1237.4154707180094,
            "rating_q025": 1190.1151869723906
        },
        "tulu-2-dpo-70b": {
            "rating": 1210.1032769376611,
            "rating_q975": 1231.4036371252262,
            "rating_q025": 1188.802916750096
        },
        "qwen1.5-7b-chat": {
            "rating": 1205.8591302602977,
            "rating_q975": 1226.6376786781216,
            "rating_q025": 1185.0805818424737
        },
        "granite-3.0-2b-instruct": {
            "rating": 1205.1625956893217,
            "rating_q975": 1222.6481569892073,
            "rating_q025": 1187.6770343894361
        },
        "starling-lm-7b-alpha": {
            "rating": 1203.0965287375916,
            "rating_q975": 1219.426095951183,
            "rating_q025": 1186.7669615240002
        },
        "yi-34b-chat": {
            "rating": 1201.4959723414318,
            "rating_q975": 1214.4266312184739,
            "rating_q025": 1188.5653134643896
        },
        "phi-3-small-8k-instruct": {
            "rating": 1200.9206840324678,
            "rating_q975": 1212.4379584359115,
            "rating_q025": 1189.403409629024
        },
        "openchat-3.5": {
            "rating": 1197.924857437239,
            "rating_q975": 1217.5533268618613,
            "rating_q025": 1178.296388012617
        },
        "phi-3-mini-4k-instruct-june-2024": {
            "rating": 1193.4905722976023,
            "rating_q975": 1207.2446478853392,
            "rating_q025": 1179.7364967098654
        },
        "gemma-2-2b-it": {
            "rating": 1192.4386290658065,
            "rating_q975": 1200.319769222048,
            "rating_q025": 1184.5574889095649
        },
        "qwen-14b-chat": {
            "rating": 1192.228091429978,
            "rating_q975": 1216.0034423872198,
            "rating_q025": 1168.452740472736
        },
        "vicuna-33b": {
            "rating": 1188.4944039194734,
            "rating_q975": 1201.1442604696,
            "rating_q025": 1175.8445473693466
        },
        "wizardlm-70b": {
            "rating": 1187.3191249621818,
            "rating_q975": 1207.1234502467312,
            "rating_q025": 1167.5147996776325
        },
        "phi-3-mini-4k-instruct": {
            "rating": 1183.9267315586285,
            "rating_q975": 1195.569807344933,
            "rating_q025": 1172.283655772324
        },
        "openhermes-2.5-mistral-7b": {
            "rating": 1182.1692472311474,
            "rating_q975": 1205.4027437703674,
            "rating_q025": 1158.9357506919275
        },
        "mistral-7b-instruct-v0.2": {
            "rating": 1181.6547803033332,
            "rating_q975": 1193.2888243558864,
            "rating_q025": 1170.02073625078
        },
        "solar-10.7b-instruct-v1.0": {
            "rating": 1178.9316115380511,
            "rating_q975": 1206.2182464597884,
            "rating_q025": 1151.644976616314
        },
        "llama-2-70b-chat": {
            "rating": 1174.6474636291816,
            "rating_q975": 1184.4552505335962,
            "rating_q025": 1164.839676724767
        },
        "llama-3.2-3b-instruct": {
            "rating": 1172.6596811684167,
            "rating_q975": 1188.9615149981596,
            "rating_q025": 1156.3578473386738
        },
        "qwq-32b-preview": {
            "rating": 1171.4767259460775,
            "rating_q975": 1195.8309166993167,
            "rating_q025": 1147.1225351928383
        },
        "nous-hermes-2-mixtral-8x7b-dpo": {
            "rating": 1171.236378653276,
            "rating_q975": 1194.8451875840467,
            "rating_q025": 1147.6275697225053
        },
        "gemma-1.1-2b-it": {
            "rating": 1169.369255942479,
            "rating_q975": 1183.2259101484894,
            "rating_q025": 1155.5126017364685
        },
        "gemma-7b-it": {
            "rating": 1165.6940890474393,
            "rating_q975": 1182.2935253146024,
            "rating_q025": 1149.0946527802762
        },
        "zephyr-7b-alpha": {
            "rating": 1164.4437506905351,
            "rating_q975": 1204.4739269835725,
            "rating_q025": 1124.4135743974978
        },
        "mpt-30b-chat": {
            "rating": 1162.1912286401584,
            "rating_q975": 1197.1725837324439,
            "rating_q025": 1127.209873547873
        },
        "vicuna-13b": {
            "rating": 1158.3982434942225,
            "rating_q975": 1172.172872543786,
            "rating_q025": 1144.6236144446589
        },
        "llama-2-13b-chat": {
            "rating": 1158.1293611976716,
            "rating_q975": 1171.0043336304832,
            "rating_q025": 1145.25438876486
        },
        "smollm2-1.7b-instruct": {
            "rating": 1155.6039618770383,
            "rating_q975": 1188.5236543530734,
            "rating_q025": 1122.6842694010031
        },
        "codellama-34b-instruct": {
            "rating": 1154.7302442647847,
            "rating_q975": 1175.1013823013966,
            "rating_q025": 1134.3591062281728
        },
        "phi-3-mini-128k-instruct": {
            "rating": 1151.0928921554023,
            "rating_q975": 1164.0326021752687,
            "rating_q025": 1138.1531821355359
        },
        "palm-2": {
            "rating": 1147.5940280943223,
            "rating_q975": 1168.514188101913,
            "rating_q025": 1126.6738680867315
        },
        "zephyr-7b-beta": {
            "rating": 1147.3449883588075,
            "rating_q975": 1165.5402283143392,
            "rating_q025": 1129.149748403276
        },
        "wizardlm-13b": {
            "rating": 1146.4181342113413,
            "rating_q975": 1168.4724266633839,
            "rating_q025": 1124.3638417592988
        },
        "llama-3.2-1b-instruct": {
            "rating": 1145.808961766942,
            "rating_q975": 1162.07287106127,
            "rating_q025": 1129.545052472614
        },
        "llama2-70b-steerlm-chat": {
            "rating": 1140.6732188733777,
            "rating_q975": 1168.5950375496489,
            "rating_q025": 1112.7514001971065
        },
        "mistral-7b-instruct": {
            "rating": 1140.282860913214,
            "rating_q975": 1160.0562485673295,
            "rating_q025": 1120.5094732590987
        },
        "gemma-2b-it": {
            "rating": 1133.4608556449634,
            "rating_q975": 1155.4606755125926,
            "rating_q025": 1111.4610357773342
        },
        "vicuna-7b": {
            "rating": 1126.0657321003728,
            "rating_q975": 1149.0292800799557,
            "rating_q025": 1103.1021841207898
        },
        "qwen1.5-4b-chat": {
            "rating": 1125.5933593630402,
            "rating_q975": 1143.032572535984,
            "rating_q025": 1108.1541461900965
        },
        "stripedhyena-nous-7b": {
            "rating": 1121.1996758742584,
            "rating_q975": 1143.458816476137,
            "rating_q025": 1098.94053527238
        },
        "guanaco-33b": {
            "rating": 1108.8124903873586,
            "rating_q975": 1144.8189460910935,
            "rating_q025": 1072.8060346836237
        },
        "olmo-7b-instruct": {
            "rating": 1103.1096315591758,
            "rating_q975": 1125.0961965974072,
            "rating_q025": 1081.1230665209443
        },
        "llama-2-7b-chat": {
            "rating": 1098.7268981250907,
            "rating_q975": 1112.7443136682798,
            "rating_q025": 1084.7094825819015
        },
        "chatglm3-6b": {
            "rating": 1084.5401376167324,
            "rating_q975": 1110.760033514944,
            "rating_q025": 1058.3202417185207
        },
        "mpt-7b-chat": {
            "rating": 1060.58859986169,
            "rating_q975": 1092.3704809793053,
            "rating_q025": 1028.8067187440747
        },
        "koala-13b": {
            "rating": 1059.6725849760194,
            "rating_q975": 1084.0462007447761,
            "rating_q025": 1035.2989692072626
        },
        "RWKV-4-Raven-14B": {
            "rating": 1053.2533195420933,
            "rating_q975": 1080.6358229901462,
            "rating_q025": 1025.8708160940405
        },
        "oasst-pythia-12b": {
            "rating": 1044.0785779829157,
            "rating_q975": 1069.3257474059574,
            "rating_q025": 1018.8314085598739
        },
        "chatglm-6b": {
            "rating": 1029.1137902788569,
            "rating_q975": 1056.578718919341,
            "rating_q025": 1001.6488616383726
        },
        "chatglm2-6b": {
            "rating": 1026.2484626862488,
            "rating_q975": 1061.406263427947,
            "rating_q025": 991.0906619445508
        },
        "stablelm-tuned-alpha-7b": {
            "rating": 998.5560711546095,
            "rating_q975": 1031.7741002931234,
            "rating_q025": 965.3380420160958
        },
        "alpaca-13b": {
            "rating": 992.9796348827947,
            "rating_q975": 1020.4098030603199,
            "rating_q025": 965.5494667052695
        },
        "dolly-v2-12b": {
            "rating": 956.2851177717339,
            "rating_q975": 990.7037154120783,
            "rating_q025": 921.8665201313895
        },
        "fastchat-t5-3b": {
            "rating": 901.665732012149,
            "rating_q975": 932.6368765877992,
            "rating_q025": 870.6945874364988
        },
        "llama-13b": {
            "rating": 874.989972843046,
            "rating_q975": 915.0250151165557,
            "rating_q025": 834.9549305695363
        }
    },
    "creative_writing": {
        "gemini-3-pro": {
            "rating": 1491.8863201102358,
            "rating_q975": 1505.7574964457897,
            "rating_q025": 1478.015143774682
        },
        "claude-opus-4-5-20251101": {
            "rating": 1457.1135851422966,
            "rating_q975": 1473.68500892111,
            "rating_q025": 1440.5421613634833
        },
        "claude-opus-4-5-20251101-thinking-32k": {
            "rating": 1452.5482123896757,
            "rating_q975": 1469.612568200812,
            "rating_q025": 1435.4838565785394
        },
        "gemini-2.5-pro": {
            "rating": 1451.6269639795637,
            "rating_q975": 1458.675269522011,
            "rating_q025": 1444.5786584371165
        },
        "grok-4.1-thinking": {
            "rating": 1445.0698602066013,
            "rating_q975": 1458.5325229087232,
            "rating_q025": 1431.6071975044795
        },
        "claude-opus-4-1-20250805-thinking-16k": {
            "rating": 1438.3393495564658,
            "rating_q975": 1446.8399215799855,
            "rating_q025": 1429.838777532946
        },
        "claude-sonnet-4-5-20250929-thinking-32k": {
            "rating": 1438.259739343159,
            "rating_q975": 1448.6291806970144,
            "rating_q025": 1427.8902979893037
        },
        "claude-sonnet-4-5-20250929": {
            "rating": 1437.3900573346523,
            "rating_q975": 1448.6057213441477,
            "rating_q025": 1426.1743933251569
        },
        "gpt-5.1-high": {
            "rating": 1436.934709979377,
            "rating_q975": 1451.550527753651,
            "rating_q025": 1422.3188922051029
        },
        "claude-opus-4-1-20250805": {
            "rating": 1433.6300996818782,
            "rating_q975": 1441.2602294085407,
            "rating_q025": 1425.9999699552156
        },
        "gpt-4.5-preview-2025-02-27": {
            "rating": 1432.9613457980493,
            "rating_q975": 1444.7276326967415,
            "rating_q025": 1421.195058899357
        },
        "grok-4.1": {
            "rating": 1423.8038181297268,
            "rating_q975": 1437.3749874142661,
            "rating_q025": 1410.2326488451874
        },
        "claude-opus-4-20250514-thinking-16k": {
            "rating": 1420.3797817520115,
            "rating_q975": 1429.4638671259925,
            "rating_q025": 1411.2956963780305
        },
        "chatgpt-4o-latest-20250326": {
            "rating": 1417.868081618365,
            "rating_q975": 1424.8197084435797,
            "rating_q025": 1410.9164547931505
        },
        "claude-opus-4-20250514": {
            "rating": 1411.0282910240012,
            "rating_q975": 1419.4609175531916,
            "rating_q025": 1402.5956644948108
        },
        "ernie-5.0-preview-1103": {
            "rating": 1407.3563620542675,
            "rating_q975": 1428.9214904061962,
            "rating_q025": 1385.7912337023388
        },
        "gpt-5.1": {
            "rating": 1406.6322515803854,
            "rating_q975": 1420.71693423038,
            "rating_q025": 1392.5475689303908
        },
        "deepseek-v3.2-thinking": {
            "rating": 1405.7314131952296,
            "rating_q975": 1427.3015926522314,
            "rating_q025": 1384.1612337382278
        },
        "grok-4-1-fast-reasoning": {
            "rating": 1404.4038996948861,
            "rating_q975": 1421.7889123721095,
            "rating_q025": 1387.0188870176628
        },
        "deepseek-v3.1-thinking": {
            "rating": 1403.6926760155422,
            "rating_q975": 1418.1802463738882,
            "rating_q025": 1389.2051056571963
        },
        "deepseek-v3.1-terminus": {
            "rating": 1403.6812238660718,
            "rating_q975": 1430.772910075166,
            "rating_q025": 1376.5895376569777
        },
        "kimi-k2-thinking-turbo": {
            "rating": 1401.3604916419906,
            "rating_q975": 1414.8449470616038,
            "rating_q025": 1387.8760362223775
        },
        "deepseek-v3.2-exp": {
            "rating": 1400.8448427448984,
            "rating_q975": 1416.0706741144222,
            "rating_q025": 1385.6190113753746
        },
        "gpt-4.1-2025-04-14": {
            "rating": 1399.0566790237801,
            "rating_q975": 1406.6649516441644,
            "rating_q025": 1391.448406403396
        },
        "gemini-2.5-flash": {
            "rating": 1397.21347064328,
            "rating_q975": 1404.0583758094408,
            "rating_q025": 1390.3685654771193
        },
        "grok-3-preview-02-24": {
            "rating": 1397.0622651970925,
            "rating_q975": 1405.9466564857555,
            "rating_q025": 1388.1778739084295
        },
        "glm-4.6": {
            "rating": 1396.9701109485482,
            "rating_q975": 1407.896059727809,
            "rating_q025": 1386.0441621692873
        },
        "qwen3-max-preview": {
            "rating": 1395.228620704046,
            "rating_q975": 1405.2876661498246,
            "rating_q025": 1385.1695752582675
        },
        "grok-4-0709": {
            "rating": 1394.0153303517975,
            "rating_q975": 1402.4013891774143,
            "rating_q025": 1385.6292715261807
        },
        "qwen3-max-2025-09-23": {
            "rating": 1393.9430802938039,
            "rating_q975": 1410.896963036332,
            "rating_q025": 1376.9891975512758
        },
        "deepseek-v3.2-exp-thinking": {
            "rating": 1393.7120821843591,
            "rating_q975": 1411.0480254505392,
            "rating_q025": 1376.376138918179
        },
        "deepseek-v3.1": {
            "rating": 1391.9299878642796,
            "rating_q975": 1405.1523964206217,
            "rating_q025": 1378.7075793079375
        },
        "claude-sonnet-4-20250514-thinking-32k": {
            "rating": 1391.807202826821,
            "rating_q975": 1400.9852967379843,
            "rating_q025": 1382.6291089156575
        },
        "deepseek-v3.2": {
            "rating": 1390.19237542663,
            "rating_q975": 1411.574979151897,
            "rating_q025": 1368.809771701363
        },
        "deepseek-v3-0324": {
            "rating": 1388.0246428873002,
            "rating_q975": 1395.9748780016287,
            "rating_q025": 1380.0744077729717
        },
        "deepseek-r1-0528": {
            "rating": 1387.9170824640642,
            "rating_q975": 1400.0314653612286,
            "rating_q025": 1375.8026995668997
        },
        "claude-3-7-sonnet-20250219-thinking-32k": {
            "rating": 1387.612592244697,
            "rating_q975": 1395.9792831838208,
            "rating_q025": 1379.2459013055732
        },
        "gpt-5-chat": {
            "rating": 1387.3099007079293,
            "rating_q975": 1396.923610365862,
            "rating_q025": 1377.6961910499965
        },
        "grok-4-fast-chat": {
            "rating": 1382.337611546261,
            "rating_q975": 1401.2159302456002,
            "rating_q025": 1363.459292846922
        },
        "o3-2025-04-16": {
            "rating": 1381.8328858079767,
            "rating_q975": 1389.1014772454703,
            "rating_q025": 1374.5642943704831
        },
        "gpt-5-high": {
            "rating": 1381.080960417887,
            "rating_q975": 1390.7693899391925,
            "rating_q025": 1371.3925308965813
        },
        "kimi-k2-0905-preview": {
            "rating": 1380.925114936552,
            "rating_q975": 1396.3307357622368,
            "rating_q025": 1365.5194941108673
        },
        "gemini-2.5-flash-preview-09-2025": {
            "rating": 1379.797777297111,
            "rating_q975": 1389.8901825689134,
            "rating_q025": 1369.7053720253086
        },
        "claude-sonnet-4-20250514": {
            "rating": 1379.6795038132295,
            "rating_q975": 1388.31869903259,
            "rating_q025": 1371.040308593869
        },
        "o1-2024-12-17": {
            "rating": 1379.3135692557498,
            "rating_q975": 1387.9802924021299,
            "rating_q025": 1370.6468461093698
        },
        "qwen3-235b-a22b-instruct-2507": {
            "rating": 1378.8926237402059,
            "rating_q975": 1386.6689882354183,
            "rating_q025": 1371.1162592449934
        },
        "mistral-medium-2508": {
            "rating": 1378.2647766696334,
            "rating_q975": 1386.617705416767,
            "rating_q025": 1369.9118479224999
        },
        "grok-4-fast-reasoning": {
            "rating": 1377.1360711659527,
            "rating_q975": 1389.3305769866447,
            "rating_q025": 1364.9415653452606
        },
        "claude-haiku-4-5-20251001": {
            "rating": 1376.479291451934,
            "rating_q975": 1387.1565483551065,
            "rating_q025": 1365.8020345487614
        },
        "hunyuan-t1-20250711": {
            "rating": 1375.916402188666,
            "rating_q975": 1399.6092606262885,
            "rating_q025": 1352.2235437510437
        },
        "deepseek-v3.1-terminus-thinking": {
            "rating": 1375.6413851203492,
            "rating_q975": 1403.8351806575301,
            "rating_q025": 1347.4475895831683
        },
        "mistral-large-3": {
            "rating": 1374.3339678958716,
            "rating_q975": 1394.5752409712272,
            "rating_q025": 1354.092694820516
        },
        "glm-4.5": {
            "rating": 1373.371465766722,
            "rating_q975": 1384.2383042697227,
            "rating_q025": 1362.5046272637212
        },
        "claude-3-7-sonnet-20250219": {
            "rating": 1372.7129179674573,
            "rating_q975": 1380.5755165254782,
            "rating_q025": 1364.8503194094365
        },
        "deepseek-r1": {
            "rating": 1371.7758803534239,
            "rating_q975": 1381.911229611913,
            "rating_q025": 1361.6405310949347
        },
        "kimi-k2-0711-preview": {
            "rating": 1370.6981765747314,
            "rating_q975": 1380.708182415214,
            "rating_q025": 1360.6881707342488
        },
        "qwen3-235b-a22b-thinking-2507": {
            "rating": 1370.562961623608,
            "rating_q975": 1388.086371636439,
            "rating_q025": 1353.0395516107772
        },
        "gemini-2.5-flash-lite-preview-06-17-thinking": {
            "rating": 1369.8947513892301,
            "rating_q975": 1379.1016252035631,
            "rating_q025": 1360.6878775748971
        },
        "claude-3-5-sonnet-20241022": {
            "rating": 1367.2135308524882,
            "rating_q975": 1373.114854485726,
            "rating_q025": 1361.3122072192505
        },
        "qwen3-235b-a22b-no-thinking": {
            "rating": 1365.5381822391414,
            "rating_q975": 1374.479000525741,
            "rating_q025": 1356.5973639525419
        },
        "o1-preview": {
            "rating": 1363.6551662369152,
            "rating_q975": 1373.2440853604742,
            "rating_q025": 1354.0662471133562
        },
        "hunyuan-turbos-20250416": {
            "rating": 1362.73566481391,
            "rating_q975": 1377.698049609163,
            "rating_q025": 1347.773280018657
        },
        "hunyuan-vision-1.5-thinking": {
            "rating": 1362.4297499486602,
            "rating_q975": 1398.9498069718188,
            "rating_q025": 1325.9096929255015
        },
        "qwen3-vl-235b-a22b-instruct": {
            "rating": 1361.266809897577,
            "rating_q975": 1378.914791753248,
            "rating_q025": 1343.6188280419062
        },
        "gemini-2.5-flash-lite-preview-09-2025-no-thinking": {
            "rating": 1360.051759577769,
            "rating_q975": 1370.0771967147903,
            "rating_q025": 1350.0263224407477
        },
        "qwen3-coder-480b-a35b-instruct": {
            "rating": 1359.8048927685977,
            "rating_q975": 1370.4349542655561,
            "rating_q025": 1349.1748312716393
        },
        "mistral-medium-2505": {
            "rating": 1359.3587863001285,
            "rating_q975": 1368.6181889421985,
            "rating_q025": 1350.0993836580585
        },
        "mai-1-preview": {
            "rating": 1357.583135098097,
            "rating_q975": 1370.4140345942265,
            "rating_q025": 1344.7522356019676
        },
        "gemini-1.5-pro-002": {
            "rating": 1357.3564321359838,
            "rating_q975": 1364.4232874442123,
            "rating_q025": 1350.2895768277554
        },
        "qwen2.5-max": {
            "rating": 1351.7244774229398,
            "rating_q975": 1359.961031408079,
            "rating_q025": 1343.4879234378006
        },
        "deepseek-v3": {
            "rating": 1347.3700803866848,
            "rating_q975": 1357.1700040486119,
            "rating_q025": 1337.5701567247577
        },
        "gemma-3-27b-it": {
            "rating": 1346.7083950675953,
            "rating_q975": 1354.199649870962,
            "rating_q025": 1339.2171402642286
        },
        "gemini-2.0-flash-001": {
            "rating": 1345.058284085572,
            "rating_q975": 1352.593863965146,
            "rating_q025": 1337.522704205998
        },
        "gpt-4.1-mini-2025-04-14": {
            "rating": 1344.109433277067,
            "rating_q975": 1352.7349004433222,
            "rating_q025": 1335.4839661108117
        },
        "gemini-2.0-flash-lite-preview-02-05": {
            "rating": 1343.687679401922,
            "rating_q975": 1352.7034989785382,
            "rating_q025": 1334.6718598253058
        },
        "qwen3-vl-235b-a22b-thinking": {
            "rating": 1342.6341146292953,
            "rating_q975": 1361.00730032898,
            "rating_q025": 1324.2609289296106
        },
        "gemini-advanced-0514": {
            "rating": 1341.3594748645373,
            "rating_q975": 1351.034634809112,
            "rating_q025": 1331.6843149199626
        },
        "o4-mini-2025-04-16": {
            "rating": 1338.997893031657,
            "rating_q975": 1347.0461809853084,
            "rating_q025": 1330.9496050780056
        },
        "grok-3-mini-beta": {
            "rating": 1335.465139785062,
            "rating_q975": 1346.367451167709,
            "rating_q025": 1324.562828402415
        },
        "gpt-4o-2024-05-13": {
            "rating": 1335.066833661636,
            "rating_q975": 1341.861455273917,
            "rating_q025": 1328.2722120493552
        },
        "step-2-16k-exp-202412": {
            "rating": 1334.2158815762873,
            "rating_q975": 1354.851238566954,
            "rating_q025": 1313.5805245856207
        },
        "command-a-03-2025": {
            "rating": 1333.6434849232598,
            "rating_q975": 1340.7495995144866,
            "rating_q025": 1326.537370332033
        },
        "llama-3.1-nemotron-ultra-253b-v1": {
            "rating": 1331.8273954428446,
            "rating_q975": 1358.5092541040801,
            "rating_q025": 1305.145536781609
        },
        "longcat-flash-chat": {
            "rating": 1330.9140458105824,
            "rating_q975": 1346.7355252464038,
            "rating_q025": 1315.092566374761
        },
        "gemma-3-12b-it": {
            "rating": 1330.5382087946125,
            "rating_q975": 1353.5389099232877,
            "rating_q025": 1307.5375076659373
        },
        "grok-3-mini-high": {
            "rating": 1330.1900163439418,
            "rating_q975": 1343.0162164595881,
            "rating_q025": 1317.3638162282955
        },
        "gpt-5-mini-high": {
            "rating": 1329.3996897589675,
            "rating_q975": 1339.8858765434793,
            "rating_q025": 1318.9135029744557
        },
        "qwen3-235b-a22b": {
            "rating": 1327.8641271979875,
            "rating_q975": 1337.7471261938767,
            "rating_q025": 1317.9811282020983
        },
        "glm-4.5-air": {
            "rating": 1326.8102275516749,
            "rating_q975": 1336.3424266550164,
            "rating_q025": 1317.2780284483333
        },
        "gpt-4o-2024-08-06": {
            "rating": 1323.4731561259232,
            "rating_q975": 1331.6517373154572,
            "rating_q025": 1315.2945749363892
        },
        "qwen3-30b-a3b-instruct-2507": {
            "rating": 1323.2910823101302,
            "rating_q975": 1334.1323706615553,
            "rating_q025": 1312.449793958705
        },
        "mistral-small-2506": {
            "rating": 1322.3626304309644,
            "rating_q975": 1334.6679832782384,
            "rating_q025": 1310.0572775836904
        },
        "minimax-m1": {
            "rating": 1322.1942737113259,
            "rating_q975": 1331.0927552129933,
            "rating_q025": 1313.2957922096584
        },
        "gpt-4-turbo-2024-04-09": {
            "rating": 1320.9523856182689,
            "rating_q975": 1328.4031035226856,
            "rating_q025": 1313.5016677138522
        },
        "qwen3-next-80b-a3b-thinking": {
            "rating": 1320.4743790808845,
            "rating_q975": 1334.943276068415,
            "rating_q025": 1306.0054820933542
        },
        "gemini-1.5-pro-001": {
            "rating": 1320.2458834378372,
            "rating_q975": 1328.0436112668228,
            "rating_q025": 1312.4481556088515
        },
        "glm-4-plus-0111": {
            "rating": 1316.80857187963,
            "rating_q975": 1335.713979743244,
            "rating_q025": 1297.9031640160163
        },
        "qwen3-next-80b-a3b-instruct": {
            "rating": 1316.7118299070016,
            "rating_q975": 1327.8209102965004,
            "rating_q025": 1305.6027495175028
        },
        "grok-2-2024-08-13": {
            "rating": 1315.4866531736607,
            "rating_q975": 1322.6055187085603,
            "rating_q025": 1308.367787638761
        },
        "qwen-plus-0125": {
            "rating": 1314.3183999457174,
            "rating_q975": 1332.2035454300062,
            "rating_q025": 1296.4332544614285
        },
        "o3-mini-high": {
            "rating": 1309.8649725487269,
            "rating_q975": 1320.4487842686465,
            "rating_q025": 1299.2811608288073
        },
        "glm-4.5v": {
            "rating": 1307.3957811542914,
            "rating_q975": 1330.2010209513464,
            "rating_q025": 1284.5905413572364
        },
        "deepseek-v2.5-1210": {
            "rating": 1307.332186573273,
            "rating_q975": 1324.2930491689426,
            "rating_q025": 1290.3713239776034
        },
        "llama-4-maverick-17b-128e-instruct": {
            "rating": 1305.9682381948694,
            "rating_q975": 1314.371294154195,
            "rating_q025": 1297.5651822355437
        },
        "gpt-4.1-nano-2025-04-14": {
            "rating": 1305.5588571874036,
            "rating_q975": 1323.8945191001915,
            "rating_q025": 1287.2231952746158
        },
        "nvidia-llama-3.3-nemotron-super-49b-v1.5": {
            "rating": 1304.7018332447874,
            "rating_q975": 1332.6134093113467,
            "rating_q025": 1276.790257178228
        },
        "step-3": {
            "rating": 1304.318390188767,
            "rating_q975": 1324.97546661312,
            "rating_q025": 1283.6613137644138
        },
        "qwen3-32b": {
            "rating": 1303.6486832675007,
            "rating_q975": 1326.2250259517396,
            "rating_q025": 1281.0723405832618
        },
        "llama-3.1-405b-instruct-fp8": {
            "rating": 1302.8849963969064,
            "rating_q975": 1310.2949812525815,
            "rating_q025": 1295.4750115412314
        },
        "claude-3-5-sonnet-20240620": {
            "rating": 1301.1897544673395,
            "rating_q975": 1308.4630830727483,
            "rating_q025": 1293.9164258619307
        },
        "o3-mini": {
            "rating": 1301.0238713153549,
            "rating_q975": 1307.7718383999602,
            "rating_q025": 1294.2759042307496
        },
        "hunyuan-turbos-20250226": {
            "rating": 1300.1375720643414,
            "rating_q975": 1325.7427252588857,
            "rating_q025": 1274.532418869797
        },
        "hunyuan-large-2025-02-10": {
            "rating": 1299.9299329663886,
            "rating_q975": 1323.7267568147251,
            "rating_q025": 1276.133109118052
        },
        "llama-3.1-405b-instruct-bf16": {
            "rating": 1299.8537677022373,
            "rating_q975": 1307.2332622653182,
            "rating_q025": 1292.4742731391564
        },
        "claude-3-5-haiku-20241022": {
            "rating": 1299.424548623914,
            "rating_q975": 1305.6537599368814,
            "rating_q025": 1293.1953373109466
        },
        "hunyuan-turbo-0110": {
            "rating": 1299.2036346894365,
            "rating_q975": 1324.366105821917,
            "rating_q025": 1274.041163556956
        },
        "gemini-1.5-flash-002": {
            "rating": 1297.3728694908675,
            "rating_q975": 1306.0177292348524,
            "rating_q025": 1288.7280097468827
        },
        "gemma-3n-e4b-it": {
            "rating": 1296.9313108248834,
            "rating_q975": 1307.8258088960577,
            "rating_q025": 1286.0368127537092
        },
        "yi-lightning": {
            "rating": 1296.2757019054602,
            "rating_q975": 1306.477476547085,
            "rating_q025": 1286.0739272638355
        },
        "llama-3.3-nemotron-49b-super-v1": {
            "rating": 1294.0264379050009,
            "rating_q975": 1321.0116073249694,
            "rating_q025": 1267.0412684850323
        },
        "qwq-32b": {
            "rating": 1293.199354627384,
            "rating_q975": 1302.825636432402,
            "rating_q025": 1283.5730728223662
        },
        "gpt-4o-mini-2024-07-18": {
            "rating": 1292.5058803370262,
            "rating_q975": 1299.1074123767446,
            "rating_q025": 1285.9043482973077
        },
        "gemma-2-27b-it": {
            "rating": 1290.301867917455,
            "rating_q975": 1296.7761441146583,
            "rating_q025": 1283.8275917202516
        },
        "amazon-nova-experimental-chat-10-09": {
            "rating": 1290.1193884692882,
            "rating_q975": 1306.924725718574,
            "rating_q025": 1273.3140512200023
        },
        "llama-4-scout-17b-16e-instruct": {
            "rating": 1289.6387233888283,
            "rating_q975": 1299.5258452625126,
            "rating_q025": 1279.751601515144
        },
        "glm-4-plus": {
            "rating": 1287.4321799466338,
            "rating_q975": 1297.4312215364182,
            "rating_q025": 1277.4331383568494
        },
        "step-1o-turbo-202506": {
            "rating": 1286.8673756845478,
            "rating_q975": 1304.971416568517,
            "rating_q025": 1268.7633348005786
        },
        "minimax-m2": {
            "rating": 1286.4737232117707,
            "rating_q975": 1307.0962515298825,
            "rating_q025": 1265.8511948936589
        },
        "magistral-medium-2506": {
            "rating": 1286.2923353677247,
            "rating_q975": 1302.2914424498294,
            "rating_q025": 1270.29322828562
        },
        "claude-3-opus-20240229": {
            "rating": 1285.98819669636,
            "rating_q975": 1292.1249372937204,
            "rating_q025": 1279.8514560989997
        },
        "mistral-large-2407": {
            "rating": 1285.5209834486168,
            "rating_q975": 1293.871762861859,
            "rating_q025": 1277.1702040353746
        },
        "llama-3.3-70b-instruct": {
            "rating": 1285.1004652182999,
            "rating_q975": 1291.8089539465852,
            "rating_q025": 1278.3919764900145
        },
        "gpt-4-1106-preview": {
            "rating": 1284.6627959639713,
            "rating_q975": 1292.286728774702,
            "rating_q025": 1277.0388631532408
        },
        "qwen3-30b-a3b": {
            "rating": 1284.6443371674084,
            "rating_q975": 1294.7761253906665,
            "rating_q025": 1274.5125489441502
        },
        "hunyuan-large-vision": {
            "rating": 1283.7778235676494,
            "rating_q975": 1306.8477587115797,
            "rating_q025": 1260.7078884237192
        },
        "qwen-max-0919": {
            "rating": 1283.2716586827466,
            "rating_q975": 1295.0902546914053,
            "rating_q025": 1271.453062674088
        },
        "gpt-oss-120b": {
            "rating": 1282.2164882995244,
            "rating_q975": 1292.0438483342987,
            "rating_q025": 1272.38912826475
        },
        "gemma-2-9b-it-simpo": {
            "rating": 1282.1385483545769,
            "rating_q975": 1296.6017732159876,
            "rating_q025": 1267.6753234931662
        },
        "o1-mini": {
            "rating": 1279.1646916767477,
            "rating_q975": 1286.500933490016,
            "rating_q025": 1271.8284498634794
        },
        "gpt-4-0125-preview": {
            "rating": 1278.750230329083,
            "rating_q975": 1286.5714070707158,
            "rating_q025": 1270.9290535874502
        },
        "intellect-3": {
            "rating": 1277.928389230855,
            "rating_q975": 1313.375660901792,
            "rating_q025": 1242.481117559918
        },
        "amazon-nova-experimental-chat-10-20": {
            "rating": 1277.3941663545197,
            "rating_q975": 1296.2381752742012,
            "rating_q025": 1258.5501574348382
        },
        "gemma-3-4b-it": {
            "rating": 1275.9219273387355,
            "rating_q975": 1297.932512474223,
            "rating_q025": 1253.911342203248
        },
        "llama-3.1-nemotron-70b-instruct": {
            "rating": 1275.5059116025614,
            "rating_q975": 1294.133372312267,
            "rating_q025": 1256.8784508928557
        },
        "mistral-large-2411": {
            "rating": 1273.6834778003522,
            "rating_q975": 1282.442632194707,
            "rating_q025": 1264.9243234059975
        },
        "hunyuan-standard-2025-02-10": {
            "rating": 1273.3597043925738,
            "rating_q975": 1297.193539233865,
            "rating_q025": 1249.5258695512825
        },
        "qwen2.5-plus-1127": {
            "rating": 1272.2608900217551,
            "rating_q975": 1286.4061007820626,
            "rating_q025": 1258.1156792614477
        },
        "mistral-small-3.1-24b-instruct-2503": {
            "rating": 1271.1172662081985,
            "rating_q975": 1280.5248363133321,
            "rating_q025": 1261.709696103065
        },
        "grok-2-mini-2024-08-13": {
            "rating": 1270.736510244169,
            "rating_q975": 1278.141053387126,
            "rating_q025": 1263.331967101212
        },
        "ling-flash-2.0": {
            "rating": 1270.7177250849477,
            "rating_q975": 1291.1653856825617,
            "rating_q025": 1250.2700644873337
        },
        "nova-2-lite": {
            "rating": 1269.6294212635719,
            "rating_q975": 1293.6051951738164,
            "rating_q025": 1245.6536473533274
        },
        "athene-70b-0725": {
            "rating": 1268.242610982134,
            "rating_q975": 1279.3164905697504,
            "rating_q025": 1257.1687313945176
        },
        "reka-core-20240904": {
            "rating": 1265.0576055830234,
            "rating_q975": 1283.2225352169849,
            "rating_q025": 1246.8926759490619
        },
        "deepseek-v2.5": {
            "rating": 1263.5046022790093,
            "rating_q975": 1273.9645736686764,
            "rating_q025": 1253.0446308893422
        },
        "gpt-4-0613": {
            "rating": 1262.8875343982725,
            "rating_q975": 1270.938977972548,
            "rating_q025": 1254.836090823997
        },
        "command-r-plus-08-2024": {
            "rating": 1262.350879743928,
            "rating_q975": 1277.2233484058959,
            "rating_q025": 1247.4784110819603
        },
        "gemini-1.5-flash-001": {
            "rating": 1262.1492109750016,
            "rating_q975": 1270.301553603603,
            "rating_q025": 1253.9968683464
        },
        "olmo-3-32b-think": {
            "rating": 1261.8968820953594,
            "rating_q975": 1290.5610893704936,
            "rating_q025": 1233.2326748202252
        },
        "llama-3.1-nemotron-51b-instruct": {
            "rating": 1259.4609510481278,
            "rating_q975": 1284.8197434894398,
            "rating_q025": 1234.1021586068157
        },
        "jamba-1.5-large": {
            "rating": 1259.0948968518883,
            "rating_q975": 1275.1026898418258,
            "rating_q025": 1243.0871038619507
        },
        "llama-3.1-70b-instruct": {
            "rating": 1256.7370013362365,
            "rating_q975": 1264.2195984711866,
            "rating_q025": 1249.2544042012864
        },
        "ring-flash-2.0": {
            "rating": 1256.1184277813395,
            "rating_q975": 1276.0860950342178,
            "rating_q025": 1236.1507605284612
        },
        "gemma-2-9b-it": {
            "rating": 1255.8521254956722,
            "rating_q975": 1262.9963675435433,
            "rating_q025": 1248.7078834478011
        },
        "gpt-5-nano-high": {
            "rating": 1254.067170728356,
            "rating_q975": 1274.265482385705,
            "rating_q025": 1233.868859071007
        },
        "llama-3-70b-instruct": {
            "rating": 1253.2422350738061,
            "rating_q975": 1260.5043541949078,
            "rating_q025": 1245.9801159527044
        },
        "qwen2.5-72b-instruct": {
            "rating": 1252.3380310169134,
            "rating_q975": 1260.472464340925,
            "rating_q025": 1244.203597692902
        },
        "gpt-4-0314": {
            "rating": 1252.1346098613913,
            "rating_q975": 1261.8611881330362,
            "rating_q025": 1242.4080315897463
        },
        "athene-v2-chat": {
            "rating": 1250.8946590938708,
            "rating_q975": 1260.427820781964,
            "rating_q025": 1241.3614974057775
        },
        "llama-3.1-tulu-3-70b": {
            "rating": 1246.6280218491488,
            "rating_q975": 1271.406656449127,
            "rating_q025": 1221.8493872491706
        },
        "claude-3-sonnet-20240229": {
            "rating": 1243.7839195250808,
            "rating_q975": 1251.73205108603,
            "rating_q025": 1235.8357879641317
        },
        "reka-flash-20240904": {
            "rating": 1240.7894792876687,
            "rating_q975": 1258.1737090436138,
            "rating_q025": 1223.4052495317235
        },
        "glm-4-0520": {
            "rating": 1239.7746227401803,
            "rating_q975": 1254.8325276213764,
            "rating_q025": 1224.7167178589843
        },
        "mercury": {
            "rating": 1238.8378532422523,
            "rating_q975": 1278.958002933208,
            "rating_q025": 1198.7177035512966
        },
        "gpt-oss-20b": {
            "rating": 1238.6393482689177,
            "rating_q975": 1256.5680255542852,
            "rating_q025": 1220.7106709835502
        },
        "nemotron-4-340b-instruct": {
            "rating": 1237.2173201815763,
            "rating_q975": 1248.6202355037137,
            "rating_q025": 1225.8144048594388
        },
        "gemini-1.5-flash-8b-001": {
            "rating": 1237.212022997654,
            "rating_q975": 1245.7798121981423,
            "rating_q025": 1228.6442337971657
        },
        "command-r-plus": {
            "rating": 1235.3384760066076,
            "rating_q975": 1243.7168612312014,
            "rating_q025": 1226.9600907820138
        },
        "amazon-nova-pro-v1.0": {
            "rating": 1234.5710708690665,
            "rating_q975": 1243.8667777826047,
            "rating_q025": 1225.2753639555283
        },
        "c4ai-aya-expanse-32b": {
            "rating": 1226.235892846867,
            "rating_q975": 1235.9511750538027,
            "rating_q025": 1216.5206106399314
        },
        "mistral-small-24b-instruct-2501": {
            "rating": 1225.475882863831,
            "rating_q975": 1237.607415900051,
            "rating_q025": 1213.344349827611
        },
        "olmo-2-0325-32b-instruct": {
            "rating": 1223.999070848588,
            "rating_q975": 1248.3590320270657,
            "rating_q025": 1199.6391096701102
        },
        "qwen2-72b-instruct": {
            "rating": 1222.416193973423,
            "rating_q975": 1231.756598827193,
            "rating_q025": 1213.075789119653
        },
        "amazon-nova-lite-v1.0": {
            "rating": 1219.1336039416728,
            "rating_q975": 1229.4144551228767,
            "rating_q025": 1208.852752760469
        },
        "ministral-8b-2410": {
            "rating": 1218.2253306428188,
            "rating_q975": 1240.1667262744743,
            "rating_q025": 1196.2839350111633
        },
        "claude-3-haiku-20240307": {
            "rating": 1213.5545866099249,
            "rating_q975": 1220.8602870624816,
            "rating_q025": 1206.2488861573681
        },
        "mistral-large-2402": {
            "rating": 1209.869031038043,
            "rating_q975": 1219.035400162102,
            "rating_q025": 1200.702661913984
        },
        "jamba-1.5-mini": {
            "rating": 1208.9393222733595,
            "rating_q975": 1224.559852829533,
            "rating_q025": 1193.318791717186
        },
        "command-r-08-2024": {
            "rating": 1208.9169061548946,
            "rating_q975": 1224.326962463919,
            "rating_q025": 1193.5068498458702
        },
        "phi-4": {
            "rating": 1208.7784789535995,
            "rating_q975": 1218.2321823191496,
            "rating_q025": 1199.3247755880493
        },
        "qwen2.5-coder-32b-instruct": {
            "rating": 1202.1788801895805,
            "rating_q975": 1221.335881653411,
            "rating_q025": 1183.02187872575
        },
        "deepseek-coder-v2": {
            "rating": 1201.9053970350833,
            "rating_q975": 1214.9275853029533,
            "rating_q025": 1188.8832087672133
        },
        "gemini-pro-dev-api": {
            "rating": 1200.7283926287746,
            "rating_q975": 1214.4918356286103,
            "rating_q025": 1186.964949628939
        },
        "wizardlm-70b": {
            "rating": 1196.7434581191753,
            "rating_q975": 1213.4849519094234,
            "rating_q025": 1180.0019643289272
        },
        "amazon-nova-micro-v1.0": {
            "rating": 1196.5721775914521,
            "rating_q975": 1207.108504102863,
            "rating_q025": 1186.0358510800413
        },
        "llama-3-8b-instruct": {
            "rating": 1195.3600083603974,
            "rating_q975": 1203.2400428951855,
            "rating_q025": 1187.4799738256092
        },
        "command-r": {
            "rating": 1194.7763779254026,
            "rating_q975": 1204.3133899019551,
            "rating_q025": 1185.23936594885
        },
        "hunyuan-standard-256k": {
            "rating": 1194.11220565447,
            "rating_q975": 1223.3080237592094,
            "rating_q025": 1164.9163875497306
        },
        "llama-3.1-tulu-3-8b": {
            "rating": 1193.3936138537347,
            "rating_q975": 1218.5372032912826,
            "rating_q025": 1168.2500244161868
        },
        "mistral-medium": {
            "rating": 1193.1967225371286,
            "rating_q975": 1203.9003061313033,
            "rating_q025": 1182.493138942954
        },
        "qwen1.5-110b-chat": {
            "rating": 1192.2904767241844,
            "rating_q975": 1203.688872244312,
            "rating_q025": 1180.8920812040567
        },
        "mixtral-8x22b-instruct-v0.1": {
            "rating": 1188.9455254150298,
            "rating_q975": 1198.0164128973183,
            "rating_q025": 1179.8746379327413
        },
        "c4ai-aya-expanse-8b": {
            "rating": 1188.9252549565779,
            "rating_q975": 1203.7298081288197,
            "rating_q025": 1174.120701784336
        },
        "qwen1.5-72b-chat": {
            "rating": 1186.381828558337,
            "rating_q975": 1196.2991046506763,
            "rating_q025": 1176.4645524659977
        },
        "gpt-3.5-turbo-0125": {
            "rating": 1186.3029629335101,
            "rating_q975": 1194.8754882095905,
            "rating_q025": 1177.7304376574298
        },
        "openchat-3.5": {
            "rating": 1183.223560928803,
            "rating_q975": 1200.7986711633544,
            "rating_q025": 1165.6484506942516
        },
        "gemma-2-2b-it": {
            "rating": 1181.9918503800623,
            "rating_q975": 1189.987877284372,
            "rating_q025": 1173.9958234757526
        },
        "gemini-pro": {
            "rating": 1181.2713785049004,
            "rating_q975": 1202.412558644216,
            "rating_q025": 1160.1301983655849
        },
        "reka-flash-21b-20240226-online": {
            "rating": 1180.055988121289,
            "rating_q975": 1194.4024125231888,
            "rating_q025": 1165.709563719389
        },
        "llama-3.1-8b-instruct": {
            "rating": 1176.9100267154531,
            "rating_q975": 1185.025293878309,
            "rating_q025": 1168.7947595525973
        },
        "reka-flash-21b-20240226": {
            "rating": 1174.591968924803,
            "rating_q975": 1186.5901094854714,
            "rating_q025": 1162.5938283641347
        },
        "vicuna-33b": {
            "rating": 1172.2106259504835,
            "rating_q975": 1184.0518750573724,
            "rating_q025": 1160.3693768435946
        },
        "granite-3.1-8b-instruct": {
            "rating": 1168.8294382266963,
            "rating_q975": 1195.0892494073562,
            "rating_q025": 1142.5696270460364
        },
        "zephyr-orpo-141b-A35b-v0.1": {
            "rating": 1166.2657792432324,
            "rating_q975": 1189.4564031079883,
            "rating_q025": 1143.0751553784764
        },
        "dbrx-instruct-preview": {
            "rating": 1162.864528899061,
            "rating_q975": 1174.3758424536834,
            "rating_q025": 1151.3532153444387
        },
        "mixtral-8x7b-instruct-v0.1": {
            "rating": 1158.0571431071035,
            "rating_q975": 1166.4415192658491,
            "rating_q025": 1149.6727669483578
        },
        "yi-1.5-34b-chat": {
            "rating": 1157.9859537679476,
            "rating_q975": 1168.8979504030683,
            "rating_q025": 1147.073957132827
        },
        "openhermes-2.5-mistral-7b": {
            "rating": 1156.126528035642,
            "rating_q975": 1177.933593622867,
            "rating_q025": 1134.319462448417
        },
        "yi-34b-chat": {
            "rating": 1153.7090850975567,
            "rating_q975": 1167.216445231496,
            "rating_q025": 1140.2017249636174
        },
        "falcon-180b-chat": {
            "rating": 1152.0154766534974,
            "rating_q975": 1189.0939765741048,
            "rating_q025": 1114.9369767328901
        },
        "gpt-3.5-turbo-1106": {
            "rating": 1149.8269039699207,
            "rating_q975": 1164.7876963713065,
            "rating_q025": 1134.866111568535
        },
        "phi-3-medium-4k-instruct": {
            "rating": 1148.513310858066,
            "rating_q975": 1159.2303706195746,
            "rating_q025": 1137.7962510965574
        },
        "granite-3.1-2b-instruct": {
            "rating": 1148.0798825694283,
            "rating_q975": 1176.8586077214998,
            "rating_q025": 1119.3011574173568
        },
        "gemma-1.1-7b-it": {
            "rating": 1145.9817836627133,
            "rating_q975": 1157.3971974398778,
            "rating_q025": 1134.5663698855487
        },
        "openchat-3.5-0106": {
            "rating": 1145.4951561507328,
            "rating_q975": 1160.2512102707083,
            "rating_q025": 1130.7391020307573
        },
        "tulu-2-dpo-70b": {
            "rating": 1145.4482288297504,
            "rating_q975": 1164.6589025657358,
            "rating_q025": 1126.237555093765
        },
        "llama-3.2-3b-instruct": {
            "rating": 1143.0136711236955,
            "rating_q975": 1162.4982349272614,
            "rating_q025": 1123.5291073201297
        },
        "snowflake-arctic-instruct": {
            "rating": 1141.7899651551631,
            "rating_q975": 1153.6893565934467,
            "rating_q025": 1129.8905737168795
        },
        "wizardlm-13b": {
            "rating": 1139.348394850971,
            "rating_q975": 1156.911513621386,
            "rating_q025": 1121.7852760805563
        },
        "solar-10.7b-instruct-v1.0": {
            "rating": 1138.9339874315165,
            "rating_q975": 1162.5832780739204,
            "rating_q025": 1115.2846967891126
        },
        "qwen1.5-14b-chat": {
            "rating": 1136.7450220772482,
            "rating_q975": 1150.754327368327,
            "rating_q025": 1122.7357167861694
        },
        "granite-3.0-8b-instruct": {
            "rating": 1136.3365205432963,
            "rating_q975": 1157.4437116640931,
            "rating_q025": 1115.2293294224994
        },
        "nous-hermes-2-mixtral-8x7b-dpo": {
            "rating": 1135.193175114796,
            "rating_q975": 1158.4555623579306,
            "rating_q025": 1111.9307878716616
        },
        "starling-lm-7b-alpha": {
            "rating": 1134.9679768584338,
            "rating_q975": 1150.46817614517,
            "rating_q025": 1119.4677775716975
        },
        "zephyr-7b-beta": {
            "rating": 1134.5605079934817,
            "rating_q975": 1150.4579734834833,
            "rating_q025": 1118.66304250348
        },
        "dolphin-2.2.1-mistral-7b": {
            "rating": 1133.8302845541418,
            "rating_q975": 1167.463543726485,
            "rating_q025": 1100.1970253817985
        },
        "phi-3-small-8k-instruct": {
            "rating": 1132.4907680952144,
            "rating_q975": 1145.403016342633,
            "rating_q025": 1119.5785198477959
        },
        "guanaco-33b": {
            "rating": 1132.4486758572907,
            "rating_q975": 1159.926636952995,
            "rating_q025": 1104.9707147615864
        },
        "mpt-30b-chat": {
            "rating": 1131.8880072910656,
            "rating_q975": 1160.8680686086948,
            "rating_q025": 1102.9079459734364
        },
        "qwen1.5-32b-chat": {
            "rating": 1131.5931058339334,
            "rating_q975": 1143.8983085390341,
            "rating_q025": 1119.2879031288326
        },
        "deepseek-llm-67b-chat": {
            "rating": 1131.0763700294738,
            "rating_q975": 1152.710516737546,
            "rating_q025": 1109.4422233214016
        },
        "internlm2_5-20b-chat": {
            "rating": 1130.4713942056237,
            "rating_q975": 1146.3975473760618,
            "rating_q025": 1114.5452410351857
        },
        "vicuna-13b": {
            "rating": 1123.6981577806062,
            "rating_q975": 1136.285996774379,
            "rating_q025": 1111.1103187868332
        },
        "llama2-70b-steerlm-chat": {
            "rating": 1119.002622760348,
            "rating_q975": 1144.208910303467,
            "rating_q025": 1093.796335217229
        },
        "llama-2-70b-chat": {
            "rating": 1112.0740729427714,
            "rating_q975": 1122.0024367297467,
            "rating_q025": 1102.145709155796
        },
        "starling-lm-7b-beta": {
            "rating": 1109.1708983303906,
            "rating_q975": 1123.6609812139982,
            "rating_q025": 1094.680815446783
        },
        "qwq-32b-preview": {
            "rating": 1106.946132171055,
            "rating_q975": 1136.1883250680771,
            "rating_q025": 1077.703939274033
        },
        "mistral-7b-instruct-v0.2": {
            "rating": 1104.5617921408161,
            "rating_q975": 1116.9468952361078,
            "rating_q025": 1092.1766890455244
        },
        "zephyr-7b-alpha": {
            "rating": 1101.5526578789804,
            "rating_q975": 1131.3134117263282,
            "rating_q025": 1071.7919040316326
        },
        "qwen-14b-chat": {
            "rating": 1099.7758394781167,
            "rating_q975": 1120.5065033101337,
            "rating_q025": 1079.0451756460998
        },
        "gemma-7b-it": {
            "rating": 1098.2537000037828,
            "rating_q975": 1115.9510222183085,
            "rating_q025": 1080.556377789257
        },
        "granite-3.0-2b-instruct": {
            "rating": 1097.5853768132883,
            "rating_q975": 1119.0588750981492,
            "rating_q025": 1076.1118785284275
        },
        "phi-3-mini-4k-instruct-june-2024": {
            "rating": 1093.7286842316673,
            "rating_q975": 1108.2485362034251,
            "rating_q025": 1079.2088322599095
        },
        "mistral-7b-instruct": {
            "rating": 1091.6411386183174,
            "rating_q975": 1108.3611300268249,
            "rating_q025": 1074.92114720981
        },
        "llama-2-13b-chat": {
            "rating": 1091.4348889187231,
            "rating_q975": 1103.8320311387897,
            "rating_q025": 1079.0377466986565
        },
        "stripedhyena-nous-7b": {
            "rating": 1089.7346366183365,
            "rating_q975": 1110.48892270418,
            "rating_q025": 1068.980350532493
        },
        "gemma-1.1-2b-it": {
            "rating": 1089.4041668176415,
            "rating_q975": 1106.1188662063064,
            "rating_q025": 1072.6894674289765
        },
        "alpaca-13b": {
            "rating": 1088.3417773272126,
            "rating_q975": 1110.3097402844276,
            "rating_q025": 1066.3738143699977
        },
        "vicuna-7b": {
            "rating": 1087.9908934891246,
            "rating_q975": 1105.9318267787596,
            "rating_q025": 1070.0499601994895
        },
        "phi-3-mini-128k-instruct": {
            "rating": 1086.0446306219237,
            "rating_q975": 1100.2758891282572,
            "rating_q025": 1071.8133721155903
        },
        "palm-2": {
            "rating": 1085.5289570791483,
            "rating_q975": 1102.9292830651982,
            "rating_q025": 1068.1286310930984
        },
        "codellama-34b-instruct": {
            "rating": 1084.6817824349919,
            "rating_q975": 1101.2054343157185,
            "rating_q025": 1068.1581305542652
        },
        "llama-3.2-1b-instruct": {
            "rating": 1083.771888811059,
            "rating_q975": 1104.0866523960624,
            "rating_q025": 1063.4571252260555
        },
        "qwen1.5-7b-chat": {
            "rating": 1078.510340352141,
            "rating_q975": 1101.4210726018348,
            "rating_q025": 1055.599608102447
        },
        "smollm2-1.7b-instruct": {
            "rating": 1078.3443178164734,
            "rating_q975": 1113.2085064648186,
            "rating_q025": 1043.4801291681283
        },
        "gemma-2b-it": {
            "rating": 1074.2354320917052,
            "rating_q975": 1097.5160579852738,
            "rating_q025": 1050.9548061981366
        },
        "llama-2-7b-chat": {
            "rating": 1072.5180717910828,
            "rating_q975": 1085.9399725152848,
            "rating_q025": 1059.0961710668807
        },
        "phi-3-mini-4k-instruct": {
            "rating": 1070.3408934284428,
            "rating_q975": 1083.0526221176399,
            "rating_q025": 1057.6291647392457
        },
        "gpt4all-13b-snoozy": {
            "rating": 1059.362317128868,
            "rating_q975": 1096.4411051719178,
            "rating_q025": 1022.2835290858181
        },
        "mpt-7b-chat": {
            "rating": 1047.3208297104939,
            "rating_q975": 1071.5344940865887,
            "rating_q025": 1023.1071653343989
        },
        "qwen1.5-4b-chat": {
            "rating": 1046.7242444352378,
            "rating_q975": 1065.4803875532655,
            "rating_q025": 1027.96810131721
        },
        "koala-13b": {
            "rating": 1042.2686105400967,
            "rating_q975": 1062.8843958620678,
            "rating_q025": 1021.6528252181256
        },
        "chatglm3-6b": {
            "rating": 1038.9015074258095,
            "rating_q975": 1061.9665392787363,
            "rating_q025": 1015.8364755728828
        },
        "oasst-pythia-12b": {
            "rating": 1008.3545418021141,
            "rating_q975": 1028.827413447813,
            "rating_q025": 987.8816701564155
        },
        "olmo-7b-instruct": {
            "rating": 1005.2419454267124,
            "rating_q975": 1025.4829998368598,
            "rating_q025": 985.0008910165649
        },
        "chatglm2-6b": {
            "rating": 1003.7907137221009,
            "rating_q975": 1029.9052713008819,
            "rating_q025": 977.67615614332
        },
        "RWKV-4-Raven-14B": {
            "rating": 1002.6660691745499,
            "rating_q975": 1025.1701530182727,
            "rating_q025": 980.1619853308271
        },
        "fastchat-t5-3b": {
            "rating": 987.1206840804849,
            "rating_q975": 1011.2131780339616,
            "rating_q025": 963.0281901270082
        },
        "dolly-v2-12b": {
            "rating": 964.8983229770172,
            "rating_q975": 992.5893105482461,
            "rating_q025": 937.2073354057883
        },
        "chatglm-6b": {
            "rating": 949.9536980530563,
            "rating_q975": 974.6319844564558,
            "rating_q025": 925.2754116496568
        },
        "llama-13b": {
            "rating": 929.1330645476072,
            "rating_q975": 962.8616001005986,
            "rating_q025": 895.4045289946158
        },
        "stablelm-tuned-alpha-7b": {
            "rating": 928.2617659321398,
            "rating_q975": 956.7390660630513,
            "rating_q025": 899.7844658012284
        }
    },
    "english": {
        "gemini-3-pro": {
            "rating": 1493.1650468844268,
            "rating_q975": 1501.4956878178275,
            "rating_q025": 1484.8344059510262
        },
        "claude-opus-4-5-20251101-thinking-32k": {
            "rating": 1484.4347434744561,
            "rating_q975": 1494.1532359265561,
            "rating_q025": 1474.7162510223561
        },
        "grok-4.1-thinking": {
            "rating": 1482.6029597811234,
            "rating_q975": 1490.6820428714855,
            "rating_q025": 1474.5238766907614
        },
        "grok-4.1": {
            "rating": 1478.2759729062745,
            "rating_q975": 1486.4348621356387,
            "rating_q025": 1470.1170836769104
        },
        "claude-opus-4-5-20251101": {
            "rating": 1476.3525621199071,
            "rating_q975": 1485.9404138023328,
            "rating_q025": 1466.7647104374814
        },
        "claude-sonnet-4-5-20250929-thinking-32k": {
            "rating": 1469.4503411789308,
            "rating_q975": 1475.4336110990737,
            "rating_q025": 1463.4670712587879
        },
        "claude-opus-4-1-20250805-thinking-16k": {
            "rating": 1466.17264857065,
            "rating_q975": 1471.193603189007,
            "rating_q025": 1461.1516939522928
        },
        "gpt-5.1-high": {
            "rating": 1466.034782725921,
            "rating_q975": 1474.7157647399408,
            "rating_q025": 1457.3538007119014
        },
        "claude-sonnet-4-5-20250929": {
            "rating": 1460.8322765582059,
            "rating_q975": 1467.3868827289193,
            "rating_q025": 1454.2776703874924
        },
        "gemini-2.5-pro": {
            "rating": 1453.9871605134624,
            "rating_q975": 1458.403696966717,
            "rating_q025": 1449.5706240602078
        },
        "claude-opus-4-1-20250805": {
            "rating": 1453.1862086047452,
            "rating_q975": 1457.92569836256,
            "rating_q025": 1448.4467188469303
        },
        "chatgpt-4o-latest-20250326": {
            "rating": 1447.3975453553605,
            "rating_q975": 1451.63437412503,
            "rating_q025": 1443.160716585691
        },
        "gpt-4.5-preview-2025-02-27": {
            "rating": 1446.4353303164362,
            "rating_q975": 1453.4453553074254,
            "rating_q025": 1439.425305325447
        },
        "grok-4-1-fast-reasoning": {
            "rating": 1443.9549542704744,
            "rating_q975": 1453.3424227782286,
            "rating_q025": 1434.5674857627203
        },
        "gpt-5.1": {
            "rating": 1443.3664074576543,
            "rating_q975": 1451.6150957217237,
            "rating_q025": 1435.117719193585
        },
        "kimi-k2-thinking-turbo": {
            "rating": 1442.5782568056718,
            "rating_q975": 1450.3959918093963,
            "rating_q025": 1434.7605218019473
        },
        "o3-2025-04-16": {
            "rating": 1442.276044495536,
            "rating_q975": 1446.8420338048916,
            "rating_q025": 1437.7100551861806
        },
        "gpt-5-high": {
            "rating": 1441.1528662597448,
            "rating_q975": 1446.9512850797419,
            "rating_q025": 1435.3544474397477
        },
        "qwen3-max-preview": {
            "rating": 1440.944657161934,
            "rating_q975": 1446.874959047345,
            "rating_q025": 1435.0143552765228
        },
        "deepseek-v3.2-thinking": {
            "rating": 1440.473177512847,
            "rating_q975": 1451.5778801276776,
            "rating_q025": 1429.3684748980165
        },
        "deepseek-v3.2": {
            "rating": 1439.3821464060256,
            "rating_q975": 1450.444018307888,
            "rating_q025": 1428.3202745041633
        },
        "glm-4.6": {
            "rating": 1439.1341276538433,
            "rating_q975": 1445.3242677419025,
            "rating_q025": 1432.943987565784
        },
        "deepseek-v3.2-exp-thinking": {
            "rating": 1438.0110121222867,
            "rating_q975": 1447.0570699663883,
            "rating_q025": 1428.9649542781851
        },
        "deepseek-v3.2-exp": {
            "rating": 1437.7080286386054,
            "rating_q975": 1446.3059786971517,
            "rating_q025": 1429.110078580059
        },
        "ernie-5.0-preview-1103": {
            "rating": 1436.7506554569266,
            "rating_q975": 1448.5394213233872,
            "rating_q025": 1424.961889590466
        },
        "claude-opus-4-20250514-thinking-16k": {
            "rating": 1434.1556567845073,
            "rating_q975": 1439.6505556995248,
            "rating_q025": 1428.6607578694898
        },
        "gpt-5-chat": {
            "rating": 1433.2753925697698,
            "rating_q975": 1438.8887809112477,
            "rating_q025": 1427.6620042282918
        },
        "qwen3-max-2025-09-23": {
            "rating": 1432.618186886319,
            "rating_q975": 1441.327183867749,
            "rating_q025": 1423.9091899048892
        },
        "deepseek-v3.1-thinking": {
            "rating": 1432.5805965524585,
            "rating_q975": 1441.1515006686514,
            "rating_q025": 1424.0096924362656
        },
        "grok-4-fast-chat": {
            "rating": 1430.185143056493,
            "rating_q975": 1440.5353696001735,
            "rating_q025": 1419.8349165128125
        },
        "mistral-large-3": {
            "rating": 1429.663485685868,
            "rating_q975": 1440.546017430103,
            "rating_q025": 1418.780953941633
        },
        "qwen3-235b-a22b-instruct-2507": {
            "rating": 1429.566868886403,
            "rating_q975": 1434.330716227894,
            "rating_q025": 1424.8030215449119
        },
        "deepseek-v3.1": {
            "rating": 1429.2894554451632,
            "rating_q975": 1437.0801826221243,
            "rating_q025": 1421.498728268202
        },
        "deepseek-r1-0528": {
            "rating": 1429.282882059326,
            "rating_q975": 1436.3541511064057,
            "rating_q025": 1422.2116130122465
        },
        "qwen3-vl-235b-a22b-instruct": {
            "rating": 1429.156667003014,
            "rating_q975": 1438.2117030201723,
            "rating_q025": 1420.1016309858558
        },
        "mistral-medium-2508": {
            "rating": 1426.9970209673652,
            "rating_q975": 1432.0395509211514,
            "rating_q025": 1421.954491013579
        },
        "claude-haiku-4-5-20251001": {
            "rating": 1426.5063237732982,
            "rating_q975": 1432.6153948308734,
            "rating_q025": 1420.397252715723
        },
        "deepseek-v3.1-terminus-thinking": {
            "rating": 1426.1670364441895,
            "rating_q975": 1440.4260864943822,
            "rating_q025": 1411.907986393997
        },
        "kimi-k2-0905-preview": {
            "rating": 1424.9612009512214,
            "rating_q975": 1433.4003234389315,
            "rating_q025": 1416.5220784635112
        },
        "longcat-flash-chat": {
            "rating": 1424.7949395038893,
            "rating_q975": 1433.0997890082751,
            "rating_q025": 1416.4900899995034
        },
        "kimi-k2-0711-preview": {
            "rating": 1424.6268268878002,
            "rating_q975": 1430.669606442974,
            "rating_q025": 1418.5840473326264
        },
        "deepseek-v3.1-terminus": {
            "rating": 1424.2887264586318,
            "rating_q975": 1438.0535433885111,
            "rating_q025": 1410.5239095287525
        },
        "claude-opus-4-20250514": {
            "rating": 1423.6565691316432,
            "rating_q975": 1428.963751118673,
            "rating_q025": 1418.3493871446135
        },
        "gpt-4.1-2025-04-14": {
            "rating": 1422.4720606644587,
            "rating_q975": 1427.148988609286,
            "rating_q025": 1417.7951327196313
        },
        "grok-3-preview-02-24": {
            "rating": 1421.1516800672546,
            "rating_q975": 1426.4110248890925,
            "rating_q025": 1415.8923352454167
        },
        "grok-4-0709": {
            "rating": 1419.866627427953,
            "rating_q975": 1424.8850260742713,
            "rating_q025": 1414.8482287816348
        },
        "glm-4.5": {
            "rating": 1418.6136786561374,
            "rating_q975": 1424.929833763016,
            "rating_q025": 1412.2975235492588
        },
        "claude-sonnet-4-20250514-thinking-32k": {
            "rating": 1416.932951666354,
            "rating_q975": 1422.449508013602,
            "rating_q025": 1411.416395319106
        },
        "gemini-2.5-flash-preview-09-2025": {
            "rating": 1414.7546175861962,
            "rating_q975": 1420.5812104897414,
            "rating_q025": 1408.928024682651
        },
        "grok-4-fast-reasoning": {
            "rating": 1414.3763168395883,
            "rating_q975": 1421.0549434054496,
            "rating_q025": 1407.697690273727
        },
        "gemini-2.5-flash": {
            "rating": 1411.3268215174046,
            "rating_q975": 1415.6224492049826,
            "rating_q025": 1407.0311938298266
        },
        "deepseek-r1": {
            "rating": 1411.1083425850143,
            "rating_q975": 1417.1160969349253,
            "rating_q025": 1405.1005882351033
        },
        "o1-2024-12-17": {
            "rating": 1410.8577826023397,
            "rating_q975": 1416.2541896740788,
            "rating_q025": 1405.4613755306007
        },
        "qwen3-next-80b-a3b-instruct": {
            "rating": 1410.6722918149785,
            "rating_q975": 1416.920495251071,
            "rating_q025": 1404.424088378886
        },
        "o1-preview": {
            "rating": 1408.2743134028747,
            "rating_q975": 1414.405349027625,
            "rating_q025": 1402.1432777781242
        },
        "mai-1-preview": {
            "rating": 1406.0451618941345,
            "rating_q975": 1413.1061804987137,
            "rating_q025": 1398.9841432895553
        },
        "deepseek-v3-0324": {
            "rating": 1405.976237219568,
            "rating_q975": 1410.8077777963701,
            "rating_q025": 1401.144696642766
        },
        "o4-mini-2025-04-16": {
            "rating": 1405.3541878806134,
            "rating_q975": 1410.270199238916,
            "rating_q025": 1400.4381765223109
        },
        "qwen3-235b-a22b-thinking-2507": {
            "rating": 1404.725358021195,
            "rating_q975": 1413.6376176409585,
            "rating_q025": 1395.8130984014315
        },
        "qwen3-235b-a22b-no-thinking": {
            "rating": 1404.5574320582298,
            "rating_q975": 1410.0317965107972,
            "rating_q025": 1399.0830676056623
        },
        "hunyuan-vision-1.5-thinking": {
            "rating": 1403.1346072699494,
            "rating_q975": 1420.5656956550247,
            "rating_q025": 1385.703518884874
        },
        "claude-3-7-sonnet-20250219-thinking-32k": {
            "rating": 1402.8111664905225,
            "rating_q975": 1407.9132774347681,
            "rating_q025": 1397.7090555462769
        },
        "qwen3-vl-235b-a22b-thinking": {
            "rating": 1402.2230038741889,
            "rating_q975": 1411.6831347250643,
            "rating_q025": 1392.7628730233134
        },
        "gpt-5-mini-high": {
            "rating": 1401.4183575411041,
            "rating_q975": 1407.547672036233,
            "rating_q025": 1395.2890430459752
        },
        "claude-sonnet-4-20250514": {
            "rating": 1399.5569949431151,
            "rating_q975": 1404.939314098715,
            "rating_q025": 1394.1746757875153
        },
        "qwen3-coder-480b-a35b-instruct": {
            "rating": 1398.6914772363973,
            "rating_q975": 1404.9760762169085,
            "rating_q025": 1392.406878255886
        },
        "mistral-medium-2505": {
            "rating": 1397.9572115023443,
            "rating_q975": 1403.6573736367009,
            "rating_q025": 1392.2570493679877
        },
        "gpt-4.1-mini-2025-04-14": {
            "rating": 1397.1905539490315,
            "rating_q975": 1402.4663253075262,
            "rating_q025": 1391.9147825905368
        },
        "qwen3-30b-a3b-instruct-2507": {
            "rating": 1393.7825264863561,
            "rating_q975": 1400.1264567740131,
            "rating_q025": 1387.438596198699
        },
        "minimax-m1": {
            "rating": 1392.99934831569,
            "rating_q975": 1398.3259045064956,
            "rating_q025": 1387.6727921248844
        },
        "hunyuan-turbos-20250416": {
            "rating": 1390.8465890552513,
            "rating_q975": 1398.9319152865805,
            "rating_q025": 1382.7612628239222
        },
        "glm-4.5-air": {
            "rating": 1388.5721773223547,
            "rating_q975": 1394.1066997614225,
            "rating_q025": 1383.037654883287
        },
        "qwen3-235b-a22b": {
            "rating": 1387.915226813557,
            "rating_q975": 1393.7538809656548,
            "rating_q025": 1382.076572661459
        },
        "gemini-2.5-flash-lite-preview-09-2025-no-thinking": {
            "rating": 1387.3855044851146,
            "rating_q975": 1393.1384558837597,
            "rating_q025": 1381.6325530864694
        },
        "hunyuan-t1-20250711": {
            "rating": 1386.7427286817635,
            "rating_q975": 1399.3269299264912,
            "rating_q025": 1374.158527437036
        },
        "qwen3-next-80b-a3b-thinking": {
            "rating": 1386.1070957194217,
            "rating_q975": 1393.735087011662,
            "rating_q025": 1378.4791044271815
        },
        "claude-3-7-sonnet-20250219": {
            "rating": 1383.5204465815707,
            "rating_q975": 1388.3294364768474,
            "rating_q025": 1378.711456686294
        },
        "amazon-nova-experimental-chat-10-20": {
            "rating": 1382.5532391940178,
            "rating_q975": 1392.3472285792275,
            "rating_q025": 1372.7592498088081
        },
        "qwen2.5-max": {
            "rating": 1382.3704935789897,
            "rating_q975": 1387.291229274612,
            "rating_q025": 1377.4497578833673
        },
        "claude-3-5-sonnet-20241022": {
            "rating": 1381.0004645740148,
            "rating_q975": 1384.7178256078473,
            "rating_q025": 1377.2831035401823
        },
        "gemini-2.5-flash-lite-preview-06-17-thinking": {
            "rating": 1380.2460339178087,
            "rating_q975": 1385.8868540188457,
            "rating_q025": 1374.6052138167718
        },
        "mistral-small-2506": {
            "rating": 1380.0374034402569,
            "rating_q975": 1386.7338538103509,
            "rating_q025": 1373.3409530701629
        },
        "glm-4.5v": {
            "rating": 1379.0676963042592,
            "rating_q975": 1391.0772085969877,
            "rating_q025": 1367.0581840115308
        },
        "o3-mini-high": {
            "rating": 1378.4861574939644,
            "rating_q975": 1384.8772048154847,
            "rating_q025": 1372.095110172444
        },
        "intellect-3": {
            "rating": 1377.593011102266,
            "rating_q975": 1394.8749777861763,
            "rating_q025": 1360.3110444183558
        },
        "ling-flash-2.0": {
            "rating": 1377.4790627009531,
            "rating_q975": 1387.424493410519,
            "rating_q025": 1367.5336319913872
        },
        "grok-3-mini-high": {
            "rating": 1374.628148272002,
            "rating_q975": 1381.422005839402,
            "rating_q025": 1367.834290704602
        },
        "llama-3.1-nemotron-ultra-253b-v1": {
            "rating": 1374.3083916947212,
            "rating_q975": 1389.2026616576884,
            "rating_q025": 1359.414121731754
        },
        "step-3": {
            "rating": 1372.8342523494512,
            "rating_q975": 1383.2269184002446,
            "rating_q025": 1362.4415862986577
        },
        "llama-3.3-nemotron-49b-super-v1": {
            "rating": 1372.804473147345,
            "rating_q975": 1388.4030134843917,
            "rating_q025": 1357.2059328102985
        },
        "gemma-3-27b-it": {
            "rating": 1372.5317043749849,
            "rating_q975": 1377.0663279270957,
            "rating_q025": 1367.997080822874
        },
        "minimax-m2": {
            "rating": 1371.0135761270753,
            "rating_q975": 1381.3135525428345,
            "rating_q025": 1360.7135997113162
        },
        "deepseek-v3": {
            "rating": 1370.3966476247556,
            "rating_q975": 1376.1855323590146,
            "rating_q025": 1364.6077628904966
        },
        "grok-3-mini-beta": {
            "rating": 1369.784906239915,
            "rating_q975": 1375.9890681148602,
            "rating_q025": 1363.5807443649699
        },
        "nvidia-llama-3.3-nemotron-super-49b-v1.5": {
            "rating": 1368.0861716646168,
            "rating_q975": 1382.1641659893269,
            "rating_q025": 1354.0081773399068
        },
        "gemini-2.0-flash-001": {
            "rating": 1366.6303692369024,
            "rating_q975": 1371.190707234781,
            "rating_q025": 1362.0700312390238
        },
        "qwen3-32b": {
            "rating": 1364.8169674997032,
            "rating_q975": 1377.2307887418788,
            "rating_q025": 1352.4031462575276
        },
        "nova-2-lite": {
            "rating": 1364.7732534347642,
            "rating_q975": 1376.303059268018,
            "rating_q025": 1353.2434476015105
        },
        "gpt-oss-120b": {
            "rating": 1364.4065955669673,
            "rating_q975": 1370.108764634777,
            "rating_q025": 1358.7044264991578
        },
        "command-a-03-2025": {
            "rating": 1363.9308519715507,
            "rating_q975": 1368.2538405333385,
            "rating_q025": 1359.607863409763
        },
        "amazon-nova-experimental-chat-10-09": {
            "rating": 1363.4569801744556,
            "rating_q975": 1372.1613746791515,
            "rating_q025": 1354.7525856697596
        },
        "o3-mini": {
            "rating": 1363.334889571231,
            "rating_q975": 1367.5530496151507,
            "rating_q025": 1359.1167295273115
        },
        "llama-3.1-405b-instruct-bf16": {
            "rating": 1361.635563008744,
            "rating_q975": 1366.0724727441916,
            "rating_q025": 1357.1986532732963
        },
        "hunyuan-turbos-20250226": {
            "rating": 1360.222239058512,
            "rating_q975": 1375.0361981067078,
            "rating_q025": 1345.4082800103163
        },
        "hunyuan-turbo-0110": {
            "rating": 1357.9936691264447,
            "rating_q975": 1372.275893854286,
            "rating_q025": 1343.7114443986034
        },
        "qwq-32b": {
            "rating": 1357.8217677892178,
            "rating_q975": 1363.3403523009824,
            "rating_q025": 1352.3031832774532
        },
        "llama-3.1-405b-instruct-fp8": {
            "rating": 1357.60068083824,
            "rating_q975": 1362.1781920604985,
            "rating_q025": 1353.0231696159813
        },
        "gpt-4o-2024-05-13": {
            "rating": 1356.4242065955334,
            "rating_q975": 1360.8228815664527,
            "rating_q025": 1352.0255316246141
        },
        "gemini-1.5-pro-002": {
            "rating": 1356.3731821668584,
            "rating_q975": 1360.6064921102852,
            "rating_q025": 1352.1398722234317
        },
        "qwen-plus-0125": {
            "rating": 1356.0114502870367,
            "rating_q975": 1366.3547001134887,
            "rating_q025": 1345.6682004605848
        },
        "gemini-2.0-flash-lite-preview-02-05": {
            "rating": 1355.5989224801651,
            "rating_q975": 1360.9040796975362,
            "rating_q025": 1350.293765262794
        },
        "olmo-3-32b-think": {
            "rating": 1355.295011166047,
            "rating_q975": 1369.9524597822733,
            "rating_q025": 1340.6375625498208
        },
        "yi-lightning": {
            "rating": 1355.087052119713,
            "rating_q975": 1361.4962647113869,
            "rating_q025": 1348.6778395280392
        },
        "step-2-16k-exp-202412": {
            "rating": 1354.2355955411422,
            "rating_q975": 1364.8824712065789,
            "rating_q025": 1343.5887198757055
        },
        "o1-mini": {
            "rating": 1353.085196767815,
            "rating_q975": 1357.6796624207884,
            "rating_q025": 1348.4907311148415
        },
        "glm-4-plus-0111": {
            "rating": 1351.988995795723,
            "rating_q975": 1362.1951402872423,
            "rating_q025": 1341.7828513042036
        },
        "ring-flash-2.0": {
            "rating": 1349.6636442068325,
            "rating_q975": 1359.6000477730774,
            "rating_q025": 1339.7272406405875
        },
        "claude-3-5-sonnet-20240620": {
            "rating": 1348.2919696129538,
            "rating_q975": 1352.6287206915522,
            "rating_q025": 1343.9552185343555
        },
        "gpt-5-nano-high": {
            "rating": 1348.0332414616273,
            "rating_q975": 1357.501425424415,
            "rating_q025": 1338.5650574988397
        },
        "gpt-4o-2024-08-06": {
            "rating": 1347.961386466091,
            "rating_q975": 1353.1286014610373,
            "rating_q025": 1342.7941714711446
        },
        "gemma-3-12b-it": {
            "rating": 1347.4450833235262,
            "rating_q975": 1359.3010145705757,
            "rating_q025": 1335.5891520764767
        },
        "qwen3-30b-a3b": {
            "rating": 1345.850687066214,
            "rating_q975": 1351.7429081017222,
            "rating_q025": 1339.958466030706
        },
        "grok-2-2024-08-13": {
            "rating": 1345.2457460228525,
            "rating_q975": 1349.6190150439877,
            "rating_q025": 1340.8724770017172
        },
        "llama-3.3-70b-instruct": {
            "rating": 1344.9006724517724,
            "rating_q975": 1349.0007979305901,
            "rating_q025": 1340.8005469729546
        },
        "hunyuan-large-2025-02-10": {
            "rating": 1343.5801493281142,
            "rating_q975": 1355.8252351411682,
            "rating_q025": 1331.3350635150603
        },
        "gpt-4-turbo-2024-04-09": {
            "rating": 1342.0867143641265,
            "rating_q975": 1346.796276290243,
            "rating_q025": 1337.37715243801
        },
        "gemini-advanced-0514": {
            "rating": 1341.772290823557,
            "rating_q975": 1347.7147199060091,
            "rating_q025": 1335.8298617411047
        },
        "llama-4-maverick-17b-128e-instruct": {
            "rating": 1341.5003221353427,
            "rating_q975": 1346.6877608399034,
            "rating_q025": 1336.312883430782
        },
        "llama-4-scout-17b-16e-instruct": {
            "rating": 1341.0061652205454,
            "rating_q975": 1346.814195953198,
            "rating_q025": 1335.198134487893
        },
        "gpt-4.1-nano-2025-04-14": {
            "rating": 1339.553121818979,
            "rating_q975": 1349.4328181007104,
            "rating_q025": 1329.6734255372476
        },
        "mistral-large-2407": {
            "rating": 1336.7312037026059,
            "rating_q975": 1341.652392899344,
            "rating_q025": 1331.8100145058677
        },
        "deepseek-v2.5-1210": {
            "rating": 1335.9437599026671,
            "rating_q975": 1346.202224052949,
            "rating_q025": 1325.6852957523852
        },
        "step-1o-turbo-202506": {
            "rating": 1335.6875777849423,
            "rating_q975": 1344.6590211448076,
            "rating_q025": 1326.716134425077
        },
        "claude-3-5-haiku-20241022": {
            "rating": 1335.4352488955287,
            "rating_q975": 1339.3542189885181,
            "rating_q025": 1331.5162788025393
        },
        "gpt-oss-20b": {
            "rating": 1333.5066490727932,
            "rating_q975": 1342.1199503171035,
            "rating_q025": 1324.8933478284828
        },
        "qwen2.5-plus-1127": {
            "rating": 1332.1147861536315,
            "rating_q975": 1339.8871068647704,
            "rating_q025": 1324.3424654424925
        },
        "athene-v2-chat": {
            "rating": 1330.7283022461247,
            "rating_q975": 1336.2901230592895,
            "rating_q025": 1325.16648143296
        },
        "mercury": {
            "rating": 1330.6210974489777,
            "rating_q975": 1350.2683223986353,
            "rating_q025": 1310.9738724993201
        },
        "gemma-3n-e4b-it": {
            "rating": 1329.1965714560165,
            "rating_q975": 1335.5932522409116,
            "rating_q025": 1322.7998906711214
        },
        "gemini-1.5-pro-001": {
            "rating": 1328.6398489172975,
            "rating_q975": 1333.5848505671847,
            "rating_q025": 1323.6948472674103
        },
        "magistral-medium-2506": {
            "rating": 1328.5742447266698,
            "rating_q975": 1337.3713613884443,
            "rating_q025": 1319.7771280648954
        },
        "gpt-4o-mini-2024-07-18": {
            "rating": 1328.536202887517,
            "rating_q975": 1332.6165971483986,
            "rating_q025": 1324.4558086266354
        },
        "llama-3.1-nemotron-70b-instruct": {
            "rating": 1328.2333844429631,
            "rating_q975": 1338.092388123263,
            "rating_q025": 1318.3743807626633
        },
        "qwen-max-0919": {
            "rating": 1327.7448280846343,
            "rating_q975": 1334.9551745884721,
            "rating_q025": 1320.5344815807964
        },
        "athene-70b-0725": {
            "rating": 1327.3065638403748,
            "rating_q975": 1334.1302845348084,
            "rating_q025": 1320.4828431459412
        },
        "gpt-4-1106-preview": {
            "rating": 1326.9194192185796,
            "rating_q975": 1331.6375419287565,
            "rating_q025": 1322.2012965084027
        },
        "llama-3-70b-instruct": {
            "rating": 1326.3078042624234,
            "rating_q975": 1330.777466566607,
            "rating_q025": 1321.8381419582397
        },
        "gpt-4-0125-preview": {
            "rating": 1326.0857637748554,
            "rating_q975": 1331.0015598258203,
            "rating_q025": 1321.1699677238905
        },
        "glm-4-plus": {
            "rating": 1325.230173812086,
            "rating_q975": 1331.498609179971,
            "rating_q025": 1318.9617384442008
        },
        "claude-3-opus-20240229": {
            "rating": 1324.4060134233007,
            "rating_q975": 1328.212750603975,
            "rating_q025": 1320.5992762426263
        },
        "mistral-small-3.1-24b-instruct-2503": {
            "rating": 1322.73124616623,
            "rating_q975": 1328.315183124345,
            "rating_q025": 1317.147309208115
        },
        "llama-3.1-70b-instruct": {
            "rating": 1321.3102797130937,
            "rating_q975": 1325.9466818670198,
            "rating_q025": 1316.6738775591675
        },
        "mistral-large-2411": {
            "rating": 1320.8816632328699,
            "rating_q975": 1326.1133567755871,
            "rating_q025": 1315.6499696901526
        },
        "grok-2-mini-2024-08-13": {
            "rating": 1320.0438584978842,
            "rating_q975": 1324.6923532514397,
            "rating_q025": 1315.3953637443287
        },
        "hunyuan-standard-2025-02-10": {
            "rating": 1319.4226308798916,
            "rating_q975": 1331.7762347538435,
            "rating_q025": 1307.0690270059397
        },
        "deepseek-v2.5": {
            "rating": 1318.7878824052405,
            "rating_q975": 1324.8137096378448,
            "rating_q025": 1312.762055172636
        },
        "llama-3.1-nemotron-51b-instruct": {
            "rating": 1318.2225908572007,
            "rating_q975": 1331.7193956514345,
            "rating_q025": 1304.7257860629668
        },
        "qwen2.5-72b-instruct": {
            "rating": 1316.122803789996,
            "rating_q975": 1321.0904617252822,
            "rating_q025": 1311.1551458547096
        },
        "jamba-1.5-large": {
            "rating": 1315.9210325117263,
            "rating_q975": 1325.0582187676735,
            "rating_q025": 1306.783846255779
        },
        "gemini-1.5-flash-002": {
            "rating": 1315.6748570255036,
            "rating_q975": 1320.9394179265953,
            "rating_q025": 1310.4102961244118
        },
        "hunyuan-large-vision": {
            "rating": 1314.4807806462914,
            "rating_q975": 1326.0462047763249,
            "rating_q025": 1302.9153565162578
        },
        "gemma-3-4b-it": {
            "rating": 1307.939114916342,
            "rating_q975": 1319.5675947364623,
            "rating_q025": 1296.3106350962219
        },
        "amazon-nova-pro-v1.0": {
            "rating": 1304.5282226050308,
            "rating_q975": 1309.8937997940254,
            "rating_q025": 1299.1626454160362
        },
        "gpt-4-0314": {
            "rating": 1301.9220895333115,
            "rating_q975": 1307.6123588805212,
            "rating_q025": 1296.2318201861017
        },
        "llama-3.1-tulu-3-70b": {
            "rating": 1301.6465588450974,
            "rating_q975": 1314.875394406115,
            "rating_q025": 1288.4177232840798
        },
        "gemma-2-27b-it": {
            "rating": 1297.3782713998698,
            "rating_q975": 1301.4602978117834,
            "rating_q025": 1293.2962449879562
        },
        "gemma-2-9b-it-simpo": {
            "rating": 1295.6915135233635,
            "rating_q975": 1304.3324022892164,
            "rating_q025": 1287.0506247575106
        },
        "mistral-small-24b-instruct-2501": {
            "rating": 1294.07104431388,
            "rating_q975": 1301.0023121347804,
            "rating_q025": 1287.1397764929798
        },
        "gpt-4-0613": {
            "rating": 1293.813390545742,
            "rating_q975": 1298.7144605810995,
            "rating_q025": 1288.9123205103847
        },
        "reka-core-20240904": {
            "rating": 1291.9686869862276,
            "rating_q975": 1301.269319065922,
            "rating_q025": 1282.6680549065331
        },
        "nemotron-4-340b-instruct": {
            "rating": 1289.910643517656,
            "rating_q975": 1297.0053426307495,
            "rating_q025": 1282.8159444045623
        },
        "claude-3-sonnet-20240229": {
            "rating": 1289.6931604912957,
            "rating_q975": 1294.4360407559082,
            "rating_q025": 1284.9502802266832
        },
        "gemini-1.5-flash-001": {
            "rating": 1289.3972087122554,
            "rating_q975": 1294.6116974688703,
            "rating_q025": 1284.1827199556406
        },
        "glm-4-0520": {
            "rating": 1288.900556684066,
            "rating_q975": 1297.9733792522409,
            "rating_q025": 1279.8277341158912
        },
        "olmo-2-0325-32b-instruct": {
            "rating": 1288.5196143065443,
            "rating_q975": 1301.368914608205,
            "rating_q025": 1275.6703140048837
        },
        "command-r-plus-08-2024": {
            "rating": 1287.7033673711999,
            "rating_q975": 1295.968751894941,
            "rating_q025": 1279.4379828474587
        },
        "qwen2.5-coder-32b-instruct": {
            "rating": 1285.7997268786546,
            "rating_q975": 1296.9378575820153,
            "rating_q025": 1274.6615961752939
        },
        "qwen2-72b-instruct": {
            "rating": 1277.2798949433957,
            "rating_q975": 1283.188989198185,
            "rating_q025": 1271.3708006886063
        },
        "reka-flash-20240904": {
            "rating": 1276.6862796913933,
            "rating_q975": 1285.7618511283574,
            "rating_q025": 1267.6107082544293
        },
        "gemma-2-9b-it": {
            "rating": 1276.3544433611078,
            "rating_q975": 1280.937371228706,
            "rating_q025": 1271.7715154935095
        },
        "amazon-nova-lite-v1.0": {
            "rating": 1274.3987925903343,
            "rating_q975": 1280.5621855610202,
            "rating_q025": 1268.2353996196484
        },
        "c4ai-aya-expanse-32b": {
            "rating": 1274.0497646791591,
            "rating_q975": 1280.0580896656556,
            "rating_q025": 1268.0414396926626
        },
        "command-r-plus": {
            "rating": 1273.0802122946125,
            "rating_q975": 1278.2434720722092,
            "rating_q025": 1267.9169525170157
        },
        "jamba-1.5-mini": {
            "rating": 1272.503146599187,
            "rating_q975": 1281.45596279098,
            "rating_q025": 1263.5503304073939
        },
        "phi-4": {
            "rating": 1271.6882693211003,
            "rating_q975": 1277.2984715859468,
            "rating_q025": 1266.0780670562538
        },
        "claude-3-haiku-20240307": {
            "rating": 1270.9650652007572,
            "rating_q975": 1275.6480592120572,
            "rating_q025": 1266.2820711894572
        },
        "deepseek-coder-v2": {
            "rating": 1269.8060312855723,
            "rating_q975": 1277.5831142744178,
            "rating_q025": 1262.0289482967269
        },
        "gemini-1.5-flash-8b-001": {
            "rating": 1267.5626657374596,
            "rating_q975": 1272.9445725544329,
            "rating_q025": 1262.1807589204864
        },
        "mistral-large-2402": {
            "rating": 1267.4516448014942,
            "rating_q975": 1273.133436360962,
            "rating_q025": 1261.7698532420266
        },
        "llama-3-8b-instruct": {
            "rating": 1266.0919025783896,
            "rating_q975": 1270.7985677078477,
            "rating_q025": 1261.3852374489315
        },
        "command-r-08-2024": {
            "rating": 1263.311160068002,
            "rating_q975": 1271.5718996804576,
            "rating_q025": 1255.0504204555464
        },
        "qwen1.5-110b-chat": {
            "rating": 1258.1320004482734,
            "rating_q975": 1265.2517078107082,
            "rating_q025": 1251.0122930858386
        },
        "ministral-8b-2410": {
            "rating": 1257.1456645595586,
            "rating_q975": 1269.004435935192,
            "rating_q025": 1245.286893183925
        },
        "amazon-nova-micro-v1.0": {
            "rating": 1256.1332652017168,
            "rating_q975": 1262.223103972022,
            "rating_q025": 1250.0434264314115
        },
        "mixtral-8x22b-instruct-v0.1": {
            "rating": 1253.9950183899064,
            "rating_q975": 1259.5181111394886,
            "rating_q025": 1248.4719256403241
        },
        "qwen1.5-72b-chat": {
            "rating": 1252.4855719152383,
            "rating_q975": 1258.6586058894468,
            "rating_q025": 1246.3125379410299
        },
        "yi-1.5-34b-chat": {
            "rating": 1251.2540223789945,
            "rating_q975": 1257.9600100778853,
            "rating_q025": 1244.5480346801037
        },
        "granite-3.1-8b-instruct": {
            "rating": 1250.5535719945533,
            "rating_q975": 1264.4135850743723,
            "rating_q025": 1236.6935589147342
        },
        "mistral-medium": {
            "rating": 1250.2780258285916,
            "rating_q975": 1256.644043168022,
            "rating_q025": 1243.912008489161
        },
        "gemini-pro-dev-api": {
            "rating": 1246.5035662108012,
            "rating_q975": 1254.9238235804469,
            "rating_q025": 1238.0833088411555
        },
        "hunyuan-standard-256k": {
            "rating": 1246.4558520713226,
            "rating_q975": 1262.7133214042824,
            "rating_q025": 1230.1983827383629
        },
        "reka-flash-21b-20240226-online": {
            "rating": 1243.7734620290416,
            "rating_q975": 1252.7746610305558,
            "rating_q025": 1234.7722630275275
        },
        "zephyr-orpo-141b-A35b-v0.1": {
            "rating": 1241.9147531275682,
            "rating_q975": 1255.1002033265918,
            "rating_q025": 1228.7293029285447
        },
        "gemini-pro": {
            "rating": 1241.8089507485038,
            "rating_q975": 1254.6642315529393,
            "rating_q025": 1228.9536699440682
        },
        "llama-3.1-tulu-3-8b": {
            "rating": 1240.0591100040897,
            "rating_q975": 1253.6930517656556,
            "rating_q025": 1226.4251682425238
        },
        "command-r": {
            "rating": 1239.534311619428,
            "rating_q975": 1245.332930035425,
            "rating_q025": 1233.735693203431
        },
        "reka-flash-21b-20240226": {
            "rating": 1239.2260529154014,
            "rating_q975": 1246.5069716073565,
            "rating_q025": 1231.9451342234463
        },
        "llama-3.1-8b-instruct": {
            "rating": 1238.3123528193491,
            "rating_q975": 1243.311893099359,
            "rating_q025": 1233.3128125393393
        },
        "gpt-3.5-turbo-0125": {
            "rating": 1237.8305851752975,
            "rating_q975": 1243.2811256884224,
            "rating_q025": 1232.3800446621726
        },
        "granite-3.0-8b-instruct": {
            "rating": 1237.7311197795116,
            "rating_q975": 1249.1475904596282,
            "rating_q025": 1226.314649099395
        },
        "internlm2_5-20b-chat": {
            "rating": 1236.7751433373228,
            "rating_q975": 1245.9919584091397,
            "rating_q025": 1227.558328265506
        },
        "c4ai-aya-expanse-8b": {
            "rating": 1233.1956515754027,
            "rating_q975": 1241.7908265768801,
            "rating_q025": 1224.6004765739253
        },
        "mixtral-8x7b-instruct-v0.1": {
            "rating": 1232.062830543634,
            "rating_q975": 1237.1871284445058,
            "rating_q025": 1226.938532642762
        },
        "phi-3-medium-4k-instruct": {
            "rating": 1231.3044479802988,
            "rating_q975": 1237.792919552125,
            "rating_q025": 1224.8159764084726
        },
        "granite-3.1-2b-instruct": {
            "rating": 1228.5501854393767,
            "rating_q975": 1242.748007167181,
            "rating_q025": 1214.3523637115725
        },
        "dbrx-instruct-preview": {
            "rating": 1227.443485110046,
            "rating_q975": 1234.943233973964,
            "rating_q025": 1219.9437362461279
        },
        "qwen1.5-32b-chat": {
            "rating": 1225.7457702347124,
            "rating_q975": 1233.3408949867405,
            "rating_q025": 1218.1506454826842
        },
        "llama-3.2-3b-instruct": {
            "rating": 1225.248221899219,
            "rating_q975": 1234.81104538079,
            "rating_q025": 1215.6853984176482
        },
        "gemma-2-2b-it": {
            "rating": 1220.9275429347354,
            "rating_q975": 1225.8021263849555,
            "rating_q025": 1216.0529594845152
        },
        "gpt-3.5-turbo-1106": {
            "rating": 1220.8130398397516,
            "rating_q975": 1230.3649496627766,
            "rating_q025": 1211.2611300167266
        },
        "wizardlm-70b": {
            "rating": 1215.299702317879,
            "rating_q975": 1225.5440902301584,
            "rating_q025": 1205.0553144055998
        },
        "phi-3-small-8k-instruct": {
            "rating": 1212.942424666308,
            "rating_q975": 1220.7494000137576,
            "rating_q025": 1205.1354493188583
        },
        "yi-34b-chat": {
            "rating": 1211.9354197599164,
            "rating_q975": 1219.7682697263617,
            "rating_q025": 1204.102569793471
        },
        "qwen1.5-14b-chat": {
            "rating": 1210.5365077011015,
            "rating_q975": 1219.356320246192,
            "rating_q025": 1201.7166951560112
        },
        "llama-2-70b-chat": {
            "rating": 1210.2299173709607,
            "rating_q975": 1216.581957830855,
            "rating_q025": 1203.8778769110666
        },
        "openhermes-2.5-mistral-7b": {
            "rating": 1209.7522946398635,
            "rating_q975": 1221.2403574151658,
            "rating_q025": 1198.2642318645612
        },
        "openchat-3.5-0106": {
            "rating": 1209.2605657925715,
            "rating_q975": 1218.0280989486619,
            "rating_q025": 1200.493032636481
        },
        "tulu-2-dpo-70b": {
            "rating": 1208.764263061976,
            "rating_q975": 1219.5630437012585,
            "rating_q025": 1197.9654824226934
        },
        "gemma-1.1-7b-it": {
            "rating": 1207.4098881942878,
            "rating_q975": 1214.458788578203,
            "rating_q025": 1200.3609878103725
        },
        "deepseek-llm-67b-chat": {
            "rating": 1206.7430712182559,
            "rating_q975": 1219.4325262237621,
            "rating_q025": 1194.0536162127496
        },
        "starling-lm-7b-beta": {
            "rating": 1204.4130417175986,
            "rating_q975": 1213.3056851222507,
            "rating_q025": 1195.5203983129466
        },
        "openchat-3.5": {
            "rating": 1202.7593455820659,
            "rating_q975": 1213.3566209969617,
            "rating_q025": 1192.16207016717
        },
        "vicuna-33b": {
            "rating": 1202.6981899307425,
            "rating_q975": 1209.9236520098448,
            "rating_q025": 1195.4727278516402
        },
        "snowflake-arctic-instruct": {
            "rating": 1202.4881465065055,
            "rating_q975": 1209.8966899773282,
            "rating_q025": 1195.0796030356828
        },
        "granite-3.0-2b-instruct": {
            "rating": 1201.3629731057729,
            "rating_q975": 1212.7279603977863,
            "rating_q025": 1189.9979858137594
        },
        "starling-lm-7b-alpha": {
            "rating": 1198.6590580717234,
            "rating_q975": 1207.678606341301,
            "rating_q025": 1189.6395098021458
        },
        "nous-hermes-2-mixtral-8x7b-dpo": {
            "rating": 1194.5975909155356,
            "rating_q975": 1207.423897601897,
            "rating_q025": 1181.7712842291744
        },
        "phi-3-mini-4k-instruct-june-2024": {
            "rating": 1193.2500022387069,
            "rating_q975": 1201.433906528041,
            "rating_q025": 1185.0660979493728
        },
        "mistral-7b-instruct-v0.2": {
            "rating": 1192.4914658513003,
            "rating_q975": 1200.1810283104815,
            "rating_q025": 1184.8019033921191
        },
        "solar-10.7b-instruct-v1.0": {
            "rating": 1188.5534339010433,
            "rating_q975": 1203.0548526706082,
            "rating_q025": 1174.0520151314784
        },
        "mpt-30b-chat": {
            "rating": 1184.9253817078145,
            "rating_q975": 1198.5773145240178,
            "rating_q025": 1171.2734488916112
        },
        "dolphin-2.2.1-mistral-7b": {
            "rating": 1184.3348673464873,
            "rating_q975": 1201.1368578264696,
            "rating_q025": 1167.532876866505
        },
        "llama2-70b-steerlm-chat": {
            "rating": 1182.7899803800703,
            "rating_q975": 1196.5314410852266,
            "rating_q025": 1169.0485196749141
        },
        "qwq-32b-preview": {
            "rating": 1179.8597745444313,
            "rating_q975": 1194.513113985525,
            "rating_q025": 1165.2064351033375
        },
        "llama-2-13b-chat": {
            "rating": 1176.0211110315147,
            "rating_q975": 1183.6524436155528,
            "rating_q025": 1168.3897784474766
        },
        "wizardlm-13b": {
            "rating": 1175.1856428527474,
            "rating_q975": 1185.4855827629103,
            "rating_q025": 1164.8857029425844
        },
        "falcon-180b-chat": {
            "rating": 1173.2773068100137,
            "rating_q975": 1191.9352767100208,
            "rating_q025": 1154.6193369100065
        },
        "phi-3-mini-4k-instruct": {
            "rating": 1173.1200875499107,
            "rating_q975": 1181.1870278375743,
            "rating_q025": 1165.0531472622472
        },
        "zephyr-7b-beta": {
            "rating": 1169.996118258364,
            "rating_q975": 1179.5888854871935,
            "rating_q025": 1160.4033510295346
        },
        "llama-3.2-1b-instruct": {
            "rating": 1169.0790044469993,
            "rating_q975": 1178.6912016154874,
            "rating_q025": 1159.4668072785112
        },
        "palm-2": {
            "rating": 1167.477193408447,
            "rating_q975": 1177.5444789799956,
            "rating_q025": 1157.4099078368984
        },
        "gemma-7b-it": {
            "rating": 1166.9460765907415,
            "rating_q975": 1177.9807680204542,
            "rating_q025": 1155.9113851610289
        },
        "phi-3-mini-128k-instruct": {
            "rating": 1165.187767163434,
            "rating_q975": 1174.228276761747,
            "rating_q025": 1156.147257565121
        },
        "smollm2-1.7b-instruct": {
            "rating": 1165.1500710945875,
            "rating_q975": 1183.8693049839442,
            "rating_q025": 1146.4308372052308
        },
        "vicuna-13b": {
            "rating": 1165.0091340972717,
            "rating_q975": 1172.4572541700124,
            "rating_q025": 1157.561014024531
        },
        "qwen1.5-7b-chat": {
            "rating": 1164.8900238186523,
            "rating_q975": 1176.1493079492075,
            "rating_q025": 1153.630739688097
        },
        "codellama-34b-instruct": {
            "rating": 1163.1004398052553,
            "rating_q975": 1172.7977625605556,
            "rating_q025": 1153.403117049955
        },
        "zephyr-7b-alpha": {
            "rating": 1163.014303212781,
            "rating_q975": 1180.3227886721916,
            "rating_q025": 1145.7058177533704
        },
        "guanaco-33b": {
            "rating": 1160.2604844138577,
            "rating_q975": 1173.6120700522674,
            "rating_q025": 1146.908898775448
        },
        "qwen-14b-chat": {
            "rating": 1155.066766224058,
            "rating_q975": 1166.888881695039,
            "rating_q025": 1143.2446507530772
        },
        "stripedhyena-nous-7b": {
            "rating": 1154.1029970838056,
            "rating_q975": 1165.9733258075223,
            "rating_q025": 1142.2326683600888
        },
        "codellama-70b-instruct": {
            "rating": 1153.3415443619106,
            "rating_q975": 1175.3687888382753,
            "rating_q025": 1131.3142998855458
        },
        "llama-2-7b-chat": {
            "rating": 1149.4293564755371,
            "rating_q975": 1157.3126842553338,
            "rating_q025": 1141.5460286957405
        },
        "mistral-7b-instruct": {
            "rating": 1145.3511496632016,
            "rating_q975": 1155.4722394416708,
            "rating_q025": 1135.2300598847323
        },
        "gemma-1.1-2b-it": {
            "rating": 1137.5902506861607,
            "rating_q975": 1147.235947390522,
            "rating_q025": 1127.9445539817996
        },
        "vicuna-7b": {
            "rating": 1135.9204030211736,
            "rating_q975": 1145.7981461358645,
            "rating_q025": 1126.0426599064826
        },
        "gemma-2b-it": {
            "rating": 1118.0536318609406,
            "rating_q975": 1131.3272053180324,
            "rating_q025": 1104.780058403849
        },
        "olmo-7b-instruct": {
            "rating": 1113.540557755381,
            "rating_q975": 1126.4964552136648,
            "rating_q025": 1100.5846602970973
        },
        "qwen1.5-4b-chat": {
            "rating": 1107.9926583141955,
            "rating_q975": 1118.8425720659347,
            "rating_q025": 1097.1427445624563
        },
        "koala-13b": {
            "rating": 1102.9016837952945,
            "rating_q975": 1114.0208855847443,
            "rating_q025": 1091.7824820058447
        },
        "gpt4all-13b-snoozy": {
            "rating": 1096.884753088584,
            "rating_q975": 1113.8113051702992,
            "rating_q025": 1079.9582010068686
        },
        "alpaca-13b": {
            "rating": 1093.7116244757856,
            "rating_q975": 1106.0173055737519,
            "rating_q025": 1081.4059433778193
        },
        "mpt-7b-chat": {
            "rating": 1089.3957243503444,
            "rating_q975": 1102.3938883713759,
            "rating_q025": 1076.397560329313
        },
        "chatglm3-6b": {
            "rating": 1089.3531345848987,
            "rating_q975": 1102.0782506446037,
            "rating_q025": 1076.6280185251937
        },
        "RWKV-4-Raven-14B": {
            "rating": 1062.575703201829,
            "rating_q975": 1075.197941815895,
            "rating_q025": 1049.9534645877627
        },
        "chatglm2-6b": {
            "rating": 1059.3135974646111,
            "rating_q975": 1074.2339869030427,
            "rating_q025": 1044.3932080261795
        },
        "oasst-pythia-12b": {
            "rating": 1053.424720476918,
            "rating_q975": 1065.2300747622892,
            "rating_q025": 1041.619366191547
        },
        "fastchat-t5-3b": {
            "rating": 1027.4702479471443,
            "rating_q975": 1040.862036544099,
            "rating_q025": 1014.0784593501895
        },
        "chatglm-6b": {
            "rating": 1019.0765989874681,
            "rating_q975": 1032.6949690581246,
            "rating_q025": 1005.4582289168115
        },
        "dolly-v2-12b": {
            "rating": 997.6095448851311,
            "rating_q975": 1012.5106798462382,
            "rating_q025": 982.708409924024
        },
        "llama-13b": {
            "rating": 984.8195729487397,
            "rating_q975": 1001.9449124299111,
            "rating_q025": 967.6942334675683
        },
        "stablelm-tuned-alpha-7b": {
            "rating": 981.2104301912912,
            "rating_q975": 995.2036857165299,
            "rating_q025": 967.2171746660524
        }
    },
    "expert": {
        "claude-opus-4-5-20251101": {
            "rating": 1549.109599753097,
            "rating_q975": 1576.4999023613295,
            "rating_q025": 1521.7192971448644
        },
        "claude-opus-4-5-20251101-thinking-32k": {
            "rating": 1505.0155922788638,
            "rating_q975": 1532.3474681692064,
            "rating_q025": 1477.6837163885211
        },
        "claude-sonnet-4-5-20250929-thinking-32k": {
            "rating": 1504.9833585091392,
            "rating_q975": 1521.8503204619178,
            "rating_q025": 1488.1163965563605
        },
        "gemini-3-pro": {
            "rating": 1497.940808972035,
            "rating_q975": 1518.2894584090245,
            "rating_q025": 1477.5921595350455
        },
        "claude-sonnet-4-5-20250929": {
            "rating": 1485.3436825997376,
            "rating_q975": 1503.692356224131,
            "rating_q025": 1466.9950089753443
        },
        "grok-4.1-thinking": {
            "rating": 1484.2434750585396,
            "rating_q975": 1505.1589306944957,
            "rating_q025": 1463.3280194225836
        },
        "gpt-5.1-high": {
            "rating": 1482.471242252323,
            "rating_q975": 1506.2937039440324,
            "rating_q025": 1458.6487805606137
        },
        "claude-opus-4-1-20250805-thinking-16k": {
            "rating": 1479.7022447629176,
            "rating_q975": 1493.6873365095107,
            "rating_q025": 1465.7171530163246
        },
        "qwen3-max-preview": {
            "rating": 1466.2189503189763,
            "rating_q975": 1483.230205129555,
            "rating_q025": 1449.2076955083976
        },
        "gemini-2.5-pro": {
            "rating": 1465.309953664981,
            "rating_q975": 1475.9485672801504,
            "rating_q025": 1454.6713400498118
        },
        "gpt-5.1": {
            "rating": 1462.6460517113696,
            "rating_q975": 1483.8796091264633,
            "rating_q025": 1441.412494296276
        },
        "qwen3-235b-a22b-thinking-2507": {
            "rating": 1461.0882515755852,
            "rating_q975": 1489.0965646848874,
            "rating_q025": 1433.079938466283
        },
        "gpt-5-high": {
            "rating": 1458.9482358348175,
            "rating_q975": 1474.834145781749,
            "rating_q025": 1443.0623258878861
        },
        "claude-opus-4-1-20250805": {
            "rating": 1455.9246273555152,
            "rating_q975": 1468.340494482066,
            "rating_q025": 1443.5087602289643
        },
        "grok-4.1": {
            "rating": 1449.8906484590807,
            "rating_q975": 1469.9529851728796,
            "rating_q025": 1429.8283117452818
        },
        "grok-4-1-fast-reasoning": {
            "rating": 1447.431890203221,
            "rating_q975": 1477.4865802222785,
            "rating_q025": 1417.3772001841635
        },
        "qwen3-235b-a22b-instruct-2507": {
            "rating": 1447.152324722433,
            "rating_q975": 1460.0596865083648,
            "rating_q025": 1434.244962936501
        },
        "o3-2025-04-16": {
            "rating": 1443.9417717229348,
            "rating_q975": 1455.475097452477,
            "rating_q025": 1432.4084459933927
        },
        "gemini-2.5-flash-preview-09-2025": {
            "rating": 1443.3787744941767,
            "rating_q975": 1459.7781873563035,
            "rating_q025": 1426.9793616320499
        },
        "claude-opus-4-20250514-thinking-16k": {
            "rating": 1442.6919297652673,
            "rating_q975": 1457.0285604639773,
            "rating_q025": 1428.3552990665573
        },
        "kimi-k2-thinking-turbo": {
            "rating": 1441.6567473558034,
            "rating_q975": 1463.3062098486464,
            "rating_q025": 1420.0072848629604
        },
        "gpt-5-chat": {
            "rating": 1441.1986993163691,
            "rating_q975": 1456.9101832715423,
            "rating_q025": 1425.487215361196
        },
        "qwen3-vl-235b-a22b-instruct": {
            "rating": 1439.6909045384198,
            "rating_q975": 1466.6109729270543,
            "rating_q025": 1412.7708361497853
        },
        "glm-4.5": {
            "rating": 1439.1322777295209,
            "rating_q975": 1456.8154147111486,
            "rating_q025": 1421.4491407478931
        },
        "claude-haiku-4-5-20251001": {
            "rating": 1437.9790763852318,
            "rating_q975": 1454.6350423894135,
            "rating_q025": 1421.3231103810501
        },
        "glm-4.6": {
            "rating": 1437.3687886577914,
            "rating_q975": 1455.0375643195937,
            "rating_q025": 1419.700012995989
        },
        "qwen3-vl-235b-a22b-thinking": {
            "rating": 1437.2196285812838,
            "rating_q975": 1467.2392858087112,
            "rating_q025": 1407.1999713538564
        },
        "deepseek-v3.2-exp-thinking": {
            "rating": 1434.3209324012653,
            "rating_q975": 1463.7302045456981,
            "rating_q025": 1404.9116602568324
        },
        "claude-sonnet-4-20250514-thinking-32k": {
            "rating": 1431.4236341313244,
            "rating_q975": 1445.7831184745833,
            "rating_q025": 1417.0641497880656
        },
        "grok-4-0709": {
            "rating": 1431.1340064591104,
            "rating_q975": 1444.7391774366909,
            "rating_q025": 1417.52883548153
        },
        "deepseek-v3.1-thinking": {
            "rating": 1430.3840964012688,
            "rating_q975": 1455.2347936607562,
            "rating_q025": 1405.5333991417815
        },
        "gemini-2.5-flash": {
            "rating": 1429.8347259897469,
            "rating_q975": 1440.1665663620456,
            "rating_q025": 1419.502885617448
        },
        "deepseek-v3.1": {
            "rating": 1429.2233650259482,
            "rating_q975": 1451.3229575927744,
            "rating_q025": 1407.123772459122
        },
        "claude-opus-4-20250514": {
            "rating": 1428.5321191997455,
            "rating_q975": 1441.054173643193,
            "rating_q025": 1416.0100647562979
        },
        "gpt-4.5-preview-2025-02-27": {
            "rating": 1425.7752370049802,
            "rating_q975": 1449.2019118517599,
            "rating_q025": 1402.3485621582006
        },
        "grok-4-fast-chat": {
            "rating": 1424.3694170458718,
            "rating_q975": 1458.055237035835,
            "rating_q025": 1390.6835970559086
        },
        "qwen3-max-2025-09-23": {
            "rating": 1424.3337978262678,
            "rating_q975": 1451.0963286972649,
            "rating_q025": 1397.5712669552706
        },
        "chatgpt-4o-latest-20250326": {
            "rating": 1423.3861611524012,
            "rating_q975": 1434.5451100193804,
            "rating_q025": 1412.227212285422
        },
        "deepseek-v3.2-exp": {
            "rating": 1422.7605788908497,
            "rating_q975": 1446.6407451112843,
            "rating_q025": 1398.8804126704151
        },
        "kimi-k2-0905-preview": {
            "rating": 1420.7186672791356,
            "rating_q975": 1446.092443687032,
            "rating_q025": 1395.3448908712392
        },
        "longcat-flash-chat": {
            "rating": 1417.7216126125934,
            "rating_q975": 1443.7703628603747,
            "rating_q025": 1391.672862364812
        },
        "deepseek-v3.2-thinking": {
            "rating": 1417.0009932531893,
            "rating_q975": 1452.1424941913333,
            "rating_q025": 1381.8594923150454
        },
        "ernie-5.0-preview-1103": {
            "rating": 1416.9388562153358,
            "rating_q975": 1448.4611440610095,
            "rating_q025": 1385.4165683696622
        },
        "grok-4-fast-reasoning": {
            "rating": 1413.9362116832258,
            "rating_q975": 1434.0360220403093,
            "rating_q025": 1393.8364013261423
        },
        "deepseek-v3.2": {
            "rating": 1413.4512466078127,
            "rating_q975": 1446.9263323846603,
            "rating_q025": 1379.976160830965
        },
        "deepseek-r1-0528": {
            "rating": 1412.4507107358315,
            "rating_q975": 1431.6057086153119,
            "rating_q025": 1393.2957128563512
        },
        "kimi-k2-0711-preview": {
            "rating": 1407.8000910047317,
            "rating_q975": 1423.478763078817,
            "rating_q025": 1392.1214189306463
        },
        "o4-mini-2025-04-16": {
            "rating": 1406.5255849013197,
            "rating_q975": 1419.104581053425,
            "rating_q025": 1393.9465887492145
        },
        "claude-3-7-sonnet-20250219-thinking-32k": {
            "rating": 1406.160806508676,
            "rating_q975": 1419.9331242901028,
            "rating_q025": 1392.388488727249
        },
        "gpt-5-mini-high": {
            "rating": 1405.0555835921202,
            "rating_q975": 1423.4788009994566,
            "rating_q025": 1386.632366184784
        },
        "mistral-medium-2508": {
            "rating": 1403.912748060366,
            "rating_q975": 1417.2124668496813,
            "rating_q025": 1390.613029271051
        },
        "glm-4.5v": {
            "rating": 1403.8249363200437,
            "rating_q975": 1445.757965479179,
            "rating_q025": 1361.8919071609084
        },
        "grok-3-preview-02-24": {
            "rating": 1402.9632287881354,
            "rating_q975": 1418.107582609008,
            "rating_q025": 1387.818874967263
        },
        "mai-1-preview": {
            "rating": 1400.509142477635,
            "rating_q975": 1421.2572962818422,
            "rating_q025": 1379.7609886734276
        },
        "grok-3-mini-high": {
            "rating": 1399.495624444761,
            "rating_q975": 1417.9880873456768,
            "rating_q025": 1381.0031615438452
        },
        "gpt-4.1-2025-04-14": {
            "rating": 1399.4089121432928,
            "rating_q975": 1411.4115896549247,
            "rating_q025": 1387.406234631661
        },
        "o1-2024-12-17": {
            "rating": 1398.0801677593024,
            "rating_q975": 1414.5145481017503,
            "rating_q025": 1381.6457874168545
        },
        "hunyuan-t1-20250711": {
            "rating": 1397.7266321995944,
            "rating_q975": 1436.317931684486,
            "rating_q025": 1359.1353327147028
        },
        "qwen3-next-80b-a3b-instruct": {
            "rating": 1397.4041390306568,
            "rating_q975": 1416.0178624821585,
            "rating_q025": 1378.790415579155
        },
        "claude-sonnet-4-20250514": {
            "rating": 1397.3370494216022,
            "rating_q975": 1410.4164313618717,
            "rating_q025": 1384.2576674813326
        },
        "mistral-large-3": {
            "rating": 1397.2433925296318,
            "rating_q975": 1428.7232180541223,
            "rating_q025": 1365.7635670051413
        },
        "qwen3-32b": {
            "rating": 1394.939772474863,
            "rating_q975": 1432.5375102208466,
            "rating_q025": 1357.3420347288795
        },
        "deepseek-r1": {
            "rating": 1394.5892308005277,
            "rating_q975": 1414.014866479686,
            "rating_q025": 1375.1635951213696
        },
        "qwen3-235b-a22b-no-thinking": {
            "rating": 1394.4136846817464,
            "rating_q975": 1408.1791542097583,
            "rating_q025": 1380.6482151537346
        },
        "o3-mini-high": {
            "rating": 1393.468665602752,
            "rating_q975": 1413.5850506068084,
            "rating_q025": 1373.3522805986956
        },
        "deepseek-v3-0324": {
            "rating": 1390.870534953777,
            "rating_q975": 1403.3383401757003,
            "rating_q025": 1378.4027297318537
        },
        "glm-4.5-air": {
            "rating": 1388.600982156121,
            "rating_q975": 1404.4606427340998,
            "rating_q025": 1372.7413215781423
        },
        "gemini-2.5-flash-lite-preview-09-2025-no-thinking": {
            "rating": 1386.4836565108405,
            "rating_q975": 1402.6693003974801,
            "rating_q025": 1370.298012624201
        },
        "qwen3-30b-a3b-instruct-2507": {
            "rating": 1385.890167717988,
            "rating_q975": 1403.2269555554876,
            "rating_q025": 1368.5533798804886
        },
        "qwen3-next-80b-a3b-thinking": {
            "rating": 1385.531117538177,
            "rating_q975": 1409.1232446812978,
            "rating_q025": 1361.9389903950564
        },
        "claude-3-7-sonnet-20250219": {
            "rating": 1382.1852255866313,
            "rating_q975": 1395.111891099295,
            "rating_q025": 1369.2585600739676
        },
        "qwen3-235b-a22b": {
            "rating": 1381.2787259684753,
            "rating_q975": 1397.1656962197283,
            "rating_q025": 1365.3917557172224
        },
        "gpt-4.1-mini-2025-04-14": {
            "rating": 1380.9193721284441,
            "rating_q975": 1394.0121315484382,
            "rating_q025": 1367.82661270845
        },
        "mistral-medium-2505": {
            "rating": 1377.4001539040626,
            "rating_q975": 1390.9683579500652,
            "rating_q025": 1363.83194985806
        },
        "o1-preview": {
            "rating": 1376.365821295218,
            "rating_q975": 1390.278943954691,
            "rating_q025": 1362.452698635745
        },
        "qwen3-coder-480b-a35b-instruct": {
            "rating": 1376.360734956117,
            "rating_q975": 1393.0249494186035,
            "rating_q025": 1359.6965204936307
        },
        "grok-3-mini-beta": {
            "rating": 1374.284254313424,
            "rating_q975": 1391.136533582011,
            "rating_q025": 1357.4319750448371
        },
        "amazon-nova-experimental-chat-10-09": {
            "rating": 1372.9863771049065,
            "rating_q975": 1402.1230391652887,
            "rating_q025": 1343.8497150445244
        },
        "minimax-m1": {
            "rating": 1371.1530007370447,
            "rating_q975": 1385.6404204325972,
            "rating_q025": 1356.6655810414923
        },
        "nvidia-llama-3.3-nemotron-super-49b-v1.5": {
            "rating": 1369.6556624163143,
            "rating_q975": 1408.6587120045638,
            "rating_q025": 1330.6526128280648
        },
        "gemini-2.5-flash-lite-preview-06-17-thinking": {
            "rating": 1368.147668328656,
            "rating_q975": 1382.901225373578,
            "rating_q025": 1353.394111283734
        },
        "qwen-plus-0125": {
            "rating": 1366.6960116645548,
            "rating_q975": 1396.3387053155407,
            "rating_q025": 1337.053318013569
        },
        "claude-3-5-sonnet-20241022": {
            "rating": 1365.509897079039,
            "rating_q975": 1374.23427861085,
            "rating_q025": 1356.7855155472282
        },
        "nova-2-lite": {
            "rating": 1365.072586637486,
            "rating_q975": 1397.7297335823678,
            "rating_q025": 1332.4154396926042
        },
        "qwen2.5-max": {
            "rating": 1364.0758155660033,
            "rating_q975": 1377.5689794400876,
            "rating_q025": 1350.582651691919
        },
        "o3-mini": {
            "rating": 1363.0328276689957,
            "rating_q975": 1374.1433783223986,
            "rating_q025": 1351.9222770155927
        },
        "amazon-nova-experimental-chat-10-20": {
            "rating": 1361.7130526947872,
            "rating_q975": 1389.8029416104707,
            "rating_q025": 1333.6231637791036
        },
        "gpt-oss-120b": {
            "rating": 1360.4379494840803,
            "rating_q975": 1376.9796007534544,
            "rating_q025": 1343.8962982147061
        },
        "ring-flash-2.0": {
            "rating": 1359.01391953733,
            "rating_q975": 1390.583398496418,
            "rating_q025": 1327.4444405782417
        },
        "qwq-32b": {
            "rating": 1358.8249380231837,
            "rating_q975": 1375.452556347349,
            "rating_q025": 1342.1973196990184
        },
        "ling-flash-2.0": {
            "rating": 1357.7826588702578,
            "rating_q975": 1387.579730455061,
            "rating_q025": 1327.9855872854546
        },
        "step-3": {
            "rating": 1357.4955634677713,
            "rating_q975": 1392.8045264473135,
            "rating_q025": 1322.186600488229
        },
        "gpt-5-nano-high": {
            "rating": 1357.4064825215394,
            "rating_q975": 1391.2338874704408,
            "rating_q025": 1323.579077572638
        },
        "hunyuan-turbos-20250416": {
            "rating": 1352.5872751365987,
            "rating_q975": 1376.1586631011903,
            "rating_q025": 1329.015887172007
        },
        "gemini-2.0-flash-001": {
            "rating": 1351.5944942042213,
            "rating_q975": 1364.1466755679041,
            "rating_q025": 1339.0423128405384
        },
        "o1-mini": {
            "rating": 1346.8878057461147,
            "rating_q975": 1357.8340100232133,
            "rating_q025": 1335.9416014690162
        },
        "deepseek-v3": {
            "rating": 1342.8070914237608,
            "rating_q975": 1358.9575565348043,
            "rating_q025": 1326.6566263127172
        },
        "qwen3-30b-a3b": {
            "rating": 1342.048910420635,
            "rating_q975": 1358.3373107043146,
            "rating_q025": 1325.7605101369552
        },
        "claude-3-5-sonnet-20240620": {
            "rating": 1336.915146638031,
            "rating_q975": 1347.3391712631433,
            "rating_q025": 1326.4911220129188
        },
        "command-a-03-2025": {
            "rating": 1336.1488349747842,
            "rating_q975": 1347.5064447053796,
            "rating_q025": 1324.7912252441888
        },
        "gemma-3-27b-it": {
            "rating": 1332.1764624877214,
            "rating_q975": 1344.7867175820475,
            "rating_q025": 1319.5662073933954
        },
        "gemini-1.5-pro-002": {
            "rating": 1332.0370310658905,
            "rating_q975": 1342.2614813240382,
            "rating_q025": 1321.8125808077427
        },
        "minimax-m2": {
            "rating": 1331.970194510379,
            "rating_q975": 1367.8132444171104,
            "rating_q025": 1296.1271446036478
        },
        "mistral-small-2506": {
            "rating": 1327.637045495048,
            "rating_q975": 1346.972395539691,
            "rating_q025": 1308.3016954504048
        },
        "gemini-2.0-flash-lite-preview-02-05": {
            "rating": 1326.6992774126834,
            "rating_q975": 1342.75929080123,
            "rating_q025": 1310.6392640241368
        },
        "yi-lightning": {
            "rating": 1326.481700716744,
            "rating_q975": 1340.5154601742436,
            "rating_q025": 1312.4479412592443
        },
        "llama-4-maverick-17b-128e-instruct": {
            "rating": 1323.3640059948254,
            "rating_q975": 1336.6123352817528,
            "rating_q025": 1310.115676707898
        },
        "step-2-16k-exp-202412": {
            "rating": 1321.2163180994928,
            "rating_q975": 1352.3374107993675,
            "rating_q025": 1290.0952253996181
        },
        "qwen2.5-plus-1127": {
            "rating": 1318.5475611411284,
            "rating_q975": 1339.472215757654,
            "rating_q025": 1297.6229065246027
        },
        "hunyuan-large-2025-02-10": {
            "rating": 1318.5388073795928,
            "rating_q975": 1354.7814093518155,
            "rating_q025": 1282.29620540737
        },
        "llama-3.1-405b-instruct-fp8": {
            "rating": 1317.835116015537,
            "rating_q975": 1328.523912058937,
            "rating_q025": 1307.1463199721372
        },
        "gpt-oss-20b": {
            "rating": 1316.391761544608,
            "rating_q975": 1344.480231564134,
            "rating_q025": 1288.303291525082
        },
        "claude-3-opus-20240229": {
            "rating": 1311.4338463795307,
            "rating_q975": 1319.9096415231775,
            "rating_q025": 1302.9580512358839
        },
        "gemini-1.5-pro-001": {
            "rating": 1311.0696248422455,
            "rating_q975": 1322.304567261433,
            "rating_q025": 1299.834682423058
        },
        "gpt-4.1-nano-2025-04-14": {
            "rating": 1309.9182469228608,
            "rating_q975": 1340.6521284333965,
            "rating_q025": 1279.1843654123252
        },
        "grok-2-2024-08-13": {
            "rating": 1308.8891236117217,
            "rating_q975": 1318.9108162819255,
            "rating_q025": 1298.867430941518
        },
        "claude-3-5-haiku-20241022": {
            "rating": 1307.8320729917525,
            "rating_q975": 1318.165510015976,
            "rating_q025": 1297.498635967529
        },
        "athene-v2-chat": {
            "rating": 1306.9059018302285,
            "rating_q975": 1321.341907278738,
            "rating_q025": 1292.4698963817189
        },
        "mistral-small-3.1-24b-instruct-2503": {
            "rating": 1306.8094856802486,
            "rating_q975": 1321.8309335609981,
            "rating_q025": 1291.788037799499
        },
        "glm-4-plus-0111": {
            "rating": 1306.1241516303867,
            "rating_q975": 1335.2201388029641,
            "rating_q025": 1277.0281644578092
        },
        "gpt-4o-2024-05-13": {
            "rating": 1305.7812293954835,
            "rating_q975": 1314.966824001977,
            "rating_q025": 1296.5956347889899
        },
        "llama-3.1-405b-instruct-bf16": {
            "rating": 1305.2575754771044,
            "rating_q975": 1317.5917595464894,
            "rating_q025": 1292.9233914077195
        },
        "gpt-4o-2024-08-06": {
            "rating": 1305.218077229526,
            "rating_q975": 1317.1788123002607,
            "rating_q025": 1293.2573421587913
        },
        "llama-4-scout-17b-16e-instruct": {
            "rating": 1303.5818047650891,
            "rating_q975": 1319.1402588233025,
            "rating_q025": 1288.0233507068758
        },
        "deepseek-v2.5-1210": {
            "rating": 1302.3788411256444,
            "rating_q975": 1328.3409127243806,
            "rating_q025": 1276.4167695269082
        },
        "hunyuan-large-vision": {
            "rating": 1301.3559338586028,
            "rating_q975": 1334.1552269901529,
            "rating_q025": 1268.5566407270528
        },
        "glm-4-plus": {
            "rating": 1298.8359207971876,
            "rating_q975": 1312.9693082326364,
            "rating_q025": 1284.7025333617387
        },
        "mistral-large-2407": {
            "rating": 1295.5550895149559,
            "rating_q975": 1307.3110085153573,
            "rating_q025": 1283.7991705145544
        },
        "qwen-max-0919": {
            "rating": 1295.527139018378,
            "rating_q975": 1313.065691538068,
            "rating_q025": 1277.988586498688
        },
        "athene-70b-0725": {
            "rating": 1292.2356119071765,
            "rating_q975": 1311.0026768666362,
            "rating_q025": 1273.4685469477167
        },
        "step-1o-turbo-202506": {
            "rating": 1292.1360777121104,
            "rating_q975": 1318.5554040382365,
            "rating_q025": 1265.7167513859843
        },
        "deepseek-v2.5": {
            "rating": 1291.4537682985729,
            "rating_q975": 1305.69838422839,
            "rating_q025": 1277.2091523687557
        },
        "gpt-4-turbo-2024-04-09": {
            "rating": 1291.3759028165755,
            "rating_q975": 1301.5413405537965,
            "rating_q025": 1281.2104650793544
        },
        "llama-3.3-70b-instruct": {
            "rating": 1291.291021854503,
            "rating_q975": 1301.9126100066533,
            "rating_q025": 1280.6694337023528
        },
        "qwen2.5-72b-instruct": {
            "rating": 1290.757439652585,
            "rating_q975": 1302.1656807172933,
            "rating_q025": 1279.3491985878766
        },
        "magistral-medium-2506": {
            "rating": 1289.9759454820926,
            "rating_q975": 1316.3076120600297,
            "rating_q025": 1263.6442789041555
        },
        "llama-3.1-nemotron-70b-instruct": {
            "rating": 1289.4691739475902,
            "rating_q975": 1316.3854324006106,
            "rating_q025": 1262.5529154945698
        },
        "grok-2-mini-2024-08-13": {
            "rating": 1288.7514793764994,
            "rating_q975": 1299.726153616532,
            "rating_q025": 1277.776805136467
        },
        "gemini-advanced-0514": {
            "rating": 1288.6232486508716,
            "rating_q975": 1302.377893032457,
            "rating_q025": 1274.8686042692862
        },
        "hunyuan-standard-2025-02-10": {
            "rating": 1286.043666310577,
            "rating_q975": 1325.0243198320284,
            "rating_q025": 1247.0630127891257
        },
        "reka-core-20240904": {
            "rating": 1283.8112202778816,
            "rating_q975": 1308.0774850107339,
            "rating_q025": 1259.5449555450293
        },
        "gpt-4-1106-preview": {
            "rating": 1283.453201870348,
            "rating_q975": 1294.6388717324023,
            "rating_q025": 1272.2675320082938
        },
        "gpt-4o-mini-2024-07-18": {
            "rating": 1279.584599987622,
            "rating_q975": 1289.572281158075,
            "rating_q025": 1269.596918817169
        },
        "jamba-1.5-large": {
            "rating": 1278.9996548224126,
            "rating_q975": 1307.6861421196058,
            "rating_q025": 1250.3131675252193
        },
        "gemma-3n-e4b-it": {
            "rating": 1278.6896838500807,
            "rating_q975": 1296.681590555902,
            "rating_q025": 1260.6977771442594
        },
        "gemini-1.5-flash-002": {
            "rating": 1277.8448597170986,
            "rating_q975": 1290.2694571262905,
            "rating_q025": 1265.4202623079068
        },
        "gpt-4-0125-preview": {
            "rating": 1274.4250029564323,
            "rating_q975": 1285.5391176201797,
            "rating_q025": 1263.310888292685
        },
        "qwen2.5-coder-32b-instruct": {
            "rating": 1272.3364886259674,
            "rating_q975": 1304.8952519394375,
            "rating_q025": 1239.7777253124973
        },
        "gemma-3-12b-it": {
            "rating": 1269.2251421635524,
            "rating_q975": 1310.9094404605896,
            "rating_q025": 1227.5408438665152
        },
        "reka-flash-20240904": {
            "rating": 1268.6364126569426,
            "rating_q975": 1291.4751187790052,
            "rating_q025": 1245.79770653488
        },
        "amazon-nova-pro-v1.0": {
            "rating": 1268.4606389055689,
            "rating_q975": 1283.7972983524098,
            "rating_q025": 1253.123979458728
        },
        "llama-3.1-70b-instruct": {
            "rating": 1267.9151143170452,
            "rating_q975": 1278.621735930573,
            "rating_q025": 1257.2084927035173
        },
        "mistral-large-2411": {
            "rating": 1265.5467796079656,
            "rating_q975": 1280.025152595201,
            "rating_q025": 1251.0684066207302
        },
        "claude-3-sonnet-20240229": {
            "rating": 1264.8571106031536,
            "rating_q975": 1275.9727473291002,
            "rating_q025": 1253.741473877207
        },
        "phi-4": {
            "rating": 1262.7653238292405,
            "rating_q975": 1279.587292936122,
            "rating_q025": 1245.9433547223591
        },
        "gemini-1.5-flash-001": {
            "rating": 1259.9743089240146,
            "rating_q975": 1271.5772263410831,
            "rating_q025": 1248.371391506946
        },
        "deepseek-coder-v2": {
            "rating": 1259.8610488850434,
            "rating_q975": 1280.845119782741,
            "rating_q025": 1238.8769779873458
        },
        "c4ai-aya-expanse-32b": {
            "rating": 1258.1189344230802,
            "rating_q975": 1271.4172269942435,
            "rating_q025": 1244.820641851917
        },
        "amazon-nova-lite-v1.0": {
            "rating": 1256.8683039112534,
            "rating_q975": 1273.088356660193,
            "rating_q025": 1240.6482511623137
        },
        "gpt-4-0314": {
            "rating": 1256.0551538464724,
            "rating_q975": 1270.8954796229627,
            "rating_q025": 1241.214828069982
        },
        "gemma-3-4b-it": {
            "rating": 1253.7137942168936,
            "rating_q975": 1295.110219563036,
            "rating_q025": 1212.3173688707511
        },
        "qwen2-72b-instruct": {
            "rating": 1253.4533958272475,
            "rating_q975": 1267.423441361849,
            "rating_q025": 1239.483350292646
        },
        "mistral-small-24b-instruct-2501": {
            "rating": 1253.3922246376292,
            "rating_q975": 1273.7542344950198,
            "rating_q025": 1233.0302147802386
        },
        "nemotron-4-340b-instruct": {
            "rating": 1252.8020257833664,
            "rating_q975": 1271.0916476936188,
            "rating_q025": 1234.512403873114
        },
        "gemma-2-27b-it": {
            "rating": 1250.1421197990935,
            "rating_q975": 1259.8235805930863,
            "rating_q025": 1240.4606590051008
        },
        "llama-3.1-nemotron-51b-instruct": {
            "rating": 1246.1829192182736,
            "rating_q975": 1279.3781405568752,
            "rating_q025": 1212.987697879672
        },
        "glm-4-0520": {
            "rating": 1245.6936052638944,
            "rating_q975": 1270.1765610188866,
            "rating_q025": 1221.2106495089022
        },
        "claude-3-haiku-20240307": {
            "rating": 1244.944056303013,
            "rating_q975": 1255.0074802313538,
            "rating_q025": 1234.8806323746721
        },
        "gpt-4-0613": {
            "rating": 1244.5244951857471,
            "rating_q975": 1256.6485240205132,
            "rating_q025": 1232.400466350981
        },
        "command-r-plus-08-2024": {
            "rating": 1243.2949721479565,
            "rating_q975": 1267.593816891908,
            "rating_q025": 1218.996127404005
        },
        "amazon-nova-micro-v1.0": {
            "rating": 1238.638715826055,
            "rating_q975": 1255.4784586433227,
            "rating_q025": 1221.7989730087872
        },
        "llama-3-70b-instruct": {
            "rating": 1236.7647592139836,
            "rating_q975": 1246.7131353636773,
            "rating_q025": 1226.8163830642898
        },
        "gemini-1.5-flash-8b-001": {
            "rating": 1235.343695014669,
            "rating_q975": 1247.7605638188504,
            "rating_q025": 1222.9268262104877
        },
        "command-r-plus": {
            "rating": 1234.6842906740974,
            "rating_q975": 1246.3148350543252,
            "rating_q025": 1223.0537462938696
        },
        "ministral-8b-2410": {
            "rating": 1231.6509261929195,
            "rating_q975": 1261.515606870904,
            "rating_q025": 1201.786245514935
        },
        "granite-3.1-8b-instruct": {
            "rating": 1228.5673390607808,
            "rating_q975": 1263.6007617213593,
            "rating_q025": 1193.5339164002023
        },
        "qwen1.5-72b-chat": {
            "rating": 1228.02393239321,
            "rating_q975": 1242.6423625865855,
            "rating_q025": 1213.4055021998347
        },
        "gemma-2-9b-it": {
            "rating": 1227.5800391834348,
            "rating_q975": 1238.7655459504092,
            "rating_q025": 1216.3945324164604
        },
        "gemma-2-9b-it-simpo": {
            "rating": 1226.0209877469033,
            "rating_q975": 1255.2390886342155,
            "rating_q025": 1196.8028868595911
        },
        "c4ai-aya-expanse-8b": {
            "rating": 1225.304735832427,
            "rating_q975": 1248.645469091357,
            "rating_q025": 1201.964002573497
        },
        "command-r-08-2024": {
            "rating": 1224.8572471758025,
            "rating_q975": 1246.6019803213437,
            "rating_q025": 1203.1125140302613
        },
        "qwen1.5-110b-chat": {
            "rating": 1221.1824802167694,
            "rating_q975": 1237.067130849118,
            "rating_q025": 1205.2978295844207
        },
        "mistral-large-2402": {
            "rating": 1220.3607375748466,
            "rating_q975": 1233.3532181520013,
            "rating_q025": 1207.3682569976918
        },
        "mistral-medium": {
            "rating": 1219.3975043528521,
            "rating_q975": 1235.9467243944082,
            "rating_q025": 1202.848284311296
        },
        "reka-flash-21b-20240226-online": {
            "rating": 1218.5264595874626,
            "rating_q975": 1239.337336656706,
            "rating_q025": 1197.7155825182192
        },
        "qwen1.5-32b-chat": {
            "rating": 1216.0976598571033,
            "rating_q975": 1233.7706855907952,
            "rating_q025": 1198.4246341234114
        },
        "internlm2_5-20b-chat": {
            "rating": 1214.1589102417067,
            "rating_q975": 1235.7502271994347,
            "rating_q025": 1192.5675932839788
        },
        "yi-1.5-34b-chat": {
            "rating": 1213.8513180768446,
            "rating_q975": 1231.8384637841893,
            "rating_q025": 1195.8641723694998
        },
        "granite-3.1-2b-instruct": {
            "rating": 1211.2719977894162,
            "rating_q975": 1246.6014440530307,
            "rating_q025": 1175.9425515258017
        },
        "mixtral-8x22b-instruct-v0.1": {
            "rating": 1210.9243473098961,
            "rating_q975": 1224.0506750244028,
            "rating_q025": 1197.7980195953894
        },
        "reka-flash-21b-20240226": {
            "rating": 1208.0549924276224,
            "rating_q975": 1224.6653768071283,
            "rating_q025": 1191.4446080481166
        },
        "command-r": {
            "rating": 1206.9772093986758,
            "rating_q975": 1220.1299781859404,
            "rating_q025": 1193.824440611411
        },
        "jamba-1.5-mini": {
            "rating": 1205.5782346345,
            "rating_q975": 1236.2849597169643,
            "rating_q025": 1174.8715095520356
        },
        "gpt-3.5-turbo-1106": {
            "rating": 1204.8459345320305,
            "rating_q975": 1232.6062529243702,
            "rating_q025": 1177.0856161396907
        },
        "llama-3-8b-instruct": {
            "rating": 1202.9789700943884,
            "rating_q975": 1213.9219553489754,
            "rating_q025": 1192.0359848398014
        },
        "phi-3-medium-4k-instruct": {
            "rating": 1197.8836554261816,
            "rating_q975": 1215.2699300696847,
            "rating_q025": 1180.4973807826784
        },
        "granite-3.0-8b-instruct": {
            "rating": 1195.8894015623482,
            "rating_q975": 1226.8281692511123,
            "rating_q025": 1164.9506338735841
        },
        "llama-3.1-8b-instruct": {
            "rating": 1191.941178350767,
            "rating_q975": 1203.4311390195007,
            "rating_q025": 1180.451217682033
        },
        "gpt-3.5-turbo-0125": {
            "rating": 1188.0947683477038,
            "rating_q975": 1200.254392174272,
            "rating_q025": 1175.9351445211357
        },
        "mixtral-8x7b-instruct-v0.1": {
            "rating": 1188.0302504187152,
            "rating_q975": 1200.3051507204639,
            "rating_q025": 1175.7553501169666
        },
        "qwen1.5-14b-chat": {
            "rating": 1187.1597605752168,
            "rating_q975": 1206.7162383875502,
            "rating_q025": 1167.6032827628833
        },
        "dbrx-instruct-preview": {
            "rating": 1181.283611225082,
            "rating_q975": 1196.9037900118838,
            "rating_q025": 1165.6634324382803
        },
        "llama-3.2-3b-instruct": {
            "rating": 1171.3289654828122,
            "rating_q975": 1195.9708878587596,
            "rating_q025": 1146.6870431068648
        },
        "gemini-pro-dev-api": {
            "rating": 1170.5117749794701,
            "rating_q975": 1193.6114688211724,
            "rating_q025": 1147.412081137768
        },
        "granite-3.0-2b-instruct": {
            "rating": 1168.729449472486,
            "rating_q975": 1197.09216156059,
            "rating_q025": 1140.366737384382
        },
        "starling-lm-7b-beta": {
            "rating": 1168.473435566971,
            "rating_q975": 1187.8132462969022,
            "rating_q025": 1149.1336248370396
        },
        "zephyr-orpo-141b-A35b-v0.1": {
            "rating": 1165.6269825809325,
            "rating_q975": 1205.3286319913882,
            "rating_q025": 1125.9253331704767
        },
        "gemma-2-2b-it": {
            "rating": 1163.3127629207113,
            "rating_q975": 1175.4197466747423,
            "rating_q025": 1151.2057791666803
        },
        "gemma-1.1-7b-it": {
            "rating": 1162.2201702123357,
            "rating_q975": 1179.4059607409426,
            "rating_q025": 1145.0343796837287
        },
        "phi-3-small-8k-instruct": {
            "rating": 1158.8592094966975,
            "rating_q975": 1177.4846372671511,
            "rating_q025": 1140.233781726244
        },
        "snowflake-arctic-instruct": {
            "rating": 1155.406593865299,
            "rating_q975": 1172.0404788926267,
            "rating_q025": 1138.7727088379715
        },
        "openchat-3.5": {
            "rating": 1155.316695283018,
            "rating_q975": 1196.8495661252052,
            "rating_q025": 1113.7838244408306
        },
        "openchat-3.5-0106": {
            "rating": 1153.4036198639699,
            "rating_q975": 1175.9968967382758,
            "rating_q025": 1130.810342989664
        },
        "qwq-32b-preview": {
            "rating": 1151.069625106842,
            "rating_q975": 1186.6877897000506,
            "rating_q025": 1115.4514605136335
        },
        "yi-34b-chat": {
            "rating": 1148.2743294259647,
            "rating_q975": 1172.9183940313512,
            "rating_q025": 1123.630264820578
        },
        "phi-3-mini-4k-instruct-june-2024": {
            "rating": 1143.2036305251365,
            "rating_q975": 1168.9667087490448,
            "rating_q025": 1117.4405523012283
        },
        "qwen1.5-7b-chat": {
            "rating": 1140.9688355023068,
            "rating_q975": 1177.4211184875046,
            "rating_q025": 1104.516552517109
        },
        "vicuna-33b": {
            "rating": 1138.4961387338915,
            "rating_q975": 1164.7984613073345,
            "rating_q025": 1112.1938161604485
        },
        "phi-3-mini-4k-instruct": {
            "rating": 1134.693258834625,
            "rating_q975": 1153.7940410626395,
            "rating_q025": 1115.5924766066107
        },
        "mistral-7b-instruct-v0.2": {
            "rating": 1133.3581587714234,
            "rating_q975": 1153.4289676719718,
            "rating_q025": 1113.287349870875
        },
        "starling-lm-7b-alpha": {
            "rating": 1131.9533776545,
            "rating_q975": 1162.3536671262286,
            "rating_q025": 1101.5530881827713
        },
        "llama-2-70b-chat": {
            "rating": 1130.3016228396955,
            "rating_q975": 1147.082318917537,
            "rating_q025": 1113.520926761854
        },
        "llama-2-7b-chat": {
            "rating": 1124.921520835197,
            "rating_q975": 1152.4600852360386,
            "rating_q025": 1097.3829564343555
        },
        "llama-2-13b-chat": {
            "rating": 1123.2501848220606,
            "rating_q975": 1148.1903630924635,
            "rating_q025": 1098.3100065516578
        },
        "gemma-7b-it": {
            "rating": 1111.8828256326851,
            "rating_q975": 1142.3932617314845,
            "rating_q025": 1081.3723895338858
        },
        "vicuna-13b": {
            "rating": 1108.4453723893273,
            "rating_q975": 1139.552627079614,
            "rating_q025": 1077.3381176990406
        },
        "olmo-7b-instruct": {
            "rating": 1107.3501474719533,
            "rating_q975": 1145.4592472279558,
            "rating_q025": 1069.2410477159508
        },
        "zephyr-7b-beta": {
            "rating": 1105.4411623121468,
            "rating_q975": 1143.7327269199209,
            "rating_q025": 1067.1495977043728
        },
        "gemma-1.1-2b-it": {
            "rating": 1104.1858555643264,
            "rating_q975": 1129.666562666135,
            "rating_q025": 1078.7051484625179
        },
        "qwen1.5-4b-chat": {
            "rating": 1098.1591554984207,
            "rating_q975": 1129.0138237833366,
            "rating_q025": 1067.3044872135047
        },
        "phi-3-mini-128k-instruct": {
            "rating": 1091.0125188374714,
            "rating_q975": 1110.968880541896,
            "rating_q025": 1071.0561571330468
        },
        "llama-3.2-1b-instruct": {
            "rating": 1076.285015745836,
            "rating_q975": 1104.0969863969256,
            "rating_q025": 1048.4730450947466
        },
        "mistral-7b-instruct": {
            "rating": 1075.294293111474,
            "rating_q975": 1114.7546715175674,
            "rating_q025": 1035.8339147053805
        }
    },
    "french": {
        "grok-4.1-thinking": {
            "rating": 1523.1417952797592,
            "rating_q975": 1556.7430440157038,
            "rating_q025": 1489.5405465438146
        },
        "gemini-3-pro": {
            "rating": 1513.7621687569142,
            "rating_q975": 1547.3769151286506,
            "rating_q025": 1480.1474223851778
        },
        "claude-opus-4-5-20251101-thinking-32k": {
            "rating": 1490.2003802515114,
            "rating_q975": 1538.574564159645,
            "rating_q025": 1441.826196343378
        },
        "claude-opus-4-5-20251101": {
            "rating": 1488.5542636100506,
            "rating_q975": 1533.9105130347411,
            "rating_q025": 1443.19801418536
        },
        "gpt-5.1-high": {
            "rating": 1486.1664965915475,
            "rating_q975": 1522.8886973449776,
            "rating_q025": 1449.4442958381173
        },
        "grok-4.1": {
            "rating": 1485.7756149439467,
            "rating_q975": 1521.7854887999572,
            "rating_q025": 1449.7657410879362
        },
        "o3-2025-04-16": {
            "rating": 1478.9668502751952,
            "rating_q975": 1503.3813341942077,
            "rating_q025": 1454.5523663561826
        },
        "claude-opus-4-1-20250805-thinking-16k": {
            "rating": 1478.3224114150635,
            "rating_q975": 1504.7104992091195,
            "rating_q025": 1451.9343236210075
        },
        "claude-opus-4-1-20250805": {
            "rating": 1472.0897513695722,
            "rating_q975": 1495.810950841669,
            "rating_q025": 1448.3685518974755
        },
        "gpt-5.1": {
            "rating": 1469.3281531658897,
            "rating_q975": 1509.0138001948008,
            "rating_q025": 1429.6425061369787
        },
        "qwen3-235b-a22b-instruct-2507": {
            "rating": 1467.219686195697,
            "rating_q975": 1491.5033367779395,
            "rating_q025": 1442.9360356134546
        },
        "qwen3-max-preview": {
            "rating": 1466.1616124269835,
            "rating_q975": 1497.8689018830867,
            "rating_q025": 1434.4543229708804
        },
        "gemini-2.5-pro": {
            "rating": 1465.9024488384737,
            "rating_q975": 1487.7284333624184,
            "rating_q025": 1444.076464314529
        },
        "glm-4.6": {
            "rating": 1465.4371252892793,
            "rating_q975": 1498.9791734090554,
            "rating_q025": 1431.895077169503
        },
        "chatgpt-4o-latest-20250326": {
            "rating": 1464.6475941151566,
            "rating_q975": 1487.902416637002,
            "rating_q025": 1441.3927715933112
        },
        "claude-sonnet-4-5-20250929-thinking-32k": {
            "rating": 1462.6814732647108,
            "rating_q975": 1493.618400635599,
            "rating_q025": 1431.7445458938225
        },
        "claude-opus-4-20250514-thinking-16k": {
            "rating": 1461.8139377640698,
            "rating_q975": 1491.1621186561379,
            "rating_q025": 1432.4657568720017
        },
        "kimi-k2-thinking-turbo": {
            "rating": 1459.7371544724733,
            "rating_q975": 1496.7306370194722,
            "rating_q025": 1422.7436719254745
        },
        "gemini-2.5-flash-preview-09-2025": {
            "rating": 1459.3917290055704,
            "rating_q975": 1490.152645529757,
            "rating_q025": 1428.6308124813838
        },
        "claude-sonnet-4-5-20250929": {
            "rating": 1458.928054739424,
            "rating_q975": 1492.6516327255106,
            "rating_q025": 1425.2044767533373
        },
        "deepseek-v3.1": {
            "rating": 1454.6392601733396,
            "rating_q975": 1494.067695292622,
            "rating_q025": 1415.2108250540573
        },
        "gpt-5-chat": {
            "rating": 1452.7245099729296,
            "rating_q975": 1484.121798011386,
            "rating_q025": 1421.327221934473
        },
        "grok-3-preview-02-24": {
            "rating": 1450.2012233746866,
            "rating_q975": 1483.3592219284483,
            "rating_q025": 1417.043224820925
        },
        "qwen3-coder-480b-a35b-instruct": {
            "rating": 1448.0295127851336,
            "rating_q975": 1484.2615256262493,
            "rating_q025": 1411.797499944018
        },
        "gpt-4.5-preview-2025-02-27": {
            "rating": 1447.946967715529,
            "rating_q975": 1505.0659044611202,
            "rating_q025": 1390.8280309699376
        },
        "grok-4-1-fast-reasoning": {
            "rating": 1446.41247426256,
            "rating_q975": 1497.438423670357,
            "rating_q025": 1395.386524854763
        },
        "mistral-medium-2508": {
            "rating": 1446.0361288148738,
            "rating_q975": 1471.936929176099,
            "rating_q025": 1420.1353284536485
        },
        "deepseek-v3.2-exp": {
            "rating": 1442.4525809345928,
            "rating_q975": 1488.179854101024,
            "rating_q025": 1396.7253077681617
        },
        "gpt-5-high": {
            "rating": 1441.7741541263192,
            "rating_q975": 1473.4766550125642,
            "rating_q025": 1410.0716532400743
        },
        "grok-4-fast-reasoning": {
            "rating": 1440.7569552158634,
            "rating_q975": 1479.2387361470053,
            "rating_q025": 1402.2751742847215
        },
        "claude-sonnet-4-20250514": {
            "rating": 1440.5694628258457,
            "rating_q975": 1467.9419659878565,
            "rating_q025": 1413.1969596638348
        },
        "claude-sonnet-4-20250514-thinking-32k": {
            "rating": 1435.431801375612,
            "rating_q975": 1464.445703478512,
            "rating_q025": 1406.4178992727118
        },
        "deepseek-v3.2": {
            "rating": 1433.3433893962645,
            "rating_q975": 1487.0871685208785,
            "rating_q025": 1379.5996102716504
        },
        "kimi-k2-0905-preview": {
            "rating": 1433.0640228910306,
            "rating_q975": 1478.1838429861873,
            "rating_q025": 1387.944202795874
        },
        "gpt-4.1-2025-04-14": {
            "rating": 1431.024224764096,
            "rating_q975": 1456.001807933534,
            "rating_q025": 1406.046641594658
        },
        "mai-1-preview": {
            "rating": 1430.5127385228732,
            "rating_q975": 1467.380611346925,
            "rating_q025": 1393.6448656988214
        },
        "kimi-k2-0711-preview": {
            "rating": 1430.0150378113763,
            "rating_q975": 1462.7083614123594,
            "rating_q025": 1397.321714210393
        },
        "longcat-flash-chat": {
            "rating": 1429.375724722469,
            "rating_q975": 1478.4366200267455,
            "rating_q025": 1380.3148294181924
        },
        "deepseek-r1-0528": {
            "rating": 1428.6070121730493,
            "rating_q975": 1468.6985151118972,
            "rating_q025": 1388.5155092342013
        },
        "grok-4-0709": {
            "rating": 1428.4634510145977,
            "rating_q975": 1456.3850777161153,
            "rating_q025": 1400.54182431308
        },
        "glm-4.5": {
            "rating": 1427.136816597974,
            "rating_q975": 1462.2885746079264,
            "rating_q025": 1391.9850585880217
        },
        "claude-opus-4-20250514": {
            "rating": 1423.1969257462713,
            "rating_q975": 1450.0703579466378,
            "rating_q025": 1396.3234935459047
        },
        "deepseek-v3-0324": {
            "rating": 1422.3716202095945,
            "rating_q975": 1449.3883920815565,
            "rating_q025": 1395.3548483376326
        },
        "gemini-2.5-flash": {
            "rating": 1421.9884073917294,
            "rating_q975": 1443.5788121392534,
            "rating_q025": 1400.3980026442055
        },
        "deepseek-v3.2-exp-thinking": {
            "rating": 1420.8840251538343,
            "rating_q975": 1470.627175168547,
            "rating_q025": 1371.1408751391216
        },
        "o4-mini-2025-04-16": {
            "rating": 1416.0575198425956,
            "rating_q975": 1442.6619166875857,
            "rating_q025": 1389.4531229976055
        },
        "qwen3-next-80b-a3b-instruct": {
            "rating": 1414.2181579833355,
            "rating_q975": 1448.0800343227775,
            "rating_q025": 1380.3562816438935
        },
        "claude-haiku-4-5-20251001": {
            "rating": 1413.7401793851095,
            "rating_q975": 1446.4555726240767,
            "rating_q025": 1381.0247861461423
        },
        "qwen2.5-max": {
            "rating": 1413.715349179002,
            "rating_q975": 1446.1272640996751,
            "rating_q025": 1381.303434258329
        },
        "gpt-5-mini-high": {
            "rating": 1411.5039525054422,
            "rating_q975": 1445.5185556725803,
            "rating_q025": 1377.489349338304
        },
        "gemini-2.0-flash-001": {
            "rating": 1409.497496309998,
            "rating_q975": 1436.3582392337205,
            "rating_q025": 1382.6367533862756
        },
        "glm-4.5-air": {
            "rating": 1409.2083155988487,
            "rating_q975": 1439.127757589147,
            "rating_q025": 1379.2888736085504
        },
        "gpt-4.1-mini-2025-04-14": {
            "rating": 1408.1146090886239,
            "rating_q975": 1435.6650005850036,
            "rating_q025": 1380.5642175922442
        },
        "qwen3-30b-a3b-instruct-2507": {
            "rating": 1407.2505177445057,
            "rating_q975": 1442.1869221190393,
            "rating_q025": 1372.3141133699721
        },
        "minimax-m1": {
            "rating": 1405.4529811695118,
            "rating_q975": 1435.319959814646,
            "rating_q025": 1375.5860025243776
        },
        "gemini-2.5-flash-lite-preview-06-17-thinking": {
            "rating": 1402.8993450999983,
            "rating_q975": 1434.2654114150566,
            "rating_q025": 1371.53327878494
        },
        "claude-3-5-sonnet-20241022": {
            "rating": 1400.7231528323155,
            "rating_q975": 1421.764091281816,
            "rating_q025": 1379.682214382815
        },
        "claude-3-7-sonnet-20250219": {
            "rating": 1399.5682733386172,
            "rating_q975": 1427.3287903657313,
            "rating_q025": 1371.8077563115032
        },
        "o1-preview": {
            "rating": 1399.349171436705,
            "rating_q975": 1433.283978558835,
            "rating_q025": 1365.414364314575
        },
        "gemma-3-27b-it": {
            "rating": 1397.8913500389765,
            "rating_q975": 1423.3822286580953,
            "rating_q025": 1372.4004714198577
        },
        "mistral-medium-2505": {
            "rating": 1397.58679049028,
            "rating_q975": 1426.753611917805,
            "rating_q025": 1368.419969062755
        },
        "qwen3-235b-a22b-no-thinking": {
            "rating": 1395.268522027081,
            "rating_q975": 1423.793941485187,
            "rating_q025": 1366.743102568975
        },
        "deepseek-r1": {
            "rating": 1394.2605624555647,
            "rating_q975": 1436.1032473302403,
            "rating_q025": 1352.4178775808891
        },
        "o1-2024-12-17": {
            "rating": 1393.577776704058,
            "rating_q975": 1430.024115701087,
            "rating_q025": 1357.1314377070287
        },
        "qwen3-next-80b-a3b-thinking": {
            "rating": 1392.7335329300226,
            "rating_q975": 1433.7110167745213,
            "rating_q025": 1351.756049085524
        },
        "gemini-2.5-flash-lite-preview-09-2025-no-thinking": {
            "rating": 1391.6342036012409,
            "rating_q975": 1423.0638699238757,
            "rating_q025": 1360.204537278606
        },
        "command-a-03-2025": {
            "rating": 1390.6696106180207,
            "rating_q975": 1415.299341803449,
            "rating_q025": 1366.0398794325924
        },
        "hunyuan-turbos-20250416": {
            "rating": 1387.5706012471778,
            "rating_q975": 1436.823963522275,
            "rating_q025": 1338.3172389720805
        },
        "gemini-2.0-flash-lite-preview-02-05": {
            "rating": 1385.3909734724418,
            "rating_q975": 1423.481883875263,
            "rating_q025": 1347.3000630696206
        },
        "qwen-max-0919": {
            "rating": 1383.9467693470767,
            "rating_q975": 1425.409100014063,
            "rating_q025": 1342.4844386800905
        },
        "mistral-large-2411": {
            "rating": 1381.8533808565046,
            "rating_q975": 1421.6685908710872,
            "rating_q025": 1342.038170841922
        },
        "claude-3-7-sonnet-20250219-thinking-32k": {
            "rating": 1379.2375556140737,
            "rating_q975": 1408.329233570634,
            "rating_q025": 1350.1458776575134
        },
        "o3-mini-high": {
            "rating": 1379.229724654755,
            "rating_q975": 1423.2114534067125,
            "rating_q025": 1335.2479959027976
        },
        "deepseek-v3": {
            "rating": 1376.9492292783445,
            "rating_q975": 1413.3796053136593,
            "rating_q025": 1340.5188532430298
        },
        "amazon-nova-experimental-chat-10-20": {
            "rating": 1376.3856125921523,
            "rating_q975": 1429.2354698649126,
            "rating_q025": 1323.535755319392
        },
        "gemini-advanced-0514": {
            "rating": 1376.020980094144,
            "rating_q975": 1400.339424483863,
            "rating_q025": 1351.7025357044251
        },
        "claude-3-5-sonnet-20240620": {
            "rating": 1374.9532189835277,
            "rating_q975": 1396.7730404503943,
            "rating_q025": 1353.133397516661
        },
        "qwen3-30b-a3b": {
            "rating": 1373.18935753419,
            "rating_q975": 1406.49267325285,
            "rating_q025": 1339.8860418155302
        },
        "o3-mini": {
            "rating": 1370.4424023865708,
            "rating_q975": 1394.3182316023915,
            "rating_q025": 1346.5665731707502
        },
        "gpt-4o-2024-05-13": {
            "rating": 1370.0642150223212,
            "rating_q975": 1388.669667357572,
            "rating_q025": 1351.4587626870702
        },
        "qwen3-235b-a22b": {
            "rating": 1369.3395824757342,
            "rating_q975": 1402.9073253757067,
            "rating_q025": 1335.7718395757618
        },
        "amazon-nova-experimental-chat-10-09": {
            "rating": 1365.8140039887853,
            "rating_q975": 1421.9119761021445,
            "rating_q025": 1309.716031875426
        },
        "grok-3-mini-beta": {
            "rating": 1365.4500282302092,
            "rating_q975": 1402.9447290948856,
            "rating_q025": 1327.9553273655329
        },
        "mistral-small-2506": {
            "rating": 1364.9058298683817,
            "rating_q975": 1405.439185426142,
            "rating_q025": 1324.3724743106213
        },
        "athene-v2-chat": {
            "rating": 1363.479746988265,
            "rating_q975": 1399.8851215636264,
            "rating_q025": 1327.0743724129038
        },
        "grok-2-2024-08-13": {
            "rating": 1358.2405449843773,
            "rating_q975": 1382.8625348404953,
            "rating_q025": 1333.6185551282592
        },
        "gemini-1.5-pro-002": {
            "rating": 1352.8914077560817,
            "rating_q975": 1380.1567071674788,
            "rating_q025": 1325.6261083446846
        },
        "glm-4-plus": {
            "rating": 1352.4658668353009,
            "rating_q975": 1387.7047314684667,
            "rating_q025": 1317.227002202135
        },
        "qwq-32b": {
            "rating": 1351.810293814342,
            "rating_q975": 1386.0636323469282,
            "rating_q025": 1317.5569552817558
        },
        "gpt-4-1106-preview": {
            "rating": 1351.4143485067868,
            "rating_q975": 1370.2922517528857,
            "rating_q025": 1332.536445260688
        },
        "llama-3.1-405b-instruct-bf16": {
            "rating": 1351.1501479239691,
            "rating_q975": 1381.0053785336638,
            "rating_q025": 1321.2949173142745
        },
        "claude-3-opus-20240229": {
            "rating": 1350.9493119774706,
            "rating_q975": 1367.4023637828159,
            "rating_q025": 1334.4962601721254
        },
        "claude-3-5-haiku-20241022": {
            "rating": 1350.598027918446,
            "rating_q975": 1373.8958260955626,
            "rating_q025": 1327.3002297413293
        },
        "gpt-oss-120b": {
            "rating": 1350.5481732744283,
            "rating_q975": 1381.9646972816927,
            "rating_q025": 1319.131649267164
        },
        "gpt-4-0125-preview": {
            "rating": 1349.2156373378368,
            "rating_q975": 1368.996751843706,
            "rating_q025": 1329.4345228319676
        },
        "gemma-3n-e4b-it": {
            "rating": 1348.8940766711096,
            "rating_q975": 1383.6790685747021,
            "rating_q025": 1314.109084767517
        },
        "yi-lightning": {
            "rating": 1346.7092168290296,
            "rating_q975": 1382.7453706393278,
            "rating_q025": 1310.6730630187315
        },
        "gpt-4-turbo-2024-04-09": {
            "rating": 1345.9142902078256,
            "rating_q975": 1365.3659952237763,
            "rating_q025": 1326.462585191875
        },
        "grok-3-mini-high": {
            "rating": 1344.3099863131515,
            "rating_q975": 1389.0668305274764,
            "rating_q025": 1299.5531420988266
        },
        "gpt-4o-mini-2024-07-18": {
            "rating": 1343.893248309368,
            "rating_q975": 1366.7045860966853,
            "rating_q025": 1321.0819105220505
        },
        "llama-3.1-405b-instruct-fp8": {
            "rating": 1341.9526600793984,
            "rating_q975": 1368.0604510927624,
            "rating_q025": 1315.8448690660343
        },
        "llama-4-scout-17b-16e-instruct": {
            "rating": 1341.407009067355,
            "rating_q975": 1372.8123915288518,
            "rating_q025": 1310.001626605858
        },
        "gemini-1.5-pro-001": {
            "rating": 1341.0288173589183,
            "rating_q975": 1361.8039522239196,
            "rating_q025": 1320.253682493917
        },
        "llama-3.3-70b-instruct": {
            "rating": 1338.2939198692734,
            "rating_q975": 1363.9004448840549,
            "rating_q025": 1312.687394854492
        },
        "gpt-4o-2024-08-06": {
            "rating": 1337.5175062827543,
            "rating_q975": 1364.733670660141,
            "rating_q025": 1310.3013419053677
        },
        "mistral-large-2407": {
            "rating": 1336.3942964660187,
            "rating_q975": 1364.3378809116296,
            "rating_q025": 1308.4507120204078
        },
        "athene-70b-0725": {
            "rating": 1335.8822688330008,
            "rating_q975": 1376.8828819923756,
            "rating_q025": 1294.881655673626
        },
        "deepseek-v2.5": {
            "rating": 1329.9697111850637,
            "rating_q975": 1366.950404676638,
            "rating_q025": 1292.9890176934894
        },
        "o1-mini": {
            "rating": 1329.6286736817456,
            "rating_q975": 1358.2321884633911,
            "rating_q025": 1301.0251589001
        },
        "magistral-medium-2506": {
            "rating": 1327.4108450239323,
            "rating_q975": 1377.4288025121568,
            "rating_q025": 1277.3928875357078
        },
        "grok-2-mini-2024-08-13": {
            "rating": 1327.1413573812374,
            "rating_q975": 1354.6058027711406,
            "rating_q025": 1299.6769119913342
        },
        "qwen2.5-72b-instruct": {
            "rating": 1324.9770920307396,
            "rating_q975": 1356.8734457313199,
            "rating_q025": 1293.0807383301594
        },
        "amazon-nova-pro-v1.0": {
            "rating": 1323.2463062305014,
            "rating_q975": 1361.4877678197217,
            "rating_q025": 1285.0048446412811
        },
        "gpt-4-0314": {
            "rating": 1320.9868059056898,
            "rating_q975": 1345.136031101202,
            "rating_q025": 1296.8375807101777
        },
        "gemma-2-27b-it": {
            "rating": 1320.6369938750786,
            "rating_q975": 1342.01915568645,
            "rating_q025": 1299.2548320637072
        },
        "claude-3-sonnet-20240229": {
            "rating": 1313.9230244311302,
            "rating_q975": 1332.6532826132834,
            "rating_q025": 1295.192766248977
        },
        "llama-3.1-70b-instruct": {
            "rating": 1309.9769043198378,
            "rating_q975": 1337.275122782014,
            "rating_q025": 1282.6786858576615
        },
        "gemini-1.5-flash-001": {
            "rating": 1305.051648508455,
            "rating_q975": 1327.2824169106668,
            "rating_q025": 1282.820880106243
        },
        "c4ai-aya-expanse-32b": {
            "rating": 1302.2231396965226,
            "rating_q975": 1336.2094080338609,
            "rating_q025": 1268.2368713591843
        },
        "llama-3-70b-instruct": {
            "rating": 1301.9243017407662,
            "rating_q975": 1318.9746737117687,
            "rating_q025": 1284.8739297697637
        },
        "mistral-small-3.1-24b-instruct-2503": {
            "rating": 1301.8479879585855,
            "rating_q975": 1333.9769410588485,
            "rating_q025": 1269.7190348583224
        },
        "llama-4-maverick-17b-128e-instruct": {
            "rating": 1301.48118048518,
            "rating_q975": 1328.4321532809747,
            "rating_q025": 1274.5302076893852
        },
        "mistral-large-2402": {
            "rating": 1298.5000889707162,
            "rating_q975": 1320.356874193284,
            "rating_q025": 1276.6433037481484
        },
        "gemini-1.5-flash-002": {
            "rating": 1294.333269729177,
            "rating_q975": 1328.1071155255393,
            "rating_q025": 1260.5594239328145
        },
        "claude-3-haiku-20240307": {
            "rating": 1288.6371229646995,
            "rating_q975": 1307.1827072062065,
            "rating_q025": 1270.0915387231926
        },
        "command-r-plus": {
            "rating": 1288.4582183081557,
            "rating_q975": 1309.3121691517356,
            "rating_q025": 1267.6042674645757
        },
        "gemini-1.5-flash-8b-001": {
            "rating": 1285.8101800119755,
            "rating_q975": 1318.051191632719,
            "rating_q025": 1253.5691683912319
        },
        "gpt-4-0613": {
            "rating": 1285.1278228840029,
            "rating_q975": 1305.1620891781586,
            "rating_q025": 1265.0935565898471
        },
        "amazon-nova-micro-v1.0": {
            "rating": 1284.9035778884022,
            "rating_q975": 1329.2862864254616,
            "rating_q025": 1240.5208693513428
        },
        "nemotron-4-340b-instruct": {
            "rating": 1276.3278611044707,
            "rating_q975": 1309.6335997165693,
            "rating_q025": 1243.022122492372
        },
        "amazon-nova-lite-v1.0": {
            "rating": 1275.8584829752722,
            "rating_q975": 1321.0153814533392,
            "rating_q025": 1230.7015844972052
        },
        "phi-4": {
            "rating": 1274.7020965067468,
            "rating_q975": 1314.7322767424876,
            "rating_q025": 1234.671916271006
        },
        "gemma-2-9b-it": {
            "rating": 1269.0413028100836,
            "rating_q975": 1293.9817582239882,
            "rating_q025": 1244.100847396179
        },
        "deepseek-coder-v2": {
            "rating": 1268.334271503521,
            "rating_q975": 1309.5058566930172,
            "rating_q025": 1227.1626863140248
        },
        "mixtral-8x22b-instruct-v0.1": {
            "rating": 1267.2018561502398,
            "rating_q975": 1291.521932783792,
            "rating_q025": 1242.8817795166876
        },
        "qwen2-72b-instruct": {
            "rating": 1265.062473173729,
            "rating_q975": 1290.006776248302,
            "rating_q025": 1240.1181700991558
        },
        "mistral-small-24b-instruct-2501": {
            "rating": 1260.7646446397926,
            "rating_q975": 1310.721436579681,
            "rating_q025": 1210.807852699904
        },
        "mistral-medium": {
            "rating": 1260.5961146229165,
            "rating_q975": 1286.3259436830133,
            "rating_q025": 1234.8662855628197
        },
        "gemini-pro-dev-api": {
            "rating": 1258.8808050136101,
            "rating_q975": 1290.1347415777398,
            "rating_q025": 1227.6268684494805
        },
        "reka-flash-21b-20240226": {
            "rating": 1257.806459274944,
            "rating_q975": 1287.9196195536583,
            "rating_q025": 1227.6932989962297
        },
        "mixtral-8x7b-instruct-v0.1": {
            "rating": 1252.8315955908392,
            "rating_q975": 1273.5094031244994,
            "rating_q025": 1232.153788057179
        },
        "qwen1.5-72b-chat": {
            "rating": 1249.898789737343,
            "rating_q975": 1273.2940284679519,
            "rating_q025": 1226.503551006734
        },
        "command-r": {
            "rating": 1247.0805400519735,
            "rating_q975": 1270.8162212354766,
            "rating_q025": 1223.3448588684703
        },
        "gpt-3.5-turbo-0125": {
            "rating": 1246.1560289593044,
            "rating_q975": 1267.271466964856,
            "rating_q025": 1225.0405909537528
        },
        "reka-flash-21b-20240226-online": {
            "rating": 1243.7358212526287,
            "rating_q975": 1284.126010465026,
            "rating_q025": 1203.3456320402315
        },
        "qwen1.5-110b-chat": {
            "rating": 1239.4093279971798,
            "rating_q975": 1270.7180646359957,
            "rating_q025": 1208.100591358364
        },
        "llama-3-8b-instruct": {
            "rating": 1234.3174907397288,
            "rating_q975": 1253.702109681755,
            "rating_q025": 1214.9328717977025
        },
        "snowflake-arctic-instruct": {
            "rating": 1230.259799312638,
            "rating_q975": 1259.632865271996,
            "rating_q025": 1200.88673335328
        },
        "phi-3-small-8k-instruct": {
            "rating": 1223.6495915549742,
            "rating_q975": 1258.6416914137112,
            "rating_q025": 1188.6574916962372
        },
        "yi-1.5-34b-chat": {
            "rating": 1218.1041448983474,
            "rating_q975": 1249.2794605689671,
            "rating_q025": 1186.9288292277276
        },
        "gemma-2-2b-it": {
            "rating": 1217.0384404036206,
            "rating_q975": 1246.0879142056926,
            "rating_q025": 1187.9889666015486
        },
        "llama-3.1-8b-instruct": {
            "rating": 1215.109105717667,
            "rating_q975": 1243.4967660702175,
            "rating_q025": 1186.7214453651166
        },
        "qwen1.5-14b-chat": {
            "rating": 1205.7079567868236,
            "rating_q975": 1243.8026215409398,
            "rating_q025": 1167.6132920327075
        },
        "gpt-3.5-turbo-1106": {
            "rating": 1203.1197790966075,
            "rating_q975": 1241.3604621767843,
            "rating_q025": 1164.8790960164308
        },
        "phi-3-medium-4k-instruct": {
            "rating": 1201.064649233755,
            "rating_q975": 1233.7722337328505,
            "rating_q025": 1168.3570647346596
        },
        "dbrx-instruct-preview": {
            "rating": 1200.6728607579853,
            "rating_q975": 1229.4999675347206,
            "rating_q025": 1171.84575398125
        },
        "openchat-3.5-0106": {
            "rating": 1196.0905278792645,
            "rating_q975": 1239.0283171878327,
            "rating_q025": 1153.1527385706963
        },
        "qwen1.5-32b-chat": {
            "rating": 1190.4612813735548,
            "rating_q975": 1224.7603688425268,
            "rating_q025": 1156.1621939045829
        },
        "gemma-1.1-7b-it": {
            "rating": 1186.25226770964,
            "rating_q975": 1217.6866490021255,
            "rating_q025": 1154.8178864171543
        },
        "vicuna-33b": {
            "rating": 1176.6980122391124,
            "rating_q975": 1213.4829064225285,
            "rating_q025": 1139.9131180556963
        },
        "starling-lm-7b-alpha": {
            "rating": 1174.9884124324035,
            "rating_q975": 1217.9609687563338,
            "rating_q025": 1132.0158561084731
        },
        "starling-lm-7b-beta": {
            "rating": 1172.5023457052298,
            "rating_q975": 1211.1922745947666,
            "rating_q025": 1133.812416815693
        },
        "yi-34b-chat": {
            "rating": 1166.2218317645766,
            "rating_q975": 1206.2122824260282,
            "rating_q025": 1126.231381103125
        },
        "llama-2-70b-chat": {
            "rating": 1164.307543379518,
            "rating_q975": 1190.776361454028,
            "rating_q025": 1137.838725305008
        },
        "phi-3-mini-4k-instruct": {
            "rating": 1161.7982465375856,
            "rating_q975": 1197.2280159900931,
            "rating_q025": 1126.368477085078
        },
        "phi-3-mini-128k-instruct": {
            "rating": 1144.541362681644,
            "rating_q975": 1179.3038667932249,
            "rating_q025": 1109.778858570063
        },
        "gemma-7b-it": {
            "rating": 1137.4775688783798,
            "rating_q975": 1183.5159238474516,
            "rating_q025": 1091.439213909308
        },
        "stripedhyena-nous-7b": {
            "rating": 1133.1022914959974,
            "rating_q975": 1181.9217117967792,
            "rating_q025": 1084.2828711952156
        },
        "vicuna-13b": {
            "rating": 1127.4748140181614,
            "rating_q975": 1172.924930385986,
            "rating_q025": 1082.0246976503367
        },
        "mistral-7b-instruct-v0.2": {
            "rating": 1127.30459604357,
            "rating_q975": 1158.577513109063,
            "rating_q025": 1096.031678978077
        },
        "llama-2-13b-chat": {
            "rating": 1121.185825013541,
            "rating_q975": 1160.0460543421661,
            "rating_q025": 1082.325595684916
        },
        "zephyr-7b-beta": {
            "rating": 1112.8321493966255,
            "rating_q975": 1161.993256214798,
            "rating_q025": 1063.671042578453
        },
        "mistral-7b-instruct": {
            "rating": 1070.1542341972895,
            "rating_q975": 1117.6717273089118,
            "rating_q025": 1022.636741085667
        },
        "llama-2-7b-chat": {
            "rating": 1049.6700119779325,
            "rating_q975": 1091.2381027935205,
            "rating_q025": 1008.1019211623445
        }
    },
    "full": {
        "gemini-3-pro": {
            "rating": 1492.0464937622653,
            "rating_q975": 1498.2338806126072,
            "rating_q025": 1485.8591069119234
        },
        "grok-4.1-thinking": {
            "rating": 1479.1793706542787,
            "rating_q975": 1485.2774593395739,
            "rating_q025": 1473.0812819689836
        },
        "gemini-3-flash": {
            "rating": 1476.7031382769967,
            "rating_q975": 1486.8384219607617,
            "rating_q025": 1466.5678545932317
        },
        "claude-opus-4-5-20251101": {
            "rating": 1468.2737259673975,
            "rating_q975": 1475.2579934621558,
            "rating_q025": 1461.2894584726391
        },
        "claude-opus-4-5-20251101-thinking-32k": {
            "rating": 1468.208625520347,
            "rating_q975": 1475.2972300280696,
            "rating_q025": 1461.1200210126242
        },
        "grok-4.1": {
            "rating": 1465.46030294056,
            "rating_q975": 1471.528108115718,
            "rating_q025": 1459.3924977654021
        },
        "gpt-5.1-high": {
            "rating": 1458.238961537425,
            "rating_q975": 1464.6339781818454,
            "rating_q025": 1451.8439448930046
        },
        "gemini-2.5-pro": {
            "rating": 1450.9709341364633,
            "rating_q975": 1454.4205609164908,
            "rating_q025": 1447.5213073564357
        },
        "claude-sonnet-4-5-20250929-thinking-32k": {
            "rating": 1449.8767907386675,
            "rating_q975": 1454.3543269506797,
            "rating_q025": 1445.3992545266553
        },
        "claude-opus-4-1-20250805-thinking-16k": {
            "rating": 1448.445275686926,
            "rating_q975": 1452.255734106768,
            "rating_q025": 1444.634817267084
        },
        "claude-sonnet-4-5-20250929": {
            "rating": 1445.4453711302708,
            "rating_q975": 1450.4841677298125,
            "rating_q025": 1440.4065745307291
        },
        "gpt-4.5-preview-2025-02-27": {
            "rating": 1443.2342731374804,
            "rating_q975": 1448.8749625538608,
            "rating_q025": 1437.5935837211
        },
        "claude-opus-4-1-20250805": {
            "rating": 1441.0801639031768,
            "rating_q975": 1444.7647104056023,
            "rating_q025": 1437.3956174007512
        },
        "chatgpt-4o-latest-20250326": {
            "rating": 1439.792990732283,
            "rating_q975": 1443.1176741600436,
            "rating_q025": 1436.4683073045223
        },
        "gpt-5.1": {
            "rating": 1437.8800773729297,
            "rating_q975": 1444.0722208083002,
            "rating_q025": 1431.6879339375591
        },
        "gpt-5-high": {
            "rating": 1436.7541925537778,
            "rating_q975": 1441.3089681729596,
            "rating_q025": 1432.199416934596
        },
        "o3-2025-04-16": {
            "rating": 1433.750508266095,
            "rating_q975": 1437.3684703042306,
            "rating_q025": 1430.1325462279594
        },
        "qwen3-max-preview": {
            "rating": 1433.2517169628154,
            "rating_q975": 1437.7947974605715,
            "rating_q025": 1428.7086364650593
        },
        "grok-4-1-fast-reasoning": {
            "rating": 1429.3951296930268,
            "rating_q975": 1436.2774142431522,
            "rating_q025": 1422.5128451429014
        },
        "ernie-5.0-preview-1103": {
            "rating": 1428.6491311248062,
            "rating_q975": 1437.485858230245,
            "rating_q025": 1419.8124040193675
        },
        "glm-4.6": {
            "rating": 1425.2516875306435,
            "rating_q975": 1429.9660654080228,
            "rating_q025": 1420.5373096532642
        },
        "kimi-k2-thinking-turbo": {
            "rating": 1425.1838175324922,
            "rating_q975": 1430.958743956461,
            "rating_q025": 1419.4088911085234
        },
        "gpt-5-chat": {
            "rating": 1425.1572385964203,
            "rating_q975": 1429.4617044542294,
            "rating_q025": 1420.852772738611
        },
        "qwen3-max-2025-09-23": {
            "rating": 1423.4962741988081,
            "rating_q975": 1429.9199926167182,
            "rating_q025": 1417.072555780898
        },
        "deepseek-v3.2-exp": {
            "rating": 1423.349146606631,
            "rating_q975": 1429.8571107015566,
            "rating_q025": 1416.8411825117053
        },
        "claude-opus-4-20250514-thinking-16k": {
            "rating": 1423.2936349572346,
            "rating_q975": 1427.624946510823,
            "rating_q025": 1418.9623234036462
        },
        "qwen3-235b-a22b-instruct-2507": {
            "rating": 1421.2087448040343,
            "rating_q975": 1424.8737929886895,
            "rating_q025": 1417.543696619379
        },
        "deepseek-v3.2-exp-thinking": {
            "rating": 1421.078731797159,
            "rating_q975": 1427.6363098632999,
            "rating_q025": 1414.521153731018
        },
        "grok-4-fast-chat": {
            "rating": 1420.0550146724888,
            "rating_q975": 1427.6349204631865,
            "rating_q025": 1412.4751088817911
        },
        "deepseek-v3.2-thinking": {
            "rating": 1419.0190913124468,
            "rating_q975": 1427.4460268901469,
            "rating_q025": 1410.5921557347467
        },
        "kimi-k2-0905-preview": {
            "rating": 1418.3911596588368,
            "rating_q975": 1424.9463848750092,
            "rating_q025": 1411.8359344426644
        },
        "deepseek-r1-0528": {
            "rating": 1417.9266643074968,
            "rating_q975": 1423.5218272641466,
            "rating_q025": 1412.331501350847
        },
        "kimi-k2-0711-preview": {
            "rating": 1417.017671843631,
            "rating_q975": 1421.8400191287537,
            "rating_q025": 1412.1953245585082
        },
        "deepseek-v3.1": {
            "rating": 1416.7721776326136,
            "rating_q975": 1422.780363741595,
            "rating_q025": 1410.7639915236323
        },
        "deepseek-v3.1-thinking": {
            "rating": 1416.2093662833663,
            "rating_q975": 1422.8052872568119,
            "rating_q025": 1409.6134453099207
        },
        "deepseek-v3.2": {
            "rating": 1415.5732761930487,
            "rating_q975": 1423.8570235983623,
            "rating_q025": 1407.2895287877352
        },
        "deepseek-v3.1-terminus": {
            "rating": 1415.2844815741828,
            "rating_q975": 1424.8791419277777,
            "rating_q025": 1405.6898212205879
        },
        "qwen3-vl-235b-a22b-instruct": {
            "rating": 1415.2450117001713,
            "rating_q975": 1421.9094619715877,
            "rating_q025": 1408.580561428755
        },
        "mistral-large-3": {
            "rating": 1414.1235494668754,
            "rating_q975": 1422.40093248313,
            "rating_q025": 1405.8461664506208
        },
        "deepseek-v3.1-terminus-thinking": {
            "rating": 1413.9270450372217,
            "rating_q975": 1423.8161408422861,
            "rating_q025": 1404.0379492321572
        },
        "claude-opus-4-20250514": {
            "rating": 1412.2123888354597,
            "rating_q975": 1416.4672897125781,
            "rating_q025": 1407.9574879583413
        },
        "gpt-4.1-2025-04-14": {
            "rating": 1412.1612949565035,
            "rating_q975": 1415.859040809016,
            "rating_q025": 1408.463549103991
        },
        "mistral-medium-2508": {
            "rating": 1410.8333469735428,
            "rating_q975": 1414.69837060615,
            "rating_q025": 1406.9683233409355
        },
        "grok-3-preview-02-24": {
            "rating": 1410.4465014225323,
            "rating_q975": 1414.6917377727507,
            "rating_q025": 1406.2012650723138
        },
        "grok-4-0709": {
            "rating": 1408.9454446797529,
            "rating_q975": 1412.8637783304202,
            "rating_q025": 1405.0271110290855
        },
        "glm-4.5": {
            "rating": 1408.7232515522655,
            "rating_q975": 1413.6018522938348,
            "rating_q025": 1403.8446508106963
        },
        "gemini-2.5-flash": {
            "rating": 1408.437267992047,
            "rating_q975": 1411.819359054571,
            "rating_q025": 1405.0551769295232
        },
        "gemini-2.5-flash-preview-09-2025": {
            "rating": 1404.8302167444688,
            "rating_q975": 1409.2056425969945,
            "rating_q025": 1400.454790891943
        },
        "grok-4-fast-reasoning": {
            "rating": 1402.4074958919512,
            "rating_q975": 1407.4748954892489,
            "rating_q025": 1397.3400962946534
        },
        "claude-haiku-4-5-20251001": {
            "rating": 1402.3509469477829,
            "rating_q975": 1406.9114472036274,
            "rating_q025": 1397.7904466919383
        },
        "o1-2024-12-17": {
            "rating": 1401.2201066023047,
            "rating_q975": 1405.5708803436057,
            "rating_q025": 1396.8693328610036
        },
        "qwen3-next-80b-a3b-instruct": {
            "rating": 1400.3326935783516,
            "rating_q975": 1405.1604386842648,
            "rating_q025": 1395.5049484724384
        },
        "longcat-flash-chat": {
            "rating": 1399.9591613261168,
            "rating_q975": 1406.3511377794027,
            "rating_q025": 1393.567184872831
        },
        "qwen3-235b-a22b-no-thinking": {
            "rating": 1399.5671101450866,
            "rating_q975": 1404.056992979033,
            "rating_q025": 1395.0772273111402
        },
        "claude-sonnet-4-20250514-thinking-32k": {
            "rating": 1399.5475964176856,
            "rating_q975": 1403.9261698795597,
            "rating_q025": 1395.1690229558114
        },
        "qwen3-235b-a22b-thinking-2507": {
            "rating": 1397.1062843430043,
            "rating_q975": 1403.556726626255,
            "rating_q025": 1390.6558420597535
        },
        "deepseek-r1": {
            "rating": 1396.1148867354368,
            "rating_q975": 1400.908757265233,
            "rating_q025": 1391.3210162056407
        },
        "qwen3-vl-235b-a22b-thinking": {
            "rating": 1393.9100940246635,
            "rating_q975": 1400.7164440048477,
            "rating_q025": 1387.1037440444793
        },
        "gpt-5-mini-high": {
            "rating": 1392.7633931466967,
            "rating_q975": 1397.44865269202,
            "rating_q025": 1388.0781336013733
        },
        "deepseek-v3-0324": {
            "rating": 1392.066317283682,
            "rating_q975": 1395.921395940932,
            "rating_q025": 1388.2112386264323
        },
        "o4-mini-2025-04-16": {
            "rating": 1391.3831883104183,
            "rating_q975": 1395.3370888430202,
            "rating_q025": 1387.4292877778164
        },
        "hunyuan-vision-1.5-thinking": {
            "rating": 1391.3024303779343,
            "rating_q975": 1403.6248900317403,
            "rating_q025": 1378.9799707241284
        },
        "mai-1-preview": {
            "rating": 1390.5098933359911,
            "rating_q975": 1395.9587555738158,
            "rating_q025": 1385.0610310981665
        },
        "claude-sonnet-4-20250514": {
            "rating": 1389.2247518524423,
            "rating_q975": 1393.5584131843948,
            "rating_q025": 1384.8910905204898
        },
        "o1-preview": {
            "rating": 1388.4313986759223,
            "rating_q975": 1393.3164469532626,
            "rating_q025": 1383.546350398582
        },
        "claude-3-7-sonnet-20250219-thinking-32k": {
            "rating": 1387.2895589009897,
            "rating_q975": 1391.4252972692977,
            "rating_q025": 1383.1538205326817
        },
        "qwen3-coder-480b-a35b-instruct": {
            "rating": 1385.5552819337424,
            "rating_q975": 1390.5342780578085,
            "rating_q025": 1380.5762858096764
        },
        "hunyuan-t1-20250711": {
            "rating": 1385.0584956764815,
            "rating_q975": 1393.607420809386,
            "rating_q025": 1376.509570543577
        },
        "mistral-medium-2505": {
            "rating": 1383.3774552379787,
            "rating_q975": 1388.044782122346,
            "rating_q025": 1378.7101283536113
        },
        "qwen3-30b-a3b-instruct-2507": {
            "rating": 1382.0082296071378,
            "rating_q975": 1386.890067332142,
            "rating_q025": 1377.1263918821335
        },
        "gpt-4.1-mini-2025-04-14": {
            "rating": 1380.8945815811746,
            "rating_q975": 1385.173222252135,
            "rating_q025": 1376.6159409102142
        },
        "hunyuan-turbos-20250416": {
            "rating": 1380.5630523985958,
            "rating_q975": 1386.886091254476,
            "rating_q025": 1374.2400135427156
        },
        "gemini-2.5-flash-lite-preview-09-2025-no-thinking": {
            "rating": 1378.7192910687081,
            "rating_q975": 1383.0688403471265,
            "rating_q025": 1374.3697417902897
        },
        "gemini-2.5-flash-lite-preview-06-17-thinking": {
            "rating": 1375.2159599376696,
            "rating_q975": 1379.7001825448685,
            "rating_q025": 1370.7317373304707
        },
        "qwen3-235b-a22b": {
            "rating": 1374.123867957691,
            "rating_q975": 1378.7947289206115,
            "rating_q025": 1369.4530069947702
        },
        "qwen2.5-max": {
            "rating": 1372.9224973453404,
            "rating_q975": 1376.9041304931961,
            "rating_q025": 1368.9408641974846
        },
        "claude-3-5-sonnet-20241022": {
            "rating": 1372.6500770323591,
            "rating_q975": 1375.719381667248,
            "rating_q025": 1369.5807723974704
        },
        "claude-3-7-sonnet-20250219": {
            "rating": 1371.3705866739979,
            "rating_q975": 1375.2447578985743,
            "rating_q025": 1367.4964154494214
        },
        "glm-4.5-air": {
            "rating": 1370.580835608843,
            "rating_q975": 1374.8452508629898,
            "rating_q025": 1366.3164203546962
        },
        "qwen3-next-80b-a3b-thinking": {
            "rating": 1367.4910667003098,
            "rating_q975": 1373.3522127545464,
            "rating_q025": 1361.6299206460733
        },
        "minimax-m1": {
            "rating": 1366.0558386483854,
            "rating_q975": 1370.2982839926412,
            "rating_q025": 1361.8133933041295
        },
        "gemma-3-27b-it": {
            "rating": 1364.7768281157023,
            "rating_q975": 1368.4163288214813,
            "rating_q025": 1361.1373274099233
        },
        "o3-mini-high": {
            "rating": 1362.9270256926252,
            "rating_q975": 1368.1002363717757,
            "rating_q025": 1357.7538150134747
        },
        "grok-3-mini-high": {
            "rating": 1362.5401012641712,
            "rating_q975": 1367.8349055775539,
            "rating_q025": 1357.2452969507885
        },
        "gemini-2.0-flash-001": {
            "rating": 1360.6203086138298,
            "rating_q975": 1364.3267710726882,
            "rating_q025": 1356.9138461549715
        },
        "deepseek-v3": {
            "rating": 1358.0578769288309,
            "rating_q975": 1362.6926449837829,
            "rating_q025": 1353.4231088738788
        },
        "grok-3-mini-beta": {
            "rating": 1356.7967093869859,
            "rating_q975": 1361.7732851442918,
            "rating_q025": 1351.82013362968
        },
        "mistral-small-2506": {
            "rating": 1354.853135670292,
            "rating_q975": 1360.031331814188,
            "rating_q025": 1349.674939526396
        },
        "gemini-2.0-flash-lite-preview-02-05": {
            "rating": 1352.9323091926094,
            "rating_q975": 1357.1519999648988,
            "rating_q025": 1348.71261842032
        },
        "gpt-oss-120b": {
            "rating": 1352.5221469611408,
            "rating_q975": 1356.9009501928308,
            "rating_q025": 1348.1433437294509
        },
        "command-a-03-2025": {
            "rating": 1352.2371976846252,
            "rating_q975": 1355.6646315367145,
            "rating_q025": 1348.809763832536
        },
        "gemini-1.5-pro-002": {
            "rating": 1352.1728909663323,
            "rating_q975": 1355.4178646065732,
            "rating_q025": 1348.9279173260913
        },
        "glm-4.5v": {
            "rating": 1351.7762639324505,
            "rating_q975": 1360.1599539254148,
            "rating_q025": 1343.3925739394863
        },
        "amazon-nova-experimental-chat-10-20": {
            "rating": 1350.9004392873167,
            "rating_q975": 1358.2434685601415,
            "rating_q025": 1343.5574100144918
        },
        "o3-mini": {
            "rating": 1348.1769949075451,
            "rating_q975": 1351.624845991392,
            "rating_q025": 1344.7291438236982
        },
        "intellect-3": {
            "rating": 1347.3768513458626,
            "rating_q975": 1359.9330312275804,
            "rating_q025": 1334.8206714641449
        },
        "hunyuan-turbos-20250226": {
            "rating": 1346.526767322468,
            "rating_q975": 1358.1746491864458,
            "rating_q025": 1334.8788854584902
        },
        "gpt-4o-2024-05-13": {
            "rating": 1346.3630830214456,
            "rating_q975": 1349.6807434127745,
            "rating_q025": 1343.0454226301167
        },
        "ling-flash-2.0": {
            "rating": 1346.0057013863918,
            "rating_q975": 1353.2334470587966,
            "rating_q025": 1338.777955713987
        },
        "minimax-m2": {
            "rating": 1345.8911053126549,
            "rating_q975": 1353.5837453220313,
            "rating_q025": 1338.1984653032785
        },
        "step-3": {
            "rating": 1345.8663887112984,
            "rating_q975": 1353.2462499906692,
            "rating_q025": 1338.4865274319277
        },
        "llama-3.1-nemotron-ultra-253b-v1": {
            "rating": 1345.7476389692692,
            "rating_q975": 1357.4196772249481,
            "rating_q025": 1334.0756007135903
        },
        "qwen-plus-0125": {
            "rating": 1345.0039942269568,
            "rating_q975": 1353.2985993018685,
            "rating_q025": 1336.709389152045
        },
        "qwen3-32b": {
            "rating": 1344.710037556465,
            "rating_q975": 1354.1784256387655,
            "rating_q025": 1335.2416494741647
        },
        "claude-3-5-sonnet-20240620": {
            "rating": 1344.0573054491374,
            "rating_q975": 1347.3927351278628,
            "rating_q025": 1340.721875770412
        },
        "glm-4-plus-0111": {
            "rating": 1343.647647742392,
            "rating_q975": 1352.003514110859,
            "rating_q025": 1335.2917813739252
        },
        "amazon-nova-experimental-chat-10-09": {
            "rating": 1341.1120207085328,
            "rating_q975": 1347.657607383807,
            "rating_q025": 1334.5664340332585
        },
        "gemma-3-12b-it": {
            "rating": 1340.5577316038248,
            "rating_q975": 1350.0386577820252,
            "rating_q025": 1331.0768054256243
        },
        "nvidia-llama-3.3-nemotron-super-49b-v1.5": {
            "rating": 1340.2210210798326,
            "rating_q975": 1350.00275436158,
            "rating_q025": 1330.4392877980852
        },
        "gpt-5-nano-high": {
            "rating": 1339.0393516488625,
            "rating_q975": 1345.938073720917,
            "rating_q025": 1332.1406295768081
        },
        "hunyuan-turbo-0110": {
            "rating": 1339.0342622583971,
            "rating_q975": 1350.4949518535307,
            "rating_q025": 1327.5735726632636
        },
        "o1-mini": {
            "rating": 1336.3717307402235,
            "rating_q975": 1339.8884608029778,
            "rating_q025": 1332.8550006774692
        },
        "llama-3.1-405b-instruct-bf16": {
            "rating": 1336.1824774987435,
            "rating_q975": 1339.765223306086,
            "rating_q025": 1332.599731691401
        },
        "gpt-4o-2024-08-06": {
            "rating": 1335.7637246399254,
            "rating_q975": 1339.8480613261672,
            "rating_q025": 1331.6793879536835
        },
        "gemini-advanced-0514": {
            "rating": 1335.6854329383993,
            "rating_q975": 1340.7791801560772,
            "rating_q025": 1330.5916857207214
        },
        "grok-2-2024-08-13": {
            "rating": 1335.1654597549373,
            "rating_q975": 1338.715693122362,
            "rating_q025": 1331.6152263875126
        },
        "llama-3.1-405b-instruct-fp8": {
            "rating": 1334.8389134581166,
            "rating_q975": 1338.2921035588336,
            "rating_q025": 1331.3857233573997
        },
        "nova-2-lite": {
            "rating": 1334.5048008994113,
            "rating_q975": 1343.1035350288078,
            "rating_q025": 1325.9060667700148
        },
        "qwq-32b": {
            "rating": 1333.915673909224,
            "rating_q975": 1338.2929696048573,
            "rating_q025": 1329.538378213591
        },
        "step-2-16k-exp-202412": {
            "rating": 1333.1517595435075,
            "rating_q975": 1341.6560320483134,
            "rating_q025": 1324.6474870387017
        },
        "yi-lightning": {
            "rating": 1329.2954398814795,
            "rating_q975": 1334.129080099639,
            "rating_q025": 1324.46179966332
        },
        "llama-4-maverick-17b-128e-instruct": {
            "rating": 1327.584570305676,
            "rating_q975": 1331.800690065802,
            "rating_q025": 1323.3684505455499
        },
        "qwen3-30b-a3b": {
            "rating": 1326.117355526203,
            "rating_q975": 1330.8042917178007,
            "rating_q025": 1321.4304193346054
        },
        "llama-3.3-nemotron-49b-super-v1": {
            "rating": 1325.8625731591428,
            "rating_q975": 1337.9321545247974,
            "rating_q025": 1313.7929917934882
        },
        "gpt-4-turbo-2024-04-09": {
            "rating": 1325.4422507818686,
            "rating_q975": 1329.2449815725913,
            "rating_q025": 1321.6395199911458
        },
        "hunyuan-large-2025-02-10": {
            "rating": 1325.2724118714082,
            "rating_q975": 1334.974348017765,
            "rating_q025": 1315.5704757250514
        },
        "gemini-1.5-pro-001": {
            "rating": 1323.706954959447,
            "rating_q975": 1327.5756318571393,
            "rating_q025": 1319.8382780617549
        },
        "claude-3-opus-20240229": {
            "rating": 1323.678769469263,
            "rating_q975": 1326.616001038146,
            "rating_q025": 1320.74153790038
        },
        "deepseek-v2.5-1210": {
            "rating": 1323.1212059142363,
            "rating_q975": 1331.3162091921365,
            "rating_q025": 1314.926202636336
        },
        "claude-3-5-haiku-20241022": {
            "rating": 1323.09577397075,
            "rating_q975": 1326.2604991126257,
            "rating_q025": 1319.9310488288745
        },
        "llama-4-scout-17b-16e-instruct": {
            "rating": 1322.4921053780965,
            "rating_q975": 1327.166217646381,
            "rating_q025": 1317.817993109812
        },
        "gpt-4.1-nano-2025-04-14": {
            "rating": 1320.7972632717576,
            "rating_q975": 1328.5133350787985,
            "rating_q025": 1313.0811914647168
        },
        "ring-flash-2.0": {
            "rating": 1319.7076716409647,
            "rating_q975": 1326.9032910974213,
            "rating_q025": 1312.512052184508
        },
        "llama-3.3-70b-instruct": {
            "rating": 1319.7045117997386,
            "rating_q975": 1323.0645386629142,
            "rating_q025": 1316.344484936563
        },
        "step-1o-turbo-202506": {
            "rating": 1319.6188438678055,
            "rating_q975": 1326.2420329042511,
            "rating_q025": 1312.9956548313598
        },
        "glm-4-plus": {
            "rating": 1319.4910065068518,
            "rating_q975": 1324.3186151678378,
            "rating_q025": 1314.6633978458658
        },
        "gemma-3n-e4b-it": {
            "rating": 1318.5344832628045,
            "rating_q975": 1323.633088587972,
            "rating_q025": 1313.435877937637
        },
        "qwen-max-0919": {
            "rating": 1318.4878049712859,
            "rating_q975": 1324.0924317359613,
            "rating_q025": 1312.8831782066104
        },
        "gpt-oss-20b": {
            "rating": 1318.0653189132352,
            "rating_q975": 1324.4107542618285,
            "rating_q025": 1311.7198835646418
        },
        "gpt-4o-mini-2024-07-18": {
            "rating": 1317.2602804767942,
            "rating_q975": 1320.642901036211,
            "rating_q025": 1313.8776599173773
        },
        "gpt-4-1106-preview": {
            "rating": 1315.349391464195,
            "rating_q975": 1319.12442786404,
            "rating_q025": 1311.57435506435
        },
        "gpt-4-0125-preview": {
            "rating": 1315.1834079085115,
            "rating_q975": 1319.1536151286193,
            "rating_q025": 1311.2132006884037
        },
        "mistral-large-2407": {
            "rating": 1314.8534282898972,
            "rating_q975": 1318.648541986752,
            "rating_q025": 1311.0583145930425
        },
        "qwen2.5-plus-1127": {
            "rating": 1314.7811325686525,
            "rating_q975": 1321.0539463054738,
            "rating_q025": 1308.5083188318313
        },
        "athene-v2-chat": {
            "rating": 1314.045881551262,
            "rating_q975": 1318.4977735945356,
            "rating_q025": 1309.5939895079885
        },
        "gemini-1.5-flash-002": {
            "rating": 1311.1724393237466,
            "rating_q975": 1315.2688951300438,
            "rating_q025": 1307.0759835174495
        },
        "mercury": {
            "rating": 1310.9815151896846,
            "rating_q975": 1324.7016393876809,
            "rating_q025": 1297.2613909916884
        },
        "hunyuan-standard-2025-02-10": {
            "rating": 1310.6244334971689,
            "rating_q975": 1320.2828730949846,
            "rating_q025": 1300.9659938993532
        },
        "olmo-3-32b-think": {
            "rating": 1308.1883290225621,
            "rating_q975": 1318.7394237399412,
            "rating_q025": 1297.637234305183
        },
        "grok-2-mini-2024-08-13": {
            "rating": 1308.119239721922,
            "rating_q975": 1311.709107353126,
            "rating_q025": 1304.529372090718
        },
        "deepseek-v2.5": {
            "rating": 1307.3572409117373,
            "rating_q975": 1311.9574950396286,
            "rating_q025": 1302.756986783846
        },
        "athene-70b-0725": {
            "rating": 1306.2335920261928,
            "rating_q975": 1311.8220683733,
            "rating_q025": 1300.6451156790856
        },
        "mistral-large-2411": {
            "rating": 1305.2415779304679,
            "rating_q975": 1309.5582313016048,
            "rating_q025": 1300.924924559331
        },
        "magistral-medium-2506": {
            "rating": 1305.0297298412333,
            "rating_q975": 1311.3934630145673,
            "rating_q025": 1298.6659966678994
        },
        "mistral-small-3.1-24b-instruct-2503": {
            "rating": 1303.2876614283414,
            "rating_q975": 1307.762729908852,
            "rating_q025": 1298.8125929478308
        },
        "gemma-3-4b-it": {
            "rating": 1302.8478994470552,
            "rating_q975": 1312.1565300746404,
            "rating_q025": 1293.53926881947
        },
        "qwen2.5-72b-instruct": {
            "rating": 1302.806672574078,
            "rating_q975": 1306.7585013854289,
            "rating_q025": 1298.8548437627271
        },
        "llama-3.1-nemotron-70b-instruct": {
            "rating": 1298.5607442190994,
            "rating_q975": 1306.273482210381,
            "rating_q025": 1290.848006227818
        },
        "hunyuan-large-vision": {
            "rating": 1295.0369057511339,
            "rating_q975": 1304.0543029859443,
            "rating_q025": 1286.0195085163234
        },
        "llama-3.1-70b-instruct": {
            "rating": 1294.2589307821595,
            "rating_q975": 1297.842811906826,
            "rating_q025": 1290.675049657493
        },
        "jamba-1.5-large": {
            "rating": 1289.8449055943092,
            "rating_q975": 1297.093822156828,
            "rating_q025": 1282.5959890317904
        },
        "gpt-4-0314": {
            "rating": 1289.5453318595987,
            "rating_q975": 1294.262968727862,
            "rating_q025": 1284.8276949913354
        },
        "amazon-nova-pro-v1.0": {
            "rating": 1288.765934053242,
            "rating_q975": 1293.2092548802427,
            "rating_q025": 1284.3226132262414
        },
        "reka-core-20240904": {
            "rating": 1288.5323388820202,
            "rating_q975": 1295.6165253852625,
            "rating_q025": 1281.4481523787779
        },
        "gemma-2-27b-it": {
            "rating": 1288.3131304447638,
            "rating_q975": 1291.5520445066668,
            "rating_q025": 1285.0742163828609
        },
        "llama-3.1-nemotron-51b-instruct": {
            "rating": 1287.3865034495916,
            "rating_q975": 1297.293593248662,
            "rating_q025": 1277.479413650521
        },
        "llama-3.1-tulu-3-70b": {
            "rating": 1286.7553522452126,
            "rating_q975": 1297.1485840685511,
            "rating_q025": 1276.3621204218741
        },
        "gemini-1.5-flash-001": {
            "rating": 1286.0135737165813,
            "rating_q975": 1290.4095867005076,
            "rating_q025": 1281.617560732655
        },
        "claude-3-sonnet-20240229": {
            "rating": 1283.3340194399739,
            "rating_q975": 1287.2446831083726,
            "rating_q025": 1279.4233557715752
        },
        "gemma-2-9b-it-simpo": {
            "rating": 1280.1317062273913,
            "rating_q975": 1286.9420706542035,
            "rating_q025": 1273.3213418005791
        },
        "nemotron-4-340b-instruct": {
            "rating": 1279.5933505802711,
            "rating_q975": 1284.8285974607988,
            "rating_q025": 1274.3581036997434
        },
        "command-r-plus-08-2024": {
            "rating": 1278.5146345214087,
            "rating_q975": 1285.0195037821618,
            "rating_q025": 1272.0097652606555
        },
        "llama-3-70b-instruct": {
            "rating": 1277.7291476708774,
            "rating_q975": 1281.2051935560803,
            "rating_q025": 1274.2531017856745
        },
        "gpt-4-0613": {
            "rating": 1277.4557321188229,
            "rating_q975": 1281.4416587730864,
            "rating_q025": 1273.4698054645594
        },
        "glm-4-0520": {
            "rating": 1274.9553078936724,
            "rating_q975": 1281.8840748352552,
            "rating_q025": 1268.0265409520896
        },
        "reka-flash-20240904": {
            "rating": 1274.0144159808574,
            "rating_q975": 1280.9449182109272,
            "rating_q025": 1267.0839137507876
        },
        "mistral-small-24b-instruct-2501": {
            "rating": 1273.9412022821293,
            "rating_q975": 1279.7617172459736,
            "rating_q025": 1268.120687318285
        },
        "qwen2.5-coder-32b-instruct": {
            "rating": 1270.465637048575,
            "rating_q975": 1278.5337141842701,
            "rating_q025": 1262.3975599128798
        },
        "c4ai-aya-expanse-32b": {
            "rating": 1267.5434846586177,
            "rating_q975": 1272.321380448778,
            "rating_q025": 1262.7655888684574
        },
        "gemma-2-9b-it": {
            "rating": 1265.6595925598676,
            "rating_q975": 1269.3505959994782,
            "rating_q025": 1261.968589120257
        },
        "deepseek-coder-v2": {
            "rating": 1265.5616642327361,
            "rating_q975": 1271.775983481861,
            "rating_q025": 1259.3473449836113
        },
        "command-r-plus": {
            "rating": 1264.9419160281293,
            "rating_q975": 1269.1845672695515,
            "rating_q025": 1260.699264786707
        },
        "qwen2-72b-instruct": {
            "rating": 1263.5102334026014,
            "rating_q975": 1268.3704401529658,
            "rating_q025": 1258.650026652237
        },
        "claude-3-haiku-20240307": {
            "rating": 1263.2452108674197,
            "rating_q975": 1266.9006443661306,
            "rating_q025": 1259.5897773687088
        },
        "gemini-1.5-flash-8b-001": {
            "rating": 1260.3726841081618,
            "rating_q975": 1264.544035839388,
            "rating_q025": 1256.2013323769356
        },
        "amazon-nova-lite-v1.0": {
            "rating": 1260.2975643885843,
            "rating_q975": 1265.3399498131246,
            "rating_q025": 1255.255178964044
        },
        "phi-4": {
            "rating": 1255.8774406332807,
            "rating_q975": 1260.3680827492697,
            "rating_q025": 1251.3867985172917
        },
        "command-r-08-2024": {
            "rating": 1252.8835106712909,
            "rating_q975": 1259.4071031565527,
            "rating_q025": 1246.359918186029
        },
        "olmo-2-0325-32b-instruct": {
            "rating": 1252.7221858223365,
            "rating_q975": 1263.4371765457804,
            "rating_q025": 1242.0071950988927
        },
        "mistral-large-2402": {
            "rating": 1244.3220994279627,
            "rating_q975": 1248.9678204134896,
            "rating_q025": 1239.6763784424359
        },
        "amazon-nova-micro-v1.0": {
            "rating": 1241.9471718937662,
            "rating_q975": 1246.9570247180104,
            "rating_q025": 1236.937319069522
        },
        "jamba-1.5-mini": {
            "rating": 1240.4354246750895,
            "rating_q975": 1247.5891441677693,
            "rating_q025": 1233.2817051824097
        },
        "ministral-8b-2410": {
            "rating": 1238.0406351641054,
            "rating_q975": 1247.05196044639,
            "rating_q025": 1229.0293098818208
        },
        "gemini-pro-dev-api": {
            "rating": 1236.8689268992282,
            "rating_q975": 1244.145919708434,
            "rating_q025": 1229.5919340900225
        },
        "qwen1.5-110b-chat": {
            "rating": 1236.528508912691,
            "rating_q975": 1241.9705837735921,
            "rating_q025": 1231.0864340517899
        },
        "qwen1.5-72b-chat": {
            "rating": 1236.0624372835553,
            "rating_q975": 1241.2679269176376,
            "rating_q025": 1230.8569476494729
        },
        "reka-flash-21b-20240226-online": {
            "rating": 1235.7409890229956,
            "rating_q975": 1243.081649367311,
            "rating_q025": 1228.4003286786801
        },
        "hunyuan-standard-256k": {
            "rating": 1234.3973499887775,
            "rating_q975": 1246.0687595274721,
            "rating_q025": 1222.7259404500828
        },
        "mixtral-8x22b-instruct-v0.1": {
            "rating": 1231.7057497322996,
            "rating_q975": 1236.167126515491,
            "rating_q025": 1227.2443729491083
        },
        "command-r": {
            "rating": 1230.144996193349,
            "rating_q975": 1234.8496258587934,
            "rating_q025": 1225.4403665279046
        },
        "reka-flash-21b-20240226": {
            "rating": 1228.965599910574,
            "rating_q975": 1234.8487764963688,
            "rating_q025": 1223.082423324779
        },
        "gpt-3.5-turbo-0125": {
            "rating": 1226.662924135505,
            "rating_q975": 1231.282345658236,
            "rating_q025": 1222.0435026127739
        },
        "mistral-medium": {
            "rating": 1226.0012332900606,
            "rating_q975": 1231.4233780355503,
            "rating_q025": 1220.5790885445708
        },
        "llama-3-8b-instruct": {
            "rating": 1225.2153649447212,
            "rating_q975": 1228.8430252500032,
            "rating_q025": 1221.5877046394392
        },
        "gemini-pro": {
            "rating": 1224.3785006399435,
            "rating_q975": 1236.1101550163478,
            "rating_q025": 1212.6468462635391
        },
        "c4ai-aya-expanse-8b": {
            "rating": 1224.262618203259,
            "rating_q975": 1231.1349890503955,
            "rating_q025": 1217.3902473561227
        },
        "llama-3.1-tulu-3-8b": {
            "rating": 1222.5583612025318,
            "rating_q975": 1233.1371288448402,
            "rating_q025": 1211.9795935602235
        },
        "zephyr-orpo-141b-A35b-v0.1": {
            "rating": 1216.0449808916676,
            "rating_q975": 1226.772998711964,
            "rating_q025": 1205.3169630713712
        },
        "yi-1.5-34b-chat": {
            "rating": 1215.4515538451135,
            "rating_q975": 1220.4041711169132,
            "rating_q025": 1210.4989365733138
        },
        "llama-3.1-8b-instruct": {
            "rating": 1212.4162281114582,
            "rating_q975": 1216.4231763313933,
            "rating_q025": 1208.409279891523
        },
        "granite-3.1-8b-instruct": {
            "rating": 1210.899671693192,
            "rating_q975": 1221.8435747999345,
            "rating_q025": 1199.9557685864495
        },
        "qwen1.5-32b-chat": {
            "rating": 1207.6458223773757,
            "rating_q975": 1213.6916565193706,
            "rating_q025": 1201.5999882353808
        },
        "gpt-3.5-turbo-1106": {
            "rating": 1204.7185510059073,
            "rating_q975": 1213.4386318231473,
            "rating_q025": 1195.9984701886674
        },
        "phi-3-medium-4k-instruct": {
            "rating": 1200.2978801822505,
            "rating_q975": 1205.3712334398685,
            "rating_q025": 1195.2245269246325
        },
        "mixtral-8x7b-instruct-v0.1": {
            "rating": 1200.178592823156,
            "rating_q975": 1204.3699757542797,
            "rating_q025": 1195.987209892032
        },
        "gemma-2-2b-it": {
            "rating": 1199.1487138182915,
            "rating_q975": 1203.1255263528617,
            "rating_q025": 1195.1719012837214
        },
        "dbrx-instruct-preview": {
            "rating": 1198.1200625619902,
            "rating_q975": 1204.1407027712653,
            "rating_q025": 1192.099422352715
        },
        "qwen1.5-14b-chat": {
            "rating": 1195.1334808438946,
            "rating_q975": 1202.1795940359127,
            "rating_q025": 1188.0873676518765
        },
        "internlm2_5-20b-chat": {
            "rating": 1193.674132385321,
            "rating_q975": 1200.7783982925353,
            "rating_q025": 1186.5698664781066
        },
        "wizardlm-70b": {
            "rating": 1187.9732512599994,
            "rating_q975": 1197.39442218143,
            "rating_q025": 1178.5520803385689
        },
        "deepseek-llm-67b-chat": {
            "rating": 1186.883657457529,
            "rating_q975": 1198.3812432269012,
            "rating_q025": 1175.3860716881566
        },
        "yi-34b-chat": {
            "rating": 1186.5093916855162,
            "rating_q975": 1193.274819589985,
            "rating_q025": 1179.7439637810473
        },
        "openchat-3.5-0106": {
            "rating": 1185.365483971731,
            "rating_q975": 1193.3265363104438,
            "rating_q025": 1177.4044316330182
        },
        "granite-3.0-8b-instruct": {
            "rating": 1185.0772846942555,
            "rating_q975": 1193.6749219602966,
            "rating_q025": 1176.4796474282143
        },
        "openchat-3.5": {
            "rating": 1185.0609502150855,
            "rating_q975": 1194.7108056184172,
            "rating_q025": 1175.4110948117539
        },
        "snowflake-arctic-instruct": {
            "rating": 1182.6535443907749,
            "rating_q975": 1188.4994814828465,
            "rating_q025": 1176.8076072987033
        },
        "gemma-1.1-7b-it": {
            "rating": 1182.0449526238726,
            "rating_q975": 1188.0363128507258,
            "rating_q025": 1176.0535923970194
        },
        "tulu-2-dpo-70b": {
            "rating": 1181.7361307892734,
            "rating_q975": 1191.516895895762,
            "rating_q025": 1171.9553656827848
        },
        "granite-3.1-2b-instruct": {
            "rating": 1181.6356415317346,
            "rating_q975": 1192.7102566853953,
            "rating_q025": 1170.5610263780738
        },
        "openhermes-2.5-mistral-7b": {
            "rating": 1178.99758150664,
            "rating_q975": 1189.4015666337623,
            "rating_q025": 1168.5935963795177
        },
        "vicuna-33b": {
            "rating": 1176.332572191995,
            "rating_q975": 1182.4891010435633,
            "rating_q025": 1170.1760433404268
        },
        "starling-lm-7b-beta": {
            "rating": 1175.1042567638494,
            "rating_q975": 1182.4658142133067,
            "rating_q025": 1167.7426993143922
        },
        "phi-3-small-8k-instruct": {
            "rating": 1174.2006466920034,
            "rating_q975": 1180.0421481691599,
            "rating_q025": 1168.3591452148469
        },
        "llama-2-70b-chat": {
            "rating": 1174.0916318728673,
            "rating_q975": 1179.5378576557878,
            "rating_q025": 1168.6454060899468
        },
        "starling-lm-7b-alpha": {
            "rating": 1170.8925492177054,
            "rating_q975": 1178.9310521671543,
            "rating_q025": 1162.8540462682565
        },
        "nous-hermes-2-mixtral-8x7b-dpo": {
            "rating": 1168.5780967588948,
            "rating_q975": 1180.4732092524744,
            "rating_q025": 1156.6829842653153
        },
        "llama-3.2-3b-instruct": {
            "rating": 1168.446116899117,
            "rating_q975": 1176.0554889169928,
            "rating_q025": 1160.8367448812412
        },
        "qwq-32b-preview": {
            "rating": 1160.2070526787595,
            "rating_q975": 1171.679648714797,
            "rating_q025": 1148.734456642722
        },
        "llama2-70b-steerlm-chat": {
            "rating": 1159.5623859334526,
            "rating_q975": 1172.165219490425,
            "rating_q025": 1146.9595523764801
        },
        "granite-3.0-2b-instruct": {
            "rating": 1158.2010096732783,
            "rating_q975": 1166.5125161276696,
            "rating_q025": 1149.889503218887
        },
        "solar-10.7b-instruct-v1.0": {
            "rating": 1156.6723286406013,
            "rating_q975": 1169.861912248563,
            "rating_q025": 1143.4827450326397
        },
        "mpt-30b-chat": {
            "rating": 1154.8789168428762,
            "rating_q975": 1167.0673111917877,
            "rating_q025": 1142.6905224939646
        },
        "dolphin-2.2.1-mistral-7b": {
            "rating": 1154.7645093232263,
            "rating_q975": 1170.1814353720065,
            "rating_q025": 1139.3475832744462
        },
        "wizardlm-13b": {
            "rating": 1153.6060801019712,
            "rating_q975": 1162.834055825117,
            "rating_q025": 1144.3781043788254
        },
        "mistral-7b-instruct-v0.2": {
            "rating": 1153.1795706635164,
            "rating_q975": 1159.769159952023,
            "rating_q025": 1146.5899813750098
        },
        "falcon-180b-chat": {
            "rating": 1150.4496558558635,
            "rating_q975": 1167.5444636234688,
            "rating_q025": 1133.3548480882582
        },
        "qwen1.5-7b-chat": {
            "rating": 1146.5041986106808,
            "rating_q975": 1156.3336619698698,
            "rating_q025": 1136.6747352514917
        },
        "llama-2-13b-chat": {
            "rating": 1145.242045347896,
            "rating_q975": 1151.8983924228312,
            "rating_q025": 1138.5856982729608
        },
        "phi-3-mini-4k-instruct-june-2024": {
            "rating": 1145.0394134051933,
            "rating_q975": 1151.399349446676,
            "rating_q025": 1138.6794773637105
        },
        "vicuna-13b": {
            "rating": 1144.8116152696462,
            "rating_q975": 1151.4678273187533,
            "rating_q025": 1138.155403220539
        },
        "qwen-14b-chat": {
            "rating": 1142.0374248068551,
            "rating_q975": 1152.9601745867417,
            "rating_q025": 1131.1146750269686
        },
        "palm-2": {
            "rating": 1140.4697280027208,
            "rating_q975": 1149.8195521968657,
            "rating_q025": 1131.1199038085758
        },
        "codellama-34b-instruct": {
            "rating": 1139.8401944157058,
            "rating_q975": 1148.6900002641878,
            "rating_q025": 1130.9903885672238
        },
        "gemma-7b-it": {
            "rating": 1137.4848939550009,
            "rating_q975": 1146.9464955074534,
            "rating_q025": 1128.0232924025483
        },
        "zephyr-7b-beta": {
            "rating": 1134.632304449648,
            "rating_q975": 1143.438615614205,
            "rating_q025": 1125.825993285091
        },
        "phi-3-mini-128k-instruct": {
            "rating": 1133.7254072090714,
            "rating_q975": 1141.041622991556,
            "rating_q025": 1126.4091914265866
        },
        "guanaco-33b": {
            "rating": 1132.0733769080814,
            "rating_q975": 1144.1617256807992,
            "rating_q025": 1119.9850281353636
        },
        "zephyr-7b-alpha": {
            "rating": 1131.6302331301513,
            "rating_q975": 1147.2934542445548,
            "rating_q025": 1115.9670120157477
        },
        "phi-3-mini-4k-instruct": {
            "rating": 1131.446376918452,
            "rating_q975": 1137.721663954661,
            "rating_q025": 1125.171089882243
        },
        "stripedhyena-nous-7b": {
            "rating": 1123.783958352977,
            "rating_q975": 1134.773088158158,
            "rating_q025": 1112.7948285477958
        },
        "codellama-70b-instruct": {
            "rating": 1121.659865573466,
            "rating_q975": 1139.8420878231354,
            "rating_q025": 1103.4776433237967
        },
        "smollm2-1.7b-instruct": {
            "rating": 1120.9123301128188,
            "rating_q975": 1135.1003729273662,
            "rating_q025": 1106.7242872982715
        },
        "vicuna-7b": {
            "rating": 1118.8872443509576,
            "rating_q975": 1128.0398757554576,
            "rating_q025": 1109.7346129464577
        },
        "gemma-1.1-2b-it": {
            "rating": 1116.2484562090867,
            "rating_q975": 1123.8915850100152,
            "rating_q025": 1108.6053274081582
        },
        "llama-3.2-1b-instruct": {
            "rating": 1114.6037652167824,
            "rating_q975": 1122.3704581199222,
            "rating_q025": 1106.8370723136427
        },
        "mistral-7b-instruct": {
            "rating": 1113.4689773803666,
            "rating_q975": 1122.7325263581486,
            "rating_q025": 1104.2054284025846
        },
        "llama-2-7b-chat": {
            "rating": 1111.546537139862,
            "rating_q975": 1118.5496790652928,
            "rating_q025": 1104.5433952144313
        },
        "qwen1.5-4b-chat": {
            "rating": 1093.751573285132,
            "rating_q975": 1103.0549389454563,
            "rating_q025": 1084.4482076248078
        },
        "gemma-2b-it": {
            "rating": 1093.7308010675345,
            "rating_q975": 1105.2437003047874,
            "rating_q025": 1082.2179018302816
        },
        "olmo-7b-instruct": {
            "rating": 1077.200278496421,
            "rating_q975": 1088.3575560086651,
            "rating_q025": 1066.043000984177
        },
        "koala-13b": {
            "rating": 1074.9529378995578,
            "rating_q975": 1084.876822521276,
            "rating_q025": 1065.0290532778397
        },
        "alpaca-13b": {
            "rating": 1070.971703732457,
            "rating_q975": 1082.446843394289,
            "rating_q025": 1059.4965640706248
        },
        "gpt4all-13b-snoozy": {
            "rating": 1069.9540324796276,
            "rating_q975": 1085.1489782243846,
            "rating_q025": 1054.7590867348706
        },
        "mpt-7b-chat": {
            "rating": 1066.1271735738626,
            "rating_q975": 1078.1008308531152,
            "rating_q025": 1054.15351629461
        },
        "chatglm3-6b": {
            "rating": 1059.882395583591,
            "rating_q975": 1071.524452929207,
            "rating_q025": 1048.240338237975
        },
        "RWKV-4-Raven-14B": {
            "rating": 1046.2603359904408,
            "rating_q975": 1057.680775065233,
            "rating_q025": 1034.8398969156485
        },
        "chatglm2-6b": {
            "rating": 1029.0194125193807,
            "rating_q975": 1042.571572537248,
            "rating_q025": 1015.4672525015134
        },
        "oasst-pythia-12b": {
            "rating": 1026.6826677119948,
            "rating_q975": 1037.6024599449424,
            "rating_q025": 1015.762875479047
        },
        "chatglm-6b": {
            "rating": 1000.3446591916622,
            "rating_q975": 1012.9186316808332,
            "rating_q025": 987.7706867024913
        },
        "fastchat-t5-3b": {
            "rating": 995.9659538530773,
            "rating_q975": 1008.3288800610667,
            "rating_q025": 983.6030276450879
        },
        "dolly-v2-12b": {
            "rating": 983.846723425205,
            "rating_q975": 997.4384530180515,
            "rating_q025": 970.2549938323585
        },
        "llama-13b": {
            "rating": 975.4133222885978,
            "rating_q975": 991.2575069257342,
            "rating_q025": 959.5691376514613
        },
        "stablelm-tuned-alpha-7b": {
            "rating": 957.2159660341024,
            "rating_q975": 970.0323436200637,
            "rating_q025": 944.3995884481411
        }
    },
    "german": {
        "gemini-3-pro": {
            "rating": 1522.3970458287026,
            "rating_q975": 1555.5955357505484,
            "rating_q025": 1489.1985559068569
        },
        "gpt-4.5-preview-2025-02-27": {
            "rating": 1470.1071156834623,
            "rating_q975": 1502.2754183436757,
            "rating_q025": 1437.938813023249
        },
        "claude-opus-4-5-20251101": {
            "rating": 1465.6813673696686,
            "rating_q975": 1505.888839958484,
            "rating_q025": 1425.4738947808532
        },
        "gemini-2.5-pro": {
            "rating": 1463.3835671410652,
            "rating_q975": 1479.7454084094709,
            "rating_q025": 1447.0217258726595
        },
        "claude-opus-4-5-20251101-thinking-32k": {
            "rating": 1458.6179126939414,
            "rating_q975": 1498.3750409043084,
            "rating_q025": 1418.8607844835744
        },
        "grok-4.1": {
            "rating": 1457.7725564042535,
            "rating_q975": 1490.0649921862262,
            "rating_q025": 1425.4801206222808
        },
        "grok-4.1-thinking": {
            "rating": 1457.2339134405688,
            "rating_q975": 1490.7735531336755,
            "rating_q025": 1423.6942737474621
        },
        "claude-opus-4-1-20250805-thinking-16k": {
            "rating": 1455.122768973749,
            "rating_q975": 1476.127544977154,
            "rating_q025": 1434.1179929703442
        },
        "gpt-5.1-high": {
            "rating": 1450.2049460808605,
            "rating_q975": 1486.644330927001,
            "rating_q025": 1413.76556123472
        },
        "gpt-5.1": {
            "rating": 1449.0634188095562,
            "rating_q975": 1484.6427938082422,
            "rating_q025": 1413.4840438108702
        },
        "claude-sonnet-4-5-20250929": {
            "rating": 1444.5956810247606,
            "rating_q975": 1474.0864865638016,
            "rating_q025": 1415.1048754857195
        },
        "gpt-5-high": {
            "rating": 1443.8606451927535,
            "rating_q975": 1467.6483129068074,
            "rating_q025": 1420.0729774786996
        },
        "claude-sonnet-4-5-20250929-thinking-32k": {
            "rating": 1440.4733075336865,
            "rating_q975": 1467.1109613819406,
            "rating_q025": 1413.8356536854324
        },
        "qwen3-max-preview": {
            "rating": 1439.4256300216937,
            "rating_q975": 1465.8828604782875,
            "rating_q025": 1412.9683995650998
        },
        "claude-opus-4-20250514-thinking-16k": {
            "rating": 1435.7587641641096,
            "rating_q975": 1456.09485730715,
            "rating_q025": 1415.4226710210692
        },
        "o3-2025-04-16": {
            "rating": 1435.3488294369827,
            "rating_q975": 1452.0653506969547,
            "rating_q025": 1418.6323081770106
        },
        "claude-opus-4-1-20250805": {
            "rating": 1430.579256611209,
            "rating_q975": 1449.34088249448,
            "rating_q025": 1411.8176307279382
        },
        "glm-4.6": {
            "rating": 1428.340564748494,
            "rating_q975": 1457.4773516567861,
            "rating_q025": 1399.2037778402018
        },
        "kimi-k2-0905-preview": {
            "rating": 1427.0569897789553,
            "rating_q975": 1463.632486137002,
            "rating_q025": 1390.4814934209087
        },
        "deepseek-v3.2-exp": {
            "rating": 1425.363201398163,
            "rating_q975": 1464.53000040389,
            "rating_q025": 1386.196402392436
        },
        "qwen3-max-2025-09-23": {
            "rating": 1425.257486818287,
            "rating_q975": 1466.213561894691,
            "rating_q025": 1384.3014117418827
        },
        "claude-opus-4-20250514": {
            "rating": 1425.2571973774373,
            "rating_q975": 1442.9797438392782,
            "rating_q025": 1407.5346509155963
        },
        "deepseek-v3.2-exp-thinking": {
            "rating": 1424.0798295704421,
            "rating_q975": 1468.406941083722,
            "rating_q025": 1379.7527180571624
        },
        "chatgpt-4o-latest-20250326": {
            "rating": 1422.9939429539706,
            "rating_q975": 1440.1643486230757,
            "rating_q025": 1405.8235372848656
        },
        "gpt-5-chat": {
            "rating": 1420.8759328722188,
            "rating_q975": 1445.1013887470801,
            "rating_q025": 1396.6504769973574
        },
        "qwen3-vl-235b-a22b-thinking": {
            "rating": 1414.869953241289,
            "rating_q975": 1460.6634581879969,
            "rating_q025": 1369.0764482945813
        },
        "deepseek-v3.2-thinking": {
            "rating": 1414.166315778193,
            "rating_q975": 1462.507430382515,
            "rating_q025": 1365.825201173871
        },
        "qwen3-235b-a22b-instruct-2507": {
            "rating": 1411.5874162546518,
            "rating_q975": 1431.229684674792,
            "rating_q025": 1391.9451478345115
        },
        "kimi-k2-0711-preview": {
            "rating": 1411.343324458155,
            "rating_q975": 1434.8312166783935,
            "rating_q025": 1387.8554322379164
        },
        "grok-4-0709": {
            "rating": 1409.4508944801958,
            "rating_q975": 1430.7261147701906,
            "rating_q025": 1388.1756741902009
        },
        "gemini-2.5-flash-preview-09-2025": {
            "rating": 1406.062687095073,
            "rating_q975": 1432.7969788287617,
            "rating_q025": 1379.3283953613843
        },
        "kimi-k2-thinking-turbo": {
            "rating": 1404.8396203393556,
            "rating_q975": 1439.0030094171047,
            "rating_q025": 1370.6762312616065
        },
        "grok-3-preview-02-24": {
            "rating": 1403.7056468448245,
            "rating_q975": 1425.246579055155,
            "rating_q025": 1382.164714634494
        },
        "gemini-2.5-flash": {
            "rating": 1402.3985447542034,
            "rating_q975": 1417.7353614306107,
            "rating_q025": 1387.061728077796
        },
        "deepseek-v3.1": {
            "rating": 1401.8732564186957,
            "rating_q975": 1432.9494749178498,
            "rating_q025": 1370.7970379195417
        },
        "gpt-4.1-2025-04-14": {
            "rating": 1399.7262308637237,
            "rating_q975": 1417.0168438667854,
            "rating_q025": 1382.435617860662
        },
        "grok-4-1-fast-reasoning": {
            "rating": 1396.1685662851078,
            "rating_q975": 1448.5168612373259,
            "rating_q025": 1343.8202713328897
        },
        "deepseek-v3.1-thinking": {
            "rating": 1391.8146186377949,
            "rating_q975": 1424.9583882051627,
            "rating_q025": 1358.670849070427
        },
        "claude-sonnet-4-20250514": {
            "rating": 1390.9509694537537,
            "rating_q975": 1410.212765845056,
            "rating_q025": 1371.6891730624513
        },
        "gpt-5-mini-high": {
            "rating": 1390.697645339398,
            "rating_q975": 1416.6626734465444,
            "rating_q025": 1364.7326172322514
        },
        "deepseek-r1": {
            "rating": 1390.1397276766538,
            "rating_q975": 1417.9739107537175,
            "rating_q025": 1362.3055445995901
        },
        "mistral-medium-2508": {
            "rating": 1390.1127085916946,
            "rating_q975": 1411.8362223951267,
            "rating_q025": 1368.3891947882626
        },
        "qwen3-235b-a22b-thinking-2507": {
            "rating": 1388.543698910918,
            "rating_q975": 1429.2550572610148,
            "rating_q025": 1347.8323405608212
        },
        "qwen3-next-80b-a3b-instruct": {
            "rating": 1387.905695171966,
            "rating_q975": 1415.9412312707916,
            "rating_q025": 1359.8701590731405
        },
        "deepseek-v3-0324": {
            "rating": 1387.6977863601228,
            "rating_q975": 1406.0206453501203,
            "rating_q025": 1369.3749273701253
        },
        "mistral-medium-2505": {
            "rating": 1387.313065952319,
            "rating_q975": 1406.3504758668232,
            "rating_q025": 1368.2756560378148
        },
        "mai-1-preview": {
            "rating": 1386.5925833815124,
            "rating_q975": 1416.6534243728715,
            "rating_q025": 1356.5317423901533
        },
        "qwen3-vl-235b-a22b-instruct": {
            "rating": 1385.0834811728046,
            "rating_q975": 1427.1072930445298,
            "rating_q025": 1343.0596693010793
        },
        "claude-haiku-4-5-20251001": {
            "rating": 1384.6630922368568,
            "rating_q975": 1412.5212222019811,
            "rating_q025": 1356.8049622717324
        },
        "longcat-flash-chat": {
            "rating": 1382.7499387805653,
            "rating_q975": 1419.8450234563304,
            "rating_q025": 1345.6548541048003
        },
        "gpt-4.1-mini-2025-04-14": {
            "rating": 1382.2206488902698,
            "rating_q975": 1401.2612269305314,
            "rating_q025": 1363.1800708500082
        },
        "grok-4-fast-reasoning": {
            "rating": 1381.3336814671688,
            "rating_q975": 1413.7484332951367,
            "rating_q025": 1348.918929639201
        },
        "gemini-2.5-flash-lite-preview-09-2025-no-thinking": {
            "rating": 1380.5168644085961,
            "rating_q975": 1407.3576129664732,
            "rating_q025": 1353.676115850719
        },
        "claude-3-7-sonnet-20250219-thinking-32k": {
            "rating": 1379.6771879337132,
            "rating_q975": 1399.0680831525212,
            "rating_q025": 1360.2862927149051
        },
        "claude-sonnet-4-20250514-thinking-32k": {
            "rating": 1379.1440996275062,
            "rating_q975": 1400.3014751422193,
            "rating_q025": 1357.9867241127931
        },
        "qwen3-235b-a22b-no-thinking": {
            "rating": 1377.185900698144,
            "rating_q975": 1396.4019573156681,
            "rating_q025": 1357.9698440806199
        },
        "deepseek-r1-0528": {
            "rating": 1376.0295606870857,
            "rating_q975": 1401.7709472379495,
            "rating_q025": 1350.2881741362219
        },
        "qwen3-235b-a22b": {
            "rating": 1375.6075678030484,
            "rating_q975": 1397.4952592591083,
            "rating_q025": 1353.7198763469885
        },
        "claude-3-5-sonnet-20241022": {
            "rating": 1375.158832431082,
            "rating_q975": 1388.263651237537,
            "rating_q025": 1362.0540136246268
        },
        "o4-mini-2025-04-16": {
            "rating": 1373.8709256136622,
            "rating_q975": 1392.130057511419,
            "rating_q025": 1355.6117937159054
        },
        "gemini-2.5-flash-lite-preview-06-17-thinking": {
            "rating": 1372.707585139274,
            "rating_q975": 1394.0530885625312,
            "rating_q025": 1351.3620817160167
        },
        "gemma-3-12b-it": {
            "rating": 1370.84450782618,
            "rating_q975": 1413.4787501718286,
            "rating_q025": 1328.2102654805315
        },
        "o1-2024-12-17": {
            "rating": 1368.5317231780764,
            "rating_q975": 1391.9496012749705,
            "rating_q025": 1345.1138450811823
        },
        "deepseek-v3.2": {
            "rating": 1368.414317649025,
            "rating_q975": 1414.2709754204218,
            "rating_q025": 1322.557659877628
        },
        "glm-4.5": {
            "rating": 1364.9068127835571,
            "rating_q975": 1391.3120803628244,
            "rating_q025": 1338.5015452042899
        },
        "gemma-3-27b-it": {
            "rating": 1364.8222786952103,
            "rating_q975": 1382.5938498900198,
            "rating_q025": 1347.050707500401
        },
        "claude-3-7-sonnet-20250219": {
            "rating": 1361.5575505295026,
            "rating_q975": 1380.666558917421,
            "rating_q025": 1342.448542141584
        },
        "qwen3-next-80b-a3b-thinking": {
            "rating": 1359.5259683370302,
            "rating_q975": 1393.2211179606784,
            "rating_q025": 1325.830818713382
        },
        "gemini-2.0-flash-001": {
            "rating": 1353.808631343039,
            "rating_q975": 1371.8017780297134,
            "rating_q025": 1335.8154846563646
        },
        "command-a-03-2025": {
            "rating": 1353.7941202551578,
            "rating_q975": 1370.5740776069708,
            "rating_q025": 1337.0141629033449
        },
        "mistral-small-2506": {
            "rating": 1351.4467944821513,
            "rating_q975": 1380.8521076969246,
            "rating_q025": 1322.041481267378
        },
        "minimax-m1": {
            "rating": 1350.5425173089293,
            "rating_q975": 1371.3195548125943,
            "rating_q025": 1329.7654798052642
        },
        "minimax-m2": {
            "rating": 1350.0827166625634,
            "rating_q975": 1404.8174007868688,
            "rating_q025": 1295.348032538258
        },
        "qwen3-30b-a3b-instruct-2507": {
            "rating": 1349.8745917321169,
            "rating_q975": 1377.0165218298646,
            "rating_q025": 1322.7326616343692
        },
        "step-3": {
            "rating": 1349.5160662249798,
            "rating_q975": 1396.3228996021828,
            "rating_q025": 1302.7092328477768
        },
        "gpt-5-nano-high": {
            "rating": 1349.5093619865866,
            "rating_q975": 1390.7243465884658,
            "rating_q025": 1308.2943773847073
        },
        "o1-preview": {
            "rating": 1349.2061744858001,
            "rating_q975": 1369.9204049486186,
            "rating_q025": 1328.4919440229817
        },
        "qwen3-coder-480b-a35b-instruct": {
            "rating": 1348.0146849202024,
            "rating_q975": 1376.0823455882144,
            "rating_q025": 1319.9470242521904
        },
        "glm-4-plus-0111": {
            "rating": 1345.7291947046622,
            "rating_q975": 1383.8559618405457,
            "rating_q025": 1307.6024275687787
        },
        "deepseek-v3": {
            "rating": 1344.8896563333967,
            "rating_q975": 1369.3690494236812,
            "rating_q025": 1320.4102632431122
        },
        "qwen2.5-max": {
            "rating": 1343.9908411107428,
            "rating_q975": 1364.852205071384,
            "rating_q025": 1323.1294771501016
        },
        "glm-4.5-air": {
            "rating": 1342.3171781075926,
            "rating_q975": 1365.9317333047204,
            "rating_q025": 1318.7026229104647
        },
        "hunyuan-turbos-20250416": {
            "rating": 1335.1508640360512,
            "rating_q975": 1367.4454522386893,
            "rating_q025": 1302.856275833413
        },
        "grok-3-mini-high": {
            "rating": 1334.9514247462198,
            "rating_q975": 1363.9115612365047,
            "rating_q025": 1305.991288255935
        },
        "llama-4-maverick-17b-128e-instruct": {
            "rating": 1330.9873309725153,
            "rating_q975": 1350.3077411373479,
            "rating_q025": 1311.6669208076828
        },
        "claude-3-5-sonnet-20240620": {
            "rating": 1330.7174800096832,
            "rating_q975": 1344.439354656186,
            "rating_q025": 1316.9956053631804
        },
        "gpt-4o-2024-05-13": {
            "rating": 1324.671009377445,
            "rating_q975": 1336.695540083142,
            "rating_q025": 1312.646478671748
        },
        "qwen3-32b": {
            "rating": 1324.2194243651688,
            "rating_q975": 1365.3499654111142,
            "rating_q025": 1283.0888833192234
        },
        "gemini-2.0-flash-lite-preview-02-05": {
            "rating": 1324.03145532884,
            "rating_q975": 1345.911035411255,
            "rating_q025": 1302.1518752464249
        },
        "o3-mini": {
            "rating": 1323.6477703883456,
            "rating_q975": 1340.2105955853751,
            "rating_q025": 1307.0849451913161
        },
        "gemini-advanced-0514": {
            "rating": 1322.1022080390335,
            "rating_q975": 1338.492641546042,
            "rating_q025": 1305.711774532025
        },
        "o3-mini-high": {
            "rating": 1321.3452196199792,
            "rating_q975": 1350.6985450182174,
            "rating_q025": 1291.991894221741
        },
        "gpt-oss-120b": {
            "rating": 1320.8282256128969,
            "rating_q975": 1345.514765254518,
            "rating_q025": 1296.1416859712758
        },
        "grok-3-mini-beta": {
            "rating": 1317.655911846376,
            "rating_q975": 1342.4367054757092,
            "rating_q025": 1292.8751182170429
        },
        "claude-3-opus-20240229": {
            "rating": 1315.6351817782174,
            "rating_q975": 1326.9158791617224,
            "rating_q025": 1304.3544843947125
        },
        "gemma-3n-e4b-it": {
            "rating": 1315.5480989947905,
            "rating_q975": 1337.8830150638296,
            "rating_q025": 1293.2131829257514
        },
        "gpt-4.1-nano-2025-04-14": {
            "rating": 1314.3266827767743,
            "rating_q975": 1351.5695830347743,
            "rating_q025": 1277.0837825187743
        },
        "amazon-nova-experimental-chat-10-09": {
            "rating": 1312.6058620191293,
            "rating_q975": 1364.4740779118608,
            "rating_q025": 1260.7376461263977
        },
        "gemini-1.5-pro-002": {
            "rating": 1310.5042419374945,
            "rating_q975": 1326.5062471975084,
            "rating_q025": 1294.5022366774806
        },
        "claude-3-5-haiku-20241022": {
            "rating": 1309.0648462434424,
            "rating_q975": 1324.2806273652566,
            "rating_q025": 1293.8490651216282
        },
        "gpt-4o-2024-08-06": {
            "rating": 1308.97110023848,
            "rating_q975": 1325.4462534392549,
            "rating_q025": 1292.495947037705
        },
        "gpt-4-turbo-2024-04-09": {
            "rating": 1308.1325630745114,
            "rating_q975": 1321.0004715070756,
            "rating_q025": 1295.2646546419471
        },
        "grok-2-2024-08-13": {
            "rating": 1307.346421893373,
            "rating_q975": 1322.3059553477876,
            "rating_q025": 1292.3868884389583
        },
        "llama-4-scout-17b-16e-instruct": {
            "rating": 1303.8929121617439,
            "rating_q975": 1325.8737460292862,
            "rating_q025": 1281.9120782942016
        },
        "llama-3.1-405b-instruct-bf16": {
            "rating": 1301.257052550834,
            "rating_q975": 1320.171113613589,
            "rating_q025": 1282.3429914880792
        },
        "amazon-nova-experimental-chat-10-20": {
            "rating": 1300.0590762228292,
            "rating_q975": 1342.000555346128,
            "rating_q025": 1258.1175970995303
        },
        "llama-3.1-405b-instruct-fp8": {
            "rating": 1299.1878541435042,
            "rating_q975": 1314.2514476493648,
            "rating_q025": 1284.1242606376436
        },
        "glm-4-plus": {
            "rating": 1298.2556256271887,
            "rating_q975": 1320.4788745777175,
            "rating_q025": 1276.0323766766599
        },
        "mistral-large-2407": {
            "rating": 1296.9323279278744,
            "rating_q975": 1313.5936651164477,
            "rating_q025": 1280.2709907393012
        },
        "magistral-medium-2506": {
            "rating": 1296.5339640924153,
            "rating_q975": 1329.699960911539,
            "rating_q025": 1263.3679672732917
        },
        "gpt-4-1106-preview": {
            "rating": 1296.1942705062222,
            "rating_q975": 1310.3494737276635,
            "rating_q025": 1282.039067284781
        },
        "gemini-1.5-pro-001": {
            "rating": 1295.8746666544384,
            "rating_q975": 1309.5652674933765,
            "rating_q025": 1282.1840658155004
        },
        "qwen3-30b-a3b": {
            "rating": 1295.8570601444894,
            "rating_q975": 1317.748330338342,
            "rating_q025": 1273.965789950637
        },
        "qwq-32b": {
            "rating": 1295.0206775803902,
            "rating_q975": 1317.878205686225,
            "rating_q025": 1272.1631494745552
        },
        "o1-mini": {
            "rating": 1294.7127845489665,
            "rating_q975": 1311.8521056478628,
            "rating_q025": 1277.5734634500702
        },
        "gpt-4o-mini-2024-07-18": {
            "rating": 1293.3820959109032,
            "rating_q975": 1307.682566554085,
            "rating_q025": 1279.0816252677214
        },
        "gpt-4-0125-preview": {
            "rating": 1291.1477197811384,
            "rating_q975": 1304.9270445348457,
            "rating_q025": 1277.3683950274312
        },
        "nova-2-lite": {
            "rating": 1289.0531057508265,
            "rating_q975": 1335.5710676081408,
            "rating_q025": 1242.5351438935122
        },
        "llama-3.3-70b-instruct": {
            "rating": 1288.8004786384686,
            "rating_q975": 1305.6239351583224,
            "rating_q025": 1271.9770221186147
        },
        "grok-2-mini-2024-08-13": {
            "rating": 1287.3675460226148,
            "rating_q975": 1303.6741908304243,
            "rating_q025": 1271.0609012148052
        },
        "mistral-small-3.1-24b-instruct-2503": {
            "rating": 1287.2461610325104,
            "rating_q975": 1309.012693441283,
            "rating_q025": 1265.4796286237377
        },
        "yi-lightning": {
            "rating": 1286.94133006054,
            "rating_q975": 1307.8762285198084,
            "rating_q025": 1266.0064316012715
        },
        "gemma-3-4b-it": {
            "rating": 1283.9893676861827,
            "rating_q975": 1325.487639991363,
            "rating_q025": 1242.4910953810024
        },
        "step-1o-turbo-202506": {
            "rating": 1283.1482686916315,
            "rating_q975": 1314.9331685540424,
            "rating_q025": 1251.3633688292207
        },
        "mistral-large-2411": {
            "rating": 1282.2028992038754,
            "rating_q975": 1304.3736619486776,
            "rating_q025": 1260.0321364590732
        },
        "deepseek-v2.5-1210": {
            "rating": 1281.661200370334,
            "rating_q975": 1328.8952310868228,
            "rating_q025": 1234.427169653845
        },
        "athene-70b-0725": {
            "rating": 1280.0772082743565,
            "rating_q975": 1303.2320072170983,
            "rating_q025": 1256.9224093316147
        },
        "qwen-max-0919": {
            "rating": 1278.2679154116636,
            "rating_q975": 1303.543789137949,
            "rating_q025": 1252.9920416853781
        },
        "reka-core-20240904": {
            "rating": 1277.7460006275012,
            "rating_q975": 1318.8199977244333,
            "rating_q025": 1236.672003530569
        },
        "gemini-1.5-flash-002": {
            "rating": 1277.1362775179093,
            "rating_q975": 1298.1320024281338,
            "rating_q025": 1256.1405526076849
        },
        "gpt-4-0314": {
            "rating": 1273.7561593643818,
            "rating_q975": 1291.8932454045769,
            "rating_q025": 1255.6190733241867
        },
        "athene-v2-chat": {
            "rating": 1273.015377492245,
            "rating_q975": 1295.1064461000246,
            "rating_q025": 1250.9243088844655
        },
        "claude-3-sonnet-20240229": {
            "rating": 1271.0014043742533,
            "rating_q975": 1284.9079061068385,
            "rating_q025": 1257.094902641668
        },
        "amazon-nova-pro-v1.0": {
            "rating": 1270.3803839355446,
            "rating_q975": 1293.2375797024001,
            "rating_q025": 1247.523188168689
        },
        "gpt-oss-20b": {
            "rating": 1268.5464543151866,
            "rating_q975": 1309.2467579039676,
            "rating_q025": 1227.8461507264055
        },
        "gemma-2-9b-it-simpo": {
            "rating": 1265.5049079099454,
            "rating_q975": 1296.448140702821,
            "rating_q025": 1234.5616751170696
        },
        "gemma-2-27b-it": {
            "rating": 1263.5082053220467,
            "rating_q975": 1276.8377854738208,
            "rating_q025": 1250.1786251702727
        },
        "gemini-1.5-flash-001": {
            "rating": 1260.870436467384,
            "rating_q975": 1275.1017080951153,
            "rating_q025": 1246.6391648396527
        },
        "qwen2.5-72b-instruct": {
            "rating": 1259.9801258535495,
            "rating_q975": 1278.419577823351,
            "rating_q025": 1241.540673883748
        },
        "command-r-plus-08-2024": {
            "rating": 1258.3324042159634,
            "rating_q975": 1291.476107475109,
            "rating_q025": 1225.1887009568177
        },
        "deepseek-v2.5": {
            "rating": 1254.7163859011798,
            "rating_q975": 1278.517607394377,
            "rating_q025": 1230.9151644079827
        },
        "amazon-nova-lite-v1.0": {
            "rating": 1253.9637934961625,
            "rating_q975": 1279.9847998070454,
            "rating_q025": 1227.9427871852795
        },
        "llama-3.1-70b-instruct": {
            "rating": 1252.7885340386492,
            "rating_q975": 1268.7907408145882,
            "rating_q025": 1236.7863272627103
        },
        "phi-4": {
            "rating": 1251.6251275577094,
            "rating_q975": 1277.0959560825438,
            "rating_q025": 1226.154299032875
        },
        "mistral-small-24b-instruct-2501": {
            "rating": 1251.0969590868594,
            "rating_q975": 1284.109553691676,
            "rating_q025": 1218.084364482043
        },
        "gpt-4-0613": {
            "rating": 1249.9975299235934,
            "rating_q975": 1264.9667547054294,
            "rating_q025": 1235.0283051417575
        },
        "command-r-plus": {
            "rating": 1249.7990328860615,
            "rating_q975": 1263.9027641850569,
            "rating_q025": 1235.695301587066
        },
        "jamba-1.5-large": {
            "rating": 1245.5165499580942,
            "rating_q975": 1281.6440587191269,
            "rating_q025": 1209.3890411970615
        },
        "mistral-large-2402": {
            "rating": 1243.803279197491,
            "rating_q975": 1259.873697309316,
            "rating_q025": 1227.7328610856662
        },
        "claude-3-haiku-20240307": {
            "rating": 1243.3179883728087,
            "rating_q975": 1256.1290813183,
            "rating_q025": 1230.5068954273174
        },
        "qwen2.5-plus-1127": {
            "rating": 1243.1608116686045,
            "rating_q975": 1278.1140453606683,
            "rating_q025": 1208.2075779765407
        },
        "nemotron-4-340b-instruct": {
            "rating": 1242.9254618649998,
            "rating_q975": 1265.4112453477908,
            "rating_q025": 1220.4396783822087
        },
        "command-r-08-2024": {
            "rating": 1241.6612881065455,
            "rating_q975": 1274.634286587723,
            "rating_q025": 1208.688289625368
        },
        "gemma-2-9b-it": {
            "rating": 1239.317410856775,
            "rating_q975": 1254.4220619471769,
            "rating_q025": 1224.2127597663732
        },
        "c4ai-aya-expanse-32b": {
            "rating": 1233.4495008971437,
            "rating_q975": 1256.6937815116598,
            "rating_q025": 1210.2052202826276
        },
        "deepseek-coder-v2": {
            "rating": 1230.4636248469023,
            "rating_q975": 1256.048968692061,
            "rating_q025": 1204.8782810017437
        },
        "gemini-1.5-flash-8b-001": {
            "rating": 1224.777501061264,
            "rating_q975": 1245.1368047721103,
            "rating_q025": 1204.4181973504178
        },
        "reka-flash-20240904": {
            "rating": 1224.6240504768182,
            "rating_q975": 1263.7076454905464,
            "rating_q025": 1185.54045546309
        },
        "llama-3-70b-instruct": {
            "rating": 1223.8631579217213,
            "rating_q975": 1236.0413711000865,
            "rating_q025": 1211.684944743356
        },
        "glm-4-0520": {
            "rating": 1223.269997490524,
            "rating_q975": 1252.5759263630634,
            "rating_q025": 1193.9640686179846
        },
        "amazon-nova-micro-v1.0": {
            "rating": 1221.888926683454,
            "rating_q975": 1248.8285700647552,
            "rating_q025": 1194.9492833021527
        },
        "qwen2-72b-instruct": {
            "rating": 1218.7817398828993,
            "rating_q975": 1235.6201165990853,
            "rating_q025": 1201.9433631667132
        },
        "c4ai-aya-expanse-8b": {
            "rating": 1216.3875509539148,
            "rating_q975": 1252.916100787618,
            "rating_q025": 1179.8590011202116
        },
        "reka-flash-21b-20240226-online": {
            "rating": 1214.8093795938994,
            "rating_q975": 1241.1182432837722,
            "rating_q025": 1188.5005159040265
        },
        "reka-flash-21b-20240226": {
            "rating": 1214.6464803907961,
            "rating_q975": 1235.6734203110416,
            "rating_q025": 1193.6195404705506
        },
        "mistral-medium": {
            "rating": 1214.2505900330816,
            "rating_q975": 1235.9405740728942,
            "rating_q025": 1192.560605993269
        },
        "mixtral-8x22b-instruct-v0.1": {
            "rating": 1213.7845121374653,
            "rating_q975": 1230.0340846641702,
            "rating_q025": 1197.5349396107604
        },
        "jamba-1.5-mini": {
            "rating": 1209.605678342492,
            "rating_q975": 1246.889014294069,
            "rating_q025": 1172.3223423909149
        },
        "gemini-pro-dev-api": {
            "rating": 1208.699469683471,
            "rating_q975": 1237.7604944950417,
            "rating_q025": 1179.6384448719004
        },
        "gpt-3.5-turbo-0125": {
            "rating": 1193.640778681085,
            "rating_q975": 1209.7220601037743,
            "rating_q025": 1177.5594972583958
        },
        "command-r": {
            "rating": 1189.5564485031541,
            "rating_q975": 1207.1211638414486,
            "rating_q025": 1171.9917331648596
        },
        "qwen1.5-110b-chat": {
            "rating": 1186.600319765865,
            "rating_q975": 1206.6307703390887,
            "rating_q025": 1166.5698691926411
        },
        "mixtral-8x7b-instruct-v0.1": {
            "rating": 1183.4038458627151,
            "rating_q975": 1198.6789959612618,
            "rating_q025": 1168.1286957641685
        },
        "gpt-3.5-turbo-1106": {
            "rating": 1171.9764621691402,
            "rating_q975": 1206.097430443613,
            "rating_q025": 1137.8554938946675
        },
        "phi-3-medium-4k-instruct": {
            "rating": 1168.092326263105,
            "rating_q975": 1188.441139196093,
            "rating_q025": 1147.743513330117
        },
        "llama-3.1-8b-instruct": {
            "rating": 1163.269200196189,
            "rating_q975": 1180.2110899933239,
            "rating_q025": 1146.3273103990543
        },
        "llama-3-8b-instruct": {
            "rating": 1158.1819192762728,
            "rating_q975": 1171.4901087616122,
            "rating_q025": 1144.8737297909333
        },
        "yi-1.5-34b-chat": {
            "rating": 1153.4201027285158,
            "rating_q975": 1173.406850941855,
            "rating_q025": 1133.4333545151765
        },
        "qwen1.5-72b-chat": {
            "rating": 1152.7401190978926,
            "rating_q975": 1171.795519646726,
            "rating_q025": 1133.6847185490592
        },
        "gemma-2-2b-it": {
            "rating": 1150.9399696706778,
            "rating_q975": 1169.129546786402,
            "rating_q025": 1132.7503925549536
        },
        "gemma-1.1-7b-it": {
            "rating": 1149.84811643435,
            "rating_q975": 1171.0337982339288,
            "rating_q025": 1128.6624346347712
        },
        "wizardlm-70b": {
            "rating": 1147.5872259433613,
            "rating_q975": 1190.5560217637635,
            "rating_q025": 1104.6184301229591
        },
        "snowflake-arctic-instruct": {
            "rating": 1143.689936531034,
            "rating_q975": 1165.6326784091032,
            "rating_q025": 1121.7471946529647
        },
        "phi-3-small-8k-instruct": {
            "rating": 1143.4038074309842,
            "rating_q975": 1167.0344460989304,
            "rating_q025": 1119.773168763038
        },
        "dbrx-instruct-preview": {
            "rating": 1136.3369793197821,
            "rating_q975": 1158.857917791776,
            "rating_q025": 1113.8160408477884
        },
        "openchat-3.5-0106": {
            "rating": 1133.9512859865777,
            "rating_q975": 1167.1338770379525,
            "rating_q025": 1100.7686949352028
        },
        "vicuna-33b": {
            "rating": 1130.2603635928685,
            "rating_q975": 1159.1396786036528,
            "rating_q025": 1101.3810485820843
        },
        "qwen1.5-32b-chat": {
            "rating": 1127.1868698071423,
            "rating_q975": 1149.0159899457772,
            "rating_q025": 1105.3577496685075
        },
        "starling-lm-7b-beta": {
            "rating": 1108.6865269841687,
            "rating_q975": 1139.0806594158048,
            "rating_q025": 1078.2923945525326
        },
        "llama-3.2-3b-instruct": {
            "rating": 1107.155429736596,
            "rating_q975": 1147.8688373590608,
            "rating_q025": 1066.4420221141313
        },
        "qwen1.5-14b-chat": {
            "rating": 1106.4202660395501,
            "rating_q975": 1131.7256857749358,
            "rating_q025": 1081.1148463041645
        },
        "phi-3-mini-4k-instruct": {
            "rating": 1105.6265518748687,
            "rating_q975": 1128.9580929819053,
            "rating_q025": 1082.295010767832
        },
        "phi-3-mini-4k-instruct-june-2024": {
            "rating": 1102.634010415568,
            "rating_q975": 1134.4064744760433,
            "rating_q025": 1070.8615463550925
        },
        "yi-34b-chat": {
            "rating": 1099.9907327269534,
            "rating_q975": 1131.024229089355,
            "rating_q025": 1068.9572363645518
        },
        "llama-2-70b-chat": {
            "rating": 1097.5837509481157,
            "rating_q975": 1118.9986297524185,
            "rating_q025": 1076.168872143813
        },
        "phi-3-mini-128k-instruct": {
            "rating": 1088.6735290749932,
            "rating_q975": 1112.5900523280595,
            "rating_q025": 1064.757005821927
        },
        "starling-lm-7b-alpha": {
            "rating": 1082.7868202838777,
            "rating_q975": 1123.9872737937144,
            "rating_q025": 1041.586366774041
        },
        "internlm2_5-20b-chat": {
            "rating": 1081.7426395169505,
            "rating_q975": 1119.1943779788892,
            "rating_q025": 1044.2909010550118
        },
        "vicuna-13b": {
            "rating": 1076.1541648662792,
            "rating_q975": 1111.6442936433646,
            "rating_q025": 1040.6640360891938
        },
        "gemma-7b-it": {
            "rating": 1070.4828212829505,
            "rating_q975": 1113.6520708187381,
            "rating_q025": 1027.3135717471628
        },
        "llama-2-13b-chat": {
            "rating": 1066.694140232088,
            "rating_q975": 1095.8480172836023,
            "rating_q025": 1037.540263180574
        },
        "llama-3.2-1b-instruct": {
            "rating": 1062.8892909473316,
            "rating_q975": 1102.637648625335,
            "rating_q025": 1023.140933269328
        },
        "zephyr-7b-beta": {
            "rating": 1057.8452989040159,
            "rating_q975": 1104.7830787035682,
            "rating_q025": 1010.9075191044635
        },
        "mistral-7b-instruct-v0.2": {
            "rating": 1045.3895181807793,
            "rating_q975": 1072.1609636211397,
            "rating_q025": 1018.6180727404188
        },
        "gemma-1.1-2b-it": {
            "rating": 1043.2576140920212,
            "rating_q975": 1077.5594915266786,
            "rating_q025": 1008.9557366573638
        },
        "llama-2-7b-chat": {
            "rating": 1036.386991290865,
            "rating_q975": 1070.3378586160907,
            "rating_q025": 1002.436123965639
        },
        "mistral-7b-instruct": {
            "rating": 1020.135154719731,
            "rating_q975": 1065.2845418126954,
            "rating_q025": 974.9857676267667
        },
        "qwen1.5-4b-chat": {
            "rating": 996.4569172944271,
            "rating_q975": 1035.4707064642903,
            "rating_q025": 957.4431281245638
        }
    },
    "hard_6": {
        "gemini-3-pro": {
            "rating": 1503.5640865669889,
            "rating_q975": 1511.5019980869579,
            "rating_q025": 1495.6261750470198
        },
        "claude-opus-4-5-20251101-thinking-32k": {
            "rating": 1497.2698451607876,
            "rating_q975": 1506.6353126319157,
            "rating_q025": 1487.9043776896594
        },
        "claude-opus-4-5-20251101": {
            "rating": 1495.4368628068357,
            "rating_q975": 1504.701361114452,
            "rating_q025": 1486.1723644992194
        },
        "grok-4.1-thinking": {
            "rating": 1491.2858748711,
            "rating_q975": 1499.13277935356,
            "rating_q025": 1483.4389703886402
        },
        "claude-sonnet-4-5-20250929-thinking-32k": {
            "rating": 1483.260084155215,
            "rating_q975": 1489.1599738456382,
            "rating_q025": 1477.360194464792
        },
        "claude-opus-4-1-20250805-thinking-16k": {
            "rating": 1479.1385217583186,
            "rating_q975": 1484.2133939558478,
            "rating_q025": 1474.0636495607894
        },
        "grok-4.1": {
            "rating": 1475.450883650928,
            "rating_q975": 1483.317088356828,
            "rating_q025": 1467.5846789450281
        },
        "gpt-5.1-high": {
            "rating": 1473.6587123945424,
            "rating_q975": 1482.1058022716272,
            "rating_q025": 1465.2116225174575
        },
        "claude-sonnet-4-5-20250929": {
            "rating": 1472.1977803640245,
            "rating_q975": 1478.6415927012897,
            "rating_q025": 1465.7539680267594
        },
        "claude-opus-4-1-20250805": {
            "rating": 1470.856499501098,
            "rating_q975": 1475.7252811101475,
            "rating_q025": 1465.9877178920483
        },
        "gemini-2.5-pro": {
            "rating": 1462.5070647539749,
            "rating_q975": 1467.0264741105136,
            "rating_q025": 1457.9876553974361
        },
        "qwen3-max-preview": {
            "rating": 1456.4189524335263,
            "rating_q975": 1462.394823793295,
            "rating_q025": 1450.4430810737576
        },
        "gpt-5.1": {
            "rating": 1454.3664112202023,
            "rating_q975": 1462.1912492269983,
            "rating_q025": 1446.5415732134063
        },
        "claude-opus-4-20250514-thinking-16k": {
            "rating": 1452.5052729351955,
            "rating_q975": 1458.184879984436,
            "rating_q025": 1446.825665885955
        },
        "chatgpt-4o-latest-20250326": {
            "rating": 1450.6657543540894,
            "rating_q975": 1455.183491822684,
            "rating_q025": 1446.1480168854948
        },
        "gpt-5-high": {
            "rating": 1448.7135923681449,
            "rating_q975": 1454.7618250045039,
            "rating_q025": 1442.6653597317859
        },
        "qwen3-235b-a22b-instruct-2507": {
            "rating": 1448.0334262167069,
            "rating_q975": 1452.9043511611271,
            "rating_q025": 1443.1625012722866
        },
        "kimi-k2-thinking-turbo": {
            "rating": 1447.0420931775093,
            "rating_q975": 1454.5558685399149,
            "rating_q025": 1439.5283178151037
        },
        "gpt-5-chat": {
            "rating": 1445.9504421531876,
            "rating_q975": 1451.6327014075177,
            "rating_q025": 1440.2681828988575
        },
        "deepseek-v3.2-exp": {
            "rating": 1445.844508644518,
            "rating_q975": 1454.0389564381044,
            "rating_q025": 1437.6500608509318
        },
        "qwen3-max-2025-09-23": {
            "rating": 1444.8452197873655,
            "rating_q975": 1453.3702118045087,
            "rating_q025": 1436.3202277702223
        },
        "glm-4.6": {
            "rating": 1442.0775114825262,
            "rating_q975": 1448.1587147052169,
            "rating_q025": 1435.9963082598356
        },
        "deepseek-v3.2-exp-thinking": {
            "rating": 1441.3589231095789,
            "rating_q975": 1450.0413522397853,
            "rating_q025": 1432.6764939793725
        },
        "deepseek-v3.1-terminus-thinking": {
            "rating": 1440.6175498525715,
            "rating_q975": 1454.9855536044308,
            "rating_q025": 1426.2495461007122
        },
        "ernie-5.0-preview-1103": {
            "rating": 1439.7892911520375,
            "rating_q975": 1451.0723677619442,
            "rating_q025": 1428.506214542131
        },
        "grok-4-1-fast-reasoning": {
            "rating": 1439.663447378166,
            "rating_q975": 1448.6820036084027,
            "rating_q025": 1430.6448911479292
        },
        "o3-2025-04-16": {
            "rating": 1439.584113745869,
            "rating_q975": 1444.4744284177596,
            "rating_q025": 1434.6937990739784
        },
        "qwen3-vl-235b-a22b-instruct": {
            "rating": 1438.5371447133043,
            "rating_q975": 1447.4774310487135,
            "rating_q025": 1429.5968583778952
        },
        "mistral-large-3": {
            "rating": 1437.6973638132815,
            "rating_q975": 1448.2098962596956,
            "rating_q025": 1427.1848313668675
        },
        "gpt-4.5-preview-2025-02-27": {
            "rating": 1436.8336857746465,
            "rating_q975": 1446.7958843974611,
            "rating_q025": 1426.8714871518318
        },
        "deepseek-v3.2": {
            "rating": 1436.2590524062205,
            "rating_q975": 1446.7104991015015,
            "rating_q025": 1425.8076057109395
        },
        "deepseek-v3.1-thinking": {
            "rating": 1435.4091003805079,
            "rating_q975": 1444.0963601621631,
            "rating_q025": 1426.7218405988526
        },
        "claude-haiku-4-5-20251001": {
            "rating": 1433.583712515297,
            "rating_q975": 1439.5656102216678,
            "rating_q025": 1427.6018148089263
        },
        "kimi-k2-0905-preview": {
            "rating": 1433.4844552797954,
            "rating_q975": 1441.9215344037616,
            "rating_q025": 1425.0473761558292
        },
        "claude-opus-4-20250514": {
            "rating": 1432.5093932784696,
            "rating_q975": 1437.9954574780888,
            "rating_q025": 1427.0233290788503
        },
        "deepseek-v3.2-thinking": {
            "rating": 1431.957901507375,
            "rating_q975": 1442.8891770402167,
            "rating_q025": 1421.0266259745333
        },
        "deepseek-r1-0528": {
            "rating": 1431.4360729784728,
            "rating_q975": 1439.1169206294246,
            "rating_q025": 1423.755225327521
        },
        "mistral-medium-2508": {
            "rating": 1431.1902749985354,
            "rating_q975": 1436.3020921331654,
            "rating_q025": 1426.0784578639054
        },
        "glm-4.5": {
            "rating": 1430.9591541505322,
            "rating_q975": 1437.4007230083341,
            "rating_q025": 1424.5175852927302
        },
        "deepseek-v3.1": {
            "rating": 1430.5121624517633,
            "rating_q975": 1438.362367157731,
            "rating_q025": 1422.6619577457957
        },
        "kimi-k2-0711-preview": {
            "rating": 1430.347460708412,
            "rating_q975": 1436.6703162596557,
            "rating_q025": 1424.0246051571683
        },
        "grok-4-fast-chat": {
            "rating": 1429.309535298037,
            "rating_q975": 1439.8780514611278,
            "rating_q025": 1418.741019134946
        },
        "claude-sonnet-4-20250514-thinking-32k": {
            "rating": 1428.9936712927608,
            "rating_q975": 1434.673472957266,
            "rating_q025": 1423.3138696282556
        },
        "gpt-4.1-2025-04-14": {
            "rating": 1427.9598643612374,
            "rating_q975": 1432.9489737551996,
            "rating_q025": 1422.970754967275
        },
        "longcat-flash-chat": {
            "rating": 1424.073011010543,
            "rating_q975": 1432.3606261855032,
            "rating_q025": 1415.785395835583
        },
        "grok-3-preview-02-24": {
            "rating": 1422.4365255149758,
            "rating_q975": 1428.8111326425912,
            "rating_q025": 1416.0619183873603
        },
        "deepseek-v3.1-terminus": {
            "rating": 1421.3934765200843,
            "rating_q975": 1434.6652970127423,
            "rating_q025": 1408.1216560274263
        },
        "qwen3-next-80b-a3b-instruct": {
            "rating": 1420.6559029131347,
            "rating_q975": 1426.9076041570008,
            "rating_q025": 1414.4042016692686
        },
        "gemini-2.5-flash-preview-09-2025": {
            "rating": 1417.4025183788008,
            "rating_q975": 1423.1302850173076,
            "rating_q025": 1411.674751740294
        },
        "grok-4-0709": {
            "rating": 1417.3312624725568,
            "rating_q975": 1422.4488715779162,
            "rating_q025": 1412.2136533671974
        },
        "qwen3-235b-a22b-thinking-2507": {
            "rating": 1416.9613386597914,
            "rating_q975": 1426.4257605047892,
            "rating_q025": 1407.4969168147936
        },
        "qwen3-235b-a22b-no-thinking": {
            "rating": 1416.5409818940254,
            "rating_q975": 1422.2551515105545,
            "rating_q025": 1410.8268122774964
        },
        "qwen3-vl-235b-a22b-thinking": {
            "rating": 1415.9983513736704,
            "rating_q975": 1425.2466552017524,
            "rating_q025": 1406.7500475455884
        },
        "deepseek-r1": {
            "rating": 1415.327213988974,
            "rating_q975": 1424.2500287157573,
            "rating_q025": 1406.404399262191
        },
        "hunyuan-vision-1.5-thinking": {
            "rating": 1414.9176742088418,
            "rating_q975": 1432.279340477632,
            "rating_q025": 1397.5560079400516
        },
        "o1-2024-12-17": {
            "rating": 1414.8382056891744,
            "rating_q975": 1422.42253261006,
            "rating_q025": 1407.2538787682888
        },
        "claude-sonnet-4-20250514": {
            "rating": 1414.747954067821,
            "rating_q975": 1420.3304924929505,
            "rating_q025": 1409.1654156426914
        },
        "claude-3-7-sonnet-20250219-thinking-32k": {
            "rating": 1414.4789543148993,
            "rating_q975": 1420.362341553292,
            "rating_q025": 1408.5955670765065
        },
        "gemini-2.5-flash": {
            "rating": 1413.8940673504692,
            "rating_q975": 1418.3794095918886,
            "rating_q025": 1409.4087251090498
        },
        "qwen3-coder-480b-a35b-instruct": {
            "rating": 1410.4704098125892,
            "rating_q975": 1417.0356816128042,
            "rating_q025": 1403.9051380123742
        },
        "grok-4-fast-reasoning": {
            "rating": 1410.341030407505,
            "rating_q975": 1416.9083472389887,
            "rating_q025": 1403.7737135760215
        },
        "qwen3-30b-a3b-instruct-2507": {
            "rating": 1405.23148247514,
            "rating_q975": 1411.644880772228,
            "rating_q025": 1398.818084178052
        },
        "gpt-5-mini-high": {
            "rating": 1404.532925182702,
            "rating_q975": 1410.8111154596465,
            "rating_q025": 1398.2547349057575
        },
        "deepseek-v3-0324": {
            "rating": 1404.1312297247773,
            "rating_q975": 1409.3949958729727,
            "rating_q025": 1398.867463576582
        },
        "o4-mini-2025-04-16": {
            "rating": 1403.970777766444,
            "rating_q975": 1409.206091709551,
            "rating_q025": 1398.7354638233369
        },
        "mai-1-preview": {
            "rating": 1401.5841849715234,
            "rating_q975": 1408.7774653296076,
            "rating_q025": 1394.3909046134393
        },
        "gpt-4.1-mini-2025-04-14": {
            "rating": 1398.7988255591467,
            "rating_q975": 1404.5229376147845,
            "rating_q025": 1393.074713503509
        },
        "o3-mini-high": {
            "rating": 1398.0923181818166,
            "rating_q975": 1407.102434202138,
            "rating_q025": 1389.0822021614952
        },
        "hunyuan-t1-20250711": {
            "rating": 1396.8274328534922,
            "rating_q975": 1409.9525312939852,
            "rating_q025": 1383.702334412999
        },
        "mistral-medium-2505": {
            "rating": 1396.6617372050723,
            "rating_q975": 1402.6512118189464,
            "rating_q025": 1390.6722625911982
        },
        "claude-3-5-sonnet-20241022": {
            "rating": 1396.2542900839014,
            "rating_q975": 1400.506409959043,
            "rating_q025": 1392.00217020876
        },
        "claude-3-7-sonnet-20250219": {
            "rating": 1394.8515143463653,
            "rating_q975": 1400.425874808739,
            "rating_q025": 1389.2771538839916
        },
        "o1-preview": {
            "rating": 1393.8701891196804,
            "rating_q975": 1401.459204265407,
            "rating_q025": 1386.2811739739539
        },
        "gemini-2.5-flash-lite-preview-09-2025-no-thinking": {
            "rating": 1390.3298933372466,
            "rating_q975": 1396.0568823833255,
            "rating_q025": 1384.6029042911678
        },
        "qwen3-235b-a22b": {
            "rating": 1389.8130721363875,
            "rating_q975": 1396.13823055106,
            "rating_q025": 1383.4879137217151
        },
        "glm-4.5-air": {
            "rating": 1388.6617053489194,
            "rating_q975": 1394.2796630663784,
            "rating_q025": 1383.0437476314605
        },
        "hunyuan-turbos-20250416": {
            "rating": 1388.2108329657265,
            "rating_q975": 1397.7018926732073,
            "rating_q025": 1378.7197732582456
        },
        "qwen3-next-80b-a3b-thinking": {
            "rating": 1382.6146561795595,
            "rating_q975": 1390.2307927802174,
            "rating_q025": 1374.9985195789016
        },
        "qwen2.5-max": {
            "rating": 1381.462468718163,
            "rating_q975": 1387.6400235539725,
            "rating_q025": 1375.2849138823537
        },
        "gemini-2.5-flash-lite-preview-06-17-thinking": {
            "rating": 1381.346360569308,
            "rating_q975": 1387.2496975417025,
            "rating_q025": 1375.4430235969135
        },
        "minimax-m1": {
            "rating": 1381.0158224042689,
            "rating_q975": 1386.5593487486396,
            "rating_q025": 1375.472296059898
        },
        "step-3": {
            "rating": 1375.0537448678226,
            "rating_q975": 1385.8048605965332,
            "rating_q025": 1364.302629139112
        },
        "grok-3-mini-high": {
            "rating": 1374.7601361561499,
            "rating_q975": 1381.9236823357503,
            "rating_q025": 1367.5965899765495
        },
        "amazon-nova-experimental-chat-10-20": {
            "rating": 1374.348770163588,
            "rating_q975": 1383.876162698479,
            "rating_q025": 1364.8213776286968
        },
        "mistral-small-2506": {
            "rating": 1370.9843082394411,
            "rating_q975": 1377.9222677268167,
            "rating_q025": 1364.0463487520656
        },
        "llama-3.1-nemotron-ultra-253b-v1": {
            "rating": 1370.6319955168494,
            "rating_q975": 1392.0319565443153,
            "rating_q025": 1349.2320344893835
        },
        "glm-4.5v": {
            "rating": 1369.2011305205303,
            "rating_q975": 1381.3043682026473,
            "rating_q025": 1357.0978928384134
        },
        "intellect-3": {
            "rating": 1368.7093238069078,
            "rating_q975": 1385.6957692277495,
            "rating_q025": 1351.7228783860662
        },
        "grok-3-mini-beta": {
            "rating": 1368.3714650833895,
            "rating_q975": 1374.9898603349613,
            "rating_q025": 1361.7530698318176
        },
        "o3-mini": {
            "rating": 1368.1801788458622,
            "rating_q975": 1373.0556219828754,
            "rating_q025": 1363.304735708849
        },
        "minimax-m2": {
            "rating": 1365.1639254191612,
            "rating_q975": 1375.0866787655768,
            "rating_q025": 1355.2411720727455
        },
        "ling-flash-2.0": {
            "rating": 1364.947378876458,
            "rating_q975": 1374.8932591537625,
            "rating_q025": 1355.0014985991536
        },
        "command-a-03-2025": {
            "rating": 1364.9083482168783,
            "rating_q975": 1369.6398947349733,
            "rating_q025": 1360.1768016987833
        },
        "gemma-3-27b-it": {
            "rating": 1363.5260313357044,
            "rating_q975": 1368.754552694537,
            "rating_q025": 1358.2975099768717
        },
        "qwen3-32b": {
            "rating": 1363.0134656427138,
            "rating_q975": 1379.2261300549571,
            "rating_q025": 1346.8008012304704
        },
        "hunyuan-turbos-20250226": {
            "rating": 1362.9304897532265,
            "rating_q975": 1385.5430185352711,
            "rating_q025": 1340.317960971182
        },
        "nova-2-lite": {
            "rating": 1361.8705072949037,
            "rating_q975": 1372.9348411640462,
            "rating_q025": 1350.8061734257612
        },
        "amazon-nova-experimental-chat-10-09": {
            "rating": 1359.5481315057818,
            "rating_q975": 1368.032163615091,
            "rating_q025": 1351.0640993964728
        },
        "gpt-oss-120b": {
            "rating": 1359.423428808512,
            "rating_q975": 1365.2048295081297,
            "rating_q025": 1353.6420281088942
        },
        "gemini-2.0-flash-001": {
            "rating": 1358.7474831637123,
            "rating_q975": 1364.2352249648914,
            "rating_q025": 1353.2597413625333
        },
        "claude-3-5-sonnet-20240620": {
            "rating": 1358.0765556960537,
            "rating_q975": 1363.5819439262139,
            "rating_q025": 1352.5711674658935
        },
        "nvidia-llama-3.3-nemotron-super-49b-v1.5": {
            "rating": 1357.4005125141125,
            "rating_q975": 1372.2141557887146,
            "rating_q025": 1342.5868692395104
        },
        "llama-3.3-nemotron-49b-super-v1": {
            "rating": 1357.3316840493967,
            "rating_q975": 1381.727878461802,
            "rating_q025": 1332.9354896369914
        },
        "o1-mini": {
            "rating": 1356.9666170435287,
            "rating_q975": 1362.8471370326047,
            "rating_q025": 1351.0860970544527
        },
        "qwq-32b": {
            "rating": 1354.326484648604,
            "rating_q975": 1360.8188235007046,
            "rating_q025": 1347.8341457965034
        },
        "gpt-5-nano-high": {
            "rating": 1353.3789191823435,
            "rating_q975": 1363.2684585135617,
            "rating_q025": 1343.4893798511252
        },
        "ring-flash-2.0": {
            "rating": 1349.9065162141874,
            "rating_q975": 1359.7197286756991,
            "rating_q025": 1340.0933037526756
        },
        "qwen-plus-0125": {
            "rating": 1349.441146677719,
            "rating_q975": 1363.7461544628422,
            "rating_q025": 1335.1361388925957
        },
        "gemini-1.5-pro-002": {
            "rating": 1348.9367395897602,
            "rating_q975": 1354.3814256570713,
            "rating_q025": 1343.4920535224492
        },
        "deepseek-v3": {
            "rating": 1347.1862125096673,
            "rating_q975": 1355.2104122487788,
            "rating_q025": 1339.1620127705557
        },
        "gemini-2.0-flash-lite-preview-02-05": {
            "rating": 1346.8992809252013,
            "rating_q975": 1354.2501972839257,
            "rating_q025": 1339.548364566477
        },
        "hunyuan-turbo-0110": {
            "rating": 1344.1696550334937,
            "rating_q975": 1367.5935154212937,
            "rating_q025": 1320.7457946456936
        },
        "qwen3-30b-a3b": {
            "rating": 1342.8219843792488,
            "rating_q975": 1349.1959821776331,
            "rating_q025": 1336.4479865808644
        },
        "claude-3-5-haiku-20241022": {
            "rating": 1341.4315123059,
            "rating_q975": 1346.0451896548805,
            "rating_q025": 1336.8178349569196
        },
        "llama-3.1-405b-instruct-bf16": {
            "rating": 1338.8974106078717,
            "rating_q975": 1344.7488966514006,
            "rating_q025": 1333.0459245643428
        },
        "yi-lightning": {
            "rating": 1338.0220487670708,
            "rating_q975": 1345.9054257557207,
            "rating_q025": 1330.138671778421
        },
        "llama-4-maverick-17b-128e-instruct": {
            "rating": 1337.2061453929928,
            "rating_q975": 1342.9624745172719,
            "rating_q025": 1331.4498162687137
        },
        "gpt-4o-2024-05-13": {
            "rating": 1334.5976165886557,
            "rating_q975": 1339.8307710593099,
            "rating_q025": 1329.3644621180015
        },
        "step-2-16k-exp-202412": {
            "rating": 1334.3939537848578,
            "rating_q975": 1349.7138783583227,
            "rating_q025": 1319.0740292113928
        },
        "llama-3.1-405b-instruct-fp8": {
            "rating": 1333.9227219675004,
            "rating_q975": 1339.6456067003685,
            "rating_q025": 1328.1998372346322
        },
        "magistral-medium-2506": {
            "rating": 1331.3382841289285,
            "rating_q975": 1339.6305146268785,
            "rating_q025": 1323.0460536309786
        },
        "athene-v2-chat": {
            "rating": 1330.0804831144633,
            "rating_q975": 1337.376239328677,
            "rating_q025": 1322.7847269002496
        },
        "step-1o-turbo-202506": {
            "rating": 1330.0283526751532,
            "rating_q975": 1339.742785572347,
            "rating_q025": 1320.3139197779594
        },
        "gemma-3-12b-it": {
            "rating": 1330.0079548882022,
            "rating_q975": 1347.9387582689546,
            "rating_q025": 1312.0771515074498
        },
        "gpt-4.1-nano-2025-04-14": {
            "rating": 1329.3505838679878,
            "rating_q975": 1342.9995700248296,
            "rating_q025": 1315.701597711146
        },
        "llama-4-scout-17b-16e-instruct": {
            "rating": 1327.3824579953712,
            "rating_q975": 1333.5819802221765,
            "rating_q025": 1321.1829357685658
        },
        "olmo-3-32b-think": {
            "rating": 1326.933034088327,
            "rating_q975": 1341.6319333190427,
            "rating_q025": 1312.2341348576115
        },
        "hunyuan-large-2025-02-10": {
            "rating": 1326.929695598717,
            "rating_q975": 1345.9463960024905,
            "rating_q025": 1307.9129951949435
        },
        "claude-3-opus-20240229": {
            "rating": 1326.1070861089515,
            "rating_q975": 1330.832165098536,
            "rating_q025": 1321.382007119367
        },
        "deepseek-v2.5-1210": {
            "rating": 1326.0591102050785,
            "rating_q975": 1339.3684070250922,
            "rating_q025": 1312.7498133850647
        },
        "gemini-1.5-pro-001": {
            "rating": 1324.3658663928454,
            "rating_q975": 1330.4099543281181,
            "rating_q025": 1318.3217784575727
        },
        "glm-4-plus-0111": {
            "rating": 1324.1470554721284,
            "rating_q975": 1338.5425770623415,
            "rating_q025": 1309.7515338819153
        },
        "gpt-4o-2024-08-06": {
            "rating": 1323.977545974301,
            "rating_q975": 1330.2939600294337,
            "rating_q025": 1317.6611319191682
        },
        "qwen2.5-plus-1127": {
            "rating": 1323.7060949518568,
            "rating_q975": 1334.344975572465,
            "rating_q025": 1313.0672143312486
        },
        "grok-2-2024-08-13": {
            "rating": 1323.1998292149115,
            "rating_q975": 1328.6394653826394,
            "rating_q025": 1317.7601930471835
        },
        "gemini-advanced-0514": {
            "rating": 1323.05331482486,
            "rating_q975": 1330.2753617198593,
            "rating_q025": 1315.8312679298608
        },
        "mercury": {
            "rating": 1321.5478751432129,
            "rating_q975": 1340.1241468734088,
            "rating_q025": 1302.971603413017
        },
        "gpt-oss-20b": {
            "rating": 1321.5044230661256,
            "rating_q975": 1330.442429236235,
            "rating_q025": 1312.566416896016
        },
        "llama-3.3-70b-instruct": {
            "rating": 1318.9956354876263,
            "rating_q975": 1323.868755144845,
            "rating_q025": 1314.1225158304076
        },
        "deepseek-v2.5": {
            "rating": 1318.8086074011985,
            "rating_q975": 1326.298436666625,
            "rating_q025": 1311.318778135772
        },
        "mistral-small-3.1-24b-instruct-2503": {
            "rating": 1317.5921465447084,
            "rating_q975": 1323.4818520930753,
            "rating_q025": 1311.7024409963415
        },
        "mistral-large-2407": {
            "rating": 1317.2114589489188,
            "rating_q975": 1323.4067382118296,
            "rating_q025": 1311.016179686008
        },
        "glm-4-plus": {
            "rating": 1316.0738891285996,
            "rating_q975": 1323.718106659799,
            "rating_q025": 1308.4296715974
        },
        "qwen-max-0919": {
            "rating": 1315.7517904638237,
            "rating_q975": 1324.9305527191789,
            "rating_q025": 1306.5730282084685
        },
        "qwen2.5-72b-instruct": {
            "rating": 1314.4742513623742,
            "rating_q975": 1320.7127646330562,
            "rating_q025": 1308.2357380916922
        },
        "gpt-4-turbo-2024-04-09": {
            "rating": 1313.248226298968,
            "rating_q975": 1319.0358675487064,
            "rating_q025": 1307.4605850492294
        },
        "gemma-3n-e4b-it": {
            "rating": 1312.5191791373322,
            "rating_q975": 1319.6382776245605,
            "rating_q025": 1305.400080650104
        },
        "mistral-large-2411": {
            "rating": 1310.337325210562,
            "rating_q975": 1317.2470723090064,
            "rating_q025": 1303.4275781121178
        },
        "gpt-4-1106-preview": {
            "rating": 1309.8055142512133,
            "rating_q975": 1315.7416589883235,
            "rating_q025": 1303.869369514103
        },
        "athene-70b-0725": {
            "rating": 1309.4920646593337,
            "rating_q975": 1318.0150151023347,
            "rating_q025": 1300.9691142163326
        },
        "gpt-4o-mini-2024-07-18": {
            "rating": 1308.1321293338221,
            "rating_q975": 1313.2786134240698,
            "rating_q025": 1302.9856452435745
        },
        "hunyuan-standard-2025-02-10": {
            "rating": 1307.9878768510512,
            "rating_q975": 1326.8626335590698,
            "rating_q025": 1289.1131201430326
        },
        "llama-3.1-nemotron-70b-instruct": {
            "rating": 1307.435282590363,
            "rating_q975": 1320.2945703003552,
            "rating_q025": 1294.5759948803707
        },
        "gpt-4-0125-preview": {
            "rating": 1304.1547563446002,
            "rating_q975": 1310.212157837308,
            "rating_q025": 1298.0973548518923
        },
        "gpt-4-0314": {
            "rating": 1301.806899004063,
            "rating_q975": 1309.5460875713568,
            "rating_q025": 1294.0677104367694
        },
        "hunyuan-large-vision": {
            "rating": 1301.2168710980936,
            "rating_q975": 1314.2280807646416,
            "rating_q025": 1288.2056614315456
        },
        "grok-2-mini-2024-08-13": {
            "rating": 1300.9988512591092,
            "rating_q975": 1306.7391822509726,
            "rating_q025": 1295.2585202672458
        },
        "gemini-1.5-flash-002": {
            "rating": 1300.6964758955307,
            "rating_q975": 1307.3102278999522,
            "rating_q025": 1294.0827238911093
        },
        "qwen2.5-coder-32b-instruct": {
            "rating": 1300.482797855644,
            "rating_q975": 1315.0486954194478,
            "rating_q025": 1285.9169002918404
        },
        "amazon-nova-pro-v1.0": {
            "rating": 1298.955602568849,
            "rating_q975": 1306.140310175734,
            "rating_q025": 1291.770894961964
        },
        "llama-3.1-70b-instruct": {
            "rating": 1295.7960215213707,
            "rating_q975": 1301.5114492026737,
            "rating_q025": 1290.0805938400676
        },
        "gpt-4-0613": {
            "rating": 1285.4753417844208,
            "rating_q975": 1291.9211874994253,
            "rating_q025": 1279.0294960694164
        },
        "gemini-1.5-flash-001": {
            "rating": 1285.2971632467113,
            "rating_q975": 1291.4608098781125,
            "rating_q025": 1279.13351661531
        },
        "deepseek-coder-v2": {
            "rating": 1284.8907942274657,
            "rating_q975": 1294.5917661514716,
            "rating_q025": 1275.1898223034598
        },
        "gemma-3-4b-it": {
            "rating": 1281.9569487659514,
            "rating_q975": 1299.3671598358862,
            "rating_q025": 1264.5467376960166
        },
        "mistral-small-24b-instruct-2501": {
            "rating": 1281.3168333687877,
            "rating_q975": 1290.9126167554366,
            "rating_q025": 1271.7210499821388
        },
        "jamba-1.5-large": {
            "rating": 1281.18312112675,
            "rating_q975": 1292.7822819113753,
            "rating_q025": 1269.5839603421246
        },
        "claude-3-sonnet-20240229": {
            "rating": 1279.4488429724013,
            "rating_q975": 1285.3300466688772,
            "rating_q025": 1273.5676392759253
        },
        "gemma-2-27b-it": {
            "rating": 1278.9749359358248,
            "rating_q975": 1284.0463458404156,
            "rating_q025": 1273.903526031234
        },
        "llama-3.1-nemotron-51b-instruct": {
            "rating": 1278.5626274291506,
            "rating_q975": 1296.0047162529945,
            "rating_q025": 1261.1205386053066
        },
        "nemotron-4-340b-instruct": {
            "rating": 1278.2619175385148,
            "rating_q975": 1287.1533014125598,
            "rating_q025": 1269.3705336644698
        },
        "reka-core-20240904": {
            "rating": 1277.6970218055983,
            "rating_q975": 1289.1951291582384,
            "rating_q025": 1266.1989144529582
        },
        "llama-3-70b-instruct": {
            "rating": 1276.8466154222858,
            "rating_q975": 1282.3551675490096,
            "rating_q025": 1271.338063295562
        },
        "phi-4": {
            "rating": 1274.9356694599662,
            "rating_q975": 1282.6238292137327,
            "rating_q025": 1267.2475097061997
        },
        "glm-4-0520": {
            "rating": 1274.8785632450267,
            "rating_q975": 1285.9604339880864,
            "rating_q025": 1263.796692501967
        },
        "llama-3.1-tulu-3-70b": {
            "rating": 1270.6234020269087,
            "rating_q975": 1289.2831119720906,
            "rating_q025": 1251.9636920817268
        },
        "qwen2-72b-instruct": {
            "rating": 1270.1621647693128,
            "rating_q975": 1277.3913289006603,
            "rating_q025": 1262.9330006379653
        },
        "gemma-2-9b-it-simpo": {
            "rating": 1269.8081280237338,
            "rating_q975": 1281.1849968000843,
            "rating_q025": 1258.4312592473834
        },
        "amazon-nova-lite-v1.0": {
            "rating": 1268.9879887682669,
            "rating_q975": 1277.2382278123591,
            "rating_q025": 1260.7377497241746
        },
        "c4ai-aya-expanse-32b": {
            "rating": 1268.3400657405616,
            "rating_q975": 1275.7973980808447,
            "rating_q025": 1260.8827334002785
        },
        "hunyuan-standard-256k": {
            "rating": 1267.1205590392083,
            "rating_q975": 1287.6980466806053,
            "rating_q025": 1246.5430713978112
        },
        "reka-flash-20240904": {
            "rating": 1264.8278804977879,
            "rating_q975": 1276.0229593799702,
            "rating_q025": 1253.6328016156056
        },
        "claude-3-haiku-20240307": {
            "rating": 1262.4021331207853,
            "rating_q975": 1268.0151691454946,
            "rating_q025": 1256.789097096076
        },
        "olmo-2-0325-32b-instruct": {
            "rating": 1259.844706793289,
            "rating_q975": 1279.6236964002821,
            "rating_q025": 1240.065717186296
        },
        "mistral-large-2402": {
            "rating": 1259.0072370374724,
            "rating_q975": 1265.9143950091548,
            "rating_q025": 1252.10007906579
        },
        "command-r-plus-08-2024": {
            "rating": 1258.4976586736761,
            "rating_q975": 1269.0524977722391,
            "rating_q025": 1247.9428195751132
        },
        "gemini-1.5-flash-8b-001": {
            "rating": 1256.4232135417355,
            "rating_q975": 1263.027261462345,
            "rating_q025": 1249.819165621126
        },
        "gemma-2-9b-it": {
            "rating": 1254.1176201868989,
            "rating_q975": 1259.9111583943056,
            "rating_q025": 1248.3240819794921
        },
        "command-r-08-2024": {
            "rating": 1253.9078039595643,
            "rating_q975": 1264.215992258645,
            "rating_q025": 1243.5996156604836
        },
        "command-r-plus": {
            "rating": 1249.029134671556,
            "rating_q975": 1255.3670931330958,
            "rating_q025": 1242.6911762100162
        },
        "ministral-8b-2410": {
            "rating": 1248.0795187046895,
            "rating_q975": 1263.3272137063593,
            "rating_q025": 1232.8318237030196
        },
        "qwen1.5-110b-chat": {
            "rating": 1243.3466814081019,
            "rating_q975": 1252.0431592197774,
            "rating_q025": 1234.6502035964263
        },
        "amazon-nova-micro-v1.0": {
            "rating": 1242.147951480254,
            "rating_q975": 1250.2963592218784,
            "rating_q025": 1233.9995437386297
        },
        "mixtral-8x22b-instruct-v0.1": {
            "rating": 1240.5335964692958,
            "rating_q975": 1247.4446135342105,
            "rating_q025": 1233.6225794043812
        },
        "qwen1.5-72b-chat": {
            "rating": 1236.426785878385,
            "rating_q975": 1244.2657289394042,
            "rating_q025": 1228.587842817366
        },
        "jamba-1.5-mini": {
            "rating": 1234.0505471408078,
            "rating_q975": 1245.91623117351,
            "rating_q025": 1222.1848631081057
        },
        "reka-flash-21b-20240226-online": {
            "rating": 1232.748533289846,
            "rating_q975": 1243.498130627043,
            "rating_q025": 1221.9989359526487
        },
        "mistral-medium": {
            "rating": 1232.6679630350131,
            "rating_q975": 1241.3395760386186,
            "rating_q025": 1223.9963500314077
        },
        "reka-flash-21b-20240226": {
            "rating": 1231.086954786525,
            "rating_q975": 1239.939441355458,
            "rating_q025": 1222.234468217592
        },
        "granite-3.1-8b-instruct": {
            "rating": 1229.0133711644555,
            "rating_q975": 1248.8772055548213,
            "rating_q025": 1209.1495367740897
        },
        "gemini-pro-dev-api": {
            "rating": 1228.1308557920252,
            "rating_q975": 1239.5026715654237,
            "rating_q025": 1216.7590400186266
        },
        "c4ai-aya-expanse-8b": {
            "rating": 1227.7520192156371,
            "rating_q975": 1239.0159832302286,
            "rating_q025": 1216.4880552010457
        },
        "gemini-pro": {
            "rating": 1225.7411804517283,
            "rating_q975": 1243.9534731636966,
            "rating_q025": 1207.52888773976
        },
        "gpt-3.5-turbo-0125": {
            "rating": 1225.2655674309333,
            "rating_q975": 1231.8818896991909,
            "rating_q025": 1218.6492451626757
        },
        "gpt-3.5-turbo-1106": {
            "rating": 1224.0063783862302,
            "rating_q975": 1236.7826294635204,
            "rating_q025": 1211.23012730894
        },
        "internlm2_5-20b-chat": {
            "rating": 1223.3386534775145,
            "rating_q975": 1234.7600896694087,
            "rating_q025": 1211.9172172856204
        },
        "yi-1.5-34b-chat": {
            "rating": 1222.4394508676287,
            "rating_q975": 1230.7146996912934,
            "rating_q025": 1214.164202043964
        },
        "llama-3.1-tulu-3-8b": {
            "rating": 1220.5175126932631,
            "rating_q975": 1240.3834281690206,
            "rating_q025": 1200.6515972175057
        },
        "llama-3.1-8b-instruct": {
            "rating": 1219.8660735114047,
            "rating_q975": 1225.906929158571,
            "rating_q025": 1213.8252178642383
        },
        "qwen1.5-32b-chat": {
            "rating": 1218.249578709026,
            "rating_q975": 1227.520258341431,
            "rating_q025": 1208.9788990766212
        },
        "llama-3-8b-instruct": {
            "rating": 1216.8617156484015,
            "rating_q975": 1222.909820221008,
            "rating_q025": 1210.813611075795
        },
        "granite-3.1-2b-instruct": {
            "rating": 1215.945450823202,
            "rating_q975": 1235.0557541239616,
            "rating_q025": 1196.8351475224424
        },
        "dbrx-instruct-preview": {
            "rating": 1214.1791880986157,
            "rating_q975": 1223.2143038172258,
            "rating_q025": 1205.1440723800056
        },
        "zephyr-orpo-141b-A35b-v0.1": {
            "rating": 1213.5323273268302,
            "rating_q975": 1230.4818882106965,
            "rating_q025": 1196.582766442964
        },
        "command-r": {
            "rating": 1211.9278795815155,
            "rating_q975": 1219.074775187197,
            "rating_q025": 1204.780983975834
        },
        "phi-3-medium-4k-instruct": {
            "rating": 1209.6669523940814,
            "rating_q975": 1217.7521893295695,
            "rating_q025": 1201.5817154585932
        },
        "mixtral-8x7b-instruct-v0.1": {
            "rating": 1208.0016654383526,
            "rating_q975": 1214.6625205861478,
            "rating_q025": 1201.3408102905573
        },
        "granite-3.0-8b-instruct": {
            "rating": 1200.4744821731401,
            "rating_q975": 1215.3172246890406,
            "rating_q025": 1185.6317396572397
        },
        "qwen1.5-14b-chat": {
            "rating": 1197.7898005566365,
            "rating_q975": 1208.4683182518404,
            "rating_q025": 1187.1112828614325
        },
        "starling-lm-7b-beta": {
            "rating": 1192.4987649675625,
            "rating_q975": 1203.2641164859829,
            "rating_q025": 1181.733413449142
        },
        "gemma-1.1-7b-it": {
            "rating": 1189.0749766641911,
            "rating_q975": 1197.6231785517384,
            "rating_q025": 1180.5267747766438
        },
        "phi-3-small-8k-instruct": {
            "rating": 1185.3327889036595,
            "rating_q975": 1194.8489977560016,
            "rating_q025": 1175.8165800513175
        },
        "tulu-2-dpo-70b": {
            "rating": 1184.843512143854,
            "rating_q975": 1201.3131603010359,
            "rating_q025": 1168.3738639866722
        },
        "snowflake-arctic-instruct": {
            "rating": 1184.080906553595,
            "rating_q975": 1193.1847214858171,
            "rating_q025": 1174.977091621373
        },
        "openchat-3.5-0106": {
            "rating": 1183.9170089956165,
            "rating_q975": 1195.1418971227051,
            "rating_q025": 1172.6921208685278
        },
        "gemma-2-2b-it": {
            "rating": 1182.513716988925,
            "rating_q975": 1188.836226167746,
            "rating_q025": 1176.1912078101038
        },
        "yi-34b-chat": {
            "rating": 1181.0994262047939,
            "rating_q975": 1191.657651059315,
            "rating_q025": 1170.5412013502728
        },
        "openhermes-2.5-mistral-7b": {
            "rating": 1177.261946036932,
            "rating_q975": 1194.238766017248,
            "rating_q025": 1160.2851260566158
        },
        "granite-3.0-2b-instruct": {
            "rating": 1174.2126770018283,
            "rating_q975": 1188.9090403538232,
            "rating_q025": 1159.5163136498334
        },
        "deepseek-llm-67b-chat": {
            "rating": 1172.4505270529648,
            "rating_q975": 1191.0484704976732,
            "rating_q025": 1153.8525836082565
        },
        "phi-3-mini-4k-instruct-june-2024": {
            "rating": 1172.4438217146208,
            "rating_q975": 1183.2642210065771,
            "rating_q025": 1161.6234224226644
        },
        "openchat-3.5": {
            "rating": 1172.2162480845805,
            "rating_q975": 1188.0253185174781,
            "rating_q025": 1156.4071776516828
        },
        "wizardlm-70b": {
            "rating": 1169.729560921674,
            "rating_q975": 1185.0407421875607,
            "rating_q025": 1154.4183796557872
        },
        "qwq-32b-preview": {
            "rating": 1166.4623835378854,
            "rating_q975": 1185.94955489971,
            "rating_q025": 1146.975212176061
        },
        "llama-3.2-3b-instruct": {
            "rating": 1166.1898838254137,
            "rating_q975": 1178.7199070701154,
            "rating_q025": 1153.6598605807121
        },
        "starling-lm-7b-alpha": {
            "rating": 1165.5459327908789,
            "rating_q975": 1178.2569761960256,
            "rating_q025": 1152.8348893857321
        },
        "vicuna-33b": {
            "rating": 1160.766520972158,
            "rating_q975": 1170.8330387102228,
            "rating_q025": 1150.7000032340934
        },
        "llama-2-70b-chat": {
            "rating": 1157.181223223016,
            "rating_q975": 1165.3401978076931,
            "rating_q025": 1149.022248638339
        },
        "solar-10.7b-instruct-v1.0": {
            "rating": 1155.0862452127335,
            "rating_q975": 1174.8673426987314,
            "rating_q025": 1135.3051477267356
        },
        "codellama-70b-instruct": {
            "rating": 1155.0755943409463,
            "rating_q975": 1186.356516515536,
            "rating_q025": 1123.7946721663566
        },
        "mistral-7b-instruct-v0.2": {
            "rating": 1153.9631363479975,
            "rating_q975": 1163.648035489125,
            "rating_q025": 1144.27823720687
        },
        "mpt-30b-chat": {
            "rating": 1153.1561829026691,
            "rating_q975": 1180.1996165607748,
            "rating_q025": 1126.1127492445635
        },
        "dolphin-2.2.1-mistral-7b": {
            "rating": 1152.5399141537782,
            "rating_q975": 1180.4017062659461,
            "rating_q025": 1124.6781220416103
        },
        "smollm2-1.7b-instruct": {
            "rating": 1150.7023423695778,
            "rating_q975": 1175.3808570263795,
            "rating_q025": 1126.023827712776
        },
        "gemma-7b-it": {
            "rating": 1150.0182416121345,
            "rating_q975": 1163.5874569405162,
            "rating_q025": 1136.4490262837528
        },
        "phi-3-mini-4k-instruct": {
            "rating": 1148.7391629527337,
            "rating_q975": 1158.3036802662061,
            "rating_q025": 1139.1746456392614
        },
        "qwen1.5-7b-chat": {
            "rating": 1147.698184769406,
            "rating_q975": 1163.369520980173,
            "rating_q025": 1132.026848558639
        },
        "llama2-70b-steerlm-chat": {
            "rating": 1142.9821704874182,
            "rating_q975": 1163.6175245728532,
            "rating_q025": 1122.3468164019832
        },
        "palm-2": {
            "rating": 1141.6504869075181,
            "rating_q975": 1157.2307931737669,
            "rating_q025": 1126.0701806412694
        },
        "qwen-14b-chat": {
            "rating": 1138.1056991847454,
            "rating_q975": 1157.1821693518555,
            "rating_q025": 1119.0292290176353
        },
        "llama-2-13b-chat": {
            "rating": 1136.0595506219247,
            "rating_q975": 1146.3665430576461,
            "rating_q025": 1125.7525581862033
        },
        "gemma-1.1-2b-it": {
            "rating": 1133.5173080280879,
            "rating_q975": 1145.35657824598,
            "rating_q025": 1121.6780378101957
        },
        "codellama-34b-instruct": {
            "rating": 1129.5097408695137,
            "rating_q975": 1144.3142203398922,
            "rating_q025": 1114.7052613991352
        },
        "vicuna-13b": {
            "rating": 1127.8636880537556,
            "rating_q975": 1138.5843262207975,
            "rating_q025": 1117.1430498867137
        },
        "phi-3-mini-128k-instruct": {
            "rating": 1127.6507239102987,
            "rating_q975": 1138.5309386179495,
            "rating_q025": 1116.7705092026479
        },
        "nous-hermes-2-mixtral-8x7b-dpo": {
            "rating": 1126.6792599234295,
            "rating_q975": 1144.4635042429597,
            "rating_q025": 1108.8950156038993
        },
        "falcon-180b-chat": {
            "rating": 1122.7574837070188,
            "rating_q975": 1158.4790433600533,
            "rating_q025": 1087.0359240539842
        },
        "zephyr-7b-alpha": {
            "rating": 1120.5743662498478,
            "rating_q975": 1150.3955269003757,
            "rating_q025": 1090.75320559932
        },
        "zephyr-7b-beta": {
            "rating": 1113.2653361860412,
            "rating_q975": 1127.7049404506154,
            "rating_q025": 1098.825731921467
        },
        "llama-3.2-1b-instruct": {
            "rating": 1111.6073204557565,
            "rating_q975": 1124.5141541578935,
            "rating_q025": 1098.7004867536195
        },
        "mistral-7b-instruct": {
            "rating": 1111.082879161022,
            "rating_q975": 1126.4587582145107,
            "rating_q025": 1095.7070001075333
        },
        "wizardlm-13b": {
            "rating": 1110.688802852154,
            "rating_q975": 1127.3426116793144,
            "rating_q025": 1094.0349940249935
        },
        "gemma-2b-it": {
            "rating": 1107.5954442309198,
            "rating_q975": 1125.2666599736306,
            "rating_q025": 1089.924228488209
        },
        "stripedhyena-nous-7b": {
            "rating": 1104.1856935406845,
            "rating_q975": 1121.2329262173937,
            "rating_q025": 1087.1384608639753
        },
        "vicuna-7b": {
            "rating": 1100.8200958512496,
            "rating_q975": 1117.904003319464,
            "rating_q025": 1083.7361883830351
        },
        "guanaco-33b": {
            "rating": 1099.9739562647483,
            "rating_q975": 1125.7788007631536,
            "rating_q025": 1074.169111766343
        },
        "llama-2-7b-chat": {
            "rating": 1093.507173309073,
            "rating_q975": 1104.4122257973609,
            "rating_q025": 1082.6021208207853
        },
        "qwen1.5-4b-chat": {
            "rating": 1091.0679203850145,
            "rating_q975": 1105.276627936959,
            "rating_q025": 1076.8592128330702
        },
        "olmo-7b-instruct": {
            "rating": 1066.5845966930824,
            "rating_q975": 1083.5244186104064,
            "rating_q025": 1049.6447747757584
        },
        "gpt4all-13b-snoozy": {
            "rating": 1058.194567975465,
            "rating_q975": 1088.916963108041,
            "rating_q025": 1027.4721728428888
        },
        "chatglm3-6b": {
            "rating": 1056.3519395046987,
            "rating_q975": 1076.4489362326246,
            "rating_q025": 1036.2549427767729
        },
        "koala-13b": {
            "rating": 1028.5424118216008,
            "rating_q975": 1047.1539813841682,
            "rating_q025": 1009.9308422590335
        },
        "mpt-7b-chat": {
            "rating": 1026.9119344064702,
            "rating_q975": 1049.1997949786723,
            "rating_q025": 1004.6240738342682
        },
        "chatglm2-6b": {
            "rating": 1023.5640341712794,
            "rating_q975": 1050.6234145367243,
            "rating_q025": 996.5046538058344
        },
        "oasst-pythia-12b": {
            "rating": 1016.6526360017572,
            "rating_q975": 1035.8764920646483,
            "rating_q025": 997.4287799388659
        },
        "RWKV-4-Raven-14B": {
            "rating": 1010.940827890164,
            "rating_q975": 1032.012853625867,
            "rating_q025": 989.868802154461
        },
        "alpaca-13b": {
            "rating": 1001.7878034353508,
            "rating_q975": 1021.9127465964457,
            "rating_q025": 981.662860274256
        },
        "chatglm-6b": {
            "rating": 995.2113946646539,
            "rating_q975": 1017.189598996048,
            "rating_q025": 973.2331903332598
        },
        "dolly-v2-12b": {
            "rating": 965.5698061849221,
            "rating_q975": 990.3762078334223,
            "rating_q025": 940.7634045364218
        },
        "stablelm-tuned-alpha-7b": {
            "rating": 937.4756846954202,
            "rating_q975": 962.297125751002,
            "rating_q025": 912.6542436398385
        },
        "fastchat-t5-3b": {
            "rating": 932.6683415068479,
            "rating_q975": 954.4582644008498,
            "rating_q025": 910.8784186128461
        },
        "llama-13b": {
            "rating": 909.6885784501715,
            "rating_q975": 940.9183585026243,
            "rating_q025": 878.4587983977186
        }
    },
    "hard_english_6": {
        "claude-opus-4-5-20251101-thinking-32k": {
            "rating": 1514.191877331506,
            "rating_q975": 1526.624470339732,
            "rating_q025": 1501.75928432328
        },
        "gemini-3-pro": {
            "rating": 1498.9222242897465,
            "rating_q975": 1509.1085760233077,
            "rating_q025": 1488.7358725561853
        },
        "claude-sonnet-4-5-20250929-thinking-32k": {
            "rating": 1497.6337740783194,
            "rating_q975": 1505.3277793615214,
            "rating_q025": 1489.9397687951175
        },
        "claude-opus-4-5-20251101": {
            "rating": 1497.2587472387138,
            "rating_q975": 1509.269628925535,
            "rating_q025": 1485.2478655518926
        },
        "claude-opus-4-1-20250805-thinking-16k": {
            "rating": 1491.039304351712,
            "rating_q975": 1497.5269324892868,
            "rating_q025": 1484.5516762141372
        },
        "grok-4.1-thinking": {
            "rating": 1490.48149154149,
            "rating_q975": 1500.4586566169557,
            "rating_q025": 1480.5043264660242
        },
        "grok-4.1": {
            "rating": 1481.8937616510757,
            "rating_q975": 1491.96859073181,
            "rating_q025": 1471.8189325703413
        },
        "claude-sonnet-4-5-20250929": {
            "rating": 1481.3780950835132,
            "rating_q975": 1489.8187548194257,
            "rating_q025": 1472.9374353476007
        },
        "claude-opus-4-1-20250805": {
            "rating": 1477.7608210130506,
            "rating_q975": 1483.8498866069413,
            "rating_q025": 1471.67175541916
        },
        "gpt-5.1-high": {
            "rating": 1476.421669402897,
            "rating_q975": 1487.4180611268791,
            "rating_q025": 1465.4252776789147
        },
        "gemini-2.5-pro": {
            "rating": 1460.813751506918,
            "rating_q975": 1466.4092006355995,
            "rating_q025": 1455.2183023782363
        },
        "kimi-k2-thinking-turbo": {
            "rating": 1460.7011683464684,
            "rating_q975": 1470.513266220289,
            "rating_q025": 1450.8890704726477
        },
        "claude-opus-4-20250514-thinking-16k": {
            "rating": 1460.5125092327478,
            "rating_q975": 1467.678973254926,
            "rating_q025": 1453.3460452105696
        },
        "gpt-5.1": {
            "rating": 1459.5341080541314,
            "rating_q975": 1469.8652159139344,
            "rating_q025": 1449.2030001943283
        },
        "deepseek-v3.2-exp-thinking": {
            "rating": 1458.5072149041594,
            "rating_q975": 1470.7071812144166,
            "rating_q025": 1446.3072485939022
        },
        "qwen3-max-preview": {
            "rating": 1457.6237684132511,
            "rating_q975": 1465.324320884274,
            "rating_q025": 1449.9232159422284
        },
        "gpt-5-high": {
            "rating": 1454.476746719685,
            "rating_q975": 1462.10281698659,
            "rating_q025": 1446.8506764527801
        },
        "deepseek-v3.2-exp": {
            "rating": 1454.4271798569964,
            "rating_q975": 1465.1883337116258,
            "rating_q025": 1443.666026002367
        },
        "chatgpt-4o-latest-20250326": {
            "rating": 1453.7612765949564,
            "rating_q975": 1459.4030291048148,
            "rating_q025": 1448.119524085098
        },
        "claude-haiku-4-5-20251001": {
            "rating": 1453.1203152629237,
            "rating_q975": 1460.8705824504543,
            "rating_q025": 1445.370048075393
        },
        "qwen3-vl-235b-a22b-instruct": {
            "rating": 1452.747428622173,
            "rating_q975": 1465.1935881634404,
            "rating_q025": 1440.3012690809055
        },
        "glm-4.6": {
            "rating": 1452.4535535633029,
            "rating_q975": 1460.3835945439357,
            "rating_q025": 1444.52351258267
        },
        "qwen3-max-2025-09-23": {
            "rating": 1451.9318782076796,
            "rating_q975": 1463.6825694446036,
            "rating_q025": 1440.1811869707556
        },
        "qwen3-235b-a22b-instruct-2507": {
            "rating": 1450.940509880075,
            "rating_q975": 1457.110410542272,
            "rating_q025": 1444.7706092178782
        },
        "deepseek-v3.2": {
            "rating": 1450.650105746283,
            "rating_q975": 1465.2179881676548,
            "rating_q025": 1436.0822233249114
        },
        "deepseek-v3.2-thinking": {
            "rating": 1450.479770853473,
            "rating_q975": 1465.7247415247693,
            "rating_q025": 1435.2348001821765
        },
        "grok-4-1-fast-reasoning": {
            "rating": 1448.6602210324475,
            "rating_q975": 1460.966920633305,
            "rating_q025": 1436.3535214315898
        },
        "deepseek-v3.1-thinking": {
            "rating": 1447.8700077180608,
            "rating_q975": 1459.9074875129222,
            "rating_q025": 1435.8325279231995
        },
        "gpt-5-chat": {
            "rating": 1446.6917386019575,
            "rating_q975": 1453.962491778527,
            "rating_q025": 1439.420985425388
        },
        "o3-2025-04-16": {
            "rating": 1446.580318674827,
            "rating_q975": 1452.556470914368,
            "rating_q025": 1440.6041664352858
        },
        "claude-sonnet-4-20250514-thinking-32k": {
            "rating": 1445.0693652493271,
            "rating_q975": 1452.2429110884839,
            "rating_q025": 1437.8958194101704
        },
        "ernie-5.0-preview-1103": {
            "rating": 1444.0362270360483,
            "rating_q975": 1459.1723865603503,
            "rating_q025": 1428.9000675117463
        },
        "mistral-large-3": {
            "rating": 1442.8490584714182,
            "rating_q975": 1457.1017910803694,
            "rating_q025": 1428.596325862467
        },
        "deepseek-v3.1-terminus-thinking": {
            "rating": 1442.2206045878897,
            "rating_q975": 1462.41857169546,
            "rating_q025": 1422.0226374803194
        },
        "gpt-4.5-preview-2025-02-27": {
            "rating": 1441.9231605874947,
            "rating_q975": 1454.1218395224998,
            "rating_q025": 1429.7244816524897
        },
        "grok-4-fast-chat": {
            "rating": 1440.5434233751278,
            "rating_q975": 1455.6057683194604,
            "rating_q025": 1425.4810784307952
        },
        "mistral-medium-2508": {
            "rating": 1439.39765338089,
            "rating_q975": 1445.814532235016,
            "rating_q025": 1432.980774526764
        },
        "deepseek-r1-0528": {
            "rating": 1439.3882046263398,
            "rating_q975": 1449.5696760538176,
            "rating_q025": 1429.206733198862
        },
        "claude-opus-4-20250514": {
            "rating": 1438.4307717053882,
            "rating_q975": 1445.1978616561676,
            "rating_q025": 1431.663681754609
        },
        "longcat-flash-chat": {
            "rating": 1437.9572536976627,
            "rating_q975": 1449.1602360990298,
            "rating_q025": 1426.7542712962957
        },
        "kimi-k2-0905-preview": {
            "rating": 1435.9380292184555,
            "rating_q975": 1447.4139152499984,
            "rating_q025": 1424.4621431869127
        },
        "gpt-4.1-2025-04-14": {
            "rating": 1435.612012262238,
            "rating_q975": 1441.7645736741158,
            "rating_q025": 1429.4594508503603
        },
        "deepseek-v3.1": {
            "rating": 1434.0748819859034,
            "rating_q975": 1444.507639620171,
            "rating_q025": 1423.6421243516359
        },
        "grok-3-preview-02-24": {
            "rating": 1433.6241715525277,
            "rating_q975": 1441.5353216923816,
            "rating_q025": 1425.713021412674
        },
        "glm-4.5": {
            "rating": 1432.9728515297465,
            "rating_q975": 1441.2803617089057,
            "rating_q025": 1424.6653413505874
        },
        "kimi-k2-0711-preview": {
            "rating": 1430.6496664819658,
            "rating_q975": 1438.6155526005537,
            "rating_q025": 1422.683780363378
        },
        "deepseek-r1": {
            "rating": 1430.577204888333,
            "rating_q975": 1441.6617336177924,
            "rating_q025": 1419.4926761588736
        },
        "qwen3-next-80b-a3b-instruct": {
            "rating": 1428.7982552892386,
            "rating_q975": 1436.8856770053847,
            "rating_q025": 1420.7108335730925
        },
        "qwen3-235b-a22b-thinking-2507": {
            "rating": 1427.973259712712,
            "rating_q975": 1441.0818996034186,
            "rating_q025": 1414.8646198220054
        },
        "deepseek-v3.1-terminus": {
            "rating": 1427.8204087830131,
            "rating_q975": 1446.174003713998,
            "rating_q025": 1409.4668138520283
        },
        "claude-3-7-sonnet-20250219-thinking-32k": {
            "rating": 1427.2766511803152,
            "rating_q975": 1434.5421823793286,
            "rating_q025": 1420.0111199813018
        },
        "qwen3-coder-480b-a35b-instruct": {
            "rating": 1424.653427045438,
            "rating_q975": 1433.0589999806962,
            "rating_q025": 1416.24785411018
        },
        "grok-4-0709": {
            "rating": 1423.037522728233,
            "rating_q975": 1429.5169676320772,
            "rating_q025": 1416.5580778243886
        },
        "claude-sonnet-4-20250514": {
            "rating": 1422.5192648629666,
            "rating_q975": 1429.4252982662022,
            "rating_q025": 1415.613231459731
        },
        "grok-4-fast-reasoning": {
            "rating": 1422.3734071080432,
            "rating_q975": 1431.0102403341637,
            "rating_q025": 1413.7365738819228
        },
        "hunyuan-vision-1.5-thinking": {
            "rating": 1421.6672095306894,
            "rating_q975": 1445.302185548298,
            "rating_q025": 1398.0322335130809
        },
        "gemini-2.5-flash-preview-09-2025": {
            "rating": 1420.5765716520307,
            "rating_q975": 1428.0443194276306,
            "rating_q025": 1413.1088238764307
        },
        "o1-2024-12-17": {
            "rating": 1419.965229579895,
            "rating_q975": 1429.2003687654262,
            "rating_q025": 1410.730090394364
        },
        "qwen3-vl-235b-a22b-thinking": {
            "rating": 1417.4440679321935,
            "rating_q975": 1430.2392231852523,
            "rating_q025": 1404.6489126791348
        },
        "o4-mini-2025-04-16": {
            "rating": 1417.3655732245961,
            "rating_q975": 1423.8108144872035,
            "rating_q025": 1410.9203319619887
        },
        "qwen3-235b-a22b-no-thinking": {
            "rating": 1417.072132188325,
            "rating_q975": 1424.167457879717,
            "rating_q025": 1409.976806496933
        },
        "deepseek-v3-0324": {
            "rating": 1416.7934465458254,
            "rating_q975": 1423.250409976039,
            "rating_q025": 1410.3364831156118
        },
        "qwen3-30b-a3b-instruct-2507": {
            "rating": 1416.2852845449358,
            "rating_q975": 1424.6063190999203,
            "rating_q025": 1407.9642499899514
        },
        "gemini-2.5-flash": {
            "rating": 1416.0277837405804,
            "rating_q975": 1421.5701116260016,
            "rating_q025": 1410.4854558551592
        },
        "mai-1-preview": {
            "rating": 1414.3678524656634,
            "rating_q975": 1423.9167438786137,
            "rating_q025": 1404.8189610527131
        },
        "gpt-5-mini-high": {
            "rating": 1411.7183689742894,
            "rating_q975": 1419.8447766770048,
            "rating_q025": 1403.591961271574
        },
        "gpt-4.1-mini-2025-04-14": {
            "rating": 1411.7019617852839,
            "rating_q975": 1418.6913862831195,
            "rating_q025": 1404.7125372874482
        },
        "o3-mini-high": {
            "rating": 1411.0025524599216,
            "rating_q975": 1421.7742679102594,
            "rating_q025": 1400.2308370095839
        },
        "o1-preview": {
            "rating": 1410.225461455912,
            "rating_q975": 1419.5168913579255,
            "rating_q025": 1400.9340315538984
        },
        "mistral-medium-2505": {
            "rating": 1406.8975421681273,
            "rating_q975": 1414.3209847351789,
            "rating_q025": 1399.4740996010757
        },
        "amazon-nova-experimental-chat-10-20": {
            "rating": 1404.8271799771649,
            "rating_q975": 1417.8283744210385,
            "rating_q025": 1391.8259855332913
        },
        "qwen3-235b-a22b": {
            "rating": 1402.3057359953973,
            "rating_q975": 1410.3008845326585,
            "rating_q025": 1394.310587458136
        },
        "glm-4.5-air": {
            "rating": 1402.2563163155642,
            "rating_q975": 1409.443588493827,
            "rating_q025": 1395.0690441373013
        },
        "claude-3-5-sonnet-20241022": {
            "rating": 1401.1807124557383,
            "rating_q975": 1406.351546161706,
            "rating_q025": 1396.0098787497707
        },
        "claude-3-7-sonnet-20250219": {
            "rating": 1400.8219942129406,
            "rating_q975": 1407.6813379078314,
            "rating_q025": 1393.9626505180497
        },
        "step-3": {
            "rating": 1400.5208324674722,
            "rating_q975": 1415.5624896464267,
            "rating_q025": 1385.4791752885178
        },
        "gemini-2.5-flash-lite-preview-09-2025-no-thinking": {
            "rating": 1399.9203472749641,
            "rating_q975": 1407.296130339882,
            "rating_q025": 1392.5445642100462
        },
        "minimax-m1": {
            "rating": 1397.755431334569,
            "rating_q975": 1404.7519947539479,
            "rating_q025": 1390.7588679151902
        },
        "hunyuan-t1-20250711": {
            "rating": 1397.221726750769,
            "rating_q975": 1416.3339290950566,
            "rating_q025": 1378.1095244064813
        },
        "intellect-3": {
            "rating": 1396.4536166968562,
            "rating_q975": 1419.6267356774554,
            "rating_q025": 1373.280497716257
        },
        "qwen3-next-80b-a3b-thinking": {
            "rating": 1395.3418807319408,
            "rating_q975": 1405.5216767277093,
            "rating_q025": 1385.1620847361723
        },
        "llama-3.1-nemotron-ultra-253b-v1": {
            "rating": 1394.3053811341374,
            "rating_q975": 1421.188922467582,
            "rating_q025": 1367.4218398006929
        },
        "mistral-small-2506": {
            "rating": 1394.1281377178677,
            "rating_q975": 1403.2913247763586,
            "rating_q025": 1384.9649506593769
        },
        "ling-flash-2.0": {
            "rating": 1394.085076034826,
            "rating_q975": 1407.6097198510674,
            "rating_q025": 1380.5604322185845
        },
        "glm-4.5v": {
            "rating": 1392.7227792261137,
            "rating_q975": 1409.5596522849528,
            "rating_q025": 1375.8859061672747
        },
        "hunyuan-turbos-20250416": {
            "rating": 1390.1457534263147,
            "rating_q975": 1402.6494717761384,
            "rating_q025": 1377.642035076491
        },
        "qwen2.5-max": {
            "rating": 1386.4050832771973,
            "rating_q975": 1393.9820175783539,
            "rating_q025": 1378.8281489760407
        },
        "nova-2-lite": {
            "rating": 1385.911677013351,
            "rating_q975": 1401.1336249312074,
            "rating_q025": 1370.6897290954946
        },
        "llama-3.3-nemotron-49b-super-v1": {
            "rating": 1384.436917584473,
            "rating_q975": 1413.708272783336,
            "rating_q025": 1355.1655623856097
        },
        "minimax-m2": {
            "rating": 1383.6912123751524,
            "rating_q975": 1397.2183854458603,
            "rating_q025": 1370.1640393044445
        },
        "gemini-2.5-flash-lite-preview-06-17-thinking": {
            "rating": 1383.2577839979376,
            "rating_q975": 1390.6705991956983,
            "rating_q025": 1375.844968800177
        },
        "amazon-nova-experimental-chat-10-09": {
            "rating": 1382.5006346646712,
            "rating_q975": 1393.9906354047127,
            "rating_q025": 1371.0106339246297
        },
        "o3-mini": {
            "rating": 1381.2990095006398,
            "rating_q975": 1387.2685981392412,
            "rating_q025": 1375.3294208620384
        },
        "grok-3-mini-high": {
            "rating": 1381.1416391101848,
            "rating_q975": 1390.6087714656987,
            "rating_q025": 1371.6745067546708
        },
        "grok-3-mini-beta": {
            "rating": 1381.1208475004862,
            "rating_q975": 1389.456865147405,
            "rating_q025": 1372.7848298535673
        },
        "qwen3-32b": {
            "rating": 1379.9636439205917,
            "rating_q975": 1400.8535270018242,
            "rating_q025": 1359.0737608393592
        },
        "ring-flash-2.0": {
            "rating": 1378.2470317487541,
            "rating_q975": 1391.7920527412682,
            "rating_q025": 1364.70201075624
        },
        "hunyuan-turbos-20250226": {
            "rating": 1378.0695724708578,
            "rating_q975": 1405.5574259926145,
            "rating_q025": 1350.581718949101
        },
        "nvidia-llama-3.3-nemotron-super-49b-v1.5": {
            "rating": 1373.9209605410597,
            "rating_q975": 1394.6254586813716,
            "rating_q025": 1353.2164624007478
        },
        "command-a-03-2025": {
            "rating": 1373.149344256843,
            "rating_q975": 1379.0159485690015,
            "rating_q025": 1367.2827399446846
        },
        "qwq-32b": {
            "rating": 1372.3479830642168,
            "rating_q975": 1380.5031784476457,
            "rating_q025": 1364.192787680788
        },
        "o1-mini": {
            "rating": 1372.1445279196605,
            "rating_q975": 1379.3292757017286,
            "rating_q025": 1364.9597801375924
        },
        "gpt-oss-120b": {
            "rating": 1367.7852750652603,
            "rating_q975": 1375.1568848133636,
            "rating_q025": 1360.413665317157
        },
        "gpt-5-nano-high": {
            "rating": 1367.5639379701856,
            "rating_q975": 1381.1869512848682,
            "rating_q025": 1353.940924655503
        },
        "gemma-3-27b-it": {
            "rating": 1366.7338816880747,
            "rating_q975": 1373.162943407569,
            "rating_q025": 1360.3048199685804
        },
        "hunyuan-turbo-0110": {
            "rating": 1365.2994942370447,
            "rating_q975": 1392.7523186603303,
            "rating_q025": 1337.846669813759
        },
        "qwen-plus-0125": {
            "rating": 1365.0506354655813,
            "rating_q975": 1382.4478847961518,
            "rating_q025": 1347.6533861350108
        },
        "gemini-2.0-flash-001": {
            "rating": 1363.9491697365156,
            "rating_q975": 1370.6995159378969,
            "rating_q025": 1357.1988235351344
        },
        "claude-3-5-sonnet-20240620": {
            "rating": 1363.2043201021593,
            "rating_q975": 1369.849350864456,
            "rating_q025": 1356.5592893398625
        },
        "olmo-3-32b-think": {
            "rating": 1362.9122908928175,
            "rating_q975": 1383.5146401368092,
            "rating_q025": 1342.3099416488258
        },
        "qwen3-30b-a3b": {
            "rating": 1361.1245152348993,
            "rating_q975": 1369.2303760838993,
            "rating_q025": 1353.0186543858993
        },
        "deepseek-v3": {
            "rating": 1359.3450485431067,
            "rating_q975": 1368.8786536421694,
            "rating_q025": 1349.811443444044
        },
        "llama-3.1-405b-instruct-bf16": {
            "rating": 1358.159902661539,
            "rating_q975": 1365.2548200830379,
            "rating_q025": 1351.0649852400402
        },
        "yi-lightning": {
            "rating": 1357.8043648256203,
            "rating_q975": 1367.4557770978433,
            "rating_q025": 1348.1529525533972
        },
        "claude-3-5-haiku-20241022": {
            "rating": 1353.010743346882,
            "rating_q975": 1358.6841249198412,
            "rating_q025": 1347.3373617739228
        },
        "gemini-2.0-flash-lite-preview-02-05": {
            "rating": 1352.046276963556,
            "rating_q975": 1360.8982541941784,
            "rating_q025": 1343.1942997329336
        },
        "gemini-1.5-pro-002": {
            "rating": 1351.5746183434385,
            "rating_q975": 1358.10582133174,
            "rating_q025": 1345.043415355137
        },
        "llama-4-maverick-17b-128e-instruct": {
            "rating": 1351.000106475013,
            "rating_q975": 1358.0131939257644,
            "rating_q025": 1343.9870190242614
        },
        "magistral-medium-2506": {
            "rating": 1350.7272416079209,
            "rating_q975": 1362.3166845945204,
            "rating_q025": 1339.1377986213213
        },
        "mercury": {
            "rating": 1350.6416870087694,
            "rating_q975": 1376.3386131072798,
            "rating_q025": 1324.944760910259
        },
        "llama-3.1-405b-instruct-fp8": {
            "rating": 1349.8928303612254,
            "rating_q975": 1356.7527475318864,
            "rating_q025": 1343.0329131905644
        },
        "llama-4-scout-17b-16e-instruct": {
            "rating": 1347.80917640334,
            "rating_q975": 1355.5758508884196,
            "rating_q025": 1340.0425019182603
        },
        "step-1o-turbo-202506": {
            "rating": 1346.9680038078513,
            "rating_q975": 1360.1264953766379,
            "rating_q025": 1333.8095122390648
        },
        "gpt-4o-2024-05-13": {
            "rating": 1345.484381612713,
            "rating_q975": 1351.6211909166727,
            "rating_q025": 1339.3475723087531
        },
        "athene-v2-chat": {
            "rating": 1343.8866131753011,
            "rating_q975": 1352.8394264285391,
            "rating_q025": 1334.9337999220631
        },
        "step-2-16k-exp-202412": {
            "rating": 1343.6687665515233,
            "rating_q975": 1362.1951586664773,
            "rating_q025": 1325.1423744365693
        },
        "qwen2.5-plus-1127": {
            "rating": 1342.370695229998,
            "rating_q975": 1355.349609632061,
            "rating_q025": 1329.3917808279352
        },
        "gpt-oss-20b": {
            "rating": 1340.2646762388165,
            "rating_q975": 1352.6829403217673,
            "rating_q025": 1327.8464121558657
        },
        "hunyuan-large-2025-02-10": {
            "rating": 1337.3688462917116,
            "rating_q975": 1360.149449725132,
            "rating_q025": 1314.5882428582913
        },
        "gpt-4.1-nano-2025-04-14": {
            "rating": 1337.0327071021793,
            "rating_q975": 1354.2365846296918,
            "rating_q025": 1319.8288295746668
        },
        "gemma-3-12b-it": {
            "rating": 1335.851949524838,
            "rating_q975": 1356.70828775666,
            "rating_q025": 1314.9956112930158
        },
        "gpt-4o-2024-08-06": {
            "rating": 1335.7882077313425,
            "rating_q975": 1343.2840635946045,
            "rating_q025": 1328.2923518680805
        },
        "deepseek-v2.5-1210": {
            "rating": 1335.438560593937,
            "rating_q975": 1351.6655482808455,
            "rating_q025": 1319.2115729070283
        },
        "llama-3.3-70b-instruct": {
            "rating": 1335.2504250967636,
            "rating_q975": 1341.222507503641,
            "rating_q025": 1329.2783426898861
        },
        "mistral-small-3.1-24b-instruct-2503": {
            "rating": 1334.0238981359175,
            "rating_q975": 1341.365273607211,
            "rating_q025": 1326.682522664624
        },
        "mistral-large-2407": {
            "rating": 1331.0711013523314,
            "rating_q975": 1338.5318629590577,
            "rating_q025": 1323.6103397456052
        },
        "grok-2-2024-08-13": {
            "rating": 1328.0512273884137,
            "rating_q975": 1334.6018030598457,
            "rating_q025": 1321.5006517169818
        },
        "deepseek-v2.5": {
            "rating": 1327.8625353908085,
            "rating_q975": 1337.0144108863033,
            "rating_q025": 1318.7106598953137
        },
        "gemini-1.5-pro-001": {
            "rating": 1327.35043700818,
            "rating_q975": 1334.3911260778548,
            "rating_q025": 1320.3097479385053
        },
        "qwen-max-0919": {
            "rating": 1326.9728904589547,
            "rating_q975": 1338.1551728991249,
            "rating_q025": 1315.7906080187845
        },
        "gpt-4-turbo-2024-04-09": {
            "rating": 1326.3810737042477,
            "rating_q975": 1333.1276937847713,
            "rating_q025": 1319.634453623724
        },
        "gemini-advanced-0514": {
            "rating": 1325.3093275624767,
            "rating_q975": 1333.9302382908422,
            "rating_q025": 1316.6884168341112
        },
        "qwen2.5-72b-instruct": {
            "rating": 1324.8846760131387,
            "rating_q975": 1332.463760608884,
            "rating_q025": 1317.3055914173933
        },
        "glm-4-plus": {
            "rating": 1323.9976879833455,
            "rating_q975": 1333.4527998710107,
            "rating_q025": 1314.5425760956803
        },
        "llama-3.1-nemotron-70b-instruct": {
            "rating": 1323.8615242603782,
            "rating_q975": 1340.5719195105876,
            "rating_q025": 1307.151129010169
        },
        "claude-3-opus-20240229": {
            "rating": 1322.6146816304538,
            "rating_q975": 1328.2050977764109,
            "rating_q025": 1317.0242654844967
        },
        "hunyuan-large-vision": {
            "rating": 1322.405471079805,
            "rating_q975": 1339.0796295582222,
            "rating_q025": 1305.7313126013878
        },
        "glm-4-plus-0111": {
            "rating": 1322.1758922266108,
            "rating_q975": 1339.8135754440348,
            "rating_q025": 1304.5382090091869
        },
        "hunyuan-standard-2025-02-10": {
            "rating": 1321.7591430588675,
            "rating_q975": 1345.2456091082663,
            "rating_q025": 1298.2726770094687
        },
        "gpt-4-1106-preview": {
            "rating": 1321.417586955702,
            "rating_q975": 1328.313951289099,
            "rating_q025": 1314.5212226223052
        },
        "mistral-large-2411": {
            "rating": 1321.343419115091,
            "rating_q975": 1329.761506962256,
            "rating_q025": 1312.925331267926
        },
        "athene-70b-0725": {
            "rating": 1321.1037271449663,
            "rating_q975": 1331.0793806490426,
            "rating_q025": 1311.12807364089
        },
        "gpt-4o-mini-2024-07-18": {
            "rating": 1318.5316283738157,
            "rating_q975": 1324.6632510874538,
            "rating_q025": 1312.4000056601776
        },
        "gemma-3n-e4b-it": {
            "rating": 1317.8053532340946,
            "rating_q975": 1326.9076579936204,
            "rating_q025": 1308.7030484745687
        },
        "qwen2.5-coder-32b-instruct": {
            "rating": 1316.1915292390822,
            "rating_q975": 1335.878036654652,
            "rating_q025": 1296.5050218235124
        },
        "gpt-4-0125-preview": {
            "rating": 1315.890810524901,
            "rating_q975": 1322.941676303243,
            "rating_q025": 1308.8399447465592
        },
        "grok-2-mini-2024-08-13": {
            "rating": 1312.0669400090187,
            "rating_q975": 1318.9568654513012,
            "rating_q025": 1305.1770145667363
        },
        "llama-3.1-70b-instruct": {
            "rating": 1311.6887485500497,
            "rating_q975": 1318.5921221148512,
            "rating_q025": 1304.7853749852482
        },
        "amazon-nova-pro-v1.0": {
            "rating": 1311.4847646546157,
            "rating_q975": 1320.1459584706902,
            "rating_q025": 1302.8235708385412
        },
        "gemini-1.5-flash-002": {
            "rating": 1310.6293791301598,
            "rating_q975": 1318.665772750186,
            "rating_q025": 1302.5929855101335
        },
        "gpt-4-0314": {
            "rating": 1309.7949608559827,
            "rating_q975": 1318.5870706129642,
            "rating_q025": 1301.0028510990012
        },
        "llama-3-70b-instruct": {
            "rating": 1306.709745555976,
            "rating_q975": 1313.2356131138113,
            "rating_q025": 1300.1838779981408
        },
        "gpt-4-0613": {
            "rating": 1296.6677048446402,
            "rating_q975": 1304.143155929063,
            "rating_q025": 1289.1922537602175
        },
        "olmo-2-0325-32b-instruct": {
            "rating": 1295.595890008837,
            "rating_q975": 1319.2658073861826,
            "rating_q025": 1271.9259726314913
        },
        "deepseek-coder-v2": {
            "rating": 1294.23949149104,
            "rating_q975": 1305.9106728590277,
            "rating_q025": 1282.5683101230525
        },
        "jamba-1.5-large": {
            "rating": 1292.2518577422543,
            "rating_q975": 1306.09187579551,
            "rating_q025": 1278.4118396889985
        },
        "mistral-small-24b-instruct-2501": {
            "rating": 1291.7661687644788,
            "rating_q975": 1303.4635975988836,
            "rating_q025": 1280.0687399300741
        },
        "gemini-1.5-flash-001": {
            "rating": 1289.5198652533418,
            "rating_q975": 1296.7316494344768,
            "rating_q025": 1282.3080810722067
        },
        "llama-3.1-tulu-3-70b": {
            "rating": 1287.974401025164,
            "rating_q975": 1311.3394518577297,
            "rating_q025": 1264.6093501925984
        },
        "phi-4": {
            "rating": 1287.528806369959,
            "rating_q975": 1296.7430639077634,
            "rating_q025": 1278.3145488321547
        },
        "gemma-2-27b-it": {
            "rating": 1284.8527159090681,
            "rating_q975": 1290.928888882196,
            "rating_q025": 1278.7765429359404
        },
        "claude-3-sonnet-20240229": {
            "rating": 1281.9077720223177,
            "rating_q975": 1288.9689511584995,
            "rating_q025": 1274.8465928861358
        },
        "gemma-3-4b-it": {
            "rating": 1281.3026780383657,
            "rating_q975": 1301.9359580068813,
            "rating_q025": 1260.66939806985
        },
        "glm-4-0520": {
            "rating": 1280.9022219330072,
            "rating_q975": 1294.3833780011416,
            "rating_q025": 1267.4210658648728
        },
        "qwen2-72b-instruct": {
            "rating": 1280.374383877218,
            "rating_q975": 1288.9307987519642,
            "rating_q025": 1271.8179690024717
        },
        "reka-core-20240904": {
            "rating": 1278.589447816321,
            "rating_q975": 1292.7447797333082,
            "rating_q025": 1264.4341158993336
        },
        "nemotron-4-340b-instruct": {
            "rating": 1277.1299630469334,
            "rating_q975": 1288.0742606797496,
            "rating_q025": 1266.1856654141172
        },
        "gemma-2-9b-it-simpo": {
            "rating": 1275.623350215381,
            "rating_q975": 1289.4088348882397,
            "rating_q025": 1261.8378655425222
        },
        "amazon-nova-lite-v1.0": {
            "rating": 1275.3734007150365,
            "rating_q975": 1285.4500381915673,
            "rating_q025": 1265.2967632385057
        },
        "hunyuan-standard-256k": {
            "rating": 1274.6765557705312,
            "rating_q975": 1303.055295642103,
            "rating_q025": 1246.2978158989595
        },
        "llama-3.1-nemotron-51b-instruct": {
            "rating": 1274.2612132595548,
            "rating_q975": 1296.6536906337508,
            "rating_q025": 1251.8687358853588
        },
        "c4ai-aya-expanse-32b": {
            "rating": 1272.8028938423354,
            "rating_q975": 1281.903816436921,
            "rating_q025": 1263.7019712477497
        },
        "mistral-large-2402": {
            "rating": 1269.2663681150907,
            "rating_q975": 1277.4249539437371,
            "rating_q025": 1261.1077822864443
        },
        "command-r-plus-08-2024": {
            "rating": 1267.1243379006373,
            "rating_q975": 1280.3070066043163,
            "rating_q025": 1253.9416691969584
        },
        "reka-flash-20240904": {
            "rating": 1266.9819477940207,
            "rating_q975": 1280.845059068739,
            "rating_q025": 1253.1188365193025
        },
        "claude-3-haiku-20240307": {
            "rating": 1265.5676402277425,
            "rating_q975": 1272.0847712223297,
            "rating_q025": 1259.0505092331553
        },
        "ministral-8b-2410": {
            "rating": 1263.5807392507504,
            "rating_q975": 1283.7488054185972,
            "rating_q025": 1243.4126730829037
        },
        "gemini-1.5-flash-8b-001": {
            "rating": 1263.1783841117408,
            "rating_q975": 1271.2570852636936,
            "rating_q025": 1255.099682959788
        },
        "qwen1.5-110b-chat": {
            "rating": 1260.2409443357146,
            "rating_q975": 1270.4856740243506,
            "rating_q025": 1249.9962146470787
        },
        "command-r-08-2024": {
            "rating": 1259.7648755977264,
            "rating_q975": 1272.5908542669183,
            "rating_q025": 1246.9388969285344
        },
        "gemma-2-9b-it": {
            "rating": 1258.0223599586357,
            "rating_q975": 1264.9958112048598,
            "rating_q025": 1251.0489087124115
        },
        "amazon-nova-micro-v1.0": {
            "rating": 1254.078010547938,
            "rating_q975": 1264.0048099172304,
            "rating_q025": 1244.1512111786456
        },
        "internlm2_5-20b-chat": {
            "rating": 1253.9883785940494,
            "rating_q975": 1268.437815173423,
            "rating_q025": 1239.538942014676
        },
        "command-r-plus": {
            "rating": 1253.724628234248,
            "rating_q975": 1261.2098741468894,
            "rating_q025": 1246.2393823216066
        },
        "mixtral-8x22b-instruct-v0.1": {
            "rating": 1251.389684734513,
            "rating_q975": 1259.5325736750674,
            "rating_q025": 1243.2467957939584
        },
        "qwen1.5-72b-chat": {
            "rating": 1248.0738934876717,
            "rating_q975": 1256.933841883931,
            "rating_q025": 1239.2139450914124
        },
        "granite-3.1-8b-instruct": {
            "rating": 1247.7497735768331,
            "rating_q975": 1271.844121358825,
            "rating_q025": 1223.6554257948412
        },
        "jamba-1.5-mini": {
            "rating": 1244.322697539697,
            "rating_q975": 1258.612971271479,
            "rating_q025": 1230.032423807915
        },
        "llama-3-8b-instruct": {
            "rating": 1241.4572852411138,
            "rating_q975": 1248.4983644645524,
            "rating_q025": 1234.4162060176752
        },
        "mistral-medium": {
            "rating": 1239.4226850181808,
            "rating_q975": 1249.1490225822622,
            "rating_q025": 1229.6963474540994
        },
        "reka-flash-21b-20240226-online": {
            "rating": 1239.3080740022688,
            "rating_q975": 1251.78618699207,
            "rating_q025": 1226.8299610124675
        },
        "llama-3.1-8b-instruct": {
            "rating": 1237.5867151994526,
            "rating_q975": 1244.9207520694106,
            "rating_q025": 1230.2526783294945
        },
        "yi-1.5-34b-chat": {
            "rating": 1237.5238036785918,
            "rating_q975": 1247.492677882861,
            "rating_q025": 1227.5549294743225
        },
        "reka-flash-21b-20240226": {
            "rating": 1235.9804367078812,
            "rating_q975": 1246.351392104456,
            "rating_q025": 1225.6094813113064
        },
        "gemini-pro": {
            "rating": 1235.9018406424593,
            "rating_q975": 1255.3639470217836,
            "rating_q025": 1216.439734263135
        },
        "gpt-3.5-turbo-0125": {
            "rating": 1235.2805050768577,
            "rating_q975": 1242.8542334835388,
            "rating_q025": 1227.7067766701766
        },
        "gpt-3.5-turbo-1106": {
            "rating": 1235.100453502829,
            "rating_q975": 1248.853805585776,
            "rating_q025": 1221.347101419882
        },
        "granite-3.1-2b-instruct": {
            "rating": 1233.7694613521255,
            "rating_q975": 1258.2523061300903,
            "rating_q025": 1209.2866165741607
        },
        "dbrx-instruct-preview": {
            "rating": 1233.0907914158865,
            "rating_q975": 1243.7958294866646,
            "rating_q025": 1222.3857533451085
        },
        "qwen1.5-32b-chat": {
            "rating": 1232.019350459435,
            "rating_q975": 1242.9988288040759,
            "rating_q025": 1221.039872114794
        },
        "granite-3.0-8b-instruct": {
            "rating": 1231.9632672231655,
            "rating_q975": 1251.550653734121,
            "rating_q025": 1212.3758807122101
        },
        "gemini-pro-dev-api": {
            "rating": 1231.4654904551462,
            "rating_q975": 1244.1949509888707,
            "rating_q025": 1218.7360299214217
        },
        "c4ai-aya-expanse-8b": {
            "rating": 1228.1659838424882,
            "rating_q975": 1242.4044003231375,
            "rating_q025": 1213.927567361839
        },
        "zephyr-orpo-141b-A35b-v0.1": {
            "rating": 1226.3610646582351,
            "rating_q975": 1246.8973018147215,
            "rating_q025": 1205.8248275017488
        },
        "phi-3-medium-4k-instruct": {
            "rating": 1224.9377459205332,
            "rating_q975": 1234.6808892946501,
            "rating_q025": 1215.1946025464163
        },
        "mixtral-8x7b-instruct-v0.1": {
            "rating": 1224.6934942618498,
            "rating_q975": 1232.30800137887,
            "rating_q025": 1217.0789871448296
        },
        "llama-3.1-tulu-3-8b": {
            "rating": 1223.2635855629533,
            "rating_q975": 1248.8973603262073,
            "rating_q025": 1197.6298107996993
        },
        "command-r": {
            "rating": 1218.9086712499209,
            "rating_q975": 1227.4221601855027,
            "rating_q025": 1210.395182314339
        },
        "phi-3-small-8k-instruct": {
            "rating": 1209.0729660619959,
            "rating_q975": 1220.6056966738624,
            "rating_q025": 1197.5402354501293
        },
        "llama-3.2-3b-instruct": {
            "rating": 1206.2702341021622,
            "rating_q975": 1221.3995333043579,
            "rating_q025": 1191.1409348999666
        },
        "qwen1.5-14b-chat": {
            "rating": 1205.0909141793977,
            "rating_q975": 1217.7487802601001,
            "rating_q025": 1192.4330480986953
        },
        "starling-lm-7b-beta": {
            "rating": 1203.7781314746555,
            "rating_q975": 1216.4381050224993,
            "rating_q025": 1191.1181579268118
        },
        "gemma-1.1-7b-it": {
            "rating": 1202.6961654961124,
            "rating_q975": 1212.9225700158247,
            "rating_q025": 1192.4697609764
        },
        "tulu-2-dpo-70b": {
            "rating": 1202.16109805951,
            "rating_q975": 1219.8242365547612,
            "rating_q025": 1184.497959564259
        },
        "snowflake-arctic-instruct": {
            "rating": 1198.5525787209224,
            "rating_q975": 1209.260966417956,
            "rating_q025": 1187.8441910238887
        },
        "phi-3-mini-4k-instruct-june-2024": {
            "rating": 1197.8634751116706,
            "rating_q975": 1210.77095348888,
            "rating_q025": 1184.9559967344612
        },
        "yi-34b-chat": {
            "rating": 1193.398993002433,
            "rating_q975": 1205.348510505443,
            "rating_q025": 1181.4494754994228
        },
        "openchat-3.5-0106": {
            "rating": 1192.7648216824382,
            "rating_q975": 1205.2129834638927,
            "rating_q025": 1180.3166599009837
        },
        "gemma-2-2b-it": {
            "rating": 1192.3202399834433,
            "rating_q975": 1199.9639563704234,
            "rating_q025": 1184.6765235964633
        },
        "openhermes-2.5-mistral-7b": {
            "rating": 1191.019002374525,
            "rating_q975": 1209.6899639838257,
            "rating_q025": 1172.3480407652241
        },
        "granite-3.0-2b-instruct": {
            "rating": 1188.555412346876,
            "rating_q975": 1207.8930405467822,
            "rating_q025": 1169.2177841469697
        },
        "deepseek-llm-67b-chat": {
            "rating": 1185.8218518009508,
            "rating_q975": 1205.7671646209772,
            "rating_q025": 1165.8765389809244
        },
        "wizardlm-70b": {
            "rating": 1182.7364515753902,
            "rating_q975": 1199.1431360369857,
            "rating_q025": 1166.3297671137948
        },
        "mpt-30b-chat": {
            "rating": 1182.2574575608305,
            "rating_q975": 1212.253159940883,
            "rating_q025": 1152.261755180778
        },
        "starling-lm-7b-alpha": {
            "rating": 1182.1707679282517,
            "rating_q975": 1196.3820136829534,
            "rating_q025": 1167.95952217355
        },
        "codellama-70b-instruct": {
            "rating": 1176.2572574593214,
            "rating_q975": 1213.1006697449202,
            "rating_q025": 1139.4138451737226
        },
        "qwq-32b-preview": {
            "rating": 1176.0279300740563,
            "rating_q975": 1200.9478054908095,
            "rating_q025": 1151.108054657303
        },
        "openchat-3.5": {
            "rating": 1174.6928006133917,
            "rating_q975": 1191.635320065003,
            "rating_q025": 1157.7502811617803
        },
        "llama-2-70b-chat": {
            "rating": 1171.9349897283014,
            "rating_q975": 1181.0446915348768,
            "rating_q025": 1162.825287921726
        },
        "mistral-7b-instruct-v0.2": {
            "rating": 1171.7072740380236,
            "rating_q975": 1182.7473629114836,
            "rating_q025": 1160.6671851645635
        },
        "vicuna-33b": {
            "rating": 1171.0659138418387,
            "rating_q975": 1182.3576547410732,
            "rating_q025": 1159.774172942604
        },
        "phi-3-mini-4k-instruct": {
            "rating": 1170.7941711833555,
            "rating_q975": 1182.3252069678963,
            "rating_q025": 1159.2631353988147
        },
        "solar-10.7b-instruct-v1.0": {
            "rating": 1165.6882913484894,
            "rating_q975": 1187.4059681055369,
            "rating_q025": 1143.970614591442
        },
        "gemma-7b-it": {
            "rating": 1164.1717888348203,
            "rating_q975": 1179.51000181017,
            "rating_q025": 1148.8335758594706
        },
        "dolphin-2.2.1-mistral-7b": {
            "rating": 1163.204000993347,
            "rating_q975": 1194.7649216492616,
            "rating_q025": 1131.6430803374326
        },
        "palm-2": {
            "rating": 1162.7167218587065,
            "rating_q975": 1179.4062836349894,
            "rating_q025": 1146.0271600824235
        },
        "smollm2-1.7b-instruct": {
            "rating": 1160.8493164617116,
            "rating_q975": 1192.7212738805486,
            "rating_q025": 1128.9773590428747
        },
        "qwen1.5-7b-chat": {
            "rating": 1154.7434689810298,
            "rating_q975": 1172.3515319467522,
            "rating_q025": 1137.1354060153074
        },
        "llama-2-13b-chat": {
            "rating": 1153.506525374393,
            "rating_q975": 1165.340522118754,
            "rating_q025": 1141.672528630032
        },
        "llama2-70b-steerlm-chat": {
            "rating": 1151.6521342664669,
            "rating_q975": 1174.4379934009196,
            "rating_q025": 1128.8662751320142
        },
        "llama-3.2-1b-instruct": {
            "rating": 1151.617837730737,
            "rating_q975": 1166.7041615688406,
            "rating_q025": 1136.5315138926333
        },
        "phi-3-mini-128k-instruct": {
            "rating": 1148.9272526188151,
            "rating_q975": 1161.3552957540608,
            "rating_q025": 1136.4992094835695
        },
        "qwen-14b-chat": {
            "rating": 1148.4306326583308,
            "rating_q975": 1168.9449887417857,
            "rating_q025": 1127.9162765748758
        },
        "gemma-1.1-2b-it": {
            "rating": 1144.5062279367453,
            "rating_q975": 1158.8356496493943,
            "rating_q025": 1130.1768062240963
        },
        "codellama-34b-instruct": {
            "rating": 1141.045632983983,
            "rating_q975": 1157.1614427802758,
            "rating_q025": 1124.9298231876903
        },
        "nous-hermes-2-mixtral-8x7b-dpo": {
            "rating": 1138.7700190283995,
            "rating_q975": 1157.5697944911901,
            "rating_q025": 1119.9702435656088
        },
        "vicuna-13b": {
            "rating": 1137.8215912837136,
            "rating_q975": 1149.7960732139932,
            "rating_q025": 1125.847109353434
        },
        "zephyr-7b-alpha": {
            "rating": 1134.5475232951906,
            "rating_q975": 1167.6924874385325,
            "rating_q025": 1101.4025591518487
        },
        "zephyr-7b-beta": {
            "rating": 1131.2967271119905,
            "rating_q975": 1146.8180413624607,
            "rating_q025": 1115.7754128615204
        },
        "mistral-7b-instruct": {
            "rating": 1128.022945110005,
            "rating_q975": 1144.582573757949,
            "rating_q025": 1111.463316462061
        },
        "wizardlm-13b": {
            "rating": 1124.638195927182,
            "rating_q975": 1143.0026184221,
            "rating_q025": 1106.273773432264
        },
        "stripedhyena-nous-7b": {
            "rating": 1118.7515148745215,
            "rating_q975": 1137.0103188596327,
            "rating_q025": 1100.4927108894103
        },
        "guanaco-33b": {
            "rating": 1113.1732926794684,
            "rating_q975": 1141.6058158849673,
            "rating_q025": 1084.7407694739695
        },
        "llama-2-7b-chat": {
            "rating": 1111.9683315726343,
            "rating_q975": 1124.3635721558912,
            "rating_q025": 1099.5730909893773
        },
        "gemma-2b-it": {
            "rating": 1110.327892433467,
            "rating_q975": 1130.581914493312,
            "rating_q025": 1090.073870373622
        },
        "vicuna-7b": {
            "rating": 1107.59245065097,
            "rating_q975": 1126.2983223943186,
            "rating_q025": 1088.8865789076215
        },
        "qwen1.5-4b-chat": {
            "rating": 1094.5221565509137,
            "rating_q975": 1110.7154109916373,
            "rating_q025": 1078.32890211019
        },
        "olmo-7b-instruct": {
            "rating": 1083.617430575128,
            "rating_q975": 1102.4043228497248,
            "rating_q025": 1064.8305383005313
        },
        "chatglm3-6b": {
            "rating": 1078.5395276471072,
            "rating_q975": 1099.8825110346897,
            "rating_q025": 1057.1965442595247
        },
        "gpt4all-13b-snoozy": {
            "rating": 1075.9157113918977,
            "rating_q975": 1109.9288579398478,
            "rating_q025": 1041.9025648439476
        },
        "chatglm2-6b": {
            "rating": 1042.696170779769,
            "rating_q975": 1072.11872856441,
            "rating_q025": 1013.2736129951281
        },
        "koala-13b": {
            "rating": 1038.8880694757638,
            "rating_q975": 1058.849169328163,
            "rating_q025": 1018.9269696233647
        },
        "mpt-7b-chat": {
            "rating": 1038.007584875715,
            "rating_q975": 1062.2398008923956,
            "rating_q025": 1013.7753688590346
        },
        "oasst-pythia-12b": {
            "rating": 1027.2563796870327,
            "rating_q975": 1047.9652167295872,
            "rating_q025": 1006.5475426444781
        },
        "RWKV-4-Raven-14B": {
            "rating": 1015.6033597847022,
            "rating_q975": 1038.2890125415922,
            "rating_q025": 992.9177070278122
        },
        "alpaca-13b": {
            "rating": 1013.3585663374256,
            "rating_q975": 1035.169368729085,
            "rating_q025": 991.5477639457662
        },
        "chatglm-6b": {
            "rating": 992.4665977699249,
            "rating_q975": 1016.3360677761248,
            "rating_q025": 968.597127763725
        },
        "dolly-v2-12b": {
            "rating": 965.5665282596963,
            "rating_q975": 992.675030701817,
            "rating_q025": 938.4580258175755
        },
        "stablelm-tuned-alpha-7b": {
            "rating": 951.3036603228874,
            "rating_q975": 978.4530044313587,
            "rating_q025": 924.154316214416
        },
        "fastchat-t5-3b": {
            "rating": 940.7285983689151,
            "rating_q975": 964.0596093445045,
            "rating_q025": 917.3975873933257
        },
        "llama-13b": {
            "rating": 910.273240572606,
            "rating_q975": 944.7859383822549,
            "rating_q025": 875.7605427629571
        }
    },
    "if": {
        "claude-opus-4-5-20251101": {
            "rating": 1476.9037524592595,
            "rating_q975": 1488.79858757989,
            "rating_q025": 1465.008917338629
        },
        "gemini-3-pro": {
            "rating": 1474.2141994943756,
            "rating_q975": 1484.0649631089223,
            "rating_q025": 1464.363435879829
        },
        "claude-opus-4-5-20251101-thinking-32k": {
            "rating": 1473.4216357158252,
            "rating_q975": 1485.6088785278466,
            "rating_q025": 1461.2343929038038
        },
        "claude-sonnet-4-5-20250929-thinking-32k": {
            "rating": 1458.8799049146521,
            "rating_q975": 1466.3742009096845,
            "rating_q025": 1451.3856089196197
        },
        "claude-opus-4-1-20250805-thinking-16k": {
            "rating": 1456.60334624649,
            "rating_q975": 1462.8306895294966,
            "rating_q025": 1450.3760029634834
        },
        "claude-sonnet-4-5-20250929": {
            "rating": 1450.9962427276369,
            "rating_q975": 1459.2345610326397,
            "rating_q025": 1442.757924422634
        },
        "claude-opus-4-1-20250805": {
            "rating": 1449.1479448259267,
            "rating_q975": 1455.0045916963845,
            "rating_q025": 1443.291297955469
        },
        "gpt-5.1-high": {
            "rating": 1446.7689746361436,
            "rating_q975": 1457.2946863741327,
            "rating_q025": 1436.2432628981546
        },
        "gemini-2.5-pro": {
            "rating": 1443.9829806178616,
            "rating_q975": 1449.3389525001296,
            "rating_q025": 1438.6270087355936
        },
        "grok-4.1-thinking": {
            "rating": 1442.308933923574,
            "rating_q975": 1452.10737626838,
            "rating_q025": 1432.5104915787679
        },
        "claude-opus-4-20250514-thinking-16k": {
            "rating": 1438.5389557421117,
            "rating_q975": 1445.3613317990944,
            "rating_q025": 1431.716579685129
        },
        "gpt-4.5-preview-2025-02-27": {
            "rating": 1431.3767999645606,
            "rating_q975": 1439.5617407370985,
            "rating_q025": 1423.1918591920228
        },
        "grok-4.1": {
            "rating": 1426.3963293634276,
            "rating_q975": 1436.2347962939723,
            "rating_q025": 1416.557862432883
        },
        "gpt-5.1": {
            "rating": 1424.6178162994058,
            "rating_q975": 1434.5865127441584,
            "rating_q025": 1414.6491198546532
        },
        "qwen3-max-preview": {
            "rating": 1424.208542192019,
            "rating_q975": 1431.5548512000107,
            "rating_q025": 1416.8622331840272
        },
        "chatgpt-4o-latest-20250326": {
            "rating": 1419.051694237347,
            "rating_q975": 1424.1119984747065,
            "rating_q025": 1413.9913899999874
        },
        "glm-4.6": {
            "rating": 1416.3912872502872,
            "rating_q975": 1423.9809724223528,
            "rating_q025": 1408.8016020782215
        },
        "deepseek-v3.1-thinking": {
            "rating": 1415.3421172195092,
            "rating_q975": 1426.4178422703699,
            "rating_q025": 1404.2663921686485
        },
        "qwen3-235b-a22b-instruct-2507": {
            "rating": 1413.1548550210548,
            "rating_q975": 1419.0169753895761,
            "rating_q025": 1407.2927346525335
        },
        "deepseek-v3.2-exp-thinking": {
            "rating": 1412.8891893580176,
            "rating_q975": 1424.4191015201548,
            "rating_q025": 1401.3592771958804
        },
        "kimi-k2-thinking-turbo": {
            "rating": 1412.549841776603,
            "rating_q975": 1422.0266897663016,
            "rating_q025": 1403.0729937869044
        },
        "gpt-5-chat": {
            "rating": 1411.7332599988683,
            "rating_q975": 1418.6944270331514,
            "rating_q025": 1404.7720929645852
        },
        "deepseek-v3.2-exp": {
            "rating": 1411.359814564937,
            "rating_q975": 1421.7885022298983,
            "rating_q025": 1400.9311268999759
        },
        "gpt-5-high": {
            "rating": 1411.2515660827273,
            "rating_q975": 1418.465292220955,
            "rating_q025": 1404.0378399444996
        },
        "qwen3-max-2025-09-23": {
            "rating": 1411.1827948847235,
            "rating_q975": 1422.5134444652379,
            "rating_q025": 1399.8521453042092
        },
        "deepseek-v3.1-terminus-thinking": {
            "rating": 1411.0674059729943,
            "rating_q975": 1431.0286713366133,
            "rating_q025": 1391.1061406093752
        },
        "qwen3-vl-235b-a22b-instruct": {
            "rating": 1410.4719357577235,
            "rating_q975": 1422.1885252881905,
            "rating_q025": 1398.7553462272565
        },
        "claude-sonnet-4-20250514-thinking-32k": {
            "rating": 1410.0893200901821,
            "rating_q975": 1416.9723451252528,
            "rating_q025": 1403.2062950551115
        },
        "claude-haiku-4-5-20251001": {
            "rating": 1409.0049692491853,
            "rating_q975": 1416.5430072592671,
            "rating_q025": 1401.4669312391034
        },
        "claude-opus-4-20250514": {
            "rating": 1408.3695349666827,
            "rating_q975": 1414.8066961319118,
            "rating_q025": 1401.9323738014537
        },
        "deepseek-v3.2-thinking": {
            "rating": 1408.169087473956,
            "rating_q975": 1422.8876318081427,
            "rating_q025": 1393.4505431397695
        },
        "deepseek-v3.2": {
            "rating": 1406.3842444224,
            "rating_q975": 1420.455987512855,
            "rating_q025": 1392.3125013319448
        },
        "mistral-large-3": {
            "rating": 1405.0360749089893,
            "rating_q975": 1418.8481930233893,
            "rating_q025": 1391.2239567945894
        },
        "glm-4.5": {
            "rating": 1404.3591485932093,
            "rating_q975": 1412.2431230172967,
            "rating_q025": 1396.4751741691218
        },
        "grok-3-preview-02-24": {
            "rating": 1402.995739213909,
            "rating_q975": 1409.456606147746,
            "rating_q025": 1396.534872280072
        },
        "claude-3-7-sonnet-20250219-thinking-32k": {
            "rating": 1402.869789258478,
            "rating_q975": 1409.1604309250251,
            "rating_q025": 1396.579147591931
        },
        "gemini-2.5-flash": {
            "rating": 1400.4281773732966,
            "rating_q975": 1405.6485977653042,
            "rating_q025": 1395.207756981289
        },
        "gemini-2.5-flash-preview-09-2025": {
            "rating": 1400.397861182881,
            "rating_q975": 1407.5231564769863,
            "rating_q025": 1393.2725658887755
        },
        "o1-2024-12-17": {
            "rating": 1400.1612942931972,
            "rating_q975": 1406.4695962399478,
            "rating_q025": 1393.8529923464466
        },
        "deepseek-v3.1": {
            "rating": 1400.089777815884,
            "rating_q975": 1409.899785504215,
            "rating_q025": 1390.2797701275529
        },
        "grok-4-fast-chat": {
            "rating": 1399.143618647413,
            "rating_q975": 1413.5615545722248,
            "rating_q025": 1384.725682722601
        },
        "o3-2025-04-16": {
            "rating": 1398.5595301378864,
            "rating_q975": 1404.1090260368653,
            "rating_q025": 1393.0100342389076
        },
        "mistral-medium-2508": {
            "rating": 1398.1390178215265,
            "rating_q975": 1404.2778218389321,
            "rating_q025": 1392.000213804121
        },
        "grok-4-1-fast-reasoning": {
            "rating": 1396.3291320499898,
            "rating_q975": 1408.1040508039946,
            "rating_q025": 1384.554213295985
        },
        "gpt-4.1-2025-04-14": {
            "rating": 1395.5944519831269,
            "rating_q975": 1401.3130134367443,
            "rating_q025": 1389.8758905295094
        },
        "grok-4-0709": {
            "rating": 1394.3999996415214,
            "rating_q975": 1400.5681805786962,
            "rating_q025": 1388.2318187043466
        },
        "deepseek-v3.1-terminus": {
            "rating": 1390.5933954153545,
            "rating_q975": 1408.5140877104059,
            "rating_q025": 1372.6727031203031
        },
        "deepseek-r1": {
            "rating": 1390.4758210271839,
            "rating_q975": 1397.8015642727785,
            "rating_q025": 1383.1500777815893
        },
        "ernie-5.0-preview-1103": {
            "rating": 1389.3917147556613,
            "rating_q975": 1404.4129093938395,
            "rating_q025": 1374.370520117483
        },
        "deepseek-r1-0528": {
            "rating": 1387.4601563491753,
            "rating_q975": 1396.8503788766268,
            "rating_q025": 1378.069933821724
        },
        "longcat-flash-chat": {
            "rating": 1387.2385135793868,
            "rating_q975": 1397.9760973017385,
            "rating_q025": 1376.500929857035
        },
        "qwen3-235b-a22b-thinking-2507": {
            "rating": 1387.0061989312198,
            "rating_q975": 1399.4026425272475,
            "rating_q025": 1374.6097553351922
        },
        "claude-sonnet-4-20250514": {
            "rating": 1386.5926880082577,
            "rating_q975": 1393.1300012575261,
            "rating_q025": 1380.0553747589893
        },
        "hunyuan-vision-1.5-thinking": {
            "rating": 1386.5267605680156,
            "rating_q975": 1409.2847824503958,
            "rating_q025": 1363.7687386856353
        },
        "grok-4-fast-reasoning": {
            "rating": 1384.3503798068268,
            "rating_q975": 1392.7107706376037,
            "rating_q025": 1375.98998897605
        },
        "kimi-k2-0905-preview": {
            "rating": 1380.6348517920042,
            "rating_q975": 1391.7189863736444,
            "rating_q025": 1369.550717210364
        },
        "qwen3-next-80b-a3b-instruct": {
            "rating": 1379.5609552483202,
            "rating_q975": 1387.2668994739126,
            "rating_q025": 1371.8550110227277
        },
        "qwen3-vl-235b-a22b-thinking": {
            "rating": 1379.044704278156,
            "rating_q975": 1391.4018995471283,
            "rating_q025": 1366.6875090091835
        },
        "qwen3-coder-480b-a35b-instruct": {
            "rating": 1379.014759613632,
            "rating_q975": 1386.9880075332862,
            "rating_q025": 1371.0415116939776
        },
        "qwen3-235b-a22b-no-thinking": {
            "rating": 1376.3791139645612,
            "rating_q975": 1383.1313552637776,
            "rating_q025": 1369.6268726653448
        },
        "claude-3-7-sonnet-20250219": {
            "rating": 1376.1584573339157,
            "rating_q975": 1381.9383297227073,
            "rating_q025": 1370.3785849451242
        },
        "hunyuan-t1-20250711": {
            "rating": 1375.2999939708097,
            "rating_q975": 1392.7587945288053,
            "rating_q025": 1357.8411934128142
        },
        "o1-preview": {
            "rating": 1374.659834723285,
            "rating_q975": 1381.339914153187,
            "rating_q025": 1367.979755293383
        },
        "gpt-5-mini-high": {
            "rating": 1373.446473813897,
            "rating_q975": 1381.098078090867,
            "rating_q025": 1365.794869536927
        },
        "deepseek-v3-0324": {
            "rating": 1372.63314812109,
            "rating_q975": 1378.4720352286402,
            "rating_q025": 1366.7942610135399
        },
        "kimi-k2-0711-preview": {
            "rating": 1372.22997343969,
            "rating_q975": 1379.8048664959633,
            "rating_q025": 1364.6550803834166
        },
        "mai-1-preview": {
            "rating": 1368.3798902125998,
            "rating_q975": 1377.5658737423978,
            "rating_q025": 1359.1939066828018
        },
        "gemini-2.5-flash-lite-preview-06-17-thinking": {
            "rating": 1367.6743836192654,
            "rating_q975": 1374.6516209743052,
            "rating_q025": 1360.6971462642257
        },
        "gpt-4.1-mini-2025-04-14": {
            "rating": 1366.4869642058356,
            "rating_q975": 1372.9261011303827,
            "rating_q025": 1360.0478272812886
        },
        "claude-3-5-sonnet-20241022": {
            "rating": 1365.135763107904,
            "rating_q975": 1369.3455839501262,
            "rating_q025": 1360.925942265682
        },
        "o4-mini-2025-04-16": {
            "rating": 1364.901018728505,
            "rating_q975": 1370.8990970500768,
            "rating_q025": 1358.9029404069333
        },
        "qwen3-30b-a3b-instruct-2507": {
            "rating": 1364.0281957812383,
            "rating_q975": 1371.9497999553532,
            "rating_q025": 1356.1065916071234
        },
        "o3-mini-high": {
            "rating": 1360.6691000431679,
            "rating_q975": 1368.1508728909685,
            "rating_q025": 1353.1873271953673
        },
        "gemini-2.5-flash-lite-preview-09-2025-no-thinking": {
            "rating": 1360.6390831594488,
            "rating_q975": 1367.7253934516111,
            "rating_q025": 1353.5527728672864
        },
        "glm-4.5-air": {
            "rating": 1360.0505056718584,
            "rating_q975": 1366.9503128194956,
            "rating_q025": 1353.1506985242213
        },
        "mistral-medium-2505": {
            "rating": 1359.453400078029,
            "rating_q975": 1366.5095049543386,
            "rating_q025": 1352.3972952017195
        },
        "grok-3-mini-high": {
            "rating": 1357.9776232777933,
            "rating_q975": 1366.9838019144308,
            "rating_q025": 1348.9714446411558
        },
        "qwen3-next-80b-a3b-thinking": {
            "rating": 1355.714297947063,
            "rating_q975": 1365.6261381898357,
            "rating_q025": 1345.8024577042902
        },
        "qwen3-235b-a22b": {
            "rating": 1354.9474158597857,
            "rating_q975": 1362.5987561802422,
            "rating_q025": 1347.2960755393292
        },
        "qwen2.5-max": {
            "rating": 1352.2549435886046,
            "rating_q975": 1358.1007523246549,
            "rating_q025": 1346.4091348525544
        },
        "grok-3-mini-beta": {
            "rating": 1352.1442765665977,
            "rating_q975": 1360.0852427539382,
            "rating_q025": 1344.2033103792571
        },
        "hunyuan-turbos-20250416": {
            "rating": 1348.8212948754376,
            "rating_q975": 1360.3343045114975,
            "rating_q025": 1337.3082852393777
        },
        "llama-3.1-nemotron-ultra-253b-v1": {
            "rating": 1345.1603035931253,
            "rating_q975": 1366.6079450891336,
            "rating_q025": 1323.712662097117
        },
        "amazon-nova-experimental-chat-10-20": {
            "rating": 1344.554173673765,
            "rating_q975": 1357.0456966295953,
            "rating_q025": 1332.0626507179347
        },
        "minimax-m1": {
            "rating": 1344.4764489095508,
            "rating_q975": 1351.0977316525289,
            "rating_q025": 1337.8551661665726
        },
        "gemini-2.0-flash-001": {
            "rating": 1344.0717511092018,
            "rating_q975": 1349.5077756442374,
            "rating_q025": 1338.6357265741663
        },
        "hunyuan-turbos-20250226": {
            "rating": 1343.3906532118021,
            "rating_q975": 1361.1052571549722,
            "rating_q025": 1325.6760492686321
        },
        "step-3": {
            "rating": 1340.326211951084,
            "rating_q975": 1354.7283890315318,
            "rating_q025": 1325.924034870636
        },
        "gemma-3-27b-it": {
            "rating": 1339.4289061582895,
            "rating_q975": 1345.0321422845893,
            "rating_q025": 1333.8256700319896
        },
        "o3-mini": {
            "rating": 1339.2250708538284,
            "rating_q975": 1344.1953410974736,
            "rating_q025": 1334.254800610183
        },
        "deepseek-v3": {
            "rating": 1338.3122183803491,
            "rating_q975": 1345.0086423416042,
            "rating_q025": 1331.615794419094
        },
        "command-a-03-2025": {
            "rating": 1336.345760315852,
            "rating_q975": 1341.5981392376277,
            "rating_q025": 1331.0933813940762
        },
        "amazon-nova-experimental-chat-10-09": {
            "rating": 1335.9707896674686,
            "rating_q975": 1347.3164245581634,
            "rating_q025": 1324.6251547767738
        },
        "glm-4.5v": {
            "rating": 1334.9717196527013,
            "rating_q975": 1351.0121979966896,
            "rating_q025": 1318.931241308713
        },
        "mistral-small-2506": {
            "rating": 1333.8758575015263,
            "rating_q975": 1342.6626352265457,
            "rating_q025": 1325.0890797765069
        },
        "gemini-1.5-pro-002": {
            "rating": 1333.471841890826,
            "rating_q975": 1338.2135841380884,
            "rating_q025": 1328.7300996435636
        },
        "minimax-m2": {
            "rating": 1332.1882996289892,
            "rating_q975": 1345.2237086144762,
            "rating_q025": 1319.1528906435021
        },
        "claude-3-5-sonnet-20240620": {
            "rating": 1329.9988440208838,
            "rating_q975": 1334.914505900865,
            "rating_q025": 1325.0831821409026
        },
        "intellect-3": {
            "rating": 1327.6912394282476,
            "rating_q975": 1351.6167501941236,
            "rating_q025": 1303.7657286623717
        },
        "qwen-plus-0125": {
            "rating": 1327.3885129287823,
            "rating_q975": 1339.4085103837426,
            "rating_q025": 1315.368515473822
        },
        "o1-mini": {
            "rating": 1326.9810959518054,
            "rating_q975": 1332.016820427269,
            "rating_q025": 1321.9453714763417
        },
        "gemini-2.0-flash-lite-preview-02-05": {
            "rating": 1326.8745896537998,
            "rating_q975": 1333.0489723584544,
            "rating_q025": 1320.7002069491452
        },
        "qwen3-32b": {
            "rating": 1326.1159311936146,
            "rating_q975": 1345.025165359197,
            "rating_q025": 1307.2066970280323
        },
        "nova-2-lite": {
            "rating": 1324.0410514267874,
            "rating_q975": 1338.8931915034873,
            "rating_q025": 1309.1889113500874
        },
        "gpt-5-nano-high": {
            "rating": 1321.92837907763,
            "rating_q975": 1335.153739336274,
            "rating_q025": 1308.7030188189863
        },
        "gpt-oss-120b": {
            "rating": 1321.9250460074595,
            "rating_q975": 1329.0144374550819,
            "rating_q025": 1314.8356545598372
        },
        "qwq-32b": {
            "rating": 1321.0165871879249,
            "rating_q975": 1327.9489425048905,
            "rating_q025": 1314.0842318709592
        },
        "llama-3.3-nemotron-49b-super-v1": {
            "rating": 1320.5231335659173,
            "rating_q975": 1339.8276144485894,
            "rating_q025": 1301.2186526832452
        },
        "gpt-4o-2024-05-13": {
            "rating": 1319.1193807522982,
            "rating_q975": 1323.8817743421168,
            "rating_q025": 1314.3569871624795
        },
        "nvidia-llama-3.3-nemotron-super-49b-v1.5": {
            "rating": 1318.0747482469592,
            "rating_q975": 1337.526567483393,
            "rating_q025": 1298.6229290105255
        },
        "gemma-3-12b-it": {
            "rating": 1317.09773740248,
            "rating_q975": 1333.30876335735,
            "rating_q025": 1300.8867114476102
        },
        "ling-flash-2.0": {
            "rating": 1315.3241233446188,
            "rating_q975": 1328.8742209074164,
            "rating_q025": 1301.7740257818211
        },
        "ring-flash-2.0": {
            "rating": 1313.9362849224326,
            "rating_q975": 1327.4484813588315,
            "rating_q025": 1300.4240884860337
        },
        "gpt-4o-2024-08-06": {
            "rating": 1311.9599535940492,
            "rating_q975": 1317.5424729330034,
            "rating_q025": 1306.377434255095
        },
        "glm-4-plus-0111": {
            "rating": 1311.4031569108674,
            "rating_q975": 1323.768063106287,
            "rating_q025": 1299.038250715448
        },
        "step-2-16k-exp-202412": {
            "rating": 1310.3571694913821,
            "rating_q975": 1322.7102137986158,
            "rating_q025": 1298.0041251841485
        },
        "hunyuan-large-2025-02-10": {
            "rating": 1310.2897791758721,
            "rating_q975": 1325.7983414531122,
            "rating_q025": 1294.781216898632
        },
        "llama-4-maverick-17b-128e-instruct": {
            "rating": 1309.413381097554,
            "rating_q975": 1315.8091661646342,
            "rating_q025": 1303.017596030474
        },
        "deepseek-v2.5-1210": {
            "rating": 1309.383822527161,
            "rating_q975": 1320.5146734893956,
            "rating_q025": 1298.2529715649266
        },
        "hunyuan-turbo-0110": {
            "rating": 1308.7525407257485,
            "rating_q975": 1326.7162302325517,
            "rating_q025": 1290.7888512189454
        },
        "gemini-advanced-0514": {
            "rating": 1308.6808300158164,
            "rating_q975": 1315.2814365148363,
            "rating_q025": 1302.0802235167964
        },
        "qwen3-30b-a3b": {
            "rating": 1307.7937752690411,
            "rating_q975": 1315.5244158957746,
            "rating_q025": 1300.0631346423077
        },
        "llama-3.1-405b-instruct-bf16": {
            "rating": 1307.648808792134,
            "rating_q975": 1312.6866334110425,
            "rating_q025": 1302.6109841732257
        },
        "llama-3.1-405b-instruct-fp8": {
            "rating": 1307.5704406514467,
            "rating_q975": 1312.6401758742866,
            "rating_q025": 1302.5007054286068
        },
        "step-1o-turbo-202506": {
            "rating": 1307.1159160334973,
            "rating_q975": 1319.4257422111252,
            "rating_q025": 1294.8060898558695
        },
        "claude-3-5-haiku-20241022": {
            "rating": 1306.5432886113604,
            "rating_q975": 1311.0747408227166,
            "rating_q025": 1302.011836400004
        },
        "grok-2-2024-08-13": {
            "rating": 1306.2690539732714,
            "rating_q975": 1311.0326297683932,
            "rating_q025": 1301.5054781781496
        },
        "claude-3-opus-20240229": {
            "rating": 1306.1693500755669,
            "rating_q975": 1310.4321722488403,
            "rating_q025": 1301.9065279022934
        },
        "yi-lightning": {
            "rating": 1304.3985553776306,
            "rating_q975": 1311.1450524070808,
            "rating_q025": 1297.6520583481804
        },
        "gemini-1.5-pro-001": {
            "rating": 1303.2888762553016,
            "rating_q975": 1308.8823229370612,
            "rating_q025": 1297.695429573542
        },
        "magistral-medium-2506": {
            "rating": 1300.3650377742142,
            "rating_q975": 1311.0547867400687,
            "rating_q025": 1289.6752888083597
        },
        "athene-v2-chat": {
            "rating": 1297.2891757271336,
            "rating_q975": 1303.4295440312796,
            "rating_q025": 1291.1488074229876
        },
        "qwen-max-0919": {
            "rating": 1296.4831676167191,
            "rating_q975": 1304.2815290280766,
            "rating_q025": 1288.6848062053616
        },
        "gpt-4-turbo-2024-04-09": {
            "rating": 1296.2132628860072,
            "rating_q975": 1301.5186963678514,
            "rating_q025": 1290.907829404163
        },
        "gpt-4.1-nano-2025-04-14": {
            "rating": 1296.0284506232467,
            "rating_q975": 1308.4478252752308,
            "rating_q025": 1283.6090759712627
        },
        "glm-4-plus": {
            "rating": 1295.315148125897,
            "rating_q975": 1302.0413992236984,
            "rating_q025": 1288.5888970280955
        },
        "llama-4-scout-17b-16e-instruct": {
            "rating": 1295.144770097514,
            "rating_q975": 1302.39712633832,
            "rating_q025": 1287.8924138567081
        },
        "olmo-3-32b-think": {
            "rating": 1294.3231322415818,
            "rating_q975": 1315.458404338289,
            "rating_q025": 1273.1878601448745
        },
        "mistral-large-2407": {
            "rating": 1292.883254983496,
            "rating_q975": 1298.3349376774397,
            "rating_q025": 1287.4315722895524
        },
        "mistral-small-3.1-24b-instruct-2503": {
            "rating": 1291.8204643678628,
            "rating_q975": 1298.878316835072,
            "rating_q025": 1284.7626119006536
        },
        "qwen2.5-plus-1127": {
            "rating": 1291.1307099703145,
            "rating_q975": 1300.0480998463008,
            "rating_q025": 1282.213320094328
        },
        "gpt-4-1106-preview": {
            "rating": 1289.0094795495258,
            "rating_q975": 1294.4328557217605,
            "rating_q025": 1283.5861033772912
        },
        "mistral-large-2411": {
            "rating": 1288.7671351353802,
            "rating_q975": 1294.6203965039954,
            "rating_q025": 1282.913873766765
        },
        "gpt-4o-mini-2024-07-18": {
            "rating": 1288.2078599970273,
            "rating_q975": 1292.7750321390795,
            "rating_q025": 1283.640687854975
        },
        "qwen2.5-72b-instruct": {
            "rating": 1286.8150160759633,
            "rating_q975": 1292.2433013648342,
            "rating_q025": 1281.3867307870923
        },
        "llama-3.3-70b-instruct": {
            "rating": 1286.672346864812,
            "rating_q975": 1291.4842605665592,
            "rating_q025": 1281.8604331630647
        },
        "deepseek-v2.5": {
            "rating": 1285.9339932555554,
            "rating_q975": 1292.4836688977487,
            "rating_q025": 1279.384317613362
        },
        "gemini-1.5-flash-002": {
            "rating": 1285.2663314293618,
            "rating_q975": 1290.951123061561,
            "rating_q025": 1279.5815397971626
        },
        "hunyuan-large-vision": {
            "rating": 1284.370623765134,
            "rating_q975": 1300.7982916130306,
            "rating_q025": 1267.9429559172374
        },
        "gpt-4-0125-preview": {
            "rating": 1283.0773593515548,
            "rating_q975": 1288.6333797795944,
            "rating_q025": 1277.5213389235153
        },
        "gemma-3n-e4b-it": {
            "rating": 1279.1915181449954,
            "rating_q975": 1287.608062062645,
            "rating_q025": 1270.7749742273456
        },
        "grok-2-mini-2024-08-13": {
            "rating": 1278.0107754627666,
            "rating_q975": 1283.0587926066166,
            "rating_q025": 1272.9627583189165
        },
        "hunyuan-standard-2025-02-10": {
            "rating": 1276.8834253897198,
            "rating_q975": 1292.0924851173352,
            "rating_q025": 1261.6743656621045
        },
        "gpt-oss-20b": {
            "rating": 1276.8144985352465,
            "rating_q975": 1288.9124227693817,
            "rating_q025": 1264.7165743011112
        },
        "llama-3.1-nemotron-70b-instruct": {
            "rating": 1275.5155629540268,
            "rating_q975": 1286.2688261344526,
            "rating_q025": 1264.762299773601
        },
        "gpt-4-0314": {
            "rating": 1274.0331955461095,
            "rating_q975": 1281.1617637402721,
            "rating_q025": 1266.9046273519468
        },
        "mercury": {
            "rating": 1271.2885472534426,
            "rating_q975": 1296.6704053649987,
            "rating_q025": 1245.9066891418865
        },
        "amazon-nova-pro-v1.0": {
            "rating": 1270.5531900453877,
            "rating_q975": 1276.6511730968355,
            "rating_q025": 1264.45520699394
        },
        "athene-70b-0725": {
            "rating": 1270.449816414872,
            "rating_q975": 1278.0227807464967,
            "rating_q025": 1262.8768520832473
        },
        "llama-3.1-tulu-3-70b": {
            "rating": 1266.9839962032884,
            "rating_q975": 1282.352674065063,
            "rating_q025": 1251.6153183415138
        },
        "llama-3.1-70b-instruct": {
            "rating": 1266.9614293483532,
            "rating_q975": 1272.0287237046277,
            "rating_q025": 1261.8941349920788
        },
        "gpt-4-0613": {
            "rating": 1266.0731930761867,
            "rating_q975": 1271.9572918646313,
            "rating_q025": 1260.1890942877421
        },
        "gemma-3-4b-it": {
            "rating": 1263.543442650566,
            "rating_q975": 1279.8188135285766,
            "rating_q025": 1247.2680717725555
        },
        "gemma-2-27b-it": {
            "rating": 1262.7612295637132,
            "rating_q975": 1267.2545378825425,
            "rating_q025": 1258.2679212448838
        },
        "jamba-1.5-large": {
            "rating": 1260.1781348364414,
            "rating_q975": 1270.752638937468,
            "rating_q025": 1249.6036307354148
        },
        "claude-3-sonnet-20240229": {
            "rating": 1259.6526224409877,
            "rating_q975": 1265.1113571085557,
            "rating_q025": 1254.1938877734196
        },
        "qwen2.5-coder-32b-instruct": {
            "rating": 1257.7636915353685,
            "rating_q975": 1269.5660258620953,
            "rating_q025": 1245.9613572086416
        },
        "gemini-1.5-flash-001": {
            "rating": 1257.614348389531,
            "rating_q975": 1263.3935923224155,
            "rating_q025": 1251.8351044566464
        },
        "reka-core-20240904": {
            "rating": 1255.1196986967066,
            "rating_q975": 1265.124296573704,
            "rating_q025": 1245.1151008197091
        },
        "llama-3.1-nemotron-51b-instruct": {
            "rating": 1254.0405815004224,
            "rating_q975": 1268.5574681006524,
            "rating_q025": 1239.5236949001924
        },
        "nemotron-4-340b-instruct": {
            "rating": 1252.0398553206992,
            "rating_q975": 1260.0688729466838,
            "rating_q025": 1244.0108376947146
        },
        "llama-3-70b-instruct": {
            "rating": 1250.5771026748712,
            "rating_q975": 1255.6871231711386,
            "rating_q025": 1245.4670821786037
        },
        "mistral-small-24b-instruct-2501": {
            "rating": 1249.7305357894995,
            "rating_q975": 1257.7946744060205,
            "rating_q025": 1241.6663971729786
        },
        "glm-4-0520": {
            "rating": 1249.021413838262,
            "rating_q975": 1259.1869311978721,
            "rating_q025": 1238.855896478652
        },
        "command-r-plus-08-2024": {
            "rating": 1246.6916346439018,
            "rating_q975": 1255.8681098600202,
            "rating_q025": 1237.5151594277834
        },
        "gemma-2-9b-it-simpo": {
            "rating": 1243.7830076334656,
            "rating_q975": 1253.7018171142317,
            "rating_q025": 1233.8641981526994
        },
        "deepseek-coder-v2": {
            "rating": 1243.5447310258517,
            "rating_q975": 1252.4391959502536,
            "rating_q025": 1234.6502661014497
        },
        "c4ai-aya-expanse-32b": {
            "rating": 1242.3887798684725,
            "rating_q975": 1248.8839551292415,
            "rating_q025": 1235.8936046077035
        },
        "reka-flash-20240904": {
            "rating": 1241.338974462201,
            "rating_q975": 1251.2787317303964,
            "rating_q025": 1231.3992171940054
        },
        "phi-4": {
            "rating": 1239.4878013934892,
            "rating_q975": 1245.9148576861287,
            "rating_q025": 1233.0607451008498
        },
        "amazon-nova-lite-v1.0": {
            "rating": 1238.4513270223006,
            "rating_q975": 1245.3416980930738,
            "rating_q025": 1231.5609559515274
        },
        "claude-3-haiku-20240307": {
            "rating": 1237.013274398196,
            "rating_q975": 1242.1291219358288,
            "rating_q025": 1231.8974268605632
        },
        "hunyuan-standard-256k": {
            "rating": 1236.6178467796067,
            "rating_q975": 1253.3412369273294,
            "rating_q025": 1219.894456631884
        },
        "gemma-2-9b-it": {
            "rating": 1236.595535779108,
            "rating_q975": 1241.6257735672784,
            "rating_q025": 1231.5652979909378
        },
        "qwen2-72b-instruct": {
            "rating": 1234.5991825498832,
            "rating_q975": 1241.2346981304147,
            "rating_q025": 1227.9636669693516
        },
        "command-r-plus": {
            "rating": 1233.5110576526,
            "rating_q975": 1239.4153031831065,
            "rating_q025": 1227.6068121220933
        },
        "gemini-1.5-flash-8b-001": {
            "rating": 1232.4751514420313,
            "rating_q975": 1238.2091100505866,
            "rating_q025": 1226.7411928334761
        },
        "mistral-large-2402": {
            "rating": 1229.281270037162,
            "rating_q975": 1235.756490254795,
            "rating_q025": 1222.8060498195289
        },
        "command-r-08-2024": {
            "rating": 1228.1170745604945,
            "rating_q975": 1237.2060962992023,
            "rating_q025": 1219.0280528217868
        },
        "olmo-2-0325-32b-instruct": {
            "rating": 1224.1778186470556,
            "rating_q975": 1241.2769028857367,
            "rating_q025": 1207.0787344083744
        },
        "amazon-nova-micro-v1.0": {
            "rating": 1210.6425534726736,
            "rating_q975": 1217.5052169540375,
            "rating_q025": 1203.7798899913098
        },
        "qwen1.5-110b-chat": {
            "rating": 1210.3145185189728,
            "rating_q975": 1218.2559157401356,
            "rating_q025": 1202.37312129781
        },
        "gemini-pro": {
            "rating": 1207.4988438165892,
            "rating_q975": 1224.0550193912186,
            "rating_q025": 1190.9426682419598
        },
        "mixtral-8x22b-instruct-v0.1": {
            "rating": 1206.7939301522024,
            "rating_q975": 1213.160269555357,
            "rating_q025": 1200.4275907490478
        },
        "ministral-8b-2410": {
            "rating": 1205.131180912878,
            "rating_q975": 1217.7688999416027,
            "rating_q025": 1192.4934618841535
        },
        "llama-3.1-tulu-3-8b": {
            "rating": 1204.2577177953194,
            "rating_q975": 1219.7140140568042,
            "rating_q025": 1188.8014215338346
        },
        "gpt-3.5-turbo-0125": {
            "rating": 1204.006667884972,
            "rating_q975": 1210.2241493652316,
            "rating_q025": 1197.7891864047126
        },
        "qwen1.5-72b-chat": {
            "rating": 1203.472140020206,
            "rating_q975": 1210.7258358063696,
            "rating_q025": 1196.2184442340426
        },
        "mistral-medium": {
            "rating": 1203.3693147936174,
            "rating_q975": 1211.453399077833,
            "rating_q025": 1195.2852305094018
        },
        "gemini-pro-dev-api": {
            "rating": 1198.2465461679965,
            "rating_q975": 1208.7170224684191,
            "rating_q025": 1187.7760698675738
        },
        "c4ai-aya-expanse-8b": {
            "rating": 1198.203963630518,
            "rating_q975": 1207.6131180938378,
            "rating_q025": 1188.7948091671983
        },
        "jamba-1.5-mini": {
            "rating": 1198.0961295632728,
            "rating_q975": 1208.6098769908383,
            "rating_q025": 1187.5823821357073
        },
        "reka-flash-21b-20240226-online": {
            "rating": 1193.1425004080309,
            "rating_q975": 1203.3102466424411,
            "rating_q025": 1182.9747541736206
        },
        "command-r": {
            "rating": 1191.0625126053828,
            "rating_q975": 1197.6717654870504,
            "rating_q025": 1184.4532597237153
        },
        "granite-3.1-8b-instruct": {
            "rating": 1187.4870220285627,
            "rating_q975": 1203.8696151531497,
            "rating_q025": 1171.1044289039758
        },
        "llama-3.1-8b-instruct": {
            "rating": 1186.9006905228534,
            "rating_q975": 1192.2320684595395,
            "rating_q025": 1181.5693125861674
        },
        "gpt-3.5-turbo-1106": {
            "rating": 1184.8971938192835,
            "rating_q975": 1196.9341878208563,
            "rating_q025": 1172.8601998177107
        },
        "llama-3-8b-instruct": {
            "rating": 1184.7614428954544,
            "rating_q975": 1190.2473567546488,
            "rating_q025": 1179.27552903626
        },
        "zephyr-orpo-141b-A35b-v0.1": {
            "rating": 1184.4729579936707,
            "rating_q975": 1199.9354853263997,
            "rating_q025": 1169.0104306609417
        },
        "reka-flash-21b-20240226": {
            "rating": 1184.0261241082276,
            "rating_q975": 1192.363122503689,
            "rating_q025": 1175.689125712766
        },
        "yi-1.5-34b-chat": {
            "rating": 1181.4693240176953,
            "rating_q975": 1189.039827556438,
            "rating_q025": 1173.8988204789525
        },
        "dbrx-instruct-preview": {
            "rating": 1178.4118578295656,
            "rating_q975": 1186.8093133766704,
            "rating_q025": 1170.0144022824609
        },
        "qwen1.5-32b-chat": {
            "rating": 1176.8826226353826,
            "rating_q975": 1185.3440470321732,
            "rating_q025": 1168.421198238592
        },
        "internlm2_5-20b-chat": {
            "rating": 1173.2596228385787,
            "rating_q975": 1183.253905349414,
            "rating_q025": 1163.2653403277434
        },
        "mixtral-8x7b-instruct-v0.1": {
            "rating": 1171.7543826320853,
            "rating_q975": 1177.886208564364,
            "rating_q025": 1165.6225566998064
        },
        "phi-3-medium-4k-instruct": {
            "rating": 1169.9392767406405,
            "rating_q975": 1177.1897926637346,
            "rating_q025": 1162.6887608175464
        },
        "granite-3.1-2b-instruct": {
            "rating": 1165.7881659053717,
            "rating_q975": 1181.956458138999,
            "rating_q025": 1149.6198736717442
        },
        "gemma-2-2b-it": {
            "rating": 1164.3627363323424,
            "rating_q975": 1169.7875927365753,
            "rating_q025": 1158.9378799281094
        },
        "tulu-2-dpo-70b": {
            "rating": 1163.2001697518454,
            "rating_q975": 1177.8585495202149,
            "rating_q025": 1148.5417899834758
        },
        "granite-3.0-8b-instruct": {
            "rating": 1162.869915167405,
            "rating_q975": 1175.076769461541,
            "rating_q025": 1150.663060873269
        },
        "qwen1.5-14b-chat": {
            "rating": 1160.4387861950697,
            "rating_q975": 1170.3328814255729,
            "rating_q025": 1150.5446909645666
        },
        "wizardlm-70b": {
            "rating": 1154.9290695433306,
            "rating_q975": 1168.3097309812365,
            "rating_q025": 1141.5484081054246
        },
        "deepseek-llm-67b-chat": {
            "rating": 1148.0658952935764,
            "rating_q975": 1164.92180219529,
            "rating_q025": 1131.209988391863
        },
        "qwq-32b-preview": {
            "rating": 1147.9012915721682,
            "rating_q975": 1163.8164929640377,
            "rating_q025": 1131.9860901802988
        },
        "phi-3-small-8k-instruct": {
            "rating": 1146.165938864783,
            "rating_q975": 1154.7674407116756,
            "rating_q025": 1137.5644370178902
        },
        "openchat-3.5-0106": {
            "rating": 1146.0940637407637,
            "rating_q975": 1156.5483779297515,
            "rating_q025": 1135.6397495517758
        },
        "gemma-1.1-7b-it": {
            "rating": 1144.8434330512707,
            "rating_q975": 1152.695595082285,
            "rating_q025": 1136.9912710202564
        },
        "yi-34b-chat": {
            "rating": 1144.56398117583,
            "rating_q975": 1154.1873841451127,
            "rating_q025": 1134.9405782065471
        },
        "openchat-3.5": {
            "rating": 1143.956590434337,
            "rating_q975": 1158.0898401199534,
            "rating_q025": 1129.8233407487205
        },
        "snowflake-arctic-instruct": {
            "rating": 1143.7635024812632,
            "rating_q975": 1152.1397723783416,
            "rating_q025": 1135.3872325841849
        },
        "openhermes-2.5-mistral-7b": {
            "rating": 1143.5797081498395,
            "rating_q975": 1158.9051607153353,
            "rating_q025": 1128.2542555843436
        },
        "starling-lm-7b-beta": {
            "rating": 1140.4150555460978,
            "rating_q975": 1150.4042250092516,
            "rating_q025": 1130.425886082944
        },
        "llama-3.2-3b-instruct": {
            "rating": 1139.4792112640628,
            "rating_q975": 1150.3365184623228,
            "rating_q025": 1128.6219040658027
        },
        "vicuna-33b": {
            "rating": 1130.580435162424,
            "rating_q975": 1139.5044573634918,
            "rating_q025": 1121.6564129613562
        },
        "starling-lm-7b-alpha": {
            "rating": 1128.7638409298966,
            "rating_q975": 1140.1750770289502,
            "rating_q025": 1117.352604830843
        },
        "llama-2-70b-chat": {
            "rating": 1127.7439155131633,
            "rating_q975": 1135.2917653838176,
            "rating_q025": 1120.196065642509
        },
        "mpt-30b-chat": {
            "rating": 1125.2502720464984,
            "rating_q975": 1146.3367379355595,
            "rating_q025": 1104.1638061574372
        },
        "falcon-180b-chat": {
            "rating": 1124.3704904982428,
            "rating_q975": 1153.0827512773662,
            "rating_q025": 1095.6582297191194
        },
        "granite-3.0-2b-instruct": {
            "rating": 1123.59357537815,
            "rating_q975": 1135.9004975759751,
            "rating_q025": 1111.286653180325
        },
        "dolphin-2.2.1-mistral-7b": {
            "rating": 1119.8852347499605,
            "rating_q975": 1144.3856733530524,
            "rating_q025": 1095.3847961468687
        },
        "llama2-70b-steerlm-chat": {
            "rating": 1117.4887221670483,
            "rating_q975": 1135.8096354552251,
            "rating_q025": 1099.1678088788715
        },
        "phi-3-mini-4k-instruct-june-2024": {
            "rating": 1116.6779297164985,
            "rating_q975": 1126.2563648458117,
            "rating_q025": 1107.0994945871853
        },
        "qwen1.5-7b-chat": {
            "rating": 1116.034794354741,
            "rating_q975": 1130.0750320073855,
            "rating_q025": 1101.9945567020966
        },
        "mistral-7b-instruct-v0.2": {
            "rating": 1115.5655358034517,
            "rating_q975": 1124.4651899246553,
            "rating_q025": 1106.665881682248
        },
        "wizardlm-13b": {
            "rating": 1114.631807357212,
            "rating_q975": 1128.522208836896,
            "rating_q025": 1100.741405877528
        },
        "solar-10.7b-instruct-v1.0": {
            "rating": 1108.565495686732,
            "rating_q975": 1127.0624444247044,
            "rating_q025": 1090.0685469487596
        },
        "qwen-14b-chat": {
            "rating": 1108.1990829988172,
            "rating_q975": 1124.5929289633032,
            "rating_q025": 1091.8052370343312
        },
        "vicuna-13b": {
            "rating": 1107.1820589247734,
            "rating_q975": 1116.702715085534,
            "rating_q025": 1097.6614027640128
        },
        "phi-3-mini-4k-instruct": {
            "rating": 1104.7307592412012,
            "rating_q975": 1113.4761310254341,
            "rating_q025": 1095.9853874569683
        },
        "palm-2": {
            "rating": 1103.6700431642876,
            "rating_q975": 1117.05552032492,
            "rating_q025": 1090.284566003655
        },
        "llama-2-13b-chat": {
            "rating": 1102.4573474469782,
            "rating_q975": 1111.7592019905396,
            "rating_q025": 1093.1554929034169
        },
        "nous-hermes-2-mixtral-8x7b-dpo": {
            "rating": 1102.1381155349764,
            "rating_q975": 1118.4429558753293,
            "rating_q025": 1085.8332751946234
        },
        "smollm2-1.7b-instruct": {
            "rating": 1098.4618458788846,
            "rating_q975": 1119.4704773817273,
            "rating_q025": 1077.4532143760418
        },
        "codellama-34b-instruct": {
            "rating": 1095.2950360708542,
            "rating_q975": 1108.230788541116,
            "rating_q025": 1082.3592836005923
        },
        "gemma-7b-it": {
            "rating": 1093.634747183541,
            "rating_q975": 1106.3531068661475,
            "rating_q025": 1080.9163875009347
        },
        "zephyr-7b-alpha": {
            "rating": 1092.233752346014,
            "rating_q975": 1116.6830671604077,
            "rating_q025": 1067.7844375316201
        },
        "phi-3-mini-128k-instruct": {
            "rating": 1091.7696550048577,
            "rating_q975": 1101.948427230655,
            "rating_q025": 1081.5908827790604
        },
        "codellama-70b-instruct": {
            "rating": 1089.3835194721214,
            "rating_q975": 1119.3876543713295,
            "rating_q025": 1059.3793845729133
        },
        "gemma-1.1-2b-it": {
            "rating": 1087.7204065405238,
            "rating_q975": 1098.5800260971403,
            "rating_q025": 1076.8607869839072
        },
        "zephyr-7b-beta": {
            "rating": 1081.3863446608862,
            "rating_q975": 1094.1050599095763,
            "rating_q025": 1068.667629412196
        },
        "stripedhyena-nous-7b": {
            "rating": 1081.1860367433592,
            "rating_q975": 1096.3849492767054,
            "rating_q025": 1065.987124210013
        },
        "llama-3.2-1b-instruct": {
            "rating": 1080.2428881110184,
            "rating_q975": 1091.4723038837863,
            "rating_q025": 1069.0134723382505
        },
        "mistral-7b-instruct": {
            "rating": 1077.4250430716465,
            "rating_q975": 1090.9911753214997,
            "rating_q025": 1063.8589108217934
        },
        "vicuna-7b": {
            "rating": 1067.5354721035662,
            "rating_q975": 1081.7073856487361,
            "rating_q025": 1053.3635585583963
        },
        "llama-2-7b-chat": {
            "rating": 1061.7105618497176,
            "rating_q975": 1071.5031642668173,
            "rating_q025": 1051.9179594326179
        },
        "qwen1.5-4b-chat": {
            "rating": 1059.3997042582328,
            "rating_q975": 1072.3102570107494,
            "rating_q025": 1046.489151505716
        },
        "gemma-2b-it": {
            "rating": 1058.7820716326416,
            "rating_q975": 1074.8547258396472,
            "rating_q025": 1042.709417425636
        },
        "guanaco-33b": {
            "rating": 1056.5423141586175,
            "rating_q975": 1077.6652950500757,
            "rating_q025": 1035.4193332671593
        },
        "gpt4all-13b-snoozy": {
            "rating": 1027.927202137516,
            "rating_q975": 1052.8033488807853,
            "rating_q025": 1003.0510553942464
        },
        "chatglm3-6b": {
            "rating": 1027.8930570209654,
            "rating_q975": 1045.5303598215078,
            "rating_q025": 1010.2557542204231
        },
        "olmo-7b-instruct": {
            "rating": 1024.6374171828622,
            "rating_q975": 1040.5372849596044,
            "rating_q025": 1008.7375494061201
        },
        "koala-13b": {
            "rating": 1016.7406530765355,
            "rating_q975": 1032.0802853013645,
            "rating_q025": 1001.4010208517066
        },
        "alpaca-13b": {
            "rating": 1009.6905802971052,
            "rating_q975": 1025.9405768439183,
            "rating_q025": 993.440583750292
        },
        "mpt-7b-chat": {
            "rating": 998.918791003772,
            "rating_q975": 1017.3257939049971,
            "rating_q025": 980.5117881025468
        },
        "oasst-pythia-12b": {
            "rating": 975.1414166166315,
            "rating_q975": 991.2557163568968,
            "rating_q025": 959.0271168763663
        },
        "chatglm2-6b": {
            "rating": 973.2252399927297,
            "rating_q975": 995.8695016070834,
            "rating_q025": 950.580978378376
        },
        "chatglm-6b": {
            "rating": 968.6931410823978,
            "rating_q975": 986.6802588446853,
            "rating_q025": 950.7060233201103
        },
        "RWKV-4-Raven-14B": {
            "rating": 959.4057555659167,
            "rating_q975": 976.3543389302755,
            "rating_q025": 942.4571722015579
        },
        "fastchat-t5-3b": {
            "rating": 946.0131951249366,
            "rating_q975": 964.683393664737,
            "rating_q025": 927.3429965851362
        },
        "dolly-v2-12b": {
            "rating": 924.7209380794633,
            "rating_q975": 945.907894446147,
            "rating_q025": 903.5339817127796
        },
        "stablelm-tuned-alpha-7b": {
            "rating": 900.9523248699329,
            "rating_q975": 921.3147522891522,
            "rating_q025": 880.5898974507136
        },
        "llama-13b": {
            "rating": 900.533529208365,
            "rating_q975": 925.9621866767113,
            "rating_q025": 875.1048717400188
        }
    },
    "industry_business_and_management_and_financial_operations": {
        "gemini-3-pro": {
            "rating": 1478.855310343681,
            "rating_q975": 1490.6094415451314,
            "rating_q025": 1467.1011791422304
        },
        "grok-4.1-thinking": {
            "rating": 1477.1877854832762,
            "rating_q975": 1488.5535947904,
            "rating_q025": 1465.8219761761525
        },
        "claude-opus-4-5-20251101": {
            "rating": 1477.0123595212174,
            "rating_q975": 1490.6566078314534,
            "rating_q025": 1463.3681112109814
        },
        "grok-4.1": {
            "rating": 1471.9402092941216,
            "rating_q975": 1483.3501026327144,
            "rating_q025": 1460.5303159555287
        },
        "claude-opus-4-5-20251101-thinking-32k": {
            "rating": 1459.8929417279085,
            "rating_q975": 1473.9522985365052,
            "rating_q025": 1445.8335849193118
        },
        "chatgpt-4o-latest-20250326": {
            "rating": 1449.520697117867,
            "rating_q975": 1456.2827053823537,
            "rating_q025": 1442.7586888533804
        },
        "claude-sonnet-4-5-20250929": {
            "rating": 1448.9686998191207,
            "rating_q975": 1458.5746585130858,
            "rating_q025": 1439.3627411251557
        },
        "claude-opus-4-1-20250805-thinking-16k": {
            "rating": 1448.5222218911772,
            "rating_q975": 1455.889107876186,
            "rating_q025": 1441.1553359061684
        },
        "gpt-5.1-high": {
            "rating": 1446.0425682169216,
            "rating_q975": 1458.5417445815115,
            "rating_q025": 1433.5433918523318
        },
        "claude-opus-4-1-20250805": {
            "rating": 1442.6895919015722,
            "rating_q975": 1449.6582919440514,
            "rating_q025": 1435.720891859093
        },
        "qwen3-max-preview": {
            "rating": 1442.4493735191118,
            "rating_q975": 1451.2696183745818,
            "rating_q025": 1433.6291286636417
        },
        "claude-sonnet-4-5-20250929-thinking-32k": {
            "rating": 1441.9327554761862,
            "rating_q975": 1450.8274124310158,
            "rating_q025": 1433.0380985213567
        },
        "gpt-5.1": {
            "rating": 1440.6688890787816,
            "rating_q975": 1452.5285307242389,
            "rating_q025": 1428.8092474333243
        },
        "gpt-5-chat": {
            "rating": 1440.6118576348379,
            "rating_q975": 1449.0973510417841,
            "rating_q025": 1432.1263642278916
        },
        "qwen3-vl-235b-a22b-instruct": {
            "rating": 1437.1829591121827,
            "rating_q975": 1451.7802321209133,
            "rating_q025": 1422.5856861034522
        },
        "gemini-2.5-pro": {
            "rating": 1436.8219586454952,
            "rating_q975": 1443.2681436520409,
            "rating_q025": 1430.3757736389496
        },
        "qwen3-235b-a22b-instruct-2507": {
            "rating": 1430.854982536858,
            "rating_q975": 1437.8949627053792,
            "rating_q025": 1423.8150023683368
        },
        "o3-2025-04-16": {
            "rating": 1426.8855387271144,
            "rating_q975": 1433.9826818390673,
            "rating_q025": 1419.7883956151616
        },
        "gpt-4.5-preview-2025-02-27": {
            "rating": 1425.3188004351764,
            "rating_q975": 1440.8054618436383,
            "rating_q025": 1409.8321390267145
        },
        "qwen3-max-2025-09-23": {
            "rating": 1419.6477350882699,
            "rating_q975": 1433.5835209640027,
            "rating_q025": 1405.711949212537
        },
        "kimi-k2-thinking-turbo": {
            "rating": 1417.651979748093,
            "rating_q975": 1428.9460320133117,
            "rating_q025": 1406.3579274828744
        },
        "grok-4-1-fast-reasoning": {
            "rating": 1417.507817664975,
            "rating_q975": 1431.9482980585808,
            "rating_q025": 1403.067337271369
        },
        "deepseek-v3.1-terminus-thinking": {
            "rating": 1417.3676120433772,
            "rating_q975": 1439.7381470631783,
            "rating_q025": 1394.9970770235761
        },
        "gpt-5-high": {
            "rating": 1416.4163153706572,
            "rating_q975": 1425.3470455412285,
            "rating_q025": 1407.485585200086
        },
        "ernie-5.0-preview-1103": {
            "rating": 1416.2706057957814,
            "rating_q975": 1434.0579909306418,
            "rating_q025": 1398.483220660921
        },
        "deepseek-v3.2": {
            "rating": 1416.0402570357992,
            "rating_q975": 1432.63882774144,
            "rating_q025": 1399.4416863301583
        },
        "gpt-4.1-2025-04-14": {
            "rating": 1415.3077429402,
            "rating_q975": 1422.5512981792763,
            "rating_q025": 1408.0641877011235
        },
        "deepseek-v3.1": {
            "rating": 1413.6508677643712,
            "rating_q975": 1425.7461432132818,
            "rating_q025": 1401.5555923154607
        },
        "deepseek-v3.1-thinking": {
            "rating": 1413.4788156298048,
            "rating_q975": 1426.957925152861,
            "rating_q025": 1399.9997061067486
        },
        "kimi-k2-0711-preview": {
            "rating": 1413.4270059852972,
            "rating_q975": 1422.6618423950933,
            "rating_q025": 1404.192169575501
        },
        "deepseek-v3.2-thinking": {
            "rating": 1413.099779471867,
            "rating_q975": 1430.2556407363188,
            "rating_q025": 1395.943918207415
        },
        "deepseek-v3.2-exp": {
            "rating": 1412.7566600556104,
            "rating_q975": 1425.5783417388454,
            "rating_q025": 1399.9349783723753
        },
        "claude-opus-4-20250514-thinking-16k": {
            "rating": 1412.6177249746816,
            "rating_q975": 1420.8638118729991,
            "rating_q025": 1404.371638076364
        },
        "longcat-flash-chat": {
            "rating": 1412.4490608176693,
            "rating_q975": 1425.3360964679634,
            "rating_q025": 1399.5620251673752
        },
        "mistral-large-3": {
            "rating": 1411.7873009495363,
            "rating_q975": 1428.618967414061,
            "rating_q025": 1394.9556344850116
        },
        "mistral-medium-2508": {
            "rating": 1411.6818213287575,
            "rating_q975": 1419.219816256699,
            "rating_q025": 1404.143826400816
        },
        "qwen3-235b-a22b-no-thinking": {
            "rating": 1410.773956553934,
            "rating_q975": 1418.9938001736114,
            "rating_q025": 1402.5541129342569
        },
        "hunyuan-vision-1.5-thinking": {
            "rating": 1409.2434729098745,
            "rating_q975": 1436.3895603320987,
            "rating_q025": 1382.0973854876504
        },
        "glm-4.5": {
            "rating": 1408.7945356705868,
            "rating_q975": 1418.3143455772076,
            "rating_q025": 1399.274725763966
        },
        "qwen3-next-80b-a3b-instruct": {
            "rating": 1408.4700765878715,
            "rating_q975": 1418.0643793522495,
            "rating_q025": 1398.8757738234935
        },
        "kimi-k2-0905-preview": {
            "rating": 1408.0142084724837,
            "rating_q975": 1421.3116173279109,
            "rating_q025": 1394.7167996170565
        },
        "claude-haiku-4-5-20251001": {
            "rating": 1407.5763404766458,
            "rating_q975": 1416.7500492644695,
            "rating_q025": 1398.402631688822
        },
        "claude-opus-4-20250514": {
            "rating": 1407.0289945627173,
            "rating_q975": 1414.8387573059495,
            "rating_q025": 1399.2192318194852
        },
        "glm-4.6": {
            "rating": 1404.4297083797974,
            "rating_q975": 1413.7490418389716,
            "rating_q025": 1395.1103749206231
        },
        "hunyuan-turbos-20250416": {
            "rating": 1403.7916277027539,
            "rating_q975": 1419.6419251631658,
            "rating_q025": 1387.941330242342
        },
        "grok-4-fast-chat": {
            "rating": 1403.433452698599,
            "rating_q975": 1420.5243324927612,
            "rating_q025": 1386.3425729044368
        },
        "deepseek-v3.2-exp-thinking": {
            "rating": 1402.6935101145416,
            "rating_q975": 1416.6598354290516,
            "rating_q025": 1388.7271848000316
        },
        "deepseek-r1-0528": {
            "rating": 1400.8079613357443,
            "rating_q975": 1412.1112922126085,
            "rating_q025": 1389.50463045888
        },
        "qwen3-235b-a22b-thinking-2507": {
            "rating": 1400.221815130014,
            "rating_q975": 1415.2561027209993,
            "rating_q025": 1385.1875275390287
        },
        "gemini-2.5-flash-preview-09-2025": {
            "rating": 1399.1986018501336,
            "rating_q975": 1407.9073142236145,
            "rating_q025": 1390.4898894766527
        },
        "grok-4-fast-reasoning": {
            "rating": 1396.5403179767432,
            "rating_q975": 1406.6980205999282,
            "rating_q025": 1386.382615353558
        },
        "qwen3-30b-a3b-instruct-2507": {
            "rating": 1395.625970753214,
            "rating_q975": 1405.1896403424698,
            "rating_q025": 1386.0623011639582
        },
        "deepseek-v3.1-terminus": {
            "rating": 1394.2696376231077,
            "rating_q975": 1415.831297346169,
            "rating_q025": 1372.7079779000462
        },
        "grok-3-preview-02-24": {
            "rating": 1394.0807975039397,
            "rating_q975": 1403.7908592021222,
            "rating_q025": 1384.3707358057572
        },
        "qwen3-coder-480b-a35b-instruct": {
            "rating": 1392.360360160361,
            "rating_q975": 1402.2262364299415,
            "rating_q025": 1382.4944838907807
        },
        "gemini-2.5-flash": {
            "rating": 1392.0749208881048,
            "rating_q975": 1398.4657563328776,
            "rating_q025": 1385.684085443332
        },
        "grok-4-0709": {
            "rating": 1391.4222969401028,
            "rating_q975": 1398.9908684676307,
            "rating_q025": 1383.853725412575
        },
        "claude-sonnet-4-20250514": {
            "rating": 1390.3407487365562,
            "rating_q975": 1398.3961389242072,
            "rating_q025": 1382.2853585489052
        },
        "deepseek-v3-0324": {
            "rating": 1389.82949900508,
            "rating_q975": 1397.5303345330208,
            "rating_q025": 1382.128663477139
        },
        "deepseek-r1": {
            "rating": 1388.4912467890238,
            "rating_q975": 1402.297413944138,
            "rating_q025": 1374.6850796339095
        },
        "qwen3-vl-235b-a22b-thinking": {
            "rating": 1387.8421259298195,
            "rating_q975": 1402.6047459153576,
            "rating_q025": 1373.0795059442814
        },
        "mistral-medium-2505": {
            "rating": 1386.8516402595042,
            "rating_q975": 1395.7004531163716,
            "rating_q025": 1378.0028274026367
        },
        "claude-sonnet-4-20250514-thinking-32k": {
            "rating": 1386.2464959879692,
            "rating_q975": 1394.6174186288524,
            "rating_q025": 1377.875573347086
        },
        "gemma-3-12b-it": {
            "rating": 1384.011537114836,
            "rating_q975": 1414.3423466807506,
            "rating_q025": 1353.6807275489216
        },
        "gpt-4.1-mini-2025-04-14": {
            "rating": 1382.8110078966108,
            "rating_q975": 1391.0387650431023,
            "rating_q025": 1374.5832507501193
        },
        "o4-mini-2025-04-16": {
            "rating": 1382.1911738312067,
            "rating_q975": 1389.8557201495173,
            "rating_q025": 1374.526627512896
        },
        "gpt-5-mini-high": {
            "rating": 1381.5990464413235,
            "rating_q975": 1391.0328665854915,
            "rating_q025": 1372.1652262971554
        },
        "mai-1-preview": {
            "rating": 1379.0182289354327,
            "rating_q975": 1389.4450875592981,
            "rating_q025": 1368.5913703115673
        },
        "gemma-3-27b-it": {
            "rating": 1377.8176391796162,
            "rating_q975": 1385.5499416262794,
            "rating_q025": 1370.085336732953
        },
        "gemini-2.5-flash-lite-preview-09-2025-no-thinking": {
            "rating": 1376.1785292050172,
            "rating_q975": 1384.7254483964848,
            "rating_q025": 1367.6316100135496
        },
        "claude-3-7-sonnet-20250219": {
            "rating": 1374.812671677489,
            "rating_q975": 1383.1814970934693,
            "rating_q025": 1366.443846261509
        },
        "o1-2024-12-17": {
            "rating": 1371.0452232792948,
            "rating_q975": 1382.5427000858483,
            "rating_q025": 1359.5477464727412
        },
        "claude-3-7-sonnet-20250219-thinking-32k": {
            "rating": 1370.3446281449026,
            "rating_q975": 1378.9052238327986,
            "rating_q025": 1361.7840324570066
        },
        "hunyuan-turbos-20250226": {
            "rating": 1368.8380172636266,
            "rating_q975": 1401.2130557262171,
            "rating_q025": 1336.4629788010361
        },
        "qwen3-235b-a22b": {
            "rating": 1367.6250079303134,
            "rating_q975": 1377.2006664191747,
            "rating_q025": 1358.049349441452
        },
        "glm-4.5-air": {
            "rating": 1367.1293529096868,
            "rating_q975": 1375.5656094320411,
            "rating_q025": 1358.6930963873324
        },
        "qwen2.5-max": {
            "rating": 1366.9266242161607,
            "rating_q975": 1376.7711315814763,
            "rating_q025": 1357.082116850845
        },
        "mistral-small-2506": {
            "rating": 1364.6149047386757,
            "rating_q975": 1375.70809672023,
            "rating_q025": 1353.5217127571213
        },
        "qwen3-next-80b-a3b-thinking": {
            "rating": 1364.577323698294,
            "rating_q975": 1376.5976322993056,
            "rating_q025": 1352.5570150972826
        },
        "gemini-2.5-flash-lite-preview-06-17-thinking": {
            "rating": 1363.5764914757963,
            "rating_q975": 1372.1807729647494,
            "rating_q025": 1354.9722099868432
        },
        "hunyuan-t1-20250711": {
            "rating": 1361.255249020817,
            "rating_q975": 1382.760203002751,
            "rating_q025": 1339.750295038883
        },
        "claude-3-5-sonnet-20241022": {
            "rating": 1361.062371421957,
            "rating_q975": 1367.3151448855667,
            "rating_q025": 1354.8095979583475
        },
        "gemini-2.0-flash-lite-preview-02-05": {
            "rating": 1358.0277715409288,
            "rating_q975": 1369.6593776188668,
            "rating_q025": 1346.396165462991
        },
        "amazon-nova-experimental-chat-10-20": {
            "rating": 1356.4480341429235,
            "rating_q975": 1371.7716149369749,
            "rating_q025": 1341.124453348872
        },
        "o1-preview": {
            "rating": 1355.8731026314888,
            "rating_q975": 1366.2105522396216,
            "rating_q025": 1345.535653023356
        },
        "step-3": {
            "rating": 1355.208789521988,
            "rating_q975": 1372.1341999410988,
            "rating_q025": 1338.283379102877
        },
        "minimax-m1": {
            "rating": 1352.4701528783169,
            "rating_q975": 1360.5547856668265,
            "rating_q025": 1344.3855200898072
        },
        "deepseek-v3": {
            "rating": 1350.4911112579334,
            "rating_q975": 1362.732621116108,
            "rating_q025": 1338.2496013997588
        },
        "command-a-03-2025": {
            "rating": 1350.2520238257994,
            "rating_q975": 1357.2142340014063,
            "rating_q025": 1343.2898136501924
        },
        "intellect-3": {
            "rating": 1349.6792893204452,
            "rating_q975": 1378.3132455402447,
            "rating_q025": 1321.0453331006456
        },
        "o3-mini-high": {
            "rating": 1349.3494645906146,
            "rating_q975": 1362.8989421455158,
            "rating_q025": 1335.7999870357135
        },
        "minimax-m2": {
            "rating": 1348.444864114114,
            "rating_q975": 1365.0279814216271,
            "rating_q025": 1331.8617468066006
        },
        "hunyuan-turbo-0110": {
            "rating": 1348.2141405352118,
            "rating_q975": 1382.2355754477665,
            "rating_q025": 1314.192705622657
        },
        "gemini-2.0-flash-001": {
            "rating": 1346.3620141231945,
            "rating_q975": 1354.820347662942,
            "rating_q025": 1337.903680583447
        },
        "gpt-oss-120b": {
            "rating": 1345.3461531306946,
            "rating_q975": 1354.025775253811,
            "rating_q025": 1336.6665310075782
        },
        "glm-4-plus-0111": {
            "rating": 1345.3342273595426,
            "rating_q975": 1369.3448445881859,
            "rating_q025": 1321.3236101308994
        },
        "llama-3.1-nemotron-ultra-253b-v1": {
            "rating": 1343.7774778484663,
            "rating_q975": 1378.3135533836567,
            "rating_q025": 1309.241402313276
        },
        "qwen-plus-0125": {
            "rating": 1341.9653583241484,
            "rating_q975": 1365.6180868951074,
            "rating_q025": 1318.3126297531894
        },
        "ling-flash-2.0": {
            "rating": 1341.1369061697346,
            "rating_q975": 1357.275759881797,
            "rating_q025": 1324.9980524576722
        },
        "grok-3-mini-beta": {
            "rating": 1340.8252280894756,
            "rating_q975": 1350.9645012940343,
            "rating_q025": 1330.6859548849168
        },
        "glm-4.5v": {
            "rating": 1338.8251269043021,
            "rating_q975": 1358.4488950088526,
            "rating_q025": 1319.2013587997517
        },
        "nova-2-lite": {
            "rating": 1338.6452232426727,
            "rating_q975": 1356.2387713974942,
            "rating_q025": 1321.0516750878512
        },
        "qwen3-32b": {
            "rating": 1338.050837533045,
            "rating_q975": 1364.7681545150294,
            "rating_q025": 1311.3335205510607
        },
        "grok-3-mini-high": {
            "rating": 1337.8273911171914,
            "rating_q975": 1349.2794769899688,
            "rating_q025": 1326.375305244414
        },
        "qwq-32b": {
            "rating": 1335.7595903619488,
            "rating_q975": 1345.6995347814786,
            "rating_q025": 1325.819645942419
        },
        "gpt-5-nano-high": {
            "rating": 1335.657768018989,
            "rating_q975": 1351.4813603533464,
            "rating_q025": 1319.8341756846314
        },
        "amazon-nova-experimental-chat-10-09": {
            "rating": 1335.1725880999052,
            "rating_q975": 1349.6621210560936,
            "rating_q025": 1320.6830551437167
        },
        "gemini-1.5-pro-002": {
            "rating": 1333.7375748803329,
            "rating_q975": 1341.7082986358498,
            "rating_q025": 1325.766851124816
        },
        "gemma-3-4b-it": {
            "rating": 1329.6178442734267,
            "rating_q975": 1360.0271704981003,
            "rating_q025": 1299.2085180487531
        },
        "qwen3-30b-a3b": {
            "rating": 1328.5301752180103,
            "rating_q975": 1338.1165422672439,
            "rating_q025": 1318.9438081687767
        },
        "o3-mini": {
            "rating": 1327.4770085719992,
            "rating_q975": 1334.6282333162412,
            "rating_q025": 1320.3257838277573
        },
        "claude-3-5-sonnet-20240620": {
            "rating": 1327.4499324050498,
            "rating_q975": 1335.545154775916,
            "rating_q025": 1319.3547100341837
        },
        "gpt-4o-2024-05-13": {
            "rating": 1324.7661913015604,
            "rating_q975": 1332.0626918971411,
            "rating_q025": 1317.4696907059797
        },
        "nvidia-llama-3.3-nemotron-super-49b-v1.5": {
            "rating": 1323.6289441858075,
            "rating_q975": 1346.622275162803,
            "rating_q025": 1300.6356132088122
        },
        "gpt-4.1-nano-2025-04-14": {
            "rating": 1323.202879224857,
            "rating_q975": 1345.352309079294,
            "rating_q025": 1301.0534493704201
        },
        "mercury": {
            "rating": 1322.9787301591587,
            "rating_q975": 1355.2099874804985,
            "rating_q025": 1290.7474728378188
        },
        "llama-4-scout-17b-16e-instruct": {
            "rating": 1322.7868015008828,
            "rating_q975": 1331.8374767962289,
            "rating_q025": 1313.7361262055367
        },
        "gpt-oss-20b": {
            "rating": 1321.758331543244,
            "rating_q975": 1335.9438311167426,
            "rating_q025": 1307.5728319697453
        },
        "llama-4-maverick-17b-128e-instruct": {
            "rating": 1321.4330510957197,
            "rating_q975": 1329.6365759022704,
            "rating_q025": 1313.2295262891691
        },
        "ring-flash-2.0": {
            "rating": 1320.6488761359851,
            "rating_q975": 1336.9471578903638,
            "rating_q025": 1304.3505943816065
        },
        "claude-3-5-haiku-20241022": {
            "rating": 1320.1747973625816,
            "rating_q975": 1327.1098985883445,
            "rating_q025": 1313.2396961368186
        },
        "yi-lightning": {
            "rating": 1320.0132975771921,
            "rating_q975": 1330.9380948955827,
            "rating_q025": 1309.0885002588016
        },
        "glm-4-plus": {
            "rating": 1319.6249972171731,
            "rating_q975": 1330.7056897062812,
            "rating_q025": 1308.544304728065
        },
        "gemini-advanced-0514": {
            "rating": 1319.0961215676775,
            "rating_q975": 1329.4359071112192,
            "rating_q025": 1308.7563360241359
        },
        "llama-3.1-405b-instruct-fp8": {
            "rating": 1319.0735608402401,
            "rating_q975": 1327.3488845283719,
            "rating_q025": 1310.7982371521084
        },
        "gemma-3n-e4b-it": {
            "rating": 1319.006917674989,
            "rating_q975": 1329.5669048606526,
            "rating_q025": 1308.4469304893253
        },
        "llama-3.3-nemotron-49b-super-v1": {
            "rating": 1318.3324658272395,
            "rating_q975": 1353.5880605823456,
            "rating_q025": 1283.0768710721334
        },
        "llama-3.1-405b-instruct-bf16": {
            "rating": 1317.8998069871022,
            "rating_q975": 1326.8482573194165,
            "rating_q025": 1308.951356654788
        },
        "o1-mini": {
            "rating": 1317.8217011945712,
            "rating_q975": 1326.138165144324,
            "rating_q025": 1309.5052372448185
        },
        "grok-2-2024-08-13": {
            "rating": 1316.8465954219155,
            "rating_q975": 1324.7225082259204,
            "rating_q025": 1308.9706826179106
        },
        "gemini-1.5-pro-001": {
            "rating": 1315.138867777864,
            "rating_q975": 1323.7866139785328,
            "rating_q025": 1306.4911215771954
        },
        "step-1o-turbo-202506": {
            "rating": 1315.0100388320295,
            "rating_q975": 1330.6538198373623,
            "rating_q025": 1299.3662578266967
        },
        "qwen2.5-plus-1127": {
            "rating": 1313.4674175756143,
            "rating_q975": 1330.8943628453737,
            "rating_q025": 1296.0404723058548
        },
        "olmo-3-32b-think": {
            "rating": 1313.3863934738933,
            "rating_q975": 1337.1338743856236,
            "rating_q025": 1289.6389125621631
        },
        "claude-3-opus-20240229": {
            "rating": 1311.8671205918458,
            "rating_q975": 1318.643444119829,
            "rating_q025": 1305.0907970638627
        },
        "gpt-4o-mini-2024-07-18": {
            "rating": 1311.2138183937898,
            "rating_q975": 1318.7090537749668,
            "rating_q025": 1303.7185830126127
        },
        "step-2-16k-exp-202412": {
            "rating": 1310.3726121385116,
            "rating_q975": 1334.9732918961956,
            "rating_q025": 1285.7719323808276
        },
        "athene-v2-chat": {
            "rating": 1309.4110651483547,
            "rating_q975": 1320.4902287906405,
            "rating_q025": 1298.331901506069
        },
        "llama-3.3-70b-instruct": {
            "rating": 1307.6433572614776,
            "rating_q975": 1315.0559256281133,
            "rating_q025": 1300.230788894842
        },
        "qwen-max-0919": {
            "rating": 1307.5851085842614,
            "rating_q975": 1320.3513836466066,
            "rating_q025": 1294.8188335219163
        },
        "gpt-4o-2024-08-06": {
            "rating": 1306.6703806510257,
            "rating_q975": 1315.5691923495356,
            "rating_q025": 1297.7715689525157
        },
        "deepseek-v2.5-1210": {
            "rating": 1306.4665943747545,
            "rating_q975": 1328.012365600034,
            "rating_q025": 1284.9208231494752
        },
        "grok-2-mini-2024-08-13": {
            "rating": 1302.5221975527938,
            "rating_q975": 1310.7674913729684,
            "rating_q025": 1294.2769037326193
        },
        "athene-70b-0725": {
            "rating": 1301.9848711394357,
            "rating_q975": 1315.2701537848154,
            "rating_q025": 1288.699588494056
        },
        "deepseek-v2.5": {
            "rating": 1301.8554111547137,
            "rating_q975": 1313.2596119984075,
            "rating_q025": 1290.4512103110198
        },
        "hunyuan-standard-2025-02-10": {
            "rating": 1300.3797121314078,
            "rating_q975": 1329.1216401436063,
            "rating_q025": 1271.6377841192093
        },
        "qwen2.5-72b-instruct": {
            "rating": 1300.2674157785186,
            "rating_q975": 1309.4263880262763,
            "rating_q025": 1291.108443530761
        },
        "gemini-1.5-flash-002": {
            "rating": 1299.5244891259545,
            "rating_q975": 1309.0397657053281,
            "rating_q025": 1290.0092125465808
        },
        "mistral-small-3.1-24b-instruct-2503": {
            "rating": 1297.7158193559094,
            "rating_q975": 1306.4767901618286,
            "rating_q025": 1288.9548485499902
        },
        "gpt-4-turbo-2024-04-09": {
            "rating": 1297.0208475310696,
            "rating_q975": 1305.2960711067499,
            "rating_q025": 1288.7456239553894
        },
        "llama-3.1-nemotron-51b-instruct": {
            "rating": 1297.010014918626,
            "rating_q975": 1324.4184326627037,
            "rating_q025": 1269.6015971745483
        },
        "magistral-medium-2506": {
            "rating": 1296.799775708771,
            "rating_q975": 1310.3746665161523,
            "rating_q025": 1283.2248849013897
        },
        "mistral-large-2411": {
            "rating": 1296.6718296202962,
            "rating_q975": 1307.225413018499,
            "rating_q025": 1286.1182462220934
        },
        "llama-3.1-nemotron-70b-instruct": {
            "rating": 1295.8789872087355,
            "rating_q975": 1315.1145041697516,
            "rating_q025": 1276.6434702477193
        },
        "mistral-large-2407": {
            "rating": 1293.7900447626425,
            "rating_q975": 1302.9596913483515,
            "rating_q025": 1284.6203981769336
        },
        "hunyuan-large-2025-02-10": {
            "rating": 1290.9189487028084,
            "rating_q975": 1321.6942204326883,
            "rating_q025": 1260.1436769729285
        },
        "llama-3.1-70b-instruct": {
            "rating": 1290.3263197469555,
            "rating_q975": 1298.6269247722528,
            "rating_q025": 1282.0257147216582
        },
        "gemma-2-9b-it-simpo": {
            "rating": 1288.5057625369147,
            "rating_q975": 1305.7782274815083,
            "rating_q025": 1271.2332975923212
        },
        "gpt-4-0125-preview": {
            "rating": 1288.2050714658062,
            "rating_q975": 1296.8779604663614,
            "rating_q025": 1279.532182465251
        },
        "gemini-1.5-flash-001": {
            "rating": 1287.726262919849,
            "rating_q975": 1296.8490811470751,
            "rating_q025": 1278.6034446926228
        },
        "qwen2.5-coder-32b-instruct": {
            "rating": 1285.661455105115,
            "rating_q975": 1308.0818709908497,
            "rating_q025": 1263.2410392193804
        },
        "reka-core-20240904": {
            "rating": 1284.6757735987326,
            "rating_q975": 1304.2867754859199,
            "rating_q025": 1265.0647717115453
        },
        "gpt-4-1106-preview": {
            "rating": 1284.2566305987882,
            "rating_q975": 1292.8522780765531,
            "rating_q025": 1275.6609831210233
        },
        "gemma-2-27b-it": {
            "rating": 1283.1080085271383,
            "rating_q975": 1290.4542555067799,
            "rating_q025": 1275.7617615474967
        },
        "hunyuan-large-vision": {
            "rating": 1282.8489390968195,
            "rating_q975": 1304.3327553152815,
            "rating_q025": 1261.3651228783576
        },
        "amazon-nova-pro-v1.0": {
            "rating": 1279.456943529287,
            "rating_q975": 1290.6582787892746,
            "rating_q025": 1268.2556082692993
        },
        "llama-3.1-tulu-3-70b": {
            "rating": 1278.9153975183044,
            "rating_q975": 1311.6052421233264,
            "rating_q025": 1246.2255529132824
        },
        "command-r-plus-08-2024": {
            "rating": 1274.0962712085238,
            "rating_q975": 1291.2414652918123,
            "rating_q025": 1256.9510771252353
        },
        "reka-flash-20240904": {
            "rating": 1271.7884618465578,
            "rating_q975": 1290.5515419577782,
            "rating_q025": 1253.0253817353373
        },
        "c4ai-aya-expanse-32b": {
            "rating": 1270.8770364639404,
            "rating_q975": 1281.7552641934494,
            "rating_q025": 1259.9988087344313
        },
        "amazon-nova-lite-v1.0": {
            "rating": 1270.6678582189056,
            "rating_q975": 1283.459395204619,
            "rating_q025": 1257.8763212331921
        },
        "jamba-1.5-large": {
            "rating": 1268.3012670639405,
            "rating_q975": 1286.8154218402394,
            "rating_q025": 1249.7871122876415
        },
        "claude-3-sonnet-20240229": {
            "rating": 1268.1802465243286,
            "rating_q975": 1277.0603566820791,
            "rating_q025": 1259.300136366578
        },
        "gemma-2-9b-it": {
            "rating": 1265.435456792903,
            "rating_q975": 1273.771017465202,
            "rating_q025": 1257.0998961206042
        },
        "command-r-plus": {
            "rating": 1264.267600942124,
            "rating_q975": 1273.6140461659793,
            "rating_q025": 1254.921155718269
        },
        "nemotron-4-340b-instruct": {
            "rating": 1264.1232299035698,
            "rating_q975": 1277.2853399524947,
            "rating_q025": 1250.961119854645
        },
        "mistral-small-24b-instruct-2501": {
            "rating": 1262.4750326975468,
            "rating_q975": 1277.9894296498217,
            "rating_q025": 1246.960635745272
        },
        "phi-4": {
            "rating": 1258.6711367405587,
            "rating_q975": 1270.6387792852381,
            "rating_q025": 1246.7034941958793
        },
        "deepseek-coder-v2": {
            "rating": 1257.6201676664627,
            "rating_q975": 1271.9502237761849,
            "rating_q025": 1243.2901115567406
        },
        "gemini-1.5-flash-8b-001": {
            "rating": 1257.408853412679,
            "rating_q975": 1266.95127672713,
            "rating_q025": 1247.866430098228
        },
        "claude-3-haiku-20240307": {
            "rating": 1255.3544870251271,
            "rating_q975": 1263.3898090835175,
            "rating_q025": 1247.3191649667367
        },
        "llama-3-70b-instruct": {
            "rating": 1255.205605302464,
            "rating_q975": 1263.059232265833,
            "rating_q025": 1247.3519783390948
        },
        "gpt-4-0314": {
            "rating": 1253.657925943388,
            "rating_q975": 1264.7568794872966,
            "rating_q025": 1242.5589723994792
        },
        "glm-4-0520": {
            "rating": 1248.1175805688554,
            "rating_q975": 1265.4569925888802,
            "rating_q025": 1230.7781685488305
        },
        "llama-3.1-tulu-3-8b": {
            "rating": 1245.9288088451958,
            "rating_q975": 1278.0491419789987,
            "rating_q025": 1213.808475711393
        },
        "gpt-4-0613": {
            "rating": 1241.4869642313697,
            "rating_q975": 1250.7319599891434,
            "rating_q025": 1232.241968473596
        },
        "ministral-8b-2410": {
            "rating": 1238.0736623237144,
            "rating_q975": 1261.81297762645,
            "rating_q025": 1214.3343470209788
        },
        "olmo-2-0325-32b-instruct": {
            "rating": 1237.3518348491239,
            "rating_q975": 1269.5122988303717,
            "rating_q025": 1205.191370867876
        },
        "gemini-pro-dev-api": {
            "rating": 1235.3566283042414,
            "rating_q975": 1252.5174167962975,
            "rating_q025": 1218.1958398121853
        },
        "amazon-nova-micro-v1.0": {
            "rating": 1235.1984954497111,
            "rating_q975": 1248.2647262437522,
            "rating_q025": 1222.13226465567
        },
        "qwen2-72b-instruct": {
            "rating": 1233.8637393783915,
            "rating_q975": 1244.4274698148165,
            "rating_q025": 1223.3000089419666
        },
        "command-r-08-2024": {
            "rating": 1233.5237481194222,
            "rating_q975": 1251.0545617046912,
            "rating_q025": 1215.9929345341532
        },
        "granite-3.1-8b-instruct": {
            "rating": 1232.5331123974115,
            "rating_q975": 1265.9945415479503,
            "rating_q025": 1199.0716832468727
        },
        "reka-flash-21b-20240226-online": {
            "rating": 1231.748847379808,
            "rating_q975": 1247.3838247991669,
            "rating_q025": 1216.1138699604492
        },
        "c4ai-aya-expanse-8b": {
            "rating": 1230.509719339389,
            "rating_q975": 1248.4008332778478,
            "rating_q025": 1212.6186054009302
        },
        "command-r": {
            "rating": 1229.9842364988062,
            "rating_q975": 1240.4168848427719,
            "rating_q025": 1219.5515881548406
        },
        "mistral-large-2402": {
            "rating": 1227.9257545769751,
            "rating_q975": 1238.0231844355083,
            "rating_q025": 1217.828324718442
        },
        "jamba-1.5-mini": {
            "rating": 1226.8067434052055,
            "rating_q975": 1245.2977374569464,
            "rating_q025": 1208.3157493534645
        },
        "qwen1.5-110b-chat": {
            "rating": 1225.7224892732572,
            "rating_q975": 1238.0577004266904,
            "rating_q025": 1213.387278119824
        },
        "hunyuan-standard-256k": {
            "rating": 1224.3752005869699,
            "rating_q975": 1256.0436686848375,
            "rating_q025": 1192.7067324891023
        },
        "reka-flash-21b-20240226": {
            "rating": 1219.8364797905392,
            "rating_q975": 1233.0285580160303,
            "rating_q025": 1206.6444015650482
        },
        "mixtral-8x22b-instruct-v0.1": {
            "rating": 1218.857253046427,
            "rating_q975": 1228.8818962917642,
            "rating_q025": 1208.83260980109
        },
        "granite-3.1-2b-instruct": {
            "rating": 1218.535437713354,
            "rating_q975": 1248.4711678616418,
            "rating_q025": 1188.5997075650662
        },
        "mistral-medium": {
            "rating": 1213.8437509776322,
            "rating_q975": 1226.3905618786566,
            "rating_q025": 1201.2969400766078
        },
        "qwen1.5-72b-chat": {
            "rating": 1213.1232525472944,
            "rating_q975": 1224.671143682452,
            "rating_q025": 1201.5753614121368
        },
        "llama-3-8b-instruct": {
            "rating": 1211.6488166611962,
            "rating_q975": 1220.441400230243,
            "rating_q025": 1202.8562330921493
        },
        "llama-3.1-8b-instruct": {
            "rating": 1211.055440227386,
            "rating_q975": 1219.8963363066848,
            "rating_q025": 1202.2145441480873
        },
        "gpt-3.5-turbo-0125": {
            "rating": 1209.5538137777544,
            "rating_q975": 1219.1104246051577,
            "rating_q025": 1199.997202950351
        },
        "yi-1.5-34b-chat": {
            "rating": 1199.1630550568525,
            "rating_q975": 1211.3174426266658,
            "rating_q025": 1187.0086674870392
        },
        "zephyr-orpo-141b-A35b-v0.1": {
            "rating": 1189.9883796709844,
            "rating_q975": 1217.8469919816494,
            "rating_q025": 1162.1297673603194
        },
        "qwen1.5-32b-chat": {
            "rating": 1189.5108277662298,
            "rating_q975": 1203.1439979803793,
            "rating_q025": 1175.8776575520803
        },
        "mixtral-8x7b-instruct-v0.1": {
            "rating": 1185.589875728376,
            "rating_q975": 1195.3643817171433,
            "rating_q025": 1175.8153697396087
        },
        "phi-3-medium-4k-instruct": {
            "rating": 1185.3961236288774,
            "rating_q975": 1197.5740693650544,
            "rating_q025": 1173.2181778927004
        },
        "gemini-pro": {
            "rating": 1184.6555519709873,
            "rating_q975": 1214.8888725510133,
            "rating_q025": 1154.4222313909613
        },
        "gemma-2-2b-it": {
            "rating": 1183.7794928653907,
            "rating_q975": 1192.989265015884,
            "rating_q025": 1174.5697207148974
        },
        "dbrx-instruct-preview": {
            "rating": 1182.9514353393813,
            "rating_q975": 1196.2248437216738,
            "rating_q025": 1169.6780269570888
        },
        "llama2-70b-steerlm-chat": {
            "rating": 1180.874577879995,
            "rating_q975": 1216.8951918910998,
            "rating_q025": 1144.8539638688903
        },
        "openchat-3.5-0106": {
            "rating": 1179.6882410181256,
            "rating_q975": 1197.836690136481,
            "rating_q025": 1161.5397918997703
        },
        "gemma-1.1-7b-it": {
            "rating": 1179.2826977518819,
            "rating_q975": 1192.1870486018572,
            "rating_q025": 1166.3783469019065
        },
        "wizardlm-70b": {
            "rating": 1178.7562836026386,
            "rating_q975": 1202.8072929788304,
            "rating_q025": 1154.7052742264468
        },
        "qwen1.5-14b-chat": {
            "rating": 1177.70207326843,
            "rating_q975": 1193.311423977006,
            "rating_q025": 1162.092722559854
        },
        "yi-34b-chat": {
            "rating": 1175.933558920464,
            "rating_q975": 1192.523022487828,
            "rating_q025": 1159.3440953531
        },
        "starling-lm-7b-beta": {
            "rating": 1174.2034388030895,
            "rating_q975": 1190.672508560798,
            "rating_q025": 1157.734369045381
        },
        "tulu-2-dpo-70b": {
            "rating": 1173.304934711505,
            "rating_q975": 1198.8349366958425,
            "rating_q025": 1147.7749327271674
        },
        "deepseek-llm-67b-chat": {
            "rating": 1170.3331903409617,
            "rating_q975": 1198.614699977385,
            "rating_q025": 1142.0516807045383
        },
        "internlm2_5-20b-chat": {
            "rating": 1169.7844308922067,
            "rating_q975": 1186.8835097657736,
            "rating_q025": 1152.6853520186398
        },
        "llama-2-70b-chat": {
            "rating": 1166.3601591359438,
            "rating_q975": 1178.3387322803064,
            "rating_q025": 1154.3815859915812
        },
        "starling-lm-7b-alpha": {
            "rating": 1165.7756029985314,
            "rating_q975": 1186.36827715094,
            "rating_q025": 1145.1829288461229
        },
        "phi-3-small-8k-instruct": {
            "rating": 1165.034908224768,
            "rating_q975": 1178.8193218782942,
            "rating_q025": 1151.250494571242
        },
        "gpt-3.5-turbo-1106": {
            "rating": 1163.082138401783,
            "rating_q975": 1182.2684402333605,
            "rating_q025": 1143.8958365702053
        },
        "granite-3.0-8b-instruct": {
            "rating": 1158.882271429408,
            "rating_q975": 1181.8271898243745,
            "rating_q025": 1135.9373530344417
        },
        "vicuna-33b": {
            "rating": 1158.2924759583668,
            "rating_q975": 1173.7861561769923,
            "rating_q025": 1142.7987957397413
        },
        "nous-hermes-2-mixtral-8x7b-dpo": {
            "rating": 1158.0013879223345,
            "rating_q975": 1193.2451932496674,
            "rating_q025": 1122.7575825950016
        },
        "openchat-3.5": {
            "rating": 1155.819110657052,
            "rating_q975": 1179.7781776415186,
            "rating_q025": 1131.8600436725856
        },
        "qwen1.5-7b-chat": {
            "rating": 1155.6164533432952,
            "rating_q975": 1183.6025240705906,
            "rating_q025": 1127.630382616
        },
        "llama-3.2-3b-instruct": {
            "rating": 1150.731118523137,
            "rating_q975": 1170.8211498562819,
            "rating_q025": 1130.641087189992
        },
        "snowflake-arctic-instruct": {
            "rating": 1148.6371006810932,
            "rating_q975": 1161.9913392791552,
            "rating_q025": 1135.2828620830312
        },
        "granite-3.0-2b-instruct": {
            "rating": 1144.7095658083194,
            "rating_q975": 1166.6826356737342,
            "rating_q025": 1122.7364959429046
        },
        "llama-2-13b-chat": {
            "rating": 1140.461135276165,
            "rating_q975": 1156.4686891564625,
            "rating_q025": 1124.4535813958673
        },
        "openhermes-2.5-mistral-7b": {
            "rating": 1140.4580821055242,
            "rating_q975": 1170.3749120753562,
            "rating_q025": 1110.5412521356923
        },
        "mistral-7b-instruct-v0.2": {
            "rating": 1137.0517143707375,
            "rating_q975": 1152.694799927917,
            "rating_q025": 1121.408628813558
        },
        "solar-10.7b-instruct-v1.0": {
            "rating": 1135.9703380115361,
            "rating_q975": 1170.436589964433,
            "rating_q025": 1101.5040860586391
        },
        "codellama-34b-instruct": {
            "rating": 1135.899610276429,
            "rating_q975": 1160.7002674844587,
            "rating_q025": 1111.0989530683994
        },
        "mpt-30b-chat": {
            "rating": 1131.855723559087,
            "rating_q975": 1170.308558040801,
            "rating_q025": 1093.402889077373
        },
        "gemma-7b-it": {
            "rating": 1131.7384830881142,
            "rating_q975": 1153.484393696992,
            "rating_q025": 1109.9925724792365
        },
        "qwen-14b-chat": {
            "rating": 1128.1024001756393,
            "rating_q975": 1156.7390230698854,
            "rating_q025": 1099.4657772813932
        },
        "vicuna-13b": {
            "rating": 1127.673043334103,
            "rating_q975": 1144.9086208961494,
            "rating_q025": 1110.4374657720568
        },
        "phi-3-mini-4k-instruct": {
            "rating": 1118.0571464971886,
            "rating_q975": 1131.7103270960697,
            "rating_q025": 1104.4039658983074
        },
        "wizardlm-13b": {
            "rating": 1115.7257965442154,
            "rating_q975": 1140.3783323544899,
            "rating_q025": 1091.073260733941
        },
        "llama-2-7b-chat": {
            "rating": 1110.467754489218,
            "rating_q975": 1128.4804507708138,
            "rating_q025": 1092.455058207622
        },
        "phi-3-mini-4k-instruct-june-2024": {
            "rating": 1109.871229746521,
            "rating_q975": 1126.82788912108,
            "rating_q025": 1092.914570371962
        },
        "gemma-2b-it": {
            "rating": 1109.73350525984,
            "rating_q975": 1138.04561771646,
            "rating_q025": 1081.4213928032202
        },
        "gemma-1.1-2b-it": {
            "rating": 1109.3942146507939,
            "rating_q975": 1128.7535058321464,
            "rating_q025": 1090.0349234694413
        },
        "phi-3-mini-128k-instruct": {
            "rating": 1108.1620569678848,
            "rating_q975": 1124.2893834339582,
            "rating_q025": 1092.0347305018115
        },
        "qwq-32b-preview": {
            "rating": 1105.1564347670928,
            "rating_q975": 1137.8046599574884,
            "rating_q025": 1072.5082095766973
        },
        "palm-2": {
            "rating": 1104.5551643338674,
            "rating_q975": 1129.2566416351513,
            "rating_q025": 1079.8536870325836
        },
        "zephyr-7b-beta": {
            "rating": 1101.8675609043776,
            "rating_q975": 1122.473458935654,
            "rating_q025": 1081.2616628731012
        },
        "qwen1.5-4b-chat": {
            "rating": 1095.417044651977,
            "rating_q975": 1119.2985720548586,
            "rating_q025": 1071.5355172490954
        },
        "vicuna-7b": {
            "rating": 1094.1424991942272,
            "rating_q975": 1121.572953181625,
            "rating_q025": 1066.7120452068293
        },
        "stripedhyena-nous-7b": {
            "rating": 1090.7029637407936,
            "rating_q975": 1120.8467238001617,
            "rating_q025": 1060.5592036814255
        },
        "olmo-7b-instruct": {
            "rating": 1090.1158996733543,
            "rating_q975": 1116.6363892206932,
            "rating_q025": 1063.5954101260154
        },
        "guanaco-33b": {
            "rating": 1088.8937867058926,
            "rating_q975": 1127.840106739982,
            "rating_q025": 1049.947466671803
        },
        "mistral-7b-instruct": {
            "rating": 1081.1433063302852,
            "rating_q975": 1105.0807085604422,
            "rating_q025": 1057.2059041001282
        },
        "smollm2-1.7b-instruct": {
            "rating": 1081.1401893441566,
            "rating_q975": 1125.186783306051,
            "rating_q025": 1037.0935953822623
        },
        "llama-3.2-1b-instruct": {
            "rating": 1074.8971417569735,
            "rating_q975": 1095.887907423654,
            "rating_q025": 1053.906376090293
        },
        "koala-13b": {
            "rating": 1058.4345286971316,
            "rating_q975": 1088.0662722330887,
            "rating_q025": 1028.8027851611744
        },
        "chatglm3-6b": {
            "rating": 1054.5458294077891,
            "rating_q975": 1086.2986042280074,
            "rating_q025": 1022.7930545875709
        },
        "mpt-7b-chat": {
            "rating": 1020.00336439478,
            "rating_q975": 1057.4786668512138,
            "rating_q025": 982.5280619383461
        },
        "RWKV-4-Raven-14B": {
            "rating": 1019.4424401901965,
            "rating_q975": 1053.8469560209105,
            "rating_q025": 985.0379243594825
        },
        "chatglm2-6b": {
            "rating": 1017.2340721767837,
            "rating_q975": 1059.18059750114,
            "rating_q025": 975.2875468524273
        },
        "fastchat-t5-3b": {
            "rating": 1011.4846601855281,
            "rating_q975": 1050.1458598485642,
            "rating_q025": 972.8234605224922
        },
        "alpaca-13b": {
            "rating": 996.364522877896,
            "rating_q975": 1030.5348371845264,
            "rating_q025": 962.1942085712654
        },
        "oasst-pythia-12b": {
            "rating": 972.901178765668,
            "rating_q975": 1004.2793226670344,
            "rating_q025": 941.5230348643015
        },
        "chatglm-6b": {
            "rating": 960.6623403169674,
            "rating_q975": 999.4018038412996,
            "rating_q025": 921.9228767926352
        },
        "stablelm-tuned-alpha-7b": {
            "rating": 916.0635493393356,
            "rating_q975": 957.7107046652525,
            "rating_q025": 874.4163940134188
        },
        "dolly-v2-12b": {
            "rating": 912.0897094913619,
            "rating_q975": 956.8075552124419,
            "rating_q025": 867.3718637702818
        }
    },
    "industry_entertainment_and_sports_and_media": {
        "gemini-3-pro": {
            "rating": 1481.0619433871075,
            "rating_q975": 1493.0299033123868,
            "rating_q025": 1469.0939834618282
        },
        "claude-opus-4-5-20251101-thinking-32k": {
            "rating": 1456.917071785945,
            "rating_q975": 1471.329754028593,
            "rating_q025": 1442.5043895432968
        },
        "grok-4.1-thinking": {
            "rating": 1452.2516495595783,
            "rating_q975": 1463.9435787401353,
            "rating_q025": 1440.5597203790212
        },
        "claude-opus-4-5-20251101": {
            "rating": 1448.374437252227,
            "rating_q975": 1462.6197822192491,
            "rating_q025": 1434.1290922852047
        },
        "gemini-2.5-pro": {
            "rating": 1436.74834415763,
            "rating_q975": 1442.9979375790042,
            "rating_q025": 1430.498750736256
        },
        "claude-sonnet-4-5-20250929-thinking-32k": {
            "rating": 1436.4176878282308,
            "rating_q975": 1445.2488603557672,
            "rating_q025": 1427.5865153006944
        },
        "gpt-5.1-high": {
            "rating": 1434.9837037913683,
            "rating_q975": 1447.4563511883703,
            "rating_q025": 1422.5110563943663
        },
        "grok-4.1": {
            "rating": 1433.452357611501,
            "rating_q975": 1444.8434504080126,
            "rating_q025": 1422.0612648149893
        },
        "gpt-4.5-preview-2025-02-27": {
            "rating": 1432.1862882117086,
            "rating_q975": 1443.7965312110032,
            "rating_q025": 1420.576045212414
        },
        "claude-opus-4-1-20250805-thinking-16k": {
            "rating": 1427.178163974393,
            "rating_q975": 1434.4189706650375,
            "rating_q025": 1419.9373572837487
        },
        "claude-sonnet-4-5-20250929": {
            "rating": 1426.603098977699,
            "rating_q975": 1436.3556279526576,
            "rating_q025": 1416.8505700027401
        },
        "claude-opus-4-1-20250805": {
            "rating": 1425.0652367268729,
            "rating_q975": 1431.7604421957137,
            "rating_q025": 1418.370031258032
        },
        "chatgpt-4o-latest-20250326": {
            "rating": 1423.0275851437789,
            "rating_q975": 1429.216215401194,
            "rating_q025": 1416.8389548863638
        },
        "claude-opus-4-20250514-thinking-16k": {
            "rating": 1414.4890658892928,
            "rating_q975": 1422.3189502422906,
            "rating_q025": 1406.659181536295
        },
        "gpt-5.1": {
            "rating": 1407.5447927396146,
            "rating_q975": 1419.5526807242427,
            "rating_q025": 1395.5369047549866
        },
        "grok-4-1-fast-reasoning": {
            "rating": 1403.6558410483167,
            "rating_q975": 1418.3665046232,
            "rating_q025": 1388.9451774734334
        },
        "deepseek-v3.2-exp": {
            "rating": 1401.5336472001643,
            "rating_q975": 1414.421434819319,
            "rating_q025": 1388.6458595810095
        },
        "gpt-5-high": {
            "rating": 1400.4584029744058,
            "rating_q975": 1408.8750246502123,
            "rating_q025": 1392.0417812985993
        },
        "claude-opus-4-20250514": {
            "rating": 1397.3993229737027,
            "rating_q975": 1404.7217864582922,
            "rating_q025": 1390.0768594891133
        },
        "gpt-4.1-2025-04-14": {
            "rating": 1396.9212335136751,
            "rating_q975": 1403.6274435920313,
            "rating_q025": 1390.215023435319
        },
        "qwen3-max-preview": {
            "rating": 1395.9874366148044,
            "rating_q975": 1404.711394829759,
            "rating_q025": 1387.2634783998499
        },
        "grok-3-preview-02-24": {
            "rating": 1395.1030736582334,
            "rating_q975": 1403.280552206964,
            "rating_q025": 1386.9255951095026
        },
        "o3-2025-04-16": {
            "rating": 1394.8314806050073,
            "rating_q975": 1401.3183000848758,
            "rating_q025": 1388.3446611251388
        },
        "kimi-k2-thinking-turbo": {
            "rating": 1394.6562271857754,
            "rating_q975": 1406.253631158737,
            "rating_q025": 1383.0588232128136
        },
        "glm-4.6": {
            "rating": 1393.015078818315,
            "rating_q975": 1402.3057396622373,
            "rating_q025": 1383.7244179743927
        },
        "deepseek-v3.1-thinking": {
            "rating": 1391.9806237421126,
            "rating_q975": 1404.4018695075295,
            "rating_q025": 1379.5593779766957
        },
        "qwen3-max-2025-09-23": {
            "rating": 1389.8036481308689,
            "rating_q975": 1403.9714244484153,
            "rating_q025": 1375.6358718133224
        },
        "gpt-5-chat": {
            "rating": 1388.9670537634354,
            "rating_q975": 1397.1381161540608,
            "rating_q025": 1380.79599137281
        },
        "gemini-2.5-flash": {
            "rating": 1387.931337826034,
            "rating_q975": 1393.9315979766006,
            "rating_q025": 1381.9310776754673
        },
        "o1-2024-12-17": {
            "rating": 1387.7499964432957,
            "rating_q975": 1396.0323632952473,
            "rating_q025": 1379.4676295913441
        },
        "grok-4-0709": {
            "rating": 1386.6933657721574,
            "rating_q975": 1393.933494881827,
            "rating_q025": 1379.4532366624878
        },
        "deepseek-v3.2-exp-thinking": {
            "rating": 1386.5708667581189,
            "rating_q975": 1400.8982032694266,
            "rating_q025": 1372.2435302468111
        },
        "deepseek-v3.2": {
            "rating": 1386.1184496047913,
            "rating_q975": 1403.769545230234,
            "rating_q025": 1368.4673539793487
        },
        "deepseek-r1-0528": {
            "rating": 1385.231705045297,
            "rating_q975": 1395.6849024054225,
            "rating_q025": 1374.7785076851717
        },
        "ernie-5.0-preview-1103": {
            "rating": 1384.6956785039629,
            "rating_q975": 1403.210043421685,
            "rating_q025": 1366.1813135862408
        },
        "claude-sonnet-4-20250514-thinking-32k": {
            "rating": 1384.5811671405488,
            "rating_q975": 1392.474912136661,
            "rating_q025": 1376.6874221444366
        },
        "grok-4-fast-chat": {
            "rating": 1381.8826420934108,
            "rating_q975": 1398.0274656359295,
            "rating_q025": 1365.7378185508921
        },
        "glm-4.5": {
            "rating": 1381.6407887018152,
            "rating_q975": 1390.848930508426,
            "rating_q025": 1372.4326468952042
        },
        "deepseek-v3.2-thinking": {
            "rating": 1381.3382115575557,
            "rating_q975": 1399.4984766407233,
            "rating_q025": 1363.1779464743881
        },
        "gemini-2.5-flash-preview-09-2025": {
            "rating": 1380.7564021576454,
            "rating_q975": 1389.3926743695326,
            "rating_q025": 1372.1201299457582
        },
        "kimi-k2-0905-preview": {
            "rating": 1380.624582360519,
            "rating_q975": 1393.5135242818506,
            "rating_q025": 1367.7356404391876
        },
        "claude-3-7-sonnet-20250219-thinking-32k": {
            "rating": 1380.169098285457,
            "rating_q975": 1387.7594164842317,
            "rating_q025": 1372.5787800866824
        },
        "kimi-k2-0711-preview": {
            "rating": 1380.0534653134748,
            "rating_q975": 1388.6022393378828,
            "rating_q025": 1371.5046912890668
        },
        "deepseek-v3-0324": {
            "rating": 1378.6939208056733,
            "rating_q975": 1385.6253874787217,
            "rating_q025": 1371.762454132625
        },
        "deepseek-v3.1": {
            "rating": 1378.6150269634963,
            "rating_q975": 1389.8947701394404,
            "rating_q025": 1367.3352837875523
        },
        "deepseek-v3.1-terminus-thinking": {
            "rating": 1377.3929634731949,
            "rating_q975": 1401.3006291597287,
            "rating_q025": 1353.485297786661
        },
        "deepseek-v3.1-terminus": {
            "rating": 1375.0657314010793,
            "rating_q975": 1398.2162024005424,
            "rating_q025": 1351.9152604016163
        },
        "qwen3-235b-a22b-instruct-2507": {
            "rating": 1374.2914119557242,
            "rating_q975": 1381.081645194684,
            "rating_q025": 1367.5011787167646
        },
        "claude-haiku-4-5-20251001": {
            "rating": 1374.2820475116528,
            "rating_q975": 1383.4074990379668,
            "rating_q025": 1365.1565959853388
        },
        "mistral-large-3": {
            "rating": 1372.081679399238,
            "rating_q975": 1389.1692149108867,
            "rating_q025": 1354.9941438875894
        },
        "claude-sonnet-4-20250514": {
            "rating": 1371.1412870395627,
            "rating_q975": 1378.792751053727,
            "rating_q025": 1363.4898230253984
        },
        "deepseek-r1": {
            "rating": 1369.9536344503372,
            "rating_q975": 1379.6721793407357,
            "rating_q025": 1360.2350895599386
        },
        "o1-preview": {
            "rating": 1369.9238482895512,
            "rating_q975": 1379.2824577958322,
            "rating_q025": 1360.5652387832702
        },
        "mistral-medium-2508": {
            "rating": 1369.354314086057,
            "rating_q975": 1376.6337187111249,
            "rating_q025": 1362.0749094609891
        },
        "claude-3-7-sonnet-20250219": {
            "rating": 1368.4969936864522,
            "rating_q975": 1375.686937430296,
            "rating_q025": 1361.3070499426085
        },
        "grok-4-fast-reasoning": {
            "rating": 1366.2940454741997,
            "rating_q975": 1376.6384291781758,
            "rating_q025": 1355.9496617702237
        },
        "hunyuan-vision-1.5-thinking": {
            "rating": 1363.6025017707643,
            "rating_q975": 1392.717646805059,
            "rating_q025": 1334.4873567364696
        },
        "claude-3-5-sonnet-20241022": {
            "rating": 1361.9597381753026,
            "rating_q975": 1367.3795280398763,
            "rating_q025": 1356.539948310729
        },
        "qwen3-vl-235b-a22b-thinking": {
            "rating": 1361.9209925056825,
            "rating_q975": 1377.262654344597,
            "rating_q025": 1346.579330666768
        },
        "gemini-2.5-flash-lite-preview-06-17-thinking": {
            "rating": 1360.3132041785873,
            "rating_q975": 1368.3354011270565,
            "rating_q025": 1352.291007230118
        },
        "qwen3-vl-235b-a22b-instruct": {
            "rating": 1357.2236562469855,
            "rating_q975": 1372.3651502523187,
            "rating_q025": 1342.0821622416522
        },
        "qwen3-235b-a22b-no-thinking": {
            "rating": 1356.0625607530635,
            "rating_q975": 1363.714371055103,
            "rating_q025": 1348.4107504510241
        },
        "mai-1-preview": {
            "rating": 1352.3006960100633,
            "rating_q975": 1362.9305059070107,
            "rating_q025": 1341.670886113116
        },
        "o4-mini-2025-04-16": {
            "rating": 1351.0279263757463,
            "rating_q975": 1358.0327485223659,
            "rating_q025": 1344.0231042291268
        },
        "mistral-medium-2505": {
            "rating": 1350.7666399265472,
            "rating_q975": 1358.8472905412516,
            "rating_q025": 1342.6859893118428
        },
        "gpt-5-mini-high": {
            "rating": 1350.7552953990157,
            "rating_q975": 1359.866845826705,
            "rating_q025": 1341.6437449713264
        },
        "qwen3-coder-480b-a35b-instruct": {
            "rating": 1349.4583183686998,
            "rating_q975": 1358.5782822668998,
            "rating_q025": 1340.3383544704998
        },
        "gemini-2.5-flash-lite-preview-09-2025-no-thinking": {
            "rating": 1347.7848338577376,
            "rating_q975": 1356.4078786492826,
            "rating_q025": 1339.1617890661926
        },
        "deepseek-v3": {
            "rating": 1346.642837570246,
            "rating_q975": 1355.7741688138412,
            "rating_q025": 1337.5115063266508
        },
        "gpt-4.1-mini-2025-04-14": {
            "rating": 1344.2064742050782,
            "rating_q975": 1351.7537468231717,
            "rating_q025": 1336.6592015869846
        },
        "qwen3-235b-a22b-thinking-2507": {
            "rating": 1343.0873731075537,
            "rating_q975": 1357.5722144106226,
            "rating_q025": 1328.602531804485
        },
        "gemini-2.0-flash-001": {
            "rating": 1342.4231249252623,
            "rating_q975": 1349.292971663609,
            "rating_q025": 1335.5532781869156
        },
        "longcat-flash-chat": {
            "rating": 1340.259199302583,
            "rating_q975": 1353.407077982914,
            "rating_q025": 1327.1113206222522
        },
        "hunyuan-t1-20250711": {
            "rating": 1339.9479282753243,
            "rating_q975": 1359.2469608750005,
            "rating_q025": 1320.6488956756482
        },
        "qwen2.5-max": {
            "rating": 1337.1500284484493,
            "rating_q975": 1344.6562119380462,
            "rating_q025": 1329.6438449588525
        },
        "gemini-1.5-pro-002": {
            "rating": 1335.6168980768016,
            "rating_q975": 1342.1381178017436,
            "rating_q025": 1329.0956783518595
        },
        "gpt-4o-2024-05-13": {
            "rating": 1335.3706321685804,
            "rating_q975": 1341.9330279492683,
            "rating_q025": 1328.8082363878925
        },
        "hunyuan-turbos-20250416": {
            "rating": 1335.2572081483022,
            "rating_q975": 1348.4425374013304,
            "rating_q025": 1322.071878895274
        },
        "gemini-advanced-0514": {
            "rating": 1334.0365161594839,
            "rating_q975": 1343.37419858609,
            "rating_q025": 1324.6988337328778
        },
        "qwen3-30b-a3b-instruct-2507": {
            "rating": 1330.5373818736564,
            "rating_q975": 1339.779317363614,
            "rating_q025": 1321.2954463836988
        },
        "command-a-03-2025": {
            "rating": 1328.2638024759488,
            "rating_q975": 1334.5234344073565,
            "rating_q025": 1322.004170544541
        },
        "qwen3-next-80b-a3b-instruct": {
            "rating": 1327.4416242050875,
            "rating_q975": 1336.8295820687097,
            "rating_q025": 1318.0536663414653
        },
        "minimax-m1": {
            "rating": 1326.8102141268862,
            "rating_q975": 1334.4046488632798,
            "rating_q025": 1319.2157793904926
        },
        "gemma-3-27b-it": {
            "rating": 1326.4833815230693,
            "rating_q975": 1333.2474784261215,
            "rating_q025": 1319.719284620017
        },
        "glm-4.5-air": {
            "rating": 1325.0143300512975,
            "rating_q975": 1333.0642094337543,
            "rating_q025": 1316.9644506688408
        },
        "gemini-2.0-flash-lite-preview-02-05": {
            "rating": 1324.932352100836,
            "rating_q975": 1333.4524005068047,
            "rating_q025": 1316.4123036948672
        },
        "qwen3-235b-a22b": {
            "rating": 1323.2372953359777,
            "rating_q975": 1331.7425271008542,
            "rating_q025": 1314.7320635711012
        },
        "grok-3-mini-high": {
            "rating": 1322.7318446895333,
            "rating_q975": 1333.364910677832,
            "rating_q025": 1312.0987787012346
        },
        "gpt-4o-2024-08-06": {
            "rating": 1322.3249753013429,
            "rating_q975": 1330.3560682990303,
            "rating_q025": 1314.2938823036554
        },
        "mistral-small-2506": {
            "rating": 1322.1198278142203,
            "rating_q975": 1332.178443709708,
            "rating_q025": 1312.0612119187326
        },
        "step-3": {
            "rating": 1320.1872378858602,
            "rating_q975": 1337.3451810227505,
            "rating_q025": 1303.02929474897
        },
        "glm-4.5v": {
            "rating": 1318.7422640979592,
            "rating_q975": 1337.55066040135,
            "rating_q025": 1299.9338677945684
        },
        "grok-3-mini-beta": {
            "rating": 1318.6673216997867,
            "rating_q975": 1328.0788748381783,
            "rating_q025": 1309.2557685613951
        },
        "grok-2-2024-08-13": {
            "rating": 1312.5766716928788,
            "rating_q975": 1319.3252856063045,
            "rating_q025": 1305.828057779453
        },
        "gpt-4-turbo-2024-04-09": {
            "rating": 1311.341822441977,
            "rating_q975": 1318.5647827145724,
            "rating_q025": 1304.1188621693816
        },
        "qwen3-next-80b-a3b-thinking": {
            "rating": 1309.0519792434643,
            "rating_q975": 1321.1354731381828,
            "rating_q025": 1296.9684853487458
        },
        "claude-3-5-sonnet-20240620": {
            "rating": 1308.5237598049343,
            "rating_q975": 1315.5376060906021,
            "rating_q025": 1301.5099135192665
        },
        "o3-mini-high": {
            "rating": 1308.145653929363,
            "rating_q975": 1318.330706384235,
            "rating_q025": 1297.960601474491
        },
        "gemini-1.5-pro-001": {
            "rating": 1306.2389970095137,
            "rating_q975": 1313.7355643968854,
            "rating_q025": 1298.742429622142
        },
        "gemma-3-12b-it": {
            "rating": 1304.9031623736344,
            "rating_q975": 1326.2147226302006,
            "rating_q025": 1283.591602117068
        },
        "amazon-nova-experimental-chat-10-09": {
            "rating": 1302.4348995582395,
            "rating_q975": 1316.515180219812,
            "rating_q025": 1288.354618896667
        },
        "llama-3.1-405b-instruct-fp8": {
            "rating": 1302.095732560263,
            "rating_q975": 1309.2045000345818,
            "rating_q025": 1294.9869650859443
        },
        "llama-3.3-nemotron-49b-super-v1": {
            "rating": 1301.4658441316851,
            "rating_q975": 1328.3687050404583,
            "rating_q025": 1274.562983222912
        },
        "llama-3.1-nemotron-ultra-253b-v1": {
            "rating": 1301.1554067282707,
            "rating_q975": 1324.9846939347917,
            "rating_q025": 1277.3261195217497
        },
        "minimax-m2": {
            "rating": 1300.6615017740905,
            "rating_q975": 1317.735690932936,
            "rating_q025": 1283.587312615245
        },
        "o3-mini": {
            "rating": 1300.51938590807,
            "rating_q975": 1306.6290880528643,
            "rating_q025": 1294.4096837632758
        },
        "deepseek-v2.5-1210": {
            "rating": 1300.3295207338767,
            "rating_q975": 1316.2386539104434,
            "rating_q025": 1284.42038755731
        },
        "step-2-16k-exp-202412": {
            "rating": 1299.5650531850245,
            "rating_q975": 1317.8963398637625,
            "rating_q025": 1281.2337665062864
        },
        "hunyuan-large-2025-02-10": {
            "rating": 1299.2718003128543,
            "rating_q975": 1321.3959365628739,
            "rating_q025": 1277.1476640628348
        },
        "glm-4-plus-0111": {
            "rating": 1299.1845071754333,
            "rating_q975": 1316.5351598458717,
            "rating_q025": 1281.8338545049949
        },
        "hunyuan-turbo-0110": {
            "rating": 1298.9938514862918,
            "rating_q975": 1324.274309789794,
            "rating_q025": 1273.7133931827896
        },
        "claude-3-5-haiku-20241022": {
            "rating": 1298.4846307402067,
            "rating_q975": 1304.1756517870897,
            "rating_q025": 1292.7936096933238
        },
        "llama-4-maverick-17b-128e-instruct": {
            "rating": 1295.5854026615516,
            "rating_q975": 1303.0696914674597,
            "rating_q025": 1288.1011138556435
        },
        "llama-3.1-405b-instruct-bf16": {
            "rating": 1293.894859085264,
            "rating_q975": 1301.002776021929,
            "rating_q025": 1286.7869421485989
        },
        "yi-lightning": {
            "rating": 1292.9125243922026,
            "rating_q975": 1302.9071663790012,
            "rating_q025": 1282.917882405404
        },
        "qwen-plus-0125": {
            "rating": 1291.8429633585781,
            "rating_q975": 1308.4410870820254,
            "rating_q025": 1275.2448396351308
        },
        "llama-4-scout-17b-16e-instruct": {
            "rating": 1289.7003358400775,
            "rating_q975": 1298.1634075780921,
            "rating_q025": 1281.237264102063
        },
        "magistral-medium-2506": {
            "rating": 1288.6457331190252,
            "rating_q975": 1301.9709460263946,
            "rating_q025": 1275.3205202116558
        },
        "nova-2-lite": {
            "rating": 1288.5011148787717,
            "rating_q975": 1308.055758269792,
            "rating_q025": 1268.9464714877513
        },
        "gpt-4-1106-preview": {
            "rating": 1288.4597397427676,
            "rating_q975": 1295.946153929087,
            "rating_q025": 1280.9733255564483
        },
        "mistral-large-2407": {
            "rating": 1288.2460591062638,
            "rating_q975": 1296.2906139627264,
            "rating_q025": 1280.2015042498012
        },
        "amazon-nova-experimental-chat-10-20": {
            "rating": 1288.0000391060603,
            "rating_q975": 1304.0980985349113,
            "rating_q025": 1271.9019796772093
        },
        "nvidia-llama-3.3-nemotron-super-49b-v1.5": {
            "rating": 1286.611893596782,
            "rating_q975": 1309.175008624173,
            "rating_q025": 1264.048778569391
        },
        "gpt-oss-120b": {
            "rating": 1286.205673383575,
            "rating_q975": 1294.4211045683592,
            "rating_q025": 1277.9902421987908
        },
        "gpt-4.1-nano-2025-04-14": {
            "rating": 1285.4786518013743,
            "rating_q975": 1302.7827936232368,
            "rating_q025": 1268.1745099795119
        },
        "gpt-4-0125-preview": {
            "rating": 1285.4639401501372,
            "rating_q975": 1293.1314240183362,
            "rating_q025": 1277.7964562819382
        },
        "qwen3-32b": {
            "rating": 1284.8343949982836,
            "rating_q975": 1305.60599841539,
            "rating_q025": 1264.0627915811772
        },
        "hunyuan-turbos-20250226": {
            "rating": 1284.4359850003998,
            "rating_q975": 1310.0566411657483,
            "rating_q025": 1258.8153288350513
        },
        "llama-3.3-70b-instruct": {
            "rating": 1284.3064557254465,
            "rating_q975": 1290.3930788284433,
            "rating_q025": 1278.2198326224498
        },
        "qwq-32b": {
            "rating": 1283.7055585443272,
            "rating_q975": 1292.327586543086,
            "rating_q025": 1275.0835305455685
        },
        "gpt-4o-mini-2024-07-18": {
            "rating": 1281.8140748861451,
            "rating_q975": 1288.0610046933537,
            "rating_q025": 1275.5671450789366
        },
        "claude-3-opus-20240229": {
            "rating": 1281.7675184011905,
            "rating_q975": 1287.5798905014465,
            "rating_q025": 1275.9551463009345
        },
        "gpt-5-nano-high": {
            "rating": 1281.1837751103371,
            "rating_q975": 1297.587171746193,
            "rating_q025": 1264.7803784744813
        },
        "intellect-3": {
            "rating": 1280.6260973415024,
            "rating_q975": 1310.4364084151837,
            "rating_q025": 1250.815786267821
        },
        "o1-mini": {
            "rating": 1279.3023216991862,
            "rating_q975": 1286.2523327852934,
            "rating_q025": 1272.352310613079
        },
        "gemma-3n-e4b-it": {
            "rating": 1278.5334111616967,
            "rating_q975": 1287.9363256926938,
            "rating_q025": 1269.1304966306996
        },
        "glm-4-plus": {
            "rating": 1278.1160280596691,
            "rating_q975": 1287.9596846431214,
            "rating_q025": 1268.272371476217
        },
        "ling-flash-2.0": {
            "rating": 1277.1293772929089,
            "rating_q975": 1294.0667998428075,
            "rating_q025": 1260.1919547430102
        },
        "qwen-max-0919": {
            "rating": 1276.686098751265,
            "rating_q975": 1288.3531663280833,
            "rating_q025": 1265.0190311744468
        },
        "mistral-small-3.1-24b-instruct-2503": {
            "rating": 1276.0181076338358,
            "rating_q975": 1284.065140497319,
            "rating_q025": 1267.9710747703527
        },
        "step-1o-turbo-202506": {
            "rating": 1275.4909930479348,
            "rating_q975": 1290.117526947894,
            "rating_q025": 1260.8644591479756
        },
        "olmo-3-32b-think": {
            "rating": 1275.2030844373885,
            "rating_q975": 1300.4729914669279,
            "rating_q025": 1249.9331774078491
        },
        "gemini-1.5-flash-002": {
            "rating": 1272.1730151445,
            "rating_q975": 1280.193893914521,
            "rating_q025": 1264.152136374479
        },
        "ring-flash-2.0": {
            "rating": 1270.2397421748522,
            "rating_q975": 1286.682751371538,
            "rating_q025": 1253.7967329781663
        },
        "gemma-2-27b-it": {
            "rating": 1270.2185727525975,
            "rating_q975": 1276.3735460763155,
            "rating_q025": 1264.0635994288796
        },
        "qwen3-30b-a3b": {
            "rating": 1269.5238468566163,
            "rating_q975": 1278.2839343732567,
            "rating_q025": 1260.7637593399759
        },
        "mistral-large-2411": {
            "rating": 1269.1957360179565,
            "rating_q975": 1277.3461292690351,
            "rating_q025": 1261.0453427668779
        },
        "athene-70b-0725": {
            "rating": 1268.7804101055895,
            "rating_q975": 1279.2153111106384,
            "rating_q025": 1258.3455091005405
        },
        "jamba-1.5-large": {
            "rating": 1267.5798106240302,
            "rating_q975": 1282.8842001445396,
            "rating_q025": 1252.2754211035208
        },
        "llama-3.1-nemotron-70b-instruct": {
            "rating": 1266.4583345531605,
            "rating_q975": 1285.4340575389622,
            "rating_q025": 1247.4826115673588
        },
        "gemma-2-9b-it-simpo": {
            "rating": 1265.9986502507934,
            "rating_q975": 1280.1128296350037,
            "rating_q025": 1251.8844708665831
        },
        "gpt-4-0613": {
            "rating": 1265.521796459165,
            "rating_q975": 1273.4768543082855,
            "rating_q025": 1257.5667386100445
        },
        "llama-3.1-70b-instruct": {
            "rating": 1262.4453761479708,
            "rating_q975": 1269.5748856844218,
            "rating_q025": 1255.3158666115198
        },
        "deepseek-v2.5": {
            "rating": 1261.7362294132308,
            "rating_q975": 1271.7368155405727,
            "rating_q025": 1251.735643285889
        },
        "grok-2-mini-2024-08-13": {
            "rating": 1261.3183947099142,
            "rating_q975": 1268.3889271178916,
            "rating_q025": 1254.2478623019367
        },
        "gpt-4-0314": {
            "rating": 1260.9079621803542,
            "rating_q975": 1270.4601457721628,
            "rating_q025": 1251.3557785885455
        },
        "llama-3.1-tulu-3-70b": {
            "rating": 1259.2513452866121,
            "rating_q975": 1281.7028900541684,
            "rating_q025": 1236.799800519056
        },
        "mercury": {
            "rating": 1258.1005068883242,
            "rating_q975": 1290.5127410736,
            "rating_q025": 1225.6882727030484
        },
        "gpt-oss-20b": {
            "rating": 1257.1517969112406,
            "rating_q975": 1271.9778915311106,
            "rating_q025": 1242.3257022913706
        },
        "hunyuan-standard-2025-02-10": {
            "rating": 1256.318974975713,
            "rating_q975": 1278.3596273014525,
            "rating_q025": 1234.2783226499735
        },
        "command-r-plus-08-2024": {
            "rating": 1256.054947109049,
            "rating_q975": 1270.7370638238351,
            "rating_q025": 1241.3728303942628
        },
        "hunyuan-large-vision": {
            "rating": 1253.8242440332012,
            "rating_q975": 1273.3735043664433,
            "rating_q025": 1234.2749836999592
        },
        "gemini-1.5-flash-001": {
            "rating": 1253.3999978673264,
            "rating_q975": 1261.1590991980665,
            "rating_q025": 1245.6408965365863
        },
        "qwen2.5-plus-1127": {
            "rating": 1252.943983179222,
            "rating_q975": 1265.8164777229072,
            "rating_q025": 1240.0714886355368
        },
        "nemotron-4-340b-instruct": {
            "rating": 1251.7967622578176,
            "rating_q975": 1263.1416267226712,
            "rating_q025": 1240.451897792964
        },
        "olmo-2-0325-32b-instruct": {
            "rating": 1251.315926067314,
            "rating_q975": 1274.3620789714191,
            "rating_q025": 1228.2697731632088
        },
        "llama-3.1-nemotron-51b-instruct": {
            "rating": 1248.6251020305433,
            "rating_q975": 1272.4072670130915,
            "rating_q025": 1224.842937047995
        },
        "llama-3-70b-instruct": {
            "rating": 1247.8819901314391,
            "rating_q975": 1254.862236173074,
            "rating_q025": 1240.9017440898042
        },
        "gemma-3-4b-it": {
            "rating": 1247.7487629085792,
            "rating_q975": 1268.4371043962758,
            "rating_q025": 1227.0604214208827
        },
        "athene-v2-chat": {
            "rating": 1246.8029614594664,
            "rating_q975": 1255.6189622135587,
            "rating_q025": 1237.986960705374
        },
        "gemma-2-9b-it": {
            "rating": 1245.180624855538,
            "rating_q975": 1251.9649915897057,
            "rating_q025": 1238.3962581213705
        },
        "reka-core-20240904": {
            "rating": 1244.7229853150573,
            "rating_q975": 1261.8431551709298,
            "rating_q025": 1227.6028154591847
        },
        "qwen2.5-72b-instruct": {
            "rating": 1242.5566059867406,
            "rating_q975": 1250.3633040331354,
            "rating_q025": 1234.7499079403458
        },
        "amazon-nova-pro-v1.0": {
            "rating": 1237.5144481487746,
            "rating_q975": 1245.997884918703,
            "rating_q025": 1229.0310113788462
        },
        "claude-3-sonnet-20240229": {
            "rating": 1236.3828843515305,
            "rating_q975": 1244.0258431552459,
            "rating_q025": 1228.7399255478151
        },
        "command-r-plus": {
            "rating": 1235.6691818099082,
            "rating_q975": 1243.8521276033898,
            "rating_q025": 1227.4862360164266
        },
        "glm-4-0520": {
            "rating": 1231.611228264608,
            "rating_q975": 1246.0317286583168,
            "rating_q025": 1217.190727870899
        },
        "reka-flash-20240904": {
            "rating": 1225.9784386983188,
            "rating_q975": 1242.6651374780465,
            "rating_q025": 1209.291739918591
        },
        "mistral-small-24b-instruct-2501": {
            "rating": 1222.7879248093168,
            "rating_q975": 1234.241143136773,
            "rating_q025": 1211.3347064818606
        },
        "qwen2-72b-instruct": {
            "rating": 1219.5959168051868,
            "rating_q975": 1228.5997930884257,
            "rating_q025": 1210.5920405219479
        },
        "c4ai-aya-expanse-32b": {
            "rating": 1219.5944670511553,
            "rating_q975": 1228.6341027287144,
            "rating_q025": 1210.5548313735962
        },
        "claude-3-haiku-20240307": {
            "rating": 1217.8250563835302,
            "rating_q975": 1224.8879146698705,
            "rating_q025": 1210.7621980971899
        },
        "gemini-1.5-flash-8b-001": {
            "rating": 1216.0643338142665,
            "rating_q975": 1224.3106954432626,
            "rating_q025": 1207.8179721852705
        },
        "command-r-08-2024": {
            "rating": 1213.8284070400973,
            "rating_q975": 1228.0478461895323,
            "rating_q025": 1199.6089678906624
        },
        "mistral-large-2402": {
            "rating": 1210.5850599257058,
            "rating_q975": 1219.399883800734,
            "rating_q025": 1201.7702360506776
        },
        "deepseek-coder-v2": {
            "rating": 1209.3641741831916,
            "rating_q975": 1221.600436872258,
            "rating_q025": 1197.1279114941253
        },
        "jamba-1.5-mini": {
            "rating": 1207.7766934807778,
            "rating_q975": 1222.9857362240464,
            "rating_q025": 1192.5676507375092
        },
        "amazon-nova-lite-v1.0": {
            "rating": 1205.4594826847888,
            "rating_q975": 1215.3008876434787,
            "rating_q025": 1195.6180777260988
        },
        "phi-4": {
            "rating": 1200.2056688717462,
            "rating_q975": 1209.1062259060386,
            "rating_q025": 1191.3051118374538
        },
        "mixtral-8x22b-instruct-v0.1": {
            "rating": 1200.1531492437298,
            "rating_q975": 1208.9395133624553,
            "rating_q025": 1191.3667851250043
        },
        "reka-flash-21b-20240226-online": {
            "rating": 1195.2235925271477,
            "rating_q975": 1209.3586844857928,
            "rating_q025": 1181.0885005685027
        },
        "gpt-3.5-turbo-0125": {
            "rating": 1192.93311025296,
            "rating_q975": 1201.2872123675256,
            "rating_q025": 1184.5790081383943
        },
        "command-r": {
            "rating": 1192.3004762846413,
            "rating_q975": 1201.4561324293243,
            "rating_q025": 1183.1448201399583
        },
        "amazon-nova-micro-v1.0": {
            "rating": 1191.7920490580705,
            "rating_q975": 1201.7044237711104,
            "rating_q025": 1181.8796743450305
        },
        "qwen1.5-110b-chat": {
            "rating": 1190.1944154408206,
            "rating_q975": 1201.1283643655977,
            "rating_q025": 1179.2604665160436
        },
        "ministral-8b-2410": {
            "rating": 1187.9085751757868,
            "rating_q975": 1208.1837666629633,
            "rating_q025": 1167.6333836886104
        },
        "zephyr-orpo-141b-A35b-v0.1": {
            "rating": 1187.5879884674182,
            "rating_q975": 1210.7789479968528,
            "rating_q025": 1164.3970289379836
        },
        "mistral-medium": {
            "rating": 1187.3249593166558,
            "rating_q975": 1197.8865457179932,
            "rating_q025": 1176.7633729153185
        },
        "llama-3-8b-instruct": {
            "rating": 1184.959975289652,
            "rating_q975": 1192.5501390503885,
            "rating_q025": 1177.3698115289155
        },
        "qwen2.5-coder-32b-instruct": {
            "rating": 1184.792942491888,
            "rating_q975": 1203.3544184865407,
            "rating_q025": 1166.2314664972353
        },
        "qwen1.5-72b-chat": {
            "rating": 1184.6636015738757,
            "rating_q975": 1194.595175532248,
            "rating_q025": 1174.7320276155033
        },
        "gemini-pro-dev-api": {
            "rating": 1183.7240129188,
            "rating_q975": 1197.7820964310456,
            "rating_q025": 1169.6659294065546
        },
        "hunyuan-standard-256k": {
            "rating": 1182.9722386761784,
            "rating_q975": 1212.244361987293,
            "rating_q025": 1153.700115365064
        },
        "c4ai-aya-expanse-8b": {
            "rating": 1179.61587440034,
            "rating_q975": 1193.2037011432283,
            "rating_q025": 1166.028047657452
        },
        "llama-3.1-tulu-3-8b": {
            "rating": 1178.2356260758838,
            "rating_q975": 1201.2079962065832,
            "rating_q025": 1155.2632559451845
        },
        "gemini-pro": {
            "rating": 1173.352641294743,
            "rating_q975": 1194.2564271493625,
            "rating_q025": 1152.4488554401237
        },
        "wizardlm-70b": {
            "rating": 1173.0671042741549,
            "rating_q975": 1190.5524087277593,
            "rating_q025": 1155.5817998205505
        },
        "llama-3.1-8b-instruct": {
            "rating": 1172.3904341905827,
            "rating_q975": 1180.1213357676659,
            "rating_q025": 1164.6595326134996
        },
        "gemma-2-2b-it": {
            "rating": 1169.706527642204,
            "rating_q975": 1177.3305835246942,
            "rating_q025": 1162.0824717597138
        },
        "tulu-2-dpo-70b": {
            "rating": 1169.25709699659,
            "rating_q975": 1189.3290728169502,
            "rating_q025": 1149.1851211762298
        },
        "openchat-3.5": {
            "rating": 1169.107401953914,
            "rating_q975": 1186.352653686315,
            "rating_q025": 1151.8621502215128
        },
        "dbrx-instruct-preview": {
            "rating": 1167.8325241770017,
            "rating_q975": 1179.2106909876024,
            "rating_q025": 1156.454357366401
        },
        "granite-3.1-8b-instruct": {
            "rating": 1164.5621587089786,
            "rating_q975": 1189.557705886841,
            "rating_q025": 1139.5666115311162
        },
        "mixtral-8x7b-instruct-v0.1": {
            "rating": 1164.4168664940526,
            "rating_q975": 1172.6559635664255,
            "rating_q025": 1156.1777694216796
        },
        "vicuna-33b": {
            "rating": 1162.9837540479011,
            "rating_q975": 1174.9160471795817,
            "rating_q025": 1151.0514609162205
        },
        "reka-flash-21b-20240226": {
            "rating": 1160.6897758583946,
            "rating_q975": 1172.3939179094057,
            "rating_q025": 1148.9856338073835
        },
        "gpt-3.5-turbo-1106": {
            "rating": 1158.4201274119487,
            "rating_q975": 1173.436073709982,
            "rating_q025": 1143.4041811139152
        },
        "yi-34b-chat": {
            "rating": 1157.2554813720526,
            "rating_q975": 1170.4933473108206,
            "rating_q025": 1144.0176154332846
        },
        "yi-1.5-34b-chat": {
            "rating": 1150.966228726955,
            "rating_q975": 1161.506658742965,
            "rating_q025": 1140.425798710945
        },
        "openhermes-2.5-mistral-7b": {
            "rating": 1147.8609591025183,
            "rating_q975": 1168.9480945927935,
            "rating_q025": 1126.7738236122432
        },
        "gemma-1.1-7b-it": {
            "rating": 1147.64438655892,
            "rating_q975": 1158.9802558847673,
            "rating_q025": 1136.3085172330725
        },
        "granite-3.1-2b-instruct": {
            "rating": 1146.703513741783,
            "rating_q975": 1170.5090950365172,
            "rating_q025": 1122.8979324470486
        },
        "snowflake-arctic-instruct": {
            "rating": 1143.1802384292819,
            "rating_q975": 1154.9409033176644,
            "rating_q025": 1131.4195735408994
        },
        "llama-3.2-3b-instruct": {
            "rating": 1140.1252088532196,
            "rating_q975": 1158.2941703047627,
            "rating_q025": 1121.9562474016766
        },
        "granite-3.0-8b-instruct": {
            "rating": 1139.5624595937354,
            "rating_q975": 1160.1215534163434,
            "rating_q025": 1119.0033657711274
        },
        "qwen1.5-32b-chat": {
            "rating": 1138.6453388520408,
            "rating_q975": 1150.7160713305634,
            "rating_q025": 1126.5746063735182
        },
        "openchat-3.5-0106": {
            "rating": 1138.537182502205,
            "rating_q975": 1153.066236628733,
            "rating_q025": 1124.0081283756772
        },
        "deepseek-llm-67b-chat": {
            "rating": 1137.9204436657392,
            "rating_q975": 1159.1935855282782,
            "rating_q025": 1116.6473018032002
        },
        "guanaco-33b": {
            "rating": 1137.8646539879078,
            "rating_q975": 1167.4733574303373,
            "rating_q025": 1108.2559505454783
        },
        "wizardlm-13b": {
            "rating": 1137.7059739311842,
            "rating_q975": 1155.9594885528825,
            "rating_q025": 1119.452459309486
        },
        "falcon-180b-chat": {
            "rating": 1137.3670435284387,
            "rating_q975": 1174.9179645026525,
            "rating_q025": 1099.8161225542249
        },
        "phi-3-medium-4k-instruct": {
            "rating": 1134.3806361649895,
            "rating_q975": 1144.7638032804991,
            "rating_q025": 1123.9974690494798
        },
        "starling-lm-7b-alpha": {
            "rating": 1131.835336971857,
            "rating_q975": 1147.1583954290531,
            "rating_q025": 1116.512278514661
        },
        "mpt-30b-chat": {
            "rating": 1127.447530077388,
            "rating_q975": 1156.6388398940783,
            "rating_q025": 1098.2562202606975
        },
        "qwen1.5-14b-chat": {
            "rating": 1123.6212442798892,
            "rating_q975": 1137.3189844886958,
            "rating_q025": 1109.9235040710826
        },
        "internlm2_5-20b-chat": {
            "rating": 1121.5235791341438,
            "rating_q975": 1137.4051356399514,
            "rating_q025": 1105.6420226283362
        },
        "solar-10.7b-instruct-v1.0": {
            "rating": 1120.88949925025,
            "rating_q975": 1144.9589998739825,
            "rating_q025": 1096.8199986265176
        },
        "dolphin-2.2.1-mistral-7b": {
            "rating": 1116.9902747601848,
            "rating_q975": 1150.3998838789514,
            "rating_q025": 1083.5806656414181
        },
        "zephyr-7b-beta": {
            "rating": 1113.4755370119115,
            "rating_q975": 1129.3073171442893,
            "rating_q025": 1097.6437568795336
        },
        "starling-lm-7b-beta": {
            "rating": 1112.430114358417,
            "rating_q975": 1127.2472845812363,
            "rating_q025": 1097.612944135598
        },
        "phi-3-small-8k-instruct": {
            "rating": 1112.2871424753862,
            "rating_q975": 1124.7268978928585,
            "rating_q025": 1099.847387057914
        },
        "nous-hermes-2-mixtral-8x7b-dpo": {
            "rating": 1111.3437883550691,
            "rating_q975": 1135.0789146353027,
            "rating_q025": 1087.6086620748356
        },
        "llama-2-70b-chat": {
            "rating": 1110.3846111739126,
            "rating_q975": 1120.2298538204648,
            "rating_q025": 1100.5393685273605
        },
        "llama2-70b-steerlm-chat": {
            "rating": 1108.6022568871747,
            "rating_q975": 1133.3008872914943,
            "rating_q025": 1083.903626482855
        },
        "vicuna-13b": {
            "rating": 1107.794571591709,
            "rating_q975": 1120.2803727849664,
            "rating_q025": 1095.3087703984515
        },
        "mistral-7b-instruct-v0.2": {
            "rating": 1107.311784346023,
            "rating_q975": 1119.4712146196125,
            "rating_q025": 1095.1523540724334
        },
        "granite-3.0-2b-instruct": {
            "rating": 1104.2552865552002,
            "rating_q975": 1125.0995868054124,
            "rating_q025": 1083.410986304988
        },
        "qwq-32b-preview": {
            "rating": 1103.6746286123598,
            "rating_q975": 1130.5646406861154,
            "rating_q025": 1076.7846165386043
        },
        "llama-2-13b-chat": {
            "rating": 1101.0573099095132,
            "rating_q975": 1113.4539117358306,
            "rating_q025": 1088.6607080831957
        },
        "zephyr-7b-alpha": {
            "rating": 1097.7576748227084,
            "rating_q975": 1129.6575719739094,
            "rating_q025": 1065.8577776715074
        },
        "vicuna-7b": {
            "rating": 1094.2597181180918,
            "rating_q975": 1111.9364784943564,
            "rating_q025": 1076.5829577418272
        },
        "palm-2": {
            "rating": 1093.2286367507313,
            "rating_q975": 1110.9969492840173,
            "rating_q025": 1075.4603242174453
        },
        "phi-3-mini-4k-instruct-june-2024": {
            "rating": 1089.5515332639598,
            "rating_q975": 1103.3753366078408,
            "rating_q025": 1075.7277299200787
        },
        "gemma-7b-it": {
            "rating": 1086.4519368982492,
            "rating_q975": 1104.0819888837827,
            "rating_q025": 1068.8218849127156
        },
        "stripedhyena-nous-7b": {
            "rating": 1085.5416841033857,
            "rating_q975": 1106.7746752286232,
            "rating_q025": 1064.3086929781482
        },
        "phi-3-mini-128k-instruct": {
            "rating": 1084.0514745572418,
            "rating_q975": 1098.1879847315397,
            "rating_q025": 1069.914964382944
        },
        "qwen1.5-7b-chat": {
            "rating": 1083.5031605873758,
            "rating_q975": 1106.1207538946212,
            "rating_q025": 1060.8855672801303
        },
        "gemma-1.1-2b-it": {
            "rating": 1082.963839615894,
            "rating_q975": 1099.6828198183114,
            "rating_q025": 1066.2448594134764
        },
        "qwen-14b-chat": {
            "rating": 1082.146278677824,
            "rating_q975": 1103.4608022638233,
            "rating_q025": 1060.8317550918248
        },
        "llama-3.2-1b-instruct": {
            "rating": 1078.883468269666,
            "rating_q975": 1097.8585642200414,
            "rating_q025": 1059.9083723192907
        },
        "codellama-34b-instruct": {
            "rating": 1078.0491455979895,
            "rating_q975": 1094.8570334553003,
            "rating_q025": 1061.2412577406787
        },
        "mistral-7b-instruct": {
            "rating": 1076.5634491832038,
            "rating_q975": 1093.9614129911374,
            "rating_q025": 1059.1654853752702
        },
        "smollm2-1.7b-instruct": {
            "rating": 1076.1679143565239,
            "rating_q975": 1109.6017612512112,
            "rating_q025": 1042.7340674618365
        },
        "phi-3-mini-4k-instruct": {
            "rating": 1067.6354183059257,
            "rating_q975": 1079.8409593303747,
            "rating_q025": 1055.4298772814766
        },
        "alpaca-13b": {
            "rating": 1067.1830411096444,
            "rating_q975": 1088.8918548095817,
            "rating_q025": 1045.474227409707
        },
        "llama-2-7b-chat": {
            "rating": 1066.1988873795854,
            "rating_q975": 1079.756743046777,
            "rating_q025": 1052.6410317123937
        },
        "gemma-2b-it": {
            "rating": 1064.4880246944072,
            "rating_q975": 1087.568394622047,
            "rating_q025": 1041.4076547667673
        },
        "qwen1.5-4b-chat": {
            "rating": 1044.619560024226,
            "rating_q975": 1062.8798361787678,
            "rating_q025": 1026.3592838696843
        },
        "gpt4all-13b-snoozy": {
            "rating": 1043.896417232906,
            "rating_q975": 1081.5205151301302,
            "rating_q025": 1006.2723193356819
        },
        "mpt-7b-chat": {
            "rating": 1031.0377935390795,
            "rating_q975": 1055.475000627223,
            "rating_q025": 1006.6005864509361
        },
        "koala-13b": {
            "rating": 1025.5641690061343,
            "rating_q975": 1046.0159869110714,
            "rating_q025": 1005.1123511011971
        },
        "olmo-7b-instruct": {
            "rating": 1023.7840710463017,
            "rating_q975": 1044.7741275277178,
            "rating_q025": 1002.7940145648856
        },
        "chatglm3-6b": {
            "rating": 1014.1005459223672,
            "rating_q975": 1037.775691502492,
            "rating_q025": 990.4254003422425
        },
        "chatglm2-6b": {
            "rating": 991.6043524456497,
            "rating_q975": 1019.5892085787292,
            "rating_q025": 963.6194963125703
        },
        "RWKV-4-Raven-14B": {
            "rating": 986.4653867949067,
            "rating_q975": 1008.6663164675856,
            "rating_q025": 964.2644571222279
        },
        "oasst-pythia-12b": {
            "rating": 982.478476164408,
            "rating_q975": 1003.8890747056537,
            "rating_q025": 961.0678776231623
        },
        "fastchat-t5-3b": {
            "rating": 953.8632836549525,
            "rating_q975": 978.7462248766416,
            "rating_q025": 928.9803424332634
        },
        "dolly-v2-12b": {
            "rating": 931.0709172205972,
            "rating_q975": 959.0826586364564,
            "rating_q025": 903.059175804738
        },
        "llama-13b": {
            "rating": 930.6588482463814,
            "rating_q975": 962.8874537336835,
            "rating_q025": 898.4302427590792
        },
        "chatglm-6b": {
            "rating": 908.9545360741686,
            "rating_q975": 933.8360594156861,
            "rating_q025": 884.073012732651
        },
        "stablelm-tuned-alpha-7b": {
            "rating": 901.4274309698258,
            "rating_q975": 930.4071455157789,
            "rating_q025": 872.4477164238726
        }
    },
    "industry_legal_and_government": {
        "grok-4.1-thinking": {
            "rating": 1509.6237011771007,
            "rating_q975": 1528.325162658228,
            "rating_q025": 1490.9222396959733
        },
        "gemini-3-pro": {
            "rating": 1499.7852280747782,
            "rating_q975": 1518.7124084239795,
            "rating_q025": 1480.8580477255769
        },
        "claude-opus-4-5-20251101": {
            "rating": 1490.7035984187553,
            "rating_q975": 1513.5042032550841,
            "rating_q025": 1467.9029935824265
        },
        "grok-4.1": {
            "rating": 1484.1941117577442,
            "rating_q975": 1502.7760425003873,
            "rating_q025": 1465.612181015101
        },
        "claude-opus-4-5-20251101-thinking-32k": {
            "rating": 1478.8403681465975,
            "rating_q975": 1501.810320951717,
            "rating_q025": 1455.870415341478
        },
        "gemini-2.5-pro": {
            "rating": 1472.8799795317825,
            "rating_q975": 1482.5292083096037,
            "rating_q025": 1463.2307507539613
        },
        "gpt-4.5-preview-2025-02-27": {
            "rating": 1469.533902893208,
            "rating_q975": 1491.9968316836657,
            "rating_q025": 1447.0709741027504
        },
        "claude-opus-4-1-20250805-thinking-16k": {
            "rating": 1463.7893065741546,
            "rating_q975": 1475.9010983635856,
            "rating_q025": 1451.6775147847236
        },
        "deepseek-v3.1-terminus-thinking": {
            "rating": 1461.2774030633789,
            "rating_q975": 1496.7830580021096,
            "rating_q025": 1425.7717481246482
        },
        "chatgpt-4o-latest-20250326": {
            "rating": 1460.8836863894542,
            "rating_q975": 1471.28054027738,
            "rating_q025": 1450.4868325015284
        },
        "gpt-5-chat": {
            "rating": 1459.9543918172405,
            "rating_q975": 1474.0877544139796,
            "rating_q025": 1445.8210292205015
        },
        "gpt-5.1-high": {
            "rating": 1459.8613223963773,
            "rating_q975": 1480.2093253618089,
            "rating_q025": 1439.5133194309458
        },
        "gpt-5-high": {
            "rating": 1459.397745522331,
            "rating_q975": 1474.0183160228903,
            "rating_q025": 1444.7771750217717
        },
        "claude-opus-4-1-20250805": {
            "rating": 1457.9701322033118,
            "rating_q975": 1468.7066705306272,
            "rating_q025": 1447.2335938759963
        },
        "o3-2025-04-16": {
            "rating": 1455.995087236384,
            "rating_q975": 1466.4206808898557,
            "rating_q025": 1445.5694935829124
        },
        "kimi-k2-0905-preview": {
            "rating": 1455.6302927309468,
            "rating_q975": 1476.8907327304344,
            "rating_q025": 1434.3698527314593
        },
        "gpt-5.1": {
            "rating": 1454.8008640273667,
            "rating_q975": 1474.3368871495152,
            "rating_q025": 1435.2648409052183
        },
        "claude-sonnet-4-5-20250929": {
            "rating": 1450.9911832594485,
            "rating_q975": 1467.075068766184,
            "rating_q025": 1434.907297752713
        },
        "claude-sonnet-4-5-20250929-thinking-32k": {
            "rating": 1449.6335499449867,
            "rating_q975": 1464.6966444623713,
            "rating_q025": 1434.5704554276022
        },
        "mistral-large-3": {
            "rating": 1443.8954979505938,
            "rating_q975": 1472.6832877219524,
            "rating_q025": 1415.1077081792353
        },
        "deepseek-v3.2": {
            "rating": 1443.4086456662376,
            "rating_q975": 1472.1253951655806,
            "rating_q025": 1414.6918961668946
        },
        "claude-opus-4-20250514": {
            "rating": 1442.1288413999837,
            "rating_q975": 1453.5472246479671,
            "rating_q025": 1430.7104581520002
        },
        "gpt-4.1-2025-04-14": {
            "rating": 1439.0624571639473,
            "rating_q975": 1449.9269085887204,
            "rating_q025": 1428.1980057391743
        },
        "deepseek-v3.2-thinking": {
            "rating": 1438.5784266153216,
            "rating_q975": 1467.5744315160623,
            "rating_q025": 1409.582421714581
        },
        "claude-opus-4-20250514-thinking-16k": {
            "rating": 1437.2050338679371,
            "rating_q975": 1449.78486449165,
            "rating_q025": 1424.6252032442242
        },
        "ernie-5.0-preview-1103": {
            "rating": 1436.8372883704797,
            "rating_q975": 1463.5587468587094,
            "rating_q025": 1410.11582988225
        },
        "grok-4-1-fast-reasoning": {
            "rating": 1433.1066939681757,
            "rating_q975": 1457.9843759054295,
            "rating_q025": 1408.229012030922
        },
        "qwen3-vl-235b-a22b-instruct": {
            "rating": 1432.0454848905156,
            "rating_q975": 1457.0928655511573,
            "rating_q025": 1406.998104229874
        },
        "grok-4-fast-chat": {
            "rating": 1431.5175964851737,
            "rating_q975": 1459.4047663047766,
            "rating_q025": 1403.630426665571
        },
        "kimi-k2-thinking-turbo": {
            "rating": 1428.5700897815066,
            "rating_q975": 1448.2171282622178,
            "rating_q025": 1408.9230513007954
        },
        "qwen3-max-preview": {
            "rating": 1427.6707690509272,
            "rating_q975": 1442.2801748754725,
            "rating_q025": 1413.061363226382
        },
        "glm-4.6": {
            "rating": 1425.8622671392159,
            "rating_q975": 1441.7147460322692,
            "rating_q025": 1410.0097882461625
        },
        "gemini-2.5-flash": {
            "rating": 1425.2128148453987,
            "rating_q975": 1434.658303550951,
            "rating_q025": 1415.7673261398465
        },
        "kimi-k2-0711-preview": {
            "rating": 1424.9964263324036,
            "rating_q975": 1439.5967579419844,
            "rating_q025": 1410.396094722823
        },
        "grok-4-fast-reasoning": {
            "rating": 1422.7278828537924,
            "rating_q975": 1440.2455127893497,
            "rating_q025": 1405.210252918235
        },
        "deepseek-v3.1": {
            "rating": 1422.4720843413188,
            "rating_q975": 1440.7734609666811,
            "rating_q025": 1404.1707077159565
        },
        "grok-4-0709": {
            "rating": 1422.1093463752711,
            "rating_q975": 1434.1173806118072,
            "rating_q025": 1410.101312138735
        },
        "gemini-2.5-flash-preview-09-2025": {
            "rating": 1421.8708671009063,
            "rating_q975": 1436.40432736316,
            "rating_q025": 1407.3374068386524
        },
        "qwen3-235b-a22b-instruct-2507": {
            "rating": 1421.4802768943468,
            "rating_q975": 1432.7092079853678,
            "rating_q025": 1410.2513458033259
        },
        "deepseek-v3.1-terminus": {
            "rating": 1421.3073441457313,
            "rating_q975": 1456.1759097440647,
            "rating_q025": 1386.438778547398
        },
        "deepseek-v3.1-thinking": {
            "rating": 1419.2394902966766,
            "rating_q975": 1440.0563340363647,
            "rating_q025": 1398.4226465569886
        },
        "mistral-medium-2508": {
            "rating": 1418.1610499224194,
            "rating_q975": 1430.1782278669154,
            "rating_q025": 1406.1438719779233
        },
        "deepseek-v3.2-exp-thinking": {
            "rating": 1417.8925851923004,
            "rating_q975": 1443.3907904071104,
            "rating_q025": 1392.3943799774904
        },
        "qwen3-max-2025-09-23": {
            "rating": 1415.1937599036794,
            "rating_q975": 1439.6565030186264,
            "rating_q025": 1390.7310167887324
        },
        "grok-3-preview-02-24": {
            "rating": 1414.7701220119388,
            "rating_q975": 1428.8747317622954,
            "rating_q025": 1400.6655122615823
        },
        "claude-sonnet-4-20250514": {
            "rating": 1414.4161441636516,
            "rating_q975": 1426.539730011446,
            "rating_q025": 1402.2925583158571
        },
        "glm-4.5": {
            "rating": 1414.0587758929198,
            "rating_q975": 1429.8278196013507,
            "rating_q025": 1398.289732184489
        },
        "qwen3-next-80b-a3b-instruct": {
            "rating": 1412.7265434276276,
            "rating_q975": 1428.8907517370965,
            "rating_q025": 1396.5623351181587
        },
        "claude-sonnet-4-20250514-thinking-32k": {
            "rating": 1412.1501697471242,
            "rating_q975": 1425.1736563109803,
            "rating_q025": 1399.1266831832681
        },
        "deepseek-v3.2-exp": {
            "rating": 1412.04104362941,
            "rating_q975": 1433.4431500961578,
            "rating_q025": 1390.6389371626624
        },
        "mistral-medium-2505": {
            "rating": 1410.6310801302689,
            "rating_q975": 1423.5513465693498,
            "rating_q025": 1397.710813691188
        },
        "deepseek-r1-0528": {
            "rating": 1410.380679830894,
            "rating_q975": 1426.7247674844086,
            "rating_q025": 1394.0365921773794
        },
        "deepseek-v3-0324": {
            "rating": 1409.1536304093565,
            "rating_q975": 1420.4794963081347,
            "rating_q025": 1397.8277645105784
        },
        "o1-2024-12-17": {
            "rating": 1408.864213122743,
            "rating_q975": 1424.232344326962,
            "rating_q025": 1393.496081918524
        },
        "claude-3-7-sonnet-20250219-thinking-32k": {
            "rating": 1406.61837447835,
            "rating_q975": 1418.870573525182,
            "rating_q025": 1394.366175431518
        },
        "o4-mini-2025-04-16": {
            "rating": 1402.2492495989081,
            "rating_q975": 1413.9595584538727,
            "rating_q025": 1390.5389407439436
        },
        "gpt-4.1-mini-2025-04-14": {
            "rating": 1401.914238995083,
            "rating_q975": 1414.0709300503402,
            "rating_q025": 1389.7575479398258
        },
        "claude-3-7-sonnet-20250219": {
            "rating": 1401.583260831584,
            "rating_q975": 1413.966955474829,
            "rating_q025": 1389.199566188339
        },
        "qwen3-235b-a22b-no-thinking": {
            "rating": 1401.5654730829253,
            "rating_q975": 1413.7260553548442,
            "rating_q025": 1389.4048908110065
        },
        "deepseek-r1": {
            "rating": 1399.249321678748,
            "rating_q975": 1416.8192990174896,
            "rating_q025": 1381.6793443400063
        },
        "qwen3-coder-480b-a35b-instruct": {
            "rating": 1398.7860407986457,
            "rating_q975": 1414.6686845361444,
            "rating_q025": 1382.903397061147
        },
        "qwen3-vl-235b-a22b-thinking": {
            "rating": 1398.2328397331642,
            "rating_q975": 1423.8782345917368,
            "rating_q025": 1372.5874448745915
        },
        "mai-1-preview": {
            "rating": 1397.6949501065574,
            "rating_q975": 1415.269005251363,
            "rating_q025": 1380.1208949617517
        },
        "gemini-2.5-flash-lite-preview-09-2025-no-thinking": {
            "rating": 1395.925891936844,
            "rating_q975": 1410.3683912454435,
            "rating_q025": 1381.4833926282445
        },
        "o1-preview": {
            "rating": 1395.0812798814309,
            "rating_q975": 1408.9611680395278,
            "rating_q025": 1381.201391723334
        },
        "claude-haiku-4-5-20251001": {
            "rating": 1394.2074429618526,
            "rating_q975": 1410.249214099771,
            "rating_q025": 1378.1656718239342
        },
        "gpt-5-mini-high": {
            "rating": 1392.3116546486654,
            "rating_q975": 1407.671209226173,
            "rating_q025": 1376.9521000711577
        },
        "claude-3-5-sonnet-20241022": {
            "rating": 1390.782464057458,
            "rating_q975": 1399.322807774773,
            "rating_q025": 1382.2421203401427
        },
        "qwen3-235b-a22b-thinking-2507": {
            "rating": 1388.1356165783989,
            "rating_q975": 1412.4280155581953,
            "rating_q025": 1363.8432175986025
        },
        "longcat-flash-chat": {
            "rating": 1387.4829206100756,
            "rating_q975": 1408.888016697495,
            "rating_q025": 1366.077824522656
        },
        "deepseek-v3": {
            "rating": 1386.9876856554529,
            "rating_q975": 1403.097548670265,
            "rating_q025": 1370.8778226406407
        },
        "qwen2.5-max": {
            "rating": 1385.5798088816168,
            "rating_q975": 1399.3135195398115,
            "rating_q025": 1371.8460982234221
        },
        "hunyuan-t1-20250711": {
            "rating": 1385.119394680245,
            "rating_q975": 1419.207681852941,
            "rating_q025": 1351.031107507549
        },
        "gemini-2.0-flash-001": {
            "rating": 1384.1612257464674,
            "rating_q975": 1395.8334354812175,
            "rating_q025": 1372.4890160117172
        },
        "gemini-2.5-flash-lite-preview-06-17-thinking": {
            "rating": 1383.7989032857583,
            "rating_q975": 1396.9798412635937,
            "rating_q025": 1370.617965307923
        },
        "glm-4-plus-0111": {
            "rating": 1382.3620769202696,
            "rating_q975": 1412.0983751372355,
            "rating_q025": 1352.6257787033037
        },
        "gemma-3-27b-it": {
            "rating": 1382.27352613687,
            "rating_q975": 1393.877932417672,
            "rating_q025": 1370.6691198560682
        },
        "gemini-2.0-flash-lite-preview-02-05": {
            "rating": 1382.1651980769177,
            "rating_q975": 1397.4364015529304,
            "rating_q025": 1366.893994600905
        },
        "gemini-advanced-0514": {
            "rating": 1381.7496035170716,
            "rating_q975": 1395.3515352772122,
            "rating_q025": 1368.147671756931
        },
        "gemma-3-12b-it": {
            "rating": 1380.4901458273719,
            "rating_q975": 1419.647995911008,
            "rating_q025": 1341.3322957437358
        },
        "qwen3-30b-a3b-instruct-2507": {
            "rating": 1380.1680056925074,
            "rating_q975": 1395.653012893509,
            "rating_q025": 1364.682998491506
        },
        "grok-3-mini-high": {
            "rating": 1379.9807349701143,
            "rating_q975": 1397.3135191149297,
            "rating_q025": 1362.647950825299
        },
        "hunyuan-turbos-20250416": {
            "rating": 1379.3738761596821,
            "rating_q975": 1400.4998403883453,
            "rating_q025": 1358.247911931019
        },
        "qwen-plus-0125": {
            "rating": 1379.1780709997151,
            "rating_q975": 1407.5409766103296,
            "rating_q025": 1350.8151653891007
        },
        "gpt-4o-2024-05-13": {
            "rating": 1376.1358112776047,
            "rating_q975": 1385.3963810170558,
            "rating_q025": 1366.8752415381537
        },
        "command-a-03-2025": {
            "rating": 1375.805801737869,
            "rating_q975": 1386.309058515253,
            "rating_q025": 1365.302544960485
        },
        "llama-3.1-405b-instruct-bf16": {
            "rating": 1374.9671182502987,
            "rating_q975": 1387.3553089118693,
            "rating_q025": 1362.578927588728
        },
        "llama-3.1-405b-instruct-fp8": {
            "rating": 1374.882170006959,
            "rating_q975": 1385.8093128427581,
            "rating_q025": 1363.95502717116
        },
        "mistral-small-2506": {
            "rating": 1372.5131797452516,
            "rating_q975": 1389.6697509300793,
            "rating_q025": 1355.3566085604239
        },
        "gemini-1.5-pro-002": {
            "rating": 1370.6993241774649,
            "rating_q975": 1381.2501197031158,
            "rating_q025": 1360.1485286518139
        },
        "yi-lightning": {
            "rating": 1368.4411890729116,
            "rating_q975": 1382.9272165292798,
            "rating_q025": 1353.9551616165434
        },
        "glm-4.5v": {
            "rating": 1367.691014353165,
            "rating_q975": 1402.5179717557867,
            "rating_q025": 1332.8640569505433
        },
        "grok-2-2024-08-13": {
            "rating": 1366.6804790543647,
            "rating_q975": 1377.0860560705817,
            "rating_q025": 1356.2749020381477
        },
        "glm-4.5-air": {
            "rating": 1366.5667590003486,
            "rating_q975": 1380.5252771772368,
            "rating_q025": 1352.6082408234604
        },
        "minimax-m1": {
            "rating": 1366.3024981373114,
            "rating_q975": 1378.7664732891117,
            "rating_q025": 1353.8385229855112
        },
        "qwen3-235b-a22b": {
            "rating": 1365.3513597560504,
            "rating_q975": 1379.389678901208,
            "rating_q025": 1351.3130406108928
        },
        "o3-mini-high": {
            "rating": 1361.6037622026179,
            "rating_q975": 1379.6798953162959,
            "rating_q025": 1343.5276290889399
        },
        "claude-3-5-sonnet-20240620": {
            "rating": 1359.601883497512,
            "rating_q975": 1369.9153644456171,
            "rating_q025": 1349.288402549407
        },
        "minimax-m2": {
            "rating": 1358.3670918637072,
            "rating_q975": 1387.4651123941446,
            "rating_q025": 1329.2690713332697
        },
        "qwen3-next-80b-a3b-thinking": {
            "rating": 1356.6486290662183,
            "rating_q975": 1377.2598675282638,
            "rating_q025": 1336.0373906041727
        },
        "grok-3-mini-beta": {
            "rating": 1356.0777439024705,
            "rating_q975": 1371.4922951420467,
            "rating_q025": 1340.6631926628943
        },
        "claude-3-opus-20240229": {
            "rating": 1355.449558915544,
            "rating_q975": 1364.1314069183902,
            "rating_q025": 1346.7677109126978
        },
        "gpt-4o-2024-08-06": {
            "rating": 1353.747407354353,
            "rating_q975": 1365.6006447708908,
            "rating_q025": 1341.8941699378154
        },
        "claude-3-5-haiku-20241022": {
            "rating": 1353.050705666833,
            "rating_q975": 1362.7714023481312,
            "rating_q025": 1343.3300089855347
        },
        "gpt-4.1-nano-2025-04-14": {
            "rating": 1352.9694427035774,
            "rating_q975": 1381.7465621666354,
            "rating_q025": 1324.1923232405195
        },
        "glm-4-plus": {
            "rating": 1351.9982669168696,
            "rating_q975": 1366.6555881300546,
            "rating_q025": 1337.3409457036846
        },
        "gpt-4o-mini-2024-07-18": {
            "rating": 1348.712699112139,
            "rating_q975": 1358.889894416221,
            "rating_q025": 1338.535503808057
        },
        "nvidia-llama-3.3-nemotron-super-49b-v1.5": {
            "rating": 1348.4922715599412,
            "rating_q975": 1384.0691991525305,
            "rating_q025": 1312.9153439673519
        },
        "llama-3.3-70b-instruct": {
            "rating": 1348.0958611343847,
            "rating_q975": 1358.5215639315713,
            "rating_q025": 1337.670158337198
        },
        "step-2-16k-exp-202412": {
            "rating": 1347.1474059639015,
            "rating_q975": 1380.5453433669843,
            "rating_q025": 1313.7494685608187
        },
        "llama-4-scout-17b-16e-instruct": {
            "rating": 1345.9170471130565,
            "rating_q975": 1359.7991839568215,
            "rating_q025": 1332.0349102692915
        },
        "ling-flash-2.0": {
            "rating": 1345.543049308652,
            "rating_q975": 1373.3106476504315,
            "rating_q025": 1317.7754509668723
        },
        "step-3": {
            "rating": 1345.0144821974714,
            "rating_q975": 1373.6260080629552,
            "rating_q025": 1316.4029563319875
        },
        "llama-4-maverick-17b-128e-instruct": {
            "rating": 1344.974419536121,
            "rating_q975": 1357.1133361885409,
            "rating_q025": 1332.8355028837013
        },
        "o1-mini": {
            "rating": 1344.1763729795475,
            "rating_q975": 1355.290049469511,
            "rating_q025": 1333.0626964895841
        },
        "mistral-large-2407": {
            "rating": 1343.7292562823786,
            "rating_q975": 1355.3919607266973,
            "rating_q025": 1332.06655183806
        },
        "amazon-nova-experimental-chat-10-09": {
            "rating": 1343.4243628784093,
            "rating_q975": 1370.1425342862528,
            "rating_q025": 1316.7061914705657
        },
        "gpt-4-turbo-2024-04-09": {
            "rating": 1342.802405261442,
            "rating_q975": 1353.226739625093,
            "rating_q025": 1332.3780708977908
        },
        "hunyuan-standard-2025-02-10": {
            "rating": 1342.204586512276,
            "rating_q975": 1375.9812390820682,
            "rating_q025": 1308.4279339424836
        },
        "o3-mini": {
            "rating": 1340.8084435896335,
            "rating_q975": 1350.865752303288,
            "rating_q025": 1330.751134875979
        },
        "gpt-oss-120b": {
            "rating": 1339.9143773891944,
            "rating_q975": 1354.1288965180638,
            "rating_q025": 1325.699858260325
        },
        "gemma-3-4b-it": {
            "rating": 1339.8043987914139,
            "rating_q975": 1376.1757618945942,
            "rating_q025": 1303.4330356882335
        },
        "llama-3.1-nemotron-51b-instruct": {
            "rating": 1339.5464211532453,
            "rating_q975": 1375.082515765919,
            "rating_q025": 1304.0103265405717
        },
        "qwq-32b": {
            "rating": 1338.3851500020182,
            "rating_q975": 1352.9185623218052,
            "rating_q025": 1323.8517376822313
        },
        "hunyuan-large-2025-02-10": {
            "rating": 1337.8349229153798,
            "rating_q975": 1373.8937262389497,
            "rating_q025": 1301.77611959181
        },
        "gemini-1.5-pro-001": {
            "rating": 1336.695578703473,
            "rating_q975": 1347.7110965692325,
            "rating_q025": 1325.6800608377137
        },
        "deepseek-v2.5": {
            "rating": 1335.3659689618726,
            "rating_q975": 1350.2993492676635,
            "rating_q025": 1320.4325886560816
        },
        "athene-70b-0725": {
            "rating": 1334.6657812900344,
            "rating_q975": 1353.4988022358407,
            "rating_q025": 1315.832760344228
        },
        "reka-core-20240904": {
            "rating": 1333.3931329718055,
            "rating_q975": 1362.1993136052636,
            "rating_q025": 1304.5869523383474
        },
        "gpt-4-0125-preview": {
            "rating": 1333.350391435932,
            "rating_q975": 1344.336667274464,
            "rating_q025": 1322.3641155973999
        },
        "llama-3.1-70b-instruct": {
            "rating": 1332.7621597743846,
            "rating_q975": 1343.9271060132205,
            "rating_q025": 1321.5972135355487
        },
        "qwen2.5-72b-instruct": {
            "rating": 1332.7582885960705,
            "rating_q975": 1344.9928632019728,
            "rating_q025": 1320.5237139901683
        },
        "gpt-5-nano-high": {
            "rating": 1331.7187286316807,
            "rating_q975": 1359.7586763604504,
            "rating_q025": 1303.678780902911
        },
        "gemma-2-9b-it-simpo": {
            "rating": 1331.351140752423,
            "rating_q975": 1355.8198090958676,
            "rating_q025": 1306.8824724089782
        },
        "gemini-1.5-flash-002": {
            "rating": 1331.1847545577853,
            "rating_q975": 1344.1366324562387,
            "rating_q025": 1318.2328766593319
        },
        "grok-2-mini-2024-08-13": {
            "rating": 1330.1785200411487,
            "rating_q975": 1341.507128933302,
            "rating_q025": 1318.8499111489953
        },
        "jamba-1.5-large": {
            "rating": 1329.8563016381422,
            "rating_q975": 1356.9496388942073,
            "rating_q025": 1302.7629643820771
        },
        "gpt-oss-20b": {
            "rating": 1329.5011745198326,
            "rating_q975": 1353.2600677410387,
            "rating_q025": 1305.7422812986265
        },
        "deepseek-v2.5-1210": {
            "rating": 1329.202483309882,
            "rating_q975": 1358.6523475746965,
            "rating_q025": 1299.7526190450674
        },
        "qwen-max-0919": {
            "rating": 1329.1426816615033,
            "rating_q975": 1346.7419382781366,
            "rating_q025": 1311.54342504487
        },
        "mistral-large-2411": {
            "rating": 1328.9484579606024,
            "rating_q975": 1343.5204680578336,
            "rating_q025": 1314.3764478633711
        },
        "athene-v2-chat": {
            "rating": 1328.1291405325364,
            "rating_q975": 1343.3881236517298,
            "rating_q025": 1312.8701574133431
        },
        "amazon-nova-pro-v1.0": {
            "rating": 1327.5665555755952,
            "rating_q975": 1343.3673539419053,
            "rating_q025": 1311.765757209285
        },
        "llama-3.1-nemotron-70b-instruct": {
            "rating": 1326.7538066803158,
            "rating_q975": 1353.242191876403,
            "rating_q025": 1300.2654214842287
        },
        "amazon-nova-experimental-chat-10-20": {
            "rating": 1326.6140087559452,
            "rating_q975": 1353.454631874843,
            "rating_q025": 1299.7733856370473
        },
        "qwen2.5-plus-1127": {
            "rating": 1326.3486986521862,
            "rating_q975": 1350.0753424831844,
            "rating_q025": 1302.622054821188
        },
        "qwen3-30b-a3b": {
            "rating": 1324.8781398899018,
            "rating_q975": 1338.782272518833,
            "rating_q025": 1310.9740072609707
        },
        "qwen3-32b": {
            "rating": 1324.7434800805709,
            "rating_q975": 1357.6014914738319,
            "rating_q025": 1291.8854686873099
        },
        "command-r-plus-08-2024": {
            "rating": 1324.6205981484459,
            "rating_q975": 1347.800464489549,
            "rating_q025": 1301.4407318073427
        },
        "gemma-3n-e4b-it": {
            "rating": 1324.3010254179678,
            "rating_q975": 1339.9924753697824,
            "rating_q025": 1308.6095754661533
        },
        "step-1o-turbo-202506": {
            "rating": 1323.373574106577,
            "rating_q975": 1346.639109608067,
            "rating_q025": 1300.1080386050871
        },
        "nemotron-4-340b-instruct": {
            "rating": 1322.3038364016484,
            "rating_q975": 1340.0847233170477,
            "rating_q025": 1304.522949486249
        },
        "gpt-4-1106-preview": {
            "rating": 1320.5413795450145,
            "rating_q975": 1331.2826242515919,
            "rating_q025": 1309.800134838437
        },
        "command-r-plus": {
            "rating": 1319.6970385162977,
            "rating_q975": 1331.496407024259,
            "rating_q025": 1307.8976700083363
        },
        "glm-4-0520": {
            "rating": 1317.9471529884677,
            "rating_q975": 1342.4078444317677,
            "rating_q025": 1293.4864615451677
        },
        "nova-2-lite": {
            "rating": 1316.8366147639813,
            "rating_q975": 1346.553863661294,
            "rating_q025": 1287.1193658666687
        },
        "gemma-2-27b-it": {
            "rating": 1316.5862676135532,
            "rating_q975": 1326.254118864353,
            "rating_q025": 1306.9184163627535
        },
        "qwen2.5-coder-32b-instruct": {
            "rating": 1312.686994806407,
            "rating_q975": 1346.8980019158848,
            "rating_q025": 1278.4759876969292
        },
        "claude-3-sonnet-20240229": {
            "rating": 1311.4052444892627,
            "rating_q975": 1322.6509348998813,
            "rating_q025": 1300.159554078644
        },
        "gemini-1.5-flash-001": {
            "rating": 1310.13296520081,
            "rating_q975": 1321.741316341877,
            "rating_q025": 1298.524614059743
        },
        "mistral-small-3.1-24b-instruct-2503": {
            "rating": 1310.1154745925096,
            "rating_q975": 1323.303713327775,
            "rating_q025": 1296.927235857244
        },
        "command-r-08-2024": {
            "rating": 1307.9038903463688,
            "rating_q975": 1332.0838932483837,
            "rating_q025": 1283.723887444354
        },
        "llama-3-70b-instruct": {
            "rating": 1307.1495497241149,
            "rating_q975": 1317.0265659332028,
            "rating_q025": 1297.272533515027
        },
        "magistral-medium-2506": {
            "rating": 1304.557645415026,
            "rating_q975": 1327.0080036247039,
            "rating_q025": 1282.107287205348
        },
        "gpt-4-0314": {
            "rating": 1304.4706016617736,
            "rating_q975": 1318.2530046770257,
            "rating_q025": 1290.6881986465214
        },
        "c4ai-aya-expanse-32b": {
            "rating": 1303.3350838159574,
            "rating_q975": 1317.4846579639532,
            "rating_q025": 1289.1855096679617
        },
        "phi-4": {
            "rating": 1302.4080903932554,
            "rating_q975": 1318.8321032220633,
            "rating_q025": 1285.9840775644475
        },
        "gemini-1.5-flash-8b-001": {
            "rating": 1298.6119725123958,
            "rating_q975": 1311.5944114687557,
            "rating_q025": 1285.629533556036
        },
        "hunyuan-large-vision": {
            "rating": 1293.5123364939345,
            "rating_q975": 1325.1606308577389,
            "rating_q025": 1261.8640421301302
        },
        "claude-3-haiku-20240307": {
            "rating": 1293.0750051429304,
            "rating_q975": 1303.2757826014915,
            "rating_q025": 1282.8742276843693
        },
        "reka-flash-20240904": {
            "rating": 1291.5086752534783,
            "rating_q975": 1321.1331435995157,
            "rating_q025": 1261.8842069074408
        },
        "jamba-1.5-mini": {
            "rating": 1290.4044902939595,
            "rating_q975": 1315.7390848122923,
            "rating_q025": 1265.0698957756267
        },
        "ring-flash-2.0": {
            "rating": 1290.021282855018,
            "rating_q975": 1318.800809344364,
            "rating_q025": 1261.2417563656718
        },
        "gemma-2-9b-it": {
            "rating": 1289.526037934585,
            "rating_q975": 1300.4848963016468,
            "rating_q025": 1278.5671795675232
        },
        "command-r": {
            "rating": 1289.1267980662788,
            "rating_q975": 1302.4492272169432,
            "rating_q025": 1275.8043689156143
        },
        "reka-flash-21b-20240226-online": {
            "rating": 1288.5851331859992,
            "rating_q975": 1309.21182306838,
            "rating_q025": 1267.9584433036184
        },
        "amazon-nova-lite-v1.0": {
            "rating": 1285.6281892451295,
            "rating_q975": 1303.5002207163905,
            "rating_q025": 1267.7561577738686
        },
        "olmo-3-32b-think": {
            "rating": 1284.3649287825137,
            "rating_q975": 1327.2774474394596,
            "rating_q025": 1241.452410125568
        },
        "gpt-4-0613": {
            "rating": 1284.1424986949746,
            "rating_q975": 1295.891118828171,
            "rating_q025": 1272.3938785617781
        },
        "deepseek-coder-v2": {
            "rating": 1283.6372809171144,
            "rating_q975": 1303.663437022456,
            "rating_q025": 1263.6111248117727
        },
        "qwen2-72b-instruct": {
            "rating": 1282.0771865961792,
            "rating_q975": 1295.5119706897535,
            "rating_q025": 1268.642402502605
        },
        "mistral-small-24b-instruct-2501": {
            "rating": 1279.1059295089874,
            "rating_q975": 1299.5883446925898,
            "rating_q025": 1258.623514325385
        },
        "olmo-2-0325-32b-instruct": {
            "rating": 1277.8926266436415,
            "rating_q975": 1318.5904438587272,
            "rating_q025": 1237.1948094285558
        },
        "mistral-large-2402": {
            "rating": 1277.494645164131,
            "rating_q975": 1290.4572759923687,
            "rating_q025": 1264.5320143358933
        },
        "qwen1.5-110b-chat": {
            "rating": 1276.294100642255,
            "rating_q975": 1293.0495062888922,
            "rating_q025": 1259.5386949956178
        },
        "ministral-8b-2410": {
            "rating": 1274.0008740417318,
            "rating_q975": 1307.8263100033953,
            "rating_q025": 1240.1754380800683
        },
        "gemini-pro-dev-api": {
            "rating": 1273.4676623882588,
            "rating_q975": 1294.5755479448032,
            "rating_q025": 1252.3597768317143
        },
        "reka-flash-21b-20240226": {
            "rating": 1269.6662186691274,
            "rating_q975": 1287.3676877980438,
            "rating_q025": 1251.964749540211
        },
        "c4ai-aya-expanse-8b": {
            "rating": 1269.142729600885,
            "rating_q975": 1294.4039536433038,
            "rating_q025": 1243.8815055584664
        },
        "amazon-nova-micro-v1.0": {
            "rating": 1268.977890230417,
            "rating_q975": 1287.358284712184,
            "rating_q025": 1250.5974957486499
        },
        "qwen1.5-72b-chat": {
            "rating": 1268.483414000491,
            "rating_q975": 1283.0945050396017,
            "rating_q025": 1253.8723229613802
        },
        "mixtral-8x22b-instruct-v0.1": {
            "rating": 1264.4145715722489,
            "rating_q975": 1277.4671147985705,
            "rating_q025": 1251.3620283459272
        },
        "mistral-medium": {
            "rating": 1261.3963574756026,
            "rating_q975": 1277.3112355194748,
            "rating_q025": 1245.4814794317303
        },
        "gpt-3.5-turbo-0125": {
            "rating": 1261.3442061192386,
            "rating_q975": 1273.4292288878496,
            "rating_q025": 1249.2591833506276
        },
        "granite-3.1-8b-instruct": {
            "rating": 1258.1432559373318,
            "rating_q975": 1300.0868478948364,
            "rating_q025": 1216.1996639798272
        },
        "yi-1.5-34b-chat": {
            "rating": 1257.1557157007528,
            "rating_q975": 1273.2300443849767,
            "rating_q025": 1241.0813870165289
        },
        "llama-3-8b-instruct": {
            "rating": 1252.2687114589949,
            "rating_q975": 1263.183517981714,
            "rating_q025": 1241.3539049362757
        },
        "llama-3.1-8b-instruct": {
            "rating": 1248.2041560341486,
            "rating_q975": 1259.990484679703,
            "rating_q025": 1236.417827388594
        },
        "openchat-3.5": {
            "rating": 1240.100015392376,
            "rating_q975": 1268.3764770697628,
            "rating_q025": 1211.8235537149892
        },
        "qwen1.5-32b-chat": {
            "rating": 1237.2264399426454,
            "rating_q975": 1254.7123660436087,
            "rating_q025": 1219.740513841682
        },
        "mixtral-8x7b-instruct-v0.1": {
            "rating": 1233.7671628641538,
            "rating_q975": 1245.8668459180058,
            "rating_q025": 1221.6674798103018
        },
        "gemini-pro": {
            "rating": 1231.0694385529227,
            "rating_q975": 1265.200894085658,
            "rating_q025": 1196.9379830201874
        },
        "zephyr-orpo-141b-A35b-v0.1": {
            "rating": 1230.4712846631369,
            "rating_q975": 1268.569547901262,
            "rating_q025": 1192.3730214250118
        },
        "yi-34b-chat": {
            "rating": 1228.3774095443678,
            "rating_q975": 1249.8762727661274,
            "rating_q025": 1206.8785463226081
        },
        "wizardlm-70b": {
            "rating": 1227.4869284146503,
            "rating_q975": 1256.3944046697013,
            "rating_q025": 1198.5794521595992
        },
        "tulu-2-dpo-70b": {
            "rating": 1225.1990149094208,
            "rating_q975": 1255.6186633018904,
            "rating_q025": 1194.7793665169513
        },
        "gemma-2-2b-it": {
            "rating": 1224.0040653190065,
            "rating_q975": 1236.345806252521,
            "rating_q025": 1211.662324385492
        },
        "openhermes-2.5-mistral-7b": {
            "rating": 1221.4083779915686,
            "rating_q975": 1257.6305589129754,
            "rating_q025": 1185.1861970701618
        },
        "phi-3-medium-4k-instruct": {
            "rating": 1219.8590365129958,
            "rating_q975": 1235.9903291426454,
            "rating_q025": 1203.7277438833462
        },
        "dbrx-instruct-preview": {
            "rating": 1218.5261242977117,
            "rating_q975": 1234.9568217412932,
            "rating_q025": 1202.0954268541302
        },
        "gemma-1.1-7b-it": {
            "rating": 1217.751040878222,
            "rating_q975": 1234.8652926847042,
            "rating_q025": 1200.63678907174
        },
        "gpt-3.5-turbo-1106": {
            "rating": 1217.3004347981039,
            "rating_q975": 1239.7119265967399,
            "rating_q025": 1194.8889429994679
        },
        "openchat-3.5-0106": {
            "rating": 1214.5205870042155,
            "rating_q975": 1238.7817787858664,
            "rating_q025": 1190.2593952225645
        },
        "qwen1.5-14b-chat": {
            "rating": 1213.7913209821966,
            "rating_q975": 1233.0140562811334,
            "rating_q025": 1194.5685856832597
        },
        "starling-lm-7b-beta": {
            "rating": 1213.136084108188,
            "rating_q975": 1234.1908180018572,
            "rating_q025": 1192.0813502145188
        },
        "deepseek-llm-67b-chat": {
            "rating": 1211.4102598841775,
            "rating_q975": 1246.2809196505318,
            "rating_q025": 1176.5396001178233
        },
        "starling-lm-7b-alpha": {
            "rating": 1210.8806441796692,
            "rating_q975": 1237.6332403288127,
            "rating_q025": 1184.1280480305256
        },
        "snowflake-arctic-instruct": {
            "rating": 1207.8790573931544,
            "rating_q975": 1225.8654653374695,
            "rating_q025": 1189.8926494488394
        },
        "hunyuan-standard-256k": {
            "rating": 1204.981084831269,
            "rating_q975": 1248.4972941742396,
            "rating_q025": 1161.4648754882985
        },
        "wizardlm-13b": {
            "rating": 1203.2736662635725,
            "rating_q975": 1235.3746143882572,
            "rating_q025": 1171.1727181388878
        },
        "phi-3-small-8k-instruct": {
            "rating": 1202.7027426077289,
            "rating_q975": 1220.7098308951659,
            "rating_q025": 1184.6956543202919
        },
        "granite-3.0-8b-instruct": {
            "rating": 1201.5984791361896,
            "rating_q975": 1235.6715829359564,
            "rating_q025": 1167.5253753364227
        },
        "vicuna-33b": {
            "rating": 1198.4359426658216,
            "rating_q975": 1217.3222380101379,
            "rating_q025": 1179.5496473215053
        },
        "internlm2_5-20b-chat": {
            "rating": 1197.806082369042,
            "rating_q975": 1221.1996934901483,
            "rating_q025": 1174.4124712479359
        },
        "llama-2-70b-chat": {
            "rating": 1196.7822767824032,
            "rating_q975": 1211.922058924078,
            "rating_q025": 1181.6424946407283
        },
        "zephyr-7b-beta": {
            "rating": 1194.8353860874095,
            "rating_q975": 1220.6568091618565,
            "rating_q025": 1169.0139630129624
        },
        "llama-3.2-3b-instruct": {
            "rating": 1194.4596404954168,
            "rating_q975": 1222.6455146939,
            "rating_q025": 1166.2737662969337
        },
        "mistral-7b-instruct-v0.2": {
            "rating": 1192.7033803239256,
            "rating_q975": 1212.9117426388084,
            "rating_q025": 1172.4950180090427
        },
        "solar-10.7b-instruct-v1.0": {
            "rating": 1191.278133922494,
            "rating_q975": 1230.9144190618435,
            "rating_q025": 1151.6418487831443
        },
        "granite-3.0-2b-instruct": {
            "rating": 1190.914097352404,
            "rating_q975": 1222.848896379762,
            "rating_q025": 1158.979298325046
        },
        "qwen1.5-7b-chat": {
            "rating": 1186.791992566862,
            "rating_q975": 1227.4467925700108,
            "rating_q025": 1146.1371925637134
        },
        "qwen-14b-chat": {
            "rating": 1182.6805965986878,
            "rating_q975": 1220.2792935988114,
            "rating_q025": 1145.0818995985642
        },
        "vicuna-13b": {
            "rating": 1181.2977715662214,
            "rating_q975": 1202.9585166765362,
            "rating_q025": 1159.6370264559066
        },
        "palm-2": {
            "rating": 1169.5232414526427,
            "rating_q975": 1201.939728186277,
            "rating_q025": 1137.1067547190082
        },
        "codellama-34b-instruct": {
            "rating": 1166.7742632853747,
            "rating_q975": 1198.8310251247003,
            "rating_q025": 1134.717501446049
        },
        "gemma-7b-it": {
            "rating": 1165.4391433700725,
            "rating_q975": 1194.1971506277712,
            "rating_q025": 1136.681136112374
        },
        "llama-2-13b-chat": {
            "rating": 1162.4948204941832,
            "rating_q975": 1183.1621735507388,
            "rating_q025": 1141.8274674376275
        },
        "phi-3-mini-4k-instruct": {
            "rating": 1161.7143944782435,
            "rating_q975": 1180.772108252784,
            "rating_q025": 1142.6566807037032
        },
        "phi-3-mini-4k-instruct-june-2024": {
            "rating": 1161.1127923439767,
            "rating_q975": 1185.7820620467157,
            "rating_q025": 1136.4435226412377
        },
        "mistral-7b-instruct": {
            "rating": 1160.6957131494225,
            "rating_q975": 1189.9753789516008,
            "rating_q025": 1131.4160473472443
        },
        "qwq-32b-preview": {
            "rating": 1157.4333130420825,
            "rating_q975": 1200.0571778619856,
            "rating_q025": 1114.8094482221795
        },
        "vicuna-7b": {
            "rating": 1156.9996974630872,
            "rating_q975": 1191.9959923544345,
            "rating_q025": 1122.0034025717398
        },
        "llama-3.2-1b-instruct": {
            "rating": 1156.1015563596652,
            "rating_q975": 1186.0353738238998,
            "rating_q025": 1126.1677388954306
        },
        "qwen1.5-4b-chat": {
            "rating": 1151.0445195938503,
            "rating_q975": 1183.260306859785,
            "rating_q025": 1118.8287323279155
        },
        "gemma-2b-it": {
            "rating": 1147.7766951701797,
            "rating_q975": 1186.024766693804,
            "rating_q025": 1109.5286236465554
        },
        "llama-2-7b-chat": {
            "rating": 1144.144848404568,
            "rating_q975": 1166.5105012177344,
            "rating_q025": 1121.7791955914015
        },
        "phi-3-mini-128k-instruct": {
            "rating": 1126.557512959338,
            "rating_q975": 1148.8284997192607,
            "rating_q025": 1104.2865261994154
        },
        "gemma-1.1-2b-it": {
            "rating": 1126.1362869415516,
            "rating_q975": 1153.8397055477844,
            "rating_q025": 1098.4328683353187
        },
        "stripedhyena-nous-7b": {
            "rating": 1122.8931151121772,
            "rating_q975": 1158.5140082166638,
            "rating_q025": 1087.2722220076905
        },
        "RWKV-4-Raven-14B": {
            "rating": 1122.034694647808,
            "rating_q975": 1169.7802878274633,
            "rating_q025": 1074.2891014681527
        },
        "olmo-7b-instruct": {
            "rating": 1110.847015838764,
            "rating_q975": 1146.3012260993341,
            "rating_q025": 1075.392805578194
        },
        "alpaca-13b": {
            "rating": 1108.9043360905528,
            "rating_q975": 1152.4447364868606,
            "rating_q025": 1065.363935694245
        },
        "chatglm3-6b": {
            "rating": 1102.410403639484,
            "rating_q975": 1143.220656741103,
            "rating_q025": 1061.600150537865
        },
        "koala-13b": {
            "rating": 1091.7404958675606,
            "rating_q975": 1132.1699643143559,
            "rating_q025": 1051.3110274207654
        },
        "oasst-pythia-12b": {
            "rating": 1078.182466548963,
            "rating_q975": 1119.4635385915699,
            "rating_q025": 1036.9013945063562
        },
        "fastchat-t5-3b": {
            "rating": 1043.1101963344972,
            "rating_q975": 1089.5275829749903,
            "rating_q025": 996.6928096940042
        },
        "chatglm-6b": {
            "rating": 1004.4456459847952,
            "rating_q975": 1052.146762792463,
            "rating_q025": 956.7445291771273
        }
    },
    "industry_life_and_physical_and_social_science": {
        "gemini-3-pro": {
            "rating": 1515.8247754261013,
            "rating_q975": 1528.3069490145078,
            "rating_q025": 1503.3426018376947
        },
        "grok-4.1-thinking": {
            "rating": 1490.9582968211216,
            "rating_q975": 1502.9696335959636,
            "rating_q025": 1478.9469600462796
        },
        "grok-4.1": {
            "rating": 1490.6554166996807,
            "rating_q975": 1502.8708744921678,
            "rating_q025": 1478.4399589071936
        },
        "claude-opus-4-5-20251101": {
            "rating": 1485.2057286931088,
            "rating_q975": 1500.3493980946039,
            "rating_q025": 1470.0620592916137
        },
        "claude-opus-4-5-20251101-thinking-32k": {
            "rating": 1480.5934396283883,
            "rating_q975": 1496.1960423950811,
            "rating_q025": 1464.9908368616955
        },
        "gemini-2.5-pro": {
            "rating": 1478.1600010366983,
            "rating_q975": 1484.4819145360561,
            "rating_q025": 1471.8380875373405
        },
        "claude-sonnet-4-5-20250929": {
            "rating": 1471.4836571642293,
            "rating_q975": 1481.7857373268976,
            "rating_q025": 1461.181577001561
        },
        "claude-sonnet-4-5-20250929-thinking-32k": {
            "rating": 1470.4837065001582,
            "rating_q975": 1480.0132941016047,
            "rating_q025": 1460.9541188987116
        },
        "claude-opus-4-1-20250805-thinking-16k": {
            "rating": 1468.1763448248898,
            "rating_q975": 1475.9136492103462,
            "rating_q025": 1460.4390404394335
        },
        "gpt-5.1-high": {
            "rating": 1466.3134095949288,
            "rating_q975": 1479.4284334035253,
            "rating_q025": 1453.1983857863322
        },
        "claude-opus-4-1-20250805": {
            "rating": 1464.720750916294,
            "rating_q975": 1471.8533140804834,
            "rating_q025": 1457.5881877521047
        },
        "o3-2025-04-16": {
            "rating": 1461.8894483179063,
            "rating_q975": 1468.7087117806263,
            "rating_q025": 1455.0701848551862
        },
        "deepseek-v3.2-thinking": {
            "rating": 1460.1892940802977,
            "rating_q975": 1478.562707468549,
            "rating_q025": 1441.8158806920464
        },
        "qwen3-max-preview": {
            "rating": 1458.5531204193358,
            "rating_q975": 1468.0996773322895,
            "rating_q025": 1449.006563506382
        },
        "chatgpt-4o-latest-20250326": {
            "rating": 1458.3347961123725,
            "rating_q975": 1464.7406771529477,
            "rating_q025": 1451.9289150717973
        },
        "gpt-5.1": {
            "rating": 1456.9078917764873,
            "rating_q975": 1469.5374333316045,
            "rating_q025": 1444.2783502213701
        },
        "deepseek-v3.1-terminus": {
            "rating": 1455.140157815372,
            "rating_q975": 1479.7482143033608,
            "rating_q025": 1430.5321013273833
        },
        "gpt-4.5-preview-2025-02-27": {
            "rating": 1451.0942174652826,
            "rating_q975": 1462.852349891372,
            "rating_q025": 1439.3360850391932
        },
        "grok-4-1-fast-reasoning": {
            "rating": 1449.7228967012286,
            "rating_q975": 1465.4958351054124,
            "rating_q025": 1433.9499582970448
        },
        "gpt-5-chat": {
            "rating": 1449.691739079436,
            "rating_q975": 1458.3955588909143,
            "rating_q025": 1440.9879192679577
        },
        "gpt-5-high": {
            "rating": 1449.3647283332489,
            "rating_q975": 1458.3873171471275,
            "rating_q025": 1440.3421395193702
        },
        "deepseek-v3.1-terminus-thinking": {
            "rating": 1447.1323534410337,
            "rating_q975": 1472.1994003967852,
            "rating_q025": 1422.0653064852822
        },
        "deepseek-v3.2-exp-thinking": {
            "rating": 1446.829243379284,
            "rating_q975": 1461.9679576977553,
            "rating_q025": 1431.6905290608127
        },
        "qwen3-vl-235b-a22b-instruct": {
            "rating": 1446.6262016712956,
            "rating_q975": 1462.9770208640134,
            "rating_q025": 1430.2753824785777
        },
        "glm-4.6": {
            "rating": 1446.5976594858673,
            "rating_q975": 1456.3122332108228,
            "rating_q025": 1436.8830857609119
        },
        "qwen3-235b-a22b-instruct-2507": {
            "rating": 1444.8518438644767,
            "rating_q975": 1452.050745348735,
            "rating_q025": 1437.6529423802183
        },
        "grok-4-fast-chat": {
            "rating": 1443.8700405080817,
            "rating_q975": 1462.7424349125442,
            "rating_q025": 1424.9976461036192
        },
        "kimi-k2-0905-preview": {
            "rating": 1442.8151951642399,
            "rating_q975": 1457.2433510419303,
            "rating_q025": 1428.3870392865495
        },
        "claude-opus-4-20250514-thinking-16k": {
            "rating": 1442.5646352491794,
            "rating_q975": 1450.7549710580597,
            "rating_q025": 1434.3742994402992
        },
        "kimi-k2-thinking-turbo": {
            "rating": 1441.46907156691,
            "rating_q975": 1453.6026861455723,
            "rating_q025": 1429.3354569882479
        },
        "deepseek-v3.1": {
            "rating": 1439.4399303941102,
            "rating_q975": 1451.8152836076013,
            "rating_q025": 1427.0645771806192
        },
        "gemini-2.5-flash-preview-09-2025": {
            "rating": 1438.888373588267,
            "rating_q975": 1448.1735184985116,
            "rating_q025": 1429.6032286780226
        },
        "grok-4-0709": {
            "rating": 1438.6089482006619,
            "rating_q975": 1446.2294315782372,
            "rating_q025": 1430.9884648230866
        },
        "deepseek-v3.2-exp": {
            "rating": 1438.1655443055677,
            "rating_q975": 1451.8346762318981,
            "rating_q025": 1424.4964123792372
        },
        "ernie-5.0-preview-1103": {
            "rating": 1437.2930231551666,
            "rating_q975": 1456.4410924898248,
            "rating_q025": 1418.1449538205084
        },
        "kimi-k2-0711-preview": {
            "rating": 1436.7028940110479,
            "rating_q975": 1445.9555049126313,
            "rating_q025": 1427.4502831094644
        },
        "grok-4-fast-reasoning": {
            "rating": 1436.664261993407,
            "rating_q975": 1447.64932205926,
            "rating_q025": 1425.6792019275542
        },
        "qwen3-max-2025-09-23": {
            "rating": 1436.4391024864215,
            "rating_q975": 1451.9130358490706,
            "rating_q025": 1420.9651691237723
        },
        "claude-opus-4-20250514": {
            "rating": 1433.2630763284455,
            "rating_q975": 1440.9570361708697,
            "rating_q025": 1425.5691164860214
        },
        "deepseek-v3.2": {
            "rating": 1432.8765753823163,
            "rating_q975": 1450.9487419880331,
            "rating_q025": 1414.8044087765995
        },
        "deepseek-v3.1-thinking": {
            "rating": 1431.403441482442,
            "rating_q975": 1444.9677675546632,
            "rating_q025": 1417.839115410221
        },
        "mistral-medium-2508": {
            "rating": 1429.0677223586465,
            "rating_q975": 1436.8356246399524,
            "rating_q025": 1421.2998200773407
        },
        "mistral-large-3": {
            "rating": 1429.008809463748,
            "rating_q975": 1447.5767197505788,
            "rating_q025": 1410.4408991769174
        },
        "gemini-2.5-flash": {
            "rating": 1427.6429852941533,
            "rating_q975": 1433.8999605135864,
            "rating_q025": 1421.3860100747202
        },
        "gpt-4.1-2025-04-14": {
            "rating": 1427.481846135132,
            "rating_q975": 1434.4204122945373,
            "rating_q025": 1420.5432799757266
        },
        "glm-4.5": {
            "rating": 1423.6721517506846,
            "rating_q975": 1433.4451543331859,
            "rating_q025": 1413.8991491681834
        },
        "claude-sonnet-4-20250514-thinking-32k": {
            "rating": 1422.1157227151828,
            "rating_q975": 1430.3231569795403,
            "rating_q025": 1413.9082884508252
        },
        "claude-haiku-4-5-20251001": {
            "rating": 1421.1844832707325,
            "rating_q975": 1431.0026068306772,
            "rating_q025": 1411.3663597107877
        },
        "deepseek-r1-0528": {
            "rating": 1420.2550235891617,
            "rating_q975": 1430.6214490281034,
            "rating_q025": 1409.88859815022
        },
        "hunyuan-t1-20250711": {
            "rating": 1418.9358357590947,
            "rating_q975": 1440.8340472418367,
            "rating_q025": 1397.0376242763527
        },
        "qwen3-next-80b-a3b-instruct": {
            "rating": 1416.3704310060486,
            "rating_q975": 1426.69264350321,
            "rating_q025": 1406.0482185088872
        },
        "claude-sonnet-4-20250514": {
            "rating": 1416.2301666366784,
            "rating_q975": 1424.2365593941581,
            "rating_q025": 1408.2237738791987
        },
        "grok-3-preview-02-24": {
            "rating": 1416.0568318537523,
            "rating_q975": 1424.1574184162623,
            "rating_q025": 1407.9562452912423
        },
        "qwen3-235b-a22b-no-thinking": {
            "rating": 1415.5123402148329,
            "rating_q975": 1423.695724820466,
            "rating_q025": 1407.3289556091997
        },
        "o1-2024-12-17": {
            "rating": 1414.6159764317451,
            "rating_q975": 1423.3551271205654,
            "rating_q025": 1405.876825742925
        },
        "deepseek-v3-0324": {
            "rating": 1414.589347829218,
            "rating_q975": 1421.7651680595643,
            "rating_q025": 1407.4135275988717
        },
        "deepseek-r1": {
            "rating": 1412.7402149777724,
            "rating_q975": 1422.9043987842165,
            "rating_q025": 1402.5760311713284
        },
        "qwen3-235b-a22b-thinking-2507": {
            "rating": 1411.6665706643516,
            "rating_q975": 1426.7517219898,
            "rating_q025": 1396.5814193389033
        },
        "hunyuan-turbos-20250416": {
            "rating": 1411.2417589536997,
            "rating_q975": 1424.4919792404871,
            "rating_q025": 1397.9915386669122
        },
        "claude-3-7-sonnet-20250219-thinking-32k": {
            "rating": 1410.6942001063867,
            "rating_q975": 1418.6000830932574,
            "rating_q025": 1402.788317119516
        },
        "o4-mini-2025-04-16": {
            "rating": 1409.083237348802,
            "rating_q975": 1416.4749518974443,
            "rating_q025": 1401.6915228001596
        },
        "mai-1-preview": {
            "rating": 1407.3768708872183,
            "rating_q975": 1418.2678449153784,
            "rating_q025": 1396.4858968590581
        },
        "qwen3-vl-235b-a22b-thinking": {
            "rating": 1407.3090084986566,
            "rating_q975": 1424.001165225847,
            "rating_q025": 1390.6168517714661
        },
        "mistral-medium-2505": {
            "rating": 1406.4428878654296,
            "rating_q975": 1414.776578333429,
            "rating_q025": 1398.1091973974303
        },
        "hunyuan-vision-1.5-thinking": {
            "rating": 1406.0176677131299,
            "rating_q975": 1437.548221698117,
            "rating_q025": 1374.4871137281427
        },
        "gemini-2.5-flash-lite-preview-09-2025-no-thinking": {
            "rating": 1405.7152459995962,
            "rating_q975": 1414.9575127750302,
            "rating_q025": 1396.4729792241621
        },
        "longcat-flash-chat": {
            "rating": 1403.1093196624715,
            "rating_q975": 1417.3536371350165,
            "rating_q025": 1388.8650021899266
        },
        "gpt-5-mini-high": {
            "rating": 1402.728010019159,
            "rating_q975": 1412.5104270301442,
            "rating_q025": 1392.9455930081738
        },
        "qwen3-coder-480b-a35b-instruct": {
            "rating": 1397.4294344607918,
            "rating_q975": 1407.331632787065,
            "rating_q025": 1387.5272361345185
        },
        "glm-4.5-air": {
            "rating": 1396.06673264627,
            "rating_q975": 1404.7051249176923,
            "rating_q025": 1387.428340374848
        },
        "qwen3-30b-a3b-instruct-2507": {
            "rating": 1394.9005340135645,
            "rating_q975": 1404.7388034492299,
            "rating_q025": 1385.0622645778992
        },
        "minimax-m1": {
            "rating": 1394.7881659154614,
            "rating_q975": 1402.7760881180004,
            "rating_q025": 1386.8002437129223
        },
        "o1-preview": {
            "rating": 1393.6882745764237,
            "rating_q975": 1402.587741878484,
            "rating_q025": 1384.7888072743635
        },
        "gemma-3-27b-it": {
            "rating": 1392.8078648942555,
            "rating_q975": 1399.8920311420036,
            "rating_q025": 1385.7236986465075
        },
        "claude-3-7-sonnet-20250219": {
            "rating": 1391.6445910592777,
            "rating_q975": 1399.0997536775635,
            "rating_q025": 1384.1894284409918
        },
        "qwen2.5-max": {
            "rating": 1391.6077836370212,
            "rating_q975": 1399.5236577357919,
            "rating_q025": 1383.6919095382505
        },
        "gpt-4.1-mini-2025-04-14": {
            "rating": 1387.9783836088059,
            "rating_q975": 1395.837359019383,
            "rating_q025": 1380.1194081982287
        },
        "gemini-2.5-flash-lite-preview-06-17-thinking": {
            "rating": 1387.810631994272,
            "rating_q975": 1396.3265717464012,
            "rating_q025": 1379.2946922421427
        },
        "qwen3-235b-a22b": {
            "rating": 1386.737483899143,
            "rating_q975": 1395.637981475786,
            "rating_q025": 1377.8369863224998
        },
        "grok-3-mini-high": {
            "rating": 1383.662357248633,
            "rating_q975": 1394.8757363403242,
            "rating_q025": 1372.4489781569418
        },
        "qwen-plus-0125": {
            "rating": 1383.3679280918889,
            "rating_q975": 1401.810983555719,
            "rating_q025": 1364.9248726280587
        },
        "amazon-nova-experimental-chat-10-20": {
            "rating": 1383.2306920375693,
            "rating_q975": 1400.0143801214845,
            "rating_q025": 1366.447003953654
        },
        "claude-3-5-sonnet-20241022": {
            "rating": 1381.6545007358925,
            "rating_q975": 1387.2434363066643,
            "rating_q025": 1376.0655651651207
        },
        "qwen3-next-80b-a3b-thinking": {
            "rating": 1379.2759165662794,
            "rating_q975": 1392.126481204605,
            "rating_q025": 1366.425351927954
        },
        "qwen3-32b": {
            "rating": 1378.9218143149687,
            "rating_q975": 1399.4558825680751,
            "rating_q025": 1358.3877460618623
        },
        "o3-mini-high": {
            "rating": 1375.990548643274,
            "rating_q975": 1386.3306181028145,
            "rating_q025": 1365.6504791837335
        },
        "deepseek-v3": {
            "rating": 1375.761686536078,
            "rating_q975": 1385.258534420714,
            "rating_q025": 1366.264838651442
        },
        "grok-3-mini-beta": {
            "rating": 1373.8597927242022,
            "rating_q975": 1383.4575051354109,
            "rating_q025": 1364.2620803129935
        },
        "gemini-2.0-flash-001": {
            "rating": 1371.0615972962958,
            "rating_q975": 1378.181409140343,
            "rating_q025": 1363.9417854522485
        },
        "command-a-03-2025": {
            "rating": 1370.4102856243571,
            "rating_q975": 1376.9841969238669,
            "rating_q025": 1363.8363743248474
        },
        "mistral-small-2506": {
            "rating": 1370.4059528821251,
            "rating_q975": 1381.4161601943042,
            "rating_q025": 1359.395745569946
        },
        "nvidia-llama-3.3-nemotron-super-49b-v1.5": {
            "rating": 1369.628266264228,
            "rating_q975": 1392.2569003960866,
            "rating_q025": 1346.9996321323692
        },
        "gemma-3-12b-it": {
            "rating": 1368.5184373738007,
            "rating_q975": 1389.3356456668587,
            "rating_q025": 1347.7012290807427
        },
        "llama-3.1-405b-instruct-bf16": {
            "rating": 1368.4612426489523,
            "rating_q975": 1375.6138804201844,
            "rating_q025": 1361.3086048777202
        },
        "glm-4-plus-0111": {
            "rating": 1368.041779948071,
            "rating_q975": 1386.4932743481913,
            "rating_q025": 1349.5902855479508
        },
        "hunyuan-turbo-0110": {
            "rating": 1367.0464733105268,
            "rating_q975": 1394.2563587027978,
            "rating_q025": 1339.8365879182559
        },
        "ling-flash-2.0": {
            "rating": 1366.839342881192,
            "rating_q975": 1385.065758106884,
            "rating_q025": 1348.6129276554998
        },
        "gemini-2.0-flash-lite-preview-02-05": {
            "rating": 1366.0315984716644,
            "rating_q975": 1374.9892212005611,
            "rating_q025": 1357.0739757427677
        },
        "gemini-1.5-pro-002": {
            "rating": 1364.864536206528,
            "rating_q975": 1371.5434234533839,
            "rating_q025": 1358.1856489596723
        },
        "llama-3.1-nemotron-ultra-253b-v1": {
            "rating": 1363.08990348842,
            "rating_q975": 1389.0890762778768,
            "rating_q025": 1337.0907306989634
        },
        "gpt-oss-120b": {
            "rating": 1363.0757110215363,
            "rating_q975": 1372.0957181229785,
            "rating_q025": 1354.0557039200942
        },
        "claude-3-5-sonnet-20240620": {
            "rating": 1361.9599755653019,
            "rating_q975": 1368.985347513775,
            "rating_q025": 1354.9346036168288
        },
        "llama-3.3-nemotron-49b-super-v1": {
            "rating": 1361.8981128448831,
            "rating_q975": 1390.310424971786,
            "rating_q025": 1333.4858007179803
        },
        "hunyuan-turbos-20250226": {
            "rating": 1361.006566140437,
            "rating_q975": 1388.2337960669404,
            "rating_q025": 1333.7793362139334
        },
        "glm-4.5v": {
            "rating": 1360.9544340192501,
            "rating_q975": 1383.2271216153072,
            "rating_q025": 1338.681746423193
        },
        "gpt-4o-2024-05-13": {
            "rating": 1358.7670751633495,
            "rating_q975": 1365.192189998376,
            "rating_q025": 1352.341960328323
        },
        "yi-lightning": {
            "rating": 1357.6172693675544,
            "rating_q975": 1367.0689838186693,
            "rating_q025": 1348.1655549164395
        },
        "llama-3.1-405b-instruct-fp8": {
            "rating": 1355.6837760210285,
            "rating_q975": 1362.757008189241,
            "rating_q025": 1348.610543852816
        },
        "o3-mini": {
            "rating": 1355.4783503724152,
            "rating_q975": 1361.8918971187197,
            "rating_q025": 1349.0648036261107
        },
        "nova-2-lite": {
            "rating": 1355.4021558975135,
            "rating_q975": 1375.1349416845867,
            "rating_q025": 1335.6693701104402
        },
        "intellect-3": {
            "rating": 1354.8662296116697,
            "rating_q975": 1385.8384057609032,
            "rating_q025": 1323.8940534624362
        },
        "minimax-m2": {
            "rating": 1354.8039689163325,
            "rating_q975": 1373.2058196409014,
            "rating_q025": 1336.4021181917635
        },
        "step-3": {
            "rating": 1353.643188295437,
            "rating_q975": 1371.9321888572563,
            "rating_q025": 1335.354187733618
        },
        "grok-2-2024-08-13": {
            "rating": 1353.5397556061494,
            "rating_q975": 1360.3863811945014,
            "rating_q025": 1346.6931300177973
        },
        "gpt-4o-2024-08-06": {
            "rating": 1353.4976046587408,
            "rating_q975": 1361.299455198836,
            "rating_q025": 1345.6957541186455
        },
        "qwq-32b": {
            "rating": 1352.5666558800226,
            "rating_q975": 1361.4023442185517,
            "rating_q025": 1343.7309675414936
        },
        "gpt-4.1-nano-2025-04-14": {
            "rating": 1352.3333933963627,
            "rating_q975": 1368.922073974731,
            "rating_q025": 1335.7447128179945
        },
        "gpt-5-nano-high": {
            "rating": 1350.3639287985297,
            "rating_q975": 1367.0460506672666,
            "rating_q025": 1333.6818069297929
        },
        "gemini-advanced-0514": {
            "rating": 1348.4146690923253,
            "rating_q975": 1357.4730034786198,
            "rating_q025": 1339.3563347060308
        },
        "step-2-16k-exp-202412": {
            "rating": 1347.5160860461588,
            "rating_q975": 1366.9327327110755,
            "rating_q025": 1328.099439381242
        },
        "llama-4-maverick-17b-128e-instruct": {
            "rating": 1347.357098645835,
            "rating_q975": 1355.2041703080595,
            "rating_q025": 1339.5100269836107
        },
        "llama-3.3-70b-instruct": {
            "rating": 1347.148679622058,
            "rating_q975": 1353.449194782125,
            "rating_q025": 1340.8481644619908
        },
        "claude-3-opus-20240229": {
            "rating": 1346.4153239108716,
            "rating_q975": 1352.2899896074255,
            "rating_q025": 1340.5406582143178
        },
        "hunyuan-large-2025-02-10": {
            "rating": 1346.3808788064798,
            "rating_q975": 1367.4067380549943,
            "rating_q025": 1325.3550195579653
        },
        "claude-3-5-haiku-20241022": {
            "rating": 1345.334155267764,
            "rating_q975": 1351.4667581000776,
            "rating_q025": 1339.2015524354501
        },
        "amazon-nova-experimental-chat-10-09": {
            "rating": 1345.2897332993878,
            "rating_q975": 1360.7858211253122,
            "rating_q025": 1329.7936454734634
        },
        "gemma-3n-e4b-it": {
            "rating": 1342.7747471768569,
            "rating_q975": 1352.6851606520538,
            "rating_q025": 1332.86433370166
        },
        "o1-mini": {
            "rating": 1342.116430168165,
            "rating_q975": 1349.182268341363,
            "rating_q025": 1335.050591994967
        },
        "athene-70b-0725": {
            "rating": 1341.4036956858213,
            "rating_q975": 1352.748588212959,
            "rating_q025": 1330.0588031586835
        },
        "qwen2.5-plus-1127": {
            "rating": 1339.9416975667984,
            "rating_q975": 1353.4308607479963,
            "rating_q025": 1326.4525343856005
        },
        "step-1o-turbo-202506": {
            "rating": 1339.9100769735564,
            "rating_q975": 1354.4840676581323,
            "rating_q025": 1325.3360862889806
        },
        "llama-4-scout-17b-16e-instruct": {
            "rating": 1339.2312553239271,
            "rating_q975": 1348.12276467488,
            "rating_q025": 1330.3397459729742
        },
        "athene-v2-chat": {
            "rating": 1338.526705047713,
            "rating_q975": 1347.507760292939,
            "rating_q025": 1329.5456498024869
        },
        "glm-4-plus": {
            "rating": 1337.0381035625144,
            "rating_q975": 1346.4933423836721,
            "rating_q025": 1327.5828647413566
        },
        "gemini-1.5-pro-001": {
            "rating": 1336.7825009828755,
            "rating_q975": 1344.3633252477046,
            "rating_q025": 1329.2016767180464
        },
        "hunyuan-standard-2025-02-10": {
            "rating": 1336.4228823782219,
            "rating_q975": 1357.8315550225286,
            "rating_q025": 1315.014209733915
        },
        "qwen3-30b-a3b": {
            "rating": 1335.729882315846,
            "rating_q975": 1344.7570556015237,
            "rating_q025": 1326.7027090301683
        },
        "mistral-large-2407": {
            "rating": 1335.4083518759705,
            "rating_q975": 1343.3952801924036,
            "rating_q025": 1327.4214235595375
        },
        "grok-2-mini-2024-08-13": {
            "rating": 1334.7251964221336,
            "rating_q975": 1341.9306030742248,
            "rating_q025": 1327.5197897700425
        },
        "mercury": {
            "rating": 1334.5463861140906,
            "rating_q975": 1370.0233787044328,
            "rating_q025": 1299.0693935237484
        },
        "deepseek-v2.5-1210": {
            "rating": 1334.5208561165596,
            "rating_q975": 1351.1520176606045,
            "rating_q025": 1317.8896945725146
        },
        "gpt-oss-20b": {
            "rating": 1333.7199259490933,
            "rating_q975": 1348.8630045799339,
            "rating_q025": 1318.5768473182527
        },
        "gpt-4-turbo-2024-04-09": {
            "rating": 1332.9808302206643,
            "rating_q975": 1340.1033608653124,
            "rating_q025": 1325.8582995760162
        },
        "gemini-1.5-flash-002": {
            "rating": 1332.482685401866,
            "rating_q975": 1340.6110612920274,
            "rating_q025": 1324.3543095117047
        },
        "gpt-4o-mini-2024-07-18": {
            "rating": 1329.4375231277493,
            "rating_q975": 1335.7904861042116,
            "rating_q025": 1323.084560151287
        },
        "qwen-max-0919": {
            "rating": 1328.3469665095906,
            "rating_q975": 1339.291435208309,
            "rating_q025": 1317.4024978108723
        },
        "reka-core-20240904": {
            "rating": 1326.3081118376242,
            "rating_q975": 1342.5607980350733,
            "rating_q025": 1310.0554256401751
        },
        "gpt-4-1106-preview": {
            "rating": 1325.9719065810277,
            "rating_q975": 1333.3602665334627,
            "rating_q025": 1318.5835466285928
        },
        "ring-flash-2.0": {
            "rating": 1325.0331680252148,
            "rating_q975": 1343.167451771538,
            "rating_q025": 1306.8988842788915
        },
        "deepseek-v2.5": {
            "rating": 1324.5890574597413,
            "rating_q975": 1333.9398769273605,
            "rating_q025": 1315.238237992122
        },
        "gpt-4-0125-preview": {
            "rating": 1323.419595729825,
            "rating_q975": 1330.9044931766439,
            "rating_q025": 1315.9346982830061
        },
        "llama-3.1-70b-instruct": {
            "rating": 1323.0367417723792,
            "rating_q975": 1330.1941901625942,
            "rating_q025": 1315.8792933821642
        },
        "qwen2.5-72b-instruct": {
            "rating": 1321.160305230883,
            "rating_q975": 1328.8067888200817,
            "rating_q025": 1313.5138216416844
        },
        "llama-3.1-nemotron-70b-instruct": {
            "rating": 1318.7140161003508,
            "rating_q975": 1335.0024727204316,
            "rating_q025": 1302.42555948027
        },
        "mistral-large-2411": {
            "rating": 1318.6384529471254,
            "rating_q975": 1327.1632055849777,
            "rating_q025": 1310.113700309273
        },
        "magistral-medium-2506": {
            "rating": 1317.7282303823586,
            "rating_q975": 1332.3549399157064,
            "rating_q025": 1303.1015208490107
        },
        "jamba-1.5-large": {
            "rating": 1317.7124265050506,
            "rating_q975": 1333.5355316438643,
            "rating_q025": 1301.889321366237
        },
        "gemma-3-4b-it": {
            "rating": 1315.8492591841764,
            "rating_q975": 1336.761128805977,
            "rating_q025": 1294.9373895623758
        },
        "hunyuan-large-vision": {
            "rating": 1315.1066498019145,
            "rating_q975": 1334.8077602265641,
            "rating_q025": 1295.4055393772649
        },
        "mistral-small-3.1-24b-instruct-2503": {
            "rating": 1312.5338356670218,
            "rating_q975": 1321.246345323428,
            "rating_q025": 1303.8213260106156
        },
        "llama-3.1-tulu-3-70b": {
            "rating": 1312.2916507835112,
            "rating_q975": 1336.9145870746938,
            "rating_q025": 1287.6687144923285
        },
        "nemotron-4-340b-instruct": {
            "rating": 1309.6915389245214,
            "rating_q975": 1321.2441323474784,
            "rating_q025": 1298.1389455015644
        },
        "llama-3.1-nemotron-51b-instruct": {
            "rating": 1308.8425505153414,
            "rating_q975": 1330.438832807696,
            "rating_q025": 1287.2462682229868
        },
        "command-r-plus-08-2024": {
            "rating": 1308.7656214762578,
            "rating_q975": 1323.1780345248144,
            "rating_q025": 1294.3532084277012
        },
        "gemma-2-27b-it": {
            "rating": 1307.7186210201394,
            "rating_q975": 1313.9963675185543,
            "rating_q025": 1301.4408745217245
        },
        "amazon-nova-pro-v1.0": {
            "rating": 1306.8258448339632,
            "rating_q975": 1315.9054579870824,
            "rating_q025": 1297.746231680844
        },
        "claude-3-sonnet-20240229": {
            "rating": 1306.131841505805,
            "rating_q975": 1313.6059652347665,
            "rating_q025": 1298.6577177768434
        },
        "olmo-3-32b-think": {
            "rating": 1304.4664470222174,
            "rating_q975": 1330.4757783405398,
            "rating_q025": 1278.457115703895
        },
        "reka-flash-20240904": {
            "rating": 1301.7140100820607,
            "rating_q975": 1317.62688959545,
            "rating_q025": 1285.8011305686714
        },
        "llama-3-70b-instruct": {
            "rating": 1300.4557186786606,
            "rating_q975": 1307.4631229841584,
            "rating_q025": 1293.4483143731627
        },
        "gemma-2-9b-it-simpo": {
            "rating": 1299.626062856969,
            "rating_q975": 1314.4830599481818,
            "rating_q025": 1284.769065765756
        },
        "mistral-small-24b-instruct-2501": {
            "rating": 1297.9625712776133,
            "rating_q975": 1309.5609393328527,
            "rating_q025": 1286.3642032223738
        },
        "gemini-1.5-flash-001": {
            "rating": 1297.7823697671188,
            "rating_q975": 1305.6209031665271,
            "rating_q025": 1289.9438363677104
        },
        "command-r-08-2024": {
            "rating": 1297.4838553875989,
            "rating_q975": 1311.837442773474,
            "rating_q025": 1283.1302680017236
        },
        "command-r-plus": {
            "rating": 1295.2630541578706,
            "rating_q975": 1303.4289680487984,
            "rating_q025": 1287.0971402669427
        },
        "glm-4-0520": {
            "rating": 1294.4979329301418,
            "rating_q975": 1309.5040057678932,
            "rating_q025": 1279.4918600923904
        },
        "gpt-4-0314": {
            "rating": 1294.3836739399264,
            "rating_q975": 1303.5136121142793,
            "rating_q025": 1285.2537357655735
        },
        "olmo-2-0325-32b-instruct": {
            "rating": 1292.6854983654403,
            "rating_q975": 1316.6558075874361,
            "rating_q025": 1268.7151891434444
        },
        "c4ai-aya-expanse-32b": {
            "rating": 1291.2007327492283,
            "rating_q975": 1300.2986368100196,
            "rating_q025": 1282.102828688437
        },
        "qwen2-72b-instruct": {
            "rating": 1286.9366718363967,
            "rating_q975": 1296.1256744621094,
            "rating_q025": 1277.747669210684
        },
        "gpt-4-0613": {
            "rating": 1284.9325718446482,
            "rating_q975": 1292.9185558527,
            "rating_q025": 1276.9465878365966
        },
        "amazon-nova-lite-v1.0": {
            "rating": 1284.441085511567,
            "rating_q975": 1294.682484046746,
            "rating_q025": 1274.1996869763882
        },
        "gemma-2-9b-it": {
            "rating": 1283.4411772255717,
            "rating_q975": 1290.5466802410529,
            "rating_q025": 1276.3356742100905
        },
        "gemini-1.5-flash-8b-001": {
            "rating": 1281.9506495444828,
            "rating_q975": 1290.082506073956,
            "rating_q025": 1273.8187930150095
        },
        "qwen2.5-coder-32b-instruct": {
            "rating": 1281.715124309263,
            "rating_q975": 1299.7123010299474,
            "rating_q025": 1263.7179475885787
        },
        "claude-3-haiku-20240307": {
            "rating": 1279.4513916644974,
            "rating_q975": 1286.4795043903605,
            "rating_q025": 1272.4232789386342
        },
        "deepseek-coder-v2": {
            "rating": 1276.3046786345703,
            "rating_q975": 1288.9262091708376,
            "rating_q025": 1263.683148098303
        },
        "phi-4": {
            "rating": 1269.363514500549,
            "rating_q975": 1278.9118799427636,
            "rating_q025": 1259.8151490583343
        },
        "reka-flash-21b-20240226-online": {
            "rating": 1266.6477905598754,
            "rating_q975": 1280.1056101628199,
            "rating_q025": 1253.189970956931
        },
        "amazon-nova-micro-v1.0": {
            "rating": 1261.1387544852873,
            "rating_q975": 1271.5319618638757,
            "rating_q025": 1250.745547106699
        },
        "gemini-pro-dev-api": {
            "rating": 1260.087740854118,
            "rating_q975": 1273.8996683979744,
            "rating_q025": 1246.2758133102616
        },
        "mistral-medium": {
            "rating": 1259.7646510977468,
            "rating_q975": 1270.1244089385236,
            "rating_q025": 1249.40489325697
        },
        "mistral-large-2402": {
            "rating": 1259.3114034973064,
            "rating_q975": 1268.1348360936477,
            "rating_q025": 1250.4879709009651
        },
        "mixtral-8x22b-instruct-v0.1": {
            "rating": 1258.3139660155773,
            "rating_q975": 1267.2013880963384,
            "rating_q025": 1249.4265439348162
        },
        "jamba-1.5-mini": {
            "rating": 1258.2707076670254,
            "rating_q975": 1273.9930573485087,
            "rating_q025": 1242.548357985542
        },
        "command-r": {
            "rating": 1257.023171836227,
            "rating_q975": 1266.162584992191,
            "rating_q025": 1247.883758680263
        },
        "qwen1.5-72b-chat": {
            "rating": 1255.074446201659,
            "rating_q975": 1264.8202258161662,
            "rating_q025": 1245.3286665871517
        },
        "c4ai-aya-expanse-8b": {
            "rating": 1254.8214915772348,
            "rating_q975": 1269.1181593095196,
            "rating_q025": 1240.52482384495
        },
        "qwen1.5-110b-chat": {
            "rating": 1254.5036529219706,
            "rating_q975": 1265.37830709534,
            "rating_q025": 1243.6289987486011
        },
        "reka-flash-21b-20240226": {
            "rating": 1253.400284013219,
            "rating_q975": 1264.7802411360576,
            "rating_q025": 1242.0203268903806
        },
        "ministral-8b-2410": {
            "rating": 1252.9707496622343,
            "rating_q975": 1273.2188418765966,
            "rating_q025": 1232.722657447872
        },
        "llama-3-8b-instruct": {
            "rating": 1250.3753714724942,
            "rating_q975": 1258.0193767302574,
            "rating_q025": 1242.731366214731
        },
        "zephyr-orpo-141b-A35b-v0.1": {
            "rating": 1247.8641331152112,
            "rating_q975": 1268.777444539661,
            "rating_q025": 1226.9508216907614
        },
        "hunyuan-standard-256k": {
            "rating": 1246.778176328622,
            "rating_q975": 1271.960776847159,
            "rating_q025": 1221.5955758100852
        },
        "gemini-pro": {
            "rating": 1245.9243288538573,
            "rating_q975": 1266.4402565479877,
            "rating_q025": 1225.408401159727
        },
        "llama-3.1-tulu-3-8b": {
            "rating": 1240.2079215784602,
            "rating_q975": 1264.910984672718,
            "rating_q025": 1215.5048584842023
        },
        "yi-1.5-34b-chat": {
            "rating": 1235.7426127163499,
            "rating_q975": 1246.3518167137358,
            "rating_q025": 1225.133408718964
        },
        "gpt-3.5-turbo-0125": {
            "rating": 1232.7423827273183,
            "rating_q975": 1241.056034939609,
            "rating_q025": 1224.4287305150276
        },
        "llama-3.1-8b-instruct": {
            "rating": 1232.1850950922715,
            "rating_q975": 1239.8672599702031,
            "rating_q025": 1224.5029302143398
        },
        "phi-3-medium-4k-instruct": {
            "rating": 1231.2602907525043,
            "rating_q975": 1241.7641727847947,
            "rating_q025": 1220.7564087202138
        },
        "qwen1.5-32b-chat": {
            "rating": 1229.0033531443942,
            "rating_q975": 1240.4400422136837,
            "rating_q025": 1217.5666640751047
        },
        "granite-3.0-8b-instruct": {
            "rating": 1225.3654021940138,
            "rating_q975": 1245.0887528232795,
            "rating_q025": 1205.642051564748
        },
        "granite-3.1-8b-instruct": {
            "rating": 1224.6262767947378,
            "rating_q975": 1249.8329894923877,
            "rating_q025": 1199.419564097088
        },
        "mixtral-8x7b-instruct-v0.1": {
            "rating": 1222.6809113751124,
            "rating_q975": 1230.9019813751938,
            "rating_q025": 1214.459841375031
        },
        "dbrx-instruct-preview": {
            "rating": 1220.6501828589521,
            "rating_q975": 1232.1379776680762,
            "rating_q025": 1209.162388049828
        },
        "yi-34b-chat": {
            "rating": 1219.8975150797592,
            "rating_q975": 1233.003615547764,
            "rating_q025": 1206.7914146117544
        },
        "gemma-2-2b-it": {
            "rating": 1216.961023872108,
            "rating_q975": 1224.7471110520787,
            "rating_q025": 1209.1749366921372
        },
        "internlm2_5-20b-chat": {
            "rating": 1215.1442649177666,
            "rating_q975": 1229.9857264698921,
            "rating_q025": 1200.302803365641
        },
        "starling-lm-7b-beta": {
            "rating": 1211.2148461648583,
            "rating_q975": 1224.9493267747807,
            "rating_q025": 1197.4803655549358
        },
        "gpt-3.5-turbo-1106": {
            "rating": 1209.4981758092003,
            "rating_q975": 1224.4553703522965,
            "rating_q025": 1194.5409812661042
        },
        "wizardlm-70b": {
            "rating": 1207.7876655860873,
            "rating_q975": 1225.5797987230296,
            "rating_q025": 1189.995532449145
        },
        "starling-lm-7b-alpha": {
            "rating": 1203.0914300209463,
            "rating_q975": 1218.315092805033,
            "rating_q025": 1187.8677672368597
        },
        "snowflake-arctic-instruct": {
            "rating": 1202.4433706923958,
            "rating_q975": 1213.9551481428775,
            "rating_q025": 1190.931593241914
        },
        "llama-2-70b-chat": {
            "rating": 1202.1272571521006,
            "rating_q975": 1211.977429531288,
            "rating_q025": 1192.2770847729132
        },
        "gemma-1.1-7b-it": {
            "rating": 1200.0089534936465,
            "rating_q975": 1211.0984485539234,
            "rating_q025": 1188.9194584333695
        },
        "phi-3-small-8k-instruct": {
            "rating": 1199.9238955324163,
            "rating_q975": 1212.0480878331148,
            "rating_q025": 1187.7997032317178
        },
        "vicuna-33b": {
            "rating": 1199.5681504048894,
            "rating_q975": 1211.0292341560767,
            "rating_q025": 1188.107066653702
        },
        "qwen1.5-14b-chat": {
            "rating": 1199.2106870188618,
            "rating_q975": 1212.5014968763392,
            "rating_q025": 1185.9198771613844
        },
        "tulu-2-dpo-70b": {
            "rating": 1197.5343925589996,
            "rating_q975": 1216.3377090430915,
            "rating_q025": 1178.7310760749076
        },
        "openchat-3.5": {
            "rating": 1195.9793548278003,
            "rating_q975": 1213.5866273136326,
            "rating_q025": 1178.372082341968
        },
        "nous-hermes-2-mixtral-8x7b-dpo": {
            "rating": 1194.9320007941144,
            "rating_q975": 1217.7882451297535,
            "rating_q025": 1172.0757564584753
        },
        "llama-3.2-3b-instruct": {
            "rating": 1192.1554556488618,
            "rating_q975": 1209.6315355255506,
            "rating_q025": 1174.679375772173
        },
        "openhermes-2.5-mistral-7b": {
            "rating": 1190.9730310000707,
            "rating_q975": 1211.3201826764362,
            "rating_q025": 1170.6258793237052
        },
        "granite-3.0-2b-instruct": {
            "rating": 1190.2686794054807,
            "rating_q975": 1209.2510637494113,
            "rating_q025": 1171.2862950615502
        },
        "openchat-3.5-0106": {
            "rating": 1190.1280525226707,
            "rating_q975": 1204.301930801016,
            "rating_q025": 1175.9541742443255
        },
        "deepseek-llm-67b-chat": {
            "rating": 1189.9633546990049,
            "rating_q975": 1211.6192853684067,
            "rating_q025": 1168.307424029603
        },
        "llama2-70b-steerlm-chat": {
            "rating": 1188.5358565559075,
            "rating_q975": 1212.7016126635172,
            "rating_q025": 1164.3701004482978
        },
        "solar-10.7b-instruct-v1.0": {
            "rating": 1186.4857785198465,
            "rating_q975": 1209.9145815832146,
            "rating_q025": 1163.0569754564783
        },
        "granite-3.1-2b-instruct": {
            "rating": 1184.142064930089,
            "rating_q975": 1211.6563649755967,
            "rating_q025": 1156.6277648845812
        },
        "mistral-7b-instruct-v0.2": {
            "rating": 1180.2149104042524,
            "rating_q975": 1192.6789623442776,
            "rating_q025": 1167.7508584642271
        },
        "dolphin-2.2.1-mistral-7b": {
            "rating": 1179.58728292368,
            "rating_q975": 1213.257655343491,
            "rating_q025": 1145.916910503869
        },
        "wizardlm-13b": {
            "rating": 1178.347152036087,
            "rating_q975": 1196.307913168692,
            "rating_q025": 1160.386390903482
        },
        "codellama-34b-instruct": {
            "rating": 1170.609672350024,
            "rating_q975": 1188.237713568939,
            "rating_q025": 1152.9816311311092
        },
        "falcon-180b-chat": {
            "rating": 1169.348664960888,
            "rating_q975": 1211.0605046373269,
            "rating_q025": 1127.6368252844493
        },
        "palm-2": {
            "rating": 1169.2313804462578,
            "rating_q975": 1187.6219861294392,
            "rating_q025": 1150.8407747630765
        },
        "guanaco-33b": {
            "rating": 1168.944037099469,
            "rating_q975": 1195.3446145796036,
            "rating_q025": 1142.5434596193343
        },
        "phi-3-mini-4k-instruct-june-2024": {
            "rating": 1167.508012781464,
            "rating_q975": 1182.0655189449192,
            "rating_q025": 1152.9505066180088
        },
        "qwen1.5-7b-chat": {
            "rating": 1167.4329583485346,
            "rating_q975": 1188.660814856884,
            "rating_q025": 1146.2051018401853
        },
        "llama-2-13b-chat": {
            "rating": 1165.5618050352282,
            "rating_q975": 1178.2980522676637,
            "rating_q025": 1152.8255578027927
        },
        "zephyr-7b-beta": {
            "rating": 1165.4789668325561,
            "rating_q975": 1181.2680116536524,
            "rating_q025": 1149.6899220114599
        },
        "qwq-32b-preview": {
            "rating": 1165.4170593744602,
            "rating_q975": 1191.1049791322755,
            "rating_q025": 1139.729139616645
        },
        "smollm2-1.7b-instruct": {
            "rating": 1162.4542487092956,
            "rating_q975": 1197.942079149928,
            "rating_q025": 1126.9664182686631
        },
        "vicuna-13b": {
            "rating": 1161.2556220518125,
            "rating_q975": 1174.1767273546163,
            "rating_q025": 1148.3345167490086
        },
        "mpt-30b-chat": {
            "rating": 1160.2179184193487,
            "rating_q975": 1186.5229082912724,
            "rating_q025": 1133.912928547425
        },
        "phi-3-mini-4k-instruct": {
            "rating": 1152.7597351763309,
            "rating_q975": 1165.3305615084732,
            "rating_q025": 1140.1889088441885
        },
        "zephyr-7b-alpha": {
            "rating": 1150.4480914828905,
            "rating_q975": 1184.215318074105,
            "rating_q025": 1116.680864891676
        },
        "phi-3-mini-128k-instruct": {
            "rating": 1146.7176298904828,
            "rating_q975": 1160.456073891113,
            "rating_q025": 1132.9791858898527
        },
        "gemma-7b-it": {
            "rating": 1143.5932646810081,
            "rating_q975": 1160.7205180838064,
            "rating_q025": 1126.4660112782099
        },
        "qwen-14b-chat": {
            "rating": 1142.6872364757191,
            "rating_q975": 1164.0427421682878,
            "rating_q025": 1121.3317307831505
        },
        "stripedhyena-nous-7b": {
            "rating": 1140.2270322982454,
            "rating_q975": 1161.1921381102466,
            "rating_q025": 1119.2619264862442
        },
        "llama-3.2-1b-instruct": {
            "rating": 1138.0743027697745,
            "rating_q975": 1156.413201179288,
            "rating_q025": 1119.7354043602609
        },
        "mistral-7b-instruct": {
            "rating": 1135.8442364330358,
            "rating_q975": 1153.6883036304448,
            "rating_q025": 1118.0001692356268
        },
        "gemma-1.1-2b-it": {
            "rating": 1132.2209194497184,
            "rating_q975": 1148.409924867411,
            "rating_q025": 1116.0319140320257
        },
        "llama-2-7b-chat": {
            "rating": 1128.8180498603795,
            "rating_q975": 1142.1321960299022,
            "rating_q025": 1115.5039036908568
        },
        "vicuna-7b": {
            "rating": 1124.8575618110174,
            "rating_q975": 1143.8379555792842,
            "rating_q025": 1105.8771680427506
        },
        "qwen1.5-4b-chat": {
            "rating": 1117.604328516592,
            "rating_q975": 1136.1559497992039,
            "rating_q025": 1099.05270723398
        },
        "koala-13b": {
            "rating": 1110.2501714246314,
            "rating_q975": 1131.0108856469897,
            "rating_q025": 1089.4894572022731
        },
        "alpaca-13b": {
            "rating": 1084.8145860970008,
            "rating_q975": 1106.7746336290268,
            "rating_q025": 1062.8545385649747
        },
        "olmo-7b-instruct": {
            "rating": 1082.1292993540667,
            "rating_q975": 1102.1538079648574,
            "rating_q025": 1062.104790743276
        },
        "gemma-2b-it": {
            "rating": 1081.884160240245,
            "rating_q975": 1104.860900898334,
            "rating_q025": 1058.9074195821559
        },
        "mpt-7b-chat": {
            "rating": 1072.8564381966014,
            "rating_q975": 1097.6973968182206,
            "rating_q025": 1048.0154795749822
        },
        "RWKV-4-Raven-14B": {
            "rating": 1069.8939100481082,
            "rating_q975": 1093.4965210663513,
            "rating_q025": 1046.291299029865
        },
        "gpt4all-13b-snoozy": {
            "rating": 1066.9871320911197,
            "rating_q975": 1103.5832438800828,
            "rating_q025": 1030.3910203021567
        },
        "chatglm3-6b": {
            "rating": 1057.0698717637645,
            "rating_q975": 1080.3415056011863,
            "rating_q025": 1033.7982379263426
        },
        "oasst-pythia-12b": {
            "rating": 1053.6625815843304,
            "rating_q975": 1075.0016131550233,
            "rating_q025": 1032.3235500136375
        },
        "chatglm2-6b": {
            "rating": 1049.4075615834533,
            "rating_q975": 1079.773738389624,
            "rating_q025": 1019.0413847772827
        },
        "fastchat-t5-3b": {
            "rating": 1000.6364900759222,
            "rating_q975": 1026.0862794246261,
            "rating_q025": 975.1867007272183
        },
        "llama-13b": {
            "rating": 1000.4338265330682,
            "rating_q975": 1033.2963130967723,
            "rating_q025": 967.571339969364
        },
        "dolly-v2-12b": {
            "rating": 991.3411357162386,
            "rating_q975": 1020.7756271350249,
            "rating_q025": 961.9066442974522
        },
        "chatglm-6b": {
            "rating": 962.3309126565345,
            "rating_q975": 987.9256385739569,
            "rating_q025": 936.736186739112
        },
        "stablelm-tuned-alpha-7b": {
            "rating": 942.4783802793811,
            "rating_q975": 969.9726841337039,
            "rating_q025": 914.9840764250583
        }
    },
    "industry_mathematical": {
        "claude-opus-4-5-20251101": {
            "rating": 1492.4353193924046,
            "rating_q975": 1518.4530992267871,
            "rating_q025": 1466.417539558022
        },
        "gpt-5.1-high": {
            "rating": 1491.0427506592105,
            "rating_q975": 1513.218214682608,
            "rating_q025": 1468.867286635813
        },
        "gemini-3-pro": {
            "rating": 1485.8158617685745,
            "rating_q975": 1505.2246554173257,
            "rating_q025": 1466.4070681198232
        },
        "claude-sonnet-4-5-20250929-thinking-32k": {
            "rating": 1476.5625494318729,
            "rating_q975": 1492.4925663742813,
            "rating_q025": 1460.6325324894644
        },
        "claude-opus-4-5-20251101-thinking-32k": {
            "rating": 1476.35278606624,
            "rating_q975": 1503.0966869026408,
            "rating_q025": 1449.6088852298392
        },
        "claude-sonnet-4-5-20250929": {
            "rating": 1461.5527694103525,
            "rating_q975": 1478.7444181187454,
            "rating_q025": 1444.3611207019596
        },
        "o3-2025-04-16": {
            "rating": 1460.0343172774074,
            "rating_q975": 1470.0963848257968,
            "rating_q025": 1449.972249729018
        },
        "gemini-2.5-pro": {
            "rating": 1457.6136770973128,
            "rating_q975": 1467.130233002264,
            "rating_q025": 1448.0971211923616
        },
        "claude-opus-4-1-20250805-thinking-16k": {
            "rating": 1455.60058906162,
            "rating_q975": 1468.1320781826732,
            "rating_q025": 1443.0690999405667
        },
        "grok-4.1-thinking": {
            "rating": 1455.5061650015316,
            "rating_q975": 1476.097110490653,
            "rating_q025": 1434.9152195124102
        },
        "deepseek-v3.1-thinking": {
            "rating": 1452.4675634289244,
            "rating_q975": 1476.34119297388,
            "rating_q025": 1428.593933883969
        },
        "glm-4.6": {
            "rating": 1448.4249072640266,
            "rating_q975": 1465.263304488185,
            "rating_q025": 1431.5865100398682
        },
        "kimi-k2-thinking-turbo": {
            "rating": 1448.120621019693,
            "rating_q975": 1469.0157974588024,
            "rating_q025": 1427.2254445805838
        },
        "gpt-5-high": {
            "rating": 1447.9441952474967,
            "rating_q975": 1461.8759436578841,
            "rating_q025": 1434.0124468371093
        },
        "qwen3-max-preview": {
            "rating": 1447.4051789373973,
            "rating_q975": 1463.1465358219773,
            "rating_q025": 1431.6638220528173
        },
        "claude-opus-4-1-20250805": {
            "rating": 1447.2838161913912,
            "rating_q975": 1458.2666981731657,
            "rating_q025": 1436.3009342096168
        },
        "gpt-5.1": {
            "rating": 1444.8467902682646,
            "rating_q975": 1464.789461349771,
            "rating_q025": 1424.9041191867582
        },
        "grok-4-fast-chat": {
            "rating": 1444.8394465070724,
            "rating_q975": 1476.1086516817832,
            "rating_q025": 1413.5702413323615
        },
        "grok-4-0709": {
            "rating": 1443.9283322166082,
            "rating_q975": 1456.549925200686,
            "rating_q025": 1431.3067392325304
        },
        "deepseek-v3.2": {
            "rating": 1443.877159469682,
            "rating_q975": 1474.666732345278,
            "rating_q025": 1413.0875865940861
        },
        "grok-4.1": {
            "rating": 1441.9241581713434,
            "rating_q975": 1460.8400487178733,
            "rating_q025": 1423.0082676248135
        },
        "qwen3-235b-a22b-instruct-2507": {
            "rating": 1440.5940050580311,
            "rating_q975": 1452.1450976663216,
            "rating_q025": 1429.0429124497407
        },
        "ernie-5.0-preview-1103": {
            "rating": 1440.4157255040916,
            "rating_q975": 1469.6166741174711,
            "rating_q025": 1411.214776890712
        },
        "deepseek-v3.2-exp-thinking": {
            "rating": 1438.6861864672198,
            "rating_q975": 1468.4856363791168,
            "rating_q025": 1408.8867365553228
        },
        "qwen3-vl-235b-a22b-thinking": {
            "rating": 1436.328669349902,
            "rating_q975": 1465.424283954126,
            "rating_q025": 1407.233054745678
        },
        "gemini-2.5-flash-preview-09-2025": {
            "rating": 1435.9451691046127,
            "rating_q975": 1451.716892255169,
            "rating_q025": 1420.1734459540564
        },
        "qwen3-235b-a22b-thinking-2507": {
            "rating": 1435.4180623805992,
            "rating_q975": 1459.3775357671132,
            "rating_q025": 1411.4585889940852
        },
        "longcat-flash-chat": {
            "rating": 1431.8930991620184,
            "rating_q975": 1456.518540612726,
            "rating_q025": 1407.267657711311
        },
        "qwen3-32b": {
            "rating": 1431.1880640141758,
            "rating_q975": 1463.1214870656195,
            "rating_q025": 1399.254640962732
        },
        "glm-4.5": {
            "rating": 1430.4063926959145,
            "rating_q975": 1446.9559415219856,
            "rating_q025": 1413.8568438698435
        },
        "qwen3-next-80b-a3b-instruct": {
            "rating": 1429.683553632499,
            "rating_q975": 1447.8124283807624,
            "rating_q025": 1411.5546788842357
        },
        "kimi-k2-0905-preview": {
            "rating": 1429.0251402074243,
            "rating_q975": 1451.9758447088195,
            "rating_q025": 1406.0744357060291
        },
        "qwen3-max-2025-09-23": {
            "rating": 1427.288067299162,
            "rating_q975": 1452.739568786958,
            "rating_q025": 1401.8365658113662
        },
        "claude-opus-4-20250514-thinking-16k": {
            "rating": 1427.165848142196,
            "rating_q975": 1439.568965373346,
            "rating_q025": 1414.762730911046
        },
        "minimax-m1": {
            "rating": 1426.2148451003145,
            "rating_q975": 1439.1371569601197,
            "rating_q025": 1413.2925332405093
        },
        "claude-haiku-4-5-20251001": {
            "rating": 1425.7605774115852,
            "rating_q975": 1442.011884329827,
            "rating_q025": 1409.5092704933436
        },
        "deepseek-v3.1": {
            "rating": 1423.3103643782122,
            "rating_q975": 1442.777738456135,
            "rating_q025": 1403.8429903002893
        },
        "deepseek-v3.2-exp": {
            "rating": 1423.2018170408112,
            "rating_q975": 1445.7407187679178,
            "rating_q025": 1400.6629153137046
        },
        "gemini-2.5-flash": {
            "rating": 1421.1759836682224,
            "rating_q975": 1430.2202227659047,
            "rating_q025": 1412.1317445705401
        },
        "grok-4-fast-reasoning": {
            "rating": 1420.0493638840169,
            "rating_q975": 1438.9266678691083,
            "rating_q025": 1401.1720598989255
        },
        "grok-4-1-fast-reasoning": {
            "rating": 1419.6816379148524,
            "rating_q975": 1446.6892034289124,
            "rating_q025": 1392.6740724007925
        },
        "gpt-4.5-preview-2025-02-27": {
            "rating": 1419.3202008815913,
            "rating_q975": 1434.7236157859886,
            "rating_q025": 1403.916785977194
        },
        "o1-2024-12-17": {
            "rating": 1418.3668653103148,
            "rating_q975": 1429.4656431148253,
            "rating_q025": 1407.2680875058043
        },
        "o4-mini-2025-04-16": {
            "rating": 1418.239757293219,
            "rating_q975": 1428.9799080200698,
            "rating_q025": 1407.4996065663684
        },
        "claude-sonnet-4-20250514-thinking-32k": {
            "rating": 1418.0743199986887,
            "rating_q975": 1430.9043780251445,
            "rating_q025": 1405.2442619722328
        },
        "o3-mini-high": {
            "rating": 1417.696742179707,
            "rating_q975": 1431.2514608427878,
            "rating_q025": 1404.142023516626
        },
        "qwen3-vl-235b-a22b-instruct": {
            "rating": 1415.8277901576187,
            "rating_q975": 1441.9154071272046,
            "rating_q025": 1389.7401731880327
        },
        "gpt-5-mini-high": {
            "rating": 1415.6893132926957,
            "rating_q975": 1432.1052426216306,
            "rating_q025": 1399.2733839637608
        },
        "deepseek-r1": {
            "rating": 1415.417781128433,
            "rating_q975": 1429.8761565532618,
            "rating_q025": 1400.9594057036043
        },
        "deepseek-v3.2-thinking": {
            "rating": 1414.9082472656544,
            "rating_q975": 1448.4574248397223,
            "rating_q025": 1381.3590696915865
        },
        "deepseek-r1-0528": {
            "rating": 1413.7327208428644,
            "rating_q975": 1431.985091265461,
            "rating_q025": 1395.4803504202678
        },
        "mistral-medium-2508": {
            "rating": 1413.7149298052263,
            "rating_q975": 1425.97862254394,
            "rating_q025": 1401.4512370665127
        },
        "chatgpt-4o-latest-20250326": {
            "rating": 1411.6777044873954,
            "rating_q975": 1420.9132843803843,
            "rating_q025": 1402.4421245944066
        },
        "gpt-5-chat": {
            "rating": 1409.8717698161206,
            "rating_q975": 1424.4182514777717,
            "rating_q025": 1395.3252881544695
        },
        "qwen3-235b-a22b-no-thinking": {
            "rating": 1409.626830026996,
            "rating_q975": 1421.5169242421205,
            "rating_q025": 1397.7367358118715
        },
        "claude-opus-4-20250514": {
            "rating": 1409.2823018525776,
            "rating_q975": 1420.2594871088008,
            "rating_q025": 1398.3051165963543
        },
        "qwen3-235b-a22b": {
            "rating": 1409.2792355509455,
            "rating_q975": 1423.716765423016,
            "rating_q025": 1394.8417056788749
        },
        "nvidia-llama-3.3-nemotron-super-49b-v1.5": {
            "rating": 1409.00833570434,
            "rating_q975": 1447.0773434763184,
            "rating_q025": 1370.9393279323615
        },
        "amazon-nova-experimental-chat-10-09": {
            "rating": 1408.7326336071633,
            "rating_q975": 1436.9809674298056,
            "rating_q025": 1380.484299784521
        },
        "qwen3-30b-a3b-instruct-2507": {
            "rating": 1408.1187870482083,
            "rating_q975": 1424.4252446856115,
            "rating_q025": 1391.8123294108052
        },
        "mai-1-preview": {
            "rating": 1404.1569042227716,
            "rating_q975": 1424.1614576124618,
            "rating_q025": 1384.1523508330813
        },
        "o1-preview": {
            "rating": 1400.676865564317,
            "rating_q975": 1410.6186040014402,
            "rating_q025": 1390.735127127194
        },
        "grok-3-preview-02-24": {
            "rating": 1399.639752742522,
            "rating_q975": 1410.9514861096634,
            "rating_q025": 1388.3280193753806
        },
        "qwen3-next-80b-a3b-thinking": {
            "rating": 1398.4441595177354,
            "rating_q975": 1420.5869753921054,
            "rating_q025": 1376.3013436433655
        },
        "glm-4.5-air": {
            "rating": 1398.3501754188223,
            "rating_q975": 1413.6401365925078,
            "rating_q025": 1383.0602142451369
        },
        "o3-mini": {
            "rating": 1398.304926752791,
            "rating_q975": 1406.8150145728744,
            "rating_q025": 1389.7948389327078
        },
        "claude-sonnet-4-20250514": {
            "rating": 1395.0555787721642,
            "rating_q975": 1406.8087603411484,
            "rating_q025": 1383.30239720318
        },
        "claude-3-7-sonnet-20250219-thinking-32k": {
            "rating": 1394.8125059926092,
            "rating_q975": 1405.922080736641,
            "rating_q025": 1383.7029312485774
        },
        "gpt-oss-120b": {
            "rating": 1392.3188135870967,
            "rating_q975": 1407.0195608818872,
            "rating_q025": 1377.6180662923061
        },
        "kimi-k2-0711-preview": {
            "rating": 1390.8355525083673,
            "rating_q975": 1405.1816847159475,
            "rating_q025": 1376.489420300787
        },
        "qwen3-coder-480b-a35b-instruct": {
            "rating": 1389.186917289843,
            "rating_q975": 1404.6390324076729,
            "rating_q025": 1373.7348021720131
        },
        "amazon-nova-experimental-chat-10-20": {
            "rating": 1388.9389796125868,
            "rating_q975": 1416.888578742935,
            "rating_q025": 1360.9893804822386
        },
        "hunyuan-t1-20250711": {
            "rating": 1386.890857394011,
            "rating_q975": 1424.6759673670038,
            "rating_q025": 1349.1057474210181
        },
        "mistral-large-3": {
            "rating": 1386.2601724168394,
            "rating_q975": 1418.3563352120161,
            "rating_q025": 1354.1640096216627
        },
        "step-3": {
            "rating": 1385.0995806394194,
            "rating_q975": 1417.984128989826,
            "rating_q025": 1352.2150322890127
        },
        "grok-3-mini-high": {
            "rating": 1384.9336407596015,
            "rating_q975": 1402.581599963991,
            "rating_q025": 1367.285681555212
        },
        "gemini-2.5-flash-lite-preview-09-2025-no-thinking": {
            "rating": 1381.651602400706,
            "rating_q975": 1397.4698838462052,
            "rating_q025": 1365.8333209552068
        },
        "o1-mini": {
            "rating": 1379.8286007156928,
            "rating_q975": 1387.6495110218382,
            "rating_q025": 1372.0076904095474
        },
        "minimax-m2": {
            "rating": 1379.7912749960872,
            "rating_q975": 1414.7897646369045,
            "rating_q025": 1344.7927853552699
        },
        "qwen3-30b-a3b": {
            "rating": 1378.467717492186,
            "rating_q975": 1392.4377994310632,
            "rating_q025": 1364.4976355533088
        },
        "gemini-2.5-flash-lite-preview-06-17-thinking": {
            "rating": 1375.6143970278285,
            "rating_q975": 1388.1435874098768,
            "rating_q025": 1363.0852066457803
        },
        "qwen2.5-max": {
            "rating": 1375.5396859709538,
            "rating_q975": 1385.6235467337774,
            "rating_q025": 1365.4558252081301
        },
        "gpt-4.1-2025-04-14": {
            "rating": 1375.031002753614,
            "rating_q975": 1385.2978837520589,
            "rating_q025": 1364.7641217551693
        },
        "deepseek-v3-0324": {
            "rating": 1371.3781162992166,
            "rating_q975": 1381.868766141105,
            "rating_q025": 1360.8874664573282
        },
        "llama-3.3-nemotron-49b-super-v1": {
            "rating": 1370.9001009388908,
            "rating_q975": 1407.9091305573832,
            "rating_q025": 1333.8910713203984
        },
        "ring-flash-2.0": {
            "rating": 1370.5186539233014,
            "rating_q975": 1400.8068767337052,
            "rating_q025": 1340.2304311128976
        },
        "ling-flash-2.0": {
            "rating": 1370.5013402142165,
            "rating_q975": 1398.9471080086757,
            "rating_q025": 1342.0555724197573
        },
        "gpt-4.1-mini-2025-04-14": {
            "rating": 1369.4508097542032,
            "rating_q975": 1380.71688471433,
            "rating_q025": 1358.1847347940763
        },
        "grok-3-mini-beta": {
            "rating": 1368.743050264018,
            "rating_q975": 1382.751867368386,
            "rating_q025": 1354.7342331596499
        },
        "qwq-32b": {
            "rating": 1367.917701722735,
            "rating_q975": 1381.7399321800413,
            "rating_q025": 1354.0954712654288
        },
        "gemini-2.0-flash-001": {
            "rating": 1366.275752559676,
            "rating_q975": 1375.2689826723815,
            "rating_q025": 1357.2825224469705
        },
        "claude-3-7-sonnet-20250219": {
            "rating": 1365.038825951148,
            "rating_q975": 1374.9311767232123,
            "rating_q025": 1355.1464751790838
        },
        "hunyuan-turbos-20250416": {
            "rating": 1364.8413692213753,
            "rating_q975": 1384.5050930668554,
            "rating_q025": 1345.1776453758953
        },
        "gpt-5-nano-high": {
            "rating": 1364.2895850590064,
            "rating_q975": 1392.2248062596932,
            "rating_q025": 1336.3543638583196
        },
        "mistral-small-2506": {
            "rating": 1362.8842729855792,
            "rating_q975": 1380.5585683659042,
            "rating_q025": 1345.2099776052542
        },
        "claude-3-5-sonnet-20241022": {
            "rating": 1359.642952312711,
            "rating_q975": 1366.0018816001116,
            "rating_q025": 1353.2840230253105
        },
        "mistral-medium-2505": {
            "rating": 1356.4308739451426,
            "rating_q975": 1368.2203635158296,
            "rating_q025": 1344.6413843744556
        },
        "gemini-1.5-pro-002": {
            "rating": 1356.195927319351,
            "rating_q975": 1363.3539414776822,
            "rating_q025": 1349.03791316102
        },
        "gemma-3-12b-it": {
            "rating": 1354.2119767628972,
            "rating_q975": 1384.4640509224341,
            "rating_q025": 1323.9599026033602
        },
        "glm-4.5v": {
            "rating": 1350.1061196091475,
            "rating_q975": 1386.8058409442851,
            "rating_q025": 1313.40639827401
        },
        "nova-2-lite": {
            "rating": 1349.0874319771988,
            "rating_q975": 1382.0937654769336,
            "rating_q025": 1316.081098477464
        },
        "gemma-3-27b-it": {
            "rating": 1344.5986873283534,
            "rating_q975": 1354.359104224833,
            "rating_q025": 1334.838270431874
        },
        "claude-3-5-sonnet-20240620": {
            "rating": 1341.436613799079,
            "rating_q975": 1348.6015987747057,
            "rating_q025": 1334.2716288234521
        },
        "gemini-2.0-flash-lite-preview-02-05": {
            "rating": 1341.2711403337657,
            "rating_q975": 1352.1203801420206,
            "rating_q025": 1330.4219005255109
        },
        "step-1o-turbo-202506": {
            "rating": 1341.1904364557695,
            "rating_q975": 1362.985216684872,
            "rating_q025": 1319.395656226667
        },
        "qwen-plus-0125": {
            "rating": 1340.6490897444457,
            "rating_q975": 1361.9426991924538,
            "rating_q025": 1319.3554802964377
        },
        "gpt-oss-20b": {
            "rating": 1334.9390487698718,
            "rating_q975": 1358.1284108551324,
            "rating_q025": 1311.749686684611
        },
        "command-a-03-2025": {
            "rating": 1330.9536645445937,
            "rating_q975": 1340.3242973489382,
            "rating_q025": 1321.5830317402492
        },
        "hunyuan-large-2025-02-10": {
            "rating": 1329.5708882983947,
            "rating_q975": 1355.4927083402674,
            "rating_q025": 1303.649068256522
        },
        "step-2-16k-exp-202412": {
            "rating": 1328.439971498919,
            "rating_q975": 1350.4854494149715,
            "rating_q025": 1306.3944935828665
        },
        "athene-v2-chat": {
            "rating": 1326.736999038014,
            "rating_q975": 1336.5877639727996,
            "rating_q025": 1316.8862341032282
        },
        "llama-4-maverick-17b-128e-instruct": {
            "rating": 1326.451585552686,
            "rating_q975": 1337.5657949550937,
            "rating_q025": 1315.3373761502785
        },
        "hunyuan-large-vision": {
            "rating": 1325.1416128569178,
            "rating_q975": 1352.1485328612737,
            "rating_q025": 1298.134692852562
        },
        "deepseek-v3": {
            "rating": 1323.4544221862525,
            "rating_q975": 1334.831024967029,
            "rating_q025": 1312.077819405476
        },
        "qwen2.5-plus-1127": {
            "rating": 1323.0212296472996,
            "rating_q975": 1337.4271007182058,
            "rating_q025": 1308.6153585763934
        },
        "yi-lightning": {
            "rating": 1322.6803066818857,
            "rating_q975": 1332.7359755164168,
            "rating_q025": 1312.6246378473545
        },
        "llama-3.1-405b-instruct-fp8": {
            "rating": 1322.3269268704537,
            "rating_q975": 1329.648894566863,
            "rating_q025": 1315.0049591740444
        },
        "llama-3.1-405b-instruct-bf16": {
            "rating": 1321.716871566342,
            "rating_q975": 1329.8631134277764,
            "rating_q025": 1313.5706297049076
        },
        "llama-4-scout-17b-16e-instruct": {
            "rating": 1319.030028739598,
            "rating_q975": 1332.2143220590867,
            "rating_q025": 1305.8457354201093
        },
        "gemini-advanced-0514": {
            "rating": 1317.456346675132,
            "rating_q975": 1326.9364793082334,
            "rating_q025": 1307.9762140420305
        },
        "gpt-4o-2024-08-06": {
            "rating": 1315.878103918753,
            "rating_q975": 1323.7285443132753,
            "rating_q025": 1308.0276635242305
        },
        "hunyuan-turbo-0110": {
            "rating": 1315.6703376412033,
            "rating_q975": 1349.6158941764706,
            "rating_q025": 1281.724781105936
        },
        "qwen2.5-72b-instruct": {
            "rating": 1314.1138358975277,
            "rating_q975": 1322.2992107609152,
            "rating_q025": 1305.9284610341401
        },
        "hunyuan-standard-2025-02-10": {
            "rating": 1314.1063158666157,
            "rating_q975": 1339.595812814254,
            "rating_q025": 1288.6168189189773
        },
        "gpt-4o-2024-05-13": {
            "rating": 1313.8985127827086,
            "rating_q975": 1320.338500532904,
            "rating_q025": 1307.4585250325133
        },
        "gpt-4-1106-preview": {
            "rating": 1312.3958118972373,
            "rating_q975": 1319.903669668211,
            "rating_q025": 1304.8879541262636
        },
        "gemini-1.5-pro-001": {
            "rating": 1312.162935517817,
            "rating_q975": 1319.741188946865,
            "rating_q025": 1304.5846820887691
        },
        "claude-3-opus-20240229": {
            "rating": 1312.0649194709567,
            "rating_q975": 1318.0468137568046,
            "rating_q025": 1306.083025185109
        },
        "glm-4-plus-0111": {
            "rating": 1308.3412310212368,
            "rating_q975": 1328.986979276384,
            "rating_q025": 1287.6954827660895
        },
        "hunyuan-turbos-20250226": {
            "rating": 1306.67824626978,
            "rating_q975": 1338.457785409447,
            "rating_q025": 1274.8987071301128
        },
        "gemini-1.5-flash-002": {
            "rating": 1305.619858136682,
            "rating_q975": 1314.3134443488339,
            "rating_q025": 1296.9262719245303
        },
        "llama-3.3-70b-instruct": {
            "rating": 1305.464790018436,
            "rating_q975": 1313.0411381131871,
            "rating_q025": 1297.8884419236847
        },
        "qwen-max-0919": {
            "rating": 1305.2858713403411,
            "rating_q975": 1317.903491535829,
            "rating_q025": 1292.6682511448532
        },
        "magistral-medium-2506": {
            "rating": 1305.2012640674125,
            "rating_q975": 1330.0368140560072,
            "rating_q025": 1280.3657140788177
        },
        "glm-4-plus": {
            "rating": 1304.6826902182493,
            "rating_q975": 1314.799470078144,
            "rating_q025": 1294.5659103583546
        },
        "llama-3.1-nemotron-70b-instruct": {
            "rating": 1304.0476357450907,
            "rating_q975": 1322.1380255355834,
            "rating_q025": 1285.957245954598
        },
        "grok-2-2024-08-13": {
            "rating": 1303.1429745034047,
            "rating_q975": 1310.1110368054392,
            "rating_q025": 1296.1749122013703
        },
        "gpt-4-turbo-2024-04-09": {
            "rating": 1302.638741453337,
            "rating_q975": 1309.8802250971112,
            "rating_q025": 1295.3972578095627
        },
        "mistral-large-2407": {
            "rating": 1301.8368692067795,
            "rating_q975": 1309.726688450466,
            "rating_q025": 1293.947049963093
        },
        "gpt-4-0125-preview": {
            "rating": 1301.6527219552015,
            "rating_q975": 1309.2446085138424,
            "rating_q025": 1294.0608353965606
        },
        "claude-3-5-haiku-20241022": {
            "rating": 1301.288873295487,
            "rating_q975": 1308.8496280011823,
            "rating_q025": 1293.7281185897918
        },
        "deepseek-v2.5": {
            "rating": 1300.4101693585887,
            "rating_q975": 1310.3316738242233,
            "rating_q025": 1290.4886648929541
        },
        "mistral-small-3.1-24b-instruct-2503": {
            "rating": 1298.7149445536088,
            "rating_q975": 1311.5924243877992,
            "rating_q025": 1285.8374647194184
        },
        "gemma-3n-e4b-it": {
            "rating": 1295.8903904687484,
            "rating_q975": 1310.7390781575784,
            "rating_q025": 1281.0417027799183
        },
        "deepseek-v2.5-1210": {
            "rating": 1292.313926555651,
            "rating_q975": 1309.817887839187,
            "rating_q025": 1274.809965272115
        },
        "gpt-4o-mini-2024-07-18": {
            "rating": 1290.3599874289575,
            "rating_q975": 1296.9903020480524,
            "rating_q025": 1283.7296728098627
        },
        "gpt-4-0314": {
            "rating": 1289.3114613982466,
            "rating_q975": 1298.917108067655,
            "rating_q025": 1279.7058147288383
        },
        "grok-2-mini-2024-08-13": {
            "rating": 1289.2112032851023,
            "rating_q975": 1296.6465927467098,
            "rating_q025": 1281.775813823495
        },
        "amazon-nova-pro-v1.0": {
            "rating": 1288.7982974001256,
            "rating_q975": 1298.8375872478398,
            "rating_q025": 1278.7590075524115
        },
        "mistral-large-2411": {
            "rating": 1287.7886537196198,
            "rating_q975": 1297.410908498688,
            "rating_q025": 1278.1663989405515
        },
        "gpt-4.1-nano-2025-04-14": {
            "rating": 1285.9047222486852,
            "rating_q975": 1309.9211397519364,
            "rating_q025": 1261.888304745434
        },
        "phi-4": {
            "rating": 1282.6581150870443,
            "rating_q975": 1293.8864951392134,
            "rating_q025": 1271.4297350348752
        },
        "llama-3.1-70b-instruct": {
            "rating": 1279.2490677040591,
            "rating_q975": 1286.68909869011,
            "rating_q025": 1271.8090367180082
        },
        "llama-3.1-nemotron-51b-instruct": {
            "rating": 1278.0838184662116,
            "rating_q975": 1303.3569608561745,
            "rating_q025": 1252.8106760762487
        },
        "gemma-3-4b-it": {
            "rating": 1278.037207066867,
            "rating_q975": 1308.2398786711992,
            "rating_q025": 1247.8345354625349
        },
        "qwen2-72b-instruct": {
            "rating": 1277.5821943358205,
            "rating_q975": 1286.9752093946622,
            "rating_q025": 1268.1891792769788
        },
        "llama-3.1-tulu-3-70b": {
            "rating": 1277.3431397533755,
            "rating_q975": 1304.7917900615012,
            "rating_q025": 1249.8944894452497
        },
        "mistral-small-24b-instruct-2501": {
            "rating": 1274.7379097199864,
            "rating_q975": 1288.8518245590171,
            "rating_q025": 1260.6239948809557
        },
        "qwen2.5-coder-32b-instruct": {
            "rating": 1273.6089739355643,
            "rating_q975": 1294.2016577135419,
            "rating_q025": 1253.0162901575868
        },
        "gemini-1.5-flash-001": {
            "rating": 1273.379852616048,
            "rating_q975": 1281.2050103803108,
            "rating_q025": 1265.5546948517854
        },
        "reka-core-20240904": {
            "rating": 1272.5739108560242,
            "rating_q975": 1287.824561728076,
            "rating_q025": 1257.3232599839723
        },
        "deepseek-coder-v2": {
            "rating": 1272.3858979455263,
            "rating_q975": 1285.9646542592102,
            "rating_q025": 1258.8071416318423
        },
        "hunyuan-standard-256k": {
            "rating": 1271.1082033623463,
            "rating_q975": 1302.2679442739816,
            "rating_q025": 1239.948462450711
        },
        "athene-70b-0725": {
            "rating": 1269.9787320463784,
            "rating_q975": 1280.5706363506783,
            "rating_q025": 1259.3868277420784
        },
        "gpt-4-0613": {
            "rating": 1269.2381874207367,
            "rating_q975": 1277.4770878143702,
            "rating_q025": 1260.9992870271033
        },
        "glm-4-0520": {
            "rating": 1267.5694103539367,
            "rating_q975": 1283.7141296493405,
            "rating_q025": 1251.424691058533
        },
        "claude-3-sonnet-20240229": {
            "rating": 1262.8838338076748,
            "rating_q975": 1270.6390130561103,
            "rating_q025": 1255.1286545592393
        },
        "gemma-2-27b-it": {
            "rating": 1262.591406507546,
            "rating_q975": 1269.0879724164142,
            "rating_q025": 1256.0948405986778
        },
        "amazon-nova-lite-v1.0": {
            "rating": 1262.5030174875908,
            "rating_q975": 1273.718768946694,
            "rating_q025": 1251.2872660284877
        },
        "llama-3-70b-instruct": {
            "rating": 1261.689939238033,
            "rating_q975": 1268.7127685053201,
            "rating_q025": 1254.667109970746
        },
        "nemotron-4-340b-instruct": {
            "rating": 1260.852997171141,
            "rating_q975": 1273.1003127414847,
            "rating_q025": 1248.6056816007972
        },
        "jamba-1.5-large": {
            "rating": 1260.3932743023574,
            "rating_q975": 1276.9230941569583,
            "rating_q025": 1243.8634544477566
        },
        "gemini-1.5-flash-8b-001": {
            "rating": 1255.7148695933292,
            "rating_q975": 1264.2059558577453,
            "rating_q025": 1247.2237833289132
        },
        "command-r-plus-08-2024": {
            "rating": 1248.6840833638435,
            "rating_q975": 1263.295103122464,
            "rating_q025": 1234.0730636052228
        },
        "c4ai-aya-expanse-32b": {
            "rating": 1248.6514762328554,
            "rating_q975": 1258.5256617463956,
            "rating_q025": 1238.7772907193153
        },
        "reka-flash-20240904": {
            "rating": 1247.5278965351395,
            "rating_q975": 1262.4717283995528,
            "rating_q025": 1232.584064670726
        },
        "mistral-large-2402": {
            "rating": 1243.379602854701,
            "rating_q975": 1252.3018180314273,
            "rating_q025": 1234.4573876779748
        },
        "amazon-nova-micro-v1.0": {
            "rating": 1239.9039816224367,
            "rating_q975": 1251.4520367515577,
            "rating_q025": 1228.3559264933158
        },
        "claude-3-haiku-20240307": {
            "rating": 1239.454020268758,
            "rating_q975": 1246.5723423040336,
            "rating_q025": 1232.3356982334826
        },
        "gemma-2-9b-it-simpo": {
            "rating": 1236.1305856900544,
            "rating_q975": 1251.6457563582169,
            "rating_q025": 1220.615415021892
        },
        "gemma-2-9b-it": {
            "rating": 1236.0306842057307,
            "rating_q975": 1243.5283869846342,
            "rating_q025": 1228.5329814268273
        },
        "qwen1.5-110b-chat": {
            "rating": 1234.6201907812938,
            "rating_q975": 1245.8728391132772,
            "rating_q025": 1223.3675424493103
        },
        "granite-3.1-2b-instruct": {
            "rating": 1232.600245650634,
            "rating_q975": 1261.0515182259603,
            "rating_q025": 1204.1489730753076
        },
        "mixtral-8x22b-instruct-v0.1": {
            "rating": 1232.3494356006427,
            "rating_q975": 1241.2731854851304,
            "rating_q025": 1223.425685716155
        },
        "granite-3.1-8b-instruct": {
            "rating": 1230.4657434300768,
            "rating_q975": 1260.8717310191769,
            "rating_q025": 1200.0597558409768
        },
        "qwq-32b-preview": {
            "rating": 1229.4927574921041,
            "rating_q975": 1255.7785294182186,
            "rating_q025": 1203.2069855659897
        },
        "mistral-medium": {
            "rating": 1228.876932459535,
            "rating_q975": 1239.7489765524617,
            "rating_q025": 1218.0048883666084
        },
        "phi-3-medium-4k-instruct": {
            "rating": 1227.2636221340297,
            "rating_q975": 1237.9908680575766,
            "rating_q025": 1216.5363762104828
        },
        "yi-1.5-34b-chat": {
            "rating": 1225.8209766385817,
            "rating_q975": 1237.0224634497008,
            "rating_q025": 1214.6194898274625
        },
        "command-r-08-2024": {
            "rating": 1225.5334979336735,
            "rating_q975": 1239.6555577248848,
            "rating_q025": 1211.4114381424622
        },
        "olmo-2-0325-32b-instruct": {
            "rating": 1225.2734729611798,
            "rating_q975": 1254.936030728729,
            "rating_q025": 1195.6109151936305
        },
        "qwen1.5-72b-chat": {
            "rating": 1224.2803180382807,
            "rating_q975": 1234.0514085569018,
            "rating_q025": 1214.5092275196596
        },
        "command-r-plus": {
            "rating": 1221.5461522201558,
            "rating_q975": 1229.8770351064754,
            "rating_q025": 1213.2152693338362
        },
        "ministral-8b-2410": {
            "rating": 1220.3120537849209,
            "rating_q975": 1242.0282311819615,
            "rating_q025": 1198.5958763878803
        },
        "reka-flash-21b-20240226-online": {
            "rating": 1219.1150637645223,
            "rating_q975": 1233.3261066739112,
            "rating_q025": 1204.9040208551335
        },
        "internlm2_5-20b-chat": {
            "rating": 1217.2105161753893,
            "rating_q975": 1233.1901226937264,
            "rating_q025": 1201.2309096570523
        },
        "c4ai-aya-expanse-8b": {
            "rating": 1217.0298374135136,
            "rating_q975": 1232.7685375072679,
            "rating_q025": 1201.2911373197594
        },
        "qwen1.5-32b-chat": {
            "rating": 1216.1466480845352,
            "rating_q975": 1228.1924569880414,
            "rating_q025": 1204.100839181029
        },
        "granite-3.0-8b-instruct": {
            "rating": 1214.8974723602382,
            "rating_q975": 1235.8113055022263,
            "rating_q025": 1193.9836392182501
        },
        "llama-3.1-tulu-3-8b": {
            "rating": 1213.7339939315539,
            "rating_q975": 1243.001729469702,
            "rating_q025": 1184.4662583934057
        },
        "gemini-pro": {
            "rating": 1211.3384262201193,
            "rating_q975": 1231.8561965878673,
            "rating_q025": 1190.8206558523714
        },
        "reka-flash-21b-20240226": {
            "rating": 1211.2124227985028,
            "rating_q975": 1222.8175630432124,
            "rating_q025": 1199.607282553793
        },
        "phi-3-small-8k-instruct": {
            "rating": 1205.1429137711907,
            "rating_q975": 1218.2726329474601,
            "rating_q025": 1192.0131945949213
        },
        "zephyr-orpo-141b-A35b-v0.1": {
            "rating": 1203.26405411503,
            "rating_q975": 1226.9083365669878,
            "rating_q025": 1179.619771663072
        },
        "llama-3-8b-instruct": {
            "rating": 1202.789176546362,
            "rating_q975": 1210.3290360759052,
            "rating_q025": 1195.2493170168186
        },
        "gpt-3.5-turbo-1106": {
            "rating": 1201.466903428064,
            "rating_q975": 1217.6396469980739,
            "rating_q025": 1185.294159858054
        },
        "llama-3.1-8b-instruct": {
            "rating": 1199.4238048548998,
            "rating_q975": 1207.2298833517252,
            "rating_q025": 1191.6177263580744
        },
        "phi-3-mini-4k-instruct-june-2024": {
            "rating": 1198.833299761342,
            "rating_q975": 1213.004040853081,
            "rating_q025": 1184.662558669603
        },
        "mixtral-8x7b-instruct-v0.1": {
            "rating": 1196.6455127618692,
            "rating_q975": 1204.9956992130346,
            "rating_q025": 1188.2953263107038
        },
        "jamba-1.5-mini": {
            "rating": 1196.0463849158878,
            "rating_q975": 1212.9336839518528,
            "rating_q025": 1179.1590858799227
        },
        "gpt-3.5-turbo-0125": {
            "rating": 1195.6334320416963,
            "rating_q975": 1204.0735249701581,
            "rating_q025": 1187.1933391132345
        },
        "gemini-pro-dev-api": {
            "rating": 1194.0395521825412,
            "rating_q975": 1208.6348129565715,
            "rating_q025": 1179.444291408511
        },
        "dbrx-instruct-preview": {
            "rating": 1191.1778491756654,
            "rating_q975": 1202.8087976982058,
            "rating_q025": 1179.546900653125
        },
        "granite-3.0-2b-instruct": {
            "rating": 1190.4190637944407,
            "rating_q975": 1210.9640078337006,
            "rating_q025": 1169.8741197551808
        },
        "command-r": {
            "rating": 1188.9319744641475,
            "rating_q975": 1198.5207582038101,
            "rating_q025": 1179.3431907244849
        },
        "qwen1.5-14b-chat": {
            "rating": 1186.1244826108857,
            "rating_q975": 1199.5481343062404,
            "rating_q025": 1172.700830915531
        },
        "gemma-2-2b-it": {
            "rating": 1181.412020671928,
            "rating_q975": 1189.4258167824173,
            "rating_q025": 1173.3982245614388
        },
        "smollm2-1.7b-instruct": {
            "rating": 1179.081236060461,
            "rating_q975": 1212.7340593943281,
            "rating_q025": 1145.4284127265937
        },
        "llama-3.2-3b-instruct": {
            "rating": 1176.5300654458176,
            "rating_q975": 1193.2081157539033,
            "rating_q025": 1159.852015137732
        },
        "starling-lm-7b-beta": {
            "rating": 1173.0552111113238,
            "rating_q975": 1187.326991036995,
            "rating_q025": 1158.7834311856527
        },
        "yi-34b-chat": {
            "rating": 1162.0938480400275,
            "rating_q975": 1175.9014181160446,
            "rating_q025": 1148.2862779640104
        },
        "snowflake-arctic-instruct": {
            "rating": 1161.7281516487174,
            "rating_q975": 1173.2413335431029,
            "rating_q025": 1150.2149697543318
        },
        "openhermes-2.5-mistral-7b": {
            "rating": 1159.3212735375419,
            "rating_q975": 1181.1823909708173,
            "rating_q025": 1137.4601561042664
        },
        "gemma-1.1-7b-it": {
            "rating": 1158.3856451325341,
            "rating_q975": 1169.985693573619,
            "rating_q025": 1146.7855966914492
        },
        "phi-3-mini-4k-instruct": {
            "rating": 1158.108581843706,
            "rating_q975": 1170.7102040160878,
            "rating_q025": 1145.506959671324
        },
        "wizardlm-70b": {
            "rating": 1158.0136738844415,
            "rating_q975": 1178.4202867628155,
            "rating_q025": 1137.6070610060674
        },
        "qwen1.5-7b-chat": {
            "rating": 1157.0397336194437,
            "rating_q975": 1179.8826992895683,
            "rating_q025": 1134.196767949319
        },
        "openchat-3.5-0106": {
            "rating": 1155.156630935102,
            "rating_q975": 1169.8646835476413,
            "rating_q025": 1140.4485783225625
        },
        "deepseek-llm-67b-chat": {
            "rating": 1150.521499802639,
            "rating_q975": 1176.8257608965187,
            "rating_q025": 1124.2172387087594
        },
        "tulu-2-dpo-70b": {
            "rating": 1145.3163061326597,
            "rating_q975": 1165.6171712262246,
            "rating_q025": 1125.0154410390949
        },
        "llama-3.2-1b-instruct": {
            "rating": 1144.443263021894,
            "rating_q975": 1162.2547769620262,
            "rating_q025": 1126.6317490817617
        },
        "phi-3-mini-128k-instruct": {
            "rating": 1144.1777136937922,
            "rating_q975": 1157.5453723856608,
            "rating_q025": 1130.8100550019235
        },
        "llama-2-70b-chat": {
            "rating": 1142.4508579097526,
            "rating_q975": 1152.9420970742917,
            "rating_q025": 1131.9596187452134
        },
        "qwen-14b-chat": {
            "rating": 1140.2687537884613,
            "rating_q975": 1165.8142387042324,
            "rating_q025": 1114.7232688726901
        },
        "mistral-7b-instruct-v0.2": {
            "rating": 1137.7357100408017,
            "rating_q975": 1150.2922181318195,
            "rating_q025": 1125.1792019497839
        },
        "starling-lm-7b-alpha": {
            "rating": 1136.4366326944378,
            "rating_q975": 1153.3762421067358,
            "rating_q025": 1119.4970232821397
        },
        "openchat-3.5": {
            "rating": 1132.0420053331768,
            "rating_q975": 1151.8293484001904,
            "rating_q025": 1112.2546622661632
        },
        "vicuna-33b": {
            "rating": 1130.657991121938,
            "rating_q975": 1143.7958589762366,
            "rating_q025": 1117.5201232676395
        },
        "llama-2-13b-chat": {
            "rating": 1122.4564497606302,
            "rating_q975": 1136.1473893317022,
            "rating_q025": 1108.7655101895582
        },
        "gemma-7b-it": {
            "rating": 1121.437468051181,
            "rating_q975": 1138.7106879021756,
            "rating_q025": 1104.1642482001864
        },
        "palm-2": {
            "rating": 1120.842154877169,
            "rating_q975": 1141.5742921863766,
            "rating_q025": 1100.1100175679612
        },
        "llama2-70b-steerlm-chat": {
            "rating": 1117.0499303085649,
            "rating_q975": 1146.7214046705722,
            "rating_q025": 1087.3784559465576
        },
        "codellama-34b-instruct": {
            "rating": 1116.2309841670976,
            "rating_q975": 1137.412437105855,
            "rating_q025": 1095.0495312283404
        },
        "mpt-30b-chat": {
            "rating": 1114.2903770429689,
            "rating_q975": 1151.0411835822774,
            "rating_q025": 1077.5395705036603
        },
        "dolphin-2.2.1-mistral-7b": {
            "rating": 1112.3989455003255,
            "rating_q975": 1146.549317333715,
            "rating_q025": 1078.248573666936
        },
        "gemma-1.1-2b-it": {
            "rating": 1112.1052373577177,
            "rating_q975": 1128.9386837969603,
            "rating_q025": 1095.271790918475
        },
        "solar-10.7b-instruct-v1.0": {
            "rating": 1111.6405858470703,
            "rating_q975": 1135.0987351070469,
            "rating_q025": 1088.1824365870937
        },
        "zephyr-7b-beta": {
            "rating": 1096.1147435908504,
            "rating_q975": 1114.084904690551,
            "rating_q025": 1078.1445824911498
        },
        "llama-2-7b-chat": {
            "rating": 1091.920440631186,
            "rating_q975": 1106.922969716354,
            "rating_q025": 1076.917911546018
        },
        "nous-hermes-2-mixtral-8x7b-dpo": {
            "rating": 1091.3961718220733,
            "rating_q975": 1117.1281685184815,
            "rating_q025": 1065.664175125665
        },
        "vicuna-13b": {
            "rating": 1084.4446686608812,
            "rating_q975": 1099.143523429121,
            "rating_q025": 1069.7458138926415
        },
        "stripedhyena-nous-7b": {
            "rating": 1083.1308401928788,
            "rating_q975": 1106.197934119924,
            "rating_q025": 1060.0637462658337
        },
        "guanaco-33b": {
            "rating": 1077.0876207534873,
            "rating_q975": 1112.2376119108044,
            "rating_q025": 1041.9376295961702
        },
        "mistral-7b-instruct": {
            "rating": 1073.2210153810622,
            "rating_q975": 1094.0411488698378,
            "rating_q025": 1052.4008818922866
        },
        "gemma-2b-it": {
            "rating": 1073.1102067646796,
            "rating_q975": 1097.3685983780324,
            "rating_q025": 1048.8518151513267
        },
        "wizardlm-13b": {
            "rating": 1071.312077229774,
            "rating_q975": 1094.2683218791578,
            "rating_q025": 1048.3558325803904
        },
        "qwen1.5-4b-chat": {
            "rating": 1067.1616765047984,
            "rating_q975": 1086.7971455864429,
            "rating_q025": 1047.526207423154
        },
        "olmo-7b-instruct": {
            "rating": 1062.8344921668627,
            "rating_q975": 1083.1116103653505,
            "rating_q025": 1042.5573739683748
        },
        "vicuna-7b": {
            "rating": 1044.276787511977,
            "rating_q975": 1067.9205169231866,
            "rating_q025": 1020.6330581007675
        },
        "chatglm3-6b": {
            "rating": 1028.9231873067001,
            "rating_q975": 1055.3697763966486,
            "rating_q025": 1002.4765982167515
        },
        "RWKV-4-Raven-14B": {
            "rating": 990.9539713890504,
            "rating_q975": 1016.8643071208539,
            "rating_q025": 965.0436356572468
        },
        "koala-13b": {
            "rating": 986.457816279656,
            "rating_q975": 1009.2158223036168,
            "rating_q025": 963.6998102556951
        },
        "mpt-7b-chat": {
            "rating": 982.8396626811721,
            "rating_q975": 1011.1661565105478,
            "rating_q025": 954.5131688517963
        },
        "alpaca-13b": {
            "rating": 974.2908170323803,
            "rating_q975": 999.5818866920146,
            "rating_q025": 948.9997473727461
        },
        "chatglm-6b": {
            "rating": 972.4776522876867,
            "rating_q975": 1000.1159307271818,
            "rating_q025": 944.8393738481917
        },
        "oasst-pythia-12b": {
            "rating": 968.9912658554256,
            "rating_q975": 993.8709844615778,
            "rating_q025": 944.1115472492734
        },
        "dolly-v2-12b": {
            "rating": 929.6796938740447,
            "rating_q975": 960.2282115557286,
            "rating_q025": 899.1311761923607
        },
        "llama-13b": {
            "rating": 925.6070255633599,
            "rating_q975": 962.8858959478525,
            "rating_q025": 888.3281551788673
        },
        "fastchat-t5-3b": {
            "rating": 920.0571346259906,
            "rating_q975": 948.4507568572423,
            "rating_q025": 891.6635123947389
        },
        "stablelm-tuned-alpha-7b": {
            "rating": 894.7064899325059,
            "rating_q975": 926.0897289281287,
            "rating_q025": 863.323250936883
        }
    },
    "industry_medicine_and_healthcare": {
        "gemini-3-pro": {
            "rating": 1529.3258972450556,
            "rating_q975": 1551.5116516372987,
            "rating_q025": 1507.1401428528125
        },
        "grok-4.1-thinking": {
            "rating": 1527.4999006150979,
            "rating_q975": 1549.8445812598611,
            "rating_q025": 1505.1552199703347
        },
        "claude-opus-4-5-20251101": {
            "rating": 1505.8208847371097,
            "rating_q975": 1533.549920134993,
            "rating_q025": 1478.0918493392264
        },
        "grok-4.1": {
            "rating": 1498.59183870176,
            "rating_q975": 1520.1753997176954,
            "rating_q025": 1477.0082776858246
        },
        "claude-opus-4-5-20251101-thinking-32k": {
            "rating": 1495.44936928944,
            "rating_q975": 1524.7071025742084,
            "rating_q025": 1466.1916360046716
        },
        "o3-2025-04-16": {
            "rating": 1486.244442368887,
            "rating_q975": 1497.8633759845804,
            "rating_q025": 1474.6255087531933
        },
        "chatgpt-4o-latest-20250326": {
            "rating": 1485.7737316080902,
            "rating_q975": 1497.3421881163845,
            "rating_q025": 1474.205275099796
        },
        "claude-opus-4-1-20250805-thinking-16k": {
            "rating": 1482.80407700581,
            "rating_q975": 1496.514399638514,
            "rating_q025": 1469.093754373106
        },
        "claude-sonnet-4-5-20250929": {
            "rating": 1481.712177915958,
            "rating_q975": 1500.449538898919,
            "rating_q025": 1462.9748169329969
        },
        "gpt-5.1-high": {
            "rating": 1478.94028770166,
            "rating_q975": 1503.2035783501242,
            "rating_q025": 1454.676997053196
        },
        "deepseek-v3.2-exp-thinking": {
            "rating": 1476.7551132196909,
            "rating_q975": 1505.850127502713,
            "rating_q025": 1447.6600989366689
        },
        "qwen3-max-preview": {
            "rating": 1475.3473599479296,
            "rating_q975": 1491.9461775235586,
            "rating_q025": 1458.7485423723006
        },
        "claude-opus-4-1-20250805": {
            "rating": 1473.1001882325536,
            "rating_q975": 1485.3405816884074,
            "rating_q025": 1460.8597947766998
        },
        "gemini-2.5-pro": {
            "rating": 1469.9549262626483,
            "rating_q975": 1480.4782206229397,
            "rating_q025": 1459.431631902357
        },
        "gpt-5-high": {
            "rating": 1468.578766210584,
            "rating_q975": 1484.104114705843,
            "rating_q025": 1453.0534177153252
        },
        "gpt-5-chat": {
            "rating": 1466.5811921073462,
            "rating_q975": 1481.8698490486977,
            "rating_q025": 1451.2925351659947
        },
        "gpt-5.1": {
            "rating": 1463.4971570258647,
            "rating_q975": 1487.3546173659543,
            "rating_q025": 1439.639696685775
        },
        "claude-sonnet-4-5-20250929-thinking-32k": {
            "rating": 1463.117870421533,
            "rating_q975": 1481.1897211488997,
            "rating_q025": 1445.0460196941665
        },
        "deepseek-v3.1-terminus-thinking": {
            "rating": 1462.0495346376483,
            "rating_q975": 1499.9148506724682,
            "rating_q025": 1424.1842186028284
        },
        "qwen3-235b-a22b-instruct-2507": {
            "rating": 1460.9645417624117,
            "rating_q975": 1473.8072227585906,
            "rating_q025": 1448.1218607662329
        },
        "grok-4-fast-chat": {
            "rating": 1457.9556846540472,
            "rating_q975": 1488.151038249081,
            "rating_q025": 1427.7603310590134
        },
        "kimi-k2-0711-preview": {
            "rating": 1457.3370700183978,
            "rating_q975": 1472.301092701967,
            "rating_q025": 1442.3730473348285
        },
        "kimi-k2-0905-preview": {
            "rating": 1456.3424090855628,
            "rating_q975": 1478.932314619611,
            "rating_q025": 1433.7525035515148
        },
        "gpt-4.5-preview-2025-02-27": {
            "rating": 1455.4216630560234,
            "rating_q975": 1479.9419322047438,
            "rating_q025": 1430.901393907303
        },
        "claude-opus-4-20250514-thinking-16k": {
            "rating": 1454.6305042233619,
            "rating_q975": 1467.8537451240315,
            "rating_q025": 1441.4072633226922
        },
        "claude-opus-4-20250514": {
            "rating": 1453.9170526247246,
            "rating_q975": 1466.2275280370743,
            "rating_q025": 1441.606577212375
        },
        "kimi-k2-thinking-turbo": {
            "rating": 1453.4239187089881,
            "rating_q975": 1476.37756572603,
            "rating_q025": 1430.4702716919462
        },
        "deepseek-v3.1-terminus": {
            "rating": 1452.4672194951881,
            "rating_q975": 1491.0441253261715,
            "rating_q025": 1413.8903136642048
        },
        "deepseek-v3.1-thinking": {
            "rating": 1451.3740893756017,
            "rating_q975": 1473.9915342786317,
            "rating_q025": 1428.7566444725717
        },
        "glm-4.6": {
            "rating": 1450.7972828498491,
            "rating_q975": 1469.6506312030976,
            "rating_q025": 1431.9439344966006
        },
        "grok-4-1-fast-reasoning": {
            "rating": 1448.5553829067176,
            "rating_q975": 1477.7369918266857,
            "rating_q025": 1419.3737739867495
        },
        "deepseek-v3.2": {
            "rating": 1446.3306213659891,
            "rating_q975": 1478.9241999482722,
            "rating_q025": 1413.737042783706
        },
        "grok-4-0709": {
            "rating": 1446.1368554457501,
            "rating_q975": 1459.470743870684,
            "rating_q025": 1432.8029670208164
        },
        "deepseek-v3.2-thinking": {
            "rating": 1443.5843852161984,
            "rating_q975": 1477.013805637754,
            "rating_q025": 1410.1549647946426
        },
        "grok-3-preview-02-24": {
            "rating": 1443.1395558475235,
            "rating_q975": 1458.2594141555148,
            "rating_q025": 1428.0196975395322
        },
        "hunyuan-t1-20250711": {
            "rating": 1442.919570549107,
            "rating_q975": 1481.8312132891965,
            "rating_q025": 1404.0079278090175
        },
        "qwen3-max-2025-09-23": {
            "rating": 1442.5249080584758,
            "rating_q975": 1470.7877051115718,
            "rating_q025": 1414.26211100538
        },
        "deepseek-v3.1": {
            "rating": 1441.3170443903919,
            "rating_q975": 1461.046616505667,
            "rating_q025": 1421.5874722751166
        },
        "gpt-4.1-2025-04-14": {
            "rating": 1441.2343517097834,
            "rating_q975": 1453.359622313611,
            "rating_q025": 1429.1090811059557
        },
        "qwen3-next-80b-a3b-instruct": {
            "rating": 1441.0257506883338,
            "rating_q975": 1459.224827937791,
            "rating_q025": 1422.8266734388767
        },
        "ernie-5.0-preview-1103": {
            "rating": 1440.4698345418797,
            "rating_q975": 1473.0437016987023,
            "rating_q025": 1407.895967385057
        },
        "longcat-flash-chat": {
            "rating": 1440.0486864761083,
            "rating_q975": 1464.3092758212088,
            "rating_q025": 1415.7880971310078
        },
        "mistral-medium-2508": {
            "rating": 1439.579105243321,
            "rating_q975": 1453.255815474115,
            "rating_q025": 1425.902395012527
        },
        "deepseek-r1-0528": {
            "rating": 1439.18438972141,
            "rating_q975": 1456.7697876407408,
            "rating_q025": 1421.5989918020794
        },
        "qwen3-vl-235b-a22b-instruct": {
            "rating": 1439.1189301371917,
            "rating_q975": 1467.6431639082175,
            "rating_q025": 1410.5946963661659
        },
        "qwen3-235b-a22b-thinking-2507": {
            "rating": 1437.2717975357434,
            "rating_q975": 1463.3046015469104,
            "rating_q025": 1411.2389935245765
        },
        "deepseek-v3.2-exp": {
            "rating": 1435.243348172513,
            "rating_q975": 1460.9848195598895,
            "rating_q025": 1409.5018767851363
        },
        "gemini-2.5-flash-preview-09-2025": {
            "rating": 1434.6149865779,
            "rating_q975": 1451.7926954875834,
            "rating_q025": 1417.4372776682167
        },
        "grok-4-fast-reasoning": {
            "rating": 1434.502351712995,
            "rating_q975": 1455.548008883034,
            "rating_q025": 1413.456694542956
        },
        "claude-sonnet-4-20250514": {
            "rating": 1434.360350715582,
            "rating_q975": 1447.531088588801,
            "rating_q025": 1421.189612842363
        },
        "hunyuan-turbos-20250416": {
            "rating": 1432.9921924160456,
            "rating_q975": 1457.4515717266313,
            "rating_q025": 1408.5328131054598
        },
        "glm-4.5": {
            "rating": 1432.2265559610212,
            "rating_q975": 1449.033783736825,
            "rating_q025": 1415.4193281852174
        },
        "deepseek-v3-0324": {
            "rating": 1431.483517084286,
            "rating_q975": 1443.5197732771796,
            "rating_q025": 1419.4472608913923
        },
        "mistral-large-3": {
            "rating": 1429.5470925063578,
            "rating_q975": 1465.0317642542552,
            "rating_q025": 1394.0624207584603
        },
        "mai-1-preview": {
            "rating": 1429.494661096704,
            "rating_q975": 1448.0020870597014,
            "rating_q025": 1410.9872351337067
        },
        "qwen3-235b-a22b-no-thinking": {
            "rating": 1428.2104587854983,
            "rating_q975": 1441.2677227260156,
            "rating_q025": 1415.153194844981
        },
        "claude-3-7-sonnet-20250219-thinking-32k": {
            "rating": 1428.0788186222103,
            "rating_q975": 1441.4187293055977,
            "rating_q025": 1414.7389079388229
        },
        "o4-mini-2025-04-16": {
            "rating": 1427.2157057822274,
            "rating_q975": 1439.8895092964738,
            "rating_q025": 1414.541902267981
        },
        "claude-sonnet-4-20250514-thinking-32k": {
            "rating": 1426.679465101578,
            "rating_q975": 1440.1389659452818,
            "rating_q025": 1413.2199642578742
        },
        "gemini-2.5-flash": {
            "rating": 1422.2381884264823,
            "rating_q975": 1432.636996749894,
            "rating_q025": 1411.8393801030707
        },
        "mistral-medium-2505": {
            "rating": 1420.994931970077,
            "rating_q975": 1434.8739725754801,
            "rating_q025": 1407.1158913646739
        },
        "claude-haiku-4-5-20251001": {
            "rating": 1420.7670126662379,
            "rating_q975": 1439.3289454431583,
            "rating_q025": 1402.2050798893174
        },
        "glm-4-plus-0111": {
            "rating": 1418.1837411212061,
            "rating_q975": 1451.8749141933984,
            "rating_q025": 1384.492568049014
        },
        "deepseek-r1": {
            "rating": 1416.448988979094,
            "rating_q975": 1436.8940029339324,
            "rating_q025": 1396.0039750242559
        },
        "qwen3-vl-235b-a22b-thinking": {
            "rating": 1413.9807073514833,
            "rating_q975": 1442.5291345972,
            "rating_q025": 1385.4322801057665
        },
        "minimax-m1": {
            "rating": 1413.758548186604,
            "rating_q975": 1427.2181409153172,
            "rating_q025": 1400.2989554578908
        },
        "qwen3-coder-480b-a35b-instruct": {
            "rating": 1411.9778576184053,
            "rating_q975": 1428.9562887117565,
            "rating_q025": 1394.999426525054
        },
        "gemini-2.5-flash-lite-preview-09-2025-no-thinking": {
            "rating": 1410.0571072514908,
            "rating_q975": 1427.597695892629,
            "rating_q025": 1392.5165186103527
        },
        "gpt-5-mini-high": {
            "rating": 1409.6557122527845,
            "rating_q975": 1426.723410561993,
            "rating_q025": 1392.588013943576
        },
        "gemini-2.5-flash-lite-preview-06-17-thinking": {
            "rating": 1408.698000580568,
            "rating_q975": 1422.95849074267,
            "rating_q025": 1394.4375104184662
        },
        "o1-2024-12-17": {
            "rating": 1406.7040323709955,
            "rating_q975": 1423.8733096569172,
            "rating_q025": 1389.5347550850738
        },
        "gemma-3-27b-it": {
            "rating": 1406.4322920983896,
            "rating_q975": 1419.2604499075217,
            "rating_q025": 1393.6041342892574
        },
        "gpt-4.1-mini-2025-04-14": {
            "rating": 1404.6121199606862,
            "rating_q975": 1417.5700803796415,
            "rating_q025": 1391.654159541731
        },
        "qwen3-30b-a3b-instruct-2507": {
            "rating": 1400.3359601085644,
            "rating_q975": 1417.269823237047,
            "rating_q025": 1383.402096980082
        },
        "deepseek-v3": {
            "rating": 1399.764833505686,
            "rating_q975": 1417.607198434058,
            "rating_q025": 1381.922468577314
        },
        "glm-4.5v": {
            "rating": 1398.6474805073015,
            "rating_q975": 1438.3615265097667,
            "rating_q025": 1358.9334345048362
        },
        "hunyuan-large-2025-02-10": {
            "rating": 1396.6363007495152,
            "rating_q975": 1435.2893530938245,
            "rating_q025": 1357.9832484052058
        },
        "qwen2.5-max": {
            "rating": 1396.5208670334496,
            "rating_q975": 1411.1460860444608,
            "rating_q025": 1381.8956480224383
        },
        "glm-4.5-air": {
            "rating": 1396.302417028108,
            "rating_q975": 1411.5330337270077,
            "rating_q025": 1381.0718003292084
        },
        "claude-3-5-sonnet-20241022": {
            "rating": 1396.1891488090096,
            "rating_q975": 1405.7061297815396,
            "rating_q025": 1386.6721678364795
        },
        "qwen3-next-80b-a3b-thinking": {
            "rating": 1394.8213822477333,
            "rating_q975": 1417.5457922121668,
            "rating_q025": 1372.0969722832997
        },
        "claude-3-7-sonnet-20250219": {
            "rating": 1394.371203549178,
            "rating_q975": 1407.8263102330366,
            "rating_q025": 1380.9160968653196
        },
        "mistral-small-2506": {
            "rating": 1392.826330664493,
            "rating_q975": 1410.8954820598046,
            "rating_q025": 1374.7571792691815
        },
        "qwen-plus-0125": {
            "rating": 1392.0368396875963,
            "rating_q975": 1423.8521062028478,
            "rating_q025": 1360.2215731723447
        },
        "grok-3-mini-high": {
            "rating": 1389.362705597655,
            "rating_q975": 1408.3970970328962,
            "rating_q025": 1370.3283141624136
        },
        "nvidia-llama-3.3-nemotron-super-49b-v1.5": {
            "rating": 1388.4483695689319,
            "rating_q975": 1428.1742278040435,
            "rating_q025": 1348.7225113338202
        },
        "qwen3-235b-a22b": {
            "rating": 1384.6874522617088,
            "rating_q975": 1399.9852592106013,
            "rating_q025": 1369.3896453128164
        },
        "gemini-2.0-flash-001": {
            "rating": 1382.9655871139526,
            "rating_q975": 1395.8332037392622,
            "rating_q025": 1370.0979704886429
        },
        "command-a-03-2025": {
            "rating": 1381.992733612674,
            "rating_q975": 1393.424872254122,
            "rating_q025": 1370.5605949712262
        },
        "step-2-16k-exp-202412": {
            "rating": 1380.1379062725862,
            "rating_q975": 1416.7775915820748,
            "rating_q025": 1343.4982209630975
        },
        "qwen3-32b": {
            "rating": 1379.9794063722552,
            "rating_q975": 1419.47837290007,
            "rating_q025": 1340.4804398444403
        },
        "gemini-2.0-flash-lite-preview-02-05": {
            "rating": 1377.2640975905583,
            "rating_q975": 1395.9256044870776,
            "rating_q025": 1358.602590694039
        },
        "llama-3.1-405b-instruct-bf16": {
            "rating": 1376.5934389624558,
            "rating_q975": 1390.1445948798184,
            "rating_q025": 1363.0422830450932
        },
        "o1-preview": {
            "rating": 1375.7340511397558,
            "rating_q975": 1390.3908102872558,
            "rating_q025": 1361.0772919922558
        },
        "o3-mini-high": {
            "rating": 1375.4190752473398,
            "rating_q975": 1396.2918157043325,
            "rating_q025": 1354.5463347903471
        },
        "gpt-5-nano-high": {
            "rating": 1375.2905722083985,
            "rating_q975": 1403.7611736841277,
            "rating_q025": 1346.8199707326694
        },
        "gpt-oss-120b": {
            "rating": 1373.4698967722472,
            "rating_q975": 1389.2670418437338,
            "rating_q025": 1357.6727517007607
        },
        "hunyuan-standard-2025-02-10": {
            "rating": 1369.294279798618,
            "rating_q975": 1406.8104872569709,
            "rating_q025": 1331.778072340265
        },
        "step-3": {
            "rating": 1368.300680975051,
            "rating_q975": 1400.15626422802,
            "rating_q025": 1336.4450977220818
        },
        "gemini-1.5-pro-002": {
            "rating": 1364.3896359111473,
            "rating_q975": 1376.1868966033753,
            "rating_q025": 1352.5923752189192
        },
        "gpt-oss-20b": {
            "rating": 1363.2563707999893,
            "rating_q975": 1389.7205861024452,
            "rating_q025": 1336.7921554975335
        },
        "grok-3-mini-beta": {
            "rating": 1363.2331564861702,
            "rating_q975": 1379.2291831687685,
            "rating_q025": 1347.2371298035719
        },
        "gpt-4o-2024-05-13": {
            "rating": 1363.1611790639138,
            "rating_q975": 1372.8116859466493,
            "rating_q025": 1353.5106721811783
        },
        "yi-lightning": {
            "rating": 1362.940013965629,
            "rating_q975": 1378.6051999772467,
            "rating_q025": 1347.2748279540115
        },
        "grok-2-2024-08-13": {
            "rating": 1362.302715280986,
            "rating_q975": 1373.3078363676277,
            "rating_q025": 1351.2975941943441
        },
        "claude-3-5-sonnet-20240620": {
            "rating": 1361.5109343659337,
            "rating_q975": 1372.2109066660505,
            "rating_q025": 1350.810962065817
        },
        "amazon-nova-experimental-chat-10-20": {
            "rating": 1361.4408722875503,
            "rating_q975": 1392.4885715993184,
            "rating_q025": 1330.3931729757821
        },
        "amazon-nova-experimental-chat-10-09": {
            "rating": 1360.4130007725564,
            "rating_q975": 1393.1892901052859,
            "rating_q025": 1327.636711439827
        },
        "minimax-m2": {
            "rating": 1359.1346663525687,
            "rating_q975": 1394.1625194659343,
            "rating_q025": 1324.1068132392031
        },
        "llama-4-maverick-17b-128e-instruct": {
            "rating": 1358.3293275574638,
            "rating_q975": 1371.7147863389462,
            "rating_q025": 1344.9438687759814
        },
        "qwq-32b": {
            "rating": 1357.90783278778,
            "rating_q975": 1373.8939564728153,
            "rating_q025": 1341.921709102745
        },
        "ling-flash-2.0": {
            "rating": 1357.3902860612625,
            "rating_q975": 1388.366426649423,
            "rating_q025": 1326.414145473102
        },
        "llama-3.1-405b-instruct-fp8": {
            "rating": 1357.3819494284598,
            "rating_q975": 1368.815529156278,
            "rating_q025": 1345.9483697006417
        },
        "claude-3-5-haiku-20241022": {
            "rating": 1354.5047704648177,
            "rating_q975": 1365.447327422302,
            "rating_q025": 1343.5622135073336
        },
        "gpt-4o-2024-08-06": {
            "rating": 1354.2519503902272,
            "rating_q975": 1367.3274937060894,
            "rating_q025": 1341.176407074365
        },
        "gemini-advanced-0514": {
            "rating": 1353.580940487216,
            "rating_q975": 1367.1405509264544,
            "rating_q025": 1340.0213300479775
        },
        "gemma-3-4b-it": {
            "rating": 1352.4032540702642,
            "rating_q975": 1391.5845427560837,
            "rating_q025": 1313.2219653844447
        },
        "llama-3.3-70b-instruct": {
            "rating": 1352.1980279212207,
            "rating_q975": 1363.70413834376,
            "rating_q025": 1340.6919174986815
        },
        "o3-mini": {
            "rating": 1351.6320761802785,
            "rating_q975": 1362.8002465557122,
            "rating_q025": 1340.463905804845
        },
        "gpt-4.1-nano-2025-04-14": {
            "rating": 1351.0038926726397,
            "rating_q975": 1383.3164157378121,
            "rating_q025": 1318.6913696074673
        },
        "reka-core-20240904": {
            "rating": 1350.364379875306,
            "rating_q975": 1378.5995581475224,
            "rating_q025": 1322.1292016030895
        },
        "grok-2-mini-2024-08-13": {
            "rating": 1349.4794272282847,
            "rating_q975": 1361.5631344214491,
            "rating_q025": 1337.3957200351203
        },
        "llama-4-scout-17b-16e-instruct": {
            "rating": 1349.1651784897458,
            "rating_q975": 1364.1348889043572,
            "rating_q025": 1334.1954680751344
        },
        "magistral-medium-2506": {
            "rating": 1348.5373281084358,
            "rating_q975": 1372.079283610237,
            "rating_q025": 1324.9953726066344
        },
        "claude-3-opus-20240229": {
            "rating": 1348.3259045559973,
            "rating_q975": 1357.228043686053,
            "rating_q025": 1339.4237654259416
        },
        "gemma-3n-e4b-it": {
            "rating": 1346.8599326252693,
            "rating_q975": 1363.562304232005,
            "rating_q025": 1330.1575610185334
        },
        "glm-4-plus": {
            "rating": 1345.2117804844618,
            "rating_q975": 1360.1326092976117,
            "rating_q025": 1330.2909516713119
        },
        "o1-mini": {
            "rating": 1342.644832321194,
            "rating_q975": 1354.5418120083766,
            "rating_q025": 1330.7478526340112
        },
        "deepseek-v2.5-1210": {
            "rating": 1342.0229202046007,
            "rating_q975": 1374.3623191700678,
            "rating_q025": 1309.6835212391336
        },
        "nova-2-lite": {
            "rating": 1341.3168773136413,
            "rating_q975": 1376.8489899354684,
            "rating_q025": 1305.7847646918142
        },
        "gpt-4o-mini-2024-07-18": {
            "rating": 1340.8062211379975,
            "rating_q975": 1351.2835234407726,
            "rating_q025": 1330.3289188352223
        },
        "llama-3.1-nemotron-70b-instruct": {
            "rating": 1339.8442264037635,
            "rating_q975": 1370.4196399707296,
            "rating_q025": 1309.2688128367975
        },
        "qwen3-30b-a3b": {
            "rating": 1339.7932601514924,
            "rating_q975": 1354.8413114467394,
            "rating_q025": 1324.7452088562454
        },
        "gpt-4-turbo-2024-04-09": {
            "rating": 1339.642237393924,
            "rating_q975": 1350.3210303096967,
            "rating_q025": 1328.9634444781514
        },
        "olmo-3-32b-think": {
            "rating": 1339.0013954026456,
            "rating_q975": 1390.2070756699227,
            "rating_q025": 1287.7957151353685
        },
        "athene-v2-chat": {
            "rating": 1337.9601799920092,
            "rating_q975": 1354.6189728982126,
            "rating_q025": 1321.3013870858058
        },
        "ring-flash-2.0": {
            "rating": 1336.0251745485036,
            "rating_q975": 1367.0909616932147,
            "rating_q025": 1304.9593874037926
        },
        "athene-70b-0725": {
            "rating": 1335.1813155748607,
            "rating_q975": 1353.4886044019174,
            "rating_q025": 1316.874026747804
        },
        "step-1o-turbo-202506": {
            "rating": 1335.1475987524768,
            "rating_q975": 1358.028448278561,
            "rating_q025": 1312.2667492263927
        },
        "gemini-1.5-flash-002": {
            "rating": 1334.9109530792182,
            "rating_q975": 1349.406124953472,
            "rating_q025": 1320.4157812049643
        },
        "qwen2.5-plus-1127": {
            "rating": 1333.9638307175355,
            "rating_q975": 1360.1959568511577,
            "rating_q025": 1307.7317045839134
        },
        "mistral-large-2407": {
            "rating": 1333.2048721048682,
            "rating_q975": 1345.7881742260342,
            "rating_q025": 1320.621569983702
        },
        "amazon-nova-pro-v1.0": {
            "rating": 1329.6262443541182,
            "rating_q975": 1346.9095798795547,
            "rating_q025": 1312.3429088286816
        },
        "gpt-4-0125-preview": {
            "rating": 1326.4248000828206,
            "rating_q975": 1337.4200080452881,
            "rating_q025": 1315.4295921203532
        },
        "mistral-large-2411": {
            "rating": 1325.5940054625798,
            "rating_q975": 1342.0086709918664,
            "rating_q025": 1309.1793399332932
        },
        "mistral-small-3.1-24b-instruct-2503": {
            "rating": 1325.4060664322128,
            "rating_q975": 1339.7767982957414,
            "rating_q025": 1311.0353345686842
        },
        "qwen-max-0919": {
            "rating": 1324.5162019225522,
            "rating_q975": 1342.7022506566902,
            "rating_q025": 1306.3301531884142
        },
        "gemma-3-12b-it": {
            "rating": 1324.066028776077,
            "rating_q975": 1370.935415540544,
            "rating_q025": 1277.19664201161
        },
        "deepseek-v2.5": {
            "rating": 1320.4015350994136,
            "rating_q975": 1337.2457255310958,
            "rating_q025": 1303.5573446677315
        },
        "llama-3.1-70b-instruct": {
            "rating": 1320.3584014530277,
            "rating_q975": 1332.134660808719,
            "rating_q025": 1308.5821420973364
        },
        "qwen2.5-72b-instruct": {
            "rating": 1320.3572268013872,
            "rating_q975": 1333.732977886388,
            "rating_q025": 1306.9814757163865
        },
        "gpt-4-1106-preview": {
            "rating": 1315.1246447752035,
            "rating_q975": 1326.080361191477,
            "rating_q025": 1304.1689283589299
        },
        "claude-3-sonnet-20240229": {
            "rating": 1313.382153191962,
            "rating_q975": 1324.7271372440766,
            "rating_q025": 1302.0371691398475
        },
        "command-r-plus-08-2024": {
            "rating": 1310.2297411256545,
            "rating_q975": 1334.3427030803648,
            "rating_q025": 1286.1167791709443
        },
        "llama-3-70b-instruct": {
            "rating": 1309.9955427107016,
            "rating_q975": 1320.0547764718706,
            "rating_q025": 1299.9363089495325
        },
        "gemini-1.5-pro-001": {
            "rating": 1309.2028016336171,
            "rating_q975": 1320.5921421337437,
            "rating_q025": 1297.8134611334906
        },
        "gemma-2-9b-it-simpo": {
            "rating": 1309.137544780423,
            "rating_q975": 1335.2049632954781,
            "rating_q025": 1283.070126265368
        },
        "gemma-2-27b-it": {
            "rating": 1301.216938807408,
            "rating_q975": 1311.5868571848343,
            "rating_q025": 1290.8470204299817
        },
        "c4ai-aya-expanse-32b": {
            "rating": 1299.6034281018844,
            "rating_q975": 1315.442838392263,
            "rating_q025": 1283.764017811506
        },
        "nemotron-4-340b-instruct": {
            "rating": 1299.5201991713163,
            "rating_q975": 1317.7147758312692,
            "rating_q025": 1281.3256225113635
        },
        "command-r-plus": {
            "rating": 1299.3684091145471,
            "rating_q975": 1311.4053689964508,
            "rating_q025": 1287.3314492326435
        },
        "command-r-08-2024": {
            "rating": 1298.6005020937596,
            "rating_q975": 1324.2552896323043,
            "rating_q025": 1272.9457145552149
        },
        "reka-flash-20240904": {
            "rating": 1295.2263080018865,
            "rating_q975": 1322.6532335624554,
            "rating_q025": 1267.7993824413177
        },
        "mistral-small-24b-instruct-2501": {
            "rating": 1294.6643659347078,
            "rating_q975": 1318.4693215679374,
            "rating_q025": 1270.8594103014782
        },
        "claude-3-haiku-20240307": {
            "rating": 1293.9842081150073,
            "rating_q975": 1304.3092448867744,
            "rating_q025": 1283.6591713432401
        },
        "jamba-1.5-large": {
            "rating": 1292.8008554726302,
            "rating_q975": 1320.1191685992233,
            "rating_q025": 1265.4825423460372
        },
        "glm-4-0520": {
            "rating": 1291.3648898918923,
            "rating_q975": 1315.299719838871,
            "rating_q025": 1267.4300599449136
        },
        "llama-3.1-nemotron-51b-instruct": {
            "rating": 1290.4562647134617,
            "rating_q975": 1329.7803609576642,
            "rating_q025": 1251.132168469259
        },
        "hunyuan-large-vision": {
            "rating": 1290.270938709573,
            "rating_q975": 1321.6997563413777,
            "rating_q025": 1258.8421210777685
        },
        "qwen2-72b-instruct": {
            "rating": 1289.756711047281,
            "rating_q975": 1303.58577510641,
            "rating_q025": 1275.927646988152
        },
        "gpt-4-0314": {
            "rating": 1288.8967095650678,
            "rating_q975": 1302.8239012152158,
            "rating_q025": 1274.9695179149198
        },
        "gpt-4-0613": {
            "rating": 1283.7060107577222,
            "rating_q975": 1295.4390592647553,
            "rating_q025": 1271.972962250689
        },
        "phi-4": {
            "rating": 1282.5931388790846,
            "rating_q975": 1301.8049736335279,
            "rating_q025": 1263.3813041246412
        },
        "amazon-nova-lite-v1.0": {
            "rating": 1281.0661996857198,
            "rating_q975": 1300.65662389856,
            "rating_q025": 1261.4757754728796
        },
        "gemini-1.5-flash-001": {
            "rating": 1280.7096838597254,
            "rating_q975": 1292.707917479672,
            "rating_q025": 1268.7114502397787
        },
        "amazon-nova-micro-v1.0": {
            "rating": 1276.2510889431633,
            "rating_q975": 1295.08043901137,
            "rating_q025": 1257.4217388749566
        },
        "gemini-1.5-flash-8b-001": {
            "rating": 1276.0899942230917,
            "rating_q975": 1290.4480091370688,
            "rating_q025": 1261.7319793091146
        },
        "jamba-1.5-mini": {
            "rating": 1274.851399646302,
            "rating_q975": 1301.4767816794158,
            "rating_q025": 1248.2260176131883
        },
        "gemini-pro-dev-api": {
            "rating": 1274.261798927218,
            "rating_q975": 1294.820089720256,
            "rating_q025": 1253.70350813418
        },
        "gemma-2-9b-it": {
            "rating": 1270.2909825769943,
            "rating_q975": 1282.160755928242,
            "rating_q025": 1258.4212092257467
        },
        "deepseek-coder-v2": {
            "rating": 1270.2826779886873,
            "rating_q975": 1290.3472605876348,
            "rating_q025": 1250.2180953897398
        },
        "c4ai-aya-expanse-8b": {
            "rating": 1268.3490892328882,
            "rating_q975": 1295.4479543177317,
            "rating_q025": 1241.2502241480447
        },
        "mistral-large-2402": {
            "rating": 1265.0257929934498,
            "rating_q975": 1277.9382634857052,
            "rating_q025": 1252.1133225011945
        },
        "qwen2.5-coder-32b-instruct": {
            "rating": 1263.7633969796589,
            "rating_q975": 1300.0082757348814,
            "rating_q025": 1227.5185182244363
        },
        "reka-flash-21b-20240226-online": {
            "rating": 1263.7133542061024,
            "rating_q975": 1284.774014085498,
            "rating_q025": 1242.6526943267068
        },
        "ministral-8b-2410": {
            "rating": 1263.4907935614679,
            "rating_q975": 1298.088957033726,
            "rating_q025": 1228.8926300892097
        },
        "reka-flash-21b-20240226": {
            "rating": 1261.6515894561749,
            "rating_q975": 1279.6098039108679,
            "rating_q025": 1243.6933750014819
        },
        "command-r": {
            "rating": 1261.5596020513658,
            "rating_q975": 1275.09913387702,
            "rating_q025": 1248.0200702257116
        },
        "qwen1.5-110b-chat": {
            "rating": 1260.0767386430475,
            "rating_q975": 1276.765460708113,
            "rating_q025": 1243.388016577982
        },
        "qwen1.5-72b-chat": {
            "rating": 1258.6315121506614,
            "rating_q975": 1272.6463074084731,
            "rating_q025": 1244.6167168928496
        },
        "mistral-medium": {
            "rating": 1256.6944752644195,
            "rating_q975": 1272.2026170899126,
            "rating_q025": 1241.1863334389263
        },
        "olmo-2-0325-32b-instruct": {
            "rating": 1255.739324412017,
            "rating_q975": 1301.4057032375663,
            "rating_q025": 1210.0729455864675
        },
        "mixtral-8x22b-instruct-v0.1": {
            "rating": 1253.8944790428138,
            "rating_q975": 1267.041246586413,
            "rating_q025": 1240.7477114992146
        },
        "gemini-pro": {
            "rating": 1251.5381691455186,
            "rating_q975": 1290.8025692036201,
            "rating_q025": 1212.2737690874171
        },
        "llama-3-8b-instruct": {
            "rating": 1248.6764630882008,
            "rating_q975": 1259.8385809865806,
            "rating_q025": 1237.514345189821
        },
        "gpt-3.5-turbo-0125": {
            "rating": 1248.2369435359474,
            "rating_q975": 1260.1977128419746,
            "rating_q025": 1236.2761742299201
        },
        "zephyr-orpo-141b-A35b-v0.1": {
            "rating": 1244.4395596847346,
            "rating_q975": 1279.660059127269,
            "rating_q025": 1209.2190602422002
        },
        "yi-1.5-34b-chat": {
            "rating": 1236.740249657816,
            "rating_q975": 1253.7550398757082,
            "rating_q025": 1219.725459439924
        },
        "llama-3.1-8b-instruct": {
            "rating": 1236.5748872477293,
            "rating_q975": 1249.016013423471,
            "rating_q025": 1224.1337610719877
        },
        "phi-3-medium-4k-instruct": {
            "rating": 1232.7469177725334,
            "rating_q975": 1249.5514845809637,
            "rating_q025": 1215.942350964103
        },
        "qwen1.5-32b-chat": {
            "rating": 1228.2669791622247,
            "rating_q975": 1246.1700996616557,
            "rating_q025": 1210.3638586627937
        },
        "starling-lm-7b-alpha": {
            "rating": 1226.5310009901195,
            "rating_q975": 1251.7646756490535,
            "rating_q025": 1201.2973263311856
        },
        "deepseek-llm-67b-chat": {
            "rating": 1226.302339437958,
            "rating_q975": 1254.9653438181142,
            "rating_q025": 1197.6393350578016
        },
        "gemma-1.1-7b-it": {
            "rating": 1226.1672269245478,
            "rating_q975": 1244.3972104528636,
            "rating_q025": 1207.937243396232
        },
        "mixtral-8x7b-instruct-v0.1": {
            "rating": 1225.072542985119,
            "rating_q975": 1237.009679446362,
            "rating_q025": 1213.135406523876
        },
        "qwen1.5-14b-chat": {
            "rating": 1223.2502600333567,
            "rating_q975": 1243.2743269541,
            "rating_q025": 1203.2261931126134
        },
        "openchat-3.5": {
            "rating": 1221.6369806758626,
            "rating_q975": 1251.6646730273717,
            "rating_q025": 1191.6092883243534
        },
        "gemma-2-2b-it": {
            "rating": 1221.4117021058505,
            "rating_q975": 1234.6898768835147,
            "rating_q025": 1208.1335273281863
        },
        "dbrx-instruct-preview": {
            "rating": 1219.1505696354238,
            "rating_q975": 1236.4584093232095,
            "rating_q025": 1201.8427299476382
        },
        "internlm2_5-20b-chat": {
            "rating": 1217.6504423931615,
            "rating_q975": 1243.1214558866193,
            "rating_q025": 1192.1794288997037
        },
        "llama-3.2-3b-instruct": {
            "rating": 1216.6314001984413,
            "rating_q975": 1247.2547249729905,
            "rating_q025": 1186.008075423892
        },
        "starling-lm-7b-beta": {
            "rating": 1215.1060724484978,
            "rating_q975": 1236.6385959812708,
            "rating_q025": 1193.5735489157248
        },
        "phi-3-small-8k-instruct": {
            "rating": 1215.090334168326,
            "rating_q975": 1234.2001087958884,
            "rating_q025": 1195.9805595407638
        },
        "yi-34b-chat": {
            "rating": 1213.1989943209983,
            "rating_q975": 1234.7052180093015,
            "rating_q025": 1191.692770632695
        },
        "wizardlm-70b": {
            "rating": 1212.8892903593314,
            "rating_q975": 1243.0459003111807,
            "rating_q025": 1182.7326804074821
        },
        "granite-3.0-8b-instruct": {
            "rating": 1212.5670817645225,
            "rating_q975": 1248.2602568935458,
            "rating_q025": 1176.8739066354992
        },
        "snowflake-arctic-instruct": {
            "rating": 1211.0296246029695,
            "rating_q975": 1229.4618008144919,
            "rating_q025": 1192.5974483914472
        },
        "openchat-3.5-0106": {
            "rating": 1210.4378620089924,
            "rating_q975": 1231.5656303344672,
            "rating_q025": 1189.3100936835176
        },
        "openhermes-2.5-mistral-7b": {
            "rating": 1208.5463910963065,
            "rating_q975": 1243.4907515436403,
            "rating_q025": 1173.6020306489727
        },
        "gpt-3.5-turbo-1106": {
            "rating": 1201.0875880082149,
            "rating_q975": 1222.6530132736923,
            "rating_q025": 1179.5221627427375
        },
        "solar-10.7b-instruct-v1.0": {
            "rating": 1196.810050315035,
            "rating_q975": 1237.5099913629883,
            "rating_q025": 1156.1101092670815
        },
        "llama-2-70b-chat": {
            "rating": 1194.0835525462985,
            "rating_q975": 1208.9091797693497,
            "rating_q025": 1179.2579253232473
        },
        "mistral-7b-instruct-v0.2": {
            "rating": 1192.7223949483569,
            "rating_q975": 1210.9403024332469,
            "rating_q025": 1174.5044874634668
        },
        "vicuna-33b": {
            "rating": 1190.2504372267927,
            "rating_q975": 1209.0232956514872,
            "rating_q025": 1171.4775788020982
        },
        "wizardlm-13b": {
            "rating": 1188.2790198076705,
            "rating_q975": 1223.189237016894,
            "rating_q025": 1153.368802598447
        },
        "tulu-2-dpo-70b": {
            "rating": 1185.5250814635951,
            "rating_q975": 1216.6124171611352,
            "rating_q025": 1154.437745766055
        },
        "qwen1.5-7b-chat": {
            "rating": 1179.596785498344,
            "rating_q975": 1215.448146966119,
            "rating_q025": 1143.7454240305688
        },
        "llama-2-13b-chat": {
            "rating": 1179.0046548517466,
            "rating_q975": 1199.454667334063,
            "rating_q025": 1158.5546423694302
        },
        "qwen-14b-chat": {
            "rating": 1177.010115846007,
            "rating_q975": 1214.1833388133027,
            "rating_q025": 1139.8368928787113
        },
        "vicuna-13b": {
            "rating": 1175.684856544195,
            "rating_q975": 1197.5786115184658,
            "rating_q025": 1153.7911015699244
        },
        "gemma-7b-it": {
            "rating": 1171.454243720289,
            "rating_q975": 1197.0837872583502,
            "rating_q025": 1145.8247001822278
        },
        "palm-2": {
            "rating": 1169.3751494966953,
            "rating_q975": 1206.715332186572,
            "rating_q025": 1132.0349668068186
        },
        "zephyr-7b-beta": {
            "rating": 1165.048188117283,
            "rating_q975": 1190.9520984201424,
            "rating_q025": 1139.1442778144235
        },
        "nous-hermes-2-mixtral-8x7b-dpo": {
            "rating": 1163.8523570019554,
            "rating_q975": 1195.881212460138,
            "rating_q025": 1131.8235015437729
        },
        "phi-3-mini-4k-instruct-june-2024": {
            "rating": 1161.911942076932,
            "rating_q975": 1187.39301551648,
            "rating_q025": 1136.430868637384
        },
        "mistral-7b-instruct": {
            "rating": 1158.5379573019013,
            "rating_q975": 1186.052481576283,
            "rating_q025": 1131.0234330275196
        },
        "gemma-1.1-2b-it": {
            "rating": 1156.5696181637823,
            "rating_q975": 1183.1170363096367,
            "rating_q025": 1130.0222000179278
        },
        "codellama-34b-instruct": {
            "rating": 1155.860349409553,
            "rating_q975": 1187.0455727443916,
            "rating_q025": 1124.6751260747144
        },
        "vicuna-7b": {
            "rating": 1152.0048002985168,
            "rating_q975": 1187.1529240284633,
            "rating_q025": 1116.8566765685703
        },
        "granite-3.0-2b-instruct": {
            "rating": 1147.9463997695243,
            "rating_q975": 1185.2062557276565,
            "rating_q025": 1110.686543811392
        },
        "phi-3-mini-128k-instruct": {
            "rating": 1146.0079920633393,
            "rating_q975": 1167.7067627540878,
            "rating_q025": 1124.3092213725909
        },
        "phi-3-mini-4k-instruct": {
            "rating": 1145.130991629652,
            "rating_q975": 1165.304743022599,
            "rating_q025": 1124.957240236705
        },
        "stripedhyena-nous-7b": {
            "rating": 1143.318257199093,
            "rating_q975": 1174.2518291545625,
            "rating_q025": 1112.3846852436236
        },
        "llama-2-7b-chat": {
            "rating": 1138.9636692321426,
            "rating_q975": 1161.584058735628,
            "rating_q025": 1116.343279728657
        },
        "olmo-7b-instruct": {
            "rating": 1134.5895691850649,
            "rating_q975": 1166.618372538869,
            "rating_q025": 1102.5607658312608
        },
        "qwen1.5-4b-chat": {
            "rating": 1125.8574851346614,
            "rating_q975": 1156.2627891587963,
            "rating_q025": 1095.4521811105265
        },
        "RWKV-4-Raven-14B": {
            "rating": 1116.7956555391197,
            "rating_q975": 1166.2358531096495,
            "rating_q025": 1067.35545796859
        },
        "llama-3.2-1b-instruct": {
            "rating": 1110.798320777796,
            "rating_q975": 1143.1278320340364,
            "rating_q025": 1078.4688095215558
        },
        "koala-13b": {
            "rating": 1106.875905330796,
            "rating_q975": 1149.2902518296353,
            "rating_q025": 1064.4615588319568
        },
        "gemma-2b-it": {
            "rating": 1106.0911014107412,
            "rating_q975": 1144.8135670991392,
            "rating_q025": 1067.3686357223432
        },
        "alpaca-13b": {
            "rating": 1061.2449128030967,
            "rating_q975": 1111.1073691111492,
            "rating_q025": 1011.3824564950442
        },
        "chatglm3-6b": {
            "rating": 1053.210229396856,
            "rating_q975": 1095.1686360140116,
            "rating_q025": 1011.2518227797004
        },
        "oasst-pythia-12b": {
            "rating": 1001.5437791887957,
            "rating_q975": 1051.0081184311919,
            "rating_q025": 952.0794399463996
        },
        "chatglm-6b": {
            "rating": 958.9600512583849,
            "rating_q975": 1012.1929273764831,
            "rating_q025": 905.7271751402866
        }
    },
    "industry_software_and_it_services": {
        "claude-opus-4-5-20251101-thinking-32k": {
            "rating": 1514.2309445551261,
            "rating_q975": 1525.0675315782905,
            "rating_q025": 1503.3943575319618
        },
        "gemini-3-pro": {
            "rating": 1513.133907601227,
            "rating_q975": 1522.3522382335848,
            "rating_q025": 1503.9155769688693
        },
        "claude-opus-4-5-20251101": {
            "rating": 1507.7507030498266,
            "rating_q975": 1518.4879978026736,
            "rating_q025": 1497.0134082969796
        },
        "grok-4.1-thinking": {
            "rating": 1505.5426383997008,
            "rating_q975": 1514.6308667223552,
            "rating_q025": 1496.4544100770463
        },
        "claude-sonnet-4-5-20250929-thinking-32k": {
            "rating": 1498.9819889559033,
            "rating_q975": 1505.7680510266423,
            "rating_q025": 1492.1959268851642
        },
        "claude-opus-4-1-20250805-thinking-16k": {
            "rating": 1492.2476835285224,
            "rating_q975": 1497.9690812604676,
            "rating_q025": 1486.5262857965772
        },
        "claude-sonnet-4-5-20250929": {
            "rating": 1488.855085084312,
            "rating_q975": 1496.290313211055,
            "rating_q025": 1481.4198569575688
        },
        "grok-4.1": {
            "rating": 1488.222260764871,
            "rating_q975": 1497.1937072803205,
            "rating_q025": 1479.2508142494214
        },
        "claude-opus-4-1-20250805": {
            "rating": 1479.3055848209995,
            "rating_q975": 1484.7583033500512,
            "rating_q025": 1473.8528662919477
        },
        "gpt-5.1-high": {
            "rating": 1471.6254212035499,
            "rating_q975": 1481.3414479616486,
            "rating_q025": 1461.9093944454512
        },
        "qwen3-max-preview": {
            "rating": 1469.2685774347158,
            "rating_q975": 1476.0435936922,
            "rating_q025": 1462.4935611772316
        },
        "ernie-5.0-preview-1103": {
            "rating": 1467.4537039135532,
            "rating_q975": 1480.896624910814,
            "rating_q025": 1454.0107829162926
        },
        "claude-opus-4-20250514-thinking-16k": {
            "rating": 1465.0144152519513,
            "rating_q975": 1471.2689400578388,
            "rating_q025": 1458.7598904460638
        },
        "gpt-5.1": {
            "rating": 1464.6854346230964,
            "rating_q975": 1473.8008675225183,
            "rating_q025": 1455.5700017236745
        },
        "gemini-2.5-pro": {
            "rating": 1463.2569994186067,
            "rating_q975": 1468.265616192281,
            "rating_q025": 1458.2483826449325
        },
        "qwen3-max-2025-09-23": {
            "rating": 1462.706195497711,
            "rating_q975": 1472.7559044787636,
            "rating_q025": 1452.6564865166583
        },
        "kimi-k2-thinking-turbo": {
            "rating": 1462.5541739535247,
            "rating_q975": 1471.3872186011636,
            "rating_q025": 1453.7211293058858
        },
        "chatgpt-4o-latest-20250326": {
            "rating": 1461.4280029687761,
            "rating_q975": 1466.441482644839,
            "rating_q025": 1456.4145232927133
        },
        "qwen3-235b-a22b-instruct-2507": {
            "rating": 1461.3274129283152,
            "rating_q975": 1466.7626399485416,
            "rating_q025": 1455.8921859080888
        },
        "claude-haiku-4-5-20251001": {
            "rating": 1457.0609016559347,
            "rating_q975": 1463.9923891484007,
            "rating_q025": 1450.1294141634687
        },
        "deepseek-v3.2-exp-thinking": {
            "rating": 1456.856290852126,
            "rating_q975": 1467.3141720914402,
            "rating_q025": 1446.3984096128117
        },
        "grok-4-fast-chat": {
            "rating": 1456.7552336903648,
            "rating_q975": 1469.1976750143936,
            "rating_q025": 1444.312792366336
        },
        "gpt-4.5-preview-2025-02-27": {
            "rating": 1456.6290982141038,
            "rating_q975": 1466.7464641055863,
            "rating_q025": 1446.5117323226214
        },
        "deepseek-v3.2-exp": {
            "rating": 1455.322685166507,
            "rating_q975": 1464.980797015897,
            "rating_q025": 1445.664573317117
        },
        "qwen3-vl-235b-a22b-instruct": {
            "rating": 1455.070052464775,
            "rating_q975": 1465.4652781688612,
            "rating_q025": 1444.6748267606888
        },
        "deepseek-r1-0528": {
            "rating": 1454.8940683262426,
            "rating_q975": 1463.1985275614295,
            "rating_q025": 1446.5896090910558
        },
        "kimi-k2-0905-preview": {
            "rating": 1454.5538912110162,
            "rating_q975": 1464.329669216025,
            "rating_q025": 1444.7781132060074
        },
        "gpt-5-high": {
            "rating": 1454.301331637906,
            "rating_q975": 1460.9517950894826,
            "rating_q025": 1447.6508681863295
        },
        "kimi-k2-0711-preview": {
            "rating": 1453.708555721686,
            "rating_q975": 1460.6134026518164,
            "rating_q025": 1446.8037087915557
        },
        "glm-4.6": {
            "rating": 1453.4546252972946,
            "rating_q975": 1460.4777092943011,
            "rating_q025": 1446.431541300288
        },
        "mistral-large-3": {
            "rating": 1453.3711911420505,
            "rating_q975": 1465.8899706824225,
            "rating_q025": 1440.8524116016786
        },
        "o3-2025-04-16": {
            "rating": 1452.9046461360515,
            "rating_q975": 1458.2327085441827,
            "rating_q025": 1447.5765837279203
        },
        "grok-4-1-fast-reasoning": {
            "rating": 1452.4995275798346,
            "rating_q975": 1463.2742263946104,
            "rating_q025": 1441.7248287650589
        },
        "longcat-flash-chat": {
            "rating": 1452.0370130188312,
            "rating_q975": 1461.6832922149833,
            "rating_q025": 1442.390733822679
        },
        "gpt-5-chat": {
            "rating": 1451.5567187433066,
            "rating_q975": 1457.9096340493243,
            "rating_q025": 1445.203803437289
        },
        "deepseek-v3.2": {
            "rating": 1447.9990994440413,
            "rating_q975": 1460.4734387841922,
            "rating_q025": 1435.5247601038905
        },
        "deepseek-v3.1-thinking": {
            "rating": 1446.9231071702784,
            "rating_q975": 1456.9499714356052,
            "rating_q025": 1436.8962429049516
        },
        "deepseek-v3.2-thinking": {
            "rating": 1446.3351511928208,
            "rating_q975": 1459.7055421319799,
            "rating_q025": 1432.9647602536618
        },
        "glm-4.5": {
            "rating": 1443.0984714039785,
            "rating_q975": 1450.2175799101765,
            "rating_q025": 1435.9793628977804
        },
        "deepseek-v3.1": {
            "rating": 1442.771629462297,
            "rating_q975": 1451.671801912039,
            "rating_q025": 1433.8714570125549
        },
        "claude-sonnet-4-20250514-thinking-32k": {
            "rating": 1442.4345039018835,
            "rating_q975": 1448.6702352429613,
            "rating_q025": 1436.1987725608058
        },
        "qwen3-next-80b-a3b-instruct": {
            "rating": 1442.2314651847234,
            "rating_q975": 1449.355272836756,
            "rating_q025": 1435.1076575326908
        },
        "mistral-medium-2508": {
            "rating": 1442.0766786564968,
            "rating_q975": 1447.788916167195,
            "rating_q025": 1436.3644411457985
        },
        "deepseek-v3.1-terminus-thinking": {
            "rating": 1441.6677451612,
            "rating_q975": 1458.902858526326,
            "rating_q025": 1424.4326317960738
        },
        "gpt-4.1-2025-04-14": {
            "rating": 1441.0174264157272,
            "rating_q975": 1446.4697325333718,
            "rating_q025": 1435.5651202980825
        },
        "claude-opus-4-20250514": {
            "rating": 1440.411201389929,
            "rating_q975": 1446.3796093278647,
            "rating_q025": 1434.442793451993
        },
        "qwen3-235b-a22b-no-thinking": {
            "rating": 1436.442371516064,
            "rating_q975": 1442.6323003728705,
            "rating_q025": 1430.2524426592574
        },
        "qwen3-vl-235b-a22b-thinking": {
            "rating": 1435.450634372384,
            "rating_q975": 1446.3531107195208,
            "rating_q025": 1424.5481580252472
        },
        "qwen3-coder-480b-a35b-instruct": {
            "rating": 1433.0056083713143,
            "rating_q975": 1440.3065223243193,
            "rating_q025": 1425.7046944183094
        },
        "grok-3-preview-02-24": {
            "rating": 1431.601172166739,
            "rating_q975": 1438.3198607142922,
            "rating_q025": 1424.8824836191857
        },
        "qwen3-235b-a22b-thinking-2507": {
            "rating": 1430.0620079959735,
            "rating_q975": 1440.8368507026646,
            "rating_q025": 1419.2871652892825
        },
        "deepseek-r1": {
            "rating": 1428.9717138308986,
            "rating_q975": 1438.1208979523167,
            "rating_q025": 1419.8225297094805
        },
        "deepseek-v3.1-terminus": {
            "rating": 1428.7310090353003,
            "rating_q975": 1444.7912234351932,
            "rating_q025": 1412.6707946354074
        },
        "qwen3-30b-a3b-instruct-2507": {
            "rating": 1427.9257963768114,
            "rating_q975": 1435.0879771973819,
            "rating_q025": 1420.763615556241
        },
        "claude-sonnet-4-20250514": {
            "rating": 1426.5662403072295,
            "rating_q975": 1432.62415068026,
            "rating_q025": 1420.5083299341989
        },
        "hunyuan-vision-1.5-thinking": {
            "rating": 1426.2608678135805,
            "rating_q975": 1446.9501330863784,
            "rating_q025": 1405.5716025407826
        },
        "grok-4-fast-reasoning": {
            "rating": 1423.712782023518,
            "rating_q975": 1431.2969170146932,
            "rating_q025": 1416.1286470323428
        },
        "grok-4-0709": {
            "rating": 1422.1276373897476,
            "rating_q975": 1427.8303279367146,
            "rating_q025": 1416.4249468427806
        },
        "o1-2024-12-17": {
            "rating": 1421.5260272713085,
            "rating_q975": 1429.0859455977209,
            "rating_q025": 1413.9661089448962
        },
        "deepseek-v3-0324": {
            "rating": 1421.0789509269553,
            "rating_q975": 1426.777105357841,
            "rating_q025": 1415.3807964960695
        },
        "o4-mini-2025-04-16": {
            "rating": 1420.6840772886976,
            "rating_q975": 1426.4180537389127,
            "rating_q025": 1414.9501008384825
        },
        "gemini-2.5-flash-preview-09-2025": {
            "rating": 1420.1639890477923,
            "rating_q975": 1426.747103186679,
            "rating_q025": 1413.5808749089056
        },
        "gemini-2.5-flash": {
            "rating": 1419.3590445639154,
            "rating_q975": 1424.3048614131728,
            "rating_q025": 1414.413227714658
        },
        "mistral-medium-2505": {
            "rating": 1418.7294942232074,
            "rating_q975": 1425.2589280436634,
            "rating_q025": 1412.2000604027514
        },
        "mai-1-preview": {
            "rating": 1418.6332934850502,
            "rating_q975": 1426.7229141016974,
            "rating_q025": 1410.543672868403
        },
        "gpt-4.1-mini-2025-04-14": {
            "rating": 1417.9548197257204,
            "rating_q975": 1424.0606443991237,
            "rating_q025": 1411.8489950523172
        },
        "claude-3-7-sonnet-20250219-thinking-32k": {
            "rating": 1416.8320343644775,
            "rating_q975": 1423.1414402429687,
            "rating_q025": 1410.5226284859864
        },
        "gpt-5-mini-high": {
            "rating": 1415.0862867538178,
            "rating_q975": 1422.1906274234884,
            "rating_q025": 1407.9819460841472
        },
        "qwen3-235b-a22b": {
            "rating": 1414.9975784121411,
            "rating_q975": 1422.01526813358,
            "rating_q025": 1407.9798886907022
        },
        "glm-4.5-air": {
            "rating": 1413.0483700242462,
            "rating_q975": 1419.3459713624788,
            "rating_q025": 1406.7507686860135
        },
        "hunyuan-turbos-20250416": {
            "rating": 1411.7277883805505,
            "rating_q975": 1422.3727038913842,
            "rating_q025": 1401.0828728697168
        },
        "qwen3-next-80b-a3b-thinking": {
            "rating": 1409.947890513953,
            "rating_q975": 1418.653861262447,
            "rating_q025": 1401.2419197654592
        },
        "o3-mini-high": {
            "rating": 1408.9862000471926,
            "rating_q975": 1418.144264011477,
            "rating_q025": 1399.8281360829083
        },
        "claude-3-5-sonnet-20241022": {
            "rating": 1406.6090170258854,
            "rating_q975": 1411.0913495391587,
            "rating_q025": 1402.126684512612
        },
        "hunyuan-t1-20250711": {
            "rating": 1406.3733043209977,
            "rating_q975": 1420.984791872811,
            "rating_q025": 1391.7618167691844
        },
        "o1-preview": {
            "rating": 1405.8225271128156,
            "rating_q975": 1413.5621705953047,
            "rating_q025": 1398.0828836303265
        },
        "claude-3-7-sonnet-20250219": {
            "rating": 1405.3066513790145,
            "rating_q975": 1411.275159332376,
            "rating_q025": 1399.338143425653
        },
        "ling-flash-2.0": {
            "rating": 1405.1455205852935,
            "rating_q975": 1416.7155500356675,
            "rating_q025": 1393.5754911349195
        },
        "intellect-3": {
            "rating": 1404.6557671841563,
            "rating_q975": 1425.7524144214683,
            "rating_q025": 1383.5591199468442
        },
        "minimax-m1": {
            "rating": 1403.7154224599415,
            "rating_q975": 1409.876960687068,
            "rating_q025": 1397.5538842328149
        },
        "mistral-small-2506": {
            "rating": 1398.5994430245823,
            "rating_q975": 1406.293700233435,
            "rating_q025": 1390.9051858157297
        },
        "gemini-2.5-flash-lite-preview-09-2025-no-thinking": {
            "rating": 1397.0353805209622,
            "rating_q975": 1403.6128277534524,
            "rating_q025": 1390.457933288472
        },
        "qwen3-32b": {
            "rating": 1396.8233516998368,
            "rating_q975": 1416.2606291999316,
            "rating_q025": 1377.386074199742
        },
        "glm-4.5v": {
            "rating": 1395.8479390199532,
            "rating_q975": 1409.7867527745134,
            "rating_q025": 1381.909125265393
        },
        "amazon-nova-experimental-chat-10-20": {
            "rating": 1395.0273241028103,
            "rating_q975": 1406.3618655732332,
            "rating_q025": 1383.6927826323874
        },
        "qwen2.5-max": {
            "rating": 1394.7848788769136,
            "rating_q975": 1401.3330115546228,
            "rating_q025": 1388.2367461992044
        },
        "hunyuan-turbos-20250226": {
            "rating": 1394.6031290635378,
            "rating_q975": 1419.528870445673,
            "rating_q025": 1369.6773876814027
        },
        "o3-mini": {
            "rating": 1388.5470467761227,
            "rating_q975": 1393.7540982593425,
            "rating_q025": 1383.3399952929028
        },
        "step-3": {
            "rating": 1387.9185965102472,
            "rating_q975": 1400.4991306839884,
            "rating_q025": 1375.338062336506
        },
        "llama-3.1-nemotron-ultra-253b-v1": {
            "rating": 1386.3536462063526,
            "rating_q975": 1410.1003674608341,
            "rating_q025": 1362.606924951871
        },
        "nova-2-lite": {
            "rating": 1386.3178386693928,
            "rating_q975": 1399.4057758662245,
            "rating_q025": 1373.229901472561
        },
        "amazon-nova-experimental-chat-10-09": {
            "rating": 1386.2671689975502,
            "rating_q975": 1396.455146618163,
            "rating_q025": 1376.0791913769374
        },
        "gemini-2.5-flash-lite-preview-06-17-thinking": {
            "rating": 1386.1571661112007,
            "rating_q975": 1392.6442786949206,
            "rating_q025": 1379.6700535274808
        },
        "gpt-oss-120b": {
            "rating": 1383.4077721730434,
            "rating_q975": 1389.917820321024,
            "rating_q025": 1376.8977240250629
        },
        "deepseek-v3": {
            "rating": 1382.640148705484,
            "rating_q975": 1390.945912415243,
            "rating_q025": 1374.3343849957253
        },
        "nvidia-llama-3.3-nemotron-super-49b-v1.5": {
            "rating": 1381.19904542321,
            "rating_q975": 1397.717984374635,
            "rating_q025": 1364.680106471785
        },
        "minimax-m2": {
            "rating": 1380.9373521939056,
            "rating_q975": 1392.9457668863847,
            "rating_q025": 1368.9289375014264
        },
        "command-a-03-2025": {
            "rating": 1378.92805894612,
            "rating_q975": 1384.068077610781,
            "rating_q025": 1373.788040281459
        },
        "qwen-plus-0125": {
            "rating": 1378.2845448275298,
            "rating_q975": 1393.3689671921059,
            "rating_q025": 1363.2001224629537
        },
        "gemma-3-27b-it": {
            "rating": 1377.6083913944065,
            "rating_q975": 1383.1966395814716,
            "rating_q025": 1372.0201432073413
        },
        "grok-3-mini-high": {
            "rating": 1377.2821501877806,
            "rating_q975": 1385.2136662366158,
            "rating_q025": 1369.3506341389455
        },
        "grok-3-mini-beta": {
            "rating": 1376.6205787800318,
            "rating_q975": 1383.8679813949593,
            "rating_q025": 1369.3731761651043
        },
        "qwq-32b": {
            "rating": 1376.421956449055,
            "rating_q975": 1383.4340787286694,
            "rating_q025": 1369.4098341694405
        },
        "ring-flash-2.0": {
            "rating": 1374.3503332108844,
            "rating_q975": 1385.8769563211013,
            "rating_q025": 1362.8237101006675
        },
        "o1-mini": {
            "rating": 1373.0865604960431,
            "rating_q975": 1379.1701163250698,
            "rating_q025": 1367.0030046670165
        },
        "claude-3-5-sonnet-20240620": {
            "rating": 1372.4734159605,
            "rating_q975": 1378.2444097511293,
            "rating_q025": 1366.7024221698707
        },
        "hunyuan-turbo-0110": {
            "rating": 1372.3402445231347,
            "rating_q975": 1395.686167034174,
            "rating_q025": 1348.9943220120954
        },
        "qwen3-30b-a3b": {
            "rating": 1370.4322717035207,
            "rating_q975": 1377.3695011234609,
            "rating_q025": 1363.4950422835805
        },
        "gpt-5-nano-high": {
            "rating": 1370.4090086148576,
            "rating_q975": 1381.649495027259,
            "rating_q025": 1359.1685222024562
        },
        "gemini-2.0-flash-001": {
            "rating": 1369.5314048020468,
            "rating_q975": 1375.4119023317278,
            "rating_q025": 1363.6509072723659
        },
        "claude-3-5-haiku-20241022": {
            "rating": 1364.0240864603475,
            "rating_q975": 1368.9464497345305,
            "rating_q025": 1359.1017231861645
        },
        "deepseek-v2.5-1210": {
            "rating": 1362.9132163416707,
            "rating_q975": 1377.0621435049486,
            "rating_q025": 1348.7642891783928
        },
        "llama-3.1-405b-instruct-bf16": {
            "rating": 1362.2839675814876,
            "rating_q975": 1368.362127756359,
            "rating_q025": 1356.205807406616
        },
        "olmo-3-32b-think": {
            "rating": 1361.2425814461603,
            "rating_q975": 1378.8351440006695,
            "rating_q025": 1343.6500188916511
        },
        "gpt-4.1-nano-2025-04-14": {
            "rating": 1360.6198765669192,
            "rating_q975": 1375.4603984149458,
            "rating_q025": 1345.7793547188926
        },
        "gpt-oss-20b": {
            "rating": 1360.3260784661838,
            "rating_q975": 1370.3199963775687,
            "rating_q025": 1350.332160554799
        },
        "gpt-4o-2024-05-13": {
            "rating": 1358.393923111782,
            "rating_q975": 1363.7815057145444,
            "rating_q025": 1353.0063405090195
        },
        "llama-4-maverick-17b-128e-instruct": {
            "rating": 1358.3575592679829,
            "rating_q975": 1364.5151607045495,
            "rating_q025": 1352.1999578314162
        },
        "yi-lightning": {
            "rating": 1358.024480288675,
            "rating_q975": 1366.1535728393794,
            "rating_q025": 1349.8953877379706
        },
        "hunyuan-large-2025-02-10": {
            "rating": 1355.3873690610046,
            "rating_q975": 1375.1711932550193,
            "rating_q025": 1335.60354486699
        },
        "gemini-1.5-pro-002": {
            "rating": 1354.802634332314,
            "rating_q975": 1360.4664431155222,
            "rating_q025": 1349.1388255491058
        },
        "gemini-2.0-flash-lite-preview-02-05": {
            "rating": 1353.80973504749,
            "rating_q975": 1361.6415665836607,
            "rating_q025": 1345.9779035113193
        },
        "llama-3.1-405b-instruct-fp8": {
            "rating": 1353.4433181156637,
            "rating_q975": 1359.362865354957,
            "rating_q025": 1347.5237708763705
        },
        "mercury": {
            "rating": 1352.3473395778028,
            "rating_q975": 1374.7640236645216,
            "rating_q025": 1329.930655491084
        },
        "athene-v2-chat": {
            "rating": 1351.6103211740494,
            "rating_q975": 1359.1413625648454,
            "rating_q025": 1344.0792797832535
        },
        "magistral-medium-2506": {
            "rating": 1349.849583750742,
            "rating_q975": 1359.4094738958108,
            "rating_q025": 1340.2896936056734
        },
        "step-2-16k-exp-202412": {
            "rating": 1349.7577625174172,
            "rating_q975": 1365.473972186425,
            "rating_q025": 1334.0415528484093
        },
        "step-1o-turbo-202506": {
            "rating": 1349.633504189731,
            "rating_q975": 1360.6055389212452,
            "rating_q025": 1338.6614694582167
        },
        "llama-4-scout-17b-16e-instruct": {
            "rating": 1349.57705003425,
            "rating_q975": 1356.3794937724645,
            "rating_q025": 1342.7746062960357
        },
        "glm-4-plus-0111": {
            "rating": 1349.2437846753128,
            "rating_q975": 1364.0856638843238,
            "rating_q025": 1334.4019054663017
        },
        "grok-2-2024-08-13": {
            "rating": 1349.1371423057572,
            "rating_q975": 1354.826667305456,
            "rating_q025": 1343.4476173060582
        },
        "deepseek-v2.5": {
            "rating": 1347.864900255486,
            "rating_q975": 1355.7651457826905,
            "rating_q025": 1339.9646547282814
        },
        "llama-3.3-nemotron-49b-super-v1": {
            "rating": 1346.8595934211457,
            "rating_q975": 1371.4411163917,
            "rating_q025": 1322.2780704505915
        },
        "gpt-4o-2024-08-06": {
            "rating": 1345.8601719963413,
            "rating_q975": 1352.4216836040368,
            "rating_q025": 1339.2986603886457
        },
        "mistral-small-3.1-24b-instruct-2503": {
            "rating": 1343.6777268812816,
            "rating_q975": 1350.095950813895,
            "rating_q025": 1337.2595029486683
        },
        "qwen2.5-plus-1127": {
            "rating": 1343.4283775899698,
            "rating_q975": 1354.7738941152672,
            "rating_q025": 1332.0828610646724
        },
        "qwen-max-0919": {
            "rating": 1342.0712652819193,
            "rating_q975": 1351.3856488926476,
            "rating_q025": 1332.756881671191
        },
        "mistral-large-2407": {
            "rating": 1341.9003878706949,
            "rating_q975": 1348.4390104700162,
            "rating_q025": 1335.3617652713735
        },
        "gemini-1.5-pro-001": {
            "rating": 1341.74421381535,
            "rating_q975": 1348.05132773942,
            "rating_q025": 1335.4370998912798
        },
        "qwen2.5-72b-instruct": {
            "rating": 1341.3990533454948,
            "rating_q975": 1347.8407245102453,
            "rating_q025": 1334.9573821807444
        },
        "gemini-advanced-0514": {
            "rating": 1339.8717369332758,
            "rating_q975": 1347.3817358410643,
            "rating_q025": 1332.3617380254873
        },
        "claude-3-opus-20240229": {
            "rating": 1339.4645574377073,
            "rating_q975": 1344.340830830754,
            "rating_q025": 1334.5882840446607
        },
        "glm-4-plus": {
            "rating": 1338.9561550340936,
            "rating_q975": 1346.844519366545,
            "rating_q025": 1331.0677907016423
        },
        "llama-3.3-70b-instruct": {
            "rating": 1338.298580723937,
            "rating_q975": 1343.5224284762758,
            "rating_q025": 1333.0747329715982
        },
        "gpt-4o-mini-2024-07-18": {
            "rating": 1336.486200705623,
            "rating_q975": 1341.8219061136297,
            "rating_q025": 1331.1504952976165
        },
        "gemma-3n-e4b-it": {
            "rating": 1335.593627829347,
            "rating_q975": 1343.3351446690494,
            "rating_q025": 1327.8521109896446
        },
        "gpt-4-turbo-2024-04-09": {
            "rating": 1335.0277253170216,
            "rating_q975": 1341.0111104554794,
            "rating_q025": 1329.0443401785637
        },
        "gemma-3-12b-it": {
            "rating": 1334.3990548197276,
            "rating_q975": 1353.5277823113372,
            "rating_q025": 1315.270327328118
        },
        "hunyuan-standard-2025-02-10": {
            "rating": 1333.1373726654501,
            "rating_q975": 1352.3665171442422,
            "rating_q025": 1313.908228186658
        },
        "mistral-large-2411": {
            "rating": 1332.204828627277,
            "rating_q975": 1339.3851393930838,
            "rating_q025": 1325.0245178614703
        },
        "athene-70b-0725": {
            "rating": 1331.6318685426972,
            "rating_q975": 1340.7455273712337,
            "rating_q025": 1322.5182097141608
        },
        "grok-2-mini-2024-08-13": {
            "rating": 1328.2397373000938,
            "rating_q975": 1334.2334958978654,
            "rating_q025": 1322.2459787023222
        },
        "amazon-nova-pro-v1.0": {
            "rating": 1327.8801534015874,
            "rating_q975": 1335.3224813929007,
            "rating_q025": 1320.4378254102742
        },
        "hunyuan-large-vision": {
            "rating": 1327.1965209864543,
            "rating_q975": 1341.178575077759,
            "rating_q025": 1313.2144668951496
        },
        "deepseek-coder-v2": {
            "rating": 1323.877470168573,
            "rating_q975": 1333.8687302568947,
            "rating_q025": 1313.8862100802512
        },
        "llama-3.1-nemotron-70b-instruct": {
            "rating": 1323.437042246503,
            "rating_q975": 1336.023162293093,
            "rating_q025": 1310.8509221999132
        },
        "gpt-4-1106-preview": {
            "rating": 1323.0029796477556,
            "rating_q975": 1329.1571004517705,
            "rating_q025": 1316.8488588437408
        },
        "gemini-1.5-flash-002": {
            "rating": 1320.5636627098377,
            "rating_q975": 1327.3176213661088,
            "rating_q025": 1313.8097040535665
        },
        "gpt-4-0125-preview": {
            "rating": 1318.7080167067409,
            "rating_q975": 1324.9696886212769,
            "rating_q025": 1312.4463447922049
        },
        "qwen2.5-coder-32b-instruct": {
            "rating": 1318.0656497443294,
            "rating_q975": 1332.940623420417,
            "rating_q025": 1303.1906760682418
        },
        "llama-3.1-70b-instruct": {
            "rating": 1317.722936945937,
            "rating_q975": 1323.660021411845,
            "rating_q025": 1311.7858524800288
        },
        "gemma-2-27b-it": {
            "rating": 1309.5757022249152,
            "rating_q975": 1314.8591061305158,
            "rating_q025": 1304.2922983193146
        },
        "llama-3.1-nemotron-51b-instruct": {
            "rating": 1309.3661191187878,
            "rating_q975": 1327.0666917452058,
            "rating_q025": 1291.6655464923697
        },
        "jamba-1.5-large": {
            "rating": 1308.7405055454406,
            "rating_q975": 1320.8146872496386,
            "rating_q025": 1296.6663238412425
        },
        "claude-3-sonnet-20240229": {
            "rating": 1305.6541029622563,
            "rating_q975": 1311.691142863463,
            "rating_q025": 1299.6170630610495
        },
        "gemini-1.5-flash-001": {
            "rating": 1305.0168807589494,
            "rating_q975": 1311.5321326372612,
            "rating_q025": 1298.5016288806376
        },
        "mistral-small-24b-instruct-2501": {
            "rating": 1304.1604144785704,
            "rating_q975": 1314.0484422100328,
            "rating_q025": 1294.272386747108
        },
        "gpt-4-0314": {
            "rating": 1303.6767730503896,
            "rating_q975": 1311.459205859487,
            "rating_q025": 1295.8943402412922
        },
        "gemma-3-4b-it": {
            "rating": 1300.1094156833228,
            "rating_q975": 1318.7892982254755,
            "rating_q025": 1281.4295331411702
        },
        "reka-core-20240904": {
            "rating": 1299.6826622518097,
            "rating_q975": 1312.2521624586516,
            "rating_q025": 1287.1131620449678
        },
        "nemotron-4-340b-instruct": {
            "rating": 1298.5383189023964,
            "rating_q975": 1307.704182075236,
            "rating_q025": 1289.3724557295568
        },
        "llama-3.1-tulu-3-70b": {
            "rating": 1297.3616794512245,
            "rating_q975": 1317.2322201799798,
            "rating_q025": 1277.4911387224693
        },
        "glm-4-0520": {
            "rating": 1294.8184065939065,
            "rating_q975": 1306.3115350229928,
            "rating_q025": 1283.3252781648202
        },
        "amazon-nova-lite-v1.0": {
            "rating": 1294.2024091059698,
            "rating_q975": 1302.7012497623832,
            "rating_q025": 1285.7035684495563
        },
        "c4ai-aya-expanse-32b": {
            "rating": 1289.3882690994997,
            "rating_q975": 1297.0264912765324,
            "rating_q025": 1281.750046922467
        },
        "llama-3-70b-instruct": {
            "rating": 1288.893717360917,
            "rating_q975": 1294.6781625739359,
            "rating_q025": 1283.109272147898
        },
        "phi-4": {
            "rating": 1288.7487209493283,
            "rating_q975": 1296.7583098021885,
            "rating_q025": 1280.7391320964682
        },
        "gpt-4-0613": {
            "rating": 1284.728497854524,
            "rating_q975": 1291.336570710142,
            "rating_q025": 1278.120424998906
        },
        "reka-flash-20240904": {
            "rating": 1284.688420420065,
            "rating_q975": 1297.1618959054179,
            "rating_q025": 1272.2149449347123
        },
        "claude-3-haiku-20240307": {
            "rating": 1284.1142597844619,
            "rating_q975": 1289.9076785517984,
            "rating_q025": 1278.3208410171253
        },
        "gemma-2-9b-it-simpo": {
            "rating": 1281.6184978142296,
            "rating_q975": 1293.555746135489,
            "rating_q025": 1269.6812494929702
        },
        "gemma-2-9b-it": {
            "rating": 1280.2847576688177,
            "rating_q975": 1286.2349524336796,
            "rating_q025": 1274.3345629039559
        },
        "qwen2-72b-instruct": {
            "rating": 1280.1149652307988,
            "rating_q975": 1287.5813786882,
            "rating_q025": 1272.6485517733977
        },
        "hunyuan-standard-256k": {
            "rating": 1275.397260688988,
            "rating_q975": 1296.1886441115767,
            "rating_q025": 1254.6058772663991
        },
        "ministral-8b-2410": {
            "rating": 1275.2067729461437,
            "rating_q975": 1290.8706406916347,
            "rating_q025": 1259.5429052006527
        },
        "gemini-1.5-flash-8b-001": {
            "rating": 1273.174722397941,
            "rating_q975": 1280.0101547826948,
            "rating_q025": 1266.339290013187
        },
        "command-r-plus-08-2024": {
            "rating": 1272.027937717406,
            "rating_q975": 1283.0632662966934,
            "rating_q025": 1260.9926091381187
        },
        "amazon-nova-micro-v1.0": {
            "rating": 1269.912042217462,
            "rating_q975": 1278.522470149722,
            "rating_q025": 1261.3016142852018
        },
        "command-r-plus": {
            "rating": 1269.4826800740448,
            "rating_q975": 1275.9820382481084,
            "rating_q025": 1262.983321899981
        },
        "mistral-large-2402": {
            "rating": 1269.1972454246406,
            "rating_q975": 1276.4043682815359,
            "rating_q025": 1261.9901225677454
        },
        "olmo-2-0325-32b-instruct": {
            "rating": 1268.3205875066947,
            "rating_q975": 1289.6526460756763,
            "rating_q025": 1246.988528937713
        },
        "command-r-08-2024": {
            "rating": 1266.7899523824794,
            "rating_q975": 1277.827993690529,
            "rating_q025": 1255.75191107443
        },
        "jamba-1.5-mini": {
            "rating": 1263.0602542114907,
            "rating_q975": 1275.5105820713009,
            "rating_q025": 1250.6099263516805
        },
        "reka-flash-21b-20240226-online": {
            "rating": 1262.5830158074468,
            "rating_q975": 1273.4437248374581,
            "rating_q025": 1251.7223067774355
        },
        "qwen1.5-110b-chat": {
            "rating": 1258.3703160902608,
            "rating_q975": 1267.2128689648664,
            "rating_q025": 1249.527763215655
        },
        "qwen1.5-72b-chat": {
            "rating": 1255.886551641062,
            "rating_q975": 1264.0810882919109,
            "rating_q025": 1247.692014990213
        },
        "mixtral-8x22b-instruct-v0.1": {
            "rating": 1253.4401503651534,
            "rating_q975": 1260.7028874148175,
            "rating_q025": 1246.1774133154893
        },
        "reka-flash-21b-20240226": {
            "rating": 1252.100623991695,
            "rating_q975": 1261.1135432932745,
            "rating_q025": 1243.0877046901157
        },
        "c4ai-aya-expanse-8b": {
            "rating": 1250.0543383963372,
            "rating_q975": 1261.9190586763327,
            "rating_q025": 1238.1896181163418
        },
        "granite-3.1-8b-instruct": {
            "rating": 1249.9476868452532,
            "rating_q975": 1270.5877650995997,
            "rating_q025": 1229.3076085909067
        },
        "gemini-pro-dev-api": {
            "rating": 1246.5472887979595,
            "rating_q975": 1258.1209964461698,
            "rating_q025": 1234.9735811497492
        },
        "gpt-3.5-turbo-0125": {
            "rating": 1244.7349979633254,
            "rating_q975": 1251.6903803693922,
            "rating_q025": 1237.7796155572587
        },
        "llama-3.1-8b-instruct": {
            "rating": 1243.3962300802987,
            "rating_q975": 1249.8024962763075,
            "rating_q025": 1236.9899638842899
        },
        "llama-3.1-tulu-3-8b": {
            "rating": 1242.6410110542615,
            "rating_q975": 1262.6967359210225,
            "rating_q025": 1222.5852861875005
        },
        "llama-3-8b-instruct": {
            "rating": 1242.313389634902,
            "rating_q975": 1248.6951242211424,
            "rating_q025": 1235.9316550486617
        },
        "mistral-medium": {
            "rating": 1241.600123955171,
            "rating_q975": 1250.479013831777,
            "rating_q025": 1232.7212340785652
        },
        "qwen1.5-32b-chat": {
            "rating": 1240.9517875239717,
            "rating_q975": 1250.3335241307732,
            "rating_q025": 1231.5700509171702
        },
        "command-r": {
            "rating": 1238.7240372253739,
            "rating_q975": 1246.088880589795,
            "rating_q025": 1231.3591938609527
        },
        "yi-1.5-34b-chat": {
            "rating": 1236.3988618625206,
            "rating_q975": 1245.0236980799434,
            "rating_q025": 1227.7740256450977
        },
        "zephyr-orpo-141b-A35b-v0.1": {
            "rating": 1233.9243587126548,
            "rating_q975": 1250.6914265881487,
            "rating_q025": 1217.1572908371609
        },
        "internlm2_5-20b-chat": {
            "rating": 1232.8667593351315,
            "rating_q975": 1244.6776037071327,
            "rating_q025": 1221.0559149631304
        },
        "qwen1.5-14b-chat": {
            "rating": 1230.055431821745,
            "rating_q975": 1240.8828353834592,
            "rating_q025": 1219.228028260031
        },
        "gpt-3.5-turbo-1106": {
            "rating": 1227.1594901103454,
            "rating_q975": 1240.2993232828758,
            "rating_q025": 1214.019656937815
        },
        "gemini-pro": {
            "rating": 1226.754746553344,
            "rating_q975": 1245.8394160102528,
            "rating_q025": 1207.670077096435
        },
        "mixtral-8x7b-instruct-v0.1": {
            "rating": 1223.9738846022842,
            "rating_q975": 1230.8162847130168,
            "rating_q025": 1217.1314844915516
        },
        "dbrx-instruct-preview": {
            "rating": 1223.6361955616885,
            "rating_q975": 1232.895871370324,
            "rating_q025": 1214.3765197530531
        },
        "granite-3.1-2b-instruct": {
            "rating": 1222.9828551461105,
            "rating_q975": 1243.2799045828474,
            "rating_q025": 1202.6858057093737
        },
        "phi-3-medium-4k-instruct": {
            "rating": 1220.0451860528751,
            "rating_q975": 1228.4722305018283,
            "rating_q025": 1211.618141603922
        },
        "granite-3.0-8b-instruct": {
            "rating": 1218.4241075155385,
            "rating_q975": 1233.2323327135098,
            "rating_q025": 1203.6158823175672
        },
        "starling-lm-7b-beta": {
            "rating": 1216.2560613767732,
            "rating_q975": 1227.2460561690366,
            "rating_q025": 1205.2660665845099
        },
        "gemma-1.1-7b-it": {
            "rating": 1213.147518468661,
            "rating_q975": 1221.858074897036,
            "rating_q025": 1204.436962040286
        },
        "openchat-3.5-0106": {
            "rating": 1209.8007672750118,
            "rating_q975": 1221.551269897261,
            "rating_q025": 1198.0502646527627
        },
        "deepseek-llm-67b-chat": {
            "rating": 1204.899337526952,
            "rating_q975": 1223.5333163036696,
            "rating_q025": 1186.2653587502343
        },
        "snowflake-arctic-instruct": {
            "rating": 1204.8007884562585,
            "rating_q975": 1214.4923337334824,
            "rating_q025": 1195.1092431790346
        },
        "yi-34b-chat": {
            "rating": 1203.539033399542,
            "rating_q975": 1214.2330061518837,
            "rating_q025": 1192.8450606472002
        },
        "gemma-2-2b-it": {
            "rating": 1199.2698373128028,
            "rating_q975": 1205.8667417818122,
            "rating_q025": 1192.6729328437934
        },
        "openchat-3.5": {
            "rating": 1198.9748048211754,
            "rating_q975": 1214.541341063092,
            "rating_q025": 1183.408268579259
        },
        "phi-3-small-8k-instruct": {
            "rating": 1197.441345252759,
            "rating_q975": 1207.2837959250887,
            "rating_q025": 1187.5988945804293
        },
        "tulu-2-dpo-70b": {
            "rating": 1196.1393625853957,
            "rating_q975": 1212.833284472054,
            "rating_q025": 1179.4454406987375
        },
        "vicuna-33b": {
            "rating": 1187.098097399667,
            "rating_q975": 1197.218401713369,
            "rating_q025": 1176.977793085965
        },
        "openhermes-2.5-mistral-7b": {
            "rating": 1186.4470422152579,
            "rating_q975": 1203.94971440111,
            "rating_q025": 1168.9443700294057
        },
        "granite-3.0-2b-instruct": {
            "rating": 1185.5080797296907,
            "rating_q975": 1199.9390719731878,
            "rating_q025": 1171.0770874861937
        },
        "wizardlm-70b": {
            "rating": 1185.3875738204185,
            "rating_q975": 1200.7782980381753,
            "rating_q025": 1169.9968496026618
        },
        "starling-lm-7b-alpha": {
            "rating": 1184.4369402128982,
            "rating_q975": 1197.5371349992604,
            "rating_q025": 1171.336745426536
        },
        "llama-2-70b-chat": {
            "rating": 1181.810621062958,
            "rating_q975": 1190.098556348253,
            "rating_q025": 1173.5226857776631
        },
        "qwen1.5-7b-chat": {
            "rating": 1179.1591556524431,
            "rating_q975": 1195.74301138178,
            "rating_q025": 1162.5752999231063
        },
        "phi-3-mini-4k-instruct-june-2024": {
            "rating": 1178.583072886342,
            "rating_q975": 1189.9438416071105,
            "rating_q025": 1167.2223041655736
        },
        "nous-hermes-2-mixtral-8x7b-dpo": {
            "rating": 1177.9492388253939,
            "rating_q975": 1196.6636067778388,
            "rating_q025": 1159.234870872949
        },
        "mistral-7b-instruct-v0.2": {
            "rating": 1175.352522037134,
            "rating_q975": 1185.3725490604738,
            "rating_q025": 1165.332495013794
        },
        "llama-3.2-3b-instruct": {
            "rating": 1172.69609955956,
            "rating_q975": 1185.914626759074,
            "rating_q025": 1159.477572360046
        },
        "qwen-14b-chat": {
            "rating": 1169.9463588703911,
            "rating_q975": 1188.3202172844508,
            "rating_q025": 1151.5725004563315
        },
        "solar-10.7b-instruct-v1.0": {
            "rating": 1168.3814853201106,
            "rating_q975": 1189.2026566045358,
            "rating_q025": 1147.5603140356855
        },
        "mpt-30b-chat": {
            "rating": 1167.0571420210567,
            "rating_q975": 1191.8839183534856,
            "rating_q025": 1142.230365688628
        },
        "gemma-7b-it": {
            "rating": 1165.3065291768492,
            "rating_q975": 1179.2116800521007,
            "rating_q025": 1151.4013783015976
        },
        "qwq-32b-preview": {
            "rating": 1164.6513979921333,
            "rating_q975": 1185.4392381440045,
            "rating_q025": 1143.863557840262
        },
        "phi-3-mini-4k-instruct": {
            "rating": 1161.9239475037903,
            "rating_q975": 1171.792759215561,
            "rating_q025": 1152.0551357920194
        },
        "codellama-70b-instruct": {
            "rating": 1160.7554855342673,
            "rating_q975": 1192.5726673264776,
            "rating_q025": 1128.938303742057
        },
        "vicuna-13b": {
            "rating": 1160.4086955823236,
            "rating_q975": 1171.1383410197864,
            "rating_q025": 1149.6790501448609
        },
        "codellama-34b-instruct": {
            "rating": 1160.1690971359453,
            "rating_q975": 1175.1860931382987,
            "rating_q025": 1145.152101133592
        },
        "zephyr-7b-alpha": {
            "rating": 1157.1852921396326,
            "rating_q975": 1186.0423566765903,
            "rating_q025": 1128.3282276026748
        },
        "llama2-70b-steerlm-chat": {
            "rating": 1156.2777470688839,
            "rating_q975": 1176.9019675269183,
            "rating_q025": 1135.6535266108494
        },
        "wizardlm-13b": {
            "rating": 1155.8310631308057,
            "rating_q975": 1171.8123274215,
            "rating_q025": 1139.8497988401114
        },
        "gemma-1.1-2b-it": {
            "rating": 1155.8147344607735,
            "rating_q975": 1167.7032290421766,
            "rating_q025": 1143.9262398793703
        },
        "llama-2-13b-chat": {
            "rating": 1154.9714110653283,
            "rating_q975": 1165.283928487551,
            "rating_q025": 1144.6588936431056
        },
        "dolphin-2.2.1-mistral-7b": {
            "rating": 1152.8770307026175,
            "rating_q975": 1181.341240200042,
            "rating_q025": 1124.412821205193
        },
        "falcon-180b-chat": {
            "rating": 1147.8579277050376,
            "rating_q975": 1180.8898344208599,
            "rating_q025": 1114.8260209892153
        },
        "smollm2-1.7b-instruct": {
            "rating": 1145.607347353105,
            "rating_q975": 1172.2220538962206,
            "rating_q025": 1118.9926408099896
        },
        "zephyr-7b-beta": {
            "rating": 1142.6638985122029,
            "rating_q975": 1156.907291676819,
            "rating_q025": 1128.4205053475866
        },
        "palm-2": {
            "rating": 1141.1282745792598,
            "rating_q975": 1156.3698897176466,
            "rating_q025": 1125.886659440873
        },
        "phi-3-mini-128k-instruct": {
            "rating": 1140.377713832399,
            "rating_q975": 1151.7416163490714,
            "rating_q025": 1129.0138113157266
        },
        "stripedhyena-nous-7b": {
            "rating": 1136.1825135594963,
            "rating_q975": 1153.9732883976249,
            "rating_q025": 1118.3917387213678
        },
        "mistral-7b-instruct": {
            "rating": 1129.5350978137753,
            "rating_q975": 1145.4811607672923,
            "rating_q025": 1113.5890348602584
        },
        "gemma-2b-it": {
            "rating": 1129.517353626393,
            "rating_q975": 1147.3458426927518,
            "rating_q025": 1111.6888645600343
        },
        "vicuna-7b": {
            "rating": 1129.3405820283142,
            "rating_q975": 1145.7754350504867,
            "rating_q025": 1112.9057290061417
        },
        "llama-3.2-1b-instruct": {
            "rating": 1125.3171029614984,
            "rating_q975": 1138.9579426736643,
            "rating_q025": 1111.6762632493326
        },
        "qwen1.5-4b-chat": {
            "rating": 1117.4287602197023,
            "rating_q975": 1132.0118730616293,
            "rating_q025": 1102.8456473777753
        },
        "guanaco-33b": {
            "rating": 1114.697837148323,
            "rating_q975": 1138.673252895761,
            "rating_q025": 1090.7224214008852
        },
        "olmo-7b-instruct": {
            "rating": 1114.5009340961283,
            "rating_q975": 1132.0444509418544,
            "rating_q025": 1096.9574172504022
        },
        "llama-2-7b-chat": {
            "rating": 1110.3817422768925,
            "rating_q975": 1121.3766681362733,
            "rating_q025": 1099.3868164175117
        },
        "chatglm3-6b": {
            "rating": 1084.910820889057,
            "rating_q975": 1105.3370443830584,
            "rating_q025": 1064.4845973950557
        },
        "gpt4all-13b-snoozy": {
            "rating": 1072.900819172113,
            "rating_q975": 1102.5630248847488,
            "rating_q025": 1043.2386134594772
        },
        "koala-13b": {
            "rating": 1071.024647658403,
            "rating_q975": 1089.2751253293898,
            "rating_q025": 1052.7741699874161
        },
        "mpt-7b-chat": {
            "rating": 1054.1055675963435,
            "rating_q975": 1076.0757316188049,
            "rating_q025": 1032.135403573882
        },
        "RWKV-4-Raven-14B": {
            "rating": 1037.6289276394878,
            "rating_q975": 1057.6486633286154,
            "rating_q025": 1017.6091919503601
        },
        "chatglm2-6b": {
            "rating": 1031.798139965731,
            "rating_q975": 1056.6602844270485,
            "rating_q025": 1006.9359955044135
        },
        "oasst-pythia-12b": {
            "rating": 1017.1869933813394,
            "rating_q975": 1036.344966852347,
            "rating_q025": 998.029019910332
        },
        "alpaca-13b": {
            "rating": 1006.299670551785,
            "rating_q975": 1026.3113178383312,
            "rating_q025": 986.2880232652387
        },
        "chatglm-6b": {
            "rating": 994.5430545110378,
            "rating_q975": 1014.8526603524629,
            "rating_q025": 974.2334486696127
        },
        "stablelm-tuned-alpha-7b": {
            "rating": 966.767514318324,
            "rating_q975": 990.9721271898071,
            "rating_q025": 942.5629014468408
        },
        "fastchat-t5-3b": {
            "rating": 965.8614476175644,
            "rating_q975": 986.7856005940171,
            "rating_q025": 944.9372946411117
        },
        "dolly-v2-12b": {
            "rating": 961.2706123844611,
            "rating_q975": 985.374235940086,
            "rating_q025": 937.1669888288361
        },
        "llama-13b": {
            "rating": 900.1249459560522,
            "rating_q975": 929.8012207729303,
            "rating_q025": 870.4486711391742
        }
    },
    "industry_writing_and_literature_and_language": {
        "gemini-3-pro": {
            "rating": 1494.4142568256677,
            "rating_q975": 1505.6665802878256,
            "rating_q025": 1483.16193336351
        },
        "claude-opus-4-5-20251101": {
            "rating": 1463.4104238892978,
            "rating_q975": 1476.3677421189134,
            "rating_q025": 1450.4531056596823
        },
        "claude-opus-4-5-20251101-thinking-32k": {
            "rating": 1455.3867429337336,
            "rating_q975": 1468.6753030943312,
            "rating_q025": 1442.098182773136
        },
        "gemini-2.5-pro": {
            "rating": 1453.0647332461026,
            "rating_q975": 1458.9015083227525,
            "rating_q025": 1447.2279581694527
        },
        "claude-sonnet-4-5-20250929-thinking-32k": {
            "rating": 1444.1043925245704,
            "rating_q975": 1452.3318108685412,
            "rating_q025": 1435.8769741805995
        },
        "gpt-4.5-preview-2025-02-27": {
            "rating": 1443.8785172972116,
            "rating_q975": 1453.399706181524,
            "rating_q025": 1434.3573284128993
        },
        "claude-sonnet-4-5-20250929": {
            "rating": 1443.680289103857,
            "rating_q975": 1452.6976070395392,
            "rating_q025": 1434.6629711681746
        },
        "claude-opus-4-1-20250805-thinking-16k": {
            "rating": 1441.7684961365808,
            "rating_q975": 1448.5090896233335,
            "rating_q025": 1435.027902649828
        },
        "grok-4.1-thinking": {
            "rating": 1440.831819190364,
            "rating_q975": 1451.688215134402,
            "rating_q025": 1429.975423246326
        },
        "claude-opus-4-1-20250805": {
            "rating": 1439.8043934382392,
            "rating_q975": 1446.011176298624,
            "rating_q025": 1433.5976105778545
        },
        "gpt-5.1-high": {
            "rating": 1439.499207820918,
            "rating_q975": 1451.0542761089769,
            "rating_q025": 1427.944139532859
        },
        "grok-4.1": {
            "rating": 1428.945570405416,
            "rating_q975": 1439.7237672269857,
            "rating_q025": 1418.1673735838463
        },
        "chatgpt-4o-latest-20250326": {
            "rating": 1425.2298386800244,
            "rating_q975": 1430.8578364303605,
            "rating_q025": 1419.6018409296883
        },
        "gpt-5.1": {
            "rating": 1424.951352786149,
            "rating_q975": 1436.0572573586678,
            "rating_q025": 1413.8454482136303
        },
        "claude-opus-4-20250514-thinking-16k": {
            "rating": 1423.5285181423533,
            "rating_q975": 1430.7592012326697,
            "rating_q025": 1416.2978350520368
        },
        "claude-opus-4-20250514": {
            "rating": 1415.5529431564837,
            "rating_q975": 1422.376563766326,
            "rating_q025": 1408.7293225466415
        },
        "grok-4-1-fast-reasoning": {
            "rating": 1413.4668433574916,
            "rating_q975": 1426.8072168432327,
            "rating_q025": 1400.1264698717505
        },
        "deepseek-v3.2-exp": {
            "rating": 1412.6733270116783,
            "rating_q975": 1424.4745238355902,
            "rating_q025": 1400.8721301877665
        },
        "deepseek-v3.2-thinking": {
            "rating": 1409.6639419784242,
            "rating_q975": 1425.540667108095,
            "rating_q025": 1393.7872168487534
        },
        "ernie-5.0-preview-1103": {
            "rating": 1408.7470308146799,
            "rating_q975": 1425.5946793969943,
            "rating_q025": 1391.8993822323655
        },
        "deepseek-v3.1-thinking": {
            "rating": 1408.0525734603484,
            "rating_q975": 1419.3359025578643,
            "rating_q025": 1396.7692443628325
        },
        "qwen3-max-preview": {
            "rating": 1406.9045400562231,
            "rating_q975": 1414.8007228815427,
            "rating_q025": 1399.0083572309036
        },
        "deepseek-v3.1-terminus": {
            "rating": 1406.0718582973466,
            "rating_q975": 1426.8287839560728,
            "rating_q025": 1385.3149326386203
        },
        "grok-3-preview-02-24": {
            "rating": 1404.4622874182023,
            "rating_q975": 1411.516251540769,
            "rating_q025": 1397.4083232956357
        },
        "qwen3-max-2025-09-23": {
            "rating": 1404.092445802904,
            "rating_q975": 1417.1359035833618,
            "rating_q025": 1391.048988022446
        },
        "gpt-5-chat": {
            "rating": 1404.037718181717,
            "rating_q975": 1411.6347748452595,
            "rating_q025": 1396.4406615181747
        },
        "kimi-k2-thinking-turbo": {
            "rating": 1402.5988986281811,
            "rating_q975": 1413.1302960962532,
            "rating_q025": 1392.067501160109
        },
        "gemini-2.5-flash": {
            "rating": 1401.5344571990117,
            "rating_q975": 1407.1028436388438,
            "rating_q025": 1395.9660707591797
        },
        "deepseek-v3.1-terminus-thinking": {
            "rating": 1401.4199867767088,
            "rating_q975": 1422.5456127529117,
            "rating_q025": 1380.294360800506
        },
        "gpt-5-high": {
            "rating": 1401.4009303129872,
            "rating_q975": 1409.10418268723,
            "rating_q025": 1393.6976779387444
        },
        "deepseek-v3.2": {
            "rating": 1401.105472531248,
            "rating_q975": 1417.0550881356098,
            "rating_q025": 1385.1558569268864
        },
        "gpt-4.1-2025-04-14": {
            "rating": 1400.5250308649297,
            "rating_q975": 1406.6840737203318,
            "rating_q025": 1394.3659880095277
        },
        "glm-4.6": {
            "rating": 1399.7684542530465,
            "rating_q975": 1408.24082596749,
            "rating_q025": 1391.2960825386028
        },
        "grok-4-0709": {
            "rating": 1397.8108107348967,
            "rating_q975": 1404.5212136219247,
            "rating_q025": 1391.1004078478686
        },
        "deepseek-v3.1": {
            "rating": 1397.686019107653,
            "rating_q975": 1407.8486879868537,
            "rating_q025": 1387.5233502284523
        },
        "mistral-large-3": {
            "rating": 1396.5165901754913,
            "rating_q975": 1412.0318196741016,
            "rating_q025": 1381.001360676881
        },
        "o3-2025-04-16": {
            "rating": 1395.8192389842316,
            "rating_q975": 1401.7624886323028,
            "rating_q025": 1389.8759893361603
        },
        "claude-sonnet-4-20250514-thinking-32k": {
            "rating": 1395.6872208528214,
            "rating_q975": 1402.937197092685,
            "rating_q025": 1388.4372446129578
        },
        "o1-2024-12-17": {
            "rating": 1395.1871223686212,
            "rating_q975": 1402.2460378641886,
            "rating_q025": 1388.1282068730538
        },
        "deepseek-v3.2-exp-thinking": {
            "rating": 1394.406336925206,
            "rating_q975": 1407.4848358102277,
            "rating_q025": 1381.3278380401844
        },
        "grok-4-fast-chat": {
            "rating": 1394.0995010561173,
            "rating_q975": 1408.8774278426315,
            "rating_q025": 1379.3215742696032
        },
        "gemini-2.5-flash-preview-09-2025": {
            "rating": 1393.992171571642,
            "rating_q975": 1402.0282015842427,
            "rating_q025": 1385.9561415590415
        },
        "qwen3-235b-a22b-instruct-2507": {
            "rating": 1392.9380540329403,
            "rating_q975": 1399.2052147633378,
            "rating_q025": 1386.6708933025427
        },
        "claude-haiku-4-5-20251001": {
            "rating": 1391.5136831234743,
            "rating_q975": 1400.0174971936026,
            "rating_q025": 1383.009869053346
        },
        "qwen3-vl-235b-a22b-instruct": {
            "rating": 1389.3099725718037,
            "rating_q975": 1402.965457428195,
            "rating_q025": 1375.6544877154124
        },
        "deepseek-r1-0528": {
            "rating": 1389.205733025589,
            "rating_q975": 1398.6129660850888,
            "rating_q025": 1379.7984999660894
        },
        "claude-3-7-sonnet-20250219-thinking-32k": {
            "rating": 1389.112570501092,
            "rating_q975": 1395.7958680423617,
            "rating_q025": 1382.4292729598224
        },
        "mistral-medium-2508": {
            "rating": 1386.7185763755904,
            "rating_q975": 1393.4014251556403,
            "rating_q025": 1380.0357275955405
        },
        "claude-sonnet-4-20250514": {
            "rating": 1384.464005324849,
            "rating_q975": 1391.4209439634976,
            "rating_q025": 1377.5070666862005
        },
        "deepseek-v3-0324": {
            "rating": 1383.7405205216087,
            "rating_q975": 1390.1245179140813,
            "rating_q025": 1377.3565231291361
        },
        "grok-4-fast-reasoning": {
            "rating": 1383.0701697040147,
            "rating_q975": 1392.5188649660338,
            "rating_q025": 1373.6214744419956
        },
        "glm-4.5": {
            "rating": 1382.0835550976465,
            "rating_q975": 1390.5255665360373,
            "rating_q025": 1373.6415436592556
        },
        "deepseek-r1": {
            "rating": 1379.830811728329,
            "rating_q975": 1387.892465335504,
            "rating_q025": 1371.769158121154
        },
        "o1-preview": {
            "rating": 1378.2871985833194,
            "rating_q975": 1386.0546332274744,
            "rating_q025": 1370.5197639391645
        },
        "kimi-k2-0905-preview": {
            "rating": 1377.8261551402634,
            "rating_q975": 1389.5073693796867,
            "rating_q025": 1366.14494090084
        },
        "qwen3-235b-a22b-thinking-2507": {
            "rating": 1376.4622555924834,
            "rating_q975": 1389.7985065245387,
            "rating_q025": 1363.1260046604282
        },
        "gemini-2.5-flash-lite-preview-06-17-thinking": {
            "rating": 1376.4234549941557,
            "rating_q975": 1383.8633450139966,
            "rating_q025": 1368.9835649743147
        },
        "claude-3-7-sonnet-20250219": {
            "rating": 1375.0705768838716,
            "rating_q975": 1381.4657665956117,
            "rating_q025": 1368.6753871721314
        },
        "qwen3-235b-a22b-no-thinking": {
            "rating": 1375.0080429693307,
            "rating_q975": 1382.0971055908574,
            "rating_q025": 1367.918980347804
        },
        "claude-3-5-sonnet-20241022": {
            "rating": 1373.5605773797042,
            "rating_q975": 1378.2619852721703,
            "rating_q025": 1368.8591694872382
        },
        "kimi-k2-0711-preview": {
            "rating": 1372.3383159930015,
            "rating_q975": 1380.2400466436445,
            "rating_q025": 1364.4365853423585
        },
        "hunyuan-vision-1.5-thinking": {
            "rating": 1371.843894133149,
            "rating_q975": 1398.2576105164828,
            "rating_q025": 1345.4301777498151
        },
        "hunyuan-t1-20250711": {
            "rating": 1370.549473886441,
            "rating_q975": 1388.7284517791177,
            "rating_q025": 1352.3704959937645
        },
        "gemini-2.5-flash-lite-preview-09-2025-no-thinking": {
            "rating": 1370.2195706632233,
            "rating_q975": 1378.170321316983,
            "rating_q025": 1362.2688200094635
        },
        "mistral-medium-2505": {
            "rating": 1367.0338368508808,
            "rating_q975": 1374.4718360585289,
            "rating_q025": 1359.5958376432327
        },
        "qwen3-coder-480b-a35b-instruct": {
            "rating": 1364.321538621904,
            "rating_q975": 1372.8310782303115,
            "rating_q025": 1355.8119990134965
        },
        "qwen3-vl-235b-a22b-thinking": {
            "rating": 1363.0453122857614,
            "rating_q975": 1377.232936479834,
            "rating_q025": 1348.8576880916887
        },
        "mai-1-preview": {
            "rating": 1360.7569554823822,
            "rating_q975": 1370.3564685143804,
            "rating_q025": 1351.157442450384
        },
        "qwen2.5-max": {
            "rating": 1360.5665748548656,
            "rating_q975": 1367.1706192949712,
            "rating_q025": 1353.96253041476
        },
        "gpt-4.1-mini-2025-04-14": {
            "rating": 1357.492536135021,
            "rating_q975": 1364.3820600030515,
            "rating_q025": 1350.6030122669906
        },
        "hunyuan-turbos-20250416": {
            "rating": 1356.0099748806556,
            "rating_q975": 1367.4227892579893,
            "rating_q025": 1344.597160503322
        },
        "gpt-5-mini-high": {
            "rating": 1354.7805430710832,
            "rating_q975": 1362.888881908463,
            "rating_q025": 1346.6722042337035
        },
        "o4-mini-2025-04-16": {
            "rating": 1354.683727718543,
            "rating_q975": 1361.1358099600798,
            "rating_q025": 1348.2316454770062
        },
        "longcat-flash-chat": {
            "rating": 1354.6077132748894,
            "rating_q975": 1366.3871636502356,
            "rating_q025": 1342.8282628995432
        },
        "deepseek-v3": {
            "rating": 1353.665436599295,
            "rating_q975": 1361.6333381298086,
            "rating_q025": 1345.6975350687812
        },
        "gemini-2.0-flash-001": {
            "rating": 1353.390472342445,
            "rating_q975": 1359.403176525595,
            "rating_q025": 1347.377768159295
        },
        "gemma-3-27b-it": {
            "rating": 1352.3068077242142,
            "rating_q975": 1358.3630834736075,
            "rating_q025": 1346.250531974821
        },
        "gemini-1.5-pro-002": {
            "rating": 1352.1465480628394,
            "rating_q975": 1357.7949306769563,
            "rating_q025": 1346.4981654487226
        },
        "qwen3-235b-a22b": {
            "rating": 1346.9656946075863,
            "rating_q975": 1354.7301858571425,
            "rating_q025": 1339.2012033580302
        },
        "grok-3-mini-high": {
            "rating": 1345.8835359239797,
            "rating_q975": 1355.6453115062081,
            "rating_q025": 1336.1217603417513
        },
        "command-a-03-2025": {
            "rating": 1345.3082794590825,
            "rating_q975": 1351.051509932125,
            "rating_q025": 1339.56504898604
        },
        "gemini-2.0-flash-lite-preview-02-05": {
            "rating": 1345.1059941854032,
            "rating_q975": 1352.3043666636609,
            "rating_q025": 1337.9076217071456
        },
        "qwen3-next-80b-a3b-instruct": {
            "rating": 1343.7278166004376,
            "rating_q975": 1352.3364638776443,
            "rating_q025": 1335.1191693232308
        },
        "gpt-4o-2024-05-13": {
            "rating": 1341.646650790936,
            "rating_q975": 1347.2492070134297,
            "rating_q025": 1336.0440945684425
        },
        "grok-3-mini-beta": {
            "rating": 1341.5816547763413,
            "rating_q975": 1350.1308135018003,
            "rating_q025": 1333.0324960508824
        },
        "qwen3-30b-a3b-instruct-2507": {
            "rating": 1341.545028672726,
            "rating_q975": 1350.053381269922,
            "rating_q025": 1333.0366760755298
        },
        "glm-4.5-air": {
            "rating": 1341.2886233561744,
            "rating_q975": 1348.7499759430448,
            "rating_q025": 1333.827270769304
        },
        "o3-mini-high": {
            "rating": 1338.8299613994577,
            "rating_q975": 1347.4867229804975,
            "rating_q025": 1330.173199818418
        },
        "gpt-4o-2024-08-06": {
            "rating": 1337.7839128564399,
            "rating_q975": 1344.436546020256,
            "rating_q025": 1331.1312796926238
        },
        "gemini-advanced-0514": {
            "rating": 1335.783341523288,
            "rating_q975": 1343.4715977689411,
            "rating_q025": 1328.095085277635
        },
        "qwen3-next-80b-a3b-thinking": {
            "rating": 1334.4890033695979,
            "rating_q975": 1345.3210819347944,
            "rating_q025": 1323.6569248044013
        },
        "minimax-m1": {
            "rating": 1331.9771834313092,
            "rating_q975": 1339.0286397732407,
            "rating_q025": 1324.9257270893777
        },
        "glm-4-plus-0111": {
            "rating": 1331.2556916263943,
            "rating_q975": 1346.3352407961972,
            "rating_q025": 1316.1761424565914
        },
        "gemini-1.5-pro-001": {
            "rating": 1330.3749555988072,
            "rating_q975": 1336.9025072429226,
            "rating_q025": 1323.8474039546918
        },
        "hunyuan-turbos-20250226": {
            "rating": 1329.1970937591072,
            "rating_q975": 1350.147790239765,
            "rating_q025": 1308.2463972784494
        },
        "claude-3-5-sonnet-20240620": {
            "rating": 1328.3260797344421,
            "rating_q975": 1334.1976662180455,
            "rating_q025": 1322.4544932508388
        },
        "mistral-small-2506": {
            "rating": 1327.0264061660382,
            "rating_q975": 1336.4770992673798,
            "rating_q025": 1317.5757130646966
        },
        "gpt-4-turbo-2024-04-09": {
            "rating": 1326.7321919505973,
            "rating_q975": 1332.9447380848005,
            "rating_q025": 1320.5196458163941
        },
        "grok-2-2024-08-13": {
            "rating": 1324.1694887952078,
            "rating_q975": 1329.8393069580827,
            "rating_q025": 1318.499670632333
        },
        "o3-mini": {
            "rating": 1323.099414589849,
            "rating_q975": 1328.590700876312,
            "rating_q025": 1317.608128303386
        },
        "hunyuan-turbo-0110": {
            "rating": 1320.400538433617,
            "rating_q975": 1340.3418270749216,
            "rating_q025": 1300.4592497923122
        },
        "qwen-plus-0125": {
            "rating": 1319.059444965886,
            "rating_q975": 1333.7066316324426,
            "rating_q025": 1304.4122582993296
        },
        "llama-3.1-nemotron-ultra-253b-v1": {
            "rating": 1318.7688661574339,
            "rating_q975": 1339.7442343632135,
            "rating_q025": 1297.7934979516542
        },
        "step-2-16k-exp-202412": {
            "rating": 1317.1482281435883,
            "rating_q975": 1332.6180380295168,
            "rating_q025": 1301.6784182576598
        },
        "glm-4.5v": {
            "rating": 1316.176830176952,
            "rating_q975": 1333.9292401217401,
            "rating_q025": 1298.424420232164
        },
        "intellect-3": {
            "rating": 1315.5215629094523,
            "rating_q975": 1342.1013475464263,
            "rating_q025": 1288.9417782724784
        },
        "step-3": {
            "rating": 1314.4580617488555,
            "rating_q975": 1329.6140923491653,
            "rating_q025": 1299.3020311485457
        },
        "amazon-nova-experimental-chat-10-20": {
            "rating": 1313.9302534887584,
            "rating_q975": 1328.4870734634649,
            "rating_q025": 1299.3734335140518
        },
        "claude-3-opus-20240229": {
            "rating": 1313.4703089597624,
            "rating_q975": 1318.4619596729256,
            "rating_q025": 1308.4786582465993
        },
        "llama-3.1-405b-instruct-fp8": {
            "rating": 1313.0144782621283,
            "rating_q975": 1318.9744889177193,
            "rating_q025": 1307.0544676065372
        },
        "gemma-3-12b-it": {
            "rating": 1312.5488897215705,
            "rating_q975": 1330.305613746348,
            "rating_q025": 1294.792165696793
        },
        "deepseek-v2.5-1210": {
            "rating": 1312.2130487884817,
            "rating_q975": 1325.565502281077,
            "rating_q025": 1298.8605952958865
        },
        "llama-4-maverick-17b-128e-instruct": {
            "rating": 1311.9314778523644,
            "rating_q975": 1318.7540100847546,
            "rating_q025": 1305.1089456199743
        },
        "gpt-4o-mini-2024-07-18": {
            "rating": 1310.82193783998,
            "rating_q975": 1316.137687135879,
            "rating_q025": 1305.5061885440807
        },
        "llama-3.1-405b-instruct-bf16": {
            "rating": 1309.946060694177,
            "rating_q975": 1315.8975901456477,
            "rating_q025": 1303.9945312427064
        },
        "gpt-oss-120b": {
            "rating": 1309.7528513873528,
            "rating_q975": 1317.4165827058575,
            "rating_q025": 1302.0891200688482
        },
        "claude-3-5-haiku-20241022": {
            "rating": 1309.597577388151,
            "rating_q975": 1314.6113885073723,
            "rating_q025": 1304.5837662689296
        },
        "amazon-nova-experimental-chat-10-09": {
            "rating": 1309.3120050826758,
            "rating_q975": 1322.1667644317902,
            "rating_q025": 1296.4572457335614
        },
        "llama-3.3-nemotron-49b-super-v1": {
            "rating": 1307.8258518827356,
            "rating_q975": 1330.4230597076387,
            "rating_q025": 1285.2286440578325
        },
        "gemini-1.5-flash-002": {
            "rating": 1307.4581511013607,
            "rating_q975": 1314.2358720140403,
            "rating_q025": 1300.6804301886812
        },
        "o1-mini": {
            "rating": 1307.3292316685347,
            "rating_q975": 1313.1619919146563,
            "rating_q025": 1301.4964714224132
        },
        "llama-4-scout-17b-16e-instruct": {
            "rating": 1307.1657416871867,
            "rating_q975": 1314.798016515892,
            "rating_q025": 1299.5334668584815
        },
        "hunyuan-large-2025-02-10": {
            "rating": 1306.9863892196408,
            "rating_q975": 1325.7032866058948,
            "rating_q025": 1288.2694918333868
        },
        "qwq-32b": {
            "rating": 1306.9312204390171,
            "rating_q975": 1314.4470417008367,
            "rating_q025": 1299.4153991771975
        },
        "qwen3-32b": {
            "rating": 1306.8816092161528,
            "rating_q975": 1323.9041471003725,
            "rating_q025": 1289.8590713319331
        },
        "glm-4-plus": {
            "rating": 1306.3182194127498,
            "rating_q975": 1314.4309141932035,
            "rating_q025": 1298.2055246322961
        },
        "gpt-4-1106-preview": {
            "rating": 1304.7625733707716,
            "rating_q975": 1311.0540385836741,
            "rating_q025": 1298.4711081578691
        },
        "qwen-max-0919": {
            "rating": 1304.328613678032,
            "rating_q975": 1313.6252027415715,
            "rating_q025": 1295.0320246144927
        },
        "qwen3-30b-a3b": {
            "rating": 1303.8276277886982,
            "rating_q975": 1311.6905832438567,
            "rating_q025": 1295.9646723335397
        },
        "gpt-4-0125-preview": {
            "rating": 1302.296777035072,
            "rating_q975": 1308.7614109988012,
            "rating_q025": 1295.8321430713427
        },
        "minimax-m2": {
            "rating": 1300.9882735141855,
            "rating_q975": 1316.9091812025101,
            "rating_q025": 1285.0673658258609
        },
        "nova-2-lite": {
            "rating": 1300.8600397127861,
            "rating_q975": 1317.911483837418,
            "rating_q025": 1283.8085955881543
        },
        "step-1o-turbo-202506": {
            "rating": 1300.8545104246882,
            "rating_q975": 1314.1511699897285,
            "rating_q025": 1287.557850859648
        },
        "yi-lightning": {
            "rating": 1300.7893483114997,
            "rating_q975": 1308.8675511670847,
            "rating_q025": 1292.7111454559147
        },
        "mistral-large-2407": {
            "rating": 1299.8034459889068,
            "rating_q975": 1306.4508513280875,
            "rating_q025": 1293.156040649726
        },
        "gemma-3n-e4b-it": {
            "rating": 1298.1736172338142,
            "rating_q975": 1306.7858407788412,
            "rating_q025": 1289.5613936887871
        },
        "gpt-4.1-nano-2025-04-14": {
            "rating": 1296.836669900722,
            "rating_q975": 1311.1449952152564,
            "rating_q025": 1282.5283445861876
        },
        "gemma-3-4b-it": {
            "rating": 1296.802770785705,
            "rating_q975": 1313.9521612766623,
            "rating_q025": 1279.6533802947476
        },
        "nvidia-llama-3.3-nemotron-super-49b-v1.5": {
            "rating": 1296.1832175811587,
            "rating_q975": 1317.5873656980575,
            "rating_q025": 1274.77906946426
        },
        "mistral-large-2411": {
            "rating": 1295.486139466077,
            "rating_q975": 1302.4693349102674,
            "rating_q025": 1288.5029440218866
        },
        "gpt-5-nano-high": {
            "rating": 1293.5882780403028,
            "rating_q975": 1307.904328832177,
            "rating_q025": 1279.2722272484286
        },
        "gemma-2-27b-it": {
            "rating": 1293.5250701175098,
            "rating_q975": 1298.7574070405542,
            "rating_q025": 1288.2927331944654
        },
        "magistral-medium-2506": {
            "rating": 1291.4201731833023,
            "rating_q975": 1303.5598585058428,
            "rating_q025": 1279.2804878607617
        },
        "grok-2-mini-2024-08-13": {
            "rating": 1291.4181729345169,
            "rating_q975": 1297.412581221469,
            "rating_q025": 1285.4237646475647
        },
        "hunyuan-standard-2025-02-10": {
            "rating": 1290.4887624574242,
            "rating_q975": 1308.6982747357167,
            "rating_q025": 1272.2792501791316
        },
        "llama-3.3-70b-instruct": {
            "rating": 1290.2101819694788,
            "rating_q975": 1295.6135056156372,
            "rating_q025": 1284.8068583233203
        },
        "mistral-small-3.1-24b-instruct-2503": {
            "rating": 1288.9548751953362,
            "rating_q975": 1296.4165114313653,
            "rating_q025": 1281.493238959307
        },
        "gemini-1.5-flash-001": {
            "rating": 1288.1124093034941,
            "rating_q975": 1294.8143779995892,
            "rating_q025": 1281.410440607399
        },
        "qwen2.5-plus-1127": {
            "rating": 1287.3176724726798,
            "rating_q975": 1298.1489437150647,
            "rating_q025": 1276.4864012302949
        },
        "olmo-3-32b-think": {
            "rating": 1286.3273891738963,
            "rating_q975": 1308.4755236794426,
            "rating_q025": 1264.17925466835
        },
        "hunyuan-large-vision": {
            "rating": 1285.7614461692115,
            "rating_q975": 1303.4107301006395,
            "rating_q025": 1268.1121622377834
        },
        "ring-flash-2.0": {
            "rating": 1284.586160755815,
            "rating_q975": 1299.9804023448833,
            "rating_q025": 1269.1919191667466
        },
        "gpt-4-0613": {
            "rating": 1280.8851192717862,
            "rating_q975": 1287.579268864314,
            "rating_q025": 1274.1909696792584
        },
        "deepseek-v2.5": {
            "rating": 1280.811753294739,
            "rating_q975": 1288.9186577763967,
            "rating_q025": 1272.7048488130813
        },
        "qwen2.5-72b-instruct": {
            "rating": 1279.5503930339403,
            "rating_q975": 1286.0945576815368,
            "rating_q025": 1273.0062283863438
        },
        "gpt-4-0314": {
            "rating": 1279.4607543511295,
            "rating_q975": 1287.671174965852,
            "rating_q025": 1271.250333736407
        },
        "ling-flash-2.0": {
            "rating": 1277.7722696548635,
            "rating_q975": 1293.2410238686093,
            "rating_q025": 1262.3035154411177
        },
        "athene-v2-chat": {
            "rating": 1276.3366360779291,
            "rating_q975": 1283.778096195439,
            "rating_q025": 1268.8951759604192
        },
        "llama-3.1-tulu-3-70b": {
            "rating": 1276.279255343276,
            "rating_q975": 1295.8456211567104,
            "rating_q025": 1256.7128895298415
        },
        "athene-70b-0725": {
            "rating": 1275.0706011163106,
            "rating_q975": 1283.82584559665,
            "rating_q025": 1266.3153566359713
        },
        "command-r-plus-08-2024": {
            "rating": 1275.0047010340395,
            "rating_q975": 1286.1907758581194,
            "rating_q025": 1263.8186262099596
        },
        "jamba-1.5-large": {
            "rating": 1273.1916149994195,
            "rating_q975": 1285.7707418625976,
            "rating_q025": 1260.6124881362414
        },
        "gpt-oss-20b": {
            "rating": 1272.8899744229284,
            "rating_q975": 1285.8638213796926,
            "rating_q025": 1259.9161274661642
        },
        "amazon-nova-pro-v1.0": {
            "rating": 1271.780172019149,
            "rating_q975": 1279.024482732514,
            "rating_q025": 1264.535861305784
        },
        "gemma-2-9b-it-simpo": {
            "rating": 1270.501650649387,
            "rating_q975": 1282.140858888891,
            "rating_q025": 1258.8624424098832
        },
        "reka-core-20240904": {
            "rating": 1269.4890730128502,
            "rating_q975": 1282.9065858483348,
            "rating_q025": 1256.0715601773657
        },
        "claude-3-sonnet-20240229": {
            "rating": 1266.3385622361307,
            "rating_q975": 1272.73952699912,
            "rating_q025": 1259.9375974731413
        },
        "llama-3.1-nemotron-51b-instruct": {
            "rating": 1266.1652019223989,
            "rating_q975": 1284.2092580655149,
            "rating_q025": 1248.1211457792829
        },
        "mercury": {
            "rating": 1265.8588081329922,
            "rating_q975": 1294.9327579489693,
            "rating_q025": 1236.784858317015
        },
        "gemma-2-9b-it": {
            "rating": 1264.6297269063866,
            "rating_q975": 1270.4021877695411,
            "rating_q025": 1258.8572660432321
        },
        "llama-3.1-nemotron-70b-instruct": {
            "rating": 1263.1859065659323,
            "rating_q975": 1276.9758886261093,
            "rating_q025": 1249.3959245057554
        },
        "llama-3.1-70b-instruct": {
            "rating": 1261.5575131289772,
            "rating_q975": 1267.592272288787,
            "rating_q025": 1255.5227539691675
        },
        "command-r-plus": {
            "rating": 1257.1067783055264,
            "rating_q975": 1264.075519115817,
            "rating_q025": 1250.1380374952357
        },
        "nemotron-4-340b-instruct": {
            "rating": 1256.6906211007995,
            "rating_q975": 1265.9503860615841,
            "rating_q025": 1247.4308561400148
        },
        "reka-flash-20240904": {
            "rating": 1255.813619440616,
            "rating_q975": 1268.7745919844592,
            "rating_q025": 1242.852646896773
        },
        "gemini-1.5-flash-8b-001": {
            "rating": 1252.3985474028855,
            "rating_q975": 1259.264279295619,
            "rating_q025": 1245.532815510152
        },
        "c4ai-aya-expanse-32b": {
            "rating": 1251.5790318292738,
            "rating_q975": 1259.2073630045138,
            "rating_q025": 1243.9507006540339
        },
        "glm-4-0520": {
            "rating": 1250.9433500078687,
            "rating_q975": 1262.8709938775835,
            "rating_q025": 1239.015706138154
        },
        "llama-3-70b-instruct": {
            "rating": 1246.7299268041752,
            "rating_q975": 1252.8293090506795,
            "rating_q025": 1240.6305445576709
        },
        "mistral-small-24b-instruct-2501": {
            "rating": 1245.706102813446,
            "rating_q975": 1255.1051330325795,
            "rating_q025": 1236.3070725943126
        },
        "claude-3-haiku-20240307": {
            "rating": 1243.7256914088302,
            "rating_q975": 1249.7876660500683,
            "rating_q025": 1237.6637167675922
        },
        "qwen2-72b-instruct": {
            "rating": 1239.733348140703,
            "rating_q975": 1247.4364727616141,
            "rating_q025": 1232.0302235197917
        },
        "deepseek-coder-v2": {
            "rating": 1237.6077073421736,
            "rating_q975": 1248.1556366263944,
            "rating_q025": 1227.0597780579528
        },
        "amazon-nova-lite-v1.0": {
            "rating": 1237.2606198193298,
            "rating_q975": 1245.4653185788327,
            "rating_q025": 1229.055921059827
        },
        "command-r-08-2024": {
            "rating": 1236.13209911768,
            "rating_q975": 1247.7559963987433,
            "rating_q025": 1224.5082018366165
        },
        "olmo-2-0325-32b-instruct": {
            "rating": 1232.496329785703,
            "rating_q975": 1251.7534272462458,
            "rating_q025": 1213.2392323251602
        },
        "phi-4": {
            "rating": 1227.3860309094089,
            "rating_q975": 1234.9746266720683,
            "rating_q025": 1219.7974351467494
        },
        "qwen2.5-coder-32b-instruct": {
            "rating": 1224.551150519097,
            "rating_q975": 1239.2379482246981,
            "rating_q025": 1209.864352813496
        },
        "mistral-large-2402": {
            "rating": 1223.1393608846781,
            "rating_q975": 1230.686454347159,
            "rating_q025": 1215.5922674221972
        },
        "ministral-8b-2410": {
            "rating": 1222.6113232479265,
            "rating_q975": 1238.1519998838082,
            "rating_q025": 1207.0706466120448
        },
        "amazon-nova-micro-v1.0": {
            "rating": 1220.5247487407523,
            "rating_q975": 1228.7920303633186,
            "rating_q025": 1212.257467118186
        },
        "gpt-3.5-turbo-0125": {
            "rating": 1220.4215362254924,
            "rating_q975": 1227.6172067041834,
            "rating_q025": 1213.2258657468014
        },
        "qwen1.5-110b-chat": {
            "rating": 1215.737174724537,
            "rating_q975": 1225.0871969065513,
            "rating_q025": 1206.3871525425227
        },
        "gemini-pro-dev-api": {
            "rating": 1211.5352459546812,
            "rating_q975": 1223.3178299104086,
            "rating_q025": 1199.7526619989537
        },
        "qwen1.5-72b-chat": {
            "rating": 1211.248309100265,
            "rating_q975": 1219.6480415943054,
            "rating_q025": 1202.8485766062247
        },
        "c4ai-aya-expanse-8b": {
            "rating": 1210.6369248588048,
            "rating_q975": 1221.7693369232504,
            "rating_q025": 1199.5045127943592
        },
        "jamba-1.5-mini": {
            "rating": 1210.3772200355434,
            "rating_q975": 1222.8543391197766,
            "rating_q025": 1197.9001009513102
        },
        "mixtral-8x22b-instruct-v0.1": {
            "rating": 1206.7282124881115,
            "rating_q975": 1214.1779403089733,
            "rating_q025": 1199.2784846672496
        },
        "mistral-medium": {
            "rating": 1205.7812446659452,
            "rating_q975": 1215.1002938140082,
            "rating_q025": 1196.4621955178823
        },
        "command-r": {
            "rating": 1205.7542390780995,
            "rating_q975": 1213.4831487896388,
            "rating_q025": 1198.0253293665603
        },
        "hunyuan-standard-256k": {
            "rating": 1205.5403296218033,
            "rating_q975": 1226.332983526281,
            "rating_q025": 1184.7476757173256
        },
        "gemini-pro": {
            "rating": 1202.045721334171,
            "rating_q975": 1220.8482077609804,
            "rating_q025": 1183.2432349073617
        },
        "reka-flash-21b-20240226-online": {
            "rating": 1201.3791105693579,
            "rating_q975": 1213.4922173490577,
            "rating_q025": 1189.266003789658
        },
        "llama-3.1-tulu-3-8b": {
            "rating": 1198.974062923344,
            "rating_q975": 1218.5016662328555,
            "rating_q025": 1179.4464596138325
        },
        "reka-flash-21b-20240226": {
            "rating": 1195.1594815443573,
            "rating_q975": 1204.9854360836562,
            "rating_q025": 1185.3335270050584
        },
        "zephyr-orpo-141b-A35b-v0.1": {
            "rating": 1193.0539840675176,
            "rating_q975": 1210.9774211931274,
            "rating_q025": 1175.1305469419078
        },
        "wizardlm-70b": {
            "rating": 1191.7263425292513,
            "rating_q975": 1206.4569975010772,
            "rating_q025": 1176.9956875574253
        },
        "gemma-2-2b-it": {
            "rating": 1189.8486075021738,
            "rating_q975": 1196.1777891603233,
            "rating_q025": 1183.5194258440242
        },
        "llama-3-8b-instruct": {
            "rating": 1189.1545676307956,
            "rating_q975": 1195.616193846411,
            "rating_q025": 1182.69294141518
        },
        "gpt-3.5-turbo-1106": {
            "rating": 1185.577942477157,
            "rating_q975": 1198.8294335096623,
            "rating_q025": 1172.3264514446516
        },
        "llama-3.1-8b-instruct": {
            "rating": 1180.1453962327175,
            "rating_q975": 1186.6096701591011,
            "rating_q025": 1173.681122306334
        },
        "granite-3.1-8b-instruct": {
            "rating": 1176.8870570775007,
            "rating_q975": 1197.5274814419747,
            "rating_q025": 1156.2466327130267
        },
        "dbrx-instruct-preview": {
            "rating": 1173.3969345666683,
            "rating_q975": 1183.1299251475277,
            "rating_q025": 1163.6639439858088
        },
        "yi-1.5-34b-chat": {
            "rating": 1173.1298227823233,
            "rating_q975": 1181.8834784012947,
            "rating_q025": 1164.376167163352
        },
        "openchat-3.5": {
            "rating": 1172.1174780136896,
            "rating_q975": 1187.5132658741609,
            "rating_q025": 1156.7216901532183
        },
        "phi-3-medium-4k-instruct": {
            "rating": 1170.8090111588333,
            "rating_q975": 1179.3539773154,
            "rating_q025": 1162.2640450022666
        },
        "qwen1.5-32b-chat": {
            "rating": 1169.7633351341806,
            "rating_q975": 1179.971769631266,
            "rating_q025": 1159.5549006370952
        },
        "vicuna-33b": {
            "rating": 1168.2158029135853,
            "rating_q975": 1178.2910613579274,
            "rating_q025": 1158.1405444692432
        },
        "mixtral-8x7b-instruct-v0.1": {
            "rating": 1168.0076822025449,
            "rating_q975": 1175.1373036395883,
            "rating_q025": 1160.8780607655015
        },
        "falcon-180b-chat": {
            "rating": 1166.8941308473222,
            "rating_q975": 1199.0400357728706,
            "rating_q025": 1134.7482259217738
        },
        "deepseek-llm-67b-chat": {
            "rating": 1166.2159906055417,
            "rating_q975": 1184.9836072108455,
            "rating_q025": 1147.448374000238
        },
        "tulu-2-dpo-70b": {
            "rating": 1163.056060186741,
            "rating_q975": 1179.8713425676776,
            "rating_q025": 1146.2407778058043
        },
        "qwen1.5-14b-chat": {
            "rating": 1162.1496700702048,
            "rating_q975": 1173.5017444303928,
            "rating_q025": 1150.7975957100168
        },
        "yi-34b-chat": {
            "rating": 1161.3140346682185,
            "rating_q975": 1172.5909834184886,
            "rating_q025": 1150.0370859179484
        },
        "openchat-3.5-0106": {
            "rating": 1159.9007271236121,
            "rating_q975": 1172.1934975160925,
            "rating_q025": 1147.6079567311317
        },
        "snowflake-arctic-instruct": {
            "rating": 1157.1447639686048,
            "rating_q975": 1167.0545016620817,
            "rating_q025": 1147.235026275128
        },
        "openhermes-2.5-mistral-7b": {
            "rating": 1155.2047704511733,
            "rating_q975": 1173.5729506877465,
            "rating_q025": 1136.8365902146002
        },
        "internlm2_5-20b-chat": {
            "rating": 1150.7681444910563,
            "rating_q975": 1162.9210546664494,
            "rating_q025": 1138.6152343156632
        },
        "wizardlm-13b": {
            "rating": 1149.5272095752152,
            "rating_q975": 1164.7998234681888,
            "rating_q025": 1134.2545956822416
        },
        "gemma-1.1-7b-it": {
            "rating": 1147.7761613719722,
            "rating_q975": 1156.9466837641091,
            "rating_q025": 1138.6056389798352
        },
        "vicuna-13b": {
            "rating": 1141.3192253092711,
            "rating_q975": 1151.9625577965658,
            "rating_q025": 1130.6758928219765
        },
        "granite-3.0-8b-instruct": {
            "rating": 1141.268157131858,
            "rating_q975": 1156.7169115850486,
            "rating_q025": 1125.8194026786675
        },
        "llama-3.2-3b-instruct": {
            "rating": 1139.8210146913455,
            "rating_q975": 1153.7941696318665,
            "rating_q025": 1125.8478597508245
        },
        "nous-hermes-2-mixtral-8x7b-dpo": {
            "rating": 1138.6248835267534,
            "rating_q975": 1158.5979930532753,
            "rating_q025": 1118.6517740002314
        },
        "phi-3-small-8k-instruct": {
            "rating": 1138.3889307881282,
            "rating_q975": 1148.4297217287374,
            "rating_q025": 1128.348139847519
        },
        "starling-lm-7b-alpha": {
            "rating": 1137.3642758791625,
            "rating_q975": 1150.479022592857,
            "rating_q025": 1124.249529165468
        },
        "solar-10.7b-instruct-v1.0": {
            "rating": 1136.1455443618215,
            "rating_q975": 1157.089413516079,
            "rating_q025": 1115.201675207564
        },
        "mpt-30b-chat": {
            "rating": 1135.1802304416035,
            "rating_q975": 1157.8734931538268,
            "rating_q025": 1112.4869677293802
        },
        "dolphin-2.2.1-mistral-7b": {
            "rating": 1129.2282411248118,
            "rating_q975": 1158.0450367971207,
            "rating_q025": 1100.411445452503
        },
        "llama-2-70b-chat": {
            "rating": 1128.5235611551752,
            "rating_q975": 1137.0430726703514,
            "rating_q025": 1120.004049639999
        },
        "starling-lm-7b-beta": {
            "rating": 1127.0924626570131,
            "rating_q975": 1139.2458055461473,
            "rating_q025": 1114.939119767879
        },
        "granite-3.1-2b-instruct": {
            "rating": 1126.2128983225216,
            "rating_q975": 1147.3108056421408,
            "rating_q025": 1105.1149910029023
        },
        "llama2-70b-steerlm-chat": {
            "rating": 1125.9052535374708,
            "rating_q975": 1147.749415457366,
            "rating_q025": 1104.0610916175756
        },
        "zephyr-7b-alpha": {
            "rating": 1120.5248589516248,
            "rating_q975": 1145.8854779738926,
            "rating_q025": 1095.1642399293569
        },
        "guanaco-33b": {
            "rating": 1118.890947799699,
            "rating_q975": 1141.935559634785,
            "rating_q025": 1095.846335964613
        },
        "zephyr-7b-beta": {
            "rating": 1118.8659355084262,
            "rating_q975": 1132.7788976423558,
            "rating_q025": 1104.9529733744967
        },
        "qwen-14b-chat": {
            "rating": 1116.771638547251,
            "rating_q975": 1134.9025893426706,
            "rating_q025": 1098.6406877518316
        },
        "qwq-32b-preview": {
            "rating": 1115.8061607043942,
            "rating_q975": 1136.8575510725013,
            "rating_q025": 1094.754770336287
        },
        "vicuna-7b": {
            "rating": 1111.6262843929396,
            "rating_q975": 1126.7571646186173,
            "rating_q025": 1096.495404167262
        },
        "mistral-7b-instruct-v0.2": {
            "rating": 1111.4322696893732,
            "rating_q975": 1121.8991863153772,
            "rating_q025": 1100.9653530633693
        },
        "qwen1.5-7b-chat": {
            "rating": 1110.5846647092235,
            "rating_q975": 1128.711217393237,
            "rating_q025": 1092.45811202521
        },
        "granite-3.0-2b-instruct": {
            "rating": 1103.6413316036942,
            "rating_q975": 1119.1559366692663,
            "rating_q025": 1088.126726538122
        },
        "llama-2-13b-chat": {
            "rating": 1102.0425590836596,
            "rating_q975": 1112.6805581450476,
            "rating_q025": 1091.4045600222717
        },
        "codellama-34b-instruct": {
            "rating": 1100.928076115672,
            "rating_q975": 1115.4708715645154,
            "rating_q025": 1086.3852806668285
        },
        "phi-3-mini-4k-instruct-june-2024": {
            "rating": 1100.7193207387015,
            "rating_q975": 1111.9619452587272,
            "rating_q025": 1089.476696218676
        },
        "gemma-7b-it": {
            "rating": 1099.8645312232152,
            "rating_q975": 1114.531481843103,
            "rating_q025": 1085.1975806033274
        },
        "phi-3-mini-128k-instruct": {
            "rating": 1096.0340970493362,
            "rating_q975": 1107.9094545820535,
            "rating_q025": 1084.1587395166189
        },
        "mistral-7b-instruct": {
            "rating": 1091.4225626458533,
            "rating_q975": 1106.469068878131,
            "rating_q025": 1076.3760564135755
        },
        "phi-3-mini-4k-instruct": {
            "rating": 1091.151609236588,
            "rating_q975": 1101.527502088097,
            "rating_q025": 1080.775716385079
        },
        "palm-2": {
            "rating": 1090.586654304201,
            "rating_q975": 1105.6534570102444,
            "rating_q025": 1075.5198515981574
        },
        "stripedhyena-nous-7b": {
            "rating": 1089.4061171650312,
            "rating_q975": 1107.3817021112234,
            "rating_q025": 1071.430532218839
        },
        "gemma-1.1-2b-it": {
            "rating": 1085.7011613686843,
            "rating_q975": 1098.8170594742542,
            "rating_q025": 1072.5852632631145
        },
        "smollm2-1.7b-instruct": {
            "rating": 1077.0927979790963,
            "rating_q975": 1103.771969203451,
            "rating_q025": 1050.4136267547417
        },
        "llama-2-7b-chat": {
            "rating": 1074.1443423452383,
            "rating_q975": 1085.5193862968,
            "rating_q025": 1062.7692983936768
        },
        "llama-3.2-1b-instruct": {
            "rating": 1073.4179095949357,
            "rating_q975": 1088.4661649809523,
            "rating_q025": 1058.3696542089192
        },
        "qwen1.5-4b-chat": {
            "rating": 1072.629667087224,
            "rating_q975": 1087.532801420865,
            "rating_q025": 1057.7265327535831
        },
        "alpaca-13b": {
            "rating": 1072.1561057040735,
            "rating_q975": 1091.461592000093,
            "rating_q025": 1052.850619408054
        },
        "codellama-70b-instruct": {
            "rating": 1055.467410878462,
            "rating_q975": 1092.586319623535,
            "rating_q025": 1018.3485021333889
        },
        "gpt4all-13b-snoozy": {
            "rating": 1055.2825647044654,
            "rating_q975": 1086.962955927254,
            "rating_q025": 1023.6021734816767
        },
        "gemma-2b-it": {
            "rating": 1052.2531697179575,
            "rating_q975": 1070.9959905535306,
            "rating_q025": 1033.5103488823843
        },
        "mpt-7b-chat": {
            "rating": 1051.0372188047875,
            "rating_q975": 1071.9052414971325,
            "rating_q025": 1030.1691961124425
        },
        "koala-13b": {
            "rating": 1043.7011290414714,
            "rating_q975": 1061.569235973163,
            "rating_q025": 1025.83302210978
        },
        "chatglm3-6b": {
            "rating": 1037.9960055445554,
            "rating_q975": 1058.1833361267636,
            "rating_q025": 1017.8086749623473
        },
        "olmo-7b-instruct": {
            "rating": 1022.3641480389014,
            "rating_q975": 1040.5025674144563,
            "rating_q025": 1004.2257286633464
        },
        "chatglm2-6b": {
            "rating": 1012.489770830497,
            "rating_q975": 1034.9309978001472,
            "rating_q025": 990.0485438608468
        },
        "oasst-pythia-12b": {
            "rating": 1006.3311143104661,
            "rating_q975": 1024.1758888858838,
            "rating_q025": 988.4863397350484
        },
        "RWKV-4-Raven-14B": {
            "rating": 998.2839533426269,
            "rating_q975": 1017.7654387401072,
            "rating_q025": 978.8024679451465
        },
        "fastchat-t5-3b": {
            "rating": 991.3423469710629,
            "rating_q975": 1012.494096634084,
            "rating_q025": 970.1905973080417
        },
        "chatglm-6b": {
            "rating": 977.5285893901605,
            "rating_q975": 998.0799815710744,
            "rating_q025": 956.9771972092466
        },
        "dolly-v2-12b": {
            "rating": 967.4814390735473,
            "rating_q975": 990.8396655143923,
            "rating_q025": 944.1232126327023
        },
        "stablelm-tuned-alpha-7b": {
            "rating": 926.2498662714439,
            "rating_q975": 950.5943406848917,
            "rating_q025": 901.9053918579962
        },
        "llama-13b": {
            "rating": 919.1334631758214,
            "rating_q975": 948.0298519788815,
            "rating_q025": 890.2370743727612
        }
    },
    "japanese": {
        "gemini-3-pro": {
            "rating": 1476.408274874279,
            "rating_q975": 1522.5150900611864,
            "rating_q025": 1430.3014596873716
        },
        "grok-4.1-thinking": {
            "rating": 1474.160347536278,
            "rating_q975": 1520.1964633550504,
            "rating_q025": 1428.1242317175058
        },
        "grok-4.1": {
            "rating": 1460.156949217913,
            "rating_q975": 1506.5567817994072,
            "rating_q025": 1413.757116636419
        },
        "gemini-2.5-pro": {
            "rating": 1455.0581883894488,
            "rating_q975": 1472.7372690226077,
            "rating_q025": 1437.3791077562898
        },
        "gpt-5.1-high": {
            "rating": 1454.7755351679411,
            "rating_q975": 1502.6688581799124,
            "rating_q025": 1406.88221215597
        },
        "gpt-5-high": {
            "rating": 1441.7026636619578,
            "rating_q975": 1463.9777709258524,
            "rating_q025": 1419.4275563980632
        },
        "gpt-4.5-preview-2025-02-27": {
            "rating": 1441.2563801738722,
            "rating_q975": 1478.8310412976284,
            "rating_q025": 1403.681719050116
        },
        "gpt-5.1": {
            "rating": 1440.1597748482134,
            "rating_q975": 1489.2217260046841,
            "rating_q025": 1391.0978236917426
        },
        "o3-2025-04-16": {
            "rating": 1436.4379590558844,
            "rating_q975": 1454.3318247408963,
            "rating_q025": 1418.5440933708726
        },
        "gpt-5-chat": {
            "rating": 1425.2693633217248,
            "rating_q975": 1454.819031953287,
            "rating_q025": 1395.7196946901624
        },
        "chatgpt-4o-latest-20250326": {
            "rating": 1411.1143592972737,
            "rating_q975": 1431.0618989118614,
            "rating_q025": 1391.166819682686
        },
        "claude-opus-4-1-20250805-thinking-16k": {
            "rating": 1407.366033923626,
            "rating_q975": 1432.9926713765506,
            "rating_q025": 1381.7393964707014
        },
        "claude-opus-4-1-20250805": {
            "rating": 1406.534410334723,
            "rating_q975": 1427.7777164104295,
            "rating_q025": 1385.2911042590163
        },
        "kimi-k2-thinking-turbo": {
            "rating": 1406.2178894799265,
            "rating_q975": 1456.496805188163,
            "rating_q025": 1355.93897377169
        },
        "gemini-2.5-flash-preview-09-2025": {
            "rating": 1393.3469797200355,
            "rating_q975": 1430.3745707608546,
            "rating_q025": 1356.3193886792164
        },
        "gemini-2.5-flash": {
            "rating": 1390.173291839648,
            "rating_q975": 1406.839300078154,
            "rating_q025": 1373.507283601142
        },
        "glm-4.6": {
            "rating": 1389.143199247974,
            "rating_q975": 1431.051074611262,
            "rating_q025": 1347.235323884686
        },
        "glm-4.5": {
            "rating": 1386.6623555269337,
            "rating_q975": 1410.099332169128,
            "rating_q025": 1363.2253788847393
        },
        "grok-4-0709": {
            "rating": 1385.4037953630866,
            "rating_q975": 1405.5723369146676,
            "rating_q025": 1365.2352538115056
        },
        "qwen3-max-preview": {
            "rating": 1385.2882839174886,
            "rating_q975": 1416.009283769075,
            "rating_q025": 1354.5672840659022
        },
        "gpt-5-mini-high": {
            "rating": 1384.447803584027,
            "rating_q975": 1415.4276606766946,
            "rating_q025": 1353.4679464913595
        },
        "claude-opus-4-20250514-thinking-16k": {
            "rating": 1384.2970832839885,
            "rating_q975": 1405.8831934091886,
            "rating_q025": 1362.7109731587884
        },
        "o1-2024-12-17": {
            "rating": 1379.9281271247016,
            "rating_q975": 1405.0832147443584,
            "rating_q025": 1354.7730395050448
        },
        "qwen3-235b-a22b-instruct-2507": {
            "rating": 1379.6064794312076,
            "rating_q975": 1399.5969637599394,
            "rating_q025": 1359.6159951024758
        },
        "gemini-2.5-flash-lite-preview-09-2025-no-thinking": {
            "rating": 1379.2664225934222,
            "rating_q975": 1417.0258453412991,
            "rating_q025": 1341.5069998455454
        },
        "claude-sonnet-4-5-20250929": {
            "rating": 1378.8473170329823,
            "rating_q975": 1419.211832457844,
            "rating_q025": 1338.4828016081208
        },
        "claude-opus-4-20250514": {
            "rating": 1378.451484259563,
            "rating_q975": 1397.4837435364232,
            "rating_q025": 1359.4192249827026
        },
        "grok-3-preview-02-24": {
            "rating": 1375.835863497617,
            "rating_q975": 1396.6958173964576,
            "rating_q025": 1354.9759095987765
        },
        "deepseek-r1-0528": {
            "rating": 1375.8127304679547,
            "rating_q975": 1401.0069670540802,
            "rating_q025": 1350.6184938818292
        },
        "kimi-k2-0711-preview": {
            "rating": 1375.6473366882726,
            "rating_q975": 1395.4965738349927,
            "rating_q025": 1355.7980995415526
        },
        "deepseek-v3.1-thinking": {
            "rating": 1373.1184300009413,
            "rating_q975": 1410.1099607518358,
            "rating_q025": 1336.1268992500468
        },
        "deepseek-v3.1": {
            "rating": 1372.6379577087264,
            "rating_q975": 1404.9477238036268,
            "rating_q025": 1340.328191613826
        },
        "claude-sonnet-4-5-20250929-thinking-32k": {
            "rating": 1369.975790561345,
            "rating_q975": 1405.3501736510948,
            "rating_q025": 1334.6014074715954
        },
        "grok-4-fast-reasoning": {
            "rating": 1367.4231503603617,
            "rating_q975": 1411.0605228305526,
            "rating_q025": 1323.7857778901707
        },
        "qwen3-235b-a22b-no-thinking": {
            "rating": 1366.4462692625918,
            "rating_q975": 1387.2533155773115,
            "rating_q025": 1345.6392229478722
        },
        "qwen3-235b-a22b-thinking-2507": {
            "rating": 1363.398311241832,
            "rating_q975": 1392.3331723264425,
            "rating_q025": 1334.4634501572216
        },
        "claude-haiku-4-5-20251001": {
            "rating": 1362.596334787755,
            "rating_q975": 1403.6019978530328,
            "rating_q025": 1321.5906717224773
        },
        "mistral-medium-2508": {
            "rating": 1362.5115093740867,
            "rating_q975": 1387.614576352931,
            "rating_q025": 1337.4084423952424
        },
        "kimi-k2-0905-preview": {
            "rating": 1360.514542559415,
            "rating_q975": 1404.0173075381183,
            "rating_q025": 1317.0117775807119
        },
        "gemini-2.5-flash-lite-preview-06-17-thinking": {
            "rating": 1360.278307615286,
            "rating_q975": 1381.7650794858314,
            "rating_q025": 1338.7915357447405
        },
        "qwen3-next-80b-a3b-instruct": {
            "rating": 1359.958601472105,
            "rating_q975": 1395.1379631495338,
            "rating_q025": 1324.7792397946764
        },
        "o1-preview": {
            "rating": 1356.147745753502,
            "rating_q975": 1379.0722062883872,
            "rating_q025": 1333.2232852186169
        },
        "gpt-4.1-2025-04-14": {
            "rating": 1350.3577320098213,
            "rating_q975": 1369.1950529033293,
            "rating_q025": 1331.5204111163134
        },
        "o4-mini-2025-04-16": {
            "rating": 1348.1976486483413,
            "rating_q975": 1367.4631832495431,
            "rating_q025": 1328.9321140471395
        },
        "claude-3-7-sonnet-20250219-thinking-32k": {
            "rating": 1344.7403526348335,
            "rating_q975": 1364.0556600504026,
            "rating_q025": 1325.4250452192643
        },
        "mai-1-preview": {
            "rating": 1344.622700245301,
            "rating_q975": 1379.319709480378,
            "rating_q025": 1309.9256910102242
        },
        "hunyuan-turbos-20250416": {
            "rating": 1343.0538082131918,
            "rating_q975": 1374.9325458029596,
            "rating_q025": 1311.175070623424
        },
        "claude-sonnet-4-20250514": {
            "rating": 1342.2356491949445,
            "rating_q975": 1362.2123295922806,
            "rating_q025": 1322.2589687976083
        },
        "deepseek-r1": {
            "rating": 1340.8818758838997,
            "rating_q975": 1366.3619858787968,
            "rating_q025": 1315.4017658890027
        },
        "claude-sonnet-4-20250514-thinking-32k": {
            "rating": 1338.8052502492346,
            "rating_q975": 1360.6694851953937,
            "rating_q025": 1316.9410153030756
        },
        "claude-3-7-sonnet-20250219": {
            "rating": 1338.2524745367455,
            "rating_q975": 1357.403910763313,
            "rating_q025": 1319.101038310178
        },
        "deepseek-v3-0324": {
            "rating": 1337.5365002188685,
            "rating_q975": 1356.7312053433789,
            "rating_q025": 1318.341795094358
        },
        "grok-3-mini-beta": {
            "rating": 1330.384215299727,
            "rating_q975": 1354.3329367986548,
            "rating_q025": 1306.4354938007991
        },
        "qwen3-30b-a3b-instruct-2507": {
            "rating": 1330.1230315175828,
            "rating_q975": 1353.713883256539,
            "rating_q025": 1306.5321797786266
        },
        "qwen3-coder-480b-a35b-instruct": {
            "rating": 1327.702594131714,
            "rating_q975": 1348.0534258309297,
            "rating_q025": 1307.3517624324984
        },
        "deepseek-v3.2-exp": {
            "rating": 1326.6746246659154,
            "rating_q975": 1382.3547706042027,
            "rating_q025": 1270.9944787276281
        },
        "glm-4.5-air": {
            "rating": 1326.2244496954427,
            "rating_q975": 1347.6139645463725,
            "rating_q025": 1304.8349348445129
        },
        "gpt-4.1-mini-2025-04-14": {
            "rating": 1324.8740509491874,
            "rating_q975": 1344.575384048616,
            "rating_q025": 1305.172717849759
        },
        "gemini-2.0-flash-lite-preview-02-05": {
            "rating": 1324.642216927985,
            "rating_q975": 1349.2168162445982,
            "rating_q025": 1300.0676176113716
        },
        "gemini-1.5-pro-002": {
            "rating": 1322.0670639859102,
            "rating_q975": 1338.6577122413603,
            "rating_q025": 1305.47641573046
        },
        "mistral-medium-2505": {
            "rating": 1317.2077896961102,
            "rating_q975": 1337.4698146412563,
            "rating_q025": 1296.9457647509641
        },
        "qwen2.5-max": {
            "rating": 1317.0002541039737,
            "rating_q975": 1338.209889134547,
            "rating_q025": 1295.7906190734004
        },
        "o3-mini-high": {
            "rating": 1316.7216036544303,
            "rating_q975": 1346.673328687772,
            "rating_q025": 1286.7698786210885
        },
        "gpt-oss-120b": {
            "rating": 1314.813882562064,
            "rating_q975": 1341.805029508793,
            "rating_q025": 1287.822735615335
        },
        "grok-3-mini-high": {
            "rating": 1314.5735437842584,
            "rating_q975": 1341.6952984561067,
            "rating_q025": 1287.45178911241
        },
        "claude-3-5-sonnet-20241022": {
            "rating": 1313.844522551934,
            "rating_q975": 1327.0665112534903,
            "rating_q025": 1300.6225338503777
        },
        "gemma-3-27b-it": {
            "rating": 1313.3912753543786,
            "rating_q975": 1332.4610188386907,
            "rating_q025": 1294.3215318700666
        },
        "command-a-03-2025": {
            "rating": 1312.7857464737672,
            "rating_q975": 1330.9452642319886,
            "rating_q025": 1294.6262287155457
        },
        "gpt-4o-2024-05-13": {
            "rating": 1310.6062011534466,
            "rating_q975": 1324.1230555582622,
            "rating_q025": 1297.089346748631
        },
        "qwen3-235b-a22b": {
            "rating": 1307.965091153107,
            "rating_q975": 1330.7669948757348,
            "rating_q025": 1285.1631874304794
        },
        "gemini-2.0-flash-001": {
            "rating": 1303.852444187363,
            "rating_q975": 1322.6543881806838,
            "rating_q025": 1285.0505001940423
        },
        "o3-mini": {
            "rating": 1301.9807448270724,
            "rating_q975": 1318.1221454507133,
            "rating_q025": 1285.8393442034314
        },
        "gpt-4o-2024-08-06": {
            "rating": 1297.4773114662523,
            "rating_q975": 1315.0100605520445,
            "rating_q025": 1279.9445623804602
        },
        "gemma-3n-e4b-it": {
            "rating": 1296.4946533771363,
            "rating_q975": 1319.1519537890501,
            "rating_q025": 1273.8373529652224
        },
        "gemini-advanced-0514": {
            "rating": 1294.994296780941,
            "rating_q975": 1314.421430023134,
            "rating_q025": 1275.5671635387482
        },
        "deepseek-v3": {
            "rating": 1294.3466237264777,
            "rating_q975": 1317.379098916442,
            "rating_q025": 1271.3141485365134
        },
        "mistral-small-2506": {
            "rating": 1294.2800107135242,
            "rating_q975": 1319.595085564507,
            "rating_q025": 1268.9649358625416
        },
        "claude-3-5-sonnet-20240620": {
            "rating": 1292.4431042529623,
            "rating_q975": 1307.1156948367782,
            "rating_q025": 1277.7705136691463
        },
        "gemini-1.5-pro-001": {
            "rating": 1290.639525128899,
            "rating_q975": 1306.0542023849491,
            "rating_q025": 1275.224847872849
        },
        "qwen3-next-80b-a3b-thinking": {
            "rating": 1283.25028479893,
            "rating_q975": 1326.9203252910759,
            "rating_q025": 1239.580244306784
        },
        "nvidia-llama-3.3-nemotron-super-49b-v1.5": {
            "rating": 1282.8911780522199,
            "rating_q975": 1312.6039704525629,
            "rating_q025": 1253.1783856518769
        },
        "o1-mini": {
            "rating": 1282.2211802109146,
            "rating_q975": 1299.4427077018754,
            "rating_q025": 1264.9996527199537
        },
        "qwen-plus-0125": {
            "rating": 1280.9706436901536,
            "rating_q975": 1318.7346325714616,
            "rating_q025": 1243.2066548088455
        },
        "llama-3.1-405b-instruct-bf16": {
            "rating": 1278.8398125436684,
            "rating_q975": 1298.4019684928103,
            "rating_q025": 1259.2776565945264
        },
        "grok-2-2024-08-13": {
            "rating": 1275.704046675859,
            "rating_q975": 1290.980525049684,
            "rating_q025": 1260.427568302034
        },
        "gpt-4-1106-preview": {
            "rating": 1269.4235834858378,
            "rating_q975": 1286.4102101173066,
            "rating_q025": 1252.4369568543689
        },
        "claude-3-opus-20240229": {
            "rating": 1268.2025156334882,
            "rating_q975": 1280.6508796388864,
            "rating_q025": 1255.75415162809
        },
        "gemini-1.5-flash-002": {
            "rating": 1266.5234871983603,
            "rating_q975": 1287.4505876276794,
            "rating_q025": 1245.5963867690411
        },
        "longcat-flash-chat": {
            "rating": 1266.5077911540557,
            "rating_q975": 1311.2287281415431,
            "rating_q025": 1221.7868541665682
        },
        "gpt-oss-20b": {
            "rating": 1263.5195720777283,
            "rating_q975": 1303.8375006548356,
            "rating_q025": 1223.201643500621
        },
        "yi-lightning": {
            "rating": 1262.4031858117414,
            "rating_q975": 1285.5834657701107,
            "rating_q025": 1239.2229058533721
        },
        "llama-4-maverick-17b-128e-instruct": {
            "rating": 1261.6148286933285,
            "rating_q975": 1282.7696111989828,
            "rating_q025": 1240.4600461876742
        },
        "llama-4-scout-17b-16e-instruct": {
            "rating": 1261.1638834673588,
            "rating_q975": 1283.3241923593123,
            "rating_q025": 1239.0035745754053
        },
        "gpt-4-0125-preview": {
            "rating": 1258.086023956018,
            "rating_q975": 1275.1154584690373,
            "rating_q025": 1241.0565894429985
        },
        "gpt-4-turbo-2024-04-09": {
            "rating": 1257.3532756428772,
            "rating_q975": 1272.140812454526,
            "rating_q025": 1242.5657388312284
        },
        "gpt-4o-mini-2024-07-18": {
            "rating": 1255.6799766917184,
            "rating_q975": 1269.3994732097742,
            "rating_q025": 1241.9604801736625
        },
        "step-1o-turbo-202506": {
            "rating": 1255.2799933746633,
            "rating_q975": 1296.7827560356307,
            "rating_q025": 1213.7772307136959
        },
        "deepseek-v2.5-1210": {
            "rating": 1255.1997341234096,
            "rating_q975": 1296.195277877267,
            "rating_q025": 1214.2041903695522
        },
        "qwen3-30b-a3b": {
            "rating": 1254.0994205231327,
            "rating_q975": 1276.536844491004,
            "rating_q025": 1231.6619965552613
        },
        "claude-3-5-haiku-20241022": {
            "rating": 1252.5410025282217,
            "rating_q975": 1268.4733970207637,
            "rating_q025": 1236.6086080356797
        },
        "qwen-max-0919": {
            "rating": 1248.301107136282,
            "rating_q975": 1279.9327533952958,
            "rating_q025": 1216.6694608772684
        },
        "qwq-32b": {
            "rating": 1244.6875350904309,
            "rating_q975": 1269.8114126297567,
            "rating_q025": 1219.563657551105
        },
        "mistral-small-3.1-24b-instruct-2503": {
            "rating": 1244.4809973423949,
            "rating_q975": 1266.4186326569945,
            "rating_q025": 1222.5433620277952
        },
        "llama-3.1-405b-instruct-fp8": {
            "rating": 1243.7799922038294,
            "rating_q975": 1258.8769038182793,
            "rating_q025": 1228.6830805893794
        },
        "grok-2-mini-2024-08-13": {
            "rating": 1240.8197476899259,
            "rating_q975": 1257.425107152877,
            "rating_q025": 1224.2143882269747
        },
        "glm-4-plus": {
            "rating": 1240.3738710051798,
            "rating_q975": 1266.0604716341513,
            "rating_q025": 1214.6872703762083
        },
        "magistral-medium-2506": {
            "rating": 1238.5874390617882,
            "rating_q975": 1271.9514821501837,
            "rating_q025": 1205.2233959733928
        },
        "qwen2.5-plus-1127": {
            "rating": 1237.762677104855,
            "rating_q975": 1269.6492105143268,
            "rating_q025": 1205.876143695383
        },
        "athene-v2-chat": {
            "rating": 1237.2647668095242,
            "rating_q975": 1259.6683858386677,
            "rating_q025": 1214.8611477803806
        },
        "mistral-large-2407": {
            "rating": 1237.1768048617841,
            "rating_q975": 1253.4011933737734,
            "rating_q025": 1220.952416349795
        },
        "gpt-4.1-nano-2025-04-14": {
            "rating": 1235.9592971546203,
            "rating_q975": 1280.8827758299572,
            "rating_q025": 1191.0358184792835
        },
        "minimax-m1": {
            "rating": 1235.3845691610368,
            "rating_q975": 1257.2482051396184,
            "rating_q025": 1213.520933182455
        },
        "deepseek-v2.5": {
            "rating": 1234.5935971273623,
            "rating_q975": 1260.2290645196294,
            "rating_q025": 1208.958129735095
        },
        "gemma-2-27b-it": {
            "rating": 1233.3789462813543,
            "rating_q975": 1247.5433862974216,
            "rating_q025": 1219.214506265287
        },
        "amazon-nova-pro-v1.0": {
            "rating": 1232.2696478726098,
            "rating_q975": 1257.6524052603327,
            "rating_q025": 1206.8868904848869
        },
        "glm-4-plus-0111": {
            "rating": 1229.0733725936552,
            "rating_q975": 1267.0060236637505,
            "rating_q025": 1191.14072152356
        },
        "gemini-1.5-flash-001": {
            "rating": 1227.6665258110952,
            "rating_q975": 1244.1631372093568,
            "rating_q025": 1211.1699144128336
        },
        "command-r-plus": {
            "rating": 1225.5497511182548,
            "rating_q975": 1243.3081485361167,
            "rating_q025": 1207.7913537003928
        },
        "gpt-4-0314": {
            "rating": 1223.825577574944,
            "rating_q975": 1248.531157184238,
            "rating_q025": 1199.1199979656499
        },
        "llama-3.3-70b-instruct": {
            "rating": 1222.4934641510622,
            "rating_q975": 1240.109718957841,
            "rating_q025": 1204.8772093442833
        },
        "command-r-plus-08-2024": {
            "rating": 1221.925237074588,
            "rating_q975": 1259.2529755617102,
            "rating_q025": 1184.597498587466
        },
        "command-r-08-2024": {
            "rating": 1218.759873272075,
            "rating_q975": 1251.8772950496232,
            "rating_q025": 1185.642451494527
        },
        "mistral-large-2411": {
            "rating": 1218.364839574193,
            "rating_q975": 1240.251492621759,
            "rating_q025": 1196.4781865266268
        },
        "qwen2.5-72b-instruct": {
            "rating": 1215.8738857119952,
            "rating_q975": 1235.819001102363,
            "rating_q025": 1195.9287703216273
        },
        "c4ai-aya-expanse-32b": {
            "rating": 1212.3247510310632,
            "rating_q975": 1234.1515927454816,
            "rating_q025": 1190.4979093166448
        },
        "gpt-4-0613": {
            "rating": 1207.3389870219712,
            "rating_q975": 1225.8133999794982,
            "rating_q025": 1188.8645740644442
        },
        "claude-3-sonnet-20240229": {
            "rating": 1203.5685705475526,
            "rating_q975": 1220.241704775803,
            "rating_q025": 1186.895436319302
        },
        "deepseek-coder-v2": {
            "rating": 1200.9776067561818,
            "rating_q975": 1231.4126034089577,
            "rating_q025": 1170.5426101034059
        },
        "gemma-2-9b-it": {
            "rating": 1199.218512308596,
            "rating_q975": 1215.287098685227,
            "rating_q025": 1183.149925931965
        },
        "phi-4": {
            "rating": 1198.8779741859098,
            "rating_q975": 1225.0148392032675,
            "rating_q025": 1172.7411091685522
        },
        "gemma-2-9b-it-simpo": {
            "rating": 1192.91580515833,
            "rating_q975": 1225.0878801734275,
            "rating_q025": 1160.7437301432324
        },
        "athene-70b-0725": {
            "rating": 1189.677008350463,
            "rating_q975": 1211.617152734184,
            "rating_q025": 1167.736863966742
        },
        "amazon-nova-lite-v1.0": {
            "rating": 1188.5834568631735,
            "rating_q975": 1215.6701800492556,
            "rating_q025": 1161.4967336770915
        },
        "amazon-nova-micro-v1.0": {
            "rating": 1186.9849371791674,
            "rating_q975": 1213.5241629910715,
            "rating_q025": 1160.4457113672634
        },
        "nemotron-4-340b-instruct": {
            "rating": 1186.499730002709,
            "rating_q975": 1214.6281640358338,
            "rating_q025": 1158.371295969584
        },
        "jamba-1.5-large": {
            "rating": 1182.4428654649048,
            "rating_q975": 1218.8331423449245,
            "rating_q025": 1146.0525885848851
        },
        "qwen2-72b-instruct": {
            "rating": 1182.3765604307455,
            "rating_q975": 1202.2619457368053,
            "rating_q025": 1162.4911751246857
        },
        "llama-3.1-70b-instruct": {
            "rating": 1180.9905586059936,
            "rating_q975": 1196.4626439266692,
            "rating_q025": 1165.518473285318
        },
        "claude-3-haiku-20240307": {
            "rating": 1179.2085649930166,
            "rating_q975": 1194.43892665264,
            "rating_q025": 1163.9782033333931
        },
        "gemini-1.5-flash-8b-001": {
            "rating": 1176.9840301948518,
            "rating_q975": 1198.5017696389805,
            "rating_q025": 1155.4662907507231
        },
        "command-r": {
            "rating": 1169.3325902687586,
            "rating_q975": 1190.8432866666562,
            "rating_q025": 1147.821893870861
        },
        "c4ai-aya-expanse-8b": {
            "rating": 1160.4301719597988,
            "rating_q975": 1194.8297112577998,
            "rating_q025": 1126.0306326617979
        },
        "mistral-small-24b-instruct-2501": {
            "rating": 1154.902436076645,
            "rating_q975": 1191.3543287872974,
            "rating_q025": 1118.4505433659926
        },
        "gpt-3.5-turbo-0125": {
            "rating": 1148.5477435071514,
            "rating_q975": 1169.3199328125645,
            "rating_q025": 1127.7755542017383
        },
        "reka-flash-21b-20240226-online": {
            "rating": 1144.778421842629,
            "rating_q975": 1179.606723477215,
            "rating_q025": 1109.9501202080432
        },
        "qwen1.5-110b-chat": {
            "rating": 1142.5694328384686,
            "rating_q975": 1168.569954640071,
            "rating_q025": 1116.5689110368662
        },
        "qwen1.5-72b-chat": {
            "rating": 1137.0417043163932,
            "rating_q975": 1164.1208056207636,
            "rating_q025": 1109.9626030120228
        },
        "gemma-2-2b-it": {
            "rating": 1125.208982873469,
            "rating_q975": 1142.5436345260566,
            "rating_q025": 1107.8743312208815
        },
        "reka-flash-21b-20240226": {
            "rating": 1124.373432440685,
            "rating_q975": 1153.027610367096,
            "rating_q025": 1095.719254514274
        },
        "phi-3-medium-4k-instruct": {
            "rating": 1121.9184579234384,
            "rating_q975": 1145.189345946554,
            "rating_q025": 1098.6475699003227
        },
        "mixtral-8x22b-instruct-v0.1": {
            "rating": 1115.308513567444,
            "rating_q975": 1135.4375926517407,
            "rating_q025": 1095.1794344831471
        },
        "gemini-pro-dev-api": {
            "rating": 1110.7176988032484,
            "rating_q975": 1155.692219767267,
            "rating_q025": 1065.7431778392297
        },
        "qwen1.5-32b-chat": {
            "rating": 1107.0155943945922,
            "rating_q975": 1140.1001947327695,
            "rating_q025": 1073.9309940564149
        },
        "llama-3.1-8b-instruct": {
            "rating": 1093.0555522145778,
            "rating_q975": 1110.9276143975644,
            "rating_q025": 1075.1834900315912
        },
        "qwen1.5-14b-chat": {
            "rating": 1091.4358546213853,
            "rating_q975": 1131.3294959674645,
            "rating_q025": 1051.542213275306
        },
        "llama-3-70b-instruct": {
            "rating": 1088.4502544684233,
            "rating_q975": 1102.5391727878095,
            "rating_q025": 1074.361336149037
        },
        "mistral-large-2402": {
            "rating": 1087.1473219559207,
            "rating_q975": 1108.6080271463475,
            "rating_q025": 1065.686616765494
        },
        "dbrx-instruct-preview": {
            "rating": 1085.019730124405,
            "rating_q975": 1114.7266852768862,
            "rating_q025": 1055.3127749719238
        },
        "jamba-1.5-mini": {
            "rating": 1083.1592845107648,
            "rating_q975": 1118.2102631417229,
            "rating_q025": 1048.1083058798067
        },
        "yi-1.5-34b-chat": {
            "rating": 1083.1571703611346,
            "rating_q975": 1109.9247748589066,
            "rating_q025": 1056.3895658633626
        },
        "mistral-medium": {
            "rating": 1078.2415308233853,
            "rating_q975": 1111.518169656187,
            "rating_q025": 1044.9648919905837
        },
        "yi-34b-chat": {
            "rating": 1063.2515452401612,
            "rating_q975": 1106.1010826355314,
            "rating_q025": 1020.402007844791
        },
        "gemma-1.1-7b-it": {
            "rating": 1054.9649474874655,
            "rating_q975": 1084.0255926114903,
            "rating_q025": 1025.9043023634406
        },
        "snowflake-arctic-instruct": {
            "rating": 1049.8901422238512,
            "rating_q975": 1074.0606995814683,
            "rating_q025": 1025.719584866234
        },
        "starling-lm-7b-beta": {
            "rating": 1047.3144178048392,
            "rating_q975": 1091.0280106461246,
            "rating_q025": 1003.6008249635538
        },
        "llama-3-8b-instruct": {
            "rating": 1041.6044150704201,
            "rating_q975": 1058.1404577302621,
            "rating_q025": 1025.0683724105781
        },
        "phi-3-small-8k-instruct": {
            "rating": 1040.3042690892166,
            "rating_q975": 1071.1399617509928,
            "rating_q025": 1009.4685764274404
        },
        "phi-3-mini-4k-instruct-june-2024": {
            "rating": 1033.2227045062455,
            "rating_q975": 1065.892388943198,
            "rating_q025": 1000.5530200692928
        },
        "vicuna-33b": {
            "rating": 1030.9199566872426,
            "rating_q975": 1071.9327773899922,
            "rating_q025": 989.9071359844929
        },
        "mixtral-8x7b-instruct-v0.1": {
            "rating": 1009.8686505575854,
            "rating_q975": 1031.3449321085682,
            "rating_q025": 988.3923690066026
        },
        "vicuna-13b": {
            "rating": 1008.374061044646,
            "rating_q975": 1061.196325412596,
            "rating_q025": 955.5517966766961
        },
        "phi-3-mini-4k-instruct": {
            "rating": 1006.3838722328009,
            "rating_q975": 1039.8588783926327,
            "rating_q025": 972.908866072969
        },
        "llama-2-70b-chat": {
            "rating": 997.1266765224524,
            "rating_q975": 1029.8515713671118,
            "rating_q025": 964.401781677793
        },
        "phi-3-mini-128k-instruct": {
            "rating": 987.5782828297304,
            "rating_q975": 1018.9439956942823,
            "rating_q025": 956.2125699651784
        },
        "llama-2-13b-chat": {
            "rating": 967.9566364455188,
            "rating_q975": 1017.0585702872008,
            "rating_q025": 918.8547026038368
        },
        "mistral-7b-instruct-v0.2": {
            "rating": 950.3324572626838,
            "rating_q975": 996.75480937045,
            "rating_q025": 903.9101051549176
        }
    },
    "korean": {
        "gemini-3-pro": {
            "rating": 1460.5017437311615,
            "rating_q975": 1504.2172006426176,
            "rating_q025": 1416.7862868197053
        },
        "gpt-5.1": {
            "rating": 1446.0479340702766,
            "rating_q975": 1488.8272367310562,
            "rating_q025": 1403.268631409497
        },
        "grok-4.1-thinking": {
            "rating": 1443.9453913849736,
            "rating_q975": 1482.656763544396,
            "rating_q025": 1405.2340192255513
        },
        "claude-opus-4-5-20251101": {
            "rating": 1435.7366763209948,
            "rating_q975": 1486.3859710982629,
            "rating_q025": 1385.0873815437267
        },
        "gemini-2.5-pro": {
            "rating": 1424.3166046308636,
            "rating_q975": 1441.9578073325179,
            "rating_q025": 1406.6754019292093
        },
        "grok-4.1": {
            "rating": 1410.2203997878628,
            "rating_q975": 1449.4259980945478,
            "rating_q025": 1371.0148014811778
        },
        "claude-opus-4-1-20250805-thinking-16k": {
            "rating": 1408.9494336412686,
            "rating_q975": 1430.425915572173,
            "rating_q025": 1387.4729517103642
        },
        "gpt-4.5-preview-2025-02-27": {
            "rating": 1406.6255505319448,
            "rating_q975": 1449.1657659559844,
            "rating_q025": 1364.0853351079052
        },
        "o1-2024-12-17": {
            "rating": 1403.9497618518926,
            "rating_q975": 1433.913343711651,
            "rating_q025": 1373.9861799921343
        },
        "chatgpt-4o-latest-20250326": {
            "rating": 1402.766647900102,
            "rating_q975": 1423.0430836667902,
            "rating_q025": 1382.490212133414
        },
        "gpt-5.1-high": {
            "rating": 1402.4964137405148,
            "rating_q975": 1443.2153901767722,
            "rating_q025": 1361.7774373042573
        },
        "gpt-5-high": {
            "rating": 1397.8298479768785,
            "rating_q975": 1421.3912838929336,
            "rating_q025": 1374.2684120608233
        },
        "claude-opus-4-5-20251101-thinking-32k": {
            "rating": 1397.7482590196335,
            "rating_q975": 1450.722250056633,
            "rating_q025": 1344.774267982634
        },
        "claude-sonnet-4-5-20250929": {
            "rating": 1394.7287254376938,
            "rating_q975": 1428.7467915021014,
            "rating_q025": 1360.7106593732863
        },
        "claude-sonnet-4-5-20250929-thinking-32k": {
            "rating": 1390.0359780536664,
            "rating_q975": 1419.8734004846415,
            "rating_q025": 1360.1985556226914
        },
        "claude-opus-4-1-20250805": {
            "rating": 1387.422846847108,
            "rating_q975": 1406.6432585318696,
            "rating_q025": 1368.2024351623465
        },
        "o3-2025-04-16": {
            "rating": 1384.0605043784117,
            "rating_q975": 1403.0849931284465,
            "rating_q025": 1365.0360156283768
        },
        "hunyuan-t1-20250711": {
            "rating": 1374.618457272165,
            "rating_q975": 1418.7190602543083,
            "rating_q025": 1330.5178542900217
        },
        "gemini-2.5-flash-preview-09-2025": {
            "rating": 1372.8364199835048,
            "rating_q975": 1400.2017511197196,
            "rating_q025": 1345.47108884729
        },
        "qwen3-235b-a22b-instruct-2507": {
            "rating": 1372.7793740650975,
            "rating_q975": 1393.605536431185,
            "rating_q025": 1351.95321169901
        },
        "gpt-4.1-2025-04-14": {
            "rating": 1371.4149106757634,
            "rating_q975": 1391.2996047627184,
            "rating_q025": 1351.5302165888083
        },
        "gpt-5-chat": {
            "rating": 1371.2583968975998,
            "rating_q975": 1394.1508549052382,
            "rating_q025": 1348.3659388899614
        },
        "claude-opus-4-20250514-thinking-16k": {
            "rating": 1370.1700498615605,
            "rating_q975": 1393.4781276140236,
            "rating_q025": 1346.8619721090975
        },
        "glm-4.6": {
            "rating": 1370.1065578798853,
            "rating_q975": 1402.9846670282222,
            "rating_q025": 1337.2284487315483
        },
        "qwen3-vl-235b-a22b-instruct": {
            "rating": 1370.0684295666688,
            "rating_q975": 1407.8379435291256,
            "rating_q025": 1332.298915604212
        },
        "qwen3-max-preview": {
            "rating": 1368.9343733242795,
            "rating_q975": 1393.3480329005986,
            "rating_q025": 1344.5207137479604
        },
        "gemini-2.5-flash": {
            "rating": 1366.8819781684326,
            "rating_q975": 1384.6534470380727,
            "rating_q025": 1349.1105092987925
        },
        "grok-4-0709": {
            "rating": 1364.635276336666,
            "rating_q975": 1386.7750825347796,
            "rating_q025": 1342.4954701385525
        },
        "qwen3-max-2025-09-23": {
            "rating": 1364.2259038059824,
            "rating_q975": 1401.7693475706787,
            "rating_q025": 1326.682460041286
        },
        "claude-opus-4-20250514": {
            "rating": 1359.203953202982,
            "rating_q975": 1379.0307069051196,
            "rating_q025": 1339.3771995008442
        },
        "qwen3-235b-a22b-no-thinking": {
            "rating": 1359.0157425863483,
            "rating_q975": 1382.8654682905888,
            "rating_q025": 1335.166016882108
        },
        "gemini-2.5-flash-lite-preview-06-17-thinking": {
            "rating": 1357.1072518316564,
            "rating_q975": 1380.6943045185792,
            "rating_q025": 1333.5201991447336
        },
        "qwen3-vl-235b-a22b-thinking": {
            "rating": 1355.779366725106,
            "rating_q975": 1397.0442299346023,
            "rating_q025": 1314.5145035156097
        },
        "o4-mini-2025-04-16": {
            "rating": 1350.6847568191988,
            "rating_q975": 1371.176324568793,
            "rating_q025": 1330.1931890696046
        },
        "glm-4.5": {
            "rating": 1348.4260514123705,
            "rating_q975": 1373.603787981328,
            "rating_q025": 1323.248314843413
        },
        "grok-4-fast-reasoning": {
            "rating": 1347.4658361499137,
            "rating_q975": 1381.2769219565562,
            "rating_q025": 1313.6547503432712
        },
        "deepseek-r1": {
            "rating": 1346.944361963643,
            "rating_q975": 1386.1182727497471,
            "rating_q025": 1307.7704511775387
        },
        "hunyuan-turbos-20250416": {
            "rating": 1345.1692213110166,
            "rating_q975": 1396.2416362832216,
            "rating_q025": 1294.0968063388116
        },
        "claude-sonnet-4-20250514": {
            "rating": 1344.6100819142134,
            "rating_q975": 1365.5341457620857,
            "rating_q025": 1323.6860180663411
        },
        "kimi-k2-0905-preview": {
            "rating": 1344.460616264306,
            "rating_q975": 1380.9913573602955,
            "rating_q025": 1307.9298751683166
        },
        "grok-3-preview-02-24": {
            "rating": 1344.1444297509458,
            "rating_q975": 1371.6249226249706,
            "rating_q025": 1316.663936876921
        },
        "gemini-2.5-flash-lite-preview-09-2025-no-thinking": {
            "rating": 1343.6539010322774,
            "rating_q975": 1372.7946695521869,
            "rating_q025": 1314.513132512368
        },
        "o1-preview": {
            "rating": 1340.9148107907333,
            "rating_q975": 1368.1842341931842,
            "rating_q025": 1313.6453873882824
        },
        "qwen3-235b-a22b-thinking-2507": {
            "rating": 1340.6951417471637,
            "rating_q975": 1382.9772696960774,
            "rating_q025": 1298.41301379825
        },
        "gpt-4.1-mini-2025-04-14": {
            "rating": 1338.2439316296052,
            "rating_q975": 1360.5576438279825,
            "rating_q025": 1315.930219431228
        },
        "gemini-2.0-flash-lite-preview-02-05": {
            "rating": 1337.7716293229175,
            "rating_q975": 1368.520549829339,
            "rating_q025": 1307.022708816496
        },
        "deepseek-v3.1-thinking": {
            "rating": 1337.5784452748694,
            "rating_q975": 1370.1202495072544,
            "rating_q025": 1305.0366410424845
        },
        "mistral-medium-2508": {
            "rating": 1336.5081708428895,
            "rating_q975": 1356.5019676859436,
            "rating_q025": 1316.5143739998355
        },
        "deepseek-v3.2-exp-thinking": {
            "rating": 1335.082786086006,
            "rating_q975": 1379.480878033985,
            "rating_q025": 1290.6846941380272
        },
        "deepseek-v3.2-exp": {
            "rating": 1334.760728479507,
            "rating_q975": 1384.0811272939088,
            "rating_q025": 1285.440329665105
        },
        "deepseek-v3.1": {
            "rating": 1334.0118257272036,
            "rating_q975": 1361.4171552024384,
            "rating_q025": 1306.6064962519688
        },
        "grok-4-fast-chat": {
            "rating": 1333.3360920073026,
            "rating_q975": 1374.0006914740652,
            "rating_q025": 1292.67149254054
        },
        "claude-sonnet-4-20250514-thinking-32k": {
            "rating": 1332.0237588681782,
            "rating_q975": 1355.528872531323,
            "rating_q025": 1308.5186452050334
        },
        "deepseek-r1-0528": {
            "rating": 1329.5183470652694,
            "rating_q975": 1364.7975375289648,
            "rating_q025": 1294.239156601574
        },
        "gpt-5-mini-high": {
            "rating": 1328.2046654443695,
            "rating_q975": 1353.8654378578601,
            "rating_q025": 1302.543893030879
        },
        "mai-1-preview": {
            "rating": 1327.7404635762705,
            "rating_q975": 1355.5385631502686,
            "rating_q025": 1299.9423640022724
        },
        "kimi-k2-0711-preview": {
            "rating": 1327.4792466866238,
            "rating_q975": 1352.6291867660402,
            "rating_q025": 1302.3293066072074
        },
        "kimi-k2-thinking-turbo": {
            "rating": 1326.0715772146204,
            "rating_q975": 1370.4041424470279,
            "rating_q025": 1281.739011982213
        },
        "grok-3-mini-high": {
            "rating": 1325.934767395469,
            "rating_q975": 1359.9606271532432,
            "rating_q025": 1291.9089076376947
        },
        "claude-haiku-4-5-20251001": {
            "rating": 1324.5556187387085,
            "rating_q975": 1358.5773323869205,
            "rating_q025": 1290.5339050904965
        },
        "o3-mini-high": {
            "rating": 1324.283544261711,
            "rating_q975": 1363.6737700314363,
            "rating_q025": 1284.8933184919858
        },
        "claude-3-7-sonnet-20250219-thinking-32k": {
            "rating": 1323.743294783699,
            "rating_q975": 1346.3119182231458,
            "rating_q025": 1301.1746713442521
        },
        "claude-3-7-sonnet-20250219": {
            "rating": 1322.0545565954903,
            "rating_q975": 1345.4125361499505,
            "rating_q025": 1298.6965770410302
        },
        "gemini-1.5-pro-002": {
            "rating": 1321.1333108708068,
            "rating_q975": 1342.9816458257276,
            "rating_q025": 1299.284975915886
        },
        "qwen3-235b-a22b": {
            "rating": 1319.6954085230032,
            "rating_q975": 1346.634269858585,
            "rating_q025": 1292.7565471874213
        },
        "gemini-2.0-flash-001": {
            "rating": 1317.72705800146,
            "rating_q975": 1340.357217253372,
            "rating_q025": 1295.0968987495478
        },
        "deepseek-v3-0324": {
            "rating": 1317.3598654013704,
            "rating_q975": 1337.7495511093196,
            "rating_q025": 1296.9701796934212
        },
        "gemma-3-27b-it": {
            "rating": 1316.4113542650996,
            "rating_q975": 1337.4674576037532,
            "rating_q025": 1295.355250926446
        },
        "longcat-flash-chat": {
            "rating": 1315.4643502091546,
            "rating_q975": 1350.9370320563255,
            "rating_q025": 1279.9916683619838
        },
        "qwen3-next-80b-a3b-instruct": {
            "rating": 1315.1245814218237,
            "rating_q975": 1344.3676272115454,
            "rating_q025": 1285.881535632102
        },
        "qwen2.5-max": {
            "rating": 1310.6009272893273,
            "rating_q975": 1337.4422419583484,
            "rating_q025": 1283.7596126203061
        },
        "qwen3-30b-a3b-instruct-2507": {
            "rating": 1308.7405131100572,
            "rating_q975": 1335.0390367823352,
            "rating_q025": 1282.4419894377793
        },
        "qwen3-coder-480b-a35b-instruct": {
            "rating": 1308.7350261881616,
            "rating_q975": 1336.2660507666924,
            "rating_q025": 1281.2040016096307
        },
        "command-a-03-2025": {
            "rating": 1307.6119397636412,
            "rating_q975": 1326.6530547310952,
            "rating_q025": 1288.5708247961873
        },
        "mistral-medium-2505": {
            "rating": 1302.7965547703143,
            "rating_q975": 1326.6784797372736,
            "rating_q025": 1278.914629803355
        },
        "amazon-nova-experimental-chat-10-09": {
            "rating": 1302.3801966717635,
            "rating_q975": 1352.9325306380197,
            "rating_q025": 1251.8278627055074
        },
        "claude-3-5-sonnet-20241022": {
            "rating": 1297.3940250816913,
            "rating_q975": 1314.9262003703404,
            "rating_q025": 1279.8618497930422
        },
        "qwen3-next-80b-a3b-thinking": {
            "rating": 1291.477018590068,
            "rating_q975": 1326.6809669769498,
            "rating_q025": 1256.273070203186
        },
        "gpt-4o-2024-05-13": {
            "rating": 1290.942703081821,
            "rating_q975": 1305.8046377444932,
            "rating_q025": 1276.0807684191489
        },
        "o3-mini": {
            "rating": 1288.4496778592552,
            "rating_q975": 1307.0896020155324,
            "rating_q025": 1269.809753702978
        },
        "ling-flash-2.0": {
            "rating": 1287.3764806703557,
            "rating_q975": 1328.1237226393512,
            "rating_q025": 1246.6292387013602
        },
        "gpt-4o-2024-08-06": {
            "rating": 1286.0305166941837,
            "rating_q975": 1308.8863825964238,
            "rating_q025": 1263.1746507919436
        },
        "claude-3-5-sonnet-20240620": {
            "rating": 1282.8167276149563,
            "rating_q975": 1300.176624899076,
            "rating_q025": 1265.4568303308367
        },
        "grok-3-mini-beta": {
            "rating": 1282.7302924282624,
            "rating_q975": 1311.950274307633,
            "rating_q025": 1253.5103105488918
        },
        "gpt-oss-20b": {
            "rating": 1281.1587440455346,
            "rating_q975": 1321.9618288531126,
            "rating_q025": 1240.3556592379566
        },
        "gemini-advanced-0514": {
            "rating": 1279.2685916409787,
            "rating_q975": 1297.806108754579,
            "rating_q025": 1260.7310745273783
        },
        "glm-4.5-air": {
            "rating": 1279.1066838385634,
            "rating_q975": 1304.365962269025,
            "rating_q025": 1253.8474054081018
        },
        "glm-4-plus": {
            "rating": 1277.0113969780118,
            "rating_q975": 1307.1589778759458,
            "rating_q025": 1246.8638160800779
        },
        "deepseek-v3": {
            "rating": 1275.8623097338868,
            "rating_q975": 1309.6341462352852,
            "rating_q025": 1242.0904732324884
        },
        "mistral-small-2506": {
            "rating": 1274.3209440357855,
            "rating_q975": 1306.396522961528,
            "rating_q025": 1242.245365110043
        },
        "grok-2-2024-08-13": {
            "rating": 1272.1905935367781,
            "rating_q975": 1292.2386738391701,
            "rating_q025": 1252.1425132343861
        },
        "gemma-3n-e4b-it": {
            "rating": 1269.9920289781976,
            "rating_q975": 1297.334949383534,
            "rating_q025": 1242.6491085728612
        },
        "llama-4-scout-17b-16e-instruct": {
            "rating": 1268.4544949187487,
            "rating_q975": 1293.8766143256912,
            "rating_q025": 1243.032375511806
        },
        "claude-3-opus-20240229": {
            "rating": 1266.9624990831628,
            "rating_q975": 1281.4711193018873,
            "rating_q025": 1252.4538788644384
        },
        "gemini-1.5-pro-001": {
            "rating": 1266.6694038300075,
            "rating_q975": 1283.1019426807004,
            "rating_q025": 1250.2368649793145
        },
        "gpt-5-nano-high": {
            "rating": 1264.89766102485,
            "rating_q975": 1307.9997888929952,
            "rating_q025": 1221.795533156705
        },
        "llama-4-maverick-17b-128e-instruct": {
            "rating": 1260.3781132630593,
            "rating_q975": 1282.146141549554,
            "rating_q025": 1238.6100849765646
        },
        "minimax-m1": {
            "rating": 1259.2855459579334,
            "rating_q975": 1284.597109669014,
            "rating_q025": 1233.973982246853
        },
        "qwen3-30b-a3b": {
            "rating": 1257.6694271433246,
            "rating_q975": 1285.4213976196968,
            "rating_q025": 1229.9174566669524
        },
        "gpt-4-turbo-2024-04-09": {
            "rating": 1257.629141281144,
            "rating_q975": 1273.7476629015719,
            "rating_q025": 1241.5106196607162
        },
        "claude-3-5-haiku-20241022": {
            "rating": 1257.5830292255441,
            "rating_q975": 1276.144519218151,
            "rating_q025": 1239.0215392329374
        },
        "gpt-oss-120b": {
            "rating": 1257.1210150554361,
            "rating_q975": 1282.3619084851387,
            "rating_q025": 1231.8801216257336
        },
        "qwq-32b": {
            "rating": 1256.3850224908822,
            "rating_q975": 1286.1167342164852,
            "rating_q025": 1226.6533107652792
        },
        "mistral-large-2411": {
            "rating": 1255.4314767186029,
            "rating_q975": 1283.2643866766498,
            "rating_q025": 1227.598566760556
        },
        "llama-3.1-405b-instruct-fp8": {
            "rating": 1253.3632829349217,
            "rating_q975": 1273.31595473219,
            "rating_q025": 1233.4106111376534
        },
        "o1-mini": {
            "rating": 1249.6794415504698,
            "rating_q975": 1271.6915257172493,
            "rating_q025": 1227.6673573836904
        },
        "gpt-4-1106-preview": {
            "rating": 1248.4507321100682,
            "rating_q975": 1267.3897271020107,
            "rating_q025": 1229.5117371181257
        },
        "deepseek-v2.5": {
            "rating": 1247.8436516849688,
            "rating_q975": 1278.805306779026,
            "rating_q025": 1216.8819965909115
        },
        "command-r-08-2024": {
            "rating": 1247.238789271545,
            "rating_q975": 1296.2881754089294,
            "rating_q025": 1198.1894031341608
        },
        "step-3": {
            "rating": 1245.7222667412973,
            "rating_q975": 1290.968657617064,
            "rating_q025": 1200.4758758655305
        },
        "gemini-1.5-flash-001": {
            "rating": 1242.4923569942162,
            "rating_q975": 1259.2980868390337,
            "rating_q025": 1225.6866271493986
        },
        "gpt-4-0125-preview": {
            "rating": 1241.8588177795307,
            "rating_q975": 1260.552403869949,
            "rating_q025": 1223.1652316891123
        },
        "mistral-small-24b-instruct-2501": {
            "rating": 1237.211909214481,
            "rating_q975": 1275.7772075025111,
            "rating_q025": 1198.6466109264509
        },
        "llama-3.1-405b-instruct-bf16": {
            "rating": 1237.109075181665,
            "rating_q975": 1261.0310077115412,
            "rating_q025": 1213.187142651789
        },
        "gpt-4o-mini-2024-07-18": {
            "rating": 1235.9589596120932,
            "rating_q975": 1254.673215665995,
            "rating_q025": 1217.2447035581913
        },
        "gemini-1.5-flash-002": {
            "rating": 1234.8530656888247,
            "rating_q975": 1261.0380433198877,
            "rating_q025": 1208.6680880577617
        },
        "ring-flash-2.0": {
            "rating": 1233.8026489145936,
            "rating_q975": 1276.1945349279424,
            "rating_q025": 1191.4107629012449
        },
        "mistral-small-3.1-24b-instruct-2503": {
            "rating": 1232.4958700690522,
            "rating_q975": 1257.5925814185623,
            "rating_q025": 1207.3991587195421
        },
        "gemma-2-27b-it": {
            "rating": 1230.14197726158,
            "rating_q975": 1247.0547810168475,
            "rating_q025": 1213.2291735063125
        },
        "yi-lightning": {
            "rating": 1229.2724760918566,
            "rating_q975": 1258.0833857023783,
            "rating_q025": 1200.4615664813348
        },
        "amazon-nova-pro-v1.0": {
            "rating": 1227.0843907475914,
            "rating_q975": 1258.1730250381,
            "rating_q025": 1195.995756457083
        },
        "qwen2.5-72b-instruct": {
            "rating": 1226.2916103658815,
            "rating_q975": 1252.1832950044827,
            "rating_q025": 1200.3999257272803
        },
        "mistral-large-2407": {
            "rating": 1226.1404103920768,
            "rating_q975": 1248.0482419950993,
            "rating_q025": 1204.2325787890543
        },
        "athene-v2-chat": {
            "rating": 1226.013890049,
            "rating_q975": 1257.7491858155947,
            "rating_q025": 1194.2785942824055
        },
        "grok-2-mini-2024-08-13": {
            "rating": 1225.4843298808298,
            "rating_q975": 1246.9226915304178,
            "rating_q025": 1204.045968231242
        },
        "claude-3-sonnet-20240229": {
            "rating": 1220.2611593782212,
            "rating_q975": 1237.4678685224922,
            "rating_q025": 1203.0544502339503
        },
        "nemotron-4-340b-instruct": {
            "rating": 1217.7137741491956,
            "rating_q975": 1242.587625474488,
            "rating_q025": 1192.8399228239032
        },
        "command-r-plus": {
            "rating": 1212.0922084433303,
            "rating_q975": 1229.9032165900107,
            "rating_q025": 1194.2812002966498
        },
        "llama-3.3-70b-instruct": {
            "rating": 1208.4040004845024,
            "rating_q975": 1228.7796613554049,
            "rating_q025": 1188.0283396135999
        },
        "athene-70b-0725": {
            "rating": 1207.1779114647682,
            "rating_q975": 1237.1462511258994,
            "rating_q025": 1177.209571803637
        },
        "claude-3-haiku-20240307": {
            "rating": 1206.2506963401097,
            "rating_q975": 1222.6783218259716,
            "rating_q025": 1189.8230708542478
        },
        "c4ai-aya-expanse-32b": {
            "rating": 1204.9814273803709,
            "rating_q975": 1233.8987094271338,
            "rating_q025": 1176.064145333608
        },
        "magistral-medium-2506": {
            "rating": 1202.819129190463,
            "rating_q975": 1251.0637848981323,
            "rating_q025": 1154.5744734827936
        },
        "deepseek-coder-v2": {
            "rating": 1198.2018443171569,
            "rating_q975": 1228.1919085050035,
            "rating_q025": 1168.2117801293102
        },
        "gemma-2-9b-it": {
            "rating": 1196.517852051701,
            "rating_q975": 1215.453104616203,
            "rating_q025": 1177.582599487199
        },
        "gpt-4-0314": {
            "rating": 1192.922872508459,
            "rating_q975": 1222.514975425758,
            "rating_q025": 1163.33076959116
        },
        "phi-4": {
            "rating": 1191.076722163088,
            "rating_q975": 1223.7581157588595,
            "rating_q025": 1158.3953285673167
        },
        "reka-flash-21b-20240226-online": {
            "rating": 1187.2516361089738,
            "rating_q975": 1220.8926954222281,
            "rating_q025": 1153.6105767957195
        },
        "amazon-nova-micro-v1.0": {
            "rating": 1187.168330173718,
            "rating_q975": 1221.9399211848547,
            "rating_q025": 1152.3967391625813
        },
        "llama-3.1-70b-instruct": {
            "rating": 1186.4785984078194,
            "rating_q975": 1207.3080660247138,
            "rating_q025": 1165.649130790925
        },
        "qwen-max-0919": {
            "rating": 1186.3306636444895,
            "rating_q975": 1220.7658490435867,
            "rating_q025": 1151.8954782453923
        },
        "command-r": {
            "rating": 1182.8108828919644,
            "rating_q975": 1202.607081490933,
            "rating_q025": 1163.0146842929958
        },
        "gemini-1.5-flash-8b-001": {
            "rating": 1181.797121407667,
            "rating_q975": 1208.1143553276086,
            "rating_q025": 1155.4798874877254
        },
        "amazon-nova-lite-v1.0": {
            "rating": 1180.382373321193,
            "rating_q975": 1213.8653977719928,
            "rating_q025": 1146.8993488703932
        },
        "gpt-4-0613": {
            "rating": 1173.1107761052476,
            "rating_q975": 1193.3208695130136,
            "rating_q025": 1152.9006826974817
        },
        "qwen2-72b-instruct": {
            "rating": 1170.090791999148,
            "rating_q975": 1189.5123436199465,
            "rating_q025": 1150.6692403783495
        },
        "reka-flash-21b-20240226": {
            "rating": 1156.3984462800302,
            "rating_q975": 1181.374812898952,
            "rating_q025": 1131.4220796611082
        },
        "gpt-3.5-turbo-0125": {
            "rating": 1151.2701319880962,
            "rating_q975": 1171.3544935893296,
            "rating_q025": 1131.1857703868627
        },
        "mixtral-8x22b-instruct-v0.1": {
            "rating": 1141.447165070228,
            "rating_q975": 1161.2679575939555,
            "rating_q025": 1121.6263725465005
        },
        "qwen1.5-72b-chat": {
            "rating": 1134.6628680794206,
            "rating_q975": 1161.1957710295073,
            "rating_q025": 1108.1299651293339
        },
        "qwen1.5-110b-chat": {
            "rating": 1122.8277254500517,
            "rating_q975": 1141.900541581125,
            "rating_q025": 1103.7549093189784
        },
        "mistral-large-2402": {
            "rating": 1108.333219576324,
            "rating_q975": 1129.4031451067003,
            "rating_q025": 1087.2632940459475
        },
        "dbrx-instruct-preview": {
            "rating": 1108.0294605299455,
            "rating_q975": 1137.0808939721678,
            "rating_q025": 1078.9780270877231
        },
        "llama-3-70b-instruct": {
            "rating": 1107.3212578340595,
            "rating_q975": 1121.896742720711,
            "rating_q025": 1092.7457729474079
        },
        "mistral-medium": {
            "rating": 1102.7131600558419,
            "rating_q975": 1137.6834122142716,
            "rating_q025": 1067.7429078974121
        },
        "glm-4-0520": {
            "rating": 1100.941143600156,
            "rating_q975": 1135.6955604650339,
            "rating_q025": 1066.1867267352782
        },
        "qwen1.5-32b-chat": {
            "rating": 1096.660699378123,
            "rating_q975": 1126.8513462359365,
            "rating_q025": 1066.4700525203093
        },
        "gemma-1.1-7b-it": {
            "rating": 1095.595602827808,
            "rating_q975": 1118.275784944259,
            "rating_q025": 1072.9154207113572
        },
        "llama-3-8b-instruct": {
            "rating": 1094.026117946378,
            "rating_q975": 1110.8324083313958,
            "rating_q025": 1077.2198275613603
        },
        "gemma-2-2b-it": {
            "rating": 1088.602855841234,
            "rating_q975": 1112.7194080163695,
            "rating_q025": 1064.4863036660986
        },
        "llama-3.1-8b-instruct": {
            "rating": 1087.0026520918773,
            "rating_q975": 1109.108402783333,
            "rating_q025": 1064.8969014004215
        },
        "yi-1.5-34b-chat": {
            "rating": 1079.23582244944,
            "rating_q975": 1102.0873305910688,
            "rating_q025": 1056.3843143078113
        },
        "mixtral-8x7b-instruct-v0.1": {
            "rating": 1068.3541260487837,
            "rating_q975": 1091.8433347121868,
            "rating_q025": 1044.8649173853805
        },
        "snowflake-arctic-instruct": {
            "rating": 1067.0597816045135,
            "rating_q975": 1094.393525008373,
            "rating_q025": 1039.726038200654
        },
        "llama-2-70b-chat": {
            "rating": 1060.736046762539,
            "rating_q975": 1098.507355121755,
            "rating_q025": 1022.964738403323
        },
        "llama-2-13b-chat": {
            "rating": 1051.542367116681,
            "rating_q975": 1098.3430324400078,
            "rating_q025": 1004.741701793354
        },
        "yi-34b-chat": {
            "rating": 1040.6051519265002,
            "rating_q975": 1080.1071388772045,
            "rating_q025": 1001.1031649757958
        },
        "phi-3-medium-4k-instruct": {
            "rating": 1034.9907783239478,
            "rating_q975": 1058.3373691821976,
            "rating_q025": 1011.6441874656979
        },
        "gemma-1.1-2b-it": {
            "rating": 1005.5552825977061,
            "rating_q975": 1036.710021205443,
            "rating_q025": 974.4005439899693
        },
        "phi-3-small-8k-instruct": {
            "rating": 990.286726895786,
            "rating_q975": 1013.4201207342032,
            "rating_q025": 967.1533330573689
        },
        "phi-3-mini-4k-instruct": {
            "rating": 978.5851527659049,
            "rating_q975": 1001.0106805667191,
            "rating_q025": 956.1596249650908
        },
        "phi-3-mini-4k-instruct-june-2024": {
            "rating": 963.3384921350674,
            "rating_q975": 1001.3449834032642,
            "rating_q025": 925.3320008668707
        },
        "phi-3-mini-128k-instruct": {
            "rating": 960.2016958664017,
            "rating_q975": 996.8527091241161,
            "rating_q025": 923.5506826086872
        }
    },
    "long_user": {
        "claude-opus-4-5-20251101": {
            "rating": 1499.68826141728,
            "rating_q975": 1512.403639039872,
            "rating_q025": 1486.9728837946882
        },
        "gemini-3-pro": {
            "rating": 1493.3899918396198,
            "rating_q975": 1504.0298061425676,
            "rating_q025": 1482.750177536672
        },
        "claude-opus-4-5-20251101-thinking-32k": {
            "rating": 1491.2251063187202,
            "rating_q975": 1504.1222470825232,
            "rating_q025": 1478.3279655549172
        },
        "claude-sonnet-4-5-20250929-thinking-32k": {
            "rating": 1484.4922301816396,
            "rating_q975": 1492.7586053921334,
            "rating_q025": 1476.2258549711457
        },
        "claude-opus-4-1-20250805-thinking-16k": {
            "rating": 1482.136890272488,
            "rating_q975": 1489.0241428990976,
            "rating_q025": 1475.2496376458785
        },
        "claude-sonnet-4-5-20250929": {
            "rating": 1473.9521177463512,
            "rating_q975": 1482.8588450046582,
            "rating_q025": 1465.0453904880442
        },
        "claude-opus-4-1-20250805": {
            "rating": 1466.600764155106,
            "rating_q975": 1473.023398023904,
            "rating_q025": 1460.1781302863078
        },
        "gpt-5.1-high": {
            "rating": 1464.3213396034323,
            "rating_q975": 1475.6217224493846,
            "rating_q025": 1453.02095675748
        },
        "gemini-2.5-pro": {
            "rating": 1462.4019621302623,
            "rating_q975": 1468.2844132429145,
            "rating_q025": 1456.51951101761
        },
        "claude-opus-4-20250514-thinking-16k": {
            "rating": 1459.9739469623146,
            "rating_q975": 1467.7748794084155,
            "rating_q025": 1452.1730145162137
        },
        "grok-4.1-thinking": {
            "rating": 1450.8259932844392,
            "rating_q975": 1461.1914373715301,
            "rating_q025": 1440.4605491973482
        },
        "grok-4.1": {
            "rating": 1450.615406353483,
            "rating_q975": 1460.9176661369308,
            "rating_q025": 1440.313146570035
        },
        "deepseek-v3.1-thinking": {
            "rating": 1446.600232606585,
            "rating_q975": 1458.6293977263224,
            "rating_q025": 1434.5710674868476
        },
        "gpt-5.1": {
            "rating": 1446.2971479088578,
            "rating_q975": 1456.8230577464506,
            "rating_q025": 1435.771238071265
        },
        "qwen3-max-preview": {
            "rating": 1446.1965404638543,
            "rating_q975": 1454.4662276193874,
            "rating_q025": 1437.9268533083211
        },
        "claude-opus-4-20250514": {
            "rating": 1442.7800267782686,
            "rating_q975": 1450.011859120198,
            "rating_q025": 1435.5481944363391
        },
        "gpt-4.5-preview-2025-02-27": {
            "rating": 1441.9031528021458,
            "rating_q975": 1455.420146435335,
            "rating_q025": 1428.3861591689565
        },
        "deepseek-v3.2-exp": {
            "rating": 1440.242923139014,
            "rating_q975": 1451.4122020186094,
            "rating_q025": 1429.0736442594186
        },
        "deepseek-v3.1-terminus-thinking": {
            "rating": 1438.1174953984564,
            "rating_q975": 1460.6874640866156,
            "rating_q025": 1415.5475267102972
        },
        "claude-sonnet-4-20250514-thinking-32k": {
            "rating": 1437.882799215841,
            "rating_q975": 1445.5982559894455,
            "rating_q025": 1430.1673424422365
        },
        "chatgpt-4o-latest-20250326": {
            "rating": 1437.4172289731046,
            "rating_q975": 1443.4306838087869,
            "rating_q025": 1431.4037741374223
        },
        "qwen3-235b-a22b-instruct-2507": {
            "rating": 1436.2290990205922,
            "rating_q975": 1442.6931148947315,
            "rating_q025": 1429.765083146453
        },
        "gpt-5-chat": {
            "rating": 1434.890271685333,
            "rating_q975": 1442.6278453578902,
            "rating_q025": 1427.1526980127755
        },
        "claude-haiku-4-5-20251001": {
            "rating": 1433.623808957851,
            "rating_q975": 1441.8940060720354,
            "rating_q025": 1425.3536118436666
        },
        "qwen3-max-2025-09-23": {
            "rating": 1433.1509684083449,
            "rating_q975": 1446.1055452292198,
            "rating_q025": 1420.1963915874699
        },
        "glm-4.6": {
            "rating": 1432.704459060819,
            "rating_q975": 1440.9481917108226,
            "rating_q025": 1424.4607264108156
        },
        "deepseek-v3.2": {
            "rating": 1432.1342187762443,
            "rating_q975": 1447.4186543208175,
            "rating_q025": 1416.8497832316712
        },
        "deepseek-v3.2-exp-thinking": {
            "rating": 1431.5582302482967,
            "rating_q975": 1444.6844483672965,
            "rating_q025": 1418.432012129297
        },
        "kimi-k2-thinking-turbo": {
            "rating": 1429.084078297568,
            "rating_q975": 1439.336802953333,
            "rating_q025": 1418.8313536418032
        },
        "grok-3-preview-02-24": {
            "rating": 1428.6705309251658,
            "rating_q975": 1437.3086227464821,
            "rating_q025": 1420.0324391038496
        },
        "deepseek-v3.2-thinking": {
            "rating": 1427.4377175933735,
            "rating_q975": 1443.2751171953903,
            "rating_q025": 1411.6003179913566
        },
        "ernie-5.0-preview-1103": {
            "rating": 1425.7765644575663,
            "rating_q975": 1441.7213368020111,
            "rating_q025": 1409.8317921131215
        },
        "claude-3-7-sonnet-20250219-thinking-32k": {
            "rating": 1424.4119915515228,
            "rating_q975": 1432.285037333821,
            "rating_q025": 1416.5389457692245
        },
        "deepseek-v3.1": {
            "rating": 1423.8624230951393,
            "rating_q975": 1434.4834012371234,
            "rating_q025": 1413.2414449531552
        },
        "grok-4-fast-chat": {
            "rating": 1423.7103808052143,
            "rating_q975": 1439.0450785545015,
            "rating_q025": 1408.375683055927
        },
        "gpt-4.1-2025-04-14": {
            "rating": 1423.470802487764,
            "rating_q975": 1430.012952346631,
            "rating_q025": 1416.9286526288972
        },
        "qwen3-vl-235b-a22b-instruct": {
            "rating": 1423.2344404099379,
            "rating_q975": 1436.808105057516,
            "rating_q025": 1409.6607757623597
        },
        "claude-sonnet-4-20250514": {
            "rating": 1422.059227153073,
            "rating_q975": 1429.4239227678936,
            "rating_q025": 1414.6945315382522
        },
        "glm-4.5": {
            "rating": 1421.1414883671182,
            "rating_q975": 1429.967717843449,
            "rating_q025": 1412.3152588907874
        },
        "gemini-2.5-flash": {
            "rating": 1420.9646490724513,
            "rating_q975": 1426.8051622383077,
            "rating_q025": 1415.1241359065948
        },
        "mistral-large-3": {
            "rating": 1419.1521575813233,
            "rating_q975": 1433.892161859632,
            "rating_q025": 1404.4121533030145
        },
        "gemini-2.5-flash-preview-09-2025": {
            "rating": 1419.11742760642,
            "rating_q975": 1426.956323688876,
            "rating_q025": 1411.2785315239641
        },
        "gpt-5-high": {
            "rating": 1416.8779541767883,
            "rating_q975": 1424.9381485743988,
            "rating_q025": 1408.8177597791778
        },
        "grok-4-0709": {
            "rating": 1416.570591216168,
            "rating_q975": 1423.4752244967335,
            "rating_q025": 1409.6659579356024
        },
        "grok-4-1-fast-reasoning": {
            "rating": 1416.0134559254661,
            "rating_q975": 1428.7143767183304,
            "rating_q025": 1403.3125351326019
        },
        "deepseek-v3.1-terminus": {
            "rating": 1414.8872969982042,
            "rating_q975": 1434.9293216056162,
            "rating_q025": 1394.8452723907922
        },
        "mistral-medium-2508": {
            "rating": 1411.0811703619515,
            "rating_q975": 1417.7859884941183,
            "rating_q025": 1404.3763522297847
        },
        "o1-2024-12-17": {
            "rating": 1409.4137525881918,
            "rating_q975": 1419.0518484876964,
            "rating_q025": 1399.7756566886871
        },
        "o3-2025-04-16": {
            "rating": 1409.3335054493577,
            "rating_q975": 1415.678995314125,
            "rating_q025": 1402.9880155845906
        },
        "grok-4-fast-reasoning": {
            "rating": 1408.767895406271,
            "rating_q975": 1418.0759526603595,
            "rating_q025": 1399.4598381521826
        },
        "claude-3-7-sonnet-20250219": {
            "rating": 1408.3833065940719,
            "rating_q975": 1415.8622261694532,
            "rating_q025": 1400.9043870186906
        },
        "deepseek-r1-0528": {
            "rating": 1407.9557631434886,
            "rating_q975": 1418.6007621508993,
            "rating_q025": 1397.310764136078
        },
        "qwen3-235b-a22b-no-thinking": {
            "rating": 1406.8472586608423,
            "rating_q975": 1414.4709271164122,
            "rating_q025": 1399.2235902052723
        },
        "qwen3-coder-480b-a35b-instruct": {
            "rating": 1405.6926933136097,
            "rating_q975": 1414.6835901955617,
            "rating_q025": 1396.7017964316576
        },
        "qwen3-vl-235b-a22b-thinking": {
            "rating": 1405.1128782066328,
            "rating_q975": 1419.1169753767883,
            "rating_q025": 1391.1087810364772
        },
        "qwen3-235b-a22b-thinking-2507": {
            "rating": 1402.9941967648222,
            "rating_q975": 1417.306907290406,
            "rating_q025": 1388.6814862392384
        },
        "kimi-k2-0905-preview": {
            "rating": 1402.9604110489731,
            "rating_q975": 1414.8552230523048,
            "rating_q025": 1391.0655990456414
        },
        "deepseek-r1": {
            "rating": 1396.4676856392232,
            "rating_q975": 1408.2936617861312,
            "rating_q025": 1384.6417094923152
        },
        "hunyuan-vision-1.5-thinking": {
            "rating": 1394.7907105371605,
            "rating_q975": 1420.5466635384525,
            "rating_q025": 1369.0347575358685
        },
        "qwen3-next-80b-a3b-instruct": {
            "rating": 1394.3348530968522,
            "rating_q975": 1403.0596612333618,
            "rating_q025": 1385.6100449603425
        },
        "kimi-k2-0711-preview": {
            "rating": 1392.9449091820018,
            "rating_q975": 1401.3222414590318,
            "rating_q025": 1384.5675769049717
        },
        "mai-1-preview": {
            "rating": 1392.066576706081,
            "rating_q975": 1402.179107024326,
            "rating_q025": 1381.954046387836
        },
        "claude-3-5-sonnet-20241022": {
            "rating": 1391.6841701040914,
            "rating_q975": 1397.2198278258418,
            "rating_q025": 1386.148512382341
        },
        "deepseek-v3-0324": {
            "rating": 1391.6222670637449,
            "rating_q975": 1398.4748406730769,
            "rating_q025": 1384.7696934544128
        },
        "mistral-medium-2505": {
            "rating": 1390.5572949100738,
            "rating_q975": 1398.6185514190736,
            "rating_q025": 1382.496038401074
        },
        "gemini-2.5-flash-lite-preview-09-2025-no-thinking": {
            "rating": 1390.289822514308,
            "rating_q975": 1398.0766130808313,
            "rating_q025": 1382.5030319477848
        },
        "longcat-flash-chat": {
            "rating": 1388.2860915765161,
            "rating_q975": 1400.5577560440533,
            "rating_q025": 1376.014427108979
        },
        "gpt-4.1-mini-2025-04-14": {
            "rating": 1386.865133501463,
            "rating_q975": 1394.4501896152256,
            "rating_q025": 1379.2800773877007
        },
        "hunyuan-t1-20250711": {
            "rating": 1386.5784373833076,
            "rating_q975": 1406.4259783478344,
            "rating_q025": 1366.7308964187807
        },
        "qwen2.5-max": {
            "rating": 1382.6355043594124,
            "rating_q975": 1391.1216970455225,
            "rating_q025": 1374.1493116733022
        },
        "gemini-2.5-flash-lite-preview-06-17-thinking": {
            "rating": 1382.4193323724196,
            "rating_q975": 1390.4455920048892,
            "rating_q025": 1374.39307273995
        },
        "qwen3-30b-a3b-instruct-2507": {
            "rating": 1381.466240075799,
            "rating_q975": 1390.2560939227988,
            "rating_q025": 1372.6763862287994
        },
        "qwen3-235b-a22b": {
            "rating": 1379.7788803863198,
            "rating_q975": 1388.5517681897468,
            "rating_q025": 1371.0059925828928
        },
        "glm-4.5-air": {
            "rating": 1379.743127957759,
            "rating_q975": 1387.501864265677,
            "rating_q025": 1371.984391649841
        },
        "o1-preview": {
            "rating": 1378.6449703242506,
            "rating_q975": 1388.1036014193708,
            "rating_q025": 1369.1863392291305
        },
        "hunyuan-turbos-20250416": {
            "rating": 1378.5633381840028,
            "rating_q975": 1393.1297428124874,
            "rating_q025": 1363.9969335555181
        },
        "grok-3-mini-high": {
            "rating": 1377.7728315921022,
            "rating_q975": 1388.0795734121202,
            "rating_q025": 1367.4660897720842
        },
        "gpt-5-mini-high": {
            "rating": 1374.4558213587454,
            "rating_q975": 1383.0738822950157,
            "rating_q025": 1365.8377604224752
        },
        "hunyuan-large-2025-02-10": {
            "rating": 1373.9803275711233,
            "rating_q975": 1402.387633706317,
            "rating_q025": 1345.5730214359296
        },
        "deepseek-v3": {
            "rating": 1371.9406713895482,
            "rating_q975": 1382.3003189335466,
            "rating_q025": 1361.58102384555
        },
        "o3-mini-high": {
            "rating": 1369.977179543889,
            "rating_q975": 1382.0349097273886,
            "rating_q025": 1357.9194493603893
        },
        "qwen3-next-80b-a3b-thinking": {
            "rating": 1369.2400642874377,
            "rating_q975": 1380.528712294557,
            "rating_q025": 1357.9514162803184
        },
        "minimax-m1": {
            "rating": 1368.5333983980668,
            "rating_q975": 1376.0241154740643,
            "rating_q025": 1361.0426813220693
        },
        "command-a-03-2025": {
            "rating": 1367.706409998213,
            "rating_q975": 1373.9749509093242,
            "rating_q025": 1361.437869087102
        },
        "grok-3-mini-beta": {
            "rating": 1367.5181259571373,
            "rating_q975": 1376.8091273772407,
            "rating_q025": 1358.227124537034
        },
        "o4-mini-2025-04-16": {
            "rating": 1367.1671914530766,
            "rating_q975": 1374.2057255249813,
            "rating_q025": 1360.128657381172
        },
        "gemma-3-27b-it": {
            "rating": 1363.7269969376512,
            "rating_q975": 1371.1787188992228,
            "rating_q025": 1356.2752749760796
        },
        "gemini-2.0-flash-001": {
            "rating": 1363.5757625721542,
            "rating_q975": 1371.0537204244374,
            "rating_q025": 1356.097804719871
        },
        "qwen-plus-0125": {
            "rating": 1359.9301071681157,
            "rating_q975": 1380.8303670823273,
            "rating_q025": 1339.029847253904
        },
        "mistral-small-2506": {
            "rating": 1359.0482953832457,
            "rating_q975": 1369.1936594918855,
            "rating_q025": 1348.9029312746059
        },
        "o3-mini": {
            "rating": 1357.6705456989223,
            "rating_q975": 1364.101428545675,
            "rating_q025": 1351.2396628521697
        },
        "amazon-nova-experimental-chat-10-20": {
            "rating": 1357.2435424329574,
            "rating_q975": 1370.9429241765056,
            "rating_q025": 1343.5441606894092
        },
        "qwen3-32b": {
            "rating": 1354.8255923038205,
            "rating_q975": 1379.5827898261687,
            "rating_q025": 1330.0683947814723
        },
        "gemini-1.5-pro-002": {
            "rating": 1353.9854247241296,
            "rating_q975": 1360.9387405042228,
            "rating_q025": 1347.0321089440365
        },
        "hunyuan-turbos-20250226": {
            "rating": 1352.2910016566634,
            "rating_q975": 1384.2155791685473,
            "rating_q025": 1320.3664241447796
        },
        "step-3": {
            "rating": 1349.5451021515928,
            "rating_q975": 1365.9715241424342,
            "rating_q025": 1333.1186801607514
        },
        "claude-3-5-sonnet-20240620": {
            "rating": 1349.086766365322,
            "rating_q975": 1356.6698203568706,
            "rating_q025": 1341.5037123737736
        },
        "gemma-3-12b-it": {
            "rating": 1346.9923812058091,
            "rating_q975": 1375.5260307895294,
            "rating_q025": 1318.4587316220889
        },
        "minimax-m2": {
            "rating": 1346.6229100173773,
            "rating_q975": 1361.748161080904,
            "rating_q025": 1331.4976589538505
        },
        "step-1o-turbo-202506": {
            "rating": 1346.5078716519822,
            "rating_q975": 1362.4756420845015,
            "rating_q025": 1330.540101219463
        },
        "gemini-2.0-flash-lite-preview-02-05": {
            "rating": 1346.2639936634946,
            "rating_q975": 1356.5682270810707,
            "rating_q025": 1335.9597602459185
        },
        "gemini-1.5-pro-001": {
            "rating": 1346.1120790880839,
            "rating_q975": 1354.3205783348603,
            "rating_q025": 1337.9035798413074
        },
        "amazon-nova-experimental-chat-10-09": {
            "rating": 1345.5179614598665,
            "rating_q975": 1358.843568285051,
            "rating_q025": 1332.1923546346818
        },
        "intellect-3": {
            "rating": 1342.11487614698,
            "rating_q975": 1367.8926935613224,
            "rating_q025": 1316.3370587326374
        },
        "llama-3.1-nemotron-ultra-253b-v1": {
            "rating": 1341.7609104014227,
            "rating_q975": 1371.744698977767,
            "rating_q025": 1311.7771218250784
        },
        "o1-mini": {
            "rating": 1341.692749558483,
            "rating_q975": 1349.0958503674294,
            "rating_q025": 1334.2896487495366
        },
        "hunyuan-turbo-0110": {
            "rating": 1341.272761897077,
            "rating_q975": 1371.2067070532287,
            "rating_q025": 1311.3388167409255
        },
        "nova-2-lite": {
            "rating": 1340.4836151650775,
            "rating_q975": 1356.8032520288723,
            "rating_q025": 1324.1639783012827
        },
        "nvidia-llama-3.3-nemotron-super-49b-v1.5": {
            "rating": 1340.3655561335274,
            "rating_q975": 1361.8807559414888,
            "rating_q025": 1318.850356325566
        },
        "claude-3-5-haiku-20241022": {
            "rating": 1339.6847578547213,
            "rating_q975": 1345.7891799510492,
            "rating_q025": 1333.5803357583934
        },
        "qwen3-30b-a3b": {
            "rating": 1339.1759449812046,
            "rating_q975": 1348.0801883843951,
            "rating_q025": 1330.271701578014
        },
        "step-2-16k-exp-202412": {
            "rating": 1338.6987857817853,
            "rating_q975": 1359.790776454138,
            "rating_q025": 1317.6067951094326
        },
        "glm-4.5v": {
            "rating": 1338.306312349383,
            "rating_q975": 1356.9425016107755,
            "rating_q025": 1319.6701230879905
        },
        "glm-4-plus-0111": {
            "rating": 1337.6980945069856,
            "rating_q975": 1358.126814963679,
            "rating_q025": 1317.2693740502923
        },
        "qwq-32b": {
            "rating": 1335.515133279729,
            "rating_q975": 1344.756159298896,
            "rating_q025": 1326.2741072605622
        },
        "magistral-medium-2506": {
            "rating": 1334.8540801656468,
            "rating_q975": 1347.2797016192828,
            "rating_q025": 1322.4284587120108
        },
        "llama-3.3-nemotron-49b-super-v1": {
            "rating": 1334.2770655975455,
            "rating_q975": 1364.6301333315034,
            "rating_q025": 1303.9239978635876
        },
        "gpt-4o-2024-08-06": {
            "rating": 1334.2729506221858,
            "rating_q975": 1342.511345934106,
            "rating_q025": 1326.0345553102657
        },
        "llama-4-maverick-17b-128e-instruct": {
            "rating": 1334.1245695459133,
            "rating_q975": 1341.6588892081913,
            "rating_q025": 1326.5902498836354
        },
        "deepseek-v2.5-1210": {
            "rating": 1333.7638059120275,
            "rating_q975": 1351.0802634272884,
            "rating_q025": 1316.4473483967665
        },
        "ring-flash-2.0": {
            "rating": 1331.8918319588631,
            "rating_q975": 1348.1246463187458,
            "rating_q025": 1315.6590175989804
        },
        "gpt-5-nano-high": {
            "rating": 1331.483161626914,
            "rating_q975": 1346.5447736501972,
            "rating_q025": 1316.4215496036306
        },
        "grok-2-2024-08-13": {
            "rating": 1331.2402715345181,
            "rating_q975": 1338.2659154454723,
            "rating_q025": 1324.214627623564
        },
        "hunyuan-standard-2025-02-10": {
            "rating": 1330.0326072288817,
            "rating_q975": 1356.6704640918983,
            "rating_q025": 1303.394750365865
        },
        "ling-flash-2.0": {
            "rating": 1328.6961513845258,
            "rating_q975": 1345.0730547053754,
            "rating_q025": 1312.3192480636762
        },
        "gpt-4o-2024-05-13": {
            "rating": 1328.0755257166584,
            "rating_q975": 1334.8180473104985,
            "rating_q025": 1321.3330041228182
        },
        "llama-4-scout-17b-16e-instruct": {
            "rating": 1327.040283714397,
            "rating_q975": 1335.4802559859834,
            "rating_q025": 1318.6003114428106
        },
        "olmo-3-32b-think": {
            "rating": 1325.635505368838,
            "rating_q975": 1347.6876813851998,
            "rating_q025": 1303.5833293524763
        },
        "mistral-small-3.1-24b-instruct-2503": {
            "rating": 1325.2774511543612,
            "rating_q975": 1333.1713791394857,
            "rating_q025": 1317.3835231692367
        },
        "gpt-4.1-nano-2025-04-14": {
            "rating": 1325.0652319306382,
            "rating_q975": 1345.125283976648,
            "rating_q025": 1305.0051798846284
        },
        "claude-3-opus-20240229": {
            "rating": 1324.0453905821314,
            "rating_q975": 1330.3070492748902,
            "rating_q025": 1317.7837318893726
        },
        "gpt-oss-120b": {
            "rating": 1323.9756362966918,
            "rating_q975": 1331.9998457908412,
            "rating_q025": 1315.9514268025425
        },
        "llama-3.1-405b-instruct-bf16": {
            "rating": 1323.3727364642796,
            "rating_q975": 1331.2457650789615,
            "rating_q025": 1315.4997078495976
        },
        "qwen-max-0919": {
            "rating": 1322.5897234254062,
            "rating_q975": 1334.3452868032916,
            "rating_q025": 1310.8341600475208
        },
        "yi-lightning": {
            "rating": 1322.4350524542251,
            "rating_q975": 1332.8935698048335,
            "rating_q025": 1311.9765351036167
        },
        "glm-4-plus": {
            "rating": 1322.2256682943407,
            "rating_q975": 1332.1772321824806,
            "rating_q025": 1312.2741044062009
        },
        "gpt-4o-mini-2024-07-18": {
            "rating": 1321.8857341976961,
            "rating_q975": 1328.7453718915713,
            "rating_q025": 1315.026096503821
        },
        "gemini-1.5-flash-002": {
            "rating": 1319.3458485426727,
            "rating_q975": 1327.6181377576765,
            "rating_q025": 1311.0735593276688
        },
        "gemini-advanced-0514": {
            "rating": 1319.2885301827741,
            "rating_q975": 1329.5964406245216,
            "rating_q025": 1308.9806197410267
        },
        "athene-v2-chat": {
            "rating": 1317.743657819635,
            "rating_q975": 1327.2275761984345,
            "rating_q025": 1308.2597394408356
        },
        "hunyuan-large-vision": {
            "rating": 1317.5832072609587,
            "rating_q975": 1337.2728401173572,
            "rating_q025": 1297.8935744045602
        },
        "llama-3.1-405b-instruct-fp8": {
            "rating": 1315.1322687566476,
            "rating_q975": 1322.570259851239,
            "rating_q025": 1307.6942776620563
        },
        "qwen2.5-72b-instruct": {
            "rating": 1313.90055783576,
            "rating_q975": 1321.8013365962001,
            "rating_q025": 1305.99977907532
        },
        "grok-2-mini-2024-08-13": {
            "rating": 1313.493752974966,
            "rating_q975": 1321.0312002636897,
            "rating_q025": 1305.956305686242
        },
        "gemma-3n-e4b-it": {
            "rating": 1312.1989361459675,
            "rating_q975": 1323.0641416320186,
            "rating_q025": 1301.3337306599165
        },
        "gemma-3-4b-it": {
            "rating": 1312.0363847612653,
            "rating_q975": 1339.509729677329,
            "rating_q025": 1284.5630398452015
        },
        "gpt-4-turbo-2024-04-09": {
            "rating": 1311.3911624150778,
            "rating_q975": 1319.1509218074018,
            "rating_q025": 1303.6314030227538
        },
        "mercury": {
            "rating": 1310.5769815118585,
            "rating_q975": 1337.4017294416174,
            "rating_q025": 1283.7522335820997
        },
        "deepseek-v2.5": {
            "rating": 1310.5759456074893,
            "rating_q975": 1320.6216153951718,
            "rating_q025": 1300.5302758198068
        },
        "llama-3.3-70b-instruct": {
            "rating": 1309.2893208153564,
            "rating_q975": 1315.8029343902972,
            "rating_q025": 1302.7757072404156
        },
        "qwen2.5-plus-1127": {
            "rating": 1304.7117489446698,
            "rating_q975": 1318.8943070504026,
            "rating_q025": 1290.529190838937
        },
        "gpt-oss-20b": {
            "rating": 1303.4975518398808,
            "rating_q975": 1317.0246121814293,
            "rating_q025": 1289.9704914983322
        },
        "gpt-4-0125-preview": {
            "rating": 1302.3730924113677,
            "rating_q975": 1310.7870205799932,
            "rating_q025": 1293.9591642427422
        },
        "mistral-large-2411": {
            "rating": 1301.6983225439394,
            "rating_q975": 1311.1215335586346,
            "rating_q025": 1292.2751115292442
        },
        "mistral-large-2407": {
            "rating": 1300.461349641274,
            "rating_q975": 1309.004048822526,
            "rating_q025": 1291.9186504600218
        },
        "amazon-nova-pro-v1.0": {
            "rating": 1297.0901745604647,
            "rating_q975": 1306.789069357737,
            "rating_q025": 1287.3912797631924
        },
        "gemini-1.5-flash-001": {
            "rating": 1296.381310486085,
            "rating_q975": 1304.9757013092174,
            "rating_q025": 1287.7869196629529
        },
        "gpt-4-1106-preview": {
            "rating": 1296.03071994361,
            "rating_q975": 1304.3555313715533,
            "rating_q025": 1287.7059085156666
        },
        "gemma-2-27b-it": {
            "rating": 1295.5200408217238,
            "rating_q975": 1302.22617834983,
            "rating_q025": 1288.8139032936176
        },
        "llama-3.1-70b-instruct": {
            "rating": 1289.956606418907,
            "rating_q975": 1297.4249479902708,
            "rating_q025": 1282.4882648475434
        },
        "athene-70b-0725": {
            "rating": 1287.9719123750542,
            "rating_q975": 1300.3235943801217,
            "rating_q025": 1275.6202303699868
        },
        "c4ai-aya-expanse-32b": {
            "rating": 1285.598392771677,
            "rating_q975": 1294.8287489015454,
            "rating_q025": 1276.3680366418087
        },
        "gemma-2-9b-it-simpo": {
            "rating": 1283.7481516923272,
            "rating_q975": 1302.9619259601527,
            "rating_q025": 1264.5343774245016
        },
        "nemotron-4-340b-instruct": {
            "rating": 1282.6908961376632,
            "rating_q975": 1295.9839536355184,
            "rating_q025": 1269.397838639808
        },
        "qwen2.5-coder-32b-instruct": {
            "rating": 1282.471788064704,
            "rating_q975": 1301.3469947105698,
            "rating_q025": 1263.5965814188382
        },
        "deepseek-coder-v2": {
            "rating": 1281.8051727735412,
            "rating_q975": 1295.6708669985671,
            "rating_q025": 1267.9394785485154
        },
        "claude-3-sonnet-20240229": {
            "rating": 1280.4869927783343,
            "rating_q975": 1289.0808076233527,
            "rating_q025": 1271.8931779333159
        },
        "llama-3.1-nemotron-70b-instruct": {
            "rating": 1277.3218895230445,
            "rating_q975": 1294.9571043369124,
            "rating_q025": 1259.6866747091767
        },
        "mistral-small-24b-instruct-2501": {
            "rating": 1277.1856491555639,
            "rating_q975": 1290.7080024299992,
            "rating_q025": 1263.6632958811285
        },
        "command-r-plus-08-2024": {
            "rating": 1276.8087229569378,
            "rating_q975": 1292.1817982016048,
            "rating_q025": 1261.4356477122708
        },
        "reka-core-20240904": {
            "rating": 1275.7320865749784,
            "rating_q975": 1293.841511199904,
            "rating_q025": 1257.6226619500528
        },
        "gpt-4-0613": {
            "rating": 1271.9437405534866,
            "rating_q975": 1281.2110310282253,
            "rating_q025": 1262.6764500787478
        },
        "amazon-nova-lite-v1.0": {
            "rating": 1271.2781876717404,
            "rating_q975": 1281.9494457189166,
            "rating_q025": 1260.6069296245641
        },
        "gpt-4-0314": {
            "rating": 1271.1777277735123,
            "rating_q975": 1282.6923028736014,
            "rating_q025": 1259.6631526734232
        },
        "llama-3.1-tulu-3-70b": {
            "rating": 1269.511999477037,
            "rating_q975": 1294.5607267296953,
            "rating_q025": 1244.463272224379
        },
        "hunyuan-standard-256k": {
            "rating": 1267.0356027827206,
            "rating_q975": 1293.6838003450712,
            "rating_q025": 1240.38740522037
        },
        "llama-3.1-nemotron-51b-instruct": {
            "rating": 1265.37530345763,
            "rating_q975": 1288.3780493497525,
            "rating_q025": 1242.3725575655076
        },
        "phi-4": {
            "rating": 1263.2490549471988,
            "rating_q975": 1273.9535720306822,
            "rating_q025": 1252.5445378637155
        },
        "gemini-1.5-flash-8b-001": {
            "rating": 1262.652944359699,
            "rating_q975": 1270.9523599977263,
            "rating_q025": 1254.3535287216716
        },
        "glm-4-0520": {
            "rating": 1261.441514401896,
            "rating_q975": 1278.0856457740977,
            "rating_q025": 1244.7973830296944
        },
        "gemma-2-9b-it": {
            "rating": 1260.9355039534862,
            "rating_q975": 1268.6355749653803,
            "rating_q025": 1253.235432941592
        },
        "claude-3-haiku-20240307": {
            "rating": 1260.8222279372428,
            "rating_q975": 1268.405012126696,
            "rating_q025": 1253.2394437477897
        },
        "reka-flash-20240904": {
            "rating": 1258.9616150302813,
            "rating_q975": 1276.737618064165,
            "rating_q025": 1241.1856119963977
        },
        "command-r-08-2024": {
            "rating": 1258.3570540899104,
            "rating_q975": 1273.3248048291632,
            "rating_q025": 1243.3893033506577
        },
        "jamba-1.5-large": {
            "rating": 1257.1170089577527,
            "rating_q975": 1274.5789569905396,
            "rating_q025": 1239.6550609249657
        },
        "command-r-plus": {
            "rating": 1256.9751265013465,
            "rating_q975": 1265.9097529819303,
            "rating_q025": 1248.0405000207627
        },
        "qwen2-72b-instruct": {
            "rating": 1255.6061498714723,
            "rating_q975": 1265.713785917258,
            "rating_q025": 1245.4985138256866
        },
        "ministral-8b-2410": {
            "rating": 1254.9414356082427,
            "rating_q975": 1275.3341657383119,
            "rating_q025": 1234.5487054781736
        },
        "llama-3-70b-instruct": {
            "rating": 1247.258739343079,
            "rating_q975": 1254.7724660499687,
            "rating_q025": 1239.7450126361894
        },
        "c4ai-aya-expanse-8b": {
            "rating": 1245.5449779246928,
            "rating_q975": 1260.2533581150324,
            "rating_q025": 1230.8365977343533
        },
        "amazon-nova-micro-v1.0": {
            "rating": 1245.259376065645,
            "rating_q975": 1256.406501536113,
            "rating_q025": 1234.112250595177
        },
        "olmo-2-0325-32b-instruct": {
            "rating": 1243.4214017001195,
            "rating_q975": 1277.4479792470258,
            "rating_q025": 1209.3948241532132
        },
        "mistral-large-2402": {
            "rating": 1240.391586232233,
            "rating_q975": 1250.2608852399542,
            "rating_q025": 1230.522287224512
        },
        "qwen1.5-72b-chat": {
            "rating": 1230.059056072952,
            "rating_q975": 1241.6155815316517,
            "rating_q025": 1218.5025306142522
        },
        "granite-3.1-8b-instruct": {
            "rating": 1227.808684024559,
            "rating_q975": 1254.9573684401244,
            "rating_q025": 1200.6599996089935
        },
        "command-r": {
            "rating": 1227.1054995806285,
            "rating_q975": 1237.0601727824426,
            "rating_q025": 1217.1508263788144
        },
        "llama-3.1-tulu-3-8b": {
            "rating": 1222.9732109059892,
            "rating_q975": 1248.921838498884,
            "rating_q025": 1197.0245833130944
        },
        "qwen1.5-110b-chat": {
            "rating": 1222.8252079704312,
            "rating_q975": 1234.555505073552,
            "rating_q025": 1211.0949108673103
        },
        "llama-3.1-8b-instruct": {
            "rating": 1219.851709826672,
            "rating_q975": 1227.7509056192864,
            "rating_q025": 1211.9525140340577
        },
        "granite-3.1-2b-instruct": {
            "rating": 1218.9957433035383,
            "rating_q975": 1245.3062403514737,
            "rating_q025": 1192.685246255603
        },
        "qwen1.5-32b-chat": {
            "rating": 1218.18338337983,
            "rating_q975": 1230.7777372546789,
            "rating_q025": 1205.5890295049812
        },
        "gemini-pro-dev-api": {
            "rating": 1217.5457716482033,
            "rating_q975": 1235.3884252978144,
            "rating_q025": 1199.7031179985922
        },
        "mistral-medium": {
            "rating": 1215.0375323238445,
            "rating_q975": 1227.9133475231251,
            "rating_q025": 1202.161717124564
        },
        "gpt-3.5-turbo-0125": {
            "rating": 1214.391136192784,
            "rating_q975": 1223.4812640633659,
            "rating_q025": 1205.301008322202
        },
        "jamba-1.5-mini": {
            "rating": 1213.115668453994,
            "rating_q975": 1230.7087462935035,
            "rating_q025": 1195.5225906144844
        },
        "mixtral-8x22b-instruct-v0.1": {
            "rating": 1211.8573707956598,
            "rating_q975": 1221.6164672421846,
            "rating_q025": 1202.098274349135
        },
        "reka-flash-21b-20240226": {
            "rating": 1211.7594520905861,
            "rating_q975": 1224.5555675224562,
            "rating_q025": 1198.9633366587161
        },
        "reka-flash-21b-20240226-online": {
            "rating": 1211.366242440866,
            "rating_q975": 1226.9668687793194,
            "rating_q025": 1195.7656161024127
        },
        "llama-3-8b-instruct": {
            "rating": 1202.7367227987813,
            "rating_q975": 1211.1965004398414,
            "rating_q025": 1194.2769451577212
        },
        "yi-1.5-34b-chat": {
            "rating": 1199.3267979373868,
            "rating_q975": 1212.617623647983,
            "rating_q025": 1186.0359722267906
        },
        "granite-3.0-8b-instruct": {
            "rating": 1197.5163285911776,
            "rating_q975": 1221.5870672380274,
            "rating_q025": 1173.4455899443278
        },
        "internlm2_5-20b-chat": {
            "rating": 1196.912262177057,
            "rating_q975": 1213.2040664603903,
            "rating_q025": 1180.6204578937238
        },
        "qwen1.5-14b-chat": {
            "rating": 1187.0131013492555,
            "rating_q975": 1201.8449876679192,
            "rating_q025": 1172.1812150305918
        },
        "phi-3-medium-4k-instruct": {
            "rating": 1186.1870708627619,
            "rating_q975": 1199.1496704958818,
            "rating_q025": 1173.224471229642
        },
        "gemma-2-2b-it": {
            "rating": 1182.7007682735848,
            "rating_q975": 1191.2554450884293,
            "rating_q025": 1174.1460914587403
        },
        "dbrx-instruct-preview": {
            "rating": 1182.5868015586946,
            "rating_q975": 1195.1367458082404,
            "rating_q025": 1170.0368573091487
        },
        "gpt-3.5-turbo-1106": {
            "rating": 1177.7377088176477,
            "rating_q975": 1198.2494776526855,
            "rating_q025": 1157.2259399826098
        },
        "zephyr-orpo-141b-A35b-v0.1": {
            "rating": 1177.6355416811475,
            "rating_q975": 1205.8911865801115,
            "rating_q025": 1149.3798967821836
        },
        "openchat-3.5": {
            "rating": 1177.4682678139663,
            "rating_q975": 1205.8407878542182,
            "rating_q025": 1149.0957477737145
        },
        "mixtral-8x7b-instruct-v0.1": {
            "rating": 1177.3889251981245,
            "rating_q975": 1186.8805379166354,
            "rating_q025": 1167.8973124796137
        },
        "qwq-32b-preview": {
            "rating": 1176.6440142971262,
            "rating_q975": 1203.0096270356248,
            "rating_q025": 1150.2784015586276
        },
        "wizardlm-70b": {
            "rating": 1176.2729210912707,
            "rating_q975": 1208.0002361306754,
            "rating_q025": 1144.5456060518661
        },
        "deepseek-llm-67b-chat": {
            "rating": 1175.7949607590533,
            "rating_q975": 1212.8175934461824,
            "rating_q025": 1138.7723280719242
        },
        "tulu-2-dpo-70b": {
            "rating": 1170.9589005137223,
            "rating_q975": 1204.5547588566246,
            "rating_q025": 1137.3630421708199
        },
        "yi-34b-chat": {
            "rating": 1165.8880377173705,
            "rating_q975": 1183.867268729605,
            "rating_q025": 1147.908806705136
        },
        "openchat-3.5-0106": {
            "rating": 1163.2972317272213,
            "rating_q975": 1181.8526520620399,
            "rating_q025": 1144.7418113924027
        },
        "starling-lm-7b-beta": {
            "rating": 1161.8368552344232,
            "rating_q975": 1177.5923732305996,
            "rating_q025": 1146.0813372382468
        },
        "gemma-1.1-7b-it": {
            "rating": 1160.0399751958882,
            "rating_q975": 1172.5843020920597,
            "rating_q025": 1147.4956482997168
        },
        "qwen1.5-7b-chat": {
            "rating": 1158.2459336937716,
            "rating_q975": 1188.4188456334175,
            "rating_q025": 1128.0730217541256
        },
        "phi-3-small-8k-instruct": {
            "rating": 1156.6601699622347,
            "rating_q975": 1169.8866007281404,
            "rating_q025": 1143.433739196329
        },
        "llama-3.2-3b-instruct": {
            "rating": 1154.7160730607807,
            "rating_q975": 1173.0804804278202,
            "rating_q025": 1136.351665693741
        },
        "starling-lm-7b-alpha": {
            "rating": 1144.4338315876316,
            "rating_q975": 1167.6061143950822,
            "rating_q025": 1121.261548780181
        },
        "granite-3.0-2b-instruct": {
            "rating": 1144.0991810427388,
            "rating_q975": 1168.869268299827,
            "rating_q025": 1119.3290937856507
        },
        "wizardlm-13b": {
            "rating": 1138.8957645214493,
            "rating_q975": 1179.8371056261888,
            "rating_q025": 1097.95442341671
        },
        "vicuna-13b": {
            "rating": 1137.6896902010885,
            "rating_q975": 1159.2480118950218,
            "rating_q025": 1116.1313685071552
        },
        "llama-2-13b-chat": {
            "rating": 1134.4775880020693,
            "rating_q975": 1152.0451986075789,
            "rating_q025": 1116.9099773965597
        },
        "vicuna-7b": {
            "rating": 1134.2689581264294,
            "rating_q975": 1179.4053919370922,
            "rating_q025": 1089.1325243157667
        },
        "openhermes-2.5-mistral-7b": {
            "rating": 1133.5257757337763,
            "rating_q975": 1167.1068503634053,
            "rating_q025": 1099.9447011041473
        },
        "llama-2-70b-chat": {
            "rating": 1133.027794090562,
            "rating_q975": 1145.8507199410017,
            "rating_q025": 1120.2048682401226
        },
        "smollm2-1.7b-instruct": {
            "rating": 1130.5403815310524,
            "rating_q975": 1163.6803035975063,
            "rating_q025": 1097.4004594645985
        },
        "mistral-7b-instruct-v0.2": {
            "rating": 1128.5386422379163,
            "rating_q975": 1143.881160089274,
            "rating_q025": 1113.1961243865585
        },
        "palm-2": {
            "rating": 1127.886678183561,
            "rating_q975": 1165.7934062692404,
            "rating_q025": 1089.9799500978813
        },
        "vicuna-33b": {
            "rating": 1127.4524537960795,
            "rating_q975": 1146.6577659761037,
            "rating_q025": 1108.2471416160552
        },
        "snowflake-arctic-instruct": {
            "rating": 1124.536462303417,
            "rating_q975": 1138.725139433206,
            "rating_q025": 1110.347785173628
        },
        "qwen-14b-chat": {
            "rating": 1117.1064743000547,
            "rating_q975": 1155.5065171856702,
            "rating_q025": 1078.7064314144393
        },
        "gemma-1.1-2b-it": {
            "rating": 1109.4892729843157,
            "rating_q975": 1127.364151081525,
            "rating_q025": 1091.6143948871063
        },
        "nous-hermes-2-mixtral-8x7b-dpo": {
            "rating": 1108.7863858182602,
            "rating_q975": 1144.5673375664917,
            "rating_q025": 1073.0054340700287
        },
        "gemma-7b-it": {
            "rating": 1106.2430163753734,
            "rating_q975": 1129.120776955416,
            "rating_q025": 1083.3652557953308
        },
        "phi-3-mini-4k-instruct-june-2024": {
            "rating": 1099.6222118953483,
            "rating_q975": 1118.702499139587,
            "rating_q025": 1080.5419246511096
        },
        "zephyr-7b-beta": {
            "rating": 1098.5429445416644,
            "rating_q975": 1126.4145220781916,
            "rating_q025": 1070.6713670051372
        },
        "llama-3.2-1b-instruct": {
            "rating": 1097.21371848469,
            "rating_q975": 1116.346244063024,
            "rating_q025": 1078.081192906356
        },
        "phi-3-mini-4k-instruct": {
            "rating": 1096.9767544354088,
            "rating_q975": 1112.3229981857414,
            "rating_q025": 1081.6305106850762
        },
        "codellama-34b-instruct": {
            "rating": 1091.5671294604604,
            "rating_q975": 1124.7141769221455,
            "rating_q025": 1058.4200819987752
        },
        "mistral-7b-instruct": {
            "rating": 1089.8109824111639,
            "rating_q975": 1116.8999646949678,
            "rating_q025": 1062.72200012736
        },
        "gemma-2b-it": {
            "rating": 1078.275322623375,
            "rating_q975": 1109.6611922709076,
            "rating_q025": 1046.8894529758422
        },
        "qwen1.5-4b-chat": {
            "rating": 1072.1462735379287,
            "rating_q975": 1096.1022711515095,
            "rating_q025": 1048.1902759243478
        },
        "llama-2-7b-chat": {
            "rating": 1070.3574421829676,
            "rating_q975": 1090.570673674096,
            "rating_q025": 1050.1442106918391
        },
        "phi-3-mini-128k-instruct": {
            "rating": 1067.08344410244,
            "rating_q975": 1083.2022810842939,
            "rating_q025": 1050.964607120586
        },
        "stripedhyena-nous-7b": {
            "rating": 1064.6428935474682,
            "rating_q975": 1097.2048595120577,
            "rating_q025": 1032.0809275828788
        },
        "llama2-70b-steerlm-chat": {
            "rating": 1051.2787723384286,
            "rating_q975": 1095.1956891592577,
            "rating_q025": 1007.3618555175996
        },
        "chatglm3-6b": {
            "rating": 1033.0929718061432,
            "rating_q975": 1073.9140819290574,
            "rating_q025": 992.2718616832291
        }
    },
    "math": {
        "claude-opus-4-5-20251101": {
            "rating": 1480.5574709149237,
            "rating_q975": 1504.5064774899854,
            "rating_q025": 1456.608464339862
        },
        "gemini-3-pro": {
            "rating": 1476.0729095792922,
            "rating_q975": 1494.4502688249363,
            "rating_q025": 1457.695550333648
        },
        "gpt-5.1-high": {
            "rating": 1474.3992945120165,
            "rating_q975": 1495.131297277773,
            "rating_q025": 1453.66729174626
        },
        "claude-opus-4-5-20251101-thinking-32k": {
            "rating": 1472.2212624116385,
            "rating_q975": 1497.310989382572,
            "rating_q025": 1447.131535440705
        },
        "claude-sonnet-4-5-20250929-thinking-32k": {
            "rating": 1463.318385349207,
            "rating_q975": 1478.3317434893547,
            "rating_q025": 1448.305027209059
        },
        "o3-2025-04-16": {
            "rating": 1456.132457625925,
            "rating_q975": 1465.9537341777293,
            "rating_q025": 1446.311181074121
        },
        "gemini-2.5-pro": {
            "rating": 1452.768926966765,
            "rating_q975": 1461.9421302058965,
            "rating_q025": 1443.5957237276336
        },
        "grok-4.1-thinking": {
            "rating": 1450.8822807553938,
            "rating_q975": 1470.6035332671165,
            "rating_q025": 1431.1610282436711
        },
        "claude-opus-4-1-20250805-thinking-16k": {
            "rating": 1446.3216071059644,
            "rating_q975": 1458.0498110217484,
            "rating_q025": 1434.5934031901804
        },
        "qwen3-max-preview": {
            "rating": 1441.9038901313713,
            "rating_q975": 1456.913997346487,
            "rating_q025": 1426.8937829162558
        },
        "gpt-5-high": {
            "rating": 1438.426167069622,
            "rating_q975": 1451.9276905730362,
            "rating_q025": 1424.9246435662076
        },
        "grok-4-0709": {
            "rating": 1437.7179312144106,
            "rating_q975": 1450.1082425409827,
            "rating_q025": 1425.3276198878384
        },
        "qwen3-max-2025-09-23": {
            "rating": 1436.6879624595538,
            "rating_q975": 1460.115045155903,
            "rating_q025": 1413.2608797632045
        },
        "claude-opus-4-1-20250805": {
            "rating": 1435.7792095431528,
            "rating_q975": 1446.1724239674895,
            "rating_q025": 1425.385995118816
        },
        "grok-4.1": {
            "rating": 1434.7104606768755,
            "rating_q975": 1452.8492403560565,
            "rating_q025": 1416.5716809976946
        },
        "kimi-k2-thinking-turbo": {
            "rating": 1432.2901917276938,
            "rating_q975": 1452.2073031540683,
            "rating_q025": 1412.3730803013193
        },
        "claude-sonnet-4-5-20250929": {
            "rating": 1432.195559540197,
            "rating_q975": 1448.2920713652284,
            "rating_q025": 1416.0990477151659
        },
        "glm-4.6": {
            "rating": 1432.0641595586897,
            "rating_q975": 1448.239099372896,
            "rating_q025": 1415.8892197444834
        },
        "deepseek-v3.2": {
            "rating": 1431.8004659909107,
            "rating_q975": 1459.6490178924353,
            "rating_q025": 1403.951914089386
        },
        "qwen3-235b-a22b-instruct-2507": {
            "rating": 1430.422557717042,
            "rating_q975": 1441.4043865396868,
            "rating_q025": 1419.4407288943974
        },
        "longcat-flash-chat": {
            "rating": 1429.1436416940678,
            "rating_q975": 1451.0998673225695,
            "rating_q025": 1407.1874160655661
        },
        "deepseek-v3.2-exp-thinking": {
            "rating": 1428.5414223110947,
            "rating_q975": 1454.9898760653684,
            "rating_q025": 1402.092968556821
        },
        "qwen3-next-80b-a3b-instruct": {
            "rating": 1427.5551278180012,
            "rating_q975": 1444.3692288787631,
            "rating_q025": 1410.7410267572393
        },
        "grok-4-fast-chat": {
            "rating": 1426.7146138603425,
            "rating_q975": 1455.2427621074073,
            "rating_q025": 1398.1864656132777
        },
        "gemini-2.5-flash-preview-09-2025": {
            "rating": 1423.8397943791288,
            "rating_q975": 1438.5310136646654,
            "rating_q025": 1409.1485750935922
        },
        "deepseek-v3.1-thinking": {
            "rating": 1422.3361512838308,
            "rating_q975": 1444.329617109981,
            "rating_q025": 1400.3426854576805
        },
        "claude-opus-4-20250514-thinking-16k": {
            "rating": 1422.2188149106973,
            "rating_q975": 1434.1878900720656,
            "rating_q025": 1410.2497397493291
        },
        "deepseek-v3.2-thinking": {
            "rating": 1421.4226876195278,
            "rating_q975": 1452.4790720920407,
            "rating_q025": 1390.3663031470148
        },
        "o4-mini-2025-04-16": {
            "rating": 1420.2434977538394,
            "rating_q975": 1430.7698809876147,
            "rating_q025": 1409.7171145200641
        },
        "glm-4.5": {
            "rating": 1420.0961212522895,
            "rating_q975": 1435.4452012969787,
            "rating_q025": 1404.7470412076004
        },
        "deepseek-v3.1": {
            "rating": 1418.1249976079218,
            "rating_q975": 1436.2859618261273,
            "rating_q025": 1399.9640333897164
        },
        "deepseek-v3.1-terminus-thinking": {
            "rating": 1417.6991148266834,
            "rating_q975": 1457.7410307745108,
            "rating_q025": 1377.657198878856
        },
        "deepseek-v3.2-exp": {
            "rating": 1417.1001306353191,
            "rating_q975": 1438.9028927310426,
            "rating_q025": 1395.2973685395957
        },
        "kimi-k2-0905-preview": {
            "rating": 1416.6604374216963,
            "rating_q975": 1437.4521261976702,
            "rating_q025": 1395.8687486457225
        },
        "gpt-5-mini-high": {
            "rating": 1415.3413122792088,
            "rating_q975": 1430.8589785257784,
            "rating_q025": 1399.823646032639
        },
        "gpt-5-chat": {
            "rating": 1414.9126183705432,
            "rating_q975": 1428.4889351084803,
            "rating_q025": 1401.3363016326061
        },
        "qwen3-vl-235b-a22b-instruct": {
            "rating": 1414.3847937908563,
            "rating_q975": 1439.0839990995246,
            "rating_q025": 1389.685588482188
        },
        "qwen3-vl-235b-a22b-thinking": {
            "rating": 1414.1849623757514,
            "rating_q975": 1442.6977728944544,
            "rating_q025": 1385.6721518570484
        },
        "gpt-4.5-preview-2025-02-27": {
            "rating": 1414.0661159866547,
            "rating_q975": 1429.0679898991586,
            "rating_q025": 1399.0642420741508
        },
        "grok-4-1-fast-reasoning": {
            "rating": 1413.6499640619113,
            "rating_q975": 1439.9292814314217,
            "rating_q025": 1387.370646692401
        },
        "deepseek-r1": {
            "rating": 1413.4032103121808,
            "rating_q975": 1427.0982285410366,
            "rating_q025": 1399.708192083325
        },
        "grok-4-fast-reasoning": {
            "rating": 1413.242004890183,
            "rating_q975": 1431.3977614433404,
            "rating_q025": 1395.0862483370254
        },
        "gemini-2.5-flash": {
            "rating": 1413.2392008215159,
            "rating_q975": 1422.0256061225357,
            "rating_q025": 1404.452795520496
        },
        "gpt-5.1": {
            "rating": 1413.1500434484994,
            "rating_q975": 1432.0007341890603,
            "rating_q025": 1394.2993527079386
        },
        "ernie-5.0-preview-1103": {
            "rating": 1411.0218702839477,
            "rating_q975": 1439.418382197274,
            "rating_q025": 1382.6253583706214
        },
        "o1-2024-12-17": {
            "rating": 1410.9926873338375,
            "rating_q975": 1421.393432318369,
            "rating_q025": 1400.591942349306
        },
        "o3-mini-high": {
            "rating": 1409.6157601789353,
            "rating_q975": 1422.449276922595,
            "rating_q025": 1396.7822434352756
        },
        "amazon-nova-experimental-chat-10-09": {
            "rating": 1408.5306579412336,
            "rating_q975": 1436.7786558696694,
            "rating_q025": 1380.2826600127978
        },
        "claude-sonnet-4-20250514-thinking-32k": {
            "rating": 1406.6004338148966,
            "rating_q975": 1419.099088831352,
            "rating_q025": 1394.1017787984413
        },
        "mistral-large-3": {
            "rating": 1404.4696715014804,
            "rating_q975": 1433.1662102482262,
            "rating_q025": 1375.7731327547347
        },
        "mistral-medium-2508": {
            "rating": 1404.4392453669766,
            "rating_q975": 1415.9750455684964,
            "rating_q025": 1392.9034451654568
        },
        "qwen3-32b": {
            "rating": 1403.6961900275414,
            "rating_q975": 1433.803370732049,
            "rating_q025": 1373.589009323034
        },
        "hunyuan-t1-20250711": {
            "rating": 1403.6927763140156,
            "rating_q975": 1441.5125144662095,
            "rating_q025": 1365.8730381618218
        },
        "chatgpt-4o-latest-20250326": {
            "rating": 1403.2951982710867,
            "rating_q975": 1412.1350336166986,
            "rating_q025": 1394.455362925475
        },
        "qwen3-235b-a22b-thinking-2507": {
            "rating": 1403.0491720847317,
            "rating_q975": 1427.1810544501022,
            "rating_q025": 1378.9172897193612
        },
        "minimax-m1": {
            "rating": 1402.753975701966,
            "rating_q975": 1415.7896470712146,
            "rating_q025": 1389.7183043327175
        },
        "claude-opus-4-20250514": {
            "rating": 1402.2671843679316,
            "rating_q975": 1412.9643724699763,
            "rating_q025": 1391.5699962658869
        },
        "qwen3-235b-a22b": {
            "rating": 1401.7521684042945,
            "rating_q975": 1415.5540259145328,
            "rating_q025": 1387.9503108940562
        },
        "qwen3-next-80b-a3b-thinking": {
            "rating": 1401.0029704483309,
            "rating_q975": 1420.4011146095354,
            "rating_q025": 1381.6048262871263
        },
        "mai-1-preview": {
            "rating": 1400.6412592009685,
            "rating_q975": 1419.822491494072,
            "rating_q025": 1381.460026907865
        },
        "deepseek-v3.1-terminus": {
            "rating": 1399.2664369818854,
            "rating_q975": 1437.7367355783158,
            "rating_q025": 1360.796138385455
        },
        "qwen3-235b-a22b-no-thinking": {
            "rating": 1398.4124256330294,
            "rating_q975": 1410.15803568583,
            "rating_q025": 1386.6668155802288
        },
        "deepseek-r1-0528": {
            "rating": 1398.0159864490383,
            "rating_q975": 1417.212836330187,
            "rating_q025": 1378.8191365678897
        },
        "glm-4.5-air": {
            "rating": 1397.3486793856773,
            "rating_q975": 1412.2039035600528,
            "rating_q025": 1382.4934552113018
        },
        "amazon-nova-experimental-chat-10-20": {
            "rating": 1397.1295669600236,
            "rating_q975": 1422.6164089806105,
            "rating_q025": 1371.6427249394367
        },
        "grok-3-mini-high": {
            "rating": 1395.293197915845,
            "rating_q975": 1413.0576188363084,
            "rating_q025": 1377.5287769953816
        },
        "nvidia-llama-3.3-nemotron-super-49b-v1.5": {
            "rating": 1394.4658738952953,
            "rating_q975": 1431.7292648544937,
            "rating_q025": 1357.2024829360969
        },
        "claude-haiku-4-5-20251001": {
            "rating": 1393.9136784178509,
            "rating_q975": 1409.0590898278135,
            "rating_q025": 1378.7682670078882
        },
        "kimi-k2-0711-preview": {
            "rating": 1393.7417224181954,
            "rating_q975": 1407.5080281807361,
            "rating_q025": 1379.9754166556547
        },
        "claude-sonnet-4-20250514": {
            "rating": 1389.35073542697,
            "rating_q975": 1400.5901707418702,
            "rating_q025": 1378.1113001120698
        },
        "o1-preview": {
            "rating": 1388.2708310461844,
            "rating_q975": 1397.4552126555561,
            "rating_q025": 1379.0864494368127
        },
        "gpt-oss-120b": {
            "rating": 1387.658130675118,
            "rating_q975": 1401.369757213698,
            "rating_q025": 1373.946504136538
        },
        "qwen3-30b-a3b-instruct-2507": {
            "rating": 1387.5049415999008,
            "rating_q975": 1402.4192615012712,
            "rating_q025": 1372.5906216985304
        },
        "o3-mini": {
            "rating": 1387.1612681978759,
            "rating_q975": 1395.323038774548,
            "rating_q025": 1378.9994976212038
        },
        "claude-3-7-sonnet-20250219-thinking-32k": {
            "rating": 1387.1185526889246,
            "rating_q975": 1397.860535400605,
            "rating_q025": 1376.3765699772443
        },
        "llama-3.1-nemotron-ultra-253b-v1": {
            "rating": 1382.8638258854255,
            "rating_q975": 1420.5063231521451,
            "rating_q025": 1345.221328618706
        },
        "grok-3-preview-02-24": {
            "rating": 1381.2207278588817,
            "rating_q975": 1391.9873695847969,
            "rating_q025": 1370.4540861329665
        },
        "qwen3-coder-480b-a35b-instruct": {
            "rating": 1380.5685654211636,
            "rating_q975": 1395.4361158108293,
            "rating_q025": 1365.701015031498
        },
        "deepseek-v3-0324": {
            "rating": 1375.3577235675937,
            "rating_q975": 1385.4725421752053,
            "rating_q025": 1365.242904959982
        },
        "gpt-4.1-2025-04-14": {
            "rating": 1375.1830187401458,
            "rating_q975": 1385.214007040348,
            "rating_q025": 1365.1520304399437
        },
        "grok-3-mini-beta": {
            "rating": 1373.1310575683074,
            "rating_q975": 1386.9134035974173,
            "rating_q025": 1359.3487115391974
        },
        "gemini-2.5-flash-lite-preview-06-17-thinking": {
            "rating": 1372.091112744704,
            "rating_q975": 1384.2898906203736,
            "rating_q025": 1359.8923348690346
        },
        "gemini-2.5-flash-lite-preview-09-2025-no-thinking": {
            "rating": 1370.7315131059706,
            "rating_q975": 1385.2955708127274,
            "rating_q025": 1356.1674553992138
        },
        "step-3": {
            "rating": 1370.315231773752,
            "rating_q975": 1401.9548961577966,
            "rating_q025": 1338.6755673897073
        },
        "qwen2.5-max": {
            "rating": 1369.085358570616,
            "rating_q975": 1378.6023485856972,
            "rating_q025": 1359.568368555535
        },
        "qwq-32b": {
            "rating": 1366.1843829495822,
            "rating_q975": 1379.3294225770776,
            "rating_q025": 1353.0393433220868
        },
        "o1-mini": {
            "rating": 1365.168253550359,
            "rating_q975": 1372.441293878167,
            "rating_q025": 1357.8952132225509
        },
        "minimax-m2": {
            "rating": 1364.4034405498423,
            "rating_q975": 1398.7951622430603,
            "rating_q025": 1330.0117188566244
        },
        "glm-4.5v": {
            "rating": 1363.447341774,
            "rating_q975": 1397.3587333081443,
            "rating_q025": 1329.5359502398558
        },
        "claude-3-7-sonnet-20250219": {
            "rating": 1361.2699934669013,
            "rating_q975": 1370.8995877629027,
            "rating_q025": 1351.6403991708999
        },
        "qwen3-30b-a3b": {
            "rating": 1360.4518745177136,
            "rating_q975": 1373.7571178201156,
            "rating_q025": 1347.1466312153116
        },
        "ling-flash-2.0": {
            "rating": 1360.1533725101392,
            "rating_q975": 1386.821804329304,
            "rating_q025": 1333.4849406909743
        },
        "gemini-2.0-flash-001": {
            "rating": 1358.1901960440794,
            "rating_q975": 1366.8458619529667,
            "rating_q025": 1349.534530135192
        },
        "gpt-4.1-mini-2025-04-14": {
            "rating": 1357.7554939829797,
            "rating_q975": 1368.6671471228663,
            "rating_q025": 1346.8438408430932
        },
        "gpt-5-nano-high": {
            "rating": 1354.442743167309,
            "rating_q975": 1381.0326235690861,
            "rating_q025": 1327.8528627655317
        },
        "mistral-medium-2505": {
            "rating": 1353.5469615572215,
            "rating_q975": 1365.2567602138852,
            "rating_q025": 1341.8371629005578
        },
        "ring-flash-2.0": {
            "rating": 1352.6599224188694,
            "rating_q975": 1379.5173036199799,
            "rating_q025": 1325.802541217759
        },
        "hunyuan-turbos-20250416": {
            "rating": 1352.39096009505,
            "rating_q975": 1371.5182784512874,
            "rating_q025": 1333.2636417388128
        },
        "claude-3-5-sonnet-20241022": {
            "rating": 1349.9758768487688,
            "rating_q975": 1356.0585324265053,
            "rating_q025": 1343.8932212710324
        },
        "nova-2-lite": {
            "rating": 1348.323756033345,
            "rating_q975": 1378.5185075482557,
            "rating_q025": 1318.1290045184344
        },
        "mistral-small-2506": {
            "rating": 1345.860566073796,
            "rating_q975": 1362.9181290517029,
            "rating_q025": 1328.8030030958892
        },
        "claude-3-5-sonnet-20240620": {
            "rating": 1343.3008315628965,
            "rating_q975": 1350.1497137645274,
            "rating_q025": 1336.4519493612656
        },
        "gemini-1.5-pro-002": {
            "rating": 1340.77504441686,
            "rating_q975": 1347.5089456188164,
            "rating_q025": 1334.0411432149037
        },
        "gpt-oss-20b": {
            "rating": 1338.6595372106844,
            "rating_q975": 1360.361525417624,
            "rating_q025": 1316.9575490037448
        },
        "gemini-2.0-flash-lite-preview-02-05": {
            "rating": 1329.1141230102858,
            "rating_q975": 1339.0243199580768,
            "rating_q025": 1319.2039260624947
        },
        "qwen-plus-0125": {
            "rating": 1328.5494066312947,
            "rating_q975": 1347.6736176684649,
            "rating_q025": 1309.4251955941245
        },
        "gemma-3-27b-it": {
            "rating": 1325.934623368093,
            "rating_q975": 1335.1511370087746,
            "rating_q025": 1316.7181097274115
        },
        "llama-4-maverick-17b-128e-instruct": {
            "rating": 1324.7452980613284,
            "rating_q975": 1335.2408154565005,
            "rating_q025": 1314.2497806661563
        },
        "gemma-3-12b-it": {
            "rating": 1322.5521916124148,
            "rating_q975": 1349.71908734369,
            "rating_q025": 1295.3852958811397
        },
        "llama-3.1-405b-instruct-fp8": {
            "rating": 1321.4873631352998,
            "rating_q975": 1328.4053190255906,
            "rating_q025": 1314.569407245009
        },
        "llama-3.1-405b-instruct-bf16": {
            "rating": 1317.4388307696127,
            "rating_q975": 1324.9423221767995,
            "rating_q025": 1309.9353393624258
        },
        "step-2-16k-exp-202412": {
            "rating": 1316.8381207382927,
            "rating_q975": 1336.459055978364,
            "rating_q025": 1297.2171854982214
        },
        "llama-4-scout-17b-16e-instruct": {
            "rating": 1316.6740516147593,
            "rating_q975": 1329.5443829776493,
            "rating_q025": 1303.8037202518692
        },
        "deepseek-v3": {
            "rating": 1315.9752416051083,
            "rating_q975": 1326.3007082153767,
            "rating_q025": 1305.6497749948398
        },
        "athene-v2-chat": {
            "rating": 1315.7635395239477,
            "rating_q975": 1324.7903167135769,
            "rating_q025": 1306.7367623343184
        },
        "command-a-03-2025": {
            "rating": 1314.740370926792,
            "rating_q975": 1323.7692428437338,
            "rating_q025": 1305.71149900985
        },
        "claude-3-opus-20240229": {
            "rating": 1313.2410950610397,
            "rating_q975": 1318.9807793665436,
            "rating_q025": 1307.5014107555357
        },
        "gpt-4o-2024-08-06": {
            "rating": 1310.9050663250491,
            "rating_q975": 1318.3185193509498,
            "rating_q025": 1303.4916132991484
        },
        "yi-lightning": {
            "rating": 1310.4746579163766,
            "rating_q975": 1319.8154271829878,
            "rating_q025": 1301.1338886497654
        },
        "qwen2.5-plus-1127": {
            "rating": 1309.5474995255709,
            "rating_q975": 1322.9309564063328,
            "rating_q025": 1296.164042644809
        },
        "step-1o-turbo-202506": {
            "rating": 1308.418733099615,
            "rating_q975": 1330.5664757171508,
            "rating_q025": 1286.2709904820795
        },
        "gpt-4o-2024-05-13": {
            "rating": 1307.9916782553223,
            "rating_q975": 1314.0908742138438,
            "rating_q025": 1301.8924822968008
        },
        "gpt-4-1106-preview": {
            "rating": 1306.3236394042092,
            "rating_q975": 1313.5019963310815,
            "rating_q025": 1299.1452824773369
        },
        "gemini-advanced-0514": {
            "rating": 1305.0750638945642,
            "rating_q975": 1314.0798164366868,
            "rating_q025": 1296.0703113524416
        },
        "hunyuan-turbos-20250226": {
            "rating": 1304.0261176716376,
            "rating_q975": 1334.8509259769053,
            "rating_q025": 1273.20130936637
        },
        "gpt-4-0125-preview": {
            "rating": 1302.0528433732761,
            "rating_q975": 1309.2668817455894,
            "rating_q025": 1294.8388050009628
        },
        "glm-4-plus-0111": {
            "rating": 1300.4262192776628,
            "rating_q975": 1319.440821088483,
            "rating_q025": 1281.4116174668425
        },
        "qwen2.5-72b-instruct": {
            "rating": 1300.0124647270861,
            "rating_q975": 1307.6504777458288,
            "rating_q025": 1292.3744517083435
        },
        "gpt-4-turbo-2024-04-09": {
            "rating": 1299.2359200389446,
            "rating_q975": 1306.142954586097,
            "rating_q025": 1292.3288854917923
        },
        "llama-3.3-70b-instruct": {
            "rating": 1299.0366985165856,
            "rating_q975": 1306.2636234388985,
            "rating_q025": 1291.8097735942727
        },
        "gemini-1.5-pro-001": {
            "rating": 1298.1935828293854,
            "rating_q975": 1305.485180910976,
            "rating_q025": 1290.9019847477948
        },
        "hunyuan-large-2025-02-10": {
            "rating": 1296.6783140135203,
            "rating_q975": 1320.4609479523263,
            "rating_q025": 1272.8956800747144
        },
        "deepseek-v2.5-1210": {
            "rating": 1296.5185883328622,
            "rating_q975": 1312.939560180091,
            "rating_q025": 1280.0976164856336
        },
        "grok-2-2024-08-13": {
            "rating": 1296.3985587620575,
            "rating_q975": 1303.0104775412444,
            "rating_q025": 1289.7866399828706
        },
        "qwen-max-0919": {
            "rating": 1294.6905371311263,
            "rating_q975": 1306.1365862405141,
            "rating_q025": 1283.2444880217386
        },
        "hunyuan-standard-2025-02-10": {
            "rating": 1293.984109925705,
            "rating_q975": 1317.9468114289705,
            "rating_q025": 1270.0214084224397
        },
        "gemini-1.5-flash-002": {
            "rating": 1291.473184815859,
            "rating_q975": 1299.5158319001646,
            "rating_q025": 1283.4305377315534
        },
        "hunyuan-large-vision": {
            "rating": 1291.4659764453509,
            "rating_q975": 1319.7991138600828,
            "rating_q025": 1263.132839030619
        },
        "mistral-large-2407": {
            "rating": 1291.252351550183,
            "rating_q975": 1298.7047173427202,
            "rating_q025": 1283.7999857576458
        },
        "deepseek-v2.5": {
            "rating": 1291.2207606921684,
            "rating_q975": 1300.46971245227,
            "rating_q025": 1281.9718089320668
        },
        "glm-4-plus": {
            "rating": 1290.6061259165926,
            "rating_q975": 1300.0517713653294,
            "rating_q025": 1281.160480467856
        },
        "magistral-medium-2506": {
            "rating": 1287.3399847349153,
            "rating_q975": 1312.1930058629114,
            "rating_q025": 1262.4869636069193
        },
        "claude-3-5-haiku-20241022": {
            "rating": 1286.3079238978173,
            "rating_q975": 1293.4578522863098,
            "rating_q025": 1279.1579955093248
        },
        "mistral-large-2411": {
            "rating": 1284.641969990491,
            "rating_q975": 1293.5130039186304,
            "rating_q025": 1275.7709360623514
        },
        "gpt-4-0314": {
            "rating": 1283.5382547426725,
            "rating_q975": 1292.6990805953026,
            "rating_q025": 1274.3774288900424
        },
        "mistral-small-3.1-24b-instruct-2503": {
            "rating": 1282.6567281134842,
            "rating_q975": 1295.2948353960319,
            "rating_q025": 1270.0186208309365
        },
        "hunyuan-turbo-0110": {
            "rating": 1281.7076089243387,
            "rating_q975": 1312.1907263606638,
            "rating_q025": 1251.2244914880137
        },
        "llama-3.1-nemotron-70b-instruct": {
            "rating": 1281.632864267946,
            "rating_q975": 1298.204563406789,
            "rating_q025": 1265.0611651291028
        },
        "gpt-4o-mini-2024-07-18": {
            "rating": 1279.4671726125341,
            "rating_q975": 1285.761335165504,
            "rating_q025": 1273.1730100595641
        },
        "gpt-4.1-nano-2025-04-14": {
            "rating": 1279.0024588871124,
            "rating_q975": 1302.0312285181224,
            "rating_q025": 1255.9736892561025
        },
        "qwen2-72b-instruct": {
            "rating": 1275.5119517461117,
            "rating_q975": 1284.3753248595754,
            "rating_q025": 1266.648578632648
        },
        "grok-2-mini-2024-08-13": {
            "rating": 1275.468238873707,
            "rating_q975": 1282.4948130176247,
            "rating_q025": 1268.4416647297892
        },
        "gpt-4-0613": {
            "rating": 1275.187588846182,
            "rating_q975": 1283.0087479283634,
            "rating_q025": 1267.3664297640007
        },
        "qwen2.5-coder-32b-instruct": {
            "rating": 1273.3307470441782,
            "rating_q975": 1292.3541616831437,
            "rating_q025": 1254.3073324052127
        },
        "llama-3.1-nemotron-51b-instruct": {
            "rating": 1272.9319395279808,
            "rating_q975": 1295.2213672793573,
            "rating_q025": 1250.6425117766044
        },
        "amazon-nova-pro-v1.0": {
            "rating": 1272.5349602090369,
            "rating_q975": 1281.9737103105329,
            "rating_q025": 1263.0962101075409
        },
        "deepseek-coder-v2": {
            "rating": 1272.2808483272825,
            "rating_q975": 1285.406115344305,
            "rating_q025": 1259.15558131026
        },
        "llama-3.1-70b-instruct": {
            "rating": 1272.0199450525172,
            "rating_q975": 1278.9561940076094,
            "rating_q025": 1265.083696097425
        },
        "gemma-3n-e4b-it": {
            "rating": 1270.1962220932276,
            "rating_q975": 1284.5392673178924,
            "rating_q025": 1255.8531768685627
        },
        "phi-4": {
            "rating": 1267.8321060247695,
            "rating_q975": 1277.9404421934767,
            "rating_q025": 1257.7237698560623
        },
        "llama-3.1-tulu-3-70b": {
            "rating": 1264.9271849583624,
            "rating_q975": 1289.1989387279293,
            "rating_q025": 1240.6554311887955
        },
        "mistral-small-24b-instruct-2501": {
            "rating": 1264.329384203415,
            "rating_q975": 1277.3801737705141,
            "rating_q025": 1251.2785946363158
        },
        "athene-70b-0725": {
            "rating": 1261.763269393993,
            "rating_q975": 1271.7107132594429,
            "rating_q025": 1251.815825528543
        },
        "llama-3-70b-instruct": {
            "rating": 1259.1807155637257,
            "rating_q975": 1265.9146232276871,
            "rating_q025": 1252.4468078997643
        },
        "gemma-3-4b-it": {
            "rating": 1257.729492652131,
            "rating_q975": 1285.87685058335,
            "rating_q025": 1229.582134720912
        },
        "gemini-1.5-flash-001": {
            "rating": 1257.638444831638,
            "rating_q975": 1265.0488746478413,
            "rating_q025": 1250.2280150154347
        },
        "nemotron-4-340b-instruct": {
            "rating": 1255.6260941854857,
            "rating_q975": 1267.2297659065798,
            "rating_q025": 1244.0224224643916
        },
        "claude-3-sonnet-20240229": {
            "rating": 1255.5404236747797,
            "rating_q975": 1262.9793135413504,
            "rating_q025": 1248.101533808209
        },
        "hunyuan-standard-256k": {
            "rating": 1254.6099120990718,
            "rating_q975": 1282.720801000791,
            "rating_q025": 1226.4990231973527
        },
        "glm-4-0520": {
            "rating": 1248.9302448574567,
            "rating_q975": 1264.098448222856,
            "rating_q025": 1233.7620414920575
        },
        "reka-core-20240904": {
            "rating": 1248.6905287284935,
            "rating_q975": 1262.6211328633883,
            "rating_q025": 1234.7599245935987
        },
        "amazon-nova-lite-v1.0": {
            "rating": 1248.1775491643527,
            "rating_q975": 1258.5946377490181,
            "rating_q025": 1237.7604605796873
        },
        "jamba-1.5-large": {
            "rating": 1247.8848039817126,
            "rating_q975": 1262.9447065290076,
            "rating_q025": 1232.8249014344176
        },
        "mistral-large-2402": {
            "rating": 1245.9895490882122,
            "rating_q975": 1254.4602579294294,
            "rating_q025": 1237.518840246995
        },
        "gemma-2-27b-it": {
            "rating": 1244.9527889802348,
            "rating_q975": 1251.1369323802862,
            "rating_q025": 1238.7686455801834
        },
        "reka-flash-20240904": {
            "rating": 1233.7165805707662,
            "rating_q975": 1247.4179648114,
            "rating_q025": 1220.0151963301323
        },
        "c4ai-aya-expanse-32b": {
            "rating": 1232.6262554263408,
            "rating_q975": 1241.7865599418255,
            "rating_q025": 1223.465950910856
        },
        "claude-3-haiku-20240307": {
            "rating": 1232.3076948084617,
            "rating_q975": 1239.09142909201,
            "rating_q025": 1225.5239605249135
        },
        "command-r-plus-08-2024": {
            "rating": 1232.280921321863,
            "rating_q975": 1245.8188563832816,
            "rating_q025": 1218.7429862604442
        },
        "olmo-2-0325-32b-instruct": {
            "rating": 1232.2053014775815,
            "rating_q975": 1260.3023737144808,
            "rating_q025": 1204.1082292406822
        },
        "gemini-1.5-flash-8b-001": {
            "rating": 1230.9042030225687,
            "rating_q975": 1238.8246775600037,
            "rating_q025": 1222.9837284851337
        },
        "mixtral-8x22b-instruct-v0.1": {
            "rating": 1230.0370359557996,
            "rating_q975": 1238.4246133658667,
            "rating_q025": 1221.6494585457326
        },
        "amazon-nova-micro-v1.0": {
            "rating": 1228.6099103386064,
            "rating_q975": 1238.9537918376259,
            "rating_q025": 1218.2660288395869
        },
        "qwen1.5-110b-chat": {
            "rating": 1223.540694330624,
            "rating_q975": 1234.373208754023,
            "rating_q025": 1212.7081799072253
        },
        "mistral-medium": {
            "rating": 1223.135682093608,
            "rating_q975": 1233.4342835236866,
            "rating_q025": 1212.8370806635294
        },
        "qwq-32b-preview": {
            "rating": 1221.4951399708145,
            "rating_q975": 1245.6371045736603,
            "rating_q025": 1197.3531753679688
        },
        "phi-3-medium-4k-instruct": {
            "rating": 1218.0874244698316,
            "rating_q975": 1228.1852098369998,
            "rating_q025": 1207.9896391026634
        },
        "gemma-2-9b-it": {
            "rating": 1217.3404192065568,
            "rating_q975": 1224.4022490672414,
            "rating_q025": 1210.2785893458722
        },
        "ministral-8b-2410": {
            "rating": 1216.4528491465665,
            "rating_q975": 1235.813606358354,
            "rating_q025": 1197.0920919347789
        },
        "yi-1.5-34b-chat": {
            "rating": 1215.751994451602,
            "rating_q975": 1226.3303839099133,
            "rating_q025": 1205.1736049932908
        },
        "command-r-plus": {
            "rating": 1214.007671583437,
            "rating_q975": 1221.8766312077869,
            "rating_q025": 1206.1387119590872
        },
        "reka-flash-21b-20240226-online": {
            "rating": 1213.4750034443239,
            "rating_q975": 1226.8108029365085,
            "rating_q025": 1200.1392039521393
        },
        "llama-3.1-tulu-3-8b": {
            "rating": 1211.7438489070453,
            "rating_q975": 1236.7651758908958,
            "rating_q025": 1186.7225219231948
        },
        "internlm2_5-20b-chat": {
            "rating": 1210.8249394220554,
            "rating_q975": 1225.2691798960204,
            "rating_q025": 1196.3806989480904
        },
        "qwen1.5-72b-chat": {
            "rating": 1210.2291133316457,
            "rating_q975": 1219.377623744736,
            "rating_q025": 1201.0806029185555
        },
        "command-r-08-2024": {
            "rating": 1206.6426320739595,
            "rating_q975": 1219.8286189905223,
            "rating_q025": 1193.4566451573967
        },
        "gemma-2-9b-it-simpo": {
            "rating": 1205.0299989008276,
            "rating_q975": 1219.8752807007045,
            "rating_q025": 1190.1847171009508
        },
        "qwen1.5-32b-chat": {
            "rating": 1202.541407419244,
            "rating_q975": 1213.724641677893,
            "rating_q025": 1191.358173160595
        },
        "gpt-3.5-turbo-1106": {
            "rating": 1202.1876778209148,
            "rating_q975": 1216.961841406237,
            "rating_q025": 1187.4135142355926
        },
        "c4ai-aya-expanse-8b": {
            "rating": 1201.0557192397946,
            "rating_q975": 1215.770574480369,
            "rating_q025": 1186.3408639992201
        },
        "reka-flash-21b-20240226": {
            "rating": 1200.7354609086237,
            "rating_q975": 1211.659818247872,
            "rating_q025": 1189.8111035693755
        },
        "gpt-3.5-turbo-0125": {
            "rating": 1199.5589723442445,
            "rating_q975": 1207.4562283070532,
            "rating_q025": 1191.6617163814358
        },
        "granite-3.1-2b-instruct": {
            "rating": 1198.7200483929266,
            "rating_q975": 1224.681184248859,
            "rating_q025": 1172.7589125369943
        },
        "zephyr-orpo-141b-A35b-v0.1": {
            "rating": 1198.1925424111364,
            "rating_q975": 1220.1701258020491,
            "rating_q025": 1176.2149590202237
        },
        "granite-3.0-8b-instruct": {
            "rating": 1197.0208732082128,
            "rating_q975": 1215.4283029545077,
            "rating_q025": 1178.613443461918
        },
        "gemini-pro": {
            "rating": 1196.873943584436,
            "rating_q975": 1215.6591617398153,
            "rating_q025": 1178.0887254290565
        },
        "dbrx-instruct-preview": {
            "rating": 1196.720365070039,
            "rating_q975": 1207.7205249869235,
            "rating_q025": 1185.7202051531544
        },
        "phi-3-mini-4k-instruct-june-2024": {
            "rating": 1195.43428375738,
            "rating_q975": 1208.6058850497454,
            "rating_q025": 1182.2626824650144
        },
        "phi-3-small-8k-instruct": {
            "rating": 1195.0470650788573,
            "rating_q975": 1207.301826064338,
            "rating_q025": 1182.7923040933765
        },
        "granite-3.1-8b-instruct": {
            "rating": 1194.6503874215737,
            "rating_q975": 1222.2371024221354,
            "rating_q025": 1167.063672421012
        },
        "llama-3-8b-instruct": {
            "rating": 1194.22915091597,
            "rating_q975": 1201.4346165441675,
            "rating_q025": 1187.0236852877724
        },
        "llama-3.1-8b-instruct": {
            "rating": 1194.1626696379767,
            "rating_q975": 1201.482172577485,
            "rating_q025": 1186.8431666984684
        },
        "mixtral-8x7b-instruct-v0.1": {
            "rating": 1193.0747268471077,
            "rating_q975": 1201.0552703167593,
            "rating_q025": 1185.0941833774561
        },
        "gemini-pro-dev-api": {
            "rating": 1192.914848517913,
            "rating_q975": 1206.3998014733963,
            "rating_q025": 1179.4298955624297
        },
        "jamba-1.5-mini": {
            "rating": 1188.567660133571,
            "rating_q975": 1204.2030202429678,
            "rating_q025": 1172.9323000241743
        },
        "command-r": {
            "rating": 1176.5256814191125,
            "rating_q975": 1185.4735729260647,
            "rating_q025": 1167.5777899121604
        },
        "granite-3.0-2b-instruct": {
            "rating": 1169.9238286502853,
            "rating_q975": 1188.4241486448425,
            "rating_q025": 1151.423508655728
        },
        "qwen1.5-14b-chat": {
            "rating": 1168.4241909081709,
            "rating_q975": 1181.5280944502515,
            "rating_q025": 1155.3202873660903
        },
        "llama-3.2-3b-instruct": {
            "rating": 1167.4109019239238,
            "rating_q975": 1182.8829117237342,
            "rating_q025": 1151.9388921241134
        },
        "snowflake-arctic-instruct": {
            "rating": 1163.5771228607655,
            "rating_q975": 1174.3837854304559,
            "rating_q025": 1152.770460291075
        },
        "gemma-2-2b-it": {
            "rating": 1162.3123959763357,
            "rating_q975": 1169.8203699611354,
            "rating_q025": 1154.804421991536
        },
        "starling-lm-7b-beta": {
            "rating": 1161.042248576638,
            "rating_q975": 1174.5480264511418,
            "rating_q025": 1147.5364707021342
        },
        "wizardlm-70b": {
            "rating": 1160.2311872588868,
            "rating_q975": 1179.1343741667094,
            "rating_q025": 1141.3280003510642
        },
        "openchat-3.5-0106": {
            "rating": 1158.6736157013006,
            "rating_q975": 1171.8767721689817,
            "rating_q025": 1145.4704592336195
        },
        "gemma-1.1-7b-it": {
            "rating": 1157.3795643299266,
            "rating_q975": 1168.3287404954424,
            "rating_q025": 1146.4303881644107
        },
        "deepseek-llm-67b-chat": {
            "rating": 1156.6863879723478,
            "rating_q975": 1179.9686832111367,
            "rating_q025": 1133.4040927335589
        },
        "phi-3-mini-4k-instruct": {
            "rating": 1153.7244808876442,
            "rating_q975": 1165.5420285560072,
            "rating_q025": 1141.9069332192812
        },
        "yi-34b-chat": {
            "rating": 1153.5021705504432,
            "rating_q975": 1166.3273900208192,
            "rating_q025": 1140.6769510800673
        },
        "smollm2-1.7b-instruct": {
            "rating": 1152.6597422849431,
            "rating_q975": 1185.0540478699088,
            "rating_q025": 1120.2654366999775
        },
        "openhermes-2.5-mistral-7b": {
            "rating": 1151.8348004637764,
            "rating_q975": 1171.5912595581376,
            "rating_q025": 1132.0783413694153
        },
        "tulu-2-dpo-70b": {
            "rating": 1147.520792480795,
            "rating_q975": 1166.2941736568753,
            "rating_q025": 1128.747411304715
        },
        "phi-3-mini-128k-instruct": {
            "rating": 1140.7252807478358,
            "rating_q975": 1153.5242945603911,
            "rating_q025": 1127.9262669352804
        },
        "llama-2-70b-chat": {
            "rating": 1137.8188189441157,
            "rating_q975": 1147.6024521898066,
            "rating_q025": 1128.0351856984248
        },
        "mistral-7b-instruct-v0.2": {
            "rating": 1130.4752085360674,
            "rating_q975": 1142.2159935308966,
            "rating_q025": 1118.7344235412381
        },
        "starling-lm-7b-alpha": {
            "rating": 1129.2285998683299,
            "rating_q975": 1144.5712477500974,
            "rating_q025": 1113.8859519865623
        },
        "dolphin-2.2.1-mistral-7b": {
            "rating": 1127.034373884283,
            "rating_q975": 1159.433337739645,
            "rating_q025": 1094.6354100289211
        },
        "llama-3.2-1b-instruct": {
            "rating": 1126.7313238594922,
            "rating_q975": 1142.5185254190137,
            "rating_q025": 1110.9441222999708
        },
        "qwen-14b-chat": {
            "rating": 1125.8752116789215,
            "rating_q975": 1149.2982045885144,
            "rating_q025": 1102.4522187693285
        },
        "openchat-3.5": {
            "rating": 1124.865959582868,
            "rating_q975": 1142.9041231133467,
            "rating_q025": 1106.8277960523894
        },
        "qwen1.5-7b-chat": {
            "rating": 1122.4092670221935,
            "rating_q975": 1142.6109760218667,
            "rating_q025": 1102.2075580225203
        },
        "vicuna-33b": {
            "rating": 1117.2609871314949,
            "rating_q975": 1129.4447430819587,
            "rating_q025": 1105.077231181031
        },
        "llama2-70b-steerlm-chat": {
            "rating": 1117.0857611333774,
            "rating_q975": 1143.5334582913515,
            "rating_q025": 1090.6380639754034
        },
        "gemma-7b-it": {
            "rating": 1116.6095561291017,
            "rating_q975": 1132.7300456175656,
            "rating_q025": 1100.489066640638
        },
        "palm-2": {
            "rating": 1113.3972441292624,
            "rating_q975": 1132.6055751100378,
            "rating_q025": 1094.188913148487
        },
        "llama-2-13b-chat": {
            "rating": 1112.1322768790699,
            "rating_q975": 1125.149908102428,
            "rating_q025": 1099.1146456557117
        },
        "solar-10.7b-instruct-v1.0": {
            "rating": 1111.314175095063,
            "rating_q975": 1132.757579596164,
            "rating_q025": 1089.870770593962
        },
        "codellama-34b-instruct": {
            "rating": 1109.3291330351044,
            "rating_q975": 1128.4089718990954,
            "rating_q025": 1090.2492941711134
        },
        "gemma-1.1-2b-it": {
            "rating": 1106.0037818035967,
            "rating_q975": 1121.5951442143037,
            "rating_q025": 1090.4124193928897
        },
        "nous-hermes-2-mixtral-8x7b-dpo": {
            "rating": 1096.8701482562196,
            "rating_q975": 1118.1072851756287,
            "rating_q025": 1075.6330113368106
        },
        "mpt-30b-chat": {
            "rating": 1096.2385767826718,
            "rating_q975": 1130.0244348928802,
            "rating_q025": 1062.4527186724633
        },
        "llama-2-7b-chat": {
            "rating": 1088.2212956499818,
            "rating_q975": 1101.7843490259727,
            "rating_q025": 1074.658242273991
        },
        "stripedhyena-nous-7b": {
            "rating": 1085.7566000075535,
            "rating_q975": 1105.7706840191586,
            "rating_q025": 1065.7425159959485
        },
        "qwen1.5-4b-chat": {
            "rating": 1085.3740381038474,
            "rating_q975": 1102.7302659175834,
            "rating_q025": 1068.0178102901114
        },
        "zephyr-7b-beta": {
            "rating": 1084.483778510847,
            "rating_q975": 1101.193835425964,
            "rating_q025": 1067.7737215957302
        },
        "vicuna-13b": {
            "rating": 1083.3967725780003,
            "rating_q975": 1096.7148065235208,
            "rating_q025": 1070.0787386324798
        },
        "mistral-7b-instruct": {
            "rating": 1082.9359764838482,
            "rating_q975": 1101.5096162059594,
            "rating_q025": 1064.362336761737
        },
        "guanaco-33b": {
            "rating": 1081.9891038524454,
            "rating_q975": 1114.2235565596095,
            "rating_q025": 1049.7546511452813
        },
        "gemma-2b-it": {
            "rating": 1068.4444860690155,
            "rating_q975": 1090.194947129123,
            "rating_q025": 1046.694025008908
        },
        "wizardlm-13b": {
            "rating": 1065.9878033604032,
            "rating_q975": 1086.2971056954582,
            "rating_q025": 1045.6785010253482
        },
        "olmo-7b-instruct": {
            "rating": 1057.8121298727226,
            "rating_q975": 1076.5620400887133,
            "rating_q025": 1039.062219656732
        },
        "vicuna-7b": {
            "rating": 1049.1287311585534,
            "rating_q975": 1070.408755890075,
            "rating_q025": 1027.8487064270316
        },
        "chatglm3-6b": {
            "rating": 1042.5935900696138,
            "rating_q975": 1065.7580097604975,
            "rating_q025": 1019.4291703787301
        },
        "gpt4all-13b-snoozy": {
            "rating": 997.7890133319062,
            "rating_q975": 1034.9755006958965,
            "rating_q025": 960.6025259679159
        },
        "alpaca-13b": {
            "rating": 986.8830314593897,
            "rating_q975": 1009.4725122692852,
            "rating_q025": 964.2935506494943
        },
        "mpt-7b-chat": {
            "rating": 983.2704100400811,
            "rating_q975": 1008.3352684291739,
            "rating_q025": 958.2055516509882
        },
        "RWKV-4-Raven-14B": {
            "rating": 982.0318506834855,
            "rating_q975": 1006.2048429090866,
            "rating_q025": 957.8588584578844
        },
        "koala-13b": {
            "rating": 980.9616920147882,
            "rating_q975": 1002.0921794160588,
            "rating_q025": 959.8312046135177
        },
        "chatglm-6b": {
            "rating": 977.2951342446478,
            "rating_q975": 1002.6183932707731,
            "rating_q025": 951.9718752185224
        },
        "chatglm2-6b": {
            "rating": 971.679991804094,
            "rating_q975": 1006.4091537937546,
            "rating_q025": 936.9508298144334
        },
        "oasst-pythia-12b": {
            "rating": 957.9482580074373,
            "rating_q975": 979.7327296889608,
            "rating_q025": 936.1637863259137
        },
        "dolly-v2-12b": {
            "rating": 946.7813671274465,
            "rating_q975": 975.2895573730411,
            "rating_q025": 918.2731768818519
        },
        "fastchat-t5-3b": {
            "rating": 919.0166269604833,
            "rating_q975": 944.7629113589406,
            "rating_q025": 893.270342562026
        },
        "llama-13b": {
            "rating": 913.0405452195555,
            "rating_q975": 945.9309267406721,
            "rating_q025": 880.1501636984389
        },
        "stablelm-tuned-alpha-7b": {
            "rating": 890.472495343226,
            "rating_q975": 919.1021346422785,
            "rating_q025": 861.8428560441735
        }
    },
    "multiturn": {
        "gemini-3-pro": {
            "rating": 1498.7246199386498,
            "rating_q975": 1511.0234614908197,
            "rating_q025": 1486.4257783864798
        },
        "claude-opus-4-5-20251101": {
            "rating": 1477.7609123927405,
            "rating_q975": 1491.7303744281328,
            "rating_q025": 1463.7914503573481
        },
        "claude-sonnet-4-5-20250929": {
            "rating": 1474.5415572056809,
            "rating_q975": 1484.5569295102807,
            "rating_q025": 1464.526184901081
        },
        "claude-opus-4-5-20251101-thinking-32k": {
            "rating": 1471.860336625412,
            "rating_q975": 1486.4963055643968,
            "rating_q025": 1457.224367686427
        },
        "gpt-5.1-high": {
            "rating": 1470.2665231918522,
            "rating_q975": 1482.912947897728,
            "rating_q025": 1457.6200984859765
        },
        "claude-sonnet-4-5-20250929-thinking-32k": {
            "rating": 1467.547076728051,
            "rating_q975": 1476.8212565969432,
            "rating_q025": 1458.272896859159
        },
        "claude-opus-4-1-20250805-thinking-16k": {
            "rating": 1466.9501733845486,
            "rating_q975": 1474.4112361595621,
            "rating_q025": 1459.4891106095351
        },
        "chatgpt-4o-latest-20250326": {
            "rating": 1465.3201039399728,
            "rating_q975": 1471.6871991419441,
            "rating_q025": 1458.9530087380015
        },
        "grok-4.1": {
            "rating": 1463.9179649115845,
            "rating_q975": 1475.273229987357,
            "rating_q025": 1452.562699835812
        },
        "gpt-4.5-preview-2025-02-27": {
            "rating": 1461.9578801875614,
            "rating_q975": 1475.2563448674507,
            "rating_q025": 1448.659415507672
        },
        "claude-opus-4-1-20250805": {
            "rating": 1461.1216512833912,
            "rating_q975": 1468.1001086082415,
            "rating_q025": 1454.143193958541
        },
        "grok-4.1-thinking": {
            "rating": 1460.7481523351603,
            "rating_q975": 1472.142615027788,
            "rating_q025": 1449.3536896425326
        },
        "gemini-2.5-pro": {
            "rating": 1453.99172101171,
            "rating_q975": 1460.3024585405772,
            "rating_q025": 1447.680983482843
        },
        "gpt-5.1": {
            "rating": 1446.9212419277098,
            "rating_q975": 1458.7455745487612,
            "rating_q025": 1435.0969093066585
        },
        "qwen3-max-2025-09-23": {
            "rating": 1445.8384777608503,
            "rating_q975": 1460.385100696905,
            "rating_q025": 1431.2918548247956
        },
        "gpt-5-chat": {
            "rating": 1445.4984699485424,
            "rating_q975": 1453.8431215953665,
            "rating_q025": 1437.1538183017183
        },
        "qwen3-max-preview": {
            "rating": 1444.2788084371437,
            "rating_q975": 1453.3108650745587,
            "rating_q025": 1435.2467517997286
        },
        "claude-opus-4-20250514-thinking-16k": {
            "rating": 1433.9413926183172,
            "rating_q975": 1442.0519385033451,
            "rating_q025": 1425.8308467332893
        },
        "qwen3-235b-a22b-instruct-2507": {
            "rating": 1431.5799811979994,
            "rating_q975": 1438.6067354259976,
            "rating_q025": 1424.553226970001
        },
        "deepseek-v3.2-exp": {
            "rating": 1427.6319701757996,
            "rating_q975": 1440.7968173591612,
            "rating_q025": 1414.467122992438
        },
        "kimi-k2-thinking-turbo": {
            "rating": 1427.0217012107264,
            "rating_q975": 1438.7353691408864,
            "rating_q025": 1415.3080332805664
        },
        "deepseek-v3.2": {
            "rating": 1426.898196513336,
            "rating_q975": 1444.2132542297786,
            "rating_q025": 1409.5831387968933
        },
        "gpt-4.1-2025-04-14": {
            "rating": 1425.9750617702869,
            "rating_q975": 1432.8763787192368,
            "rating_q025": 1419.073744821337
        },
        "grok-4-fast-chat": {
            "rating": 1425.0715873123206,
            "rating_q975": 1441.8549707888506,
            "rating_q025": 1408.2882038357907
        },
        "gpt-5-high": {
            "rating": 1424.5098204940496,
            "rating_q975": 1433.5101804325752,
            "rating_q025": 1415.509460555524
        },
        "claude-opus-4-20250514": {
            "rating": 1424.1325666493292,
            "rating_q975": 1431.721318596041,
            "rating_q025": 1416.5438147026173
        },
        "ernie-5.0-preview-1103": {
            "rating": 1423.9302734866335,
            "rating_q975": 1442.9568547446145,
            "rating_q025": 1404.9036922286525
        },
        "qwen3-vl-235b-a22b-instruct": {
            "rating": 1421.8643960310608,
            "rating_q975": 1436.8808163323936,
            "rating_q025": 1406.847975729728
        },
        "claude-haiku-4-5-20251001": {
            "rating": 1420.2334723677243,
            "rating_q975": 1429.5676318997305,
            "rating_q025": 1410.899312835718
        },
        "o3-2025-04-16": {
            "rating": 1419.6508527544224,
            "rating_q975": 1426.4881502477294,
            "rating_q025": 1412.8135552611154
        },
        "deepseek-v3.2-exp-thinking": {
            "rating": 1419.568581300744,
            "rating_q975": 1434.8764755648192,
            "rating_q025": 1404.2606870366687
        },
        "glm-4.6": {
            "rating": 1419.2921542363545,
            "rating_q975": 1429.0272177454594,
            "rating_q025": 1409.5570907272495
        },
        "kimi-k2-0711-preview": {
            "rating": 1417.1531063202326,
            "rating_q975": 1426.1350924478572,
            "rating_q025": 1408.171120192608
        },
        "mistral-large-3": {
            "rating": 1416.4093644961895,
            "rating_q975": 1433.6135185654398,
            "rating_q025": 1399.2052104269392
        },
        "deepseek-v3.1-terminus-thinking": {
            "rating": 1416.1186867291726,
            "rating_q975": 1439.841002655862,
            "rating_q025": 1392.3963708024833
        },
        "deepseek-v3.2-thinking": {
            "rating": 1414.7504307887366,
            "rating_q975": 1432.6883626393774,
            "rating_q025": 1396.8124989380958
        },
        "claude-sonnet-4-20250514-thinking-32k": {
            "rating": 1414.5117677482247,
            "rating_q975": 1422.7329517604608,
            "rating_q025": 1406.2905837359885
        },
        "deepseek-v3.1-thinking": {
            "rating": 1413.6842454358525,
            "rating_q975": 1427.3155477107775,
            "rating_q025": 1400.0529431609275
        },
        "mistral-medium-2508": {
            "rating": 1412.6875603426197,
            "rating_q975": 1420.2446908196548,
            "rating_q025": 1405.1304298655846
        },
        "grok-4-0709": {
            "rating": 1412.3037437522817,
            "rating_q975": 1420.0001480491646,
            "rating_q025": 1404.6073394553987
        },
        "grok-3-preview-02-24": {
            "rating": 1408.6197675016103,
            "rating_q975": 1417.507063117157,
            "rating_q025": 1399.7324718860636
        },
        "qwen3-235b-a22b-no-thinking": {
            "rating": 1406.8367742547773,
            "rating_q975": 1414.737700343455,
            "rating_q025": 1398.9358481660997
        },
        "glm-4.5": {
            "rating": 1406.0910786518402,
            "rating_q975": 1415.886272254824,
            "rating_q025": 1396.2958850488565
        },
        "deepseek-r1": {
            "rating": 1405.9433253154398,
            "rating_q975": 1417.7370573655476,
            "rating_q025": 1394.149593265332
        },
        "grok-4-1-fast-reasoning": {
            "rating": 1405.6358680410192,
            "rating_q975": 1420.1548971210177,
            "rating_q025": 1391.1168389610207
        },
        "deepseek-v3-0324": {
            "rating": 1405.381616776864,
            "rating_q975": 1412.6023300453355,
            "rating_q025": 1398.1609035083923
        },
        "deepseek-r1-0528": {
            "rating": 1404.8516467560091,
            "rating_q975": 1415.6766639148013,
            "rating_q025": 1394.026629597217
        },
        "kimi-k2-0905-preview": {
            "rating": 1404.1487426482297,
            "rating_q975": 1417.2424639788214,
            "rating_q025": 1391.055021317638
        },
        "deepseek-v3.1": {
            "rating": 1404.0299566842862,
            "rating_q975": 1415.710367229844,
            "rating_q025": 1392.3495461387283
        },
        "grok-4-fast-reasoning": {
            "rating": 1403.1570440267808,
            "rating_q975": 1413.9092435977834,
            "rating_q025": 1392.4048444557782
        },
        "claude-sonnet-4-20250514": {
            "rating": 1402.9473229941916,
            "rating_q975": 1410.7400240162947,
            "rating_q025": 1395.1546219720885
        },
        "hunyuan-vision-1.5-thinking": {
            "rating": 1400.950618508904,
            "rating_q975": 1428.8201406377739,
            "rating_q025": 1373.081096380034
        },
        "qwen3-next-80b-a3b-instruct": {
            "rating": 1400.7953412392653,
            "rating_q975": 1410.3482971359674,
            "rating_q025": 1391.2423853425632
        },
        "gemini-2.5-flash": {
            "rating": 1399.7512480427313,
            "rating_q975": 1405.9761966155504,
            "rating_q025": 1393.5262994699121
        },
        "mistral-medium-2505": {
            "rating": 1397.9178094154836,
            "rating_q975": 1406.178624235739,
            "rating_q025": 1389.656994595228
        },
        "gemini-2.5-flash-preview-09-2025": {
            "rating": 1397.8637837253773,
            "rating_q975": 1406.5889738762103,
            "rating_q025": 1389.1385935745443
        },
        "claude-3-7-sonnet-20250219-thinking-32k": {
            "rating": 1395.212728867179,
            "rating_q975": 1403.2009058092149,
            "rating_q025": 1387.2245519251433
        },
        "claude-3-7-sonnet-20250219": {
            "rating": 1393.9089561835908,
            "rating_q975": 1401.4693011521726,
            "rating_q025": 1386.348611215009
        },
        "qwen3-235b-a22b-thinking-2507": {
            "rating": 1393.551384910969,
            "rating_q975": 1409.0188640647036,
            "rating_q025": 1378.0839057572346
        },
        "deepseek-v3.1-terminus": {
            "rating": 1392.2291158035212,
            "rating_q975": 1414.5218375132704,
            "rating_q025": 1369.936394093772
        },
        "qwen3-coder-480b-a35b-instruct": {
            "rating": 1392.2265591674502,
            "rating_q975": 1401.9454443958343,
            "rating_q025": 1382.507673939066
        },
        "longcat-flash-chat": {
            "rating": 1390.021923397773,
            "rating_q975": 1403.0490503368294,
            "rating_q025": 1376.9947964587166
        },
        "gpt-4.1-mini-2025-04-14": {
            "rating": 1388.7047620681474,
            "rating_q975": 1396.3276910705508,
            "rating_q025": 1381.081833065744
        },
        "mai-1-preview": {
            "rating": 1388.1926317350947,
            "rating_q975": 1399.5762390588286,
            "rating_q025": 1376.8090244113607
        },
        "o1-preview": {
            "rating": 1386.8169656063167,
            "rating_q975": 1395.8429701114865,
            "rating_q025": 1377.7909611011469
        },
        "claude-3-5-sonnet-20241022": {
            "rating": 1386.7778013033821,
            "rating_q975": 1392.3260339795888,
            "rating_q025": 1381.2295686271755
        },
        "hunyuan-turbos-20250416": {
            "rating": 1386.2674213894268,
            "rating_q975": 1400.2724377149389,
            "rating_q025": 1372.2624050639147
        },
        "o1-2024-12-17": {
            "rating": 1383.1454119158905,
            "rating_q975": 1392.0786162917257,
            "rating_q025": 1374.2122075400553
        },
        "qwen3-30b-a3b-instruct-2507": {
            "rating": 1381.0934725688053,
            "rating_q975": 1390.6288918249288,
            "rating_q025": 1371.5580533126817
        },
        "o4-mini-2025-04-16": {
            "rating": 1380.9107253368086,
            "rating_q975": 1388.1666516812647,
            "rating_q025": 1373.6547989923524
        },
        "qwen3-vl-235b-a22b-thinking": {
            "rating": 1380.835915607248,
            "rating_q975": 1397.349901595672,
            "rating_q025": 1364.3219296188238
        },
        "hunyuan-t1-20250711": {
            "rating": 1380.6046802851656,
            "rating_q975": 1402.294369407633,
            "rating_q025": 1358.9149911626982
        },
        "gpt-5-mini-high": {
            "rating": 1374.3244416719685,
            "rating_q975": 1383.7549039318587,
            "rating_q025": 1364.8939794120784
        },
        "deepseek-v3": {
            "rating": 1369.4929576693453,
            "rating_q975": 1379.0896285989286,
            "rating_q025": 1359.896286739762
        },
        "qwen2.5-max": {
            "rating": 1368.9163471025308,
            "rating_q975": 1377.28269164941,
            "rating_q025": 1360.5500025556516
        },
        "qwen3-235b-a22b": {
            "rating": 1368.5483858608502,
            "rating_q975": 1377.7155445520443,
            "rating_q025": 1359.381227169656
        },
        "gemini-2.5-flash-lite-preview-09-2025-no-thinking": {
            "rating": 1368.361727597465,
            "rating_q975": 1377.228369039638,
            "rating_q025": 1359.495086155292
        },
        "glm-4.5-air": {
            "rating": 1367.4822018883413,
            "rating_q975": 1376.0537862891504,
            "rating_q025": 1358.9106174875321
        },
        "gemini-2.5-flash-lite-preview-06-17-thinking": {
            "rating": 1366.438357803973,
            "rating_q975": 1374.7779684696661,
            "rating_q025": 1358.09874713828
        },
        "mistral-small-2506": {
            "rating": 1362.9404819375075,
            "rating_q975": 1373.555381091252,
            "rating_q025": 1352.325582783763
        },
        "minimax-m2": {
            "rating": 1362.334564325134,
            "rating_q975": 1379.5661808672683,
            "rating_q025": 1345.1029477829995
        },
        "command-a-03-2025": {
            "rating": 1358.1685422726644,
            "rating_q975": 1364.77958396234,
            "rating_q025": 1351.5575005829887
        },
        "gemma-3-27b-it": {
            "rating": 1357.478565493833,
            "rating_q975": 1364.8832070348033,
            "rating_q025": 1350.0739239528627
        },
        "intellect-3": {
            "rating": 1356.3710894342366,
            "rating_q975": 1386.7977823193035,
            "rating_q025": 1325.9443965491698
        },
        "minimax-m1": {
            "rating": 1356.0373718819183,
            "rating_q975": 1364.195874182535,
            "rating_q025": 1347.8788695813016
        },
        "gemini-2.0-flash-001": {
            "rating": 1355.4876701093922,
            "rating_q975": 1362.8046004376054,
            "rating_q025": 1348.170739781179
        },
        "glm-4.5v": {
            "rating": 1354.117546756102,
            "rating_q975": 1373.9807388721674,
            "rating_q025": 1334.2543546400366
        },
        "qwen-plus-0125": {
            "rating": 1349.440977426896,
            "rating_q975": 1368.4346082075463,
            "rating_q025": 1330.447346646246
        },
        "grok-3-mini-high": {
            "rating": 1348.6331256041854,
            "rating_q975": 1359.67083417835,
            "rating_q025": 1337.5954170300206
        },
        "claude-3-5-sonnet-20240620": {
            "rating": 1347.2467382628774,
            "rating_q975": 1354.2333339354348,
            "rating_q025": 1340.2601425903201
        },
        "grok-3-mini-beta": {
            "rating": 1344.1671691804574,
            "rating_q975": 1353.7480807400113,
            "rating_q025": 1334.5862576209036
        },
        "qwen3-next-80b-a3b-thinking": {
            "rating": 1343.6818310598478,
            "rating_q975": 1356.331400974714,
            "rating_q025": 1331.0322611449817
        },
        "gemma-3-12b-it": {
            "rating": 1343.5919074834821,
            "rating_q975": 1369.4272672760478,
            "rating_q025": 1317.7565476909165
        },
        "o3-mini-high": {
            "rating": 1342.243823167684,
            "rating_q975": 1353.8249818107438,
            "rating_q025": 1330.6626645246242
        },
        "llama-3.1-nemotron-ultra-253b-v1": {
            "rating": 1338.8069235953797,
            "rating_q975": 1369.1714926404236,
            "rating_q025": 1308.4423545503357
        },
        "llama-3.1-405b-instruct-bf16": {
            "rating": 1337.9217936465702,
            "rating_q975": 1345.3207862595755,
            "rating_q025": 1330.522801033565
        },
        "hunyuan-turbos-20250226": {
            "rating": 1337.2832422323563,
            "rating_q975": 1369.929959044415,
            "rating_q025": 1304.6365254202976
        },
        "step-3": {
            "rating": 1336.8333571229728,
            "rating_q975": 1354.5556526654575,
            "rating_q025": 1319.111061580488
        },
        "gpt-4o-2024-05-13": {
            "rating": 1336.5527292042138,
            "rating_q975": 1342.873427021766,
            "rating_q025": 1330.2320313866617
        },
        "o3-mini": {
            "rating": 1336.232432029686,
            "rating_q975": 1342.716854481918,
            "rating_q025": 1329.7480095774538
        },
        "amazon-nova-experimental-chat-10-09": {
            "rating": 1335.0250223181556,
            "rating_q975": 1350.4829292237039,
            "rating_q025": 1319.5671154126073
        },
        "qwen3-32b": {
            "rating": 1334.2428127632961,
            "rating_q975": 1357.6910821225104,
            "rating_q025": 1310.7945434040819
        },
        "nova-2-lite": {
            "rating": 1334.1691274874224,
            "rating_q975": 1353.0842512020045,
            "rating_q025": 1315.2540037728404
        },
        "nvidia-llama-3.3-nemotron-super-49b-v1.5": {
            "rating": 1334.061519132237,
            "rating_q975": 1357.6189449702053,
            "rating_q025": 1310.5040932942686
        },
        "glm-4-plus-0111": {
            "rating": 1331.7584778714279,
            "rating_q975": 1351.1443064685163,
            "rating_q025": 1312.3726492743394
        },
        "gpt-5-nano-high": {
            "rating": 1328.5499926950206,
            "rating_q975": 1344.228703179364,
            "rating_q025": 1312.8712822106772
        },
        "llama-3.1-405b-instruct-fp8": {
            "rating": 1327.9097848586566,
            "rating_q975": 1334.821453536722,
            "rating_q025": 1320.9981161805913
        },
        "gemini-1.5-pro-002": {
            "rating": 1327.4748628629914,
            "rating_q975": 1334.0980800558305,
            "rating_q025": 1320.8516456701523
        },
        "yi-lightning": {
            "rating": 1327.312096097402,
            "rating_q975": 1336.9435791124101,
            "rating_q025": 1317.6806130823938
        },
        "gemini-2.0-flash-lite-preview-02-05": {
            "rating": 1325.4717762592982,
            "rating_q975": 1335.1010717839679,
            "rating_q025": 1315.8424807346285
        },
        "llama-3.3-nemotron-49b-super-v1": {
            "rating": 1325.2429060315035,
            "rating_q975": 1357.0058510356002,
            "rating_q025": 1293.4799610274067
        },
        "amazon-nova-experimental-chat-10-20": {
            "rating": 1324.2834012014227,
            "rating_q975": 1340.8283196070818,
            "rating_q025": 1307.7384827957637
        },
        "claude-3-5-haiku-20241022": {
            "rating": 1323.4196417816665,
            "rating_q975": 1329.584015114225,
            "rating_q025": 1317.2552684491081
        },
        "gpt-4o-2024-08-06": {
            "rating": 1323.413629869839,
            "rating_q975": 1331.0181776847671,
            "rating_q025": 1315.809082054911
        },
        "llama-4-maverick-17b-128e-instruct": {
            "rating": 1322.516368930645,
            "rating_q975": 1330.3043460443166,
            "rating_q025": 1314.7283918169735
        },
        "hunyuan-turbo-0110": {
            "rating": 1322.466690054132,
            "rating_q975": 1351.7448777870034,
            "rating_q025": 1293.1885023212606
        },
        "gpt-oss-120b": {
            "rating": 1322.1054840944948,
            "rating_q975": 1330.8705570147124,
            "rating_q025": 1313.3404111742773
        },
        "step-1o-turbo-202506": {
            "rating": 1321.35106898196,
            "rating_q975": 1337.1702199012575,
            "rating_q025": 1305.5319180626625
        },
        "grok-2-2024-08-13": {
            "rating": 1321.2579714608828,
            "rating_q975": 1328.0330467225538,
            "rating_q025": 1314.4828961992118
        },
        "claude-3-opus-20240229": {
            "rating": 1320.0537769250873,
            "rating_q975": 1325.9706158799365,
            "rating_q025": 1314.136937970238
        },
        "deepseek-v2.5-1210": {
            "rating": 1319.5048148543196,
            "rating_q975": 1335.6658220384143,
            "rating_q025": 1303.343807670225
        },
        "o1-mini": {
            "rating": 1319.190307206225,
            "rating_q975": 1326.2560980879823,
            "rating_q025": 1312.1245163244678
        },
        "llama-4-scout-17b-16e-instruct": {
            "rating": 1319.1808322383795,
            "rating_q975": 1327.8512252571513,
            "rating_q025": 1310.5104392196076
        },
        "qwq-32b": {
            "rating": 1318.8027426466886,
            "rating_q975": 1328.2592254654562,
            "rating_q025": 1309.346259827921
        },
        "qwen3-30b-a3b": {
            "rating": 1318.6633835320595,
            "rating_q975": 1327.7345721450893,
            "rating_q025": 1309.5921949190297
        },
        "gemini-advanced-0514": {
            "rating": 1318.4501250698195,
            "rating_q975": 1327.8026236412832,
            "rating_q025": 1309.0976264983558
        },
        "llama-3.3-70b-instruct": {
            "rating": 1315.9092558489174,
            "rating_q975": 1322.32167967382,
            "rating_q025": 1309.4968320240148
        },
        "ling-flash-2.0": {
            "rating": 1315.8899218571578,
            "rating_q975": 1333.0421196375748,
            "rating_q025": 1298.7377240767407
        },
        "magistral-medium-2506": {
            "rating": 1312.8139633444232,
            "rating_q975": 1327.756218480108,
            "rating_q025": 1297.8717082087385
        },
        "gemini-1.5-pro-001": {
            "rating": 1312.1422660957032,
            "rating_q975": 1319.6499945525354,
            "rating_q025": 1304.634537638871
        },
        "gpt-4.1-nano-2025-04-14": {
            "rating": 1310.8220926310485,
            "rating_q975": 1328.924036465519,
            "rating_q025": 1292.7201487965779
        },
        "glm-4-plus": {
            "rating": 1309.9463643943377,
            "rating_q975": 1319.1621546253002,
            "rating_q025": 1300.7305741633752
        },
        "gpt-4-turbo-2024-04-09": {
            "rating": 1309.2354686127433,
            "rating_q975": 1316.4023455542915,
            "rating_q025": 1302.068591671195
        },
        "hunyuan-large-2025-02-10": {
            "rating": 1307.6770202757386,
            "rating_q975": 1332.7782256855867,
            "rating_q025": 1282.5758148658906
        },
        "gpt-4o-mini-2024-07-18": {
            "rating": 1306.4461466003813,
            "rating_q975": 1312.8158013651127,
            "rating_q025": 1300.07649183565
        },
        "step-2-16k-exp-202412": {
            "rating": 1303.4650421289487,
            "rating_q975": 1323.365104576427,
            "rating_q025": 1283.5649796814703
        },
        "qwen2.5-plus-1127": {
            "rating": 1302.7927829253888,
            "rating_q975": 1315.9518690301002,
            "rating_q025": 1289.6336968206774
        },
        "athene-v2-chat": {
            "rating": 1302.7097084082156,
            "rating_q975": 1311.739757678154,
            "rating_q025": 1293.6796591382772
        },
        "qwen-max-0919": {
            "rating": 1301.889859054791,
            "rating_q975": 1312.7071366037228,
            "rating_q025": 1291.0725815058593
        },
        "mercury": {
            "rating": 1299.3359456883331,
            "rating_q975": 1331.8772222194523,
            "rating_q025": 1266.794669157214
        },
        "hunyuan-standard-2025-02-10": {
            "rating": 1296.8023119049462,
            "rating_q975": 1320.6477963970383,
            "rating_q025": 1272.9568274128542
        },
        "gpt-4-1106-preview": {
            "rating": 1296.522362086563,
            "rating_q975": 1304.039271405701,
            "rating_q025": 1289.005452767425
        },
        "qwen2.5-72b-instruct": {
            "rating": 1295.3330551992158,
            "rating_q975": 1302.9486213903997,
            "rating_q025": 1287.7174890080319
        },
        "olmo-3-32b-think": {
            "rating": 1294.0344525618166,
            "rating_q975": 1322.2343929450496,
            "rating_q025": 1265.8345121785835
        },
        "mistral-large-2407": {
            "rating": 1293.3851220361225,
            "rating_q975": 1301.0148934045003,
            "rating_q025": 1285.7553506677448
        },
        "grok-2-mini-2024-08-13": {
            "rating": 1293.2797621657455,
            "rating_q975": 1300.376942808716,
            "rating_q025": 1286.182581522775
        },
        "athene-70b-0725": {
            "rating": 1291.973063266483,
            "rating_q975": 1302.6311774149235,
            "rating_q025": 1281.3149491180425
        },
        "gemma-3n-e4b-it": {
            "rating": 1291.3668331879744,
            "rating_q975": 1301.6575365629556,
            "rating_q025": 1281.0761298129933
        },
        "mistral-large-2411": {
            "rating": 1291.2287417241496,
            "rating_q975": 1299.9798555832906,
            "rating_q025": 1282.4776278650086
        },
        "mistral-small-3.1-24b-instruct-2503": {
            "rating": 1290.4566504996712,
            "rating_q975": 1299.0323167209924,
            "rating_q025": 1281.88098427835
        },
        "llama-3.1-nemotron-70b-instruct": {
            "rating": 1290.2959090287086,
            "rating_q975": 1306.9570203956434,
            "rating_q025": 1273.6347976617737
        },
        "gpt-4-0125-preview": {
            "rating": 1289.4681165027043,
            "rating_q975": 1297.0175100060774,
            "rating_q025": 1281.9187229993313
        },
        "deepseek-v2.5": {
            "rating": 1288.8163268588996,
            "rating_q975": 1298.2311591137159,
            "rating_q025": 1279.4014946040834
        },
        "gpt-oss-20b": {
            "rating": 1287.3861073050914,
            "rating_q975": 1301.636796385589,
            "rating_q025": 1273.1354182245939
        },
        "llama-3.1-70b-instruct": {
            "rating": 1286.4868691217416,
            "rating_q975": 1293.3767136896445,
            "rating_q025": 1279.5970245538388
        },
        "ring-flash-2.0": {
            "rating": 1281.6076126192584,
            "rating_q975": 1299.1156745292628,
            "rating_q025": 1264.099550709254
        },
        "gemma-2-27b-it": {
            "rating": 1276.6386145996066,
            "rating_q975": 1282.8593100414976,
            "rating_q025": 1270.4179191577157
        },
        "hunyuan-large-vision": {
            "rating": 1276.5179088690525,
            "rating_q975": 1295.9994422391053,
            "rating_q025": 1257.0363754989996
        },
        "llama-3.1-tulu-3-70b": {
            "rating": 1276.1252973687792,
            "rating_q975": 1299.2138368359622,
            "rating_q025": 1253.0367579015963
        },
        "claude-3-sonnet-20240229": {
            "rating": 1276.1145444354129,
            "rating_q975": 1283.867611907884,
            "rating_q025": 1268.3614769629417
        },
        "gemini-1.5-flash-002": {
            "rating": 1275.297580231796,
            "rating_q975": 1283.358677688196,
            "rating_q025": 1267.236482775396
        },
        "llama-3.1-nemotron-51b-instruct": {
            "rating": 1274.3256408179827,
            "rating_q975": 1294.3351072915577,
            "rating_q025": 1254.3161743444077
        },
        "amazon-nova-pro-v1.0": {
            "rating": 1274.171227116808,
            "rating_q975": 1283.3058377223795,
            "rating_q025": 1265.0366165112366
        },
        "llama-3-70b-instruct": {
            "rating": 1270.6031139202987,
            "rating_q975": 1277.6935690663436,
            "rating_q025": 1263.5126587742539
        },
        "gemma-3-4b-it": {
            "rating": 1270.5992218398815,
            "rating_q975": 1294.2831452077482,
            "rating_q025": 1246.9152984720147
        },
        "gpt-4-0314": {
            "rating": 1269.5578747091931,
            "rating_q975": 1279.2455842549855,
            "rating_q025": 1259.8701651634008
        },
        "gemma-2-9b-it-simpo": {
            "rating": 1268.560526058865,
            "rating_q975": 1282.995068803774,
            "rating_q025": 1254.1259833139559
        },
        "gemini-1.5-flash-001": {
            "rating": 1266.8722229383397,
            "rating_q975": 1274.5518563140374,
            "rating_q025": 1259.192589562642
        },
        "jamba-1.5-large": {
            "rating": 1263.4867562276957,
            "rating_q975": 1277.8802750986051,
            "rating_q025": 1249.0932373567862
        },
        "reka-core-20240904": {
            "rating": 1262.0359516912188,
            "rating_q975": 1278.1924601413766,
            "rating_q025": 1245.879443241061
        },
        "gpt-4-0613": {
            "rating": 1257.9544880655862,
            "rating_q975": 1266.1173490030806,
            "rating_q025": 1249.791627128092
        },
        "nemotron-4-340b-instruct": {
            "rating": 1256.1570524451945,
            "rating_q975": 1267.522146350682,
            "rating_q025": 1244.791958539707
        },
        "glm-4-0520": {
            "rating": 1255.6609577654126,
            "rating_q975": 1270.1078239012822,
            "rating_q025": 1241.214091629543
        },
        "command-r-plus-08-2024": {
            "rating": 1248.4420304112973,
            "rating_q975": 1261.8771374387463,
            "rating_q025": 1235.0069233838483
        },
        "gemma-2-9b-it": {
            "rating": 1247.9466516295647,
            "rating_q975": 1254.95881443491,
            "rating_q025": 1240.9344888242194
        },
        "mistral-small-24b-instruct-2501": {
            "rating": 1247.458664826163,
            "rating_q975": 1260.2485840051404,
            "rating_q025": 1234.6687456471855
        },
        "qwen2.5-coder-32b-instruct": {
            "rating": 1246.920284947037,
            "rating_q975": 1264.7579198253668,
            "rating_q025": 1229.0826500687074
        },
        "claude-3-haiku-20240307": {
            "rating": 1242.9366190209566,
            "rating_q975": 1249.9755591213755,
            "rating_q025": 1235.8976789205378
        },
        "olmo-2-0325-32b-instruct": {
            "rating": 1242.3901394371574,
            "rating_q975": 1271.6334127841271,
            "rating_q025": 1213.1468660901876
        },
        "qwen2-72b-instruct": {
            "rating": 1240.9073171005475,
            "rating_q975": 1249.8839900840749,
            "rating_q025": 1231.9306441170202
        },
        "phi-4": {
            "rating": 1238.8391452915043,
            "rating_q975": 1248.9105920033028,
            "rating_q025": 1228.767698579706
        },
        "command-r-plus": {
            "rating": 1235.7412691311183,
            "rating_q975": 1243.9760293139825,
            "rating_q025": 1227.5065089482541
        },
        "reka-flash-20240904": {
            "rating": 1234.9412472631702,
            "rating_q975": 1250.8306336349885,
            "rating_q025": 1219.051860891352
        },
        "deepseek-coder-v2": {
            "rating": 1232.689010214889,
            "rating_q975": 1244.8924379504801,
            "rating_q025": 1220.485582479298
        },
        "c4ai-aya-expanse-32b": {
            "rating": 1229.9971451120773,
            "rating_q975": 1238.860397613255,
            "rating_q025": 1221.1338926108997
        },
        "amazon-nova-lite-v1.0": {
            "rating": 1225.8887477627954,
            "rating_q975": 1236.2590907358015,
            "rating_q025": 1215.5184047897894
        },
        "mistral-large-2402": {
            "rating": 1223.586465738817,
            "rating_q975": 1232.6010097605879,
            "rating_q025": 1214.571921717046
        },
        "gemini-1.5-flash-8b-001": {
            "rating": 1219.5795188750253,
            "rating_q975": 1227.7460510341555,
            "rating_q025": 1211.4129867158952
        },
        "qwen1.5-72b-chat": {
            "rating": 1215.3865828451187,
            "rating_q975": 1225.5287270952067,
            "rating_q025": 1205.2444385950307
        },
        "qwen1.5-110b-chat": {
            "rating": 1210.6548060475784,
            "rating_q975": 1221.8847550149621,
            "rating_q025": 1199.4248570801947
        },
        "command-r-08-2024": {
            "rating": 1210.3796165877604,
            "rating_q975": 1223.9567754346347,
            "rating_q025": 1196.8024577408862
        },
        "amazon-nova-micro-v1.0": {
            "rating": 1208.5248850427524,
            "rating_q975": 1219.1500997699234,
            "rating_q025": 1197.8996703155815
        },
        "hunyuan-standard-256k": {
            "rating": 1204.677523142263,
            "rating_q975": 1229.4640457046069,
            "rating_q025": 1179.8910005799191
        },
        "ministral-8b-2410": {
            "rating": 1204.4164288989139,
            "rating_q975": 1223.306166517873,
            "rating_q025": 1185.5266912799548
        },
        "llama-3-8b-instruct": {
            "rating": 1202.9295782747092,
            "rating_q975": 1210.7744929574467,
            "rating_q025": 1195.0846635919718
        },
        "jamba-1.5-mini": {
            "rating": 1202.8803139160673,
            "rating_q975": 1217.4057195314417,
            "rating_q025": 1188.3549083006928
        },
        "reka-flash-21b-20240226-online": {
            "rating": 1202.5710176519103,
            "rating_q975": 1217.2998282308954,
            "rating_q025": 1187.8422070729252
        },
        "gpt-3.5-turbo-0125": {
            "rating": 1198.0201135393363,
            "rating_q975": 1206.4715184566699,
            "rating_q025": 1189.5687086220028
        },
        "c4ai-aya-expanse-8b": {
            "rating": 1197.2794600501804,
            "rating_q975": 1211.608734379872,
            "rating_q025": 1182.950185720489
        },
        "gemini-pro": {
            "rating": 1197.0782064390407,
            "rating_q975": 1221.9341949230175,
            "rating_q025": 1172.222217955064
        },
        "command-r": {
            "rating": 1196.0707956819997,
            "rating_q975": 1205.352332434082,
            "rating_q025": 1186.7892589299174
        },
        "llama-3.1-8b-instruct": {
            "rating": 1195.4218869126694,
            "rating_q975": 1202.8507348313594,
            "rating_q025": 1187.9930389939793
        },
        "mistral-medium": {
            "rating": 1193.859293177791,
            "rating_q975": 1205.0700946648183,
            "rating_q025": 1182.6484916907636
        },
        "reka-flash-21b-20240226": {
            "rating": 1191.930179733506,
            "rating_q975": 1203.8393453677072,
            "rating_q025": 1180.021014099305
        },
        "qwen1.5-32b-chat": {
            "rating": 1191.2592701076956,
            "rating_q975": 1203.4124955923128,
            "rating_q025": 1179.1060446230783
        },
        "yi-1.5-34b-chat": {
            "rating": 1186.7674526791945,
            "rating_q975": 1197.8258102717589,
            "rating_q025": 1175.7090950866302
        },
        "mixtral-8x22b-instruct-v0.1": {
            "rating": 1185.600178072267,
            "rating_q975": 1194.4404928956928,
            "rating_q025": 1176.7598632488412
        },
        "gemini-pro-dev-api": {
            "rating": 1183.8009050722198,
            "rating_q975": 1198.296843524613,
            "rating_q025": 1169.3049666198267
        },
        "llama-3.1-tulu-3-8b": {
            "rating": 1175.514493881333,
            "rating_q975": 1200.8428170530785,
            "rating_q025": 1150.1861707095875
        },
        "dbrx-instruct-preview": {
            "rating": 1172.4737028898203,
            "rating_q975": 1184.020714278043,
            "rating_q025": 1160.9266915015976
        },
        "gpt-3.5-turbo-1106": {
            "rating": 1167.9539577262694,
            "rating_q975": 1183.689084929695,
            "rating_q025": 1152.218830522844
        },
        "mixtral-8x7b-instruct-v0.1": {
            "rating": 1165.9712479912898,
            "rating_q975": 1174.3903566605786,
            "rating_q025": 1157.552139322001
        },
        "internlm2_5-20b-chat": {
            "rating": 1165.7145829757953,
            "rating_q975": 1180.2424949874091,
            "rating_q025": 1151.1866709641815
        },
        "wizardlm-70b": {
            "rating": 1164.438709839267,
            "rating_q975": 1183.7569656290464,
            "rating_q025": 1145.1204540494875
        },
        "qwen1.5-14b-chat": {
            "rating": 1163.4954703336166,
            "rating_q975": 1177.631850833242,
            "rating_q025": 1149.3590898339912
        },
        "gemma-2-2b-it": {
            "rating": 1160.9167181653283,
            "rating_q975": 1168.8372387715237,
            "rating_q025": 1152.996197559133
        },
        "yi-34b-chat": {
            "rating": 1158.8871386587084,
            "rating_q975": 1173.5140856083265,
            "rating_q025": 1144.2601917090903
        },
        "zephyr-orpo-141b-A35b-v0.1": {
            "rating": 1158.2863044107212,
            "rating_q975": 1182.1939828953127,
            "rating_q025": 1134.3786259261296
        },
        "granite-3.1-8b-instruct": {
            "rating": 1157.145438276065,
            "rating_q975": 1182.7785046409058,
            "rating_q025": 1131.5123719112244
        },
        "openchat-3.5": {
            "rating": 1153.7335228191582,
            "rating_q975": 1172.4769627992564,
            "rating_q025": 1134.99008283906
        },
        "openchat-3.5-0106": {
            "rating": 1150.3140258125975,
            "rating_q975": 1165.3070737041262,
            "rating_q025": 1135.3209779210688
        },
        "deepseek-llm-67b-chat": {
            "rating": 1149.535410328187,
            "rating_q975": 1173.8552436929365,
            "rating_q025": 1125.2155769634376
        },
        "llama-3.2-3b-instruct": {
            "rating": 1147.6457333195415,
            "rating_q975": 1164.5623302857973,
            "rating_q025": 1130.7291363532856
        },
        "qwq-32b-preview": {
            "rating": 1146.707044981703,
            "rating_q975": 1173.7631335510525,
            "rating_q025": 1119.6509564123533
        },
        "starling-lm-7b-beta": {
            "rating": 1144.2141448550633,
            "rating_q975": 1159.23401374503,
            "rating_q025": 1129.1942759650965
        },
        "granite-3.1-2b-instruct": {
            "rating": 1143.0348462869329,
            "rating_q975": 1170.1793259664282,
            "rating_q025": 1115.8903666074375
        },
        "snowflake-arctic-instruct": {
            "rating": 1140.6717942583214,
            "rating_q975": 1153.0924586628244,
            "rating_q025": 1128.2511298538184
        },
        "vicuna-33b": {
            "rating": 1138.4554570082446,
            "rating_q975": 1151.2997161174717,
            "rating_q025": 1125.6111978990175
        },
        "phi-3-medium-4k-instruct": {
            "rating": 1137.4088306270824,
            "rating_q975": 1148.24824426338,
            "rating_q025": 1126.5694169907847
        },
        "granite-3.0-8b-instruct": {
            "rating": 1134.981785182938,
            "rating_q975": 1154.6852460537118,
            "rating_q025": 1115.2783243121642
        },
        "tulu-2-dpo-70b": {
            "rating": 1134.1147985615123,
            "rating_q975": 1155.2209264047065,
            "rating_q025": 1113.0086707183182
        },
        "llama-2-70b-chat": {
            "rating": 1132.9903987753848,
            "rating_q975": 1143.3479879599654,
            "rating_q025": 1122.6328095908043
        },
        "openhermes-2.5-mistral-7b": {
            "rating": 1132.859798692833,
            "rating_q975": 1155.3056857496413,
            "rating_q025": 1110.4139116360247
        },
        "starling-lm-7b-alpha": {
            "rating": 1132.1006161353243,
            "rating_q975": 1149.5755958644745,
            "rating_q025": 1114.6256364061742
        },
        "nous-hermes-2-mixtral-8x7b-dpo": {
            "rating": 1126.6855967860763,
            "rating_q975": 1152.6512559226755,
            "rating_q025": 1100.719937649477
        },
        "mpt-30b-chat": {
            "rating": 1122.695459917749,
            "rating_q975": 1154.3513389777286,
            "rating_q025": 1091.0395808577696
        },
        "gemma-1.1-7b-it": {
            "rating": 1119.9299459033596,
            "rating_q975": 1131.4747305306332,
            "rating_q025": 1108.385161276086
        },
        "phi-3-small-8k-instruct": {
            "rating": 1116.4152044230677,
            "rating_q975": 1128.5137151030942,
            "rating_q025": 1104.3166937430412
        },
        "granite-3.0-2b-instruct": {
            "rating": 1115.8744171373703,
            "rating_q975": 1134.7812500859154,
            "rating_q025": 1096.9675841888252
        },
        "llama2-70b-steerlm-chat": {
            "rating": 1112.6444583899893,
            "rating_q975": 1140.5517966390062,
            "rating_q025": 1084.7371201409724
        },
        "mistral-7b-instruct-v0.2": {
            "rating": 1112.4659596374227,
            "rating_q975": 1125.4919565313503,
            "rating_q025": 1099.439962743495
        },
        "qwen1.5-7b-chat": {
            "rating": 1111.2747433340994,
            "rating_q975": 1136.264333795482,
            "rating_q025": 1086.285152872717
        },
        "solar-10.7b-instruct-v1.0": {
            "rating": 1109.2333398758096,
            "rating_q975": 1134.3353351336982,
            "rating_q025": 1084.131344617921
        },
        "wizardlm-13b": {
            "rating": 1106.0232072157676,
            "rating_q975": 1125.8522122500074,
            "rating_q025": 1086.1942021815278
        },
        "llama-2-13b-chat": {
            "rating": 1099.2354683667882,
            "rating_q975": 1113.023603071933,
            "rating_q025": 1085.4473336616434
        },
        "vicuna-13b": {
            "rating": 1098.1486722195646,
            "rating_q975": 1112.0721370432286,
            "rating_q025": 1084.2252073959005
        },
        "phi-3-mini-4k-instruct-june-2024": {
            "rating": 1096.2027085783384,
            "rating_q975": 1110.864678354804,
            "rating_q025": 1081.5407388018727
        },
        "falcon-180b-chat": {
            "rating": 1093.9658462425455,
            "rating_q975": 1133.7875712207028,
            "rating_q025": 1054.144121264388
        },
        "qwen-14b-chat": {
            "rating": 1091.3807866899056,
            "rating_q975": 1114.7598886256478,
            "rating_q025": 1068.0016847541633
        },
        "zephyr-7b-beta": {
            "rating": 1087.972567520407,
            "rating_q975": 1105.4553228518619,
            "rating_q025": 1070.489812188952
        },
        "palm-2": {
            "rating": 1087.1542077209378,
            "rating_q975": 1106.7993661745145,
            "rating_q025": 1067.5090492673612
        },
        "dolphin-2.2.1-mistral-7b": {
            "rating": 1083.36521671006,
            "rating_q975": 1124.564851465213,
            "rating_q025": 1042.1655819549069
        },
        "mistral-7b-instruct": {
            "rating": 1079.1891134345437,
            "rating_q975": 1098.4152702438719,
            "rating_q025": 1059.9629566252156
        },
        "llama-3.2-1b-instruct": {
            "rating": 1075.6512261446856,
            "rating_q975": 1094.227818816325,
            "rating_q025": 1057.074633473046
        },
        "llama-2-7b-chat": {
            "rating": 1075.2771858559013,
            "rating_q975": 1090.2729828206002,
            "rating_q025": 1060.2813888912024
        },
        "stripedhyena-nous-7b": {
            "rating": 1074.6361008087435,
            "rating_q975": 1097.5816496998823,
            "rating_q025": 1051.6905519176048
        },
        "codellama-34b-instruct": {
            "rating": 1071.8870539983582,
            "rating_q975": 1090.3572412652875,
            "rating_q025": 1053.4168667314289
        },
        "zephyr-7b-alpha": {
            "rating": 1071.1704342912021,
            "rating_q975": 1105.2663405757341,
            "rating_q025": 1037.07452800667
        },
        "guanaco-33b": {
            "rating": 1069.199953057996,
            "rating_q975": 1102.6958971745164,
            "rating_q025": 1035.7040089414756
        },
        "phi-3-mini-4k-instruct": {
            "rating": 1063.6969419325528,
            "rating_q975": 1076.9991586483306,
            "rating_q025": 1050.394725216775
        },
        "vicuna-7b": {
            "rating": 1059.1224121864534,
            "rating_q975": 1080.0362790942477,
            "rating_q025": 1038.2085452786591
        },
        "phi-3-mini-128k-instruct": {
            "rating": 1056.9707256847673,
            "rating_q975": 1072.4909463039717,
            "rating_q025": 1041.450505065563
        },
        "smollm2-1.7b-instruct": {
            "rating": 1053.34477552936,
            "rating_q975": 1091.755190980282,
            "rating_q025": 1014.9343600784381
        },
        "qwen1.5-4b-chat": {
            "rating": 1052.7533920746555,
            "rating_q975": 1071.493218240229,
            "rating_q025": 1034.013565909082
        },
        "gemma-1.1-2b-it": {
            "rating": 1046.061741122238,
            "rating_q975": 1063.8547355464418,
            "rating_q025": 1028.268746698034
        },
        "olmo-7b-instruct": {
            "rating": 1038.1407654968266,
            "rating_q975": 1065.8065202642397,
            "rating_q025": 1010.4750107294136
        },
        "gemma-7b-it": {
            "rating": 1038.1380923934917,
            "rating_q975": 1056.844577830797,
            "rating_q025": 1019.4316069561861
        },
        "chatglm3-6b": {
            "rating": 1032.1533540710914,
            "rating_q975": 1057.789412456188,
            "rating_q025": 1006.5172956859946
        },
        "gemma-2b-it": {
            "rating": 1030.1122285610872,
            "rating_q975": 1053.4033236838495,
            "rating_q025": 1006.8211334383251
        },
        "gpt4all-13b-snoozy": {
            "rating": 1021.5910570857325,
            "rating_q975": 1059.3367555753023,
            "rating_q025": 983.8453585961627
        },
        "alpaca-13b": {
            "rating": 1004.1913379723862,
            "rating_q975": 1029.9342045933035,
            "rating_q025": 978.4484713514689
        },
        "mpt-7b-chat": {
            "rating": 998.0023323004486,
            "rating_q975": 1026.9331389382091,
            "rating_q025": 969.071525662688
        },
        "koala-13b": {
            "rating": 991.7499092911337,
            "rating_q975": 1015.9894377746232,
            "rating_q025": 967.5103808076442
        },
        "RWKV-4-Raven-14B": {
            "rating": 975.4538636763816,
            "rating_q975": 1002.7659664139426,
            "rating_q025": 948.1417609388207
        },
        "chatglm2-6b": {
            "rating": 975.1167315949383,
            "rating_q975": 1007.0396525193288,
            "rating_q025": 943.1938106705478
        },
        "oasst-pythia-12b": {
            "rating": 955.0261556940151,
            "rating_q975": 980.5210374656739,
            "rating_q025": 929.5312739223563
        },
        "fastchat-t5-3b": {
            "rating": 934.6542916345493,
            "rating_q975": 965.077363990707,
            "rating_q025": 904.2312192783916
        },
        "chatglm-6b": {
            "rating": 919.5049474852419,
            "rating_q975": 948.9686065299778,
            "rating_q025": 890.041288440506
        },
        "stablelm-tuned-alpha-7b": {
            "rating": 894.2413726526081,
            "rating_q975": 928.4179241166285,
            "rating_q025": 860.0648211885878
        },
        "llama-13b": {
            "rating": 881.3704196724774,
            "rating_q975": 923.7210596281881,
            "rating_q025": 839.0197797167667
        },
        "dolly-v2-12b": {
            "rating": 856.5573744832038,
            "rating_q975": 891.8801851723493,
            "rating_q025": 821.2345637940583
        }
    },
    "no_refusal": {
        "gemini-3-pro": {
            "rating": 1490.3808393521201,
            "rating_q975": 1496.591789684551,
            "rating_q025": 1484.1698890196892
        },
        "grok-4.1-thinking": {
            "rating": 1477.0988645553684,
            "rating_q975": 1483.2282701189606,
            "rating_q025": 1470.9694589917763
        },
        "claude-opus-4-5-20251101": {
            "rating": 1466.057654797723,
            "rating_q975": 1473.0829632951845,
            "rating_q025": 1459.0323463002615
        },
        "claude-opus-4-5-20251101-thinking-32k": {
            "rating": 1465.7673091355282,
            "rating_q975": 1472.9037630153741,
            "rating_q025": 1458.6308552556823
        },
        "grok-4.1": {
            "rating": 1463.7563938369574,
            "rating_q975": 1469.85303092694,
            "rating_q025": 1457.6597567469748
        },
        "gpt-5.1-high": {
            "rating": 1456.68138817971,
            "rating_q975": 1463.090550697359,
            "rating_q025": 1450.272225662061
        },
        "gemini-2.5-pro": {
            "rating": 1449.8308869987054,
            "rating_q975": 1453.2950362074012,
            "rating_q025": 1446.3667377900097
        },
        "claude-sonnet-4-5-20250929-thinking-32k": {
            "rating": 1447.7837959139,
            "rating_q975": 1452.2904452359892,
            "rating_q025": 1443.2771465918106
        },
        "claude-opus-4-1-20250805-thinking-16k": {
            "rating": 1446.0883687747312,
            "rating_q975": 1449.9169879741135,
            "rating_q025": 1442.259749575349
        },
        "claude-sonnet-4-5-20250929": {
            "rating": 1443.0456440934902,
            "rating_q975": 1448.1097270844882,
            "rating_q025": 1437.9815611024922
        },
        "gpt-4.5-preview-2025-02-27": {
            "rating": 1441.8602575278403,
            "rating_q975": 1447.5544254783415,
            "rating_q025": 1436.166089577339
        },
        "claude-opus-4-1-20250805": {
            "rating": 1438.8939999866814,
            "rating_q975": 1442.5951927493813,
            "rating_q025": 1435.1928072239814
        },
        "chatgpt-4o-latest-20250326": {
            "rating": 1438.3339321664726,
            "rating_q975": 1441.6729857214686,
            "rating_q025": 1434.9948786114765
        },
        "gpt-5.1": {
            "rating": 1436.0604653814319,
            "rating_q975": 1442.2626216877602,
            "rating_q025": 1429.8583090751035
        },
        "gpt-5-high": {
            "rating": 1435.6381441370036,
            "rating_q975": 1440.2067393336965,
            "rating_q025": 1431.0695489403106
        },
        "o3-2025-04-16": {
            "rating": 1433.071930845831,
            "rating_q975": 1436.7078456382105,
            "rating_q025": 1429.4360160534516
        },
        "qwen3-max-preview": {
            "rating": 1432.2098737183592,
            "rating_q975": 1436.7700103410857,
            "rating_q025": 1427.6497370956326
        },
        "ernie-5.0-preview-1103": {
            "rating": 1427.729325035519,
            "rating_q975": 1436.6300739286087,
            "rating_q025": 1418.8285761424293
        },
        "grok-4-1-fast-reasoning": {
            "rating": 1427.3595774160683,
            "rating_q975": 1434.2783213060384,
            "rating_q025": 1420.4408335260982
        },
        "glm-4.6": {
            "rating": 1424.670028812113,
            "rating_q975": 1429.414469886833,
            "rating_q025": 1419.925587737393
        },
        "kimi-k2-thinking-turbo": {
            "rating": 1423.4353674532902,
            "rating_q975": 1429.2378765427668,
            "rating_q025": 1417.6328583638135
        },
        "gpt-5-chat": {
            "rating": 1422.7159007710961,
            "rating_q975": 1427.031141060142,
            "rating_q025": 1418.4006604820502
        },
        "qwen3-max-2025-09-23": {
            "rating": 1421.4844297162,
            "rating_q975": 1427.932937630438,
            "rating_q025": 1415.0359218019623
        },
        "deepseek-v3.2-exp": {
            "rating": 1421.41676675376,
            "rating_q975": 1427.9600615174465,
            "rating_q025": 1414.8734719900733
        },
        "claude-opus-4-20250514-thinking-16k": {
            "rating": 1420.9901708529337,
            "rating_q975": 1425.341342307512,
            "rating_q025": 1416.6389993983555
        },
        "qwen3-235b-a22b-instruct-2507": {
            "rating": 1420.9587470471843,
            "rating_q975": 1424.6488036837577,
            "rating_q025": 1417.2686904106108
        },
        "deepseek-v3.2-exp-thinking": {
            "rating": 1419.1563642399433,
            "rating_q975": 1425.748197524974,
            "rating_q025": 1412.5645309549125
        },
        "grok-4-fast-chat": {
            "rating": 1418.1513411910003,
            "rating_q975": 1425.7574970952464,
            "rating_q025": 1410.545185286754
        },
        "deepseek-v3.2-thinking": {
            "rating": 1417.0028839031652,
            "rating_q975": 1425.4542128287426,
            "rating_q025": 1408.5515549775878
        },
        "deepseek-r1-0528": {
            "rating": 1416.8759499455368,
            "rating_q975": 1422.4925267117706,
            "rating_q025": 1411.259373179303
        },
        "kimi-k2-0905-preview": {
            "rating": 1416.2862244682174,
            "rating_q975": 1422.8621067886543,
            "rating_q025": 1409.7103421477805
        },
        "deepseek-v3.1": {
            "rating": 1416.1950580029402,
            "rating_q975": 1422.2279877445233,
            "rating_q025": 1410.162128261357
        },
        "deepseek-v3.1-thinking": {
            "rating": 1414.8654036319492,
            "rating_q975": 1421.4788982133882,
            "rating_q025": 1408.2519090505102
        },
        "deepseek-v3.2": {
            "rating": 1414.6300403398811,
            "rating_q975": 1422.9536382389522,
            "rating_q025": 1406.30644244081
        },
        "deepseek-v3.1-terminus": {
            "rating": 1414.2217302163817,
            "rating_q975": 1423.8511449542973,
            "rating_q025": 1404.5923154784662
        },
        "qwen3-vl-235b-a22b-instruct": {
            "rating": 1414.1611195738885,
            "rating_q975": 1420.8569237714419,
            "rating_q025": 1407.4653153763352
        },
        "kimi-k2-0711-preview": {
            "rating": 1414.1297324140646,
            "rating_q975": 1418.9616212183016,
            "rating_q025": 1409.2978436098276
        },
        "mistral-large-3": {
            "rating": 1412.6806453614172,
            "rating_q975": 1420.9848383724593,
            "rating_q025": 1404.376452350375
        },
        "deepseek-v3.1-terminus-thinking": {
            "rating": 1411.9150774747154,
            "rating_q975": 1421.873047448167,
            "rating_q025": 1401.9571075012639
        },
        "gpt-4.1-2025-04-14": {
            "rating": 1410.504531659088,
            "rating_q975": 1414.2237797527948,
            "rating_q025": 1406.785283565381
        },
        "grok-4-0709": {
            "rating": 1410.1809050279244,
            "rating_q975": 1414.1414799992767,
            "rating_q025": 1406.220330056572
        },
        "mistral-medium-2508": {
            "rating": 1409.6493096755964,
            "rating_q975": 1413.5279858500198,
            "rating_q025": 1405.770633501173
        },
        "grok-3-preview-02-24": {
            "rating": 1409.2040225602832,
            "rating_q975": 1413.463054345079,
            "rating_q025": 1404.9449907754874
        },
        "claude-opus-4-20250514": {
            "rating": 1409.1105402241808,
            "rating_q975": 1413.385783934693,
            "rating_q025": 1404.8352965136685
        },
        "glm-4.5": {
            "rating": 1408.0313059925006,
            "rating_q975": 1412.9256091826749,
            "rating_q025": 1403.1370028023264
        },
        "gemini-2.5-flash": {
            "rating": 1407.4362878979323,
            "rating_q975": 1410.8325059997483,
            "rating_q025": 1404.0400697961163
        },
        "gemini-2.5-flash-preview-09-2025": {
            "rating": 1403.2960747524003,
            "rating_q975": 1407.6926724850912,
            "rating_q025": 1398.8994770197094
        },
        "grok-4-fast-reasoning": {
            "rating": 1402.029788239764,
            "rating_q975": 1407.1571756897727,
            "rating_q025": 1396.9024007897553
        },
        "qwen3-next-80b-a3b-instruct": {
            "rating": 1400.3667368652943,
            "rating_q975": 1405.2236130366077,
            "rating_q025": 1395.509860693981
        },
        "claude-haiku-4-5-20251001": {
            "rating": 1400.2055854354403,
            "rating_q975": 1404.790690571091,
            "rating_q025": 1395.6204802997895
        },
        "longcat-flash-chat": {
            "rating": 1399.6309411592088,
            "rating_q975": 1406.0612043103843,
            "rating_q025": 1393.2006780080333
        },
        "o1-2024-12-17": {
            "rating": 1399.4108718768641,
            "rating_q975": 1403.7964474572627,
            "rating_q025": 1395.0252962964655
        },
        "qwen3-235b-a22b-no-thinking": {
            "rating": 1398.4030142919514,
            "rating_q975": 1402.9105220882313,
            "rating_q025": 1393.8955064956715
        },
        "qwen3-235b-a22b-thinking-2507": {
            "rating": 1396.725783645572,
            "rating_q975": 1403.1930003717616,
            "rating_q025": 1390.2585669193822
        },
        "claude-sonnet-4-20250514-thinking-32k": {
            "rating": 1396.6759202739363,
            "rating_q975": 1401.0716519450204,
            "rating_q025": 1392.2801886028521
        },
        "deepseek-r1": {
            "rating": 1394.1516845796668,
            "rating_q975": 1398.9665685201492,
            "rating_q025": 1389.3368006391845
        },
        "gpt-5-mini-high": {
            "rating": 1392.8740089066732,
            "rating_q975": 1397.580958691088,
            "rating_q025": 1388.1670591222585
        },
        "qwen3-vl-235b-a22b-thinking": {
            "rating": 1392.5219055017149,
            "rating_q975": 1399.3595928136247,
            "rating_q025": 1385.684218189805
        },
        "hunyuan-vision-1.5-thinking": {
            "rating": 1390.5773132652264,
            "rating_q975": 1402.9867411951138,
            "rating_q025": 1378.167885335339
        },
        "o1-preview": {
            "rating": 1390.1074967535048,
            "rating_q975": 1395.1185393856088,
            "rating_q025": 1385.096454121401
        },
        "deepseek-v3-0324": {
            "rating": 1389.9708326591742,
            "rating_q975": 1393.8393990424522,
            "rating_q025": 1386.1022662758962
        },
        "o4-mini-2025-04-16": {
            "rating": 1389.5415367300832,
            "rating_q975": 1393.510370660275,
            "rating_q025": 1385.5727027998914
        },
        "mai-1-preview": {
            "rating": 1388.9005000499078,
            "rating_q975": 1394.3631721042861,
            "rating_q025": 1383.4378279955295
        },
        "claude-sonnet-4-20250514": {
            "rating": 1386.5061938710735,
            "rating_q975": 1390.852362819027,
            "rating_q025": 1382.16002492312
        },
        "hunyuan-t1-20250711": {
            "rating": 1385.4135366185326,
            "rating_q975": 1394.064548885764,
            "rating_q025": 1376.7625243513012
        },
        "claude-3-7-sonnet-20250219-thinking-32k": {
            "rating": 1383.574012900954,
            "rating_q975": 1387.7319787127121,
            "rating_q025": 1379.4160470891957
        },
        "qwen3-coder-480b-a35b-instruct": {
            "rating": 1383.460878993709,
            "rating_q975": 1388.4600947747515,
            "rating_q025": 1378.4616632126665
        },
        "qwen3-30b-a3b-instruct-2507": {
            "rating": 1381.4857138051923,
            "rating_q975": 1386.3933149507811,
            "rating_q025": 1376.5781126596034
        },
        "mistral-medium-2505": {
            "rating": 1381.3865616810447,
            "rating_q975": 1386.0655774266663,
            "rating_q025": 1376.707545935423
        },
        "hunyuan-turbos-20250416": {
            "rating": 1379.5379089097455,
            "rating_q975": 1385.8988324915981,
            "rating_q025": 1373.176985327893
        },
        "gpt-4.1-mini-2025-04-14": {
            "rating": 1378.5639727376906,
            "rating_q975": 1382.8581097025733,
            "rating_q025": 1374.269835772808
        },
        "gemini-2.5-flash-lite-preview-09-2025-no-thinking": {
            "rating": 1376.9573037516384,
            "rating_q975": 1381.3314293387725,
            "rating_q025": 1372.5831781645043
        },
        "gemini-2.5-flash-lite-preview-06-17-thinking": {
            "rating": 1374.280851893689,
            "rating_q975": 1378.77904444026,
            "rating_q025": 1369.7826593471182
        },
        "qwen3-235b-a22b": {
            "rating": 1372.0147888676672,
            "rating_q975": 1376.7033312569758,
            "rating_q025": 1367.3262464783586
        },
        "qwen2.5-max": {
            "rating": 1371.6446612335546,
            "rating_q975": 1375.657391811394,
            "rating_q025": 1367.6319306557152
        },
        "claude-3-5-sonnet-20241022": {
            "rating": 1369.7022922815265,
            "rating_q975": 1372.7979596624891,
            "rating_q025": 1366.606624900564
        },
        "glm-4.5-air": {
            "rating": 1369.6963915413849,
            "rating_q975": 1373.9788932359334,
            "rating_q025": 1365.4138898468364
        },
        "claude-3-7-sonnet-20250219": {
            "rating": 1367.5513612566363,
            "rating_q975": 1371.4456219466601,
            "rating_q025": 1363.6571005666124
        },
        "qwen3-next-80b-a3b-thinking": {
            "rating": 1367.0480619346426,
            "rating_q975": 1372.9346840770188,
            "rating_q025": 1361.1614397922665
        },
        "minimax-m1": {
            "rating": 1364.091037807635,
            "rating_q975": 1368.3502046828405,
            "rating_q025": 1359.8318709324296
        },
        "gemma-3-27b-it": {
            "rating": 1363.485370189835,
            "rating_q975": 1367.1450177130732,
            "rating_q025": 1359.825722666597
        },
        "o3-mini-high": {
            "rating": 1362.3436062607198,
            "rating_q975": 1367.5887119032225,
            "rating_q025": 1357.098500618217
        },
        "grok-3-mini-high": {
            "rating": 1362.2615702494866,
            "rating_q975": 1367.5914122557715,
            "rating_q025": 1356.9317282432016
        },
        "gemini-2.0-flash-001": {
            "rating": 1359.2742628932099,
            "rating_q975": 1363.002445903796,
            "rating_q025": 1355.5460798826239
        },
        "grok-3-mini-beta": {
            "rating": 1355.92670806348,
            "rating_q975": 1360.9317424500466,
            "rating_q025": 1350.9216736769133
        },
        "deepseek-v3": {
            "rating": 1354.2962578057081,
            "rating_q975": 1358.9730781729907,
            "rating_q025": 1349.6194374384256
        },
        "mistral-small-2506": {
            "rating": 1352.6865379843453,
            "rating_q975": 1357.8747040239693,
            "rating_q025": 1347.4983719447212
        },
        "gpt-oss-120b": {
            "rating": 1351.9103192996745,
            "rating_q975": 1356.3006147477402,
            "rating_q025": 1347.5200238516088
        },
        "gemini-2.0-flash-lite-preview-02-05": {
            "rating": 1351.1749826870778,
            "rating_q975": 1355.4139390750945,
            "rating_q025": 1346.936026299061
        },
        "amazon-nova-experimental-chat-10-20": {
            "rating": 1350.9235133624493,
            "rating_q975": 1358.2924566173456,
            "rating_q025": 1343.554570107553
        },
        "command-a-03-2025": {
            "rating": 1350.2996185557295,
            "rating_q975": 1353.7422420972784,
            "rating_q025": 1346.8569950141805
        },
        "glm-4.5v": {
            "rating": 1349.534629633225,
            "rating_q975": 1357.959403485793,
            "rating_q025": 1341.109855780657
        },
        "gemini-1.5-pro-002": {
            "rating": 1349.373428921549,
            "rating_q975": 1352.6451289454192,
            "rating_q025": 1346.1017288976789
        },
        "o3-mini": {
            "rating": 1347.4859645482743,
            "rating_q975": 1350.9616679234666,
            "rating_q025": 1344.010261173082
        },
        "intellect-3": {
            "rating": 1346.766693009562,
            "rating_q975": 1359.3574612896668,
            "rating_q025": 1334.1759247294572
        },
        "hunyuan-turbos-20250226": {
            "rating": 1346.008699787887,
            "rating_q975": 1357.7865848336885,
            "rating_q025": 1334.2308147420856
        },
        "ling-flash-2.0": {
            "rating": 1345.55197945109,
            "rating_q975": 1352.8038226111325,
            "rating_q025": 1338.3001362910472
        },
        "step-3": {
            "rating": 1344.5875106176552,
            "rating_q975": 1351.9854207118003,
            "rating_q025": 1337.18960052351
        },
        "minimax-m2": {
            "rating": 1344.302917060355,
            "rating_q975": 1352.042016046896,
            "rating_q025": 1336.563818073814
        },
        "llama-3.1-nemotron-ultra-253b-v1": {
            "rating": 1344.0581805590898,
            "rating_q975": 1355.79811202154,
            "rating_q025": 1332.3182490966396
        },
        "claude-3-5-sonnet-20240620": {
            "rating": 1343.6098492877454,
            "rating_q975": 1347.0476927981817,
            "rating_q025": 1340.172005777309
        },
        "qwen3-32b": {
            "rating": 1342.9677810153303,
            "rating_q975": 1352.4854981476337,
            "rating_q025": 1333.4500638830268
        },
        "qwen-plus-0125": {
            "rating": 1342.902131425195,
            "rating_q975": 1351.3081313955433,
            "rating_q025": 1334.4961314548466
        },
        "gpt-4o-2024-05-13": {
            "rating": 1342.3925821139694,
            "rating_q975": 1345.7481715204337,
            "rating_q025": 1339.036992707505
        },
        "glm-4-plus-0111": {
            "rating": 1341.5213799367818,
            "rating_q975": 1349.9453706681572,
            "rating_q025": 1333.0973892054064
        },
        "gemma-3-12b-it": {
            "rating": 1340.2671196078356,
            "rating_q975": 1349.7855201046095,
            "rating_q025": 1330.7487191110617
        },
        "amazon-nova-experimental-chat-10-09": {
            "rating": 1339.9931182169778,
            "rating_q975": 1346.5676738442378,
            "rating_q025": 1333.4185625897178
        },
        "gpt-5-nano-high": {
            "rating": 1339.230965108612,
            "rating_q975": 1346.1484801501779,
            "rating_q025": 1332.3134500670462
        },
        "nvidia-llama-3.3-nemotron-super-49b-v1.5": {
            "rating": 1338.6828329908103,
            "rating_q975": 1348.5292996195342,
            "rating_q025": 1328.8363663620864
        },
        "hunyuan-turbo-0110": {
            "rating": 1335.8044942348583,
            "rating_q975": 1347.426116528306,
            "rating_q025": 1324.1828719414107
        },
        "o1-mini": {
            "rating": 1335.6604402874207,
            "rating_q975": 1339.2277367155393,
            "rating_q025": 1332.093143859302
        },
        "nova-2-lite": {
            "rating": 1334.0524140877217,
            "rating_q975": 1342.6725425240397,
            "rating_q025": 1325.4322856514036
        },
        "llama-3.1-405b-instruct-bf16": {
            "rating": 1332.3449975151234,
            "rating_q975": 1335.950293680121,
            "rating_q025": 1328.7397013501259
        },
        "qwq-32b": {
            "rating": 1332.1985200227775,
            "rating_q975": 1336.595855912076,
            "rating_q025": 1327.801184133479
        },
        "gpt-4o-2024-08-06": {
            "rating": 1331.9962085867778,
            "rating_q975": 1336.1205882111774,
            "rating_q025": 1327.8718289623782
        },
        "grok-2-2024-08-13": {
            "rating": 1331.6820394256292,
            "rating_q975": 1335.2619578345389,
            "rating_q025": 1328.1021210167196
        },
        "step-2-16k-exp-202412": {
            "rating": 1331.4674569926249,
            "rating_q975": 1340.0699276299206,
            "rating_q025": 1322.8649863553292
        },
        "llama-3.1-405b-instruct-fp8": {
            "rating": 1330.7084150005817,
            "rating_q975": 1334.1998445564102,
            "rating_q025": 1327.2169854447532
        },
        "gemini-advanced-0514": {
            "rating": 1329.8611075559215,
            "rating_q975": 1334.9952666243878,
            "rating_q025": 1324.7269484874553
        },
        "claude-3-opus-20240229": {
            "rating": 1327.2553094824118,
            "rating_q975": 1330.2967241655872,
            "rating_q025": 1324.2138947992364
        },
        "yi-lightning": {
            "rating": 1325.612500948283,
            "rating_q975": 1330.4704221755403,
            "rating_q025": 1320.7545797210257
        },
        "llama-4-maverick-17b-128e-instruct": {
            "rating": 1325.0500320442547,
            "rating_q975": 1329.2824772034971,
            "rating_q025": 1320.8175868850124
        },
        "llama-3.3-nemotron-49b-super-v1": {
            "rating": 1324.51254832253,
            "rating_q975": 1336.7546079751405,
            "rating_q025": 1312.2704886699194
        },
        "qwen3-30b-a3b": {
            "rating": 1324.0841077193509,
            "rating_q975": 1328.7897826878198,
            "rating_q025": 1319.378432750882
        },
        "claude-3-5-haiku-20241022": {
            "rating": 1323.9317055800188,
            "rating_q975": 1327.1756761202282,
            "rating_q025": 1320.6877350398095
        },
        "hunyuan-large-2025-02-10": {
            "rating": 1322.377120404136,
            "rating_q975": 1332.3159831761006,
            "rating_q025": 1312.4382576321711
        },
        "gpt-4-turbo-2024-04-09": {
            "rating": 1321.0489783987719,
            "rating_q975": 1324.887519383566,
            "rating_q025": 1317.2104374139776
        },
        "gemini-1.5-pro-001": {
            "rating": 1320.842549021155,
            "rating_q975": 1324.7626737853857,
            "rating_q025": 1316.9224242569244
        },
        "deepseek-v2.5-1210": {
            "rating": 1320.6345047948926,
            "rating_q975": 1328.9190778092634,
            "rating_q025": 1312.3499317805217
        },
        "llama-4-scout-17b-16e-instruct": {
            "rating": 1320.4661930617358,
            "rating_q975": 1325.1601488308766,
            "rating_q025": 1315.772237292595
        },
        "ring-flash-2.0": {
            "rating": 1319.0285041074194,
            "rating_q975": 1326.2559206211629,
            "rating_q025": 1311.801087593676
        },
        "gpt-4.1-nano-2025-04-14": {
            "rating": 1318.9216212426745,
            "rating_q975": 1326.713306512705,
            "rating_q025": 1311.129935972644
        },
        "step-1o-turbo-202506": {
            "rating": 1318.284340162686,
            "rating_q975": 1324.9347123254302,
            "rating_q025": 1311.633967999942
        },
        "gemma-3n-e4b-it": {
            "rating": 1317.3103175474937,
            "rating_q975": 1322.432739018337,
            "rating_q025": 1312.1878960766503
        },
        "llama-3.3-70b-instruct": {
            "rating": 1316.7908240271397,
            "rating_q975": 1320.168423980698,
            "rating_q025": 1313.4132240735814
        },
        "glm-4-plus": {
            "rating": 1316.6249534057652,
            "rating_q975": 1321.5020437696598,
            "rating_q025": 1311.7478630418705
        },
        "qwen-max-0919": {
            "rating": 1315.9690250940653,
            "rating_q975": 1321.64039409376,
            "rating_q025": 1310.2976560943705
        },
        "gpt-oss-20b": {
            "rating": 1315.4451557010657,
            "rating_q975": 1321.8083169437168,
            "rating_q025": 1309.0819944584146
        },
        "gpt-4o-mini-2024-07-18": {
            "rating": 1313.8548842821074,
            "rating_q975": 1317.2666632792634,
            "rating_q025": 1310.4431052849513
        },
        "qwen2.5-plus-1127": {
            "rating": 1313.7005587874721,
            "rating_q975": 1320.0363981329442,
            "rating_q025": 1307.364719442
        },
        "gpt-4-1106-preview": {
            "rating": 1313.3648723682877,
            "rating_q975": 1317.227328030383,
            "rating_q025": 1309.5024167061924
        },
        "gpt-4-0125-preview": {
            "rating": 1312.694168936303,
            "rating_q975": 1316.7431410477516,
            "rating_q025": 1308.6451968248543
        },
        "athene-v2-chat": {
            "rating": 1310.9056228082045,
            "rating_q975": 1315.3923074367303,
            "rating_q025": 1306.4189381796787
        },
        "mistral-large-2407": {
            "rating": 1310.502427461814,
            "rating_q975": 1314.3431911266878,
            "rating_q025": 1306.6616637969403
        },
        "mercury": {
            "rating": 1309.9003074754064,
            "rating_q975": 1323.6579088368492,
            "rating_q025": 1296.1427061139636
        },
        "hunyuan-standard-2025-02-10": {
            "rating": 1308.7441749649508,
            "rating_q975": 1318.5670122226818,
            "rating_q025": 1298.92133770722
        },
        "gemini-1.5-flash-002": {
            "rating": 1308.7038982032666,
            "rating_q975": 1312.8362623089283,
            "rating_q025": 1304.5715340976049
        },
        "olmo-3-32b-think": {
            "rating": 1306.2278648111428,
            "rating_q975": 1316.8346953427372,
            "rating_q025": 1295.6210342795484
        },
        "grok-2-mini-2024-08-13": {
            "rating": 1304.9167226999532,
            "rating_q975": 1308.534435447105,
            "rating_q025": 1301.2990099528015
        },
        "deepseek-v2.5": {
            "rating": 1303.9050435979523,
            "rating_q975": 1308.5583424053443,
            "rating_q025": 1299.2517447905602
        },
        "magistral-medium-2506": {
            "rating": 1302.5504742413996,
            "rating_q975": 1308.9270976504413,
            "rating_q025": 1296.1738508323579
        },
        "mistral-large-2411": {
            "rating": 1302.2297384851468,
            "rating_q975": 1306.5842486201332,
            "rating_q025": 1297.8752283501603
        },
        "athene-70b-0725": {
            "rating": 1301.8837487360292,
            "rating_q975": 1307.5203642691392,
            "rating_q025": 1296.2471332029193
        },
        "gemma-3-4b-it": {
            "rating": 1301.690123863113,
            "rating_q975": 1311.0458182289494,
            "rating_q025": 1292.3344294972767
        },
        "mistral-small-3.1-24b-instruct-2503": {
            "rating": 1301.3904517813298,
            "rating_q975": 1305.8917059063042,
            "rating_q025": 1296.8891976563555
        },
        "qwen2.5-72b-instruct": {
            "rating": 1299.7145462785402,
            "rating_q975": 1303.6969105878404,
            "rating_q025": 1295.73218196924
        },
        "llama-3.1-nemotron-70b-instruct": {
            "rating": 1295.2777261416759,
            "rating_q975": 1303.0464518640176,
            "rating_q025": 1287.5090004193341
        },
        "hunyuan-large-vision": {
            "rating": 1294.2645018244461,
            "rating_q975": 1303.4072840481933,
            "rating_q025": 1285.121719600699
        },
        "llama-3.1-70b-instruct": {
            "rating": 1290.1474546861107,
            "rating_q975": 1293.7645581642748,
            "rating_q025": 1286.5303512079465
        },
        "amazon-nova-pro-v1.0": {
            "rating": 1286.2347540789756,
            "rating_q975": 1290.7050501245014,
            "rating_q025": 1281.7644580334497
        },
        "jamba-1.5-large": {
            "rating": 1284.7550334732807,
            "rating_q975": 1292.1115134876939,
            "rating_q025": 1277.3985534588676
        },
        "reka-core-20240904": {
            "rating": 1284.490732820078,
            "rating_q975": 1291.6491732435911,
            "rating_q025": 1277.3322923965648
        },
        "gemma-2-27b-it": {
            "rating": 1284.469277051283,
            "rating_q975": 1287.753993858763,
            "rating_q025": 1281.184560243803
        },
        "llama-3.1-nemotron-51b-instruct": {
            "rating": 1283.3859028604993,
            "rating_q975": 1293.4136963936717,
            "rating_q025": 1273.358109327327
        },
        "llama-3.1-tulu-3-70b": {
            "rating": 1283.0078255588237,
            "rating_q975": 1293.5771996182089,
            "rating_q025": 1272.4384514994385
        },
        "gemini-1.5-flash-001": {
            "rating": 1282.6643001905425,
            "rating_q975": 1287.126165926084,
            "rating_q025": 1278.202434455001
        },
        "gpt-4-0314": {
            "rating": 1282.3522300234054,
            "rating_q975": 1287.1691806741997,
            "rating_q025": 1277.535279372611
        },
        "claude-3-sonnet-20240229": {
            "rating": 1282.0410300091062,
            "rating_q975": 1286.0407405092815,
            "rating_q025": 1278.0413195089309
        },
        "command-r-plus-08-2024": {
            "rating": 1277.519381825421,
            "rating_q975": 1284.150902827589,
            "rating_q025": 1270.887860823253
        },
        "nemotron-4-340b-instruct": {
            "rating": 1275.430612283041,
            "rating_q975": 1280.8045252174938,
            "rating_q025": 1270.0566993485882
        },
        "gemma-2-9b-it-simpo": {
            "rating": 1274.2522960301976,
            "rating_q975": 1281.1675338759487,
            "rating_q025": 1267.3370581844465
        },
        "deepseek-coder-v2": {
            "rating": 1273.7572973786994,
            "rating_q975": 1280.2797408367344,
            "rating_q025": 1267.2348539206644
        },
        "gpt-4-0613": {
            "rating": 1272.7467763719187,
            "rating_q975": 1276.8414555639276,
            "rating_q025": 1268.6520971799098
        },
        "mistral-small-24b-instruct-2501": {
            "rating": 1271.8047900948995,
            "rating_q975": 1277.6844815510779,
            "rating_q025": 1265.9250986387212
        },
        "llama-3-70b-instruct": {
            "rating": 1271.364036296735,
            "rating_q975": 1274.8979474711612,
            "rating_q025": 1267.830125122309
        },
        "glm-4-0520": {
            "rating": 1269.5602752992072,
            "rating_q975": 1276.571024040066,
            "rating_q025": 1262.5495265583484
        },
        "reka-flash-20240904": {
            "rating": 1269.1787280513463,
            "rating_q975": 1276.1748628702856,
            "rating_q025": 1262.182593232407
        },
        "qwen2.5-coder-32b-instruct": {
            "rating": 1267.1132264210423,
            "rating_q975": 1275.2529301924235,
            "rating_q025": 1258.9735226496612
        },
        "c4ai-aya-expanse-32b": {
            "rating": 1264.972417670816,
            "rating_q975": 1269.8116844337264,
            "rating_q025": 1260.1331509079055
        },
        "claude-3-haiku-20240307": {
            "rating": 1263.2114082539479,
            "rating_q975": 1266.950224385835,
            "rating_q025": 1259.4725921220606
        },
        "gemma-2-9b-it": {
            "rating": 1261.440397886542,
            "rating_q975": 1265.1737142648453,
            "rating_q025": 1257.7070815082388
        },
        "command-r-plus": {
            "rating": 1260.9219184446115,
            "rating_q975": 1265.2394065846083,
            "rating_q025": 1256.6044303046147
        },
        "qwen2-72b-instruct": {
            "rating": 1260.143689899349,
            "rating_q975": 1265.061136919257,
            "rating_q025": 1255.226242879441
        },
        "amazon-nova-lite-v1.0": {
            "rating": 1258.334818482063,
            "rating_q975": 1263.4129297696197,
            "rating_q025": 1253.2567071945061
        },
        "gemini-1.5-flash-8b-001": {
            "rating": 1258.1210348146742,
            "rating_q975": 1262.3309892030054,
            "rating_q025": 1253.911080426343
        },
        "phi-4": {
            "rating": 1253.3949762189504,
            "rating_q975": 1257.9527093744985,
            "rating_q025": 1248.8372430634024
        },
        "olmo-2-0325-32b-instruct": {
            "rating": 1250.1399770222447,
            "rating_q975": 1260.967703166758,
            "rating_q025": 1239.3122508777315
        },
        "command-r-08-2024": {
            "rating": 1249.5054114202358,
            "rating_q975": 1256.1251999408084,
            "rating_q025": 1242.885622899663
        },
        "amazon-nova-micro-v1.0": {
            "rating": 1239.096916051186,
            "rating_q975": 1244.143102861693,
            "rating_q025": 1234.0507292406792
        },
        "mistral-large-2402": {
            "rating": 1238.5723151754298,
            "rating_q975": 1243.3190708718832,
            "rating_q025": 1233.8255594789764
        },
        "jamba-1.5-mini": {
            "rating": 1236.058175792692,
            "rating_q975": 1243.3102348295718,
            "rating_q025": 1228.8061167558124
        },
        "ministral-8b-2410": {
            "rating": 1233.7293250456296,
            "rating_q975": 1242.815579498245,
            "rating_q025": 1224.6430705930143
        },
        "hunyuan-standard-256k": {
            "rating": 1231.113017633146,
            "rating_q975": 1242.968109614021,
            "rating_q025": 1219.257925652271
        },
        "qwen1.5-110b-chat": {
            "rating": 1230.9310701416052,
            "rating_q975": 1236.4773375474679,
            "rating_q025": 1225.3848027357426
        },
        "qwen1.5-72b-chat": {
            "rating": 1230.568678083443,
            "rating_q975": 1235.893388663583,
            "rating_q025": 1225.243967503303
        },
        "gemini-pro-dev-api": {
            "rating": 1229.633619853293,
            "rating_q975": 1237.1090727245428,
            "rating_q025": 1222.1581669820434
        },
        "reka-flash-21b-20240226-online": {
            "rating": 1229.3743823701311,
            "rating_q975": 1236.8160794067642,
            "rating_q025": 1221.932685333498
        },
        "mixtral-8x22b-instruct-v0.1": {
            "rating": 1225.6428610929024,
            "rating_q975": 1230.1930394772787,
            "rating_q025": 1221.0926827085261
        },
        "command-r": {
            "rating": 1224.8251552974968,
            "rating_q975": 1229.596655019775,
            "rating_q025": 1220.0536555752187
        },
        "reka-flash-21b-20240226": {
            "rating": 1222.7823773529847,
            "rating_q975": 1228.764356616304,
            "rating_q025": 1216.8003980896654
        },
        "c4ai-aya-expanse-8b": {
            "rating": 1221.4007045908272,
            "rating_q975": 1228.3364402379696,
            "rating_q025": 1214.4649689436849
        },
        "gpt-3.5-turbo-0125": {
            "rating": 1221.1780223077194,
            "rating_q975": 1225.9233941312416,
            "rating_q025": 1216.4326504841972
        },
        "llama-3.1-tulu-3-8b": {
            "rating": 1220.727427222029,
            "rating_q975": 1231.4637862805712,
            "rating_q025": 1209.991068163487
        },
        "mistral-medium": {
            "rating": 1219.4265035145822,
            "rating_q975": 1224.9912402313107,
            "rating_q025": 1213.8617667978538
        },
        "llama-3-8b-instruct": {
            "rating": 1218.7209472320462,
            "rating_q975": 1222.4115988623987,
            "rating_q025": 1215.0302956016938
        },
        "gemini-pro": {
            "rating": 1218.6686372390097,
            "rating_q975": 1230.6856659181703,
            "rating_q025": 1206.6516085598491
        },
        "yi-1.5-34b-chat": {
            "rating": 1210.6148537266677,
            "rating_q975": 1215.6682967673505,
            "rating_q025": 1205.5614106859848
        },
        "zephyr-orpo-141b-A35b-v0.1": {
            "rating": 1208.444573250714,
            "rating_q975": 1219.3598163704557,
            "rating_q025": 1197.5293301309723
        },
        "llama-3.1-8b-instruct": {
            "rating": 1208.2954492115987,
            "rating_q975": 1212.3403722859355,
            "rating_q025": 1204.2505261372619
        },
        "granite-3.1-8b-instruct": {
            "rating": 1207.8470337425188,
            "rating_q975": 1219.0473813854674,
            "rating_q025": 1196.6466860995702
        },
        "gpt-3.5-turbo-1106": {
            "rating": 1205.9608969588703,
            "rating_q975": 1215.1651064346433,
            "rating_q025": 1196.7566874830973
        },
        "qwen1.5-32b-chat": {
            "rating": 1201.8252656705622,
            "rating_q975": 1207.996658861322,
            "rating_q025": 1195.6538724798024
        },
        "phi-3-medium-4k-instruct": {
            "rating": 1195.2697165956831,
            "rating_q975": 1200.4023648814182,
            "rating_q025": 1190.137068309948
        },
        "gemma-2-2b-it": {
            "rating": 1194.7348730229407,
            "rating_q975": 1198.7561594314777,
            "rating_q025": 1190.7135866144038
        },
        "mixtral-8x7b-instruct-v0.1": {
            "rating": 1192.4723727070036,
            "rating_q975": 1196.7558867256816,
            "rating_q025": 1188.1888586883256
        },
        "dbrx-instruct-preview": {
            "rating": 1190.7511494457278,
            "rating_q975": 1196.9397340246228,
            "rating_q025": 1184.5625648668329
        },
        "internlm2_5-20b-chat": {
            "rating": 1190.686877835419,
            "rating_q975": 1197.9076049243272,
            "rating_q025": 1183.4661507465107
        },
        "qwen1.5-14b-chat": {
            "rating": 1189.0120887821427,
            "rating_q975": 1196.2207463542077,
            "rating_q025": 1181.8034312100776
        },
        "yi-34b-chat": {
            "rating": 1182.0180165548286,
            "rating_q975": 1188.9992137066456,
            "rating_q025": 1175.0368194030116
        },
        "granite-3.0-8b-instruct": {
            "rating": 1179.4285192794655,
            "rating_q975": 1188.2185672487574,
            "rating_q025": 1170.6384713101736
        },
        "deepseek-llm-67b-chat": {
            "rating": 1178.913554007014,
            "rating_q975": 1190.7214548363809,
            "rating_q025": 1167.1056531776471
        },
        "wizardlm-70b": {
            "rating": 1178.611219652539,
            "rating_q975": 1188.2977195087667,
            "rating_q025": 1168.9247197963111
        },
        "openchat-3.5-0106": {
            "rating": 1176.7680630409309,
            "rating_q975": 1184.8487860286102,
            "rating_q025": 1168.6873400532515
        },
        "granite-3.1-2b-instruct": {
            "rating": 1176.5421978206132,
            "rating_q975": 1187.8107647405238,
            "rating_q025": 1165.2736309007025
        },
        "snowflake-arctic-instruct": {
            "rating": 1175.1202404505336,
            "rating_q975": 1181.077505343235,
            "rating_q025": 1169.1629755578322
        },
        "tulu-2-dpo-70b": {
            "rating": 1173.8908655387572,
            "rating_q975": 1184.0208121672263,
            "rating_q025": 1163.7609189102882
        },
        "gemma-1.1-7b-it": {
            "rating": 1173.7362572097854,
            "rating_q975": 1179.7902843750098,
            "rating_q025": 1167.682230044561
        },
        "openchat-3.5": {
            "rating": 1170.3044825581167,
            "rating_q975": 1180.2772768211469,
            "rating_q025": 1160.3316882950865
        },
        "starling-lm-7b-beta": {
            "rating": 1168.940429885181,
            "rating_q975": 1176.3895643516025,
            "rating_q025": 1161.4912954187594
        },
        "phi-3-small-8k-instruct": {
            "rating": 1168.215678874081,
            "rating_q975": 1174.2148882005713,
            "rating_q025": 1162.2164695475908
        },
        "llama-2-70b-chat": {
            "rating": 1167.844628357806,
            "rating_q975": 1173.3992588464732,
            "rating_q025": 1162.2899978691387
        },
        "openhermes-2.5-mistral-7b": {
            "rating": 1167.1172561139024,
            "rating_q975": 1177.7674092045625,
            "rating_q025": 1156.4671030232423
        },
        "vicuna-33b": {
            "rating": 1165.7559225850432,
            "rating_q975": 1172.0604385006714,
            "rating_q025": 1159.451406669415
        },
        "llama-3.2-3b-instruct": {
            "rating": 1163.7719381698291,
            "rating_q975": 1171.4709869613441,
            "rating_q025": 1156.0728893783141
        },
        "nous-hermes-2-mixtral-8x7b-dpo": {
            "rating": 1161.501832827112,
            "rating_q975": 1173.6299926603567,
            "rating_q025": 1149.373672993867
        },
        "starling-lm-7b-alpha": {
            "rating": 1160.7509353792816,
            "rating_q975": 1168.9727872563874,
            "rating_q025": 1152.5290835021758
        },
        "qwq-32b-preview": {
            "rating": 1158.595709011159,
            "rating_q975": 1170.301948952303,
            "rating_q025": 1146.889469070015
        },
        "granite-3.0-2b-instruct": {
            "rating": 1152.3131324914427,
            "rating_q975": 1160.8218791049178,
            "rating_q025": 1143.8043858779677
        },
        "llama2-70b-steerlm-chat": {
            "rating": 1149.3490640550908,
            "rating_q975": 1162.28587371744,
            "rating_q025": 1136.4122543927417
        },
        "solar-10.7b-instruct-v1.0": {
            "rating": 1145.5311303472254,
            "rating_q975": 1159.0041682386868,
            "rating_q025": 1132.058092455764
        },
        "mistral-7b-instruct-v0.2": {
            "rating": 1145.205656424187,
            "rating_q975": 1151.9825692762072,
            "rating_q025": 1138.428743572167
        },
        "wizardlm-13b": {
            "rating": 1144.5856976484622,
            "rating_q975": 1154.1456151271193,
            "rating_q025": 1135.025780169805
        },
        "dolphin-2.2.1-mistral-7b": {
            "rating": 1143.2180340593363,
            "rating_q975": 1158.954588867687,
            "rating_q025": 1127.4814792509856
        },
        "llama-2-13b-chat": {
            "rating": 1141.7740570998503,
            "rating_q975": 1148.5745932689158,
            "rating_q025": 1134.9735209307848
        },
        "mpt-30b-chat": {
            "rating": 1140.0108477515282,
            "rating_q975": 1152.7237008134462,
            "rating_q025": 1127.2979946896103
        },
        "qwen1.5-7b-chat": {
            "rating": 1138.1903957644151,
            "rating_q975": 1148.2637722974212,
            "rating_q025": 1128.1170192314091
        },
        "phi-3-mini-4k-instruct-june-2024": {
            "rating": 1138.151950495393,
            "rating_q975": 1144.6714885811532,
            "rating_q025": 1131.632412409633
        },
        "falcon-180b-chat": {
            "rating": 1137.9109966069364,
            "rating_q975": 1156.1165190113036,
            "rating_q025": 1119.7054742025691
        },
        "vicuna-13b": {
            "rating": 1136.5754473795146,
            "rating_q975": 1143.415250442776,
            "rating_q025": 1129.7356443162532
        },
        "qwen-14b-chat": {
            "rating": 1133.4183263496584,
            "rating_q975": 1144.8114081612787,
            "rating_q025": 1122.0252445380381
        },
        "codellama-34b-instruct": {
            "rating": 1132.7041926946326,
            "rating_q975": 1141.8518379947752,
            "rating_q025": 1123.55654739449
        },
        "gemma-7b-it": {
            "rating": 1128.865676930874,
            "rating_q975": 1138.4932865315861,
            "rating_q025": 1119.238067330162
        },
        "phi-3-mini-128k-instruct": {
            "rating": 1126.1066896679245,
            "rating_q975": 1133.5758584498576,
            "rating_q025": 1118.6375208859913
        },
        "phi-3-mini-4k-instruct": {
            "rating": 1125.750894164629,
            "rating_q975": 1132.1984342489036,
            "rating_q025": 1119.3033540803544
        },
        "guanaco-33b": {
            "rating": 1125.4724687522455,
            "rating_q975": 1138.20002824492,
            "rating_q025": 1112.744909259571
        },
        "codellama-70b-instruct": {
            "rating": 1123.606546391113,
            "rating_q975": 1142.791667057638,
            "rating_q025": 1104.4214257245878
        },
        "zephyr-7b-beta": {
            "rating": 1123.5157075827221,
            "rating_q975": 1132.5793024195025,
            "rating_q025": 1114.4521127459418
        },
        "palm-2": {
            "rating": 1123.3071772692583,
            "rating_q975": 1132.9935072145092,
            "rating_q025": 1113.6208473240074
        },
        "smollm2-1.7b-instruct": {
            "rating": 1116.539837521861,
            "rating_q975": 1131.065131232307,
            "rating_q025": 1102.014543811415
        },
        "zephyr-7b-alpha": {
            "rating": 1116.2001177898042,
            "rating_q975": 1132.5051068099924,
            "rating_q025": 1099.895128769616
        },
        "stripedhyena-nous-7b": {
            "rating": 1114.5003879916349,
            "rating_q975": 1125.8023745698342,
            "rating_q025": 1103.1984014134355
        },
        "llama-3.2-1b-instruct": {
            "rating": 1110.1189107101432,
            "rating_q975": 1117.9607748496812,
            "rating_q025": 1102.277046570605
        },
        "llama-2-7b-chat": {
            "rating": 1109.7097879640974,
            "rating_q975": 1116.9325337960195,
            "rating_q025": 1102.4870421321752
        },
        "vicuna-7b": {
            "rating": 1108.717612413176,
            "rating_q975": 1118.189074102941,
            "rating_q025": 1099.2461507234111
        },
        "gemma-1.1-2b-it": {
            "rating": 1108.3691722396497,
            "rating_q975": 1116.122384026128,
            "rating_q025": 1100.6159604531715
        },
        "mistral-7b-instruct": {
            "rating": 1096.512661932154,
            "rating_q975": 1106.076209288557,
            "rating_q025": 1086.949114575751
        },
        "gemma-2b-it": {
            "rating": 1084.1923432908243,
            "rating_q975": 1095.9894173004507,
            "rating_q025": 1072.395269281198
        },
        "qwen1.5-4b-chat": {
            "rating": 1082.5859002833008,
            "rating_q975": 1092.1742044031696,
            "rating_q025": 1072.997596163432
        },
        "olmo-7b-instruct": {
            "rating": 1068.1422110263295,
            "rating_q975": 1079.5907431216042,
            "rating_q025": 1056.6936789310548
        },
        "koala-13b": {
            "rating": 1062.9600890299475,
            "rating_q975": 1073.5027369453137,
            "rating_q025": 1052.4174411145814
        },
        "gpt4all-13b-snoozy": {
            "rating": 1054.5487621772259,
            "rating_q975": 1070.6579036798132,
            "rating_q025": 1038.4396206746385
        },
        "mpt-7b-chat": {
            "rating": 1053.696297662401,
            "rating_q975": 1066.1806617952734,
            "rating_q025": 1041.2119335295288
        },
        "alpaca-13b": {
            "rating": 1047.3216345688961,
            "rating_q975": 1059.2171274059483,
            "rating_q025": 1035.426141731844
        },
        "chatglm3-6b": {
            "rating": 1044.5591368636901,
            "rating_q975": 1056.901210866614,
            "rating_q025": 1032.2170628607662
        },
        "RWKV-4-Raven-14B": {
            "rating": 1027.6709107167012,
            "rating_q975": 1039.4958546038833,
            "rating_q025": 1015.845966829519
        },
        "oasst-pythia-12b": {
            "rating": 1007.6360492799033,
            "rating_q975": 1019.0021348660991,
            "rating_q025": 996.2699636937075
        },
        "chatglm2-6b": {
            "rating": 1006.7954441748644,
            "rating_q975": 1021.4265675790194,
            "rating_q025": 992.1643207707094
        },
        "chatglm-6b": {
            "rating": 977.5755299443668,
            "rating_q975": 990.8226084206766,
            "rating_q025": 964.3284514680571
        },
        "fastchat-t5-3b": {
            "rating": 973.4018969056917,
            "rating_q975": 986.3825599311803,
            "rating_q025": 960.4212338802032
        },
        "dolly-v2-12b": {
            "rating": 957.731430731465,
            "rating_q975": 971.6725752130876,
            "rating_q025": 943.7902862498424
        },
        "llama-13b": {
            "rating": 949.9375573523013,
            "rating_q975": 966.2312441921649,
            "rating_q025": 933.6438705124376
        },
        "stablelm-tuned-alpha-7b": {
            "rating": 937.242041410736,
            "rating_q975": 950.7387747910857,
            "rating_q025": 923.7453080303862
        }
    },
    "no_short": {
        "gemini-3-pro": {
            "rating": 1493.2951827784827,
            "rating_q975": 1499.5277127304025,
            "rating_q025": 1487.062652826563
        },
        "grok-4.1-thinking": {
            "rating": 1478.8731933648016,
            "rating_q975": 1485.0115543881118,
            "rating_q025": 1472.7348323414915
        },
        "claude-opus-4-5-20251101-thinking-32k": {
            "rating": 1470.4594730999536,
            "rating_q975": 1477.6052728820655,
            "rating_q025": 1463.3136733178417
        },
        "claude-opus-4-5-20251101": {
            "rating": 1470.4548319738478,
            "rating_q975": 1477.5103699456592,
            "rating_q025": 1463.3992940020364
        },
        "grok-4.1": {
            "rating": 1465.6163911218634,
            "rating_q975": 1471.7239232153927,
            "rating_q025": 1459.5088590283342
        },
        "gpt-5.1-high": {
            "rating": 1459.3356696730407,
            "rating_q975": 1465.7749840787646,
            "rating_q025": 1452.8963552673167
        },
        "gemini-2.5-pro": {
            "rating": 1452.1078459349842,
            "rating_q975": 1455.5850861907018,
            "rating_q025": 1448.6306056792666
        },
        "claude-sonnet-4-5-20250929-thinking-32k": {
            "rating": 1451.1472036578737,
            "rating_q975": 1455.6573890760073,
            "rating_q025": 1446.63701823974
        },
        "claude-opus-4-1-20250805-thinking-16k": {
            "rating": 1450.017333637241,
            "rating_q975": 1453.8557663140264,
            "rating_q025": 1446.1789009604558
        },
        "claude-sonnet-4-5-20250929": {
            "rating": 1447.20787807138,
            "rating_q975": 1452.2792371287153,
            "rating_q025": 1442.1365190140448
        },
        "gpt-4.5-preview-2025-02-27": {
            "rating": 1444.0331330906736,
            "rating_q975": 1449.7232264528134,
            "rating_q025": 1438.3430397285338
        },
        "claude-opus-4-1-20250805": {
            "rating": 1443.1955397216755,
            "rating_q975": 1446.9096624870208,
            "rating_q025": 1439.4814169563301
        },
        "chatgpt-4o-latest-20250326": {
            "rating": 1440.392051829446,
            "rating_q975": 1443.7387649511563,
            "rating_q025": 1437.0453387077357
        },
        "gpt-5.1": {
            "rating": 1438.3813656966734,
            "rating_q975": 1444.6033338232958,
            "rating_q025": 1432.159397570051
        },
        "gpt-5-high": {
            "rating": 1436.8902613869946,
            "rating_q975": 1441.482589105932,
            "rating_q025": 1432.297933668057
        },
        "qwen3-max-preview": {
            "rating": 1434.2487606070013,
            "rating_q975": 1438.8210863441855,
            "rating_q025": 1429.676434869817
        },
        "o3-2025-04-16": {
            "rating": 1434.2129383273796,
            "rating_q975": 1437.8542637958212,
            "rating_q025": 1430.571612858938
        },
        "grok-4-1-fast-reasoning": {
            "rating": 1430.2853044461108,
            "rating_q975": 1437.2192668790713,
            "rating_q025": 1423.3513420131503
        },
        "ernie-5.0-preview-1103": {
            "rating": 1428.6171272922675,
            "rating_q975": 1437.5340602081185,
            "rating_q025": 1419.7001943764164
        },
        "gpt-5-chat": {
            "rating": 1426.904765723483,
            "rating_q975": 1431.2378450422218,
            "rating_q025": 1422.5716864047442
        },
        "glm-4.6": {
            "rating": 1426.2488226764162,
            "rating_q975": 1430.9886311420653,
            "rating_q025": 1421.5090142107672
        },
        "kimi-k2-thinking-turbo": {
            "rating": 1426.2355701776708,
            "rating_q975": 1432.0595338861528,
            "rating_q025": 1420.4116064691887
        },
        "claude-opus-4-20250514-thinking-16k": {
            "rating": 1424.440350847329,
            "rating_q975": 1428.8070049541989,
            "rating_q025": 1420.0736967404591
        },
        "qwen3-max-2025-09-23": {
            "rating": 1423.9504739619342,
            "rating_q975": 1430.4318692252907,
            "rating_q025": 1417.4690786985777
        },
        "deepseek-v3.2-exp": {
            "rating": 1423.706022384529,
            "rating_q975": 1430.2477828114752,
            "rating_q025": 1417.1642619575828
        },
        "qwen3-235b-a22b-instruct-2507": {
            "rating": 1422.3409399778384,
            "rating_q975": 1426.031379796542,
            "rating_q025": 1418.6505001591347
        },
        "deepseek-v3.2-exp-thinking": {
            "rating": 1421.4575721304482,
            "rating_q975": 1428.0647084112136,
            "rating_q025": 1414.8504358496828
        },
        "grok-4-fast-chat": {
            "rating": 1420.7934722980424,
            "rating_q975": 1428.4411484468458,
            "rating_q025": 1413.145796149239
        },
        "kimi-k2-0905-preview": {
            "rating": 1419.778774462472,
            "rating_q975": 1426.3817969981815,
            "rating_q025": 1413.1757519267626
        },
        "deepseek-v3.2-thinking": {
            "rating": 1419.5935944278037,
            "rating_q975": 1428.0712699182359,
            "rating_q025": 1411.1159189373716
        },
        "deepseek-v3.1": {
            "rating": 1418.4265870935205,
            "rating_q975": 1424.4686499612142,
            "rating_q025": 1412.384524225827
        },
        "deepseek-r1-0528": {
            "rating": 1418.1211028829798,
            "rating_q975": 1423.7523906478064,
            "rating_q025": 1412.4898151181533
        },
        "deepseek-v3.2": {
            "rating": 1418.0369826918932,
            "rating_q975": 1426.3733795830717,
            "rating_q025": 1409.7005858007146
        },
        "kimi-k2-0711-preview": {
            "rating": 1417.0476307611118,
            "rating_q975": 1421.8973025710566,
            "rating_q025": 1412.197958951167
        },
        "deepseek-v3.1-thinking": {
            "rating": 1416.0176409390474,
            "rating_q975": 1422.6736567237317,
            "rating_q025": 1409.361625154363
        },
        "qwen3-vl-235b-a22b-instruct": {
            "rating": 1415.7162058976069,
            "rating_q975": 1422.429663414088,
            "rating_q025": 1409.0027483811257
        },
        "deepseek-v3.1-terminus": {
            "rating": 1415.2977955050098,
            "rating_q975": 1424.9476540042344,
            "rating_q025": 1405.6479370057853
        },
        "deepseek-v3.1-terminus-thinking": {
            "rating": 1414.7788316026074,
            "rating_q975": 1424.764898154888,
            "rating_q025": 1404.7927650503268
        },
        "mistral-large-3": {
            "rating": 1414.276529483524,
            "rating_q975": 1422.6117848203314,
            "rating_q025": 1405.9412741467165
        },
        "claude-opus-4-20250514": {
            "rating": 1413.3956259405845,
            "rating_q975": 1417.6788418720278,
            "rating_q025": 1409.1124100091413
        },
        "gpt-4.1-2025-04-14": {
            "rating": 1413.1489484848328,
            "rating_q975": 1416.8687531461198,
            "rating_q025": 1409.4291438235457
        },
        "mistral-medium-2508": {
            "rating": 1411.6056020732494,
            "rating_q975": 1415.4956629120056,
            "rating_q025": 1407.7155412344932
        },
        "grok-3-preview-02-24": {
            "rating": 1409.8898397789487,
            "rating_q975": 1414.1594538073673,
            "rating_q025": 1405.6202257505302
        },
        "glm-4.5": {
            "rating": 1409.617515054451,
            "rating_q975": 1414.5323374126674,
            "rating_q025": 1404.7026926962344
        },
        "grok-4-0709": {
            "rating": 1409.0830933017442,
            "rating_q975": 1413.020928344238,
            "rating_q025": 1405.1452582592503
        },
        "gemini-2.5-flash": {
            "rating": 1408.5970099175709,
            "rating_q975": 1412.001973582703,
            "rating_q025": 1405.1920462524388
        },
        "gemini-2.5-flash-preview-09-2025": {
            "rating": 1404.8195505887138,
            "rating_q975": 1409.2277280344283,
            "rating_q025": 1400.4113731429993
        },
        "claude-haiku-4-5-20251001": {
            "rating": 1403.0947510163683,
            "rating_q975": 1407.6871408282204,
            "rating_q025": 1398.502361204516
        },
        "grok-4-fast-reasoning": {
            "rating": 1402.5466853606727,
            "rating_q975": 1407.6437045440805,
            "rating_q025": 1397.4496661772648
        },
        "o1-2024-12-17": {
            "rating": 1402.1197883502784,
            "rating_q975": 1406.5047751692762,
            "rating_q025": 1397.7348015312807
        },
        "qwen3-235b-a22b-no-thinking": {
            "rating": 1400.509896844758,
            "rating_q975": 1405.0259440141406,
            "rating_q025": 1395.9938496753755
        },
        "claude-sonnet-4-20250514-thinking-32k": {
            "rating": 1400.3534653276977,
            "rating_q975": 1404.7549460799023,
            "rating_q025": 1395.951984575493
        },
        "qwen3-next-80b-a3b-instruct": {
            "rating": 1400.3379105897302,
            "rating_q975": 1405.2003816079014,
            "rating_q025": 1395.475439571559
        },
        "longcat-flash-chat": {
            "rating": 1400.1992464617379,
            "rating_q975": 1406.637227354752,
            "rating_q025": 1393.7612655687237
        },
        "qwen3-235b-a22b-thinking-2507": {
            "rating": 1396.7232409755297,
            "rating_q975": 1403.2254053660442,
            "rating_q025": 1390.2210765850152
        },
        "deepseek-r1": {
            "rating": 1396.634110431133,
            "rating_q975": 1401.459452213479,
            "rating_q025": 1391.808768648787
        },
        "qwen3-vl-235b-a22b-thinking": {
            "rating": 1394.0975899505552,
            "rating_q975": 1400.944446282376,
            "rating_q025": 1387.2507336187343
        },
        "hunyuan-vision-1.5-thinking": {
            "rating": 1393.1996892718273,
            "rating_q975": 1405.6426790503656,
            "rating_q025": 1380.756699493289
        },
        "deepseek-v3-0324": {
            "rating": 1392.9123742975446,
            "rating_q975": 1396.7889704486122,
            "rating_q025": 1389.035778146477
        },
        "gpt-5-mini-high": {
            "rating": 1391.447214280924,
            "rating_q975": 1396.171546873473,
            "rating_q025": 1386.722881688375
        },
        "o4-mini-2025-04-16": {
            "rating": 1391.3314279230688,
            "rating_q975": 1395.313053098175,
            "rating_q025": 1387.3498027479625
        },
        "claude-sonnet-4-20250514": {
            "rating": 1390.7514414835969,
            "rating_q975": 1395.1140077748082,
            "rating_q025": 1386.3888751923855
        },
        "mai-1-preview": {
            "rating": 1390.3907648645634,
            "rating_q975": 1395.8713573789394,
            "rating_q025": 1384.9101723501874
        },
        "claude-3-7-sonnet-20250219-thinking-32k": {
            "rating": 1388.8122087704612,
            "rating_q975": 1392.9747823435262,
            "rating_q025": 1384.6496351973963
        },
        "o1-preview": {
            "rating": 1388.059089360834,
            "rating_q975": 1392.966817307567,
            "rating_q025": 1383.1513614141008
        },
        "qwen3-coder-480b-a35b-instruct": {
            "rating": 1385.155622989828,
            "rating_q975": 1390.1664551862593,
            "rating_q025": 1380.1447907933969
        },
        "hunyuan-t1-20250711": {
            "rating": 1384.4820739904876,
            "rating_q975": 1393.1233253279258,
            "rating_q025": 1375.8408226530494
        },
        "mistral-medium-2505": {
            "rating": 1384.3777699329362,
            "rating_q975": 1389.0604238083401,
            "rating_q025": 1379.6951160575322
        },
        "qwen3-30b-a3b-instruct-2507": {
            "rating": 1382.8669734899281,
            "rating_q975": 1387.780155768711,
            "rating_q025": 1377.9537912111452
        },
        "gpt-4.1-mini-2025-04-14": {
            "rating": 1381.101586764471,
            "rating_q975": 1385.4094056476142,
            "rating_q025": 1376.7937678813278
        },
        "hunyuan-turbos-20250416": {
            "rating": 1380.9728254773358,
            "rating_q975": 1387.3451879795919,
            "rating_q025": 1374.6004629750798
        },
        "gemini-2.5-flash-lite-preview-09-2025-no-thinking": {
            "rating": 1378.6894962536553,
            "rating_q975": 1383.0691910471269,
            "rating_q025": 1374.3098014601837
        },
        "gemini-2.5-flash-lite-preview-06-17-thinking": {
            "rating": 1374.8575391988816,
            "rating_q975": 1379.3668456254502,
            "rating_q025": 1370.348232772313
        },
        "qwen3-235b-a22b": {
            "rating": 1374.668044827503,
            "rating_q975": 1379.3713968755435,
            "rating_q025": 1369.9646927794627
        },
        "claude-3-5-sonnet-20241022": {
            "rating": 1373.3305994009165,
            "rating_q975": 1376.4155133683983,
            "rating_q025": 1370.2456854334348
        },
        "qwen2.5-max": {
            "rating": 1372.456191992366,
            "rating_q975": 1376.4607221549059,
            "rating_q025": 1368.4516618298262
        },
        "claude-3-7-sonnet-20250219": {
            "rating": 1372.408774921907,
            "rating_q975": 1376.3071739548443,
            "rating_q025": 1368.5103758889697
        },
        "glm-4.5-air": {
            "rating": 1370.9383838437627,
            "rating_q975": 1375.233377316697,
            "rating_q025": 1366.6433903708285
        },
        "qwen3-next-80b-a3b-thinking": {
            "rating": 1366.8612506416189,
            "rating_q975": 1372.7550553107633,
            "rating_q025": 1360.9674459724745
        },
        "minimax-m1": {
            "rating": 1366.7642100280373,
            "rating_q975": 1371.0277703124054,
            "rating_q025": 1362.500649743669
        },
        "gemma-3-27b-it": {
            "rating": 1365.206003933078,
            "rating_q975": 1368.8663096743428,
            "rating_q025": 1361.545698191813
        },
        "o3-mini-high": {
            "rating": 1363.1051164380535,
            "rating_q975": 1368.3119974437047,
            "rating_q025": 1357.8982354324023
        },
        "grok-3-mini-high": {
            "rating": 1362.226041027882,
            "rating_q975": 1367.557785648012,
            "rating_q025": 1356.894296407752
        },
        "gemini-2.0-flash-001": {
            "rating": 1360.4042496874195,
            "rating_q975": 1364.1358112715827,
            "rating_q025": 1356.6726881032562
        },
        "deepseek-v3": {
            "rating": 1357.519250203417,
            "rating_q975": 1362.1860992486613,
            "rating_q025": 1352.8524011581726
        },
        "grok-3-mini-beta": {
            "rating": 1356.9983548283462,
            "rating_q975": 1362.0062564158466,
            "rating_q025": 1351.990453240846
        },
        "mistral-small-2506": {
            "rating": 1355.4453314448049,
            "rating_q975": 1360.6533142623782,
            "rating_q025": 1350.2373486272315
        },
        "command-a-03-2025": {
            "rating": 1352.6508053321454,
            "rating_q975": 1356.0990167758657,
            "rating_q025": 1349.202593888425
        },
        "gemini-2.0-flash-lite-preview-02-05": {
            "rating": 1351.8843954945016,
            "rating_q975": 1356.1255638251162,
            "rating_q025": 1347.643227163887
        },
        "glm-4.5v": {
            "rating": 1351.8160908602026,
            "rating_q975": 1360.2855871164465,
            "rating_q025": 1343.3465946039587
        },
        "gemini-1.5-pro-002": {
            "rating": 1351.492200463576,
            "rating_q975": 1354.759967561591,
            "rating_q025": 1348.2244333655608
        },
        "gpt-oss-120b": {
            "rating": 1351.0213607415194,
            "rating_q975": 1355.431580311152,
            "rating_q025": 1346.6111411718869
        },
        "amazon-nova-experimental-chat-10-20": {
            "rating": 1350.6250600930548,
            "rating_q975": 1358.0147609491548,
            "rating_q025": 1343.2353592369548
        },
        "intellect-3": {
            "rating": 1348.979483936559,
            "rating_q975": 1361.5915458994496,
            "rating_q025": 1336.3674219736686
        },
        "o3-mini": {
            "rating": 1347.9546894493396,
            "rating_q975": 1351.4265260238471,
            "rating_q025": 1344.4828528748321
        },
        "hunyuan-turbos-20250226": {
            "rating": 1347.189962249106,
            "rating_q975": 1358.8946929521887,
            "rating_q025": 1335.4852315460232
        },
        "llama-3.1-nemotron-ultra-253b-v1": {
            "rating": 1347.0455350454486,
            "rating_q975": 1358.7599126706248,
            "rating_q025": 1335.3311574202723
        },
        "step-3": {
            "rating": 1346.9639530090953,
            "rating_q975": 1354.419718120342,
            "rating_q025": 1339.5081878978488
        },
        "minimax-m2": {
            "rating": 1346.0935416934449,
            "rating_q975": 1353.846820799055,
            "rating_q025": 1338.3402625878348
        },
        "gpt-4o-2024-05-13": {
            "rating": 1345.917642322767,
            "rating_q975": 1349.2542584004336,
            "rating_q025": 1342.5810262451005
        },
        "qwen3-32b": {
            "rating": 1345.5179256601332,
            "rating_q975": 1355.0529023693211,
            "rating_q025": 1335.9829489509452
        },
        "ling-flash-2.0": {
            "rating": 1345.487205733457,
            "rating_q975": 1352.781813933361,
            "rating_q025": 1338.1925975335528
        },
        "qwen-plus-0125": {
            "rating": 1345.0397734666008,
            "rating_q975": 1353.383621685213,
            "rating_q025": 1336.6959252479885
        },
        "glm-4-plus-0111": {
            "rating": 1343.4824811116614,
            "rating_q975": 1351.8822924008387,
            "rating_q025": 1335.0826698224841
        },
        "claude-3-5-sonnet-20240620": {
            "rating": 1343.2409691595176,
            "rating_q975": 1346.6016697349835,
            "rating_q025": 1339.8802685840517
        },
        "amazon-nova-experimental-chat-10-09": {
            "rating": 1341.5281283287327,
            "rating_q975": 1348.1125332410838,
            "rating_q025": 1334.9437234163815
        },
        "gemma-3-12b-it": {
            "rating": 1341.328627186524,
            "rating_q975": 1350.8629886504907,
            "rating_q025": 1331.7942657225574
        },
        "hunyuan-turbo-0110": {
            "rating": 1339.7435925403952,
            "rating_q975": 1351.2694393206123,
            "rating_q025": 1328.217745760178
        },
        "nvidia-llama-3.3-nemotron-super-49b-v1.5": {
            "rating": 1339.7016396245847,
            "rating_q975": 1349.553658783295,
            "rating_q025": 1329.8496204658743
        },
        "gpt-5-nano-high": {
            "rating": 1337.9470263769176,
            "rating_q975": 1344.895715838205,
            "rating_q025": 1330.9983369156303
        },
        "llama-3.1-405b-instruct-bf16": {
            "rating": 1335.4139123623258,
            "rating_q975": 1339.0180083289988,
            "rating_q025": 1331.809816395653
        },
        "gpt-4o-2024-08-06": {
            "rating": 1335.3949998611247,
            "rating_q975": 1339.501089048101,
            "rating_q025": 1331.2889106741484
        },
        "o1-mini": {
            "rating": 1335.368580282919,
            "rating_q975": 1338.9066826387716,
            "rating_q025": 1331.8304779270666
        },
        "gemini-advanced-0514": {
            "rating": 1335.1939598147064,
            "rating_q975": 1340.312555114153,
            "rating_q025": 1330.07536451526
        },
        "grok-2-2024-08-13": {
            "rating": 1335.1257233704846,
            "rating_q975": 1338.698282960658,
            "rating_q025": 1331.5531637803113
        },
        "qwq-32b": {
            "rating": 1334.3739423910906,
            "rating_q975": 1338.7760478931336,
            "rating_q025": 1329.9718368890476
        },
        "nova-2-lite": {
            "rating": 1334.2273824593826,
            "rating_q975": 1342.881300382837,
            "rating_q025": 1325.5734645359282
        },
        "llama-3.1-405b-instruct-fp8": {
            "rating": 1334.1936976273257,
            "rating_q975": 1337.6689880709428,
            "rating_q025": 1330.7184071837087
        },
        "step-2-16k-exp-202412": {
            "rating": 1332.001479276852,
            "rating_q975": 1340.5566590217236,
            "rating_q025": 1323.4462995319805
        },
        "yi-lightning": {
            "rating": 1328.9405708210675,
            "rating_q975": 1333.7845724808421,
            "rating_q025": 1324.0965691612928
        },
        "llama-4-maverick-17b-128e-instruct": {
            "rating": 1327.765474974592,
            "rating_q975": 1332.0086658671544,
            "rating_q025": 1323.5222840820297
        },
        "llama-3.3-nemotron-49b-super-v1": {
            "rating": 1327.6194301227868,
            "rating_q975": 1339.7618818120325,
            "rating_q025": 1315.476978433541
        },
        "qwen3-30b-a3b": {
            "rating": 1325.7872325071853,
            "rating_q975": 1330.504573998025,
            "rating_q025": 1321.0698910163455
        },
        "hunyuan-large-2025-02-10": {
            "rating": 1325.5190715691565,
            "rating_q975": 1335.335494080875,
            "rating_q025": 1315.702649057438
        },
        "gpt-4-turbo-2024-04-09": {
            "rating": 1324.6142961418452,
            "rating_q975": 1328.4383858071583,
            "rating_q025": 1320.7902064765321
        },
        "claude-3-5-haiku-20241022": {
            "rating": 1323.5684855463273,
            "rating_q975": 1326.7523269724584,
            "rating_q025": 1320.3846441201963
        },
        "claude-3-opus-20240229": {
            "rating": 1323.236789688957,
            "rating_q975": 1326.1946102351264,
            "rating_q025": 1320.2789691427877
        },
        "gemini-1.5-pro-001": {
            "rating": 1322.611171132352,
            "rating_q975": 1326.4999625893606,
            "rating_q025": 1318.7223796753433
        },
        "deepseek-v2.5-1210": {
            "rating": 1322.565325925253,
            "rating_q975": 1330.7899914929133,
            "rating_q025": 1314.340660357593
        },
        "llama-4-scout-17b-16e-instruct": {
            "rating": 1322.0233735349698,
            "rating_q975": 1326.7301081490898,
            "rating_q025": 1317.3166389208498
        },
        "gpt-4.1-nano-2025-04-14": {
            "rating": 1321.3000043792326,
            "rating_q975": 1329.0871362473254,
            "rating_q025": 1313.51287251114
        },
        "ring-flash-2.0": {
            "rating": 1319.9086881631674,
            "rating_q975": 1327.14821847633,
            "rating_q025": 1312.669157850005
        },
        "step-1o-turbo-202506": {
            "rating": 1319.3712073397273,
            "rating_q975": 1326.0589961689282,
            "rating_q025": 1312.6834185105265
        },
        "llama-3.3-70b-instruct": {
            "rating": 1318.9718033662828,
            "rating_q975": 1322.349862251025,
            "rating_q025": 1315.5937444815406
        },
        "glm-4-plus": {
            "rating": 1318.5630079183336,
            "rating_q975": 1323.41104017109,
            "rating_q025": 1313.7149756655772
        },
        "qwen-max-0919": {
            "rating": 1318.135227317719,
            "rating_q975": 1323.773344449605,
            "rating_q025": 1312.497110185833
        },
        "gemma-3n-e4b-it": {
            "rating": 1317.8730894537493,
            "rating_q975": 1322.9997347452554,
            "rating_q025": 1312.7464441622433
        },
        "gpt-oss-20b": {
            "rating": 1316.8801327541962,
            "rating_q975": 1323.2811452073852,
            "rating_q025": 1310.4791203010072
        },
        "gpt-4o-mini-2024-07-18": {
            "rating": 1315.8461106758277,
            "rating_q975": 1319.2423479900754,
            "rating_q025": 1312.44987336158
        },
        "gpt-4-1106-preview": {
            "rating": 1314.2966812129584,
            "rating_q975": 1318.1063709884322,
            "rating_q025": 1310.4869914374847
        },
        "mistral-large-2407": {
            "rating": 1314.195753707071,
            "rating_q975": 1318.0049591908646,
            "rating_q025": 1310.3865482232773
        },
        "gpt-4-0125-preview": {
            "rating": 1313.6013596378332,
            "rating_q975": 1317.6086068084805,
            "rating_q025": 1309.5941124671858
        },
        "qwen2.5-plus-1127": {
            "rating": 1313.4665636830323,
            "rating_q975": 1319.763121937639,
            "rating_q025": 1307.1700054284256
        },
        "athene-v2-chat": {
            "rating": 1312.9479661337468,
            "rating_q975": 1317.4256606031145,
            "rating_q025": 1308.4702716643792
        },
        "mercury": {
            "rating": 1311.6016111296497,
            "rating_q975": 1325.354411467448,
            "rating_q025": 1297.8488107918513
        },
        "gemini-1.5-flash-002": {
            "rating": 1310.5609037228278,
            "rating_q975": 1314.6810401432972,
            "rating_q025": 1306.4407673023584
        },
        "hunyuan-standard-2025-02-10": {
            "rating": 1310.4848335758722,
            "rating_q975": 1320.2514712905875,
            "rating_q025": 1300.718195861157
        },
        "olmo-3-32b-think": {
            "rating": 1309.506615989869,
            "rating_q975": 1320.1391922168555,
            "rating_q025": 1298.8740397628826
        },
        "grok-2-mini-2024-08-13": {
            "rating": 1307.4308643123509,
            "rating_q975": 1311.0377037015112,
            "rating_q025": 1303.8240249231906
        },
        "deepseek-v2.5": {
            "rating": 1306.4202430333366,
            "rating_q975": 1311.0415308025586,
            "rating_q025": 1301.7989552641147
        },
        "magistral-medium-2506": {
            "rating": 1305.773928486509,
            "rating_q975": 1312.1666396403991,
            "rating_q025": 1299.381217332619
        },
        "mistral-large-2411": {
            "rating": 1305.458134028947,
            "rating_q975": 1309.7957028728435,
            "rating_q025": 1301.1205651850503
        },
        "athene-70b-0725": {
            "rating": 1304.8867903693522,
            "rating_q975": 1310.4919631509872,
            "rating_q025": 1299.2816175877172
        },
        "mistral-small-3.1-24b-instruct-2503": {
            "rating": 1303.7637465916468,
            "rating_q975": 1308.2656980616075,
            "rating_q025": 1299.2617951216862
        },
        "qwen2.5-72b-instruct": {
            "rating": 1302.3274008448648,
            "rating_q975": 1306.296480567263,
            "rating_q025": 1298.3583211224666
        },
        "gemma-3-4b-it": {
            "rating": 1300.9626589178192,
            "rating_q975": 1310.3523260007833,
            "rating_q025": 1291.5729918348552
        },
        "llama-3.1-nemotron-70b-instruct": {
            "rating": 1297.655413860359,
            "rating_q975": 1305.3945456170661,
            "rating_q025": 1289.9162821036518
        },
        "hunyuan-large-vision": {
            "rating": 1295.669644044327,
            "rating_q975": 1304.7213263075666,
            "rating_q025": 1286.6179617810874
        },
        "llama-3.1-70b-instruct": {
            "rating": 1293.398954215329,
            "rating_q975": 1297.0050629082057,
            "rating_q025": 1289.7928455224524
        },
        "amazon-nova-pro-v1.0": {
            "rating": 1289.2692427210648,
            "rating_q975": 1293.7370277262346,
            "rating_q025": 1284.801457715895
        },
        "jamba-1.5-large": {
            "rating": 1288.7299985744644,
            "rating_q975": 1296.0319760865768,
            "rating_q025": 1281.428021062352
        },
        "gpt-4-0314": {
            "rating": 1288.5035257717159,
            "rating_q975": 1293.269938265865,
            "rating_q025": 1283.7371132775668
        },
        "gemma-2-27b-it": {
            "rating": 1287.9693908749064,
            "rating_q975": 1291.228698834416,
            "rating_q025": 1284.7100829153967
        },
        "reka-core-20240904": {
            "rating": 1287.0106258817773,
            "rating_q975": 1294.139884153881,
            "rating_q025": 1279.8813676096736
        },
        "llama-3.1-nemotron-51b-instruct": {
            "rating": 1286.94593787729,
            "rating_q975": 1296.8897103791987,
            "rating_q025": 1277.002165375381
        },
        "llama-3.1-tulu-3-70b": {
            "rating": 1286.8673142185708,
            "rating_q975": 1297.3001267623374,
            "rating_q025": 1276.434501674804
        },
        "gemini-1.5-flash-001": {
            "rating": 1284.8101368173784,
            "rating_q975": 1289.2191154390223,
            "rating_q025": 1280.4011581957345
        },
        "claude-3-sonnet-20240229": {
            "rating": 1282.2154377016354,
            "rating_q975": 1286.1579708222675,
            "rating_q025": 1278.2729045810033
        },
        "gemma-2-9b-it-simpo": {
            "rating": 1279.1289656183296,
            "rating_q975": 1285.981407122999,
            "rating_q025": 1272.2765241136603
        },
        "nemotron-4-340b-instruct": {
            "rating": 1278.5228359271146,
            "rating_q975": 1283.7925185747768,
            "rating_q025": 1273.2531532794524
        },
        "command-r-plus-08-2024": {
            "rating": 1277.7902868313365,
            "rating_q975": 1284.3188832808485,
            "rating_q025": 1271.2616903818246
        },
        "gpt-4-0613": {
            "rating": 1277.0975053963402,
            "rating_q975": 1281.1205763220098,
            "rating_q025": 1273.0744344706707
        },
        "llama-3-70b-instruct": {
            "rating": 1276.0058082139685,
            "rating_q975": 1279.5109364099117,
            "rating_q025": 1272.5006800180254
        },
        "glm-4-0520": {
            "rating": 1273.988405165548,
            "rating_q975": 1280.953817449839,
            "rating_q025": 1267.022992881257
        },
        "mistral-small-24b-instruct-2501": {
            "rating": 1273.564557478374,
            "rating_q975": 1279.4259881779833,
            "rating_q025": 1267.7031267787645
        },
        "reka-flash-20240904": {
            "rating": 1273.0743111891761,
            "rating_q975": 1280.0346481323083,
            "rating_q025": 1266.1139742460439
        },
        "qwen2.5-coder-32b-instruct": {
            "rating": 1269.328699713277,
            "rating_q975": 1277.4389403812493,
            "rating_q025": 1261.2184590453048
        },
        "c4ai-aya-expanse-32b": {
            "rating": 1267.8418779402505,
            "rating_q975": 1272.6496886549285,
            "rating_q025": 1263.0340672255725
        },
        "deepseek-coder-v2": {
            "rating": 1265.304696256855,
            "rating_q975": 1271.5550654095446,
            "rating_q025": 1259.0543271041656
        },
        "gemma-2-9b-it": {
            "rating": 1265.011130373854,
            "rating_q975": 1268.7229902937975,
            "rating_q025": 1261.2992704539106
        },
        "command-r-plus": {
            "rating": 1264.0204050772506,
            "rating_q975": 1268.2817612483514,
            "rating_q025": 1259.75904890615
        },
        "qwen2-72b-instruct": {
            "rating": 1262.2658728780448,
            "rating_q975": 1267.1479237549088,
            "rating_q025": 1257.3838220011808
        },
        "claude-3-haiku-20240307": {
            "rating": 1261.7537557490402,
            "rating_q975": 1265.431468136791,
            "rating_q025": 1258.0760433612895
        },
        "amazon-nova-lite-v1.0": {
            "rating": 1259.7748397406353,
            "rating_q975": 1264.8490254239034,
            "rating_q025": 1254.7006540573673
        },
        "gemini-1.5-flash-8b-001": {
            "rating": 1259.0889472829845,
            "rating_q975": 1263.2666345797995,
            "rating_q025": 1254.9112599861694
        },
        "phi-4": {
            "rating": 1255.1142091263446,
            "rating_q975": 1259.633582778334,
            "rating_q025": 1250.5948354743552
        },
        "olmo-2-0325-32b-instruct": {
            "rating": 1252.1784545681458,
            "rating_q975": 1262.9299179626769,
            "rating_q025": 1241.4269911736146
        },
        "command-r-08-2024": {
            "rating": 1251.6412609281583,
            "rating_q975": 1258.2000163265432,
            "rating_q025": 1245.0825055297735
        },
        "mistral-large-2402": {
            "rating": 1244.2106644829178,
            "rating_q975": 1248.8806565599207,
            "rating_q025": 1239.5406724059148
        },
        "amazon-nova-micro-v1.0": {
            "rating": 1241.0142782006033,
            "rating_q975": 1246.0540096020316,
            "rating_q025": 1235.974546799175
        },
        "jamba-1.5-mini": {
            "rating": 1239.11282924055,
            "rating_q975": 1246.3181644495942,
            "rating_q025": 1231.9074940315056
        },
        "ministral-8b-2410": {
            "rating": 1236.4195247821244,
            "rating_q975": 1245.4933209667988,
            "rating_q025": 1227.34572859745
        },
        "hunyuan-standard-256k": {
            "rating": 1236.1794199166138,
            "rating_q975": 1247.857417434444,
            "rating_q025": 1224.5014223987837
        },
        "gemini-pro-dev-api": {
            "rating": 1235.8597292701736,
            "rating_q975": 1243.2132093358439,
            "rating_q025": 1228.5062492045033
        },
        "reka-flash-21b-20240226-online": {
            "rating": 1234.6855172314467,
            "rating_q975": 1242.0971199147407,
            "rating_q025": 1227.2739145481528
        },
        "qwen1.5-110b-chat": {
            "rating": 1234.5339135428069,
            "rating_q975": 1240.0465846699574,
            "rating_q025": 1229.0212424156564
        },
        "qwen1.5-72b-chat": {
            "rating": 1233.7337084051694,
            "rating_q975": 1238.9754293087467,
            "rating_q025": 1228.4919875015921
        },
        "mixtral-8x22b-instruct-v0.1": {
            "rating": 1231.7068306999588,
            "rating_q975": 1236.198643613858,
            "rating_q025": 1227.2150177860597
        },
        "command-r": {
            "rating": 1228.2947106316421,
            "rating_q975": 1233.0251668409342,
            "rating_q025": 1223.5642544223501
        },
        "reka-flash-21b-20240226": {
            "rating": 1226.8964399377614,
            "rating_q975": 1232.829853124128,
            "rating_q025": 1220.9630267513949
        },
        "mistral-medium": {
            "rating": 1224.9378652098953,
            "rating_q975": 1230.4095769062787,
            "rating_q025": 1219.466153513512
        },
        "gpt-3.5-turbo-0125": {
            "rating": 1224.8710970864645,
            "rating_q975": 1229.5277138859472,
            "rating_q025": 1220.2144802869818
        },
        "c4ai-aya-expanse-8b": {
            "rating": 1224.0076951307187,
            "rating_q975": 1230.9106922303702,
            "rating_q025": 1217.1046980310673
        },
        "gemini-pro": {
            "rating": 1223.4162615815562,
            "rating_q975": 1235.25628147985,
            "rating_q025": 1211.5762416832624
        },
        "llama-3.1-tulu-3-8b": {
            "rating": 1222.8631692261383,
            "rating_q975": 1233.4652755359864,
            "rating_q025": 1212.2610629162903
        },
        "llama-3-8b-instruct": {
            "rating": 1222.1985663158443,
            "rating_q975": 1225.8615350139899,
            "rating_q025": 1218.5355976176988
        },
        "zephyr-orpo-141b-A35b-v0.1": {
            "rating": 1215.934542001507,
            "rating_q975": 1226.7865439093307,
            "rating_q025": 1205.0825400936833
        },
        "yi-1.5-34b-chat": {
            "rating": 1213.284381516764,
            "rating_q975": 1218.2785423816931,
            "rating_q025": 1208.2902206518347
        },
        "llama-3.1-8b-instruct": {
            "rating": 1210.9526492310765,
            "rating_q975": 1214.9845604872353,
            "rating_q025": 1206.9207379749178
        },
        "granite-3.1-8b-instruct": {
            "rating": 1208.746702550061,
            "rating_q975": 1219.7729820007232,
            "rating_q025": 1197.7204230993987
        },
        "qwen1.5-32b-chat": {
            "rating": 1205.1072929819973,
            "rating_q975": 1211.217925163175,
            "rating_q025": 1198.9966608008194
        },
        "gpt-3.5-turbo-1106": {
            "rating": 1202.6175128893667,
            "rating_q975": 1211.4151821622925,
            "rating_q025": 1193.819843616441
        },
        "mixtral-8x7b-instruct-v0.1": {
            "rating": 1199.311520746803,
            "rating_q975": 1203.52879970932,
            "rating_q025": 1195.0942417842857
        },
        "phi-3-medium-4k-instruct": {
            "rating": 1198.4723429778808,
            "rating_q975": 1203.5702999717573,
            "rating_q025": 1193.3743859840042
        },
        "gemma-2-2b-it": {
            "rating": 1197.8028573637976,
            "rating_q975": 1201.8032061190688,
            "rating_q025": 1193.8025086085263
        },
        "dbrx-instruct-preview": {
            "rating": 1197.372732786128,
            "rating_q975": 1203.4614270597663,
            "rating_q025": 1191.2840385124896
        },
        "qwen1.5-14b-chat": {
            "rating": 1192.092675857813,
            "rating_q975": 1199.2035895297504,
            "rating_q025": 1184.9817621858756
        },
        "internlm2_5-20b-chat": {
            "rating": 1191.9978476637893,
            "rating_q975": 1199.1478997104532,
            "rating_q025": 1184.8477956171255
        },
        "yi-34b-chat": {
            "rating": 1185.1800564252662,
            "rating_q975": 1191.9999399737792,
            "rating_q025": 1178.3601728767533
        },
        "granite-3.0-8b-instruct": {
            "rating": 1184.9568195963698,
            "rating_q975": 1193.606811884856,
            "rating_q025": 1176.3068273078836
        },
        "wizardlm-70b": {
            "rating": 1184.4520303302231,
            "rating_q975": 1193.9372745029646,
            "rating_q025": 1174.9667861574817
        },
        "deepseek-llm-67b-chat": {
            "rating": 1183.9705478775647,
            "rating_q975": 1195.5476205884056,
            "rating_q025": 1172.3934751667239
        },
        "openchat-3.5-0106": {
            "rating": 1182.2811179131536,
            "rating_q975": 1190.2753525925255,
            "rating_q025": 1174.2868832337817
        },
        "openchat-3.5": {
            "rating": 1182.213207058686,
            "rating_q975": 1191.9367865740521,
            "rating_q025": 1172.48962754332
        },
        "granite-3.1-2b-instruct": {
            "rating": 1181.2813684068356,
            "rating_q975": 1192.3995110271342,
            "rating_q025": 1170.163225786537
        },
        "snowflake-arctic-instruct": {
            "rating": 1180.3923424170084,
            "rating_q975": 1186.3275581909986,
            "rating_q025": 1174.4571266430182
        },
        "gemma-1.1-7b-it": {
            "rating": 1179.8248189179758,
            "rating_q975": 1185.8644396982938,
            "rating_q025": 1173.7851981376577
        },
        "tulu-2-dpo-70b": {
            "rating": 1179.5684702278968,
            "rating_q975": 1189.4714286112828,
            "rating_q025": 1169.6655118445108
        },
        "openhermes-2.5-mistral-7b": {
            "rating": 1176.364149617275,
            "rating_q975": 1186.8605030509832,
            "rating_q025": 1165.8677961835667
        },
        "vicuna-33b": {
            "rating": 1173.442550666518,
            "rating_q975": 1179.6604460527915,
            "rating_q025": 1167.2246552802444
        },
        "starling-lm-7b-beta": {
            "rating": 1173.1012801683892,
            "rating_q975": 1180.5286826707218,
            "rating_q025": 1165.6738776660566
        },
        "phi-3-small-8k-instruct": {
            "rating": 1172.6104102962588,
            "rating_q975": 1178.4892267912262,
            "rating_q025": 1166.7315938012914
        },
        "llama-2-70b-chat": {
            "rating": 1172.1628839662771,
            "rating_q975": 1177.6603814723014,
            "rating_q025": 1166.6653864602529
        },
        "starling-lm-7b-alpha": {
            "rating": 1168.6977644296019,
            "rating_q975": 1176.8009761845503,
            "rating_q025": 1160.5945526746534
        },
        "llama-3.2-3b-instruct": {
            "rating": 1166.3133794942933,
            "rating_q975": 1173.9643077635305,
            "rating_q025": 1158.662451225056
        },
        "nous-hermes-2-mixtral-8x7b-dpo": {
            "rating": 1165.5189358776556,
            "rating_q975": 1177.4694529040703,
            "rating_q025": 1153.568418851241
        },
        "llama2-70b-steerlm-chat": {
            "rating": 1157.3968471011733,
            "rating_q975": 1170.0889110936612,
            "rating_q025": 1144.7047831086854
        },
        "qwq-32b-preview": {
            "rating": 1156.8405659431023,
            "rating_q975": 1168.3637738263315,
            "rating_q025": 1145.3173580598732
        },
        "granite-3.0-2b-instruct": {
            "rating": 1156.7479616712556,
            "rating_q975": 1165.107306097628,
            "rating_q025": 1148.388617244883
        },
        "solar-10.7b-instruct-v1.0": {
            "rating": 1154.9660347952656,
            "rating_q975": 1168.2438829809878,
            "rating_q025": 1141.6881866095434
        },
        "dolphin-2.2.1-mistral-7b": {
            "rating": 1152.951939676366,
            "rating_q975": 1168.454370619716,
            "rating_q025": 1137.449508733016
        },
        "mpt-30b-chat": {
            "rating": 1151.1365275459202,
            "rating_q975": 1163.5063145634244,
            "rating_q025": 1138.766740528416
        },
        "mistral-7b-instruct-v0.2": {
            "rating": 1150.3995394879173,
            "rating_q975": 1157.069141999903,
            "rating_q025": 1143.7299369759317
        },
        "wizardlm-13b": {
            "rating": 1149.8501593629226,
            "rating_q975": 1159.1840419534838,
            "rating_q025": 1140.5162767723614
        },
        "falcon-180b-chat": {
            "rating": 1149.3362414187798,
            "rating_q975": 1166.671150854967,
            "rating_q025": 1132.0013319825925
        },
        "phi-3-mini-4k-instruct-june-2024": {
            "rating": 1143.4254001791282,
            "rating_q975": 1149.8271734742027,
            "rating_q025": 1137.0236268840538
        },
        "qwen1.5-7b-chat": {
            "rating": 1143.1248064718243,
            "rating_q975": 1153.0360658143622,
            "rating_q025": 1133.2135471292863
        },
        "llama-2-13b-chat": {
            "rating": 1142.6928683581882,
            "rating_q975": 1149.414004372321,
            "rating_q025": 1135.9717323440555
        },
        "vicuna-13b": {
            "rating": 1141.8193077539754,
            "rating_q975": 1148.529017512467,
            "rating_q025": 1135.109597995484
        },
        "qwen-14b-chat": {
            "rating": 1138.9190577241825,
            "rating_q975": 1149.9494562717675,
            "rating_q025": 1127.8886591765975
        },
        "palm-2": {
            "rating": 1136.7823097343598,
            "rating_q975": 1146.2775214117214,
            "rating_q025": 1127.2870980569983
        },
        "codellama-34b-instruct": {
            "rating": 1136.081124483418,
            "rating_q975": 1145.016713590155,
            "rating_q025": 1127.1455353766812
        },
        "gemma-7b-it": {
            "rating": 1135.0222380467512,
            "rating_q975": 1144.5565895900356,
            "rating_q025": 1125.4878865034668
        },
        "zephyr-7b-beta": {
            "rating": 1131.2550980838905,
            "rating_q975": 1140.1558833900135,
            "rating_q025": 1122.3543127777675
        },
        "phi-3-mini-128k-instruct": {
            "rating": 1129.7550297060088,
            "rating_q975": 1137.1845889934812,
            "rating_q025": 1122.3254704185365
        },
        "phi-3-mini-4k-instruct": {
            "rating": 1128.8189203846607,
            "rating_q975": 1135.1551521063366,
            "rating_q025": 1122.4826886629849
        },
        "zephyr-7b-alpha": {
            "rating": 1128.73193510007,
            "rating_q975": 1144.6088975064035,
            "rating_q025": 1112.8549726937363
        },
        "guanaco-33b": {
            "rating": 1128.4046964209692,
            "rating_q975": 1140.5943290247938,
            "rating_q025": 1116.2150638171447
        },
        "stripedhyena-nous-7b": {
            "rating": 1120.8440162132083,
            "rating_q975": 1131.878138600837,
            "rating_q025": 1109.8098938255796
        },
        "codellama-70b-instruct": {
            "rating": 1119.6076968867246,
            "rating_q975": 1138.031790496477,
            "rating_q025": 1101.1836032769722
        },
        "smollm2-1.7b-instruct": {
            "rating": 1119.001986130586,
            "rating_q975": 1133.3071711640325,
            "rating_q025": 1104.6968010971393
        },
        "vicuna-7b": {
            "rating": 1115.7984656995286,
            "rating_q975": 1125.0458817441067,
            "rating_q025": 1106.5510496549505
        },
        "gemma-1.1-2b-it": {
            "rating": 1113.4552815222403,
            "rating_q975": 1121.2253557394583,
            "rating_q025": 1105.6852073050222
        },
        "llama-3.2-1b-instruct": {
            "rating": 1111.689249257492,
            "rating_q975": 1119.519321546028,
            "rating_q025": 1103.859176968956
        },
        "mistral-7b-instruct": {
            "rating": 1110.253272697396,
            "rating_q975": 1119.5984323182656,
            "rating_q025": 1100.9081130765262
        },
        "llama-2-7b-chat": {
            "rating": 1108.1833920684212,
            "rating_q975": 1115.2438406355193,
            "rating_q025": 1101.122943501323
        },
        "gemma-2b-it": {
            "rating": 1091.0682411053517,
            "rating_q975": 1102.748558366036,
            "rating_q025": 1079.3879238446675
        },
        "qwen1.5-4b-chat": {
            "rating": 1089.9581648418807,
            "rating_q975": 1099.3769450767493,
            "rating_q025": 1080.5393846070122
        },
        "olmo-7b-instruct": {
            "rating": 1074.2896092029662,
            "rating_q975": 1085.5568332524358,
            "rating_q025": 1063.0223851534965
        },
        "koala-13b": {
            "rating": 1069.2056381456741,
            "rating_q975": 1079.2521967958176,
            "rating_q025": 1059.1590794955307
        },
        "gpt4all-13b-snoozy": {
            "rating": 1065.8626539190113,
            "rating_q975": 1081.2911647374324,
            "rating_q025": 1050.4341431005903
        },
        "alpaca-13b": {
            "rating": 1063.5107371220681,
            "rating_q975": 1075.04812171033,
            "rating_q025": 1051.9733525338063
        },
        "mpt-7b-chat": {
            "rating": 1060.5460422585295,
            "rating_q975": 1072.6368808484358,
            "rating_q025": 1048.4552036686232
        },
        "chatglm3-6b": {
            "rating": 1055.7565737366322,
            "rating_q975": 1067.4966577443934,
            "rating_q025": 1044.016489728871
        },
        "RWKV-4-Raven-14B": {
            "rating": 1040.0446705698414,
            "rating_q975": 1051.5292148902172,
            "rating_q025": 1028.5601262494656
        },
        "chatglm2-6b": {
            "rating": 1023.2407896215586,
            "rating_q975": 1036.9666863363332,
            "rating_q025": 1009.5148929067841
        },
        "oasst-pythia-12b": {
            "rating": 1021.98211029773,
            "rating_q975": 1032.970679868726,
            "rating_q025": 1010.9935407267338
        },
        "chatglm-6b": {
            "rating": 992.2079408442899,
            "rating_q975": 1005.0245638635439,
            "rating_q025": 979.3913178250358
        },
        "fastchat-t5-3b": {
            "rating": 989.9815135397216,
            "rating_q975": 1002.5703814430468,
            "rating_q025": 977.3926456363964
        },
        "dolly-v2-12b": {
            "rating": 977.796366876635,
            "rating_q975": 991.4738846789695,
            "rating_q025": 964.1188490743006
        },
        "llama-13b": {
            "rating": 972.0304135397685,
            "rating_q975": 987.9734232333516,
            "rating_q025": 956.0874038461853
        },
        "stablelm-tuned-alpha-7b": {
            "rating": 950.4578768066983,
            "rating_q975": 963.3927153560999,
            "rating_q025": 937.5230382572968
        }
    },
    "no_tie": {
        "gemini-3-pro": {
            "rating": 1508.9572975582405,
            "rating_q975": 1517.5887744575873,
            "rating_q025": 1500.3258206588937
        },
        "grok-4.1-thinking": {
            "rating": 1491.0247144554548,
            "rating_q975": 1499.343127805187,
            "rating_q025": 1482.7063011057228
        },
        "claude-opus-4-5-20251101": {
            "rating": 1478.3187262131655,
            "rating_q975": 1487.6963695020997,
            "rating_q025": 1468.9410829242313
        },
        "claude-opus-4-5-20251101-thinking-32k": {
            "rating": 1477.3345376798989,
            "rating_q975": 1486.9087035172238,
            "rating_q025": 1467.760371842574
        },
        "grok-4.1": {
            "rating": 1473.4324061815341,
            "rating_q975": 1481.7927858944195,
            "rating_q025": 1465.0720264686488
        },
        "gpt-5.1-high": {
            "rating": 1461.1161178277212,
            "rating_q975": 1469.7469466089453,
            "rating_q025": 1452.485289046497
        },
        "claude-sonnet-4-5-20250929-thinking-32k": {
            "rating": 1452.4301763715737,
            "rating_q975": 1458.5586667024268,
            "rating_q025": 1446.3016860407206
        },
        "gemini-2.5-pro": {
            "rating": 1451.950957191982,
            "rating_q975": 1456.855216694897,
            "rating_q025": 1447.046697689067
        },
        "claude-opus-4-1-20250805-thinking-16k": {
            "rating": 1451.118147458785,
            "rating_q975": 1456.361942678903,
            "rating_q025": 1445.874352238667
        },
        "gpt-4.5-preview-2025-02-27": {
            "rating": 1449.9583818609472,
            "rating_q975": 1458.4910204232929,
            "rating_q025": 1441.4257432986014
        },
        "claude-sonnet-4-5-20250929": {
            "rating": 1447.1033179002104,
            "rating_q975": 1453.9102555644638,
            "rating_q025": 1440.296380235957
        },
        "chatgpt-4o-latest-20250326": {
            "rating": 1441.1998052548731,
            "rating_q975": 1445.8775179289357,
            "rating_q025": 1436.5220925808105
        },
        "claude-opus-4-1-20250805": {
            "rating": 1439.7061479110262,
            "rating_q975": 1444.7287900173399,
            "rating_q025": 1434.6835058047125
        },
        "gpt-5.1": {
            "rating": 1433.805155355898,
            "rating_q975": 1442.1564463113489,
            "rating_q025": 1425.4538644004472
        },
        "gpt-5-high": {
            "rating": 1431.0550584304915,
            "rating_q975": 1437.2442256439006,
            "rating_q025": 1424.8658912170824
        },
        "qwen3-max-preview": {
            "rating": 1429.6357123839407,
            "rating_q975": 1436.0473565176612,
            "rating_q025": 1423.2240682502202
        },
        "o3-2025-04-16": {
            "rating": 1428.061037128858,
            "rating_q975": 1433.1377938037383,
            "rating_q025": 1422.9842804539778
        },
        "grok-4-1-fast-reasoning": {
            "rating": 1422.2690668126509,
            "rating_q975": 1431.9743364475241,
            "rating_q025": 1412.5637971777776
        },
        "ernie-5.0-preview-1103": {
            "rating": 1421.7571618081047,
            "rating_q975": 1434.1281550491008,
            "rating_q025": 1409.3861685671086
        },
        "gpt-5-chat": {
            "rating": 1417.861360066746,
            "rating_q975": 1423.8485390670091,
            "rating_q025": 1411.874181066483
        },
        "kimi-k2-thinking-turbo": {
            "rating": 1417.27840463998,
            "rating_q975": 1425.2424854508772,
            "rating_q025": 1409.3143238290827
        },
        "deepseek-v3.2-exp": {
            "rating": 1416.225125133358,
            "rating_q975": 1425.3563741521007,
            "rating_q025": 1407.0938761146153
        },
        "glm-4.6": {
            "rating": 1415.8684042254727,
            "rating_q975": 1422.5308549982992,
            "rating_q025": 1409.205953452646
        },
        "qwen3-max-2025-09-23": {
            "rating": 1415.519336329827,
            "rating_q975": 1424.7420734459831,
            "rating_q025": 1406.2965992136708
        },
        "claude-opus-4-20250514-thinking-16k": {
            "rating": 1415.0197939593986,
            "rating_q975": 1420.8037156597898,
            "rating_q025": 1409.2358722590075
        },
        "qwen3-235b-a22b-instruct-2507": {
            "rating": 1413.6982310505737,
            "rating_q975": 1418.8620515833015,
            "rating_q025": 1408.5344105178458
        },
        "grok-4-fast-chat": {
            "rating": 1409.4990846422913,
            "rating_q975": 1419.9983536175457,
            "rating_q025": 1398.999815667037
        },
        "deepseek-v3.2-exp-thinking": {
            "rating": 1409.3388955376424,
            "rating_q975": 1418.5216639324417,
            "rating_q025": 1400.1561271428432
        },
        "kimi-k2-0905-preview": {
            "rating": 1407.7775964186014,
            "rating_q975": 1416.4693075986659,
            "rating_q025": 1399.085885238537
        },
        "deepseek-v3.2-thinking": {
            "rating": 1407.2471843566668,
            "rating_q975": 1418.750767322366,
            "rating_q025": 1395.7436013909676
        },
        "deepseek-r1-0528": {
            "rating": 1407.151871508734,
            "rating_q975": 1414.9860630211979,
            "rating_q025": 1399.3176799962703
        },
        "kimi-k2-0711-preview": {
            "rating": 1406.1511312458388,
            "rating_q975": 1412.5854638357496,
            "rating_q025": 1399.716798655928
        },
        "deepseek-v3.1": {
            "rating": 1403.0471298257685,
            "rating_q975": 1411.3983456252429,
            "rating_q025": 1394.695914026294
        },
        "deepseek-v3.1-thinking": {
            "rating": 1402.585074836709,
            "rating_q975": 1411.639053493049,
            "rating_q025": 1393.531096180369
        },
        "deepseek-v3.2": {
            "rating": 1402.1182633612882,
            "rating_q975": 1413.329609368776,
            "rating_q025": 1390.9069173538005
        },
        "qwen3-vl-235b-a22b-instruct": {
            "rating": 1401.7447012888215,
            "rating_q975": 1411.3143396567639,
            "rating_q025": 1392.175062920879
        },
        "gpt-4.1-2025-04-14": {
            "rating": 1400.5389917811417,
            "rating_q975": 1405.672418238449,
            "rating_q025": 1395.4055653238345
        },
        "claude-opus-4-20250514": {
            "rating": 1400.5307730125173,
            "rating_q975": 1406.2463183350767,
            "rating_q025": 1394.815227689958
        },
        "mistral-large-3": {
            "rating": 1400.405098242171,
            "rating_q975": 1411.696197978764,
            "rating_q025": 1389.1139985055781
        },
        "deepseek-v3.1-terminus": {
            "rating": 1400.3987410165823,
            "rating_q975": 1414.2610859594897,
            "rating_q025": 1386.536396073675
        },
        "grok-3-preview-02-24": {
            "rating": 1398.028542126104,
            "rating_q975": 1404.123118438483,
            "rating_q025": 1391.9339658137249
        },
        "deepseek-v3.1-terminus-thinking": {
            "rating": 1397.697218628016,
            "rating_q975": 1411.943346495228,
            "rating_q025": 1383.4510907608037
        },
        "mistral-medium-2508": {
            "rating": 1396.5300962409656,
            "rating_q975": 1402.018392907163,
            "rating_q025": 1391.0417995747682
        },
        "grok-4-0709": {
            "rating": 1393.7565974257311,
            "rating_q975": 1399.1713213418611,
            "rating_q025": 1388.341873509601
        },
        "glm-4.5": {
            "rating": 1393.1759681878164,
            "rating_q975": 1400.0346405703433,
            "rating_q025": 1386.3172958052894
        },
        "gemini-2.5-flash": {
            "rating": 1391.494395156792,
            "rating_q975": 1396.2153979477237,
            "rating_q025": 1386.7733923658604
        },
        "claude-haiku-4-5-20251001": {
            "rating": 1387.405588361549,
            "rating_q975": 1393.8255974876045,
            "rating_q025": 1380.9855792354936
        },
        "gemini-2.5-flash-preview-09-2025": {
            "rating": 1386.5946731623055,
            "rating_q975": 1392.743918821739,
            "rating_q025": 1380.445427502872
        },
        "grok-4-fast-reasoning": {
            "rating": 1384.9466736803959,
            "rating_q975": 1392.10012822485,
            "rating_q025": 1377.7932191359416
        },
        "o1-2024-12-17": {
            "rating": 1384.8320044272768,
            "rating_q975": 1391.199651519152,
            "rating_q025": 1378.4643573354017
        },
        "claude-sonnet-4-20250514-thinking-32k": {
            "rating": 1383.3294863973729,
            "rating_q975": 1389.144788409688,
            "rating_q025": 1377.5141843850577
        },
        "qwen3-next-80b-a3b-instruct": {
            "rating": 1381.907729918302,
            "rating_q975": 1388.6430371458134,
            "rating_q025": 1375.1724226907907
        },
        "qwen3-235b-a22b-no-thinking": {
            "rating": 1381.3035405200353,
            "rating_q975": 1387.4053606682692,
            "rating_q025": 1375.2017203718015
        },
        "deepseek-r1": {
            "rating": 1380.311740002615,
            "rating_q975": 1387.5425242974884,
            "rating_q025": 1373.0809557077414
        },
        "longcat-flash-chat": {
            "rating": 1379.8667474842543,
            "rating_q975": 1388.7127291891923,
            "rating_q025": 1371.0207657793164
        },
        "qwen3-235b-a22b-thinking-2507": {
            "rating": 1376.8025461334082,
            "rating_q975": 1386.1018114392216,
            "rating_q025": 1367.5032808275948
        },
        "deepseek-v3-0324": {
            "rating": 1372.0004102178034,
            "rating_q975": 1377.4455900781875,
            "rating_q025": 1366.5552303574193
        },
        "qwen3-vl-235b-a22b-thinking": {
            "rating": 1370.2856598375258,
            "rating_q975": 1380.0219173224884,
            "rating_q025": 1360.5494023525632
        },
        "claude-sonnet-4-20250514": {
            "rating": 1369.6069378057798,
            "rating_q975": 1375.392550972032,
            "rating_q025": 1363.8213246395276
        },
        "o4-mini-2025-04-16": {
            "rating": 1369.4321468544642,
            "rating_q975": 1374.9229391618867,
            "rating_q025": 1363.9413545470418
        },
        "gpt-5-mini-high": {
            "rating": 1369.4101437247432,
            "rating_q975": 1375.8004101645097,
            "rating_q025": 1363.0198772849767
        },
        "mai-1-preview": {
            "rating": 1369.164412521242,
            "rating_q975": 1376.7739777271777,
            "rating_q025": 1361.5548473153062
        },
        "claude-3-7-sonnet-20250219-thinking-32k": {
            "rating": 1368.4788981392794,
            "rating_q975": 1374.0325236354308,
            "rating_q025": 1362.925272643128
        },
        "hunyuan-vision-1.5-thinking": {
            "rating": 1367.1481701124478,
            "rating_q975": 1384.7711407919787,
            "rating_q025": 1349.525199432917
        },
        "o1-preview": {
            "rating": 1364.890578593852,
            "rating_q975": 1372.150813419324,
            "rating_q025": 1357.63034376838
        },
        "qwen3-coder-480b-a35b-instruct": {
            "rating": 1361.9501599130222,
            "rating_q975": 1368.7768402728796,
            "rating_q025": 1355.1234795531648
        },
        "mistral-medium-2505": {
            "rating": 1360.5155673891818,
            "rating_q975": 1366.9733996911114,
            "rating_q025": 1354.0577350872522
        },
        "hunyuan-t1-20250711": {
            "rating": 1357.928619906259,
            "rating_q975": 1370.2802579041543,
            "rating_q025": 1345.5769819083637
        },
        "qwen3-30b-a3b-instruct-2507": {
            "rating": 1357.5486761030584,
            "rating_q975": 1364.3641232660152,
            "rating_q025": 1350.7332289401015
        },
        "gpt-4.1-mini-2025-04-14": {
            "rating": 1357.106024201266,
            "rating_q975": 1362.993258824532,
            "rating_q025": 1351.2187895780003
        },
        "hunyuan-turbos-20250416": {
            "rating": 1356.139256356731,
            "rating_q975": 1365.0642648549947,
            "rating_q025": 1347.2142478584674
        },
        "gemini-2.5-flash-lite-preview-09-2025-no-thinking": {
            "rating": 1350.6750326843319,
            "rating_q975": 1356.848446137795,
            "rating_q025": 1344.5016192308688
        },
        "claude-3-7-sonnet-20250219": {
            "rating": 1347.6069980873808,
            "rating_q975": 1352.8812812686845,
            "rating_q025": 1342.3327149060772
        },
        "qwen2.5-max": {
            "rating": 1346.7918342411508,
            "rating_q975": 1352.703664088113,
            "rating_q025": 1340.8800043941885
        },
        "claude-3-5-sonnet-20241022": {
            "rating": 1345.2133649007337,
            "rating_q975": 1349.4125152802612,
            "rating_q025": 1341.0142145212062
        },
        "gemini-2.5-flash-lite-preview-06-17-thinking": {
            "rating": 1345.1041778504514,
            "rating_q975": 1351.3490482867294,
            "rating_q025": 1338.8593074141734
        },
        "qwen3-235b-a22b": {
            "rating": 1344.340082354092,
            "rating_q975": 1350.897084424417,
            "rating_q025": 1337.7830802837668
        },
        "glm-4.5-air": {
            "rating": 1339.4204959508952,
            "rating_q975": 1345.4658830959802,
            "rating_q025": 1333.3751088058102
        },
        "qwen3-next-80b-a3b-thinking": {
            "rating": 1334.3637953072653,
            "rating_q975": 1342.4537872871797,
            "rating_q025": 1326.2738033273508
        },
        "minimax-m1": {
            "rating": 1333.4982853720996,
            "rating_q975": 1339.4136384784363,
            "rating_q025": 1327.582932265763
        },
        "gemma-3-27b-it": {
            "rating": 1329.5863411948014,
            "rating_q975": 1334.7615985004184,
            "rating_q025": 1324.4110838891845
        },
        "o3-mini-high": {
            "rating": 1328.373540250217,
            "rating_q975": 1336.0629444427132,
            "rating_q025": 1320.684136057721
        },
        "deepseek-v3": {
            "rating": 1326.3800318963815,
            "rating_q975": 1333.680223918481,
            "rating_q025": 1319.079839874282
        },
        "grok-3-mini-high": {
            "rating": 1326.2476008206024,
            "rating_q975": 1333.5327746507744,
            "rating_q025": 1318.9624269904305
        },
        "gemini-2.0-flash-001": {
            "rating": 1325.2293606859166,
            "rating_q975": 1330.5582136880803,
            "rating_q025": 1319.900507683753
        },
        "grok-3-mini-beta": {
            "rating": 1318.869894218896,
            "rating_q975": 1325.7826112539585,
            "rating_q025": 1311.9571771838334
        },
        "mistral-small-2506": {
            "rating": 1316.4789471374,
            "rating_q975": 1323.8138923375336,
            "rating_q025": 1309.1440019372662
        },
        "gpt-oss-120b": {
            "rating": 1312.786336453028,
            "rating_q975": 1318.9949960500253,
            "rating_q025": 1306.5776768560308
        },
        "gemini-1.5-pro-002": {
            "rating": 1312.6997406737903,
            "rating_q975": 1317.8266425281047,
            "rating_q025": 1307.572838819476
        },
        "gemini-2.0-flash-lite-preview-02-05": {
            "rating": 1312.464480223828,
            "rating_q975": 1319.066639049636,
            "rating_q025": 1305.8623213980202
        },
        "command-a-03-2025": {
            "rating": 1312.1433653220377,
            "rating_q975": 1317.1337927113761,
            "rating_q025": 1307.1529379326992
        },
        "glm-4.5v": {
            "rating": 1311.925200564462,
            "rating_q975": 1324.2262478406535,
            "rating_q025": 1299.6241532882707
        },
        "amazon-nova-experimental-chat-10-20": {
            "rating": 1309.4385669859157,
            "rating_q975": 1319.586068861398,
            "rating_q025": 1299.2910651104335
        },
        "o3-mini": {
            "rating": 1307.3175922398395,
            "rating_q975": 1312.1622196666608,
            "rating_q025": 1302.4729648130183
        },
        "qwen-plus-0125": {
            "rating": 1305.9902004098788,
            "rating_q975": 1318.8497433289258,
            "rating_q025": 1293.1306574908317
        },
        "step-3": {
            "rating": 1304.8913796039174,
            "rating_q975": 1315.4932389456258,
            "rating_q025": 1294.289520262209
        },
        "hunyuan-turbos-20250226": {
            "rating": 1304.2388182972927,
            "rating_q975": 1323.3810933956297,
            "rating_q025": 1285.0965431989557
        },
        "gpt-4o-2024-05-13": {
            "rating": 1303.5536696824693,
            "rating_q975": 1308.9219115703872,
            "rating_q025": 1298.1854277945513
        },
        "qwen3-32b": {
            "rating": 1303.1200968514217,
            "rating_q975": 1317.790765271824,
            "rating_q025": 1288.4494284310194
        },
        "minimax-m2": {
            "rating": 1303.0389049993498,
            "rating_q975": 1313.7569148114512,
            "rating_q025": 1292.3208951872484
        },
        "intellect-3": {
            "rating": 1302.0435579554255,
            "rating_q975": 1320.4139541705204,
            "rating_q025": 1283.6731617403307
        },
        "llama-3.1-nemotron-ultra-253b-v1": {
            "rating": 1301.6117843926904,
            "rating_q975": 1319.2667357231876,
            "rating_q025": 1283.9568330621933
        },
        "ling-flash-2.0": {
            "rating": 1301.0065633096337,
            "rating_q975": 1311.3129521721683,
            "rating_q025": 1290.7001744470992
        },
        "glm-4-plus-0111": {
            "rating": 1299.8108978958585,
            "rating_q975": 1312.4986786500729,
            "rating_q025": 1287.1231171416441
        },
        "claude-3-5-sonnet-20240620": {
            "rating": 1296.5434602347018,
            "rating_q975": 1301.6633807510846,
            "rating_q025": 1291.423539718319
        },
        "amazon-nova-experimental-chat-10-09": {
            "rating": 1296.2196541703802,
            "rating_q975": 1305.5605150640308,
            "rating_q025": 1286.8787932767295
        },
        "nvidia-llama-3.3-nemotron-super-49b-v1.5": {
            "rating": 1295.8706148954593,
            "rating_q975": 1310.354408975249,
            "rating_q025": 1281.3868208156696
        },
        "gpt-5-nano-high": {
            "rating": 1294.9170087576385,
            "rating_q975": 1304.5766804151262,
            "rating_q025": 1285.2573371001508
        },
        "gemma-3-12b-it": {
            "rating": 1293.4753181172134,
            "rating_q975": 1307.9190972206222,
            "rating_q025": 1279.0315390138046
        },
        "nova-2-lite": {
            "rating": 1289.522584535242,
            "rating_q975": 1301.387419065319,
            "rating_q025": 1277.657750005165
        },
        "o1-mini": {
            "rating": 1288.5417247319083,
            "rating_q975": 1293.9692672983479,
            "rating_q025": 1283.1141821654687
        },
        "step-2-16k-exp-202412": {
            "rating": 1287.404585585277,
            "rating_q975": 1301.3606114239778,
            "rating_q025": 1273.448559746576
        },
        "llama-3.1-405b-instruct-bf16": {
            "rating": 1286.9964358019333,
            "rating_q975": 1292.4947610675686,
            "rating_q025": 1281.498110536298
        },
        "grok-2-2024-08-13": {
            "rating": 1285.8186978808235,
            "rating_q975": 1291.2684183906686,
            "rating_q025": 1280.3689773709784
        },
        "qwq-32b": {
            "rating": 1285.5412171911587,
            "rating_q975": 1292.035060550849,
            "rating_q025": 1279.0473738314683
        },
        "gpt-4o-2024-08-06": {
            "rating": 1285.5302841097337,
            "rating_q975": 1291.9072798107654,
            "rating_q025": 1279.1532884087019
        },
        "hunyuan-turbo-0110": {
            "rating": 1285.276446664718,
            "rating_q975": 1304.6924224876188,
            "rating_q025": 1265.860470841817
        },
        "gemini-advanced-0514": {
            "rating": 1283.3964146870699,
            "rating_q975": 1290.7611519931954,
            "rating_q025": 1276.0316773809443
        },
        "llama-3.1-405b-instruct-fp8": {
            "rating": 1282.3684742123191,
            "rating_q975": 1288.0168716275957,
            "rating_q025": 1276.7200767970426
        },
        "llama-4-maverick-17b-128e-instruct": {
            "rating": 1279.918880202205,
            "rating_q975": 1285.9196389938288,
            "rating_q025": 1273.918121410581
        },
        "yi-lightning": {
            "rating": 1279.8990423000025,
            "rating_q975": 1287.4778599600686,
            "rating_q025": 1272.3202246399364
        },
        "llama-3.3-nemotron-49b-super-v1": {
            "rating": 1275.783870274186,
            "rating_q975": 1294.9518476522908,
            "rating_q025": 1256.6158928960813
        },
        "qwen3-30b-a3b": {
            "rating": 1274.074093527609,
            "rating_q975": 1280.7475253930593,
            "rating_q025": 1267.4006616621587
        },
        "llama-4-scout-17b-16e-instruct": {
            "rating": 1269.8462338246545,
            "rating_q975": 1276.493025388128,
            "rating_q025": 1263.199442261181
        },
        "claude-3-5-haiku-20241022": {
            "rating": 1269.4191259292415,
            "rating_q975": 1274.0747682427914,
            "rating_q025": 1264.7634836156917
        },
        "deepseek-v2.5-1210": {
            "rating": 1268.5724007959602,
            "rating_q975": 1281.7368394587586,
            "rating_q025": 1255.4079621331618
        },
        "hunyuan-large-2025-02-10": {
            "rating": 1268.4151780796465,
            "rating_q975": 1283.663913864013,
            "rating_q025": 1253.16644229528
        },
        "gpt-4-turbo-2024-04-09": {
            "rating": 1266.6082805673539,
            "rating_q975": 1272.4222425421406,
            "rating_q025": 1260.7943185925672
        },
        "ring-flash-2.0": {
            "rating": 1266.5282931861962,
            "rating_q975": 1276.8302767084658,
            "rating_q025": 1256.2263096639265
        },
        "gemini-1.5-pro-001": {
            "rating": 1265.271438836573,
            "rating_q975": 1271.4362156498971,
            "rating_q025": 1259.1066620232489
        },
        "gpt-4.1-nano-2025-04-14": {
            "rating": 1265.22090278811,
            "rating_q975": 1277.5090126355028,
            "rating_q025": 1252.932792940717
        },
        "step-1o-turbo-202506": {
            "rating": 1264.1787132329323,
            "rating_q975": 1273.5488526415243,
            "rating_q025": 1254.8085738243403
        },
        "llama-3.3-70b-instruct": {
            "rating": 1263.8410985250218,
            "rating_q975": 1268.7551349983937,
            "rating_q025": 1258.92706205165
        },
        "gpt-oss-20b": {
            "rating": 1263.2543173322078,
            "rating_q975": 1272.2858441126657,
            "rating_q025": 1254.22279055175
        },
        "claude-3-opus-20240229": {
            "rating": 1262.808051223498,
            "rating_q975": 1267.44551284606,
            "rating_q025": 1258.1705896009362
        },
        "glm-4-plus": {
            "rating": 1262.5789280758122,
            "rating_q975": 1270.2127494042531,
            "rating_q025": 1254.9451067473713
        },
        "gemma-3n-e4b-it": {
            "rating": 1262.1786296741957,
            "rating_q975": 1269.285210035873,
            "rating_q025": 1255.0720493125184
        },
        "gpt-4o-mini-2024-07-18": {
            "rating": 1259.1179624751771,
            "rating_q975": 1264.2566447462266,
            "rating_q025": 1253.9792802041277
        },
        "qwen2.5-plus-1127": {
            "rating": 1257.3521364241205,
            "rating_q975": 1267.4745376572403,
            "rating_q025": 1247.2297351910008
        },
        "qwen-max-0919": {
            "rating": 1256.5766986404547,
            "rating_q975": 1265.1490841341688,
            "rating_q025": 1248.0043131467405
        },
        "athene-v2-chat": {
            "rating": 1254.9126548687727,
            "rating_q975": 1261.9221841542312,
            "rating_q025": 1247.9031255833142
        },
        "mistral-large-2407": {
            "rating": 1253.4892791456941,
            "rating_q975": 1259.534881455453,
            "rating_q025": 1247.4436768359353
        },
        "hunyuan-standard-2025-02-10": {
            "rating": 1251.773849144763,
            "rating_q975": 1267.1054609941316,
            "rating_q025": 1236.4422372953945
        },
        "mercury": {
            "rating": 1251.0732568881283,
            "rating_q975": 1272.1938253327921,
            "rating_q025": 1229.9526884434645
        },
        "magistral-medium-2506": {
            "rating": 1250.5382152856691,
            "rating_q975": 1259.555612444935,
            "rating_q025": 1241.5208181264034
        },
        "olmo-3-32b-think": {
            "rating": 1247.6631953368642,
            "rating_q975": 1263.400845897858,
            "rating_q025": 1231.9255447758703
        },
        "gemini-1.5-flash-002": {
            "rating": 1247.3876679863306,
            "rating_q975": 1253.8187166341036,
            "rating_q025": 1240.9566193385576
        },
        "gpt-4-1106-preview": {
            "rating": 1246.0611747085777,
            "rating_q975": 1251.9479022826736,
            "rating_q025": 1240.1744471344819
        },
        "grok-2-mini-2024-08-13": {
            "rating": 1245.6805245538014,
            "rating_q975": 1251.3709594033305,
            "rating_q025": 1239.9900897042723
        },
        "gpt-4-0125-preview": {
            "rating": 1245.3086166560634,
            "rating_q975": 1251.422628987889,
            "rating_q025": 1239.1946043242376
        },
        "athene-70b-0725": {
            "rating": 1242.3760440949486,
            "rating_q975": 1251.135885453258,
            "rating_q025": 1233.6162027366393
        },
        "deepseek-v2.5": {
            "rating": 1241.9437595683166,
            "rating_q975": 1249.4140237295717,
            "rating_q025": 1234.4734954070616
        },
        "mistral-small-3.1-24b-instruct-2503": {
            "rating": 1239.462069567283,
            "rating_q975": 1245.8958215990801,
            "rating_q025": 1233.0283175354857
        },
        "qwen2.5-72b-instruct": {
            "rating": 1236.0290377903252,
            "rating_q975": 1242.348131947341,
            "rating_q025": 1229.7099436333094
        },
        "mistral-large-2411": {
            "rating": 1235.8556612907496,
            "rating_q975": 1242.6156282828633,
            "rating_q025": 1229.0956942986359
        },
        "hunyuan-large-vision": {
            "rating": 1234.196742564825,
            "rating_q975": 1246.8142055396888,
            "rating_q025": 1221.579279589961
        },
        "gemma-3-4b-it": {
            "rating": 1233.2209903892424,
            "rating_q975": 1247.277028087494,
            "rating_q025": 1219.1649526909907
        },
        "llama-3.1-nemotron-70b-instruct": {
            "rating": 1229.9159661858585,
            "rating_q975": 1241.4112288329072,
            "rating_q025": 1218.4207035388097
        },
        "llama-3.1-70b-instruct": {
            "rating": 1221.64182344253,
            "rating_q975": 1227.4331377421634,
            "rating_q025": 1215.8505091428967
        },
        "jamba-1.5-large": {
            "rating": 1212.4579160448422,
            "rating_q975": 1223.7705812347685,
            "rating_q025": 1201.145250854916
        },
        "amazon-nova-pro-v1.0": {
            "rating": 1212.3431960093785,
            "rating_q975": 1219.4181893456566,
            "rating_q025": 1205.2682026731004
        },
        "llama-3.1-tulu-3-70b": {
            "rating": 1211.7625447356425,
            "rating_q975": 1229.3787204080963,
            "rating_q025": 1194.1463690631886
        },
        "reka-core-20240904": {
            "rating": 1211.2545175089222,
            "rating_q975": 1223.0053106629891,
            "rating_q025": 1199.5037243548552
        },
        "gemma-2-27b-it": {
            "rating": 1209.0795967165445,
            "rating_q975": 1214.1555726770289,
            "rating_q025": 1204.0036207560602
        },
        "gemini-1.5-flash-001": {
            "rating": 1206.443014034839,
            "rating_q975": 1213.1505138169534,
            "rating_q025": 1199.7355142527247
        },
        "llama-3.1-nemotron-51b-instruct": {
            "rating": 1205.070125408314,
            "rating_q975": 1221.1458508957564,
            "rating_q025": 1188.9943999208715
        },
        "gpt-4-0314": {
            "rating": 1201.5754035788168,
            "rating_q975": 1208.6461395502456,
            "rating_q025": 1194.504667607388
        },
        "claude-3-sonnet-20240229": {
            "rating": 1200.5846658949388,
            "rating_q975": 1206.4017987292812,
            "rating_q025": 1194.7675330605964
        },
        "nemotron-4-340b-instruct": {
            "rating": 1197.2725828728446,
            "rating_q975": 1205.6293051583261,
            "rating_q025": 1188.915860587363
        },
        "gemma-2-9b-it-simpo": {
            "rating": 1194.8000501048248,
            "rating_q975": 1205.5228438703361,
            "rating_q025": 1184.0772563393134
        },
        "llama-3-70b-instruct": {
            "rating": 1193.2760886694412,
            "rating_q975": 1198.762196999073,
            "rating_q025": 1187.7899803398093
        },
        "glm-4-0520": {
            "rating": 1191.4066448494123,
            "rating_q975": 1202.3418729046502,
            "rating_q025": 1180.4714167941743
        },
        "command-r-plus-08-2024": {
            "rating": 1191.1780673651483,
            "rating_q975": 1201.5406917740754,
            "rating_q025": 1180.8154429562212
        },
        "gpt-4-0613": {
            "rating": 1187.363770791195,
            "rating_q975": 1193.3182483850867,
            "rating_q025": 1181.4092931973034
        },
        "mistral-small-24b-instruct-2501": {
            "rating": 1187.006281295167,
            "rating_q975": 1196.3126908639672,
            "rating_q025": 1177.6998717263666
        },
        "qwen2.5-coder-32b-instruct": {
            "rating": 1182.5973240169897,
            "rating_q975": 1196.1019173768339,
            "rating_q025": 1169.0927306571455
        },
        "reka-flash-20240904": {
            "rating": 1179.2327767630545,
            "rating_q975": 1191.3026927874585,
            "rating_q025": 1167.1628607386506
        },
        "deepseek-coder-v2": {
            "rating": 1175.7445620627864,
            "rating_q975": 1185.0869927478736,
            "rating_q025": 1166.402131377699
        },
        "c4ai-aya-expanse-32b": {
            "rating": 1175.6183892163394,
            "rating_q975": 1183.4050243240692,
            "rating_q025": 1167.8317541086096
        },
        "command-r-plus": {
            "rating": 1172.9101072814074,
            "rating_q975": 1179.2270802314044,
            "rating_q025": 1166.5931343314103
        },
        "qwen2-72b-instruct": {
            "rating": 1171.7941461398163,
            "rating_q975": 1179.141569265288,
            "rating_q025": 1164.4467230143448
        },
        "claude-3-haiku-20240307": {
            "rating": 1171.7458502456739,
            "rating_q975": 1177.5264736156764,
            "rating_q025": 1165.9652268756713
        },
        "gemma-2-9b-it": {
            "rating": 1171.2782946234036,
            "rating_q975": 1177.0814502394273,
            "rating_q025": 1165.4751390073798
        },
        "gemini-1.5-flash-8b-001": {
            "rating": 1164.9275820919424,
            "rating_q975": 1171.6462842915637,
            "rating_q025": 1158.2088798923212
        },
        "amazon-nova-lite-v1.0": {
            "rating": 1164.4331265568524,
            "rating_q975": 1172.6156654066444,
            "rating_q025": 1156.2505877070603
        },
        "phi-4": {
            "rating": 1155.5466978639572,
            "rating_q975": 1163.2554958795872,
            "rating_q025": 1147.8378998483272
        },
        "olmo-2-0325-32b-instruct": {
            "rating": 1154.9731066834188,
            "rating_q975": 1172.214588895611,
            "rating_q025": 1137.7316244712265
        },
        "command-r-08-2024": {
            "rating": 1145.6436504685744,
            "rating_q975": 1156.3526135687835,
            "rating_q025": 1134.9346873683653
        },
        "mistral-large-2402": {
            "rating": 1141.7869535418022,
            "rating_q975": 1148.69108679424,
            "rating_q025": 1134.8828202893644
        },
        "reka-flash-21b-20240226-online": {
            "rating": 1130.9092253518565,
            "rating_q975": 1141.9979127833114,
            "rating_q025": 1119.8205379204016
        },
        "amazon-nova-micro-v1.0": {
            "rating": 1130.70266096545,
            "rating_q975": 1139.0478453118524,
            "rating_q025": 1122.3574766190475
        },
        "qwen1.5-110b-chat": {
            "rating": 1129.9017820191273,
            "rating_q975": 1138.5350535079776,
            "rating_q025": 1121.268510530277
        },
        "jamba-1.5-mini": {
            "rating": 1129.8071629124206,
            "rating_q975": 1141.661298867514,
            "rating_q025": 1117.9530269573272
        },
        "qwen1.5-72b-chat": {
            "rating": 1128.8725271186886,
            "rating_q975": 1136.8505993955398,
            "rating_q025": 1120.8944548418374
        },
        "gemini-pro-dev-api": {
            "rating": 1127.6717629091834,
            "rating_q975": 1138.4658714683474,
            "rating_q025": 1116.8776543500194
        },
        "ministral-8b-2410": {
            "rating": 1125.042368010079,
            "rating_q975": 1140.1430759019945,
            "rating_q025": 1109.9416601181633
        },
        "hunyuan-standard-256k": {
            "rating": 1123.657156067953,
            "rating_q975": 1142.372769327547,
            "rating_q025": 1104.9415428083591
        },
        "mixtral-8x22b-instruct-v0.1": {
            "rating": 1121.8730547594564,
            "rating_q975": 1128.8808707957853,
            "rating_q025": 1114.8652387231275
        },
        "reka-flash-21b-20240226": {
            "rating": 1120.3812554746396,
            "rating_q975": 1129.6863497390084,
            "rating_q025": 1111.0761612102708
        },
        "command-r": {
            "rating": 1118.2366618993892,
            "rating_q975": 1125.3958020243215,
            "rating_q025": 1111.077521774457
        },
        "mistral-medium": {
            "rating": 1113.5244677353555,
            "rating_q975": 1121.5994307553565,
            "rating_q025": 1105.4495047153546
        },
        "gpt-3.5-turbo-0125": {
            "rating": 1112.0207279662445,
            "rating_q975": 1118.893271364061,
            "rating_q025": 1105.148184568428
        },
        "llama-3-8b-instruct": {
            "rating": 1110.751577429075,
            "rating_q975": 1116.7063765186124,
            "rating_q025": 1104.7967783395377
        },
        "c4ai-aya-expanse-8b": {
            "rating": 1105.7277071431454,
            "rating_q975": 1117.3988136281607,
            "rating_q025": 1094.05660065813
        },
        "gemini-pro": {
            "rating": 1103.700582115804,
            "rating_q975": 1120.51205691879,
            "rating_q025": 1086.8891073128182
        },
        "llama-3.1-tulu-3-8b": {
            "rating": 1101.5588812931946,
            "rating_q975": 1120.8885291624533,
            "rating_q025": 1082.229233423936
        },
        "zephyr-orpo-141b-A35b-v0.1": {
            "rating": 1100.0713278675994,
            "rating_q975": 1115.8823075706414,
            "rating_q025": 1084.2603481645574
        },
        "yi-1.5-34b-chat": {
            "rating": 1098.1644275921697,
            "rating_q975": 1106.4210654328624,
            "rating_q025": 1089.907789751477
        },
        "llama-3.1-8b-instruct": {
            "rating": 1088.5013073463958,
            "rating_q975": 1095.074239929141,
            "rating_q025": 1081.9283747636507
        },
        "qwen1.5-32b-chat": {
            "rating": 1086.2500247955945,
            "rating_q975": 1095.7128713035293,
            "rating_q025": 1076.7871782876598
        },
        "gpt-3.5-turbo-1106": {
            "rating": 1079.8424907957062,
            "rating_q975": 1092.2018332905038,
            "rating_q025": 1067.4831483009086
        },
        "granite-3.1-8b-instruct": {
            "rating": 1076.7541404550423,
            "rating_q975": 1096.6243872131954,
            "rating_q025": 1056.8838936968891
        },
        "mixtral-8x7b-instruct-v0.1": {
            "rating": 1072.0797086240423,
            "rating_q975": 1078.5949801142376,
            "rating_q025": 1065.564437133847
        },
        "dbrx-instruct-preview": {
            "rating": 1069.4097243497458,
            "rating_q975": 1078.746659656446,
            "rating_q025": 1060.0727890430458
        },
        "qwen1.5-14b-chat": {
            "rating": 1068.4703392243198,
            "rating_q975": 1079.442258003855,
            "rating_q025": 1057.4984204447846
        },
        "phi-3-medium-4k-instruct": {
            "rating": 1065.5736054731105,
            "rating_q975": 1074.1448810269558,
            "rating_q025": 1057.0023299192653
        },
        "gemma-2-2b-it": {
            "rating": 1061.996520407838,
            "rating_q975": 1068.6666026687453,
            "rating_q025": 1055.3264381469307
        },
        "wizardlm-70b": {
            "rating": 1059.4617340905215,
            "rating_q975": 1072.7533660622753,
            "rating_q025": 1046.1701021187678
        },
        "internlm2_5-20b-chat": {
            "rating": 1055.740412478152,
            "rating_q975": 1068.0236835637895,
            "rating_q025": 1043.4571413925144
        },
        "deepseek-llm-67b-chat": {
            "rating": 1055.1560114181539,
            "rating_q975": 1071.9771460735453,
            "rating_q025": 1038.3348767627624
        },
        "yi-34b-chat": {
            "rating": 1053.1611861332053,
            "rating_q975": 1063.2525675688532,
            "rating_q025": 1043.0698046975574
        },
        "openchat-3.5-0106": {
            "rating": 1052.6233244055738,
            "rating_q975": 1064.3669236854223,
            "rating_q025": 1040.8797251257254
        },
        "openchat-3.5": {
            "rating": 1049.6341107863686,
            "rating_q975": 1063.7300234952538,
            "rating_q025": 1035.5381980774835
        },
        "tulu-2-dpo-70b": {
            "rating": 1045.5113793673195,
            "rating_q975": 1059.6423078456264,
            "rating_q025": 1031.3804508890125
        },
        "starling-lm-7b-beta": {
            "rating": 1042.2193479603434,
            "rating_q975": 1053.1946313076248,
            "rating_q025": 1031.244064613062
        },
        "openhermes-2.5-mistral-7b": {
            "rating": 1041.5171353671296,
            "rating_q975": 1056.8511500949276,
            "rating_q025": 1026.1831206393317
        },
        "vicuna-33b": {
            "rating": 1040.7451612985674,
            "rating_q975": 1050.0490810844915,
            "rating_q025": 1031.4412415126433
        },
        "snowflake-arctic-instruct": {
            "rating": 1040.5926785399577,
            "rating_q975": 1050.201578074451,
            "rating_q025": 1030.9837790054644
        },
        "gemma-1.1-7b-it": {
            "rating": 1038.8121495435544,
            "rating_q975": 1047.9157679986045,
            "rating_q025": 1029.7085310885043
        },
        "granite-3.0-8b-instruct": {
            "rating": 1033.8149331878308,
            "rating_q975": 1049.975355663715,
            "rating_q025": 1017.6545107119466
        },
        "llama-2-70b-chat": {
            "rating": 1033.5350036191348,
            "rating_q975": 1041.6898837212545,
            "rating_q025": 1025.3801235170151
        },
        "starling-lm-7b-alpha": {
            "rating": 1029.7120035832586,
            "rating_q975": 1041.6216303164772,
            "rating_q025": 1017.8023768500401
        },
        "nous-hermes-2-mixtral-8x7b-dpo": {
            "rating": 1026.314821079875,
            "rating_q975": 1043.5337433917186,
            "rating_q025": 1009.0958987680314
        },
        "phi-3-small-8k-instruct": {
            "rating": 1022.9096059113231,
            "rating_q975": 1033.360663955902,
            "rating_q025": 1012.458547866744
        },
        "granite-3.1-2b-instruct": {
            "rating": 1020.6422529885051,
            "rating_q975": 1041.9196069341222,
            "rating_q025": 999.3648990428879
        },
        "qwq-32b-preview": {
            "rating": 1016.1419845494942,
            "rating_q975": 1034.7153063682952,
            "rating_q025": 997.5686627306931
        },
        "mpt-30b-chat": {
            "rating": 1013.3554758275743,
            "rating_q975": 1031.5204708731312,
            "rating_q025": 995.1904807820174
        },
        "llama2-70b-steerlm-chat": {
            "rating": 1011.9845799890354,
            "rating_q975": 1029.7016737830704,
            "rating_q025": 994.2674861950003
        },
        "llama-3.2-3b-instruct": {
            "rating": 1008.928105461342,
            "rating_q975": 1022.6159124842782,
            "rating_q025": 995.240298438406
        },
        "wizardlm-13b": {
            "rating": 1008.7591585818728,
            "rating_q975": 1022.2242357930704,
            "rating_q025": 995.2940813706753
        },
        "solar-10.7b-instruct-v1.0": {
            "rating": 1007.6697498183155,
            "rating_q975": 1026.868290047573,
            "rating_q025": 988.4712095890578
        },
        "dolphin-2.2.1-mistral-7b": {
            "rating": 1006.6980083815633,
            "rating_q975": 1029.1844675731386,
            "rating_q025": 984.2115491899882
        },
        "falcon-180b-chat": {
            "rating": 1001.5200138850844,
            "rating_q975": 1025.5771069073712,
            "rating_q025": 977.4629208627975
        },
        "mistral-7b-instruct-v0.2": {
            "rating": 1001.0465743700677,
            "rating_q975": 1011.236427282891,
            "rating_q025": 990.8567214572444
        },
        "qwen1.5-7b-chat": {
            "rating": 993.6908858299247,
            "rating_q975": 1009.2128729890139,
            "rating_q025": 978.1688986708355
        },
        "qwen-14b-chat": {
            "rating": 990.3985567946827,
            "rating_q975": 1006.2373454758133,
            "rating_q025": 974.5597681135521
        },
        "llama-2-13b-chat": {
            "rating": 990.0578490677751,
            "rating_q975": 1000.102780263198,
            "rating_q025": 980.0129178723522
        },
        "vicuna-13b": {
            "rating": 987.6473800052734,
            "rating_q975": 997.7727039143233,
            "rating_q025": 977.5220560962234
        },
        "palm-2": {
            "rating": 986.4769522304696,
            "rating_q975": 999.6880598422089,
            "rating_q025": 973.2658446187303
        },
        "codellama-34b-instruct": {
            "rating": 982.8353555387694,
            "rating_q975": 995.8051298400298,
            "rating_q025": 969.8655812375089
        },
        "granite-3.0-2b-instruct": {
            "rating": 981.0825752119706,
            "rating_q975": 998.2466532331763,
            "rating_q025": 963.9184971907649
        },
        "guanaco-33b": {
            "rating": 976.1422772184351,
            "rating_q975": 994.2841913315727,
            "rating_q025": 958.0003631052974
        },
        "zephyr-7b-beta": {
            "rating": 974.8496451062158,
            "rating_q975": 987.484045245598,
            "rating_q025": 962.2152449668336
        },
        "zephyr-7b-alpha": {
            "rating": 974.1438968572199,
            "rating_q975": 996.6914183391264,
            "rating_q025": 951.5963753753135
        },
        "gemma-7b-it": {
            "rating": 973.581818988457,
            "rating_q975": 987.9077380148067,
            "rating_q025": 959.2558999621074
        },
        "phi-3-mini-4k-instruct-june-2024": {
            "rating": 963.2554875760961,
            "rating_q975": 975.6053341021991,
            "rating_q025": 950.9056410499932
        },
        "vicuna-7b": {
            "rating": 960.1752333684941,
            "rating_q975": 973.6235895104415,
            "rating_q025": 946.7268772265467
        },
        "phi-3-mini-128k-instruct": {
            "rating": 958.852751289684,
            "rating_q975": 971.8125073118583,
            "rating_q025": 945.8929952675096
        },
        "codellama-70b-instruct": {
            "rating": 958.2050090115858,
            "rating_q975": 986.3840777215489,
            "rating_q025": 930.0259403016228
        },
        "stripedhyena-nous-7b": {
            "rating": 957.6148797187998,
            "rating_q975": 974.3176109881603,
            "rating_q025": 940.9121484494393
        },
        "phi-3-mini-4k-instruct": {
            "rating": 950.152360323751,
            "rating_q975": 961.6297698150959,
            "rating_q025": 938.6749508324062
        },
        "mistral-7b-instruct": {
            "rating": 941.5845340364845,
            "rating_q975": 955.3921552604548,
            "rating_q025": 927.7769128125141
        },
        "llama-2-7b-chat": {
            "rating": 938.189699555991,
            "rating_q975": 948.7215081186481,
            "rating_q025": 927.6578909933338
        },
        "gemma-1.1-2b-it": {
            "rating": 924.2395878337622,
            "rating_q975": 937.8046071180612,
            "rating_q025": 910.6745685494633
        },
        "smollm2-1.7b-instruct": {
            "rating": 909.0628379156531,
            "rating_q975": 940.5957205163909,
            "rating_q025": 877.5299553149152
        },
        "gemma-2b-it": {
            "rating": 902.5157471964671,
            "rating_q975": 920.6843102047748,
            "rating_q025": 884.3471841881595
        },
        "llama-3.2-1b-instruct": {
            "rating": 900.7454952689628,
            "rating_q975": 916.737197411808,
            "rating_q025": 884.7537931261177
        },
        "qwen1.5-4b-chat": {
            "rating": 897.7030450097777,
            "rating_q975": 913.663632562511,
            "rating_q025": 881.7424574570445
        },
        "koala-13b": {
            "rating": 896.3161000400303,
            "rating_q975": 911.8160239886558,
            "rating_q025": 880.8161760914047
        },
        "alpaca-13b": {
            "rating": 889.2579586614329,
            "rating_q975": 906.3983039153604,
            "rating_q025": 872.1176134075054
        },
        "olmo-7b-instruct": {
            "rating": 885.8093455624689,
            "rating_q975": 903.4925606582586,
            "rating_q025": 868.1261304666792
        },
        "gpt4all-13b-snoozy": {
            "rating": 885.5427359483749,
            "rating_q975": 909.4636193377978,
            "rating_q025": 861.621852558952
        },
        "mpt-7b-chat": {
            "rating": 878.2572956473696,
            "rating_q975": 896.6475064797828,
            "rating_q025": 859.8670848149563
        },
        "chatglm3-6b": {
            "rating": 863.0911110843748,
            "rating_q975": 881.4584594300175,
            "rating_q025": 844.7237627387321
        },
        "RWKV-4-Raven-14B": {
            "rating": 851.5828180312283,
            "rating_q975": 869.0835967581237,
            "rating_q025": 834.0820393043329
        },
        "oasst-pythia-12b": {
            "rating": 822.7339910108883,
            "rating_q975": 839.4376886069514,
            "rating_q025": 806.0302934148252
        },
        "chatglm2-6b": {
            "rating": 805.4703819202222,
            "rating_q975": 827.4277621130739,
            "rating_q025": 783.5130017273705
        },
        "fastchat-t5-3b": {
            "rating": 768.4284953535387,
            "rating_q975": 787.7651125367897,
            "rating_q025": 749.0918781702876
        },
        "chatglm-6b": {
            "rating": 767.9925324723891,
            "rating_q975": 787.7149653173767,
            "rating_q025": 748.2700996274016
        },
        "dolly-v2-12b": {
            "rating": 749.1192417653958,
            "rating_q975": 771.2898967326147,
            "rating_q025": 726.948586798177
        },
        "llama-13b": {
            "rating": 722.8894651298056,
            "rating_q975": 748.9498395703689,
            "rating_q025": 696.8290906892422
        },
        "stablelm-tuned-alpha-7b": {
            "rating": 701.3968582366207,
            "rating_q975": 722.9642324000847,
            "rating_q025": 679.8294840731567
        }
    },
    "russian": {
        "gemini-3-pro": {
            "rating": 1506.9109788634037,
            "rating_q975": 1524.5953199373407,
            "rating_q025": 1489.2266377894666
        },
        "grok-4.1-thinking": {
            "rating": 1468.8615235640839,
            "rating_q975": 1485.6423306156055,
            "rating_q025": 1452.0807165125623
        },
        "claude-opus-4-5-20251101": {
            "rating": 1467.730451034956,
            "rating_q975": 1487.460663848594,
            "rating_q025": 1448.000238221318
        },
        "gemini-2.5-pro": {
            "rating": 1460.0436772119406,
            "rating_q975": 1469.5822406451443,
            "rating_q025": 1450.5051137787368
        },
        "claude-opus-4-1-20250805": {
            "rating": 1449.6351513884047,
            "rating_q975": 1460.3600385316327,
            "rating_q025": 1438.9102642451767
        },
        "grok-4.1": {
            "rating": 1449.1081323142814,
            "rating_q975": 1466.1793156283395,
            "rating_q025": 1432.0369490002233
        },
        "claude-opus-4-5-20251101-thinking-32k": {
            "rating": 1448.3529208542784,
            "rating_q975": 1468.7189118893266,
            "rating_q025": 1427.9869298192302
        },
        "gpt-4.5-preview-2025-02-27": {
            "rating": 1442.0544909956373,
            "rating_q975": 1457.2540284860463,
            "rating_q025": 1426.8549535052282
        },
        "gpt-5.1": {
            "rating": 1441.838778430771,
            "rating_q975": 1460.0357609403309,
            "rating_q025": 1423.6417959212113
        },
        "claude-opus-4-1-20250805-thinking-16k": {
            "rating": 1439.9749740008433,
            "rating_q975": 1451.8939478863647,
            "rating_q025": 1428.056000115322
        },
        "chatgpt-4o-latest-20250326": {
            "rating": 1439.4218556254011,
            "rating_q975": 1448.7721843943252,
            "rating_q025": 1430.071526856477
        },
        "claude-sonnet-4-5-20250929-thinking-32k": {
            "rating": 1438.131046649189,
            "rating_q975": 1452.4053334480734,
            "rating_q025": 1423.8567598503048
        },
        "claude-sonnet-4-5-20250929": {
            "rating": 1437.2815056461232,
            "rating_q975": 1452.411820535478,
            "rating_q025": 1422.1511907567683
        },
        "gpt-5.1-high": {
            "rating": 1436.2159100038352,
            "rating_q975": 1454.7421327537513,
            "rating_q025": 1417.6896872539191
        },
        "ernie-5.0-preview-1103": {
            "rating": 1433.5343198848173,
            "rating_q975": 1461.5468679581204,
            "rating_q025": 1405.521771811514
        },
        "o3-2025-04-16": {
            "rating": 1433.1889357487044,
            "rating_q975": 1443.0578643747167,
            "rating_q025": 1423.320007122692
        },
        "claude-opus-4-20250514-thinking-16k": {
            "rating": 1432.3766923516582,
            "rating_q975": 1445.0238083450663,
            "rating_q025": 1419.7295763582501
        },
        "qwen3-max-2025-09-23": {
            "rating": 1430.9093482407266,
            "rating_q975": 1454.8872966357953,
            "rating_q025": 1406.9313998456578
        },
        "gpt-5-high": {
            "rating": 1430.6025163923407,
            "rating_q975": 1445.8682051780288,
            "rating_q025": 1415.3368276066526
        },
        "gpt-5-chat": {
            "rating": 1426.435007487101,
            "rating_q975": 1441.335998796342,
            "rating_q025": 1411.5340161778602
        },
        "deepseek-v3.1-terminus": {
            "rating": 1424.786308004343,
            "rating_q975": 1458.5534413948535,
            "rating_q025": 1391.0191746138325
        },
        "claude-opus-4-20250514": {
            "rating": 1424.075706488076,
            "rating_q975": 1435.3658046527366,
            "rating_q025": 1412.7856083234155
        },
        "deepseek-v3.1-terminus-thinking": {
            "rating": 1423.0906547329816,
            "rating_q975": 1459.0226503878432,
            "rating_q025": 1387.15865907812
        },
        "grok-4-1-fast-reasoning": {
            "rating": 1417.4952478415007,
            "rating_q975": 1439.244973499033,
            "rating_q025": 1395.7455221839684
        },
        "qwen3-max-preview": {
            "rating": 1416.545499022011,
            "rating_q975": 1432.6032742983539,
            "rating_q025": 1400.487723745668
        },
        "grok-4-0709": {
            "rating": 1414.1214657688454,
            "rating_q975": 1426.7661577698398,
            "rating_q025": 1401.476773767851
        },
        "deepseek-v3.2": {
            "rating": 1414.034399858063,
            "rating_q975": 1439.795626615326,
            "rating_q025": 1388.2731731007998
        },
        "gemini-2.5-flash": {
            "rating": 1413.6114580419285,
            "rating_q975": 1422.5822468474835,
            "rating_q025": 1404.6406692363735
        },
        "qwen3-235b-a22b-instruct-2507": {
            "rating": 1412.0746569524279,
            "rating_q975": 1423.0219056327903,
            "rating_q025": 1401.1274082720654
        },
        "deepseek-r1-0528": {
            "rating": 1409.8441432814545,
            "rating_q975": 1426.1675383706618,
            "rating_q025": 1393.5207481922473
        },
        "deepseek-v3.2-exp-thinking": {
            "rating": 1408.5191744705455,
            "rating_q975": 1433.3507938827506,
            "rating_q025": 1383.6875550583404
        },
        "grok-3-preview-02-24": {
            "rating": 1408.5180334539618,
            "rating_q975": 1420.0711418066335,
            "rating_q025": 1396.9649251012902
        },
        "kimi-k2-0905-preview": {
            "rating": 1407.7991715964156,
            "rating_q975": 1430.4339826299476,
            "rating_q025": 1385.1643605628835
        },
        "glm-4.6": {
            "rating": 1407.2242397339016,
            "rating_q975": 1422.6452872951763,
            "rating_q025": 1391.803192172627
        },
        "gpt-4.1-2025-04-14": {
            "rating": 1406.263134202596,
            "rating_q975": 1416.8074181547624,
            "rating_q025": 1395.7188502504293
        },
        "qwen3-235b-a22b-thinking-2507": {
            "rating": 1405.7121593866125,
            "rating_q975": 1432.9045045393166,
            "rating_q025": 1378.5198142339084
        },
        "claude-sonnet-4-20250514-thinking-32k": {
            "rating": 1404.0229637934003,
            "rating_q975": 1417.2600507283064,
            "rating_q025": 1390.7858768584942
        },
        "kimi-k2-0711-preview": {
            "rating": 1403.646977182426,
            "rating_q975": 1418.2853183342231,
            "rating_q025": 1389.008636030629
        },
        "deepseek-v3.1": {
            "rating": 1403.5586419362794,
            "rating_q975": 1424.3505420458291,
            "rating_q025": 1382.7667418267297
        },
        "kimi-k2-thinking-turbo": {
            "rating": 1402.3805880585523,
            "rating_q975": 1420.2169247650477,
            "rating_q025": 1384.544251352057
        },
        "deepseek-v3.2-exp": {
            "rating": 1402.1146820931754,
            "rating_q975": 1423.355077948135,
            "rating_q025": 1380.8742862382157
        },
        "deepseek-v3.1-thinking": {
            "rating": 1401.5078164148802,
            "rating_q975": 1424.0653222901105,
            "rating_q025": 1378.9503105396498
        },
        "gemini-2.5-flash-preview-09-2025": {
            "rating": 1401.236536319165,
            "rating_q975": 1415.2577756458156,
            "rating_q025": 1387.2152969925144
        },
        "qwen3-235b-a22b-no-thinking": {
            "rating": 1399.314187051897,
            "rating_q975": 1411.334468167821,
            "rating_q025": 1387.2939059359733
        },
        "mistral-medium-2508": {
            "rating": 1397.1566331098777,
            "rating_q975": 1409.0999547436854,
            "rating_q025": 1385.21331147607
        },
        "grok-4-fast-chat": {
            "rating": 1393.4517493371582,
            "rating_q975": 1421.1699718775187,
            "rating_q025": 1365.7335267967976
        },
        "glm-4.5": {
            "rating": 1392.0496210745503,
            "rating_q975": 1408.3900918581792,
            "rating_q025": 1375.7091502909213
        },
        "grok-4-fast-reasoning": {
            "rating": 1391.8827101853865,
            "rating_q975": 1410.319807490067,
            "rating_q025": 1373.445612880706
        },
        "deepseek-v3-0324": {
            "rating": 1391.2007860098427,
            "rating_q975": 1401.5301646744929,
            "rating_q025": 1380.8714073451924
        },
        "qwen3-next-80b-a3b-instruct": {
            "rating": 1389.5916306326612,
            "rating_q975": 1406.6435316805255,
            "rating_q025": 1372.539729584797
        },
        "mistral-large-3": {
            "rating": 1389.3067999333614,
            "rating_q975": 1414.4127344907881,
            "rating_q025": 1364.2008653759347
        },
        "qwen3-vl-235b-a22b-instruct": {
            "rating": 1388.4530904671237,
            "rating_q975": 1413.5422053384661,
            "rating_q025": 1363.3639755957813
        },
        "claude-sonnet-4-20250514": {
            "rating": 1388.315533246147,
            "rating_q975": 1399.9419349657287,
            "rating_q025": 1376.6891315265652
        },
        "deepseek-v3.2-thinking": {
            "rating": 1385.6764523342035,
            "rating_q975": 1412.7576018636757,
            "rating_q025": 1358.5953028047313
        },
        "o1-2024-12-17": {
            "rating": 1384.0021211932194,
            "rating_q975": 1394.0781887556534,
            "rating_q025": 1373.9260536307854
        },
        "mai-1-preview": {
            "rating": 1383.2607536537764,
            "rating_q975": 1401.8339647135438,
            "rating_q025": 1364.687542594009
        },
        "qwen3-coder-480b-a35b-instruct": {
            "rating": 1379.098312538356,
            "rating_q975": 1395.6023940689415,
            "rating_q025": 1362.5942310077703
        },
        "gpt-5-mini-high": {
            "rating": 1378.1883709794922,
            "rating_q975": 1394.0685153147188,
            "rating_q025": 1362.3082266442657
        },
        "gemini-2.5-flash-lite-preview-06-17-thinking": {
            "rating": 1377.9609403113814,
            "rating_q975": 1391.4816725733742,
            "rating_q025": 1364.4402080493885
        },
        "deepseek-r1": {
            "rating": 1376.1340090772082,
            "rating_q975": 1388.7016553755977,
            "rating_q025": 1363.5663627788188
        },
        "mistral-medium-2505": {
            "rating": 1376.019694814073,
            "rating_q975": 1387.7969428459062,
            "rating_q025": 1364.24244678224
        },
        "hunyuan-turbos-20250416": {
            "rating": 1375.7774814954644,
            "rating_q975": 1393.8667427677328,
            "rating_q025": 1357.688220223196
        },
        "hunyuan-t1-20250711": {
            "rating": 1374.3389031850068,
            "rating_q975": 1409.0189699400928,
            "rating_q025": 1339.6588364299207
        },
        "claude-haiku-4-5-20251001": {
            "rating": 1373.4219555068614,
            "rating_q975": 1388.7159320608569,
            "rating_q025": 1358.127978952866
        },
        "o4-mini-2025-04-16": {
            "rating": 1372.7031343871768,
            "rating_q975": 1383.48722607218,
            "rating_q025": 1361.9190427021736
        },
        "claude-3-7-sonnet-20250219": {
            "rating": 1371.673815201637,
            "rating_q975": 1381.8562400563208,
            "rating_q025": 1361.491390346953
        },
        "claude-3-7-sonnet-20250219-thinking-32k": {
            "rating": 1371.0072327786988,
            "rating_q975": 1381.6750761906405,
            "rating_q025": 1360.3393893667571
        },
        "claude-3-5-sonnet-20241022": {
            "rating": 1370.9835586331267,
            "rating_q975": 1377.399726234407,
            "rating_q025": 1364.5673910318465
        },
        "qwen3-vl-235b-a22b-thinking": {
            "rating": 1369.246223890156,
            "rating_q975": 1395.0391354058338,
            "rating_q025": 1343.4533123744782
        },
        "gemma-3-27b-it": {
            "rating": 1368.019155512265,
            "rating_q975": 1378.3797379162413,
            "rating_q025": 1357.6585731082885
        },
        "gemini-2.5-flash-lite-preview-09-2025-no-thinking": {
            "rating": 1367.5639818231023,
            "rating_q975": 1381.7064615576955,
            "rating_q025": 1353.421502088509
        },
        "qwen3-30b-a3b-instruct-2507": {
            "rating": 1366.8592300568548,
            "rating_q975": 1383.4410727860868,
            "rating_q025": 1350.2773873276228
        },
        "longcat-flash-chat": {
            "rating": 1364.1839579643972,
            "rating_q975": 1385.9691549365814,
            "rating_q025": 1342.398760992213
        },
        "qwen2.5-max": {
            "rating": 1363.0534602827329,
            "rating_q975": 1373.4770715111167,
            "rating_q025": 1352.629849054349
        },
        "glm-4.5-air": {
            "rating": 1361.337628727626,
            "rating_q975": 1376.415357956801,
            "rating_q025": 1346.259899498451
        },
        "gemini-2.0-flash-001": {
            "rating": 1361.063321893554,
            "rating_q975": 1370.7854695313513,
            "rating_q025": 1351.3411742557569
        },
        "gemma-3-12b-it": {
            "rating": 1358.1599125588211,
            "rating_q975": 1389.906915241603,
            "rating_q025": 1326.4129098760393
        },
        "gpt-4.1-mini-2025-04-14": {
            "rating": 1356.7435550148284,
            "rating_q975": 1368.2123115273216,
            "rating_q025": 1345.2747985023352
        },
        "o1-preview": {
            "rating": 1356.7241661394078,
            "rating_q975": 1365.8934286072588,
            "rating_q025": 1347.5549036715568
        },
        "qwen3-235b-a22b": {
            "rating": 1353.343231445199,
            "rating_q975": 1366.3127803527075,
            "rating_q025": 1340.3736825376907
        },
        "qwen3-next-80b-a3b-thinking": {
            "rating": 1352.4047161605445,
            "rating_q975": 1372.9313966410382,
            "rating_q025": 1331.8780356800507
        },
        "deepseek-v3": {
            "rating": 1351.967707177208,
            "rating_q975": 1362.9879701220225,
            "rating_q025": 1340.9474442323935
        },
        "gemini-2.0-flash-lite-preview-02-05": {
            "rating": 1350.1565574809115,
            "rating_q975": 1361.4860393807735,
            "rating_q025": 1338.8270755810495
        },
        "qwen-plus-0125": {
            "rating": 1349.836940226307,
            "rating_q975": 1371.6432513245697,
            "rating_q025": 1328.0306291280442
        },
        "gemini-1.5-pro-002": {
            "rating": 1349.1639431550118,
            "rating_q975": 1356.2815530295588,
            "rating_q025": 1342.0463332804648
        },
        "grok-3-mini-beta": {
            "rating": 1347.766876639112,
            "rating_q975": 1363.2604304348242,
            "rating_q025": 1332.2733228434
        },
        "mistral-small-2506": {
            "rating": 1346.535232035316,
            "rating_q975": 1364.4860962847558,
            "rating_q025": 1328.5843677858763
        },
        "amazon-nova-experimental-chat-10-09": {
            "rating": 1346.221704569105,
            "rating_q975": 1376.8539919962707,
            "rating_q025": 1315.5894171419393
        },
        "grok-3-mini-high": {
            "rating": 1344.3867597720714,
            "rating_q975": 1362.6869661357746,
            "rating_q025": 1326.0865534083682
        },
        "claude-3-5-sonnet-20240620": {
            "rating": 1341.7762817464113,
            "rating_q975": 1349.3035649349129,
            "rating_q025": 1334.2489985579098
        },
        "minimax-m1": {
            "rating": 1340.8335054020663,
            "rating_q975": 1353.985466747463,
            "rating_q025": 1327.6815440566695
        },
        "command-a-03-2025": {
            "rating": 1338.4352361375265,
            "rating_q975": 1348.0189715819752,
            "rating_q025": 1328.851500693078
        },
        "step-2-16k-exp-202412": {
            "rating": 1337.9027676608462,
            "rating_q975": 1359.550692448001,
            "rating_q025": 1316.2548428736914
        },
        "hunyuan-turbos-20250226": {
            "rating": 1335.3521157460113,
            "rating_q975": 1370.6660757506108,
            "rating_q025": 1300.0381557414119
        },
        "gpt-oss-120b": {
            "rating": 1334.0802821957031,
            "rating_q975": 1348.7098692578998,
            "rating_q025": 1319.4506951335065
        },
        "amazon-nova-experimental-chat-10-20": {
            "rating": 1333.3380966801674,
            "rating_q975": 1358.747031145268,
            "rating_q025": 1307.9291622150668
        },
        "claude-3-opus-20240229": {
            "rating": 1332.6719122315192,
            "rating_q975": 1338.9789099903012,
            "rating_q025": 1326.3649144727372
        },
        "llama-4-maverick-17b-128e-instruct": {
            "rating": 1331.2791540048934,
            "rating_q975": 1342.4641328443922,
            "rating_q025": 1320.0941751653945
        },
        "hunyuan-turbo-0110": {
            "rating": 1329.638122757962,
            "rating_q975": 1361.6838883346293,
            "rating_q025": 1297.5923571812948
        },
        "gemini-advanced-0514": {
            "rating": 1328.7767275859342,
            "rating_q975": 1338.750671411425,
            "rating_q025": 1318.8027837604434
        },
        "gpt-4o-2024-05-13": {
            "rating": 1328.7481905524837,
            "rating_q975": 1335.5224839664315,
            "rating_q025": 1321.973897138536
        },
        "glm-4-plus-0111": {
            "rating": 1328.5898166651496,
            "rating_q975": 1350.148168207084,
            "rating_q025": 1307.0314651232152
        },
        "o3-mini-high": {
            "rating": 1327.2753295961625,
            "rating_q975": 1340.3741936288784,
            "rating_q025": 1314.1764655634465
        },
        "step-1o-turbo-202506": {
            "rating": 1325.9114720235104,
            "rating_q975": 1349.4698757362899,
            "rating_q025": 1302.353068310731
        },
        "o3-mini": {
            "rating": 1324.3896289071145,
            "rating_q975": 1332.9192610622565,
            "rating_q025": 1315.8599967519724
        },
        "nova-2-lite": {
            "rating": 1323.0725309534382,
            "rating_q975": 1349.831593334231,
            "rating_q025": 1296.3134685726454
        },
        "step-3": {
            "rating": 1322.9812511824377,
            "rating_q975": 1351.8911635310794,
            "rating_q025": 1294.071338833796
        },
        "qwen3-32b": {
            "rating": 1322.631237029162,
            "rating_q975": 1348.4241401072247,
            "rating_q025": 1296.8383339510995
        },
        "gemini-1.5-pro-001": {
            "rating": 1322.5847845785847,
            "rating_q975": 1330.7480404209423,
            "rating_q025": 1314.4215287362272
        },
        "grok-2-2024-08-13": {
            "rating": 1322.2645822927186,
            "rating_q975": 1329.3005589078887,
            "rating_q025": 1315.2286056775486
        },
        "gpt-4o-2024-08-06": {
            "rating": 1320.7125850626337,
            "rating_q975": 1328.9410763606973,
            "rating_q025": 1312.4840937645702
        },
        "deepseek-v2.5-1210": {
            "rating": 1318.1288383708866,
            "rating_q975": 1335.0548914402332,
            "rating_q025": 1301.20278530154
        },
        "gpt-5-nano-high": {
            "rating": 1316.7585408597292,
            "rating_q975": 1343.2425678410098,
            "rating_q025": 1290.2745138784487
        },
        "minimax-m2": {
            "rating": 1315.6639658496833,
            "rating_q975": 1348.8812406389343,
            "rating_q025": 1282.4466910604324
        },
        "claude-3-5-haiku-20241022": {
            "rating": 1314.1335317677363,
            "rating_q975": 1321.5848829786369,
            "rating_q025": 1306.6821805568356
        },
        "glm-4.5v": {
            "rating": 1314.0836482722862,
            "rating_q975": 1345.4066919443821,
            "rating_q025": 1282.7606046001902
        },
        "gemma-3-4b-it": {
            "rating": 1313.6499233816667,
            "rating_q975": 1344.0470470581288,
            "rating_q025": 1283.2527997052046
        },
        "llama-3.1-405b-instruct-fp8": {
            "rating": 1312.9929515337312,
            "rating_q975": 1320.3417351314515,
            "rating_q025": 1305.644167936011
        },
        "llama-3.1-nemotron-ultra-253b-v1": {
            "rating": 1310.3676775004628,
            "rating_q975": 1340.2070954251612,
            "rating_q025": 1280.5282595757644
        },
        "gpt-4-turbo-2024-04-09": {
            "rating": 1310.3171201242087,
            "rating_q975": 1318.0756813826408,
            "rating_q025": 1302.5585588657766
        },
        "llama-4-scout-17b-16e-instruct": {
            "rating": 1309.0489820053413,
            "rating_q975": 1322.5308400117606,
            "rating_q025": 1295.567123998922
        },
        "gemma-3n-e4b-it": {
            "rating": 1307.935862127698,
            "rating_q975": 1323.2022635971134,
            "rating_q025": 1292.6694606582828
        },
        "qwen-max-0919": {
            "rating": 1307.5670698977488,
            "rating_q975": 1318.9468767324697,
            "rating_q025": 1296.1872630630278
        },
        "gemini-1.5-flash-002": {
            "rating": 1307.1449052367157,
            "rating_q975": 1315.4847030060787,
            "rating_q025": 1298.8051074673526
        },
        "o1-mini": {
            "rating": 1306.143379250162,
            "rating_q975": 1313.4668761813589,
            "rating_q025": 1298.8198823189653
        },
        "qwen3-30b-a3b": {
            "rating": 1305.9212794182959,
            "rating_q975": 1319.0256175003417,
            "rating_q025": 1292.81694133625
        },
        "llama-3.1-405b-instruct-bf16": {
            "rating": 1304.5356331756313,
            "rating_q975": 1312.7235611863675,
            "rating_q025": 1296.3477051648952
        },
        "gpt-4o-mini-2024-07-18": {
            "rating": 1304.3051433871751,
            "rating_q975": 1311.1421282752465,
            "rating_q025": 1297.4681584991038
        },
        "glm-4-plus": {
            "rating": 1303.7886783487638,
            "rating_q975": 1313.414685135905,
            "rating_q025": 1294.1626715616226
        },
        "gpt-oss-20b": {
            "rating": 1302.5250085763942,
            "rating_q975": 1326.3598274097121,
            "rating_q025": 1278.6901897430762
        },
        "qwq-32b": {
            "rating": 1302.140734080192,
            "rating_q975": 1315.2232249622348,
            "rating_q025": 1289.0582431981493
        },
        "mistral-large-2407": {
            "rating": 1300.851976649464,
            "rating_q975": 1309.0608198385678,
            "rating_q025": 1292.64313346036
        },
        "athene-v2-chat": {
            "rating": 1300.843959150675,
            "rating_q975": 1310.4171308341702,
            "rating_q025": 1291.2707874671796
        },
        "hunyuan-large-2025-02-10": {
            "rating": 1299.629382856327,
            "rating_q975": 1328.285734457487,
            "rating_q025": 1270.9730312551671
        },
        "gpt-4-1106-preview": {
            "rating": 1298.3978198547954,
            "rating_q975": 1307.0457122495313,
            "rating_q025": 1289.7499274600596
        },
        "gpt-4.1-nano-2025-04-14": {
            "rating": 1297.5825439562516,
            "rating_q975": 1318.4421304132766,
            "rating_q025": 1276.7229574992266
        },
        "qwen2.5-plus-1127": {
            "rating": 1294.3707723594748,
            "rating_q975": 1309.22718427035,
            "rating_q025": 1279.5143604485995
        },
        "grok-2-mini-2024-08-13": {
            "rating": 1294.0400875846947,
            "rating_q975": 1301.4081290949835,
            "rating_q025": 1286.672046074406
        },
        "mistral-small-3.1-24b-instruct-2503": {
            "rating": 1293.932397749439,
            "rating_q975": 1307.018427834605,
            "rating_q025": 1280.8463676642727
        },
        "gpt-4-0125-preview": {
            "rating": 1292.7595006547876,
            "rating_q975": 1301.0745276388707,
            "rating_q025": 1284.4444736707046
        },
        "qwen2.5-72b-instruct": {
            "rating": 1292.242915259913,
            "rating_q975": 1300.1611675827014,
            "rating_q025": 1284.3246629371245
        },
        "reka-core-20240904": {
            "rating": 1292.0631525142994,
            "rating_q975": 1309.6538410682679,
            "rating_q025": 1274.472463960331
        },
        "mistral-large-2411": {
            "rating": 1291.9548156426579,
            "rating_q975": 1301.5986281877863,
            "rating_q025": 1282.3110030975295
        },
        "hunyuan-standard-2025-02-10": {
            "rating": 1291.3997245180847,
            "rating_q975": 1318.4728693686047,
            "rating_q025": 1264.3265796675646
        },
        "llama-3.3-70b-instruct": {
            "rating": 1290.292316770322,
            "rating_q975": 1297.9751211786242,
            "rating_q025": 1282.6095123620198
        },
        "gemma-2-27b-it": {
            "rating": 1285.9674112934745,
            "rating_q975": 1292.5532318890778,
            "rating_q025": 1279.3815906978712
        },
        "deepseek-v2.5": {
            "rating": 1285.6968556456268,
            "rating_q975": 1295.4886938068207,
            "rating_q025": 1275.9050174844328
        },
        "athene-70b-0725": {
            "rating": 1284.4578832219245,
            "rating_q975": 1297.1884474413812,
            "rating_q025": 1271.7273190024678
        },
        "ling-flash-2.0": {
            "rating": 1284.043627371369,
            "rating_q975": 1314.3775516138278,
            "rating_q025": 1253.7097031289102
        },
        "claude-3-sonnet-20240229": {
            "rating": 1283.7131588779516,
            "rating_q975": 1292.3699424172491,
            "rating_q025": 1275.056375338654
        },
        "yi-lightning": {
            "rating": 1283.7005310022507,
            "rating_q975": 1293.20640370097,
            "rating_q025": 1274.1946583035315
        },
        "llama-3.3-nemotron-49b-super-v1": {
            "rating": 1283.49811016796,
            "rating_q975": 1317.6654941083975,
            "rating_q025": 1249.3307262275225
        },
        "gemini-1.5-flash-001": {
            "rating": 1281.791929277194,
            "rating_q975": 1290.3516149694292,
            "rating_q025": 1273.2322435849587
        },
        "hunyuan-large-vision": {
            "rating": 1277.6881527245296,
            "rating_q975": 1308.1831696784768,
            "rating_q025": 1247.1931357705823
        },
        "llama-3.1-tulu-3-70b": {
            "rating": 1275.7463637498477,
            "rating_q975": 1302.577616978186,
            "rating_q025": 1248.9151105215094
        },
        "amazon-nova-pro-v1.0": {
            "rating": 1274.4862711282508,
            "rating_q975": 1284.4544785061062,
            "rating_q025": 1264.5180637503954
        },
        "nemotron-4-340b-instruct": {
            "rating": 1270.8111104390669,
            "rating_q975": 1283.020902173297,
            "rating_q025": 1258.6013187048368
        },
        "command-r-plus-08-2024": {
            "rating": 1269.6644476140655,
            "rating_q975": 1284.3455531666095,
            "rating_q025": 1254.9833420615214
        },
        "gemma-2-9b-it-simpo": {
            "rating": 1268.3221057325627,
            "rating_q975": 1284.9332808623178,
            "rating_q025": 1251.7109306028076
        },
        "llama-3.1-70b-instruct": {
            "rating": 1268.010817511417,
            "rating_q975": 1275.4807491995157,
            "rating_q025": 1260.5408858233181
        },
        "magistral-medium-2506": {
            "rating": 1266.796740503513,
            "rating_q975": 1288.0841390762848,
            "rating_q025": 1245.5093419307414
        },
        "qwen2.5-coder-32b-instruct": {
            "rating": 1266.5419316623997,
            "rating_q975": 1284.912866797889,
            "rating_q025": 1248.1709965269106
        },
        "gpt-4-0314": {
            "rating": 1265.9559738288108,
            "rating_q975": 1277.6959176395978,
            "rating_q025": 1254.2160300180237
        },
        "claude-3-haiku-20240307": {
            "rating": 1265.5486441214423,
            "rating_q975": 1273.2022382864786,
            "rating_q025": 1257.895049956406
        },
        "reka-flash-20240904": {
            "rating": 1265.3867461927323,
            "rating_q975": 1282.6070987238038,
            "rating_q025": 1248.1663936616608
        },
        "gemini-pro-dev-api": {
            "rating": 1264.1817977369433,
            "rating_q975": 1284.054359435341,
            "rating_q025": 1244.3092360385456
        },
        "gemini-1.5-flash-8b-001": {
            "rating": 1263.049491499138,
            "rating_q975": 1271.2800233303267,
            "rating_q025": 1254.8189596679492
        },
        "c4ai-aya-expanse-32b": {
            "rating": 1262.2849669694806,
            "rating_q975": 1271.597859395669,
            "rating_q025": 1252.9720745432921
        },
        "mistral-small-24b-instruct-2501": {
            "rating": 1257.857159555019,
            "rating_q975": 1272.2776305055881,
            "rating_q025": 1243.43668860445
        },
        "command-r-plus": {
            "rating": 1257.1306584571405,
            "rating_q975": 1266.0329668756187,
            "rating_q025": 1248.2283500386623
        },
        "glm-4-0520": {
            "rating": 1257.0819486043447,
            "rating_q975": 1272.976256988957,
            "rating_q025": 1241.1876402197324
        },
        "deepseek-coder-v2": {
            "rating": 1255.1097440269486,
            "rating_q975": 1268.7578771032292,
            "rating_q025": 1241.461610950668
        },
        "gemma-2-9b-it": {
            "rating": 1254.0513629939173,
            "rating_q975": 1261.5994378070377,
            "rating_q025": 1246.503288180797
        },
        "gpt-4-0613": {
            "rating": 1253.8516875749824,
            "rating_q975": 1263.4665425505596,
            "rating_q025": 1244.2368325994053
        },
        "llama-3.1-nemotron-51b-instruct": {
            "rating": 1247.045850504624,
            "rating_q975": 1269.0190222776005,
            "rating_q025": 1225.0726787316476
        },
        "amazon-nova-lite-v1.0": {
            "rating": 1246.5410906576872,
            "rating_q975": 1257.6213238398848,
            "rating_q025": 1235.4608574754895
        },
        "jamba-1.5-large": {
            "rating": 1246.1717508702156,
            "rating_q975": 1263.6899109730987,
            "rating_q025": 1228.6535907673326
        },
        "phi-4": {
            "rating": 1242.5904693663442,
            "rating_q975": 1253.4894513523254,
            "rating_q025": 1231.691487380363
        },
        "olmo-3-32b-think": {
            "rating": 1241.7138507140787,
            "rating_q975": 1281.6107644524743,
            "rating_q025": 1201.8169369756831
        },
        "ministral-8b-2410": {
            "rating": 1241.0301536388326,
            "rating_q975": 1260.626314961743,
            "rating_q025": 1221.4339923159223
        },
        "llama-3.1-nemotron-70b-instruct": {
            "rating": 1238.224040076499,
            "rating_q975": 1255.3400662394915,
            "rating_q025": 1221.1080139135065
        },
        "qwen2-72b-instruct": {
            "rating": 1235.9419269648952,
            "rating_q975": 1245.920945095011,
            "rating_q025": 1225.9629088347795
        },
        "mistral-large-2402": {
            "rating": 1235.4777962477056,
            "rating_q975": 1245.5355811834856,
            "rating_q025": 1225.4200113119255
        },
        "command-r-08-2024": {
            "rating": 1229.9678912279296,
            "rating_q975": 1245.2650898833213,
            "rating_q025": 1214.670692572538
        },
        "ring-flash-2.0": {
            "rating": 1229.2428100187615,
            "rating_q975": 1259.0074197387012,
            "rating_q025": 1199.4782002988218
        },
        "c4ai-aya-expanse-8b": {
            "rating": 1227.6177716204772,
            "rating_q975": 1242.0233946415308,
            "rating_q025": 1213.2121485994237
        },
        "reka-flash-21b-20240226-online": {
            "rating": 1225.709095288061,
            "rating_q975": 1241.6599916474875,
            "rating_q025": 1209.7581989286346
        },
        "olmo-2-0325-32b-instruct": {
            "rating": 1225.6037696356784,
            "rating_q975": 1258.9678691529282,
            "rating_q025": 1192.2396701184286
        },
        "mixtral-8x22b-instruct-v0.1": {
            "rating": 1222.8467417365478,
            "rating_q975": 1232.5659326453324,
            "rating_q025": 1213.1275508277631
        },
        "reka-flash-21b-20240226": {
            "rating": 1222.2986679022722,
            "rating_q975": 1235.0891680549626,
            "rating_q025": 1209.5081677495818
        },
        "llama-3.1-tulu-3-8b": {
            "rating": 1222.2441299563395,
            "rating_q975": 1246.6733645941113,
            "rating_q025": 1197.8148953185678
        },
        "amazon-nova-micro-v1.0": {
            "rating": 1219.5972363788935,
            "rating_q975": 1230.8410172602566,
            "rating_q025": 1208.3534554975304
        },
        "llama-3-70b-instruct": {
            "rating": 1219.3737087717793,
            "rating_q975": 1227.1045521699164,
            "rating_q025": 1211.6428653736423
        },
        "mistral-medium": {
            "rating": 1217.132010223865,
            "rating_q975": 1231.7447653797176,
            "rating_q025": 1202.5192550680126
        },
        "gpt-3.5-turbo-0125": {
            "rating": 1216.257093867905,
            "rating_q975": 1226.078219494981,
            "rating_q025": 1206.435968240829
        },
        "jamba-1.5-mini": {
            "rating": 1215.1548526914135,
            "rating_q975": 1232.8631592498257,
            "rating_q025": 1197.4465461330012
        },
        "command-r": {
            "rating": 1214.1486148715871,
            "rating_q975": 1224.2524244669669,
            "rating_q025": 1204.0448052762074
        },
        "wizardlm-70b": {
            "rating": 1204.7827340459244,
            "rating_q975": 1249.0859808698185,
            "rating_q025": 1160.4794872220302
        },
        "phi-3-medium-4k-instruct": {
            "rating": 1193.7878144388346,
            "rating_q975": 1204.8606992080304,
            "rating_q025": 1182.7149296696389
        },
        "hunyuan-standard-256k": {
            "rating": 1191.7681646911446,
            "rating_q975": 1217.7204159421926,
            "rating_q025": 1165.8159134400967
        },
        "openchat-3.5": {
            "rating": 1189.5372154751894,
            "rating_q975": 1230.542780315112,
            "rating_q025": 1148.531650635267
        },
        "llama-3.1-8b-instruct": {
            "rating": 1188.4461178601946,
            "rating_q975": 1196.2835834995994,
            "rating_q025": 1180.6086522207897
        },
        "zephyr-orpo-141b-A35b-v0.1": {
            "rating": 1181.4929795058597,
            "rating_q975": 1208.3587293154333,
            "rating_q025": 1154.6272296962861
        },
        "gpt-3.5-turbo-1106": {
            "rating": 1175.512437453899,
            "rating_q975": 1203.8277837355674,
            "rating_q025": 1147.1970911722308
        },
        "qwen1.5-110b-chat": {
            "rating": 1174.6633351951664,
            "rating_q975": 1186.481878375906,
            "rating_q025": 1162.8447920144267
        },
        "llama-3-8b-instruct": {
            "rating": 1171.1944477863299,
            "rating_q975": 1179.6401488587362,
            "rating_q025": 1162.7487467139235
        },
        "qwen1.5-72b-chat": {
            "rating": 1169.546853255486,
            "rating_q975": 1181.9406220915134,
            "rating_q025": 1157.1530844194585
        },
        "phi-3-small-8k-instruct": {
            "rating": 1167.9787946802971,
            "rating_q975": 1180.8460186490058,
            "rating_q025": 1155.1115707115885
        },
        "snowflake-arctic-instruct": {
            "rating": 1167.6805630708711,
            "rating_q975": 1180.5969072450478,
            "rating_q025": 1154.7642188966945
        },
        "gemma-2-2b-it": {
            "rating": 1166.1712074885056,
            "rating_q975": 1174.52368123682,
            "rating_q025": 1157.8187337401912
        },
        "mixtral-8x7b-instruct-v0.1": {
            "rating": 1158.2015835302636,
            "rating_q975": 1168.2406727788298,
            "rating_q025": 1148.1624942816975
        },
        "dbrx-instruct-preview": {
            "rating": 1157.2457244800974,
            "rating_q975": 1169.7940293432823,
            "rating_q025": 1144.6974196169124
        },
        "starling-lm-7b-alpha": {
            "rating": 1152.377583865586,
            "rating_q975": 1179.6330838667445,
            "rating_q025": 1125.1220838644276
        },
        "granite-3.1-8b-instruct": {
            "rating": 1151.9269830040014,
            "rating_q975": 1179.9163066453737,
            "rating_q025": 1123.9376593626291
        },
        "openchat-3.5-0106": {
            "rating": 1150.722932969209,
            "rating_q975": 1171.1930660978935,
            "rating_q025": 1130.2527998405246
        },
        "codellama-34b-instruct": {
            "rating": 1146.4382563397012,
            "rating_q975": 1190.4110625424498,
            "rating_q025": 1102.4654501369525
        },
        "internlm2_5-20b-chat": {
            "rating": 1144.9381573422793,
            "rating_q975": 1160.470616843512,
            "rating_q025": 1129.4056978410465
        },
        "vicuna-33b": {
            "rating": 1141.9474713379627,
            "rating_q975": 1163.261476543819,
            "rating_q025": 1120.6334661321064
        },
        "qwen1.5-32b-chat": {
            "rating": 1140.1664617636507,
            "rating_q975": 1153.4783783055914,
            "rating_q025": 1126.85454522171
        },
        "starling-lm-7b-beta": {
            "rating": 1139.201972872374,
            "rating_q975": 1155.3585921878234,
            "rating_q025": 1123.0453535569245
        },
        "yi-1.5-34b-chat": {
            "rating": 1138.7358296324285,
            "rating_q975": 1150.2510981454095,
            "rating_q025": 1127.2205611194474
        },
        "granite-3.0-8b-instruct": {
            "rating": 1136.724941455031,
            "rating_q975": 1156.2076602338539,
            "rating_q025": 1117.2422226762083
        },
        "llama-2-70b-chat": {
            "rating": 1136.5395162518287,
            "rating_q975": 1150.493445027683,
            "rating_q025": 1122.5855874759743
        },
        "gemma-1.1-7b-it": {
            "rating": 1132.817598310948,
            "rating_q975": 1145.098335644547,
            "rating_q025": 1120.5368609773489
        },
        "zephyr-7b-beta": {
            "rating": 1131.5085106443933,
            "rating_q975": 1169.6662900310605,
            "rating_q025": 1093.350731257726
        },
        "vicuna-13b": {
            "rating": 1124.6038243752378,
            "rating_q975": 1150.9752090558666,
            "rating_q025": 1098.232439694609
        },
        "qwq-32b-preview": {
            "rating": 1115.5446766759633,
            "rating_q975": 1141.745714120689,
            "rating_q025": 1089.3436392312376
        },
        "llama-2-13b-chat": {
            "rating": 1111.8118269494316,
            "rating_q975": 1132.3452371348737,
            "rating_q025": 1091.2784167639895
        },
        "granite-3.1-2b-instruct": {
            "rating": 1111.804431257482,
            "rating_q975": 1139.9828456838154,
            "rating_q025": 1083.6260168311487
        },
        "granite-3.0-2b-instruct": {
            "rating": 1110.8561175115403,
            "rating_q975": 1129.9879109859253,
            "rating_q025": 1091.7243240371554
        },
        "yi-34b-chat": {
            "rating": 1110.5214582668327,
            "rating_q975": 1131.2088688953459,
            "rating_q025": 1089.8340476383196
        },
        "qwen1.5-14b-chat": {
            "rating": 1108.1469329078955,
            "rating_q975": 1123.3900863215922,
            "rating_q025": 1092.9037794941987
        },
        "mistral-7b-instruct-v0.2": {
            "rating": 1088.407038988029,
            "rating_q975": 1105.3375165011757,
            "rating_q025": 1071.4765614748821
        },
        "mistral-7b-instruct": {
            "rating": 1085.3343453796226,
            "rating_q975": 1126.7220130574171,
            "rating_q025": 1043.946677701828
        },
        "gemma-1.1-2b-it": {
            "rating": 1084.5970293640958,
            "rating_q975": 1102.5793474857073,
            "rating_q025": 1066.6147112424842
        },
        "phi-3-mini-4k-instruct-june-2024": {
            "rating": 1074.255113822481,
            "rating_q975": 1090.5899137428928,
            "rating_q025": 1057.9203139020692
        },
        "gemma-7b-it": {
            "rating": 1073.4297861897662,
            "rating_q975": 1096.5201669999615,
            "rating_q025": 1050.339405379571
        },
        "qwen1.5-7b-chat": {
            "rating": 1071.1764457198901,
            "rating_q975": 1105.2844796669804,
            "rating_q025": 1037.0684117728
        },
        "phi-3-mini-4k-instruct": {
            "rating": 1068.2806996358534,
            "rating_q975": 1081.0045179435986,
            "rating_q025": 1055.5568813281081
        },
        "phi-3-mini-128k-instruct": {
            "rating": 1065.625629675097,
            "rating_q975": 1081.3499126641534,
            "rating_q025": 1049.9013466860404
        },
        "smollm2-1.7b-instruct": {
            "rating": 1058.5741314625839,
            "rating_q975": 1089.5196571581725,
            "rating_q025": 1027.6286057669952
        },
        "llama-2-7b-chat": {
            "rating": 1054.522066387617,
            "rating_q975": 1077.5917913942333,
            "rating_q025": 1031.452341381001
        },
        "qwen1.5-4b-chat": {
            "rating": 1040.719742299859,
            "rating_q975": 1065.4560117961407,
            "rating_q025": 1015.9834728035775
        },
        "gemma-2b-it": {
            "rating": 1025.9326303609578,
            "rating_q975": 1062.3161918777928,
            "rating_q025": 989.5490688441226
        },
        "llama-3.2-3b-instruct": {
            "rating": 1007.6920449340566,
            "rating_q975": 1030.9789264693343,
            "rating_q025": 984.405163398779
        },
        "llama-3.2-1b-instruct": {
            "rating": 990.2025852133194,
            "rating_q975": 1013.6860343287054,
            "rating_q025": 966.7191360979333
        },
        "olmo-7b-instruct": {
            "rating": 983.2159063655404,
            "rating_q975": 1011.057545385785,
            "rating_q025": 955.3742673452957
        }
    },
    "spanish": {
        "grok-4.1-thinking": {
            "rating": 1507.7196603361206,
            "rating_q975": 1541.2215844511268,
            "rating_q025": 1474.2177362211144
        },
        "gemini-3-pro": {
            "rating": 1499.313258591307,
            "rating_q975": 1531.69632021523,
            "rating_q025": 1466.930196967384
        },
        "claude-opus-4-5-20251101": {
            "rating": 1475.7868494700263,
            "rating_q975": 1515.447076599057,
            "rating_q025": 1436.1266223409955
        },
        "claude-sonnet-4-5-20250929": {
            "rating": 1467.1484856901025,
            "rating_q975": 1493.9951208535174,
            "rating_q025": 1440.3018505266875
        },
        "claude-opus-4-1-20250805-thinking-16k": {
            "rating": 1456.2848151654218,
            "rating_q975": 1478.2165597940968,
            "rating_q025": 1434.3530705367468
        },
        "gemini-2.5-pro": {
            "rating": 1453.8797127362066,
            "rating_q975": 1472.4969812399202,
            "rating_q025": 1435.262444232493
        },
        "gpt-5.1-high": {
            "rating": 1452.7582046566272,
            "rating_q975": 1486.6663664581383,
            "rating_q025": 1418.850042855116
        },
        "claude-opus-4-1-20250805": {
            "rating": 1448.5375076881537,
            "rating_q975": 1467.6579845905255,
            "rating_q025": 1429.417030785782
        },
        "grok-4.1": {
            "rating": 1448.3875113813583,
            "rating_q975": 1480.7643927745655,
            "rating_q025": 1416.010629988151
        },
        "qwen3-max-preview": {
            "rating": 1445.7488005870734,
            "rating_q975": 1470.0973475225555,
            "rating_q025": 1421.4002536515914
        },
        "chatgpt-4o-latest-20250326": {
            "rating": 1444.643374029727,
            "rating_q975": 1464.6940610991496,
            "rating_q025": 1424.5926869603045
        },
        "gpt-5.1": {
            "rating": 1444.4437320215936,
            "rating_q975": 1477.9286126402587,
            "rating_q025": 1410.9588514029285
        },
        "claude-sonnet-4-5-20250929-thinking-32k": {
            "rating": 1443.673583001422,
            "rating_q975": 1467.4629198768505,
            "rating_q025": 1419.8842461259935
        },
        "ernie-5.0-preview-1103": {
            "rating": 1442.4278946170516,
            "rating_q975": 1485.5288166857051,
            "rating_q025": 1399.326972548398
        },
        "claude-opus-4-5-20251101-thinking-32k": {
            "rating": 1442.2057463795927,
            "rating_q975": 1481.3469564928762,
            "rating_q025": 1403.0645362663092
        },
        "grok-4-1-fast-reasoning": {
            "rating": 1435.6405340726485,
            "rating_q975": 1483.4470152492488,
            "rating_q025": 1387.8340528960482
        },
        "grok-4-fast-chat": {
            "rating": 1433.9736238834319,
            "rating_q975": 1473.6987693348676,
            "rating_q025": 1394.248478431996
        },
        "deepseek-v3.2-thinking": {
            "rating": 1432.2147217557056,
            "rating_q975": 1483.083276621087,
            "rating_q025": 1381.3461668903242
        },
        "glm-4.5": {
            "rating": 1431.2048138966138,
            "rating_q975": 1457.6381137940998,
            "rating_q025": 1404.7715139991278
        },
        "glm-4.6": {
            "rating": 1425.9794647781057,
            "rating_q975": 1452.5282166738702,
            "rating_q025": 1399.4307128823411
        },
        "qwen3-235b-a22b-instruct-2507": {
            "rating": 1424.301003049865,
            "rating_q975": 1444.6146489797836,
            "rating_q025": 1403.9873571199462
        },
        "claude-opus-4-20250514-thinking-16k": {
            "rating": 1420.46814105071,
            "rating_q975": 1443.8687643323763,
            "rating_q025": 1397.067517769044
        },
        "qwen3-next-80b-a3b-instruct": {
            "rating": 1419.2720585600543,
            "rating_q975": 1445.980596930393,
            "rating_q025": 1392.5635201897157
        },
        "gpt-5-high": {
            "rating": 1416.5750084087695,
            "rating_q975": 1440.8217303823922,
            "rating_q025": 1392.3282864351468
        },
        "kimi-k2-thinking-turbo": {
            "rating": 1416.5130945314736,
            "rating_q975": 1449.8966636207974,
            "rating_q025": 1383.1295254421498
        },
        "kimi-k2-0905-preview": {
            "rating": 1416.481610350164,
            "rating_q975": 1452.3384679343862,
            "rating_q025": 1380.6247527659416
        },
        "gpt-5-chat": {
            "rating": 1416.4318878155373,
            "rating_q975": 1440.570178336509,
            "rating_q025": 1392.2935972945656
        },
        "claude-haiku-4-5-20251001": {
            "rating": 1414.8728895314223,
            "rating_q975": 1441.348010226925,
            "rating_q025": 1388.3977688359196
        },
        "grok-4-0709": {
            "rating": 1413.4672021404692,
            "rating_q975": 1435.3421461331598,
            "rating_q025": 1391.5922581477787
        },
        "deepseek-v3.2-exp": {
            "rating": 1412.9238682099465,
            "rating_q975": 1448.8735201231452,
            "rating_q025": 1376.9742162967477
        },
        "o3-2025-04-16": {
            "rating": 1411.619030780012,
            "rating_q975": 1432.8812813065874,
            "rating_q025": 1390.3567802534367
        },
        "deepseek-v3.1-thinking": {
            "rating": 1409.4111541842815,
            "rating_q975": 1443.2354506385245,
            "rating_q025": 1375.5868577300384
        },
        "claude-sonnet-4-20250514": {
            "rating": 1407.0622214101245,
            "rating_q975": 1430.1834875892382,
            "rating_q025": 1383.9409552310108
        },
        "qwen3-235b-a22b-no-thinking": {
            "rating": 1406.9267469911663,
            "rating_q975": 1432.307147730565,
            "rating_q025": 1381.5463462517675
        },
        "longcat-flash-chat": {
            "rating": 1406.8843867914695,
            "rating_q975": 1440.0592692490723,
            "rating_q025": 1373.7095043338668
        },
        "grok-3-preview-02-24": {
            "rating": 1406.579352664472,
            "rating_q975": 1437.968697250205,
            "rating_q025": 1375.190008078739
        },
        "qwen3-vl-235b-a22b-instruct": {
            "rating": 1405.2182571142487,
            "rating_q975": 1439.0984709414388,
            "rating_q025": 1371.3380432870586
        },
        "grok-4-fast-reasoning": {
            "rating": 1405.1740515177505,
            "rating_q975": 1432.7072074812909,
            "rating_q025": 1377.6408955542101
        },
        "qwen3-max-2025-09-23": {
            "rating": 1405.1365243819005,
            "rating_q975": 1436.8478123556376,
            "rating_q025": 1373.4252364081633
        },
        "deepseek-v3.2-exp-thinking": {
            "rating": 1404.1138489053146,
            "rating_q975": 1440.1118102701732,
            "rating_q025": 1368.115887540456
        },
        "mistral-medium-2508": {
            "rating": 1402.1609089870617,
            "rating_q975": 1423.3263887292999,
            "rating_q025": 1380.9954292448235
        },
        "deepseek-v3.1": {
            "rating": 1401.722637022333,
            "rating_q975": 1435.715863191499,
            "rating_q025": 1367.7294108531669
        },
        "gpt-4.1-2025-04-14": {
            "rating": 1399.8623326654588,
            "rating_q975": 1421.2210687154877,
            "rating_q025": 1378.5035966154298
        },
        "gemini-2.5-flash": {
            "rating": 1398.1323213865796,
            "rating_q975": 1416.7053360626248,
            "rating_q025": 1379.5593067105344
        },
        "claude-opus-4-20250514": {
            "rating": 1398.0424785665173,
            "rating_q975": 1420.4231168900305,
            "rating_q025": 1375.661840243004
        },
        "claude-sonnet-4-20250514-thinking-32k": {
            "rating": 1396.0997567965205,
            "rating_q975": 1420.3057012535176,
            "rating_q025": 1371.8938123395235
        },
        "deepseek-r1-0528": {
            "rating": 1393.7894083470765,
            "rating_q975": 1432.6240243977504,
            "rating_q025": 1354.9547922964025
        },
        "deepseek-r1": {
            "rating": 1391.8816690608726,
            "rating_q975": 1443.3340971287764,
            "rating_q025": 1340.4292409929687
        },
        "qwen3-vl-235b-a22b-thinking": {
            "rating": 1390.7756565648867,
            "rating_q975": 1425.7053110839106,
            "rating_q025": 1355.8460020458629
        },
        "gemini-2.5-flash-lite-preview-09-2025-no-thinking": {
            "rating": 1390.490032687254,
            "rating_q975": 1413.5592946900015,
            "rating_q025": 1367.4207706845064
        },
        "gpt-5-nano-high": {
            "rating": 1389.7524559321005,
            "rating_q975": 1434.4269593141526,
            "rating_q025": 1345.0779525500484
        },
        "gemini-2.5-flash-preview-09-2025": {
            "rating": 1389.466545306876,
            "rating_q975": 1413.6077208150639,
            "rating_q025": 1365.3253697986881
        },
        "mai-1-preview": {
            "rating": 1388.9875184823475,
            "rating_q975": 1415.7370389541602,
            "rating_q025": 1362.2379980105347
        },
        "o1-2024-12-17": {
            "rating": 1388.4900776802685,
            "rating_q975": 1436.834954673941,
            "rating_q025": 1340.1452006865961
        },
        "grok-3-mini-beta": {
            "rating": 1386.8976417877316,
            "rating_q975": 1417.3790681139676,
            "rating_q025": 1356.4162154614955
        },
        "o4-mini-2025-04-16": {
            "rating": 1386.2538397242886,
            "rating_q975": 1408.2505141372121,
            "rating_q025": 1364.257165311365
        },
        "qwen3-30b-a3b-instruct-2507": {
            "rating": 1383.2726625407759,
            "rating_q975": 1409.0902100922922,
            "rating_q025": 1357.4551149892595
        },
        "kimi-k2-0711-preview": {
            "rating": 1382.0231404072304,
            "rating_q975": 1411.185810956838,
            "rating_q025": 1352.8604698576228
        },
        "claude-3-7-sonnet-20250219-thinking-32k": {
            "rating": 1381.581008420218,
            "rating_q975": 1408.6231879599402,
            "rating_q025": 1354.5388288804959
        },
        "qwen3-coder-480b-a35b-instruct": {
            "rating": 1380.2563206585612,
            "rating_q975": 1408.777424003333,
            "rating_q025": 1351.7352173137895
        },
        "mistral-medium-2505": {
            "rating": 1379.569564861816,
            "rating_q975": 1408.4543236587908,
            "rating_q025": 1350.684806064841
        },
        "deepseek-v3": {
            "rating": 1378.3244346164836,
            "rating_q975": 1427.197849333762,
            "rating_q025": 1329.4510198992052
        },
        "qwen3-235b-a22b": {
            "rating": 1377.8255902560297,
            "rating_q975": 1407.8186702329424,
            "rating_q025": 1347.832510279117
        },
        "gpt-5-mini-high": {
            "rating": 1377.5393194769354,
            "rating_q975": 1402.4632969747101,
            "rating_q025": 1352.6153419791606
        },
        "ling-flash-2.0": {
            "rating": 1377.503397057145,
            "rating_q975": 1416.5705052892554,
            "rating_q025": 1338.4362888250348
        },
        "step-3": {
            "rating": 1374.8245020805416,
            "rating_q975": 1420.4313870004473,
            "rating_q025": 1329.2176171606359
        },
        "qwen2.5-max": {
            "rating": 1374.1297392700674,
            "rating_q975": 1410.2585383866951,
            "rating_q025": 1338.0009401534396
        },
        "gpt-oss-120b": {
            "rating": 1371.9193050394033,
            "rating_q975": 1396.3990439689737,
            "rating_q025": 1347.4395661098329
        },
        "gemini-2.0-flash-001": {
            "rating": 1370.5855314292285,
            "rating_q975": 1397.2399107613267,
            "rating_q025": 1343.9311520971303
        },
        "mistral-small-2506": {
            "rating": 1368.6717704118837,
            "rating_q975": 1401.3710574664774,
            "rating_q025": 1335.97248335729
        },
        "claude-3-7-sonnet-20250219": {
            "rating": 1367.6173675130542,
            "rating_q975": 1394.0038442811424,
            "rating_q025": 1341.230890744966
        },
        "ring-flash-2.0": {
            "rating": 1366.8040755772709,
            "rating_q975": 1405.5225383078298,
            "rating_q025": 1328.085612846712
        },
        "gemini-2.5-flash-lite-preview-06-17-thinking": {
            "rating": 1366.3703351286579,
            "rating_q975": 1391.156812491724,
            "rating_q025": 1341.5838577655918
        },
        "claude-3-5-sonnet-20241022": {
            "rating": 1364.9612295983923,
            "rating_q975": 1384.853737052179,
            "rating_q025": 1345.0687221446055
        },
        "glm-4.5-air": {
            "rating": 1362.2527075203166,
            "rating_q975": 1386.8819434470242,
            "rating_q025": 1337.6234715936089
        },
        "qwen3-next-80b-a3b-thinking": {
            "rating": 1356.7157312565566,
            "rating_q975": 1387.8646198907134,
            "rating_q025": 1325.5668426224
        },
        "minimax-m1": {
            "rating": 1354.9495894192048,
            "rating_q975": 1379.474383303743,
            "rating_q025": 1330.4247955346666
        },
        "grok-3-mini-high": {
            "rating": 1353.73187862733,
            "rating_q975": 1389.7209981569902,
            "rating_q025": 1317.7427590976697
        },
        "claude-3-5-sonnet-20240620": {
            "rating": 1353.5481661030262,
            "rating_q975": 1374.225515607174,
            "rating_q025": 1332.8708165988785
        },
        "command-a-03-2025": {
            "rating": 1353.5298910883605,
            "rating_q975": 1373.838577553297,
            "rating_q025": 1333.221204623424
        },
        "gpt-4.1-mini-2025-04-14": {
            "rating": 1353.3276074885548,
            "rating_q975": 1377.1469768893212,
            "rating_q025": 1329.5082380877884
        },
        "o1-preview": {
            "rating": 1352.756130803909,
            "rating_q975": 1382.7977868381483,
            "rating_q025": 1322.7144747696696
        },
        "deepseek-v3-0324": {
            "rating": 1351.9346574173233,
            "rating_q975": 1374.4518315482424,
            "rating_q025": 1329.4174832864041
        },
        "gemma-3-27b-it": {
            "rating": 1351.8236831158079,
            "rating_q975": 1374.5057276072912,
            "rating_q025": 1329.1416386243245
        },
        "gemini-1.5-pro-002": {
            "rating": 1350.7325481786556,
            "rating_q975": 1378.9591433666828,
            "rating_q025": 1322.5059529906284
        },
        "glm-4.5v": {
            "rating": 1348.2504155282254,
            "rating_q975": 1394.4711907155329,
            "rating_q025": 1302.029640340918
        },
        "qwq-32b": {
            "rating": 1347.022513714508,
            "rating_q975": 1379.3372647719307,
            "rating_q025": 1314.7077626570854
        },
        "o3-mini-high": {
            "rating": 1345.659208479894,
            "rating_q975": 1395.4692068141655,
            "rating_q025": 1295.8492101456225
        },
        "amazon-nova-experimental-chat-10-09": {
            "rating": 1343.1021854114879,
            "rating_q975": 1386.8894297394766,
            "rating_q025": 1299.3149410834992
        },
        "gpt-4o-2024-05-13": {
            "rating": 1342.6723522057434,
            "rating_q975": 1360.5591151726871,
            "rating_q025": 1324.7855892387997
        },
        "yi-lightning": {
            "rating": 1341.1429186926764,
            "rating_q975": 1372.1960224983115,
            "rating_q025": 1310.0898148870413
        },
        "glm-4-plus": {
            "rating": 1340.686961846202,
            "rating_q975": 1371.485371013689,
            "rating_q025": 1309.8885526787149
        },
        "o1-mini": {
            "rating": 1333.6948661825145,
            "rating_q975": 1360.3836255182468,
            "rating_q025": 1307.0061068467821
        },
        "gemini-2.0-flash-lite-preview-02-05": {
            "rating": 1333.2926805516613,
            "rating_q975": 1377.94450694608,
            "rating_q025": 1288.6408541572425
        },
        "magistral-medium-2506": {
            "rating": 1331.8431233021824,
            "rating_q975": 1373.7265284873656,
            "rating_q025": 1289.9597181169993
        },
        "gpt-4o-2024-08-06": {
            "rating": 1329.7965119449586,
            "rating_q975": 1355.1860751757038,
            "rating_q025": 1304.4069487142135
        },
        "o3-mini": {
            "rating": 1329.5563358726788,
            "rating_q975": 1351.9626024260324,
            "rating_q025": 1307.1500693193252
        },
        "qwen-max-0919": {
            "rating": 1327.7696340454404,
            "rating_q975": 1365.4116554138925,
            "rating_q025": 1290.1276126769883
        },
        "claude-3-5-haiku-20241022": {
            "rating": 1323.5671432963277,
            "rating_q975": 1345.5804607139476,
            "rating_q025": 1301.5538258787078
        },
        "llama-4-maverick-17b-128e-instruct": {
            "rating": 1322.6786870430308,
            "rating_q975": 1346.296225956203,
            "rating_q025": 1299.0611481298586
        },
        "qwen3-30b-a3b": {
            "rating": 1321.1080702130012,
            "rating_q975": 1352.2597256967642,
            "rating_q025": 1289.956414729238
        },
        "minimax-m2": {
            "rating": 1320.3894361297312,
            "rating_q975": 1368.3459179710526,
            "rating_q025": 1272.4329542884097
        },
        "gpt-4-1106-preview": {
            "rating": 1318.6739773978047,
            "rating_q975": 1338.6383593407786,
            "rating_q025": 1298.7095954548308
        },
        "gpt-4-turbo-2024-04-09": {
            "rating": 1316.8937961485026,
            "rating_q975": 1336.0120138233992,
            "rating_q025": 1297.775578473606
        },
        "llama-3.1-405b-instruct-bf16": {
            "rating": 1315.1742528315344,
            "rating_q975": 1344.3149986633412,
            "rating_q025": 1286.0335069997277
        },
        "claude-3-opus-20240229": {
            "rating": 1312.3848528310425,
            "rating_q975": 1329.2793053952353,
            "rating_q025": 1295.4904002668497
        },
        "llama-3.1-405b-instruct-fp8": {
            "rating": 1312.26123416577,
            "rating_q975": 1335.9025825120275,
            "rating_q025": 1288.6198858195125
        },
        "amazon-nova-experimental-chat-10-20": {
            "rating": 1311.4803441467063,
            "rating_q975": 1354.5712903133583,
            "rating_q025": 1268.3893979800544
        },
        "grok-2-2024-08-13": {
            "rating": 1311.21201847995,
            "rating_q975": 1334.1550154327817,
            "rating_q025": 1288.2690215271184
        },
        "gpt-4o-mini-2024-07-18": {
            "rating": 1310.5028023413347,
            "rating_q975": 1332.611900641229,
            "rating_q025": 1288.3937040414403
        },
        "llama-4-scout-17b-16e-instruct": {
            "rating": 1310.3529962708942,
            "rating_q975": 1337.2867378192075,
            "rating_q025": 1283.419254722581
        },
        "grok-2-mini-2024-08-13": {
            "rating": 1310.0557875660684,
            "rating_q975": 1333.5893572349223,
            "rating_q025": 1286.5222178972144
        },
        "gpt-4-0125-preview": {
            "rating": 1308.0832470031112,
            "rating_q975": 1328.5143174128596,
            "rating_q025": 1287.6521765933628
        },
        "mistral-large-2411": {
            "rating": 1307.1191327222534,
            "rating_q975": 1351.3220169075769,
            "rating_q025": 1262.91624853693
        },
        "llama-3.3-70b-instruct": {
            "rating": 1304.2408377093777,
            "rating_q975": 1329.3936539852898,
            "rating_q025": 1279.0880214334657
        },
        "mistral-small-3.1-24b-instruct-2503": {
            "rating": 1302.8327297362098,
            "rating_q975": 1328.0863138226305,
            "rating_q025": 1277.579145649789
        },
        "gemma-3n-e4b-it": {
            "rating": 1301.3419631947022,
            "rating_q975": 1332.6424818842956,
            "rating_q025": 1270.0414445051088
        },
        "gemini-advanced-0514": {
            "rating": 1297.0458827007478,
            "rating_q975": 1319.7824982726056,
            "rating_q025": 1274.30926712889
        },
        "athene-v2-chat": {
            "rating": 1296.5034452378486,
            "rating_q975": 1335.1373043495105,
            "rating_q025": 1257.8695861261867
        },
        "gemini-1.5-pro-001": {
            "rating": 1296.1419893544671,
            "rating_q975": 1316.1125811674983,
            "rating_q025": 1276.171397541436
        },
        "llama-3-70b-instruct": {
            "rating": 1294.915214877767,
            "rating_q975": 1312.091049117125,
            "rating_q025": 1277.739380638409
        },
        "gpt-oss-20b": {
            "rating": 1294.6655405989122,
            "rating_q975": 1336.2784203909735,
            "rating_q025": 1253.052660806851
        },
        "qwen2.5-72b-instruct": {
            "rating": 1292.5181905553509,
            "rating_q975": 1322.4339814458322,
            "rating_q025": 1262.6023996648696
        },
        "athene-70b-0725": {
            "rating": 1291.5673449730484,
            "rating_q975": 1326.272087591132,
            "rating_q025": 1256.8626023549648
        },
        "gemma-2-27b-it": {
            "rating": 1291.2848073321318,
            "rating_q975": 1312.0743724821123,
            "rating_q025": 1270.4952421821513
        },
        "llama-3.1-70b-instruct": {
            "rating": 1290.8353177440613,
            "rating_q975": 1314.5693906261051,
            "rating_q025": 1267.1012448620174
        },
        "mistral-large-2407": {
            "rating": 1287.5499430354485,
            "rating_q975": 1311.855694756796,
            "rating_q025": 1263.2441913141008
        },
        "gpt-4-0314": {
            "rating": 1285.7755661993347,
            "rating_q975": 1311.9263832672812,
            "rating_q025": 1259.6247491313882
        },
        "deepseek-v2.5": {
            "rating": 1284.1458070431913,
            "rating_q975": 1317.6820293665153,
            "rating_q025": 1250.6095847198674
        },
        "gemini-1.5-flash-001": {
            "rating": 1276.6140911693647,
            "rating_q975": 1297.0527726905616,
            "rating_q025": 1256.1754096481677
        },
        "gemini-1.5-flash-002": {
            "rating": 1275.8284959053594,
            "rating_q975": 1308.7236059616343,
            "rating_q025": 1242.9333858490845
        },
        "claude-3-sonnet-20240229": {
            "rating": 1273.3631880620371,
            "rating_q975": 1293.3850607730756,
            "rating_q025": 1253.3413153509987
        },
        "amazon-nova-lite-v1.0": {
            "rating": 1272.608715122253,
            "rating_q975": 1326.394054276458,
            "rating_q025": 1218.823375968048
        },
        "gpt-4-0613": {
            "rating": 1270.8018386263047,
            "rating_q975": 1291.3752934216475,
            "rating_q025": 1250.228383830962
        },
        "phi-4": {
            "rating": 1269.1038320518721,
            "rating_q975": 1320.2820018452753,
            "rating_q025": 1217.925662258469
        },
        "mistral-large-2402": {
            "rating": 1265.7445223253048,
            "rating_q975": 1288.810017354761,
            "rating_q025": 1242.6790272958488
        },
        "gemma-2-9b-it": {
            "rating": 1264.5553800654502,
            "rating_q975": 1288.800634569484,
            "rating_q025": 1240.3101255614165
        },
        "command-r-plus": {
            "rating": 1256.8422668790517,
            "rating_q975": 1277.7522067092232,
            "rating_q025": 1235.9323270488803
        },
        "nemotron-4-340b-instruct": {
            "rating": 1255.1899131749858,
            "rating_q975": 1285.8806057919035,
            "rating_q025": 1224.4992205580681
        },
        "amazon-nova-micro-v1.0": {
            "rating": 1253.861632363112,
            "rating_q975": 1298.960545734895,
            "rating_q025": 1208.762718991329
        },
        "qwen2-72b-instruct": {
            "rating": 1253.6805557005364,
            "rating_q975": 1280.0319148346937,
            "rating_q025": 1227.329196566379
        },
        "gemini-1.5-flash-8b-001": {
            "rating": 1252.0421336993563,
            "rating_q975": 1282.5702255694364,
            "rating_q025": 1221.5140418292763
        },
        "c4ai-aya-expanse-32b": {
            "rating": 1245.090970689703,
            "rating_q975": 1280.6538955043711,
            "rating_q025": 1209.5280458750349
        },
        "claude-3-haiku-20240307": {
            "rating": 1242.944060571208,
            "rating_q975": 1261.5323439280153,
            "rating_q025": 1224.3557772144006
        },
        "mixtral-8x22b-instruct-v0.1": {
            "rating": 1232.1867184296982,
            "rating_q975": 1255.9614627671547,
            "rating_q025": 1208.4119740922417
        },
        "gpt-3.5-turbo-0125": {
            "rating": 1231.1844447379615,
            "rating_q975": 1254.4443393096144,
            "rating_q025": 1207.9245501663086
        },
        "llama-3-8b-instruct": {
            "rating": 1229.6182430030062,
            "rating_q975": 1248.6266398293865,
            "rating_q025": 1210.609846176626
        },
        "gemini-pro-dev-api": {
            "rating": 1229.1903957634422,
            "rating_q975": 1271.4032909279865,
            "rating_q025": 1186.977500598898
        },
        "amazon-nova-pro-v1.0": {
            "rating": 1228.2132143761678,
            "rating_q975": 1277.9770276467893,
            "rating_q025": 1178.4494011055463
        },
        "command-r": {
            "rating": 1227.31702975205,
            "rating_q975": 1252.4678837078393,
            "rating_q025": 1202.1661757962609
        },
        "deepseek-coder-v2": {
            "rating": 1224.4813337714863,
            "rating_q975": 1260.7913352341109,
            "rating_q025": 1188.1713323088618
        },
        "reka-flash-21b-20240226-online": {
            "rating": 1222.0881751591278,
            "rating_q975": 1262.93173157017,
            "rating_q025": 1181.2446187480855
        },
        "qwen1.5-110b-chat": {
            "rating": 1218.0478531811425,
            "rating_q975": 1246.6707358768376,
            "rating_q025": 1189.4249704854474
        },
        "gpt-3.5-turbo-1106": {
            "rating": 1213.884863184215,
            "rating_q975": 1252.8437881229663,
            "rating_q025": 1174.9259382454636
        },
        "mistral-medium": {
            "rating": 1209.10958409075,
            "rating_q975": 1240.0187093914562,
            "rating_q025": 1178.200458790044
        },
        "reka-flash-21b-20240226": {
            "rating": 1204.2247581082793,
            "rating_q975": 1235.2851005564046,
            "rating_q025": 1173.164415660154
        },
        "llama-2-70b-chat": {
            "rating": 1200.5000476002974,
            "rating_q975": 1228.3173658319463,
            "rating_q025": 1172.6827293686486
        },
        "llama-3.1-8b-instruct": {
            "rating": 1191.4958263334715,
            "rating_q975": 1217.7646111479282,
            "rating_q025": 1165.2270415190148
        },
        "qwen1.5-72b-chat": {
            "rating": 1190.3123140510409,
            "rating_q975": 1218.915604514515,
            "rating_q025": 1161.7090235875667
        },
        "gemma-2-2b-it": {
            "rating": 1189.3622621540624,
            "rating_q975": 1215.7201922754502,
            "rating_q025": 1163.0043320326745
        },
        "mixtral-8x7b-instruct-v0.1": {
            "rating": 1183.6972042062582,
            "rating_q975": 1205.86946614974,
            "rating_q025": 1161.5249422627764
        },
        "snowflake-arctic-instruct": {
            "rating": 1181.3802054637852,
            "rating_q975": 1209.965704860396,
            "rating_q025": 1152.7947060671743
        },
        "phi-3-small-8k-instruct": {
            "rating": 1180.903932473482,
            "rating_q975": 1217.5265564225645,
            "rating_q025": 1144.2813085243995
        },
        "qwen1.5-32b-chat": {
            "rating": 1173.6114944165097,
            "rating_q975": 1203.9598586107559,
            "rating_q025": 1143.2631302222635
        },
        "yi-1.5-34b-chat": {
            "rating": 1171.2250143439455,
            "rating_q975": 1200.5130924890277,
            "rating_q025": 1141.9369361988634
        },
        "vicuna-13b": {
            "rating": 1170.582899045445,
            "rating_q975": 1218.7317912380695,
            "rating_q025": 1122.4340068528204
        },
        "phi-3-medium-4k-instruct": {
            "rating": 1168.6070123674003,
            "rating_q975": 1198.153263606038,
            "rating_q025": 1139.0607611287626
        },
        "qwen1.5-14b-chat": {
            "rating": 1161.413978842613,
            "rating_q975": 1196.0433037420696,
            "rating_q025": 1126.7846539431564
        },
        "dbrx-instruct-preview": {
            "rating": 1160.0599952542755,
            "rating_q975": 1191.376421561359,
            "rating_q025": 1128.743568947192
        },
        "gemma-1.1-7b-it": {
            "rating": 1152.0512029932688,
            "rating_q975": 1183.2865518246713,
            "rating_q025": 1120.8158541618664
        },
        "llama-2-13b-chat": {
            "rating": 1152.0145356639482,
            "rating_q975": 1190.568877318928,
            "rating_q025": 1113.4601940089685
        },
        "phi-3-mini-4k-instruct": {
            "rating": 1151.4186145274102,
            "rating_q975": 1182.702835362596,
            "rating_q025": 1120.1343936922244
        },
        "vicuna-33b": {
            "rating": 1151.1283593640837,
            "rating_q975": 1187.9065588866367,
            "rating_q025": 1114.3501598415307
        },
        "phi-3-mini-128k-instruct": {
            "rating": 1148.7561118185008,
            "rating_q975": 1182.3531969060787,
            "rating_q025": 1115.159026730923
        },
        "zephyr-7b-beta": {
            "rating": 1148.4915130710629,
            "rating_q975": 1202.9885738467958,
            "rating_q025": 1093.99445229533
        },
        "yi-34b-chat": {
            "rating": 1137.0024639948033,
            "rating_q975": 1177.4837656617544,
            "rating_q025": 1096.5211623278522
        },
        "mistral-7b-instruct-v0.2": {
            "rating": 1104.004243013288,
            "rating_q975": 1148.3988659331167,
            "rating_q025": 1059.6096200934594
        },
        "gemma-1.1-2b-it": {
            "rating": 1093.3981143840838,
            "rating_q975": 1142.9501060068726,
            "rating_q025": 1043.846122761295
        },
        "llama-2-7b-chat": {
            "rating": 1073.6393266161565,
            "rating_q975": 1124.2307661220584,
            "rating_q025": 1023.0478871102546
        }
    }
}