{
    "chinese": {
        "gemini-2.5-pro": {
            "rating": 1501.6545576365886,
            "rating_q975": 1517.178290751966,
            "rating_q025": 1486.1308245212113
        },
        "qwen-max-2025-08-15": {
            "rating": 1479.8962455676615,
            "rating_q975": 1515.4952700359647,
            "rating_q025": 1444.2972210993582
        },
        "deepseek-v3.1-thinking": {
            "rating": 1470.5093706141963,
            "rating_q975": 1506.2111278425532,
            "rating_q025": 1434.8076133858394
        },
        "o3-2025-04-16": {
            "rating": 1466.21657920131,
            "rating_q975": 1480.50630106481,
            "rating_q025": 1451.92685733781
        },
        "qwen3-235b-a22b-instruct-2507": {
            "rating": 1463.9500903515104,
            "rating_q975": 1486.501506079903,
            "rating_q025": 1441.3986746231178
        },
        "claude-opus-4-1-20250805": {
            "rating": 1463.7119677345108,
            "rating_q975": 1487.4700599236105,
            "rating_q025": 1439.9538755454114
        },
        "chatgpt-4o-latest-20250326": {
            "rating": 1463.494018934882,
            "rating_q975": 1477.3887316305845,
            "rating_q025": 1449.5993062391797
        },
        "deepseek-v3.1": {
            "rating": 1457.677814722231,
            "rating_q975": 1491.9364970796728,
            "rating_q025": 1423.4191323647892
        },
        "claude-opus-4-1-20250805-thinking-16k": {
            "rating": 1450.9406432226024,
            "rating_q975": 1480.2996038343429,
            "rating_q025": 1421.581682610862
        },
        "qwen3-235b-a22b-thinking-2507": {
            "rating": 1450.4047062537863,
            "rating_q975": 1479.746514444701,
            "rating_q025": 1421.0628980628717
        },
        "kimi-k2-0711-preview": {
            "rating": 1449.971600660854,
            "rating_q975": 1469.9963771547364,
            "rating_q025": 1429.9468241669715
        },
        "gpt-5-high": {
            "rating": 1449.9433926058834,
            "rating_q975": 1476.7682154904942,
            "rating_q025": 1423.118569721273
        },
        "gemini-2.5-flash": {
            "rating": 1444.474508183767,
            "rating_q975": 1458.687776033236,
            "rating_q025": 1430.261240334298
        },
        "deepseek-r1-0528": {
            "rating": 1443.0324040962125,
            "rating_q975": 1461.4360746227499,
            "rating_q025": 1424.628733569675
        },
        "gpt-4.5-preview-2025-02-27": {
            "rating": 1442.3867455108373,
            "rating_q975": 1460.8741275639295,
            "rating_q025": 1423.899363457745
        },
        "claude-opus-4-20250514-thinking-16k": {
            "rating": 1438.5044056964014,
            "rating_q975": 1456.1768205999472,
            "rating_q025": 1420.8319907928555
        },
        "gpt-5-chat": {
            "rating": 1435.9407402747518,
            "rating_q975": 1463.8419906652334,
            "rating_q025": 1408.0394898842703
        },
        "claude-opus-4-20250514": {
            "rating": 1435.3579981155222,
            "rating_q975": 1450.0776111293073,
            "rating_q025": 1420.6383851017367
        },
        "grok-4-0709": {
            "rating": 1432.8318480000733,
            "rating_q975": 1454.0037644536023,
            "rating_q025": 1411.659931546544
        },
        "qwen3-30b-a3b-instruct-2507": {
            "rating": 1428.9955816197203,
            "rating_q975": 1456.274476488974,
            "rating_q025": 1401.7166867504664
        },
        "grok-3-preview-02-24": {
            "rating": 1427.8237483402977,
            "rating_q975": 1441.6578951533086,
            "rating_q025": 1413.989601527287
        },
        "glm-4.5": {
            "rating": 1427.0331931055814,
            "rating_q975": 1451.997310453213,
            "rating_q025": 1402.0690757579496
        },
        "qwen3-235b-a22b-no-thinking": {
            "rating": 1426.5951000159357,
            "rating_q975": 1442.669681478498,
            "rating_q025": 1410.5205185533734
        },
        "o1-2024-12-17": {
            "rating": 1424.3016166582784,
            "rating_q975": 1437.6580308117996,
            "rating_q025": 1410.9452025047574
        },
        "gpt-5-mini-high": {
            "rating": 1424.2521831037807,
            "rating_q975": 1457.7905033243708,
            "rating_q025": 1390.7138628831904
        },
        "deepseek-r1": {
            "rating": 1419.5546585672591,
            "rating_q975": 1436.6429689214538,
            "rating_q025": 1402.4663482130647
        },
        "mistral-medium-2508": {
            "rating": 1419.1091634516176,
            "rating_q975": 1451.3087726385334,
            "rating_q025": 1386.9095542647017
        },
        "hunyuan-t1-20250711": {
            "rating": 1418.3586746245767,
            "rating_q975": 1451.8397052020166,
            "rating_q025": 1384.8776440471368
        },
        "hunyuan-turbos-20250416": {
            "rating": 1414.7857422244394,
            "rating_q975": 1440.0013936607293,
            "rating_q025": 1389.5700907881494
        },
        "deepseek-v3-0324": {
            "rating": 1410.9421721770275,
            "rating_q975": 1425.5934575565666,
            "rating_q025": 1396.2908867974884
        },
        "o3-mini-high": {
            "rating": 1403.4518418591156,
            "rating_q975": 1419.7780377926001,
            "rating_q025": 1387.125645925631
        },
        "gpt-4.1-2025-04-14": {
            "rating": 1402.5236875967128,
            "rating_q975": 1418.516072645747,
            "rating_q025": 1386.5313025476785
        },
        "mai-1-preview": {
            "rating": 1397.8518347474799,
            "rating_q975": 1430.4896323256296,
            "rating_q025": 1365.2140371693304
        },
        "claude-sonnet-4-20250514-thinking-32k": {
            "rating": 1397.5126269299783,
            "rating_q975": 1415.3752378206655,
            "rating_q025": 1379.6500160392911
        },
        "claude-sonnet-4-20250514": {
            "rating": 1397.2233537334935,
            "rating_q975": 1412.8559775977453,
            "rating_q025": 1381.5907298692418
        },
        "glm-4-plus-0111": {
            "rating": 1395.6679056607418,
            "rating_q975": 1424.798476600243,
            "rating_q025": 1366.5373347212405
        },
        "glm-4.5-air": {
            "rating": 1395.3706687717056,
            "rating_q975": 1421.5576732105562,
            "rating_q025": 1369.1836643328547
        },
        "gpt-5-nano-high": {
            "rating": 1388.6817639691744,
            "rating_q975": 1425.2546102182312,
            "rating_q025": 1352.1089177201177
        },
        "o4-mini-2025-04-16": {
            "rating": 1388.573599691725,
            "rating_q975": 1404.5766279902766,
            "rating_q025": 1372.5705713931732
        },
        "hunyuan-turbo-0110": {
            "rating": 1387.1120207256104,
            "rating_q975": 1423.7218836753698,
            "rating_q025": 1350.5021577758512
        },
        "qwen2.5-max": {
            "rating": 1387.0548606751295,
            "rating_q975": 1399.4786471773944,
            "rating_q025": 1374.6310741728644
        },
        "qwen3-coder-480b-a35b-instruct": {
            "rating": 1386.3147494294178,
            "rating_q975": 1412.5973814358606,
            "rating_q025": 1360.0321174229748
        },
        "qwen3-235b-a22b": {
            "rating": 1386.0739730808893,
            "rating_q975": 1402.5583392266012,
            "rating_q025": 1369.5896069351777
        },
        "gemini-2.0-flash-001": {
            "rating": 1384.0600018541556,
            "rating_q975": 1396.0116088828067,
            "rating_q025": 1372.1083948255043
        },
        "claude-3-7-sonnet-20250219-thinking-32k": {
            "rating": 1383.5556880515796,
            "rating_q975": 1397.045471518612,
            "rating_q025": 1370.0659045845473
        },
        "gpt-oss-120b": {
            "rating": 1382.0921321224694,
            "rating_q975": 1409.4531288713113,
            "rating_q025": 1354.7311353736277
        },
        "grok-3-mini-high": {
            "rating": 1382.001216798054,
            "rating_q975": 1404.6671118327467,
            "rating_q025": 1359.335321763361
        },
        "minimax-m1": {
            "rating": 1379.3438653245935,
            "rating_q975": 1397.469846201474,
            "rating_q025": 1361.2178844477132
        },
        "mistral-medium-2505": {
            "rating": 1378.8949723461758,
            "rating_q975": 1393.5417859576103,
            "rating_q025": 1364.2481587347415
        },
        "hunyuan-large-2025-02-10": {
            "rating": 1378.4664247381327,
            "rating_q975": 1410.8104460439588,
            "rating_q025": 1346.1224034323066
        },
        "o1-preview": {
            "rating": 1377.2872565976465,
            "rating_q975": 1388.6180007885587,
            "rating_q025": 1365.9565124067344
        },
        "qwq-32b": {
            "rating": 1374.7064376118342,
            "rating_q975": 1390.6225800193783,
            "rating_q025": 1358.7902952042903
        },
        "grok-3-mini-beta": {
            "rating": 1374.6332928967852,
            "rating_q975": 1392.6873488412211,
            "rating_q025": 1356.579236952349
        },
        "gpt-4.1-mini-2025-04-14": {
            "rating": 1371.8161792116746,
            "rating_q975": 1388.00857249289,
            "rating_q025": 1355.6237859304592
        },
        "qwen-plus-0125": {
            "rating": 1369.3212617956437,
            "rating_q975": 1395.9023697638324,
            "rating_q025": 1342.740153827455
        },
        "claude-3-7-sonnet-20250219": {
            "rating": 1368.2025114159305,
            "rating_q975": 1380.7649341732417,
            "rating_q025": 1355.6400886586193
        },
        "qwen3-30b-a3b": {
            "rating": 1366.8319809127377,
            "rating_q975": 1383.3866268311056,
            "rating_q025": 1350.2773349943698
        },
        "gemini-1.5-pro-002": {
            "rating": 1365.840312963136,
            "rating_q975": 1374.7115359222557,
            "rating_q025": 1356.9690900040164
        },
        "gemma-3-27b-it": {
            "rating": 1363.598234604596,
            "rating_q975": 1377.695258815335,
            "rating_q025": 1349.5012103938573
        },
        "gemini-2.0-flash-lite-preview-02-05": {
            "rating": 1362.70877909953,
            "rating_q975": 1376.7617249678624,
            "rating_q025": 1348.6558332311977
        },
        "deepseek-v3": {
            "rating": 1362.0852560682554,
            "rating_q975": 1376.6987617056436,
            "rating_q025": 1347.4717504308674
        },
        "qwen3-32b": {
            "rating": 1359.871599191791,
            "rating_q975": 1394.596980171831,
            "rating_q025": 1325.1462182117507
        },
        "gpt-oss-20b": {
            "rating": 1355.778642748189,
            "rating_q975": 1384.6324518750037,
            "rating_q025": 1326.9248336213743
        },
        "o3-mini": {
            "rating": 1354.9404822447316,
            "rating_q975": 1366.023430219251,
            "rating_q025": 1343.8575342702122
        },
        "claude-3-5-sonnet-20241022": {
            "rating": 1354.6719920516923,
            "rating_q975": 1362.3324436126516,
            "rating_q025": 1347.0115404907333
        },
        "yi-lightning": {
            "rating": 1354.6151239461274,
            "rating_q975": 1365.7996786344554,
            "rating_q025": 1343.4305692577996
        },
        "hunyuan-turbos-20250226": {
            "rating": 1354.4153496317692,
            "rating_q975": 1391.7325763976621,
            "rating_q025": 1317.0981228658763
        },
        "hunyuan-standard-2025-02-10": {
            "rating": 1352.5937384000617,
            "rating_q975": 1383.2462404454159,
            "rating_q025": 1321.9412363547076
        },
        "step-1o-turbo-202506": {
            "rating": 1351.8921373211865,
            "rating_q975": 1377.411111087687,
            "rating_q025": 1326.3731635546862
        },
        "step-2-16k-exp-202412": {
            "rating": 1350.734012147118,
            "rating_q975": 1383.0658994464266,
            "rating_q025": 1318.402124847809
        },
        "deepseek-v2.5-1210": {
            "rating": 1348.8163609012863,
            "rating_q975": 1374.4904024153939,
            "rating_q025": 1323.1423193871788
        },
        "mistral-small-2506": {
            "rating": 1344.4582176217584,
            "rating_q975": 1365.4874954873485,
            "rating_q025": 1323.4289397561683
        },
        "o1-mini": {
            "rating": 1342.322059323785,
            "rating_q975": 1351.3677600167127,
            "rating_q025": 1333.2763586308574
        },
        "command-a-03-2025": {
            "rating": 1336.2855831951945,
            "rating_q975": 1350.1263845668914,
            "rating_q025": 1322.4447818234978
        },
        "amazon-nova-experimental-chat-05-14": {
            "rating": 1336.2850443552422,
            "rating_q975": 1356.349012799563,
            "rating_q025": 1316.2210759109212
        },
        "gemini-advanced-0514": {
            "rating": 1336.0822756258574,
            "rating_q975": 1346.1651418387357,
            "rating_q025": 1325.9994094129793
        },
        "claude-3-5-sonnet-20240620": {
            "rating": 1335.712913187949,
            "rating_q975": 1343.864711704464,
            "rating_q025": 1327.5611146714336
        },
        "gemma-3n-e4b-it": {
            "rating": 1334.8011753940045,
            "rating_q975": 1356.1796843777106,
            "rating_q025": 1313.4226664102987
        },
        "glm-4-plus": {
            "rating": 1333.7093530113607,
            "rating_q975": 1345.550092458348,
            "rating_q025": 1321.8686135643734
        },
        "grok-2-2024-08-13": {
            "rating": 1332.4492045619397,
            "rating_q975": 1340.7367346910303,
            "rating_q025": 1324.1616744328492
        },
        "gemini-1.5-pro-001": {
            "rating": 1331.3207105612516,
            "rating_q975": 1339.916689238604,
            "rating_q025": 1322.7247318838995
        },
        "gpt-4o-2024-05-13": {
            "rating": 1329.8926746666134,
            "rating_q975": 1337.0842203347809,
            "rating_q025": 1322.7011289984462
        },
        "athene-v2-chat": {
            "rating": 1327.267420732862,
            "rating_q975": 1340.2781856056176,
            "rating_q025": 1314.2566558601063
        },
        "llama-4-maverick-17b-128e-instruct": {
            "rating": 1323.9063399789384,
            "rating_q975": 1339.4108342254538,
            "rating_q025": 1308.401845732423
        },
        "qwen2.5-plus-1127": {
            "rating": 1323.842772790861,
            "rating_q975": 1345.7349376070838,
            "rating_q025": 1301.9506079746384
        },
        "deepseek-v2.5": {
            "rating": 1323.6253040947645,
            "rating_q975": 1335.64408703851,
            "rating_q025": 1311.6065211510188
        },
        "gpt-4o-2024-08-06": {
            "rating": 1321.1727961268293,
            "rating_q975": 1330.681716384034,
            "rating_q025": 1311.663875869625
        },
        "gemini-1.5-flash-002": {
            "rating": 1320.1749971928057,
            "rating_q975": 1330.5716445439582,
            "rating_q025": 1309.778349841653
        },
        "claude-3-opus-20240229": {
            "rating": 1317.3251620554756,
            "rating_q975": 1323.9394508429596,
            "rating_q025": 1310.710873267992
        },
        "qwen2.5-72b-instruct": {
            "rating": 1314.0312705371366,
            "rating_q975": 1323.8943133091623,
            "rating_q025": 1304.1682277651112
        },
        "llama-3.1-405b-instruct-bf16": {
            "rating": 1312.1418827774364,
            "rating_q975": 1322.2620809146863,
            "rating_q025": 1302.0216846401865
        },
        "gpt-4.1-nano-2025-04-14": {
            "rating": 1310.8501705405297,
            "rating_q975": 1345.5768200453842,
            "rating_q025": 1276.1235210356754
        },
        "gpt-4-turbo-2024-04-09": {
            "rating": 1308.5130252167633,
            "rating_q975": 1316.6320324580447,
            "rating_q025": 1300.3940179754816
        },
        "gpt-4-1106-preview": {
            "rating": 1307.7308518657915,
            "rating_q975": 1316.4732671868653,
            "rating_q025": 1298.9884365447176
        },
        "gpt-4o-mini-2024-07-18": {
            "rating": 1307.4470816596286,
            "rating_q975": 1315.4111175681132,
            "rating_q025": 1299.4830457511441
        },
        "llama-3.3-nemotron-49b-super-v1": {
            "rating": 1307.010662085277,
            "rating_q975": 1341.3690819463015,
            "rating_q025": 1272.6522422242524
        },
        "llama-4-scout-17b-16e-instruct": {
            "rating": 1306.6469340616984,
            "rating_q975": 1326.836958709974,
            "rating_q025": 1286.4569094134229
        },
        "llama-3.1-405b-instruct-fp8": {
            "rating": 1306.3394317860675,
            "rating_q975": 1314.8023389346808,
            "rating_q025": 1297.8765246374542
        },
        "grok-2-mini-2024-08-13": {
            "rating": 1304.292478204371,
            "rating_q975": 1313.086180965232,
            "rating_q025": 1295.49877544351
        },
        "gpt-4-0125-preview": {
            "rating": 1303.8273885607064,
            "rating_q975": 1312.3273639329134,
            "rating_q025": 1295.3274131884996
        },
        "claude-3-5-haiku-20241022": {
            "rating": 1303.7998641185523,
            "rating_q975": 1313.8210393229413,
            "rating_q025": 1293.7786889141635
        },
        "qwen-max-0919": {
            "rating": 1303.5846257660623,
            "rating_q975": 1318.0820986621195,
            "rating_q025": 1289.0871528700054
        },
        "hunyuan-large-vision": {
            "rating": 1300.757726405979,
            "rating_q975": 1336.3566162391003,
            "rating_q025": 1265.1588365728576
        },
        "reka-core-20240904": {
            "rating": 1299.3522837457276,
            "rating_q975": 1321.387728030593,
            "rating_q025": 1277.3168394608624
        },
        "llama-3.1-nemotron-70b-instruct": {
            "rating": 1297.674020794783,
            "rating_q975": 1318.1024572265655,
            "rating_q025": 1277.2455843630005
        },
        "glm-4-0520": {
            "rating": 1297.4045459114263,
            "rating_q975": 1313.6118264155352,
            "rating_q025": 1281.1972654073172
        },
        "llama-3.1-tulu-3-70b": {
            "rating": 1296.7580463990378,
            "rating_q975": 1332.683608868356,
            "rating_q025": 1260.8324839297195
        },
        "mistral-large-2407": {
            "rating": 1296.2841224447775,
            "rating_q975": 1305.7914455201217,
            "rating_q025": 1286.7767993694335
        },
        "qwen2-72b-instruct": {
            "rating": 1293.2666271624266,
            "rating_q975": 1303.6807952639322,
            "rating_q025": 1282.8524590609213
        },
        "reka-flash-20240904": {
            "rating": 1292.7694577913408,
            "rating_q975": 1314.9452461183096,
            "rating_q025": 1270.5936694643717
        },
        "mistral-large-2411": {
            "rating": 1291.8463181079135,
            "rating_q975": 1304.4355250028364,
            "rating_q025": 1279.2571112129906
        },
        "athene-70b-0725": {
            "rating": 1291.8095330909844,
            "rating_q975": 1305.5425749062485,
            "rating_q025": 1278.0764912757202
        },
        "gemma-2-27b-it": {
            "rating": 1288.4917783940073,
            "rating_q975": 1296.0207058102924,
            "rating_q025": 1280.962850977722
        },
        "command-r-plus-08-2024": {
            "rating": 1287.3303719924731,
            "rating_q975": 1306.03269790371,
            "rating_q025": 1268.6280460812363
        },
        "gemini-1.5-flash-001": {
            "rating": 1286.8393559691567,
            "rating_q975": 1295.818073700896,
            "rating_q025": 1277.8606382374176
        },
        "hunyuan-standard-256k": {
            "rating": 1284.640133754567,
            "rating_q975": 1316.8453302755008,
            "rating_q025": 1252.4349372336333
        },
        "amazon-nova-pro-v1.0": {
            "rating": 1284.3536619955053,
            "rating_q975": 1297.722950938788,
            "rating_q025": 1270.9843730522227
        },
        "gemma-2-9b-it-simpo": {
            "rating": 1283.1205340371707,
            "rating_q975": 1303.0406097722146,
            "rating_q025": 1263.200458302127
        },
        "deepseek-coder-v2": {
            "rating": 1281.3795839327777,
            "rating_q975": 1295.477951501129,
            "rating_q025": 1267.2812163644267
        },
        "llama-3.3-70b-instruct": {
            "rating": 1280.3976932483945,
            "rating_q975": 1290.6435819618675,
            "rating_q025": 1270.1518045349212
        },
        "magistral-medium-2506": {
            "rating": 1280.0274022669055,
            "rating_q975": 1308.6721600681021,
            "rating_q025": 1251.3826444657084
        },
        "nemotron-4-340b-instruct": {
            "rating": 1280.0071798129104,
            "rating_q975": 1292.3039819985595,
            "rating_q025": 1267.7103776272613
        },
        "gpt-4-0314": {
            "rating": 1277.2336088644943,
            "rating_q975": 1287.95062735309,
            "rating_q025": 1266.5165903758989
        },
        "qwen1.5-72b-chat": {
            "rating": 1274.0226280426627,
            "rating_q975": 1285.2384551534815,
            "rating_q025": 1262.8068009318442
        },
        "qwen1.5-110b-chat": {
            "rating": 1272.4171223941132,
            "rating_q975": 1284.5610840563695,
            "rating_q025": 1260.273160731857
        },
        "mistral-small-3.1-24b-instruct-2503": {
            "rating": 1270.6885145224967,
            "rating_q975": 1290.542079717604,
            "rating_q025": 1250.834949327389
        },
        "qwen2.5-coder-32b-instruct": {
            "rating": 1269.8797883946,
            "rating_q975": 1293.4865428707926,
            "rating_q025": 1246.2730339184075
        },
        "llama-3.1-70b-instruct": {
            "rating": 1269.6223215011396,
            "rating_q975": 1278.268815132208,
            "rating_q025": 1260.9758278700715
        },
        "claude-3-sonnet-20240229": {
            "rating": 1269.138744767321,
            "rating_q975": 1277.131181383623,
            "rating_q025": 1261.1463081510192
        },
        "jamba-1.5-large": {
            "rating": 1268.9324452136748,
            "rating_q975": 1289.8587452487836,
            "rating_q025": 1248.0061451785664
        },
        "llama-3.1-nemotron-51b-instruct": {
            "rating": 1267.9177563211792,
            "rating_q975": 1294.7762692028107,
            "rating_q025": 1241.0592434395476
        },
        "gemini-1.5-flash-8b-001": {
            "rating": 1267.6882087448214,
            "rating_q975": 1278.3189919321553,
            "rating_q025": 1257.0574255574875
        },
        "yi-1.5-34b-chat": {
            "rating": 1267.4956578865654,
            "rating_q975": 1279.2963510544623,
            "rating_q025": 1255.6949647186686
        },
        "amazon-nova-lite-v1.0": {
            "rating": 1265.1164991783908,
            "rating_q975": 1280.2477330931436,
            "rating_q025": 1249.985265263638
        },
        "c4ai-aya-expanse-32b": {
            "rating": 1264.977052889698,
            "rating_q975": 1276.5247092595685,
            "rating_q025": 1253.4293965198272
        },
        "command-r-plus": {
            "rating": 1262.981778395581,
            "rating_q975": 1271.5925153207181,
            "rating_q025": 1254.371041470444
        },
        "phi-4": {
            "rating": 1261.5011466002745,
            "rating_q975": 1276.1037500595103,
            "rating_q025": 1246.8985431410388
        },
        "qwen1.5-32b-chat": {
            "rating": 1259.7131671573047,
            "rating_q975": 1272.0408766835367,
            "rating_q025": 1247.3854576310725
        },
        "mistral-small-24b-instruct-2501": {
            "rating": 1257.0654793225067,
            "rating_q975": 1273.8529146911471,
            "rating_q025": 1240.2780439538662
        },
        "command-r-08-2024": {
            "rating": 1256.499592858954,
            "rating_q975": 1275.5985567193923,
            "rating_q025": 1237.400628998516
        },
        "amazon-nova-micro-v1.0": {
            "rating": 1256.304500057689,
            "rating_q975": 1271.4805799447602,
            "rating_q025": 1241.1284201706183
        },
        "gemma-2-9b-it": {
            "rating": 1255.211706272365,
            "rating_q975": 1263.7337324012356,
            "rating_q025": 1246.6896801434946
        },
        "ministral-8b-2410": {
            "rating": 1252.5780827472536,
            "rating_q975": 1276.8614181355667,
            "rating_q025": 1228.2947473589404
        },
        "internlm2_5-20b-chat": {
            "rating": 1246.7328745798022,
            "rating_q975": 1264.0901628730467,
            "rating_q025": 1229.3755862865582
        },
        "gpt-4-0613": {
            "rating": 1246.2582471565752,
            "rating_q975": 1255.5384565661413,
            "rating_q025": 1236.9780377470092
        },
        "yi-34b-chat": {
            "rating": 1243.2614858577124,
            "rating_q975": 1260.653030554506,
            "rating_q025": 1225.8699411609189
        },
        "olmo-2-0325-32b-instruct": {
            "rating": 1241.9137468484332,
            "rating_q975": 1275.7805718827012,
            "rating_q025": 1208.0469218141652
        },
        "claude-3-haiku-20240307": {
            "rating": 1240.7668788745475,
            "rating_q975": 1248.3889529708028,
            "rating_q025": 1233.1448047782922
        },
        "qwq-32b-preview": {
            "rating": 1237.4641183250799,
            "rating_q975": 1276.160217107874,
            "rating_q025": 1198.7680195422859
        },
        "qwen1.5-14b-chat": {
            "rating": 1235.8139142641357,
            "rating_q975": 1248.7571486031652,
            "rating_q025": 1222.8706799251063
        },
        "command-r": {
            "rating": 1232.8986392064007,
            "rating_q975": 1242.5449019526968,
            "rating_q025": 1223.2523764601049
        },
        "c4ai-aya-expanse-8b": {
            "rating": 1231.4079013326157,
            "rating_q975": 1253.7992060722645,
            "rating_q025": 1209.0165965929668
        },
        "reka-flash-21b-20240226-online": {
            "rating": 1226.7619067527673,
            "rating_q975": 1241.0602285201794,
            "rating_q025": 1212.4635849853553
        },
        "deepseek-llm-67b-chat": {
            "rating": 1224.6496945089273,
            "rating_q975": 1265.6604477934823,
            "rating_q025": 1183.6389412243723
        },
        "gemini-pro-dev-api": {
            "rating": 1224.4298265824632,
            "rating_q975": 1241.240668380005,
            "rating_q025": 1207.6189847849214
        },
        "qwen1.5-7b-chat": {
            "rating": 1218.3033053783672,
            "rating_q975": 1246.2979416585417,
            "rating_q025": 1190.3086690981927
        },
        "reka-flash-21b-20240226": {
            "rating": 1218.2903791860595,
            "rating_q975": 1230.9120849305798,
            "rating_q025": 1205.6686734415393
        },
        "llama-3.1-tulu-3-8b": {
            "rating": 1216.3716342767693,
            "rating_q975": 1252.7891452850452,
            "rating_q025": 1179.9541232684933
        },
        "jamba-1.5-mini": {
            "rating": 1212.481058386257,
            "rating_q975": 1233.156025395012,
            "rating_q025": 1191.806091377502
        },
        "gemini-pro": {
            "rating": 1210.873415385746,
            "rating_q975": 1248.1780224541194,
            "rating_q025": 1173.5688083173727
        },
        "granite-3.1-8b-instruct": {
            "rating": 1210.7540282017171,
            "rating_q975": 1248.7962663455728,
            "rating_q025": 1172.7117900578612
        },
        "granite-3.1-2b-instruct": {
            "rating": 1206.7792521716924,
            "rating_q975": 1244.3497268429392,
            "rating_q025": 1169.2087775004459
        },
        "mixtral-8x22b-instruct-v0.1": {
            "rating": 1204.301561929854,
            "rating_q975": 1214.2848995008421,
            "rating_q025": 1194.3182243588656
        },
        "mistral-large-2402": {
            "rating": 1202.4330444761085,
            "rating_q975": 1212.0220448322634,
            "rating_q025": 1192.8440441199539
        },
        "gpt-3.5-turbo-0125": {
            "rating": 1199.6661912607315,
            "rating_q975": 1208.9027115265653,
            "rating_q025": 1190.4296709948976
        },
        "llama-3.1-8b-instruct": {
            "rating": 1198.6226724548799,
            "rating_q975": 1207.9980314705454,
            "rating_q025": 1189.2473134392144
        },
        "llama-3-70b-instruct": {
            "rating": 1195.1433476615025,
            "rating_q975": 1202.8841415898796,
            "rating_q025": 1187.4025537331254
        },
        "phi-3-medium-4k-instruct": {
            "rating": 1194.9503637110975,
            "rating_q975": 1206.8050036141847,
            "rating_q025": 1183.0957238080105
        },
        "qwen-14b-chat": {
            "rating": 1194.6292682698354,
            "rating_q975": 1237.1483401780335,
            "rating_q025": 1152.1101963616372
        },
        "gemma-2-2b-it": {
            "rating": 1189.7700770948209,
            "rating_q975": 1199.7420578347712,
            "rating_q025": 1179.7980963548703
        },
        "mistral-medium": {
            "rating": 1189.5547733262854,
            "rating_q975": 1202.205050000879,
            "rating_q025": 1176.9044966516917
        },
        "zephyr-orpo-141b-A35b-v0.1": {
            "rating": 1180.3404699759058,
            "rating_q975": 1202.3114084554413,
            "rating_q025": 1158.3695314963704
        },
        "starling-lm-7b-beta": {
            "rating": 1176.0015626350546,
            "rating_q975": 1190.0439044141715,
            "rating_q025": 1161.959220855938
        },
        "openchat-3.5-0106": {
            "rating": 1173.6017567443532,
            "rating_q975": 1190.3479244359644,
            "rating_q025": 1156.855589052742
        },
        "dbrx-instruct-preview": {
            "rating": 1172.3614605736398,
            "rating_q975": 1184.4132962167987,
            "rating_q025": 1160.3096249304808
        },
        "snowflake-arctic-instruct": {
            "rating": 1171.3714506348342,
            "rating_q975": 1184.133008954184,
            "rating_q025": 1158.609892315484
        },
        "openchat-3.5": {
            "rating": 1169.89122509169,
            "rating_q975": 1201.4609911133944,
            "rating_q025": 1138.3214590699854
        },
        "granite-3.0-2b-instruct": {
            "rating": 1168.2901093355015,
            "rating_q975": 1190.9685553999898,
            "rating_q025": 1145.611663271013
        },
        "gemma-1.1-7b-it": {
            "rating": 1165.7373134757884,
            "rating_q975": 1177.3353609027695,
            "rating_q025": 1154.1392660488073
        },
        "granite-3.0-8b-instruct": {
            "rating": 1163.389423403396,
            "rating_q975": 1186.2255578628412,
            "rating_q025": 1140.5532889439505
        },
        "llama-3-8b-instruct": {
            "rating": 1160.2146575713855,
            "rating_q975": 1168.6974905396135,
            "rating_q025": 1151.7318246031573
        },
        "chatglm3-6b": {
            "rating": 1158.6792939361703,
            "rating_q975": 1200.893771258226,
            "rating_q025": 1116.4648166141144
        },
        "chatglm-6b": {
            "rating": 1157.0578252135174,
            "rating_q975": 1195.856953143355,
            "rating_q025": 1118.2586972836798
        },
        "gpt-3.5-turbo-1106": {
            "rating": 1152.8607864854132,
            "rating_q975": 1176.7731004120524,
            "rating_q025": 1128.948472558774
        },
        "wizardlm-70b": {
            "rating": 1151.886521059403,
            "rating_q975": 1183.9527673030912,
            "rating_q025": 1119.8202748157155
        },
        "mixtral-8x7b-instruct-v0.1": {
            "rating": 1148.8611973557445,
            "rating_q975": 1158.1853507504657,
            "rating_q025": 1139.5370439610233
        },
        "phi-3-small-8k-instruct": {
            "rating": 1145.5499350928812,
            "rating_q975": 1158.67325079685,
            "rating_q025": 1132.4266193889125
        },
        "qwen1.5-4b-chat": {
            "rating": 1139.7726500011531,
            "rating_q975": 1158.97504205116,
            "rating_q025": 1120.5702579511462
        },
        "vicuna-13b": {
            "rating": 1138.8545599980798,
            "rating_q975": 1157.6683263467528,
            "rating_q025": 1120.0407936494069
        },
        "starling-lm-7b-alpha": {
            "rating": 1131.2641337555938,
            "rating_q975": 1152.2915870609877,
            "rating_q025": 1110.2366804502
        },
        "gemma-7b-it": {
            "rating": 1129.9018510365574,
            "rating_q975": 1149.0227619501661,
            "rating_q025": 1110.780940122949
        },
        "gemma-1.1-2b-it": {
            "rating": 1129.881825634646,
            "rating_q975": 1146.7799371085823,
            "rating_q025": 1112.9837141607097
        },
        "llama-3.2-3b-instruct": {
            "rating": 1128.5387905138189,
            "rating_q975": 1152.3888980904221,
            "rating_q025": 1104.6886829372156
        },
        "vicuna-33b": {
            "rating": 1128.3132974341531,
            "rating_q975": 1144.6474730398954,
            "rating_q025": 1111.9791218284106
        },
        "phi-3-mini-128k-instruct": {
            "rating": 1122.7711623269722,
            "rating_q975": 1137.6926890806926,
            "rating_q025": 1107.8496355732518
        },
        "phi-3-mini-4k-instruct-june-2024": {
            "rating": 1119.3666819611885,
            "rating_q975": 1136.288957810672,
            "rating_q025": 1102.444406111705
        },
        "wizardlm-13b": {
            "rating": 1113.9909068100233,
            "rating_q975": 1146.9314233511766,
            "rating_q025": 1081.05039026887
        },
        "openhermes-2.5-mistral-7b": {
            "rating": 1109.821400756289,
            "rating_q975": 1151.9065149874584,
            "rating_q025": 1067.7362865251198
        },
        "phi-3-mini-4k-instruct": {
            "rating": 1107.8374530160147,
            "rating_q975": 1121.4106128690428,
            "rating_q025": 1094.2642931629866
        },
        "gemma-2b-it": {
            "rating": 1096.1722381199654,
            "rating_q975": 1120.5087895728732,
            "rating_q025": 1071.8356866670574
        },
        "mistral-7b-instruct-v0.2": {
            "rating": 1096.0083912380853,
            "rating_q975": 1110.3489427961094,
            "rating_q025": 1081.6678396800612
        },
        "tulu-2-dpo-70b": {
            "rating": 1093.0649769033066,
            "rating_q975": 1128.0014979911439,
            "rating_q025": 1058.1284558154691
        },
        "llama-2-13b-chat": {
            "rating": 1085.7277853708645,
            "rating_q975": 1103.8771942143978,
            "rating_q025": 1067.578376527331
        },
        "mpt-7b-chat": {
            "rating": 1082.2545059451627,
            "rating_q975": 1123.9039261905455,
            "rating_q025": 1040.60508569978
        },
        "vicuna-7b": {
            "rating": 1078.8445782186661,
            "rating_q975": 1112.2570038248725,
            "rating_q025": 1045.43215261246
        },
        "llama-2-70b-chat": {
            "rating": 1077.4287422146047,
            "rating_q975": 1089.9649056947626,
            "rating_q025": 1064.892578734447
        },
        "olmo-7b-instruct": {
            "rating": 1076.707762500409,
            "rating_q975": 1099.3389550425138,
            "rating_q025": 1054.0765699583044
        },
        "codellama-34b-instruct": {
            "rating": 1076.4239384548066,
            "rating_q975": 1114.596824072747,
            "rating_q025": 1038.2510528368662
        },
        "llama-2-7b-chat": {
            "rating": 1057.6912521347626,
            "rating_q975": 1076.7449982833386,
            "rating_q025": 1038.6375059861869
        },
        "palm-2": {
            "rating": 1056.7976923675783,
            "rating_q975": 1090.85727584628,
            "rating_q025": 1022.7381088888769
        },
        "llama-3.2-1b-instruct": {
            "rating": 1048.557383471427,
            "rating_q975": 1075.381424018873,
            "rating_q025": 1021.7333429239814
        },
        "zephyr-7b-beta": {
            "rating": 1046.3501195513313,
            "rating_q975": 1076.7116602594144,
            "rating_q025": 1015.988578843248
        },
        "mistral-7b-instruct": {
            "rating": 1037.7829404571823,
            "rating_q975": 1070.98534175233,
            "rating_q025": 1004.5805391620347
        },
        "RWKV-4-Raven-14B": {
            "rating": 1015.0567870671996,
            "rating_q975": 1055.0371836784311,
            "rating_q025": 975.0763904559681
        },
        "koala-13b": {
            "rating": 985.4219014010653,
            "rating_q975": 1018.0854360774387,
            "rating_q025": 952.758366724692
        },
        "dolly-v2-12b": {
            "rating": 974.8923659164209,
            "rating_q975": 1022.0764219446909,
            "rating_q025": 927.7083098881508
        },
        "oasst-pythia-12b": {
            "rating": 925.784673805859,
            "rating_q975": 960.267766317391,
            "rating_q025": 891.301581294327
        },
        "fastchat-t5-3b": {
            "rating": 919.5694576586657,
            "rating_q975": 960.5230582926235,
            "rating_q025": 878.6158570247078
        },
        "alpaca-13b": {
            "rating": 901.0894885782175,
            "rating_q975": 942.5438011005854,
            "rating_q025": 859.6351760558496
        }
    },
    "coding": {
        "claude-opus-4-1-20250805-thinking-16k": {
            "rating": 1504.4800580175051,
            "rating_q975": 1516.1211048857049,
            "rating_q025": 1492.8390111493054
        },
        "claude-opus-4-1-20250805": {
            "rating": 1492.7344957809628,
            "rating_q975": 1502.8264781753114,
            "rating_q025": 1482.6425133866142
        },
        "claude-opus-4-20250514-thinking-16k": {
            "rating": 1478.0897300706565,
            "rating_q975": 1486.2268824410266,
            "rating_q025": 1469.9525777002862
        },
        "qwen3-235b-a22b-instruct-2507": {
            "rating": 1473.0197349997043,
            "rating_q975": 1482.788761697774,
            "rating_q025": 1463.2507083016344
        },
        "gemini-2.5-pro": {
            "rating": 1472.296586385637,
            "rating_q975": 1479.689823662566,
            "rating_q025": 1464.9033491087082
        },
        "gpt-5-high": {
            "rating": 1470.9159873275248,
            "rating_q975": 1481.353147695408,
            "rating_q025": 1460.4788269596418
        },
        "qwen-max-2025-08-15": {
            "rating": 1470.2583093109606,
            "rating_q975": 1484.8322191693821,
            "rating_q025": 1455.6843994525393
        },
        "chatgpt-4o-latest-20250326": {
            "rating": 1469.6151942004687,
            "rating_q975": 1476.5355276193418,
            "rating_q025": 1462.6948607815957
        },
        "o3-2025-04-16": {
            "rating": 1466.9734344137019,
            "rating_q975": 1473.5372194753008,
            "rating_q025": 1460.4096493521029
        },
        "claude-sonnet-4-20250514-thinking-32k": {
            "rating": 1461.8384610269754,
            "rating_q975": 1469.964708692179,
            "rating_q025": 1453.7122133617718
        },
        "gpt-4.5-preview-2025-02-27": {
            "rating": 1458.6758897401432,
            "rating_q975": 1469.2725288818926,
            "rating_q025": 1448.0792505983936
        },
        "mistral-medium-2508": {
            "rating": 1458.3995803353955,
            "rating_q975": 1470.610819005556,
            "rating_q025": 1446.188341665235
        },
        "gpt-5-chat": {
            "rating": 1457.8750265875988,
            "rating_q975": 1470.179550886773,
            "rating_q025": 1445.5705022884244
        },
        "kimi-k2-0711-preview": {
            "rating": 1457.5738072220988,
            "rating_q975": 1465.9710709466126,
            "rating_q025": 1449.176543497585
        },
        "deepseek-r1-0528": {
            "rating": 1456.3626379329035,
            "rating_q975": 1464.7667344447368,
            "rating_q025": 1447.9585414210699
        },
        "claude-opus-4-20250514": {
            "rating": 1454.2340126932445,
            "rating_q975": 1461.690262954622,
            "rating_q025": 1446.777762431867
        },
        "deepseek-v3.1": {
            "rating": 1452.787321469052,
            "rating_q975": 1468.3738285512884,
            "rating_q025": 1437.2008143868154
        },
        "glm-4.5": {
            "rating": 1452.7034490751448,
            "rating_q975": 1462.8481359491993,
            "rating_q025": 1442.5587622010903
        },
        "deepseek-v3.1-thinking": {
            "rating": 1447.9589632486304,
            "rating_q975": 1464.9692281984533,
            "rating_q025": 1430.9486982988074
        },
        "qwen3-235b-a22b-thinking-2507": {
            "rating": 1447.7975840601384,
            "rating_q975": 1459.4102981704186,
            "rating_q025": 1436.184869949858
        },
        "qwen-vl-max-2025-08-13": {
            "rating": 1444.1166997482364,
            "rating_q975": 1471.6208544425228,
            "rating_q025": 1416.6125450539503
        },
        "gpt-4.1-2025-04-14": {
            "rating": 1443.540591818387,
            "rating_q975": 1451.0661692692283,
            "rating_q025": 1436.0150143675457
        },
        "grok-4-0709": {
            "rating": 1441.85051387027,
            "rating_q975": 1450.2471858768997,
            "rating_q025": 1433.4538418636405
        },
        "gpt-5-old": {
            "rating": 1441.3401997257704,
            "rating_q975": 1482.0106562674364,
            "rating_q025": 1400.6697431841044
        },
        "qwen3-235b-a22b-no-thinking": {
            "rating": 1440.7933348140268,
            "rating_q975": 1448.1614860520199,
            "rating_q025": 1433.425183576034
        },
        "grok-3-preview-02-24": {
            "rating": 1438.8174251353566,
            "rating_q975": 1445.7902423675266,
            "rating_q025": 1431.8446079031867
        },
        "qwen3-coder-480b-a35b-instruct": {
            "rating": 1437.8321239362763,
            "rating_q975": 1447.607783135571,
            "rating_q025": 1428.0564647369815
        },
        "claude-sonnet-4-20250514": {
            "rating": 1437.659751379085,
            "rating_q975": 1445.4115619823829,
            "rating_q025": 1429.907940775787
        },
        "deepseek-r1": {
            "rating": 1434.727829821018,
            "rating_q975": 1444.4815378260944,
            "rating_q025": 1424.974121815942
        },
        "qwen3-30b-a3b-instruct-2507": {
            "rating": 1433.8854021037043,
            "rating_q975": 1445.320643264604,
            "rating_q025": 1422.4501609428046
        },
        "deepseek-v3-0324": {
            "rating": 1431.3573213629152,
            "rating_q975": 1438.4566233998178,
            "rating_q025": 1424.2580193260126
        },
        "mai-1-preview": {
            "rating": 1429.9398241554936,
            "rating_q975": 1446.7571366176815,
            "rating_q025": 1413.122511693306
        },
        "o4-mini-2025-04-16": {
            "rating": 1429.868852728704,
            "rating_q975": 1437.1008221000177,
            "rating_q025": 1422.6368833573902
        },
        "claude-3-7-sonnet-20250219-thinking-32k": {
            "rating": 1428.8818153603747,
            "rating_q975": 1435.9703713890308,
            "rating_q025": 1421.7932593317187
        },
        "glm-4.5-air": {
            "rating": 1426.5321770248888,
            "rating_q975": 1436.8948187849398,
            "rating_q025": 1416.1695352648378
        },
        "gpt-5-mini-high": {
            "rating": 1426.1594161276923,
            "rating_q975": 1438.5137915703783,
            "rating_q025": 1413.8050406850064
        },
        "o1-2024-12-17": {
            "rating": 1425.1513450246703,
            "rating_q975": 1433.2570412312443,
            "rating_q025": 1417.0456488180962
        },
        "gpt-4.1-mini-2025-04-14": {
            "rating": 1422.082302539683,
            "rating_q975": 1429.4904342052273,
            "rating_q025": 1414.6741708741386
        },
        "qwen3-235b-a22b": {
            "rating": 1422.015267100472,
            "rating_q975": 1429.8458992385474,
            "rating_q025": 1414.184634962397
        },
        "mistral-medium-2505": {
            "rating": 1421.5983980746234,
            "rating_q975": 1428.8463064934713,
            "rating_q025": 1414.3504896557758
        },
        "o3-mini-high": {
            "rating": 1420.8916749048183,
            "rating_q975": 1430.6406641157246,
            "rating_q025": 1411.142685693912
        },
        "step-3": {
            "rating": 1419.1662950514437,
            "rating_q975": 1437.5982553850865,
            "rating_q025": 1400.7343347178007
        },
        "gemini-2.5-flash": {
            "rating": 1417.5140455171656,
            "rating_q975": 1424.6540625174273,
            "rating_q025": 1410.374028516904
        },
        "claude-3-5-sonnet-20241022": {
            "rating": 1416.8209024029677,
            "rating_q975": 1421.6483522856684,
            "rating_q025": 1411.993452520267
        },
        "claude-3-7-sonnet-20250219": {
            "rating": 1414.2354056730874,
            "rating_q975": 1420.9073731615886,
            "rating_q025": 1407.563438184586
        },
        "o1-preview": {
            "rating": 1412.3135142235124,
            "rating_q975": 1420.383471603358,
            "rating_q025": 1404.2435568436665
        },
        "hunyuan-t1-20250711": {
            "rating": 1411.1271669621076,
            "rating_q975": 1424.5445726338148,
            "rating_q025": 1397.7097612904004
        },
        "hunyuan-turbos-20250416": {
            "rating": 1408.7683221275715,
            "rating_q975": 1419.5936734919292,
            "rating_q025": 1397.9429707632137
        },
        "qwen3-32b": {
            "rating": 1406.3588089229954,
            "rating_q975": 1427.2247932654388,
            "rating_q025": 1385.492824580552
        },
        "minimax-m1": {
            "rating": 1406.035738762414,
            "rating_q975": 1413.8427466686237,
            "rating_q025": 1398.228730856204
        },
        "llama-3.1-nemotron-ultra-253b-v1": {
            "rating": 1403.396794083284,
            "rating_q975": 1429.3607286095717,
            "rating_q025": 1377.4328595569966
        },
        "o3-mini": {
            "rating": 1401.179542174299,
            "rating_q975": 1407.285019480774,
            "rating_q025": 1395.0740648678243
        },
        "qwen2.5-max": {
            "rating": 1398.3246463131693,
            "rating_q975": 1405.2402964034488,
            "rating_q025": 1391.4089962228898
        },
        "mistral-small-2506": {
            "rating": 1398.2482516920988,
            "rating_q975": 1407.3817342783395,
            "rating_q025": 1389.114769105858
        },
        "gpt-oss-120b": {
            "rating": 1393.8105938956594,
            "rating_q975": 1404.8716543158764,
            "rating_q025": 1382.7495334754426
        },
        "nvidia-llama-3.3-nemotron-super-49b-v1.5": {
            "rating": 1387.276180855314,
            "rating_q975": 1403.9502614499056,
            "rating_q025": 1370.602100260722
        },
        "grok-3-mini-high": {
            "rating": 1386.4511826368093,
            "rating_q975": 1395.326880807206,
            "rating_q025": 1377.5754844664125
        },
        "hunyuan-turbos-20250226": {
            "rating": 1386.3645261425252,
            "rating_q975": 1412.0815609967017,
            "rating_q025": 1360.6474912883486
        },
        "gpt-5-nano-high": {
            "rating": 1384.3633259839619,
            "rating_q975": 1399.5214878913469,
            "rating_q025": 1369.2051640765771
        },
        "grok-3-mini-beta": {
            "rating": 1383.7025105480614,
            "rating_q975": 1391.6895608407128,
            "rating_q025": 1375.71546025541
        },
        "claude-3-5-sonnet-20240620": {
            "rating": 1383.1346557202367,
            "rating_q975": 1389.2338999632802,
            "rating_q025": 1377.0354114771933
        },
        "qwq-32b": {
            "rating": 1383.0263074888733,
            "rating_q975": 1390.9431353901616,
            "rating_q025": 1375.109479587585
        },
        "gpt-oss-20b": {
            "rating": 1382.7805832098281,
            "rating_q975": 1394.6563035105646,
            "rating_q025": 1370.9048629090917
        },
        "o1-mini": {
            "rating": 1382.6221236301974,
            "rating_q975": 1388.8149126869391,
            "rating_q025": 1376.4293345734557
        },
        "command-a-03-2025": {
            "rating": 1379.2596721385266,
            "rating_q975": 1386.0998793430037,
            "rating_q025": 1372.4194649340498
        },
        "deepseek-v3": {
            "rating": 1378.795700004011,
            "rating_q975": 1387.5237091076463,
            "rating_q025": 1370.0676909003757
        },
        "qwen3-30b-a3b": {
            "rating": 1376.7248403529052,
            "rating_q975": 1384.56979283104,
            "rating_q025": 1368.87988787477
        },
        "qwen-plus-0125": {
            "rating": 1373.847470288817,
            "rating_q975": 1390.1161553327431,
            "rating_q025": 1357.578785244891
        },
        "glm-4.5v": {
            "rating": 1373.786630244492,
            "rating_q975": 1403.8631341783957,
            "rating_q025": 1343.710126310588
        },
        "gemini-2.0-flash-001": {
            "rating": 1372.7593035458556,
            "rating_q975": 1379.2803909501897,
            "rating_q025": 1366.2382161415214
        },
        "gemma-3-27b-it": {
            "rating": 1371.8358590899081,
            "rating_q975": 1378.7869661517125,
            "rating_q025": 1364.884752028104
        },
        "hunyuan-turbo-0110": {
            "rating": 1371.511056442063,
            "rating_q975": 1396.0891820142497,
            "rating_q025": 1346.9329308698764
        },
        "claude-3-5-haiku-20241022": {
            "rating": 1369.0784603810332,
            "rating_q975": 1374.6861779767455,
            "rating_q025": 1363.4707427853211
        },
        "llama-3.3-nemotron-49b-super-v1": {
            "rating": 1366.614619999259,
            "rating_q975": 1392.0725102431654,
            "rating_q025": 1341.1567297553524
        },
        "llama-3.1-405b-instruct-bf16": {
            "rating": 1363.3951244138998,
            "rating_q975": 1369.877693509899,
            "rating_q025": 1356.9125553179006
        },
        "gpt-4.1-nano-2025-04-14": {
            "rating": 1363.2293505366233,
            "rating_q975": 1379.6384108599495,
            "rating_q025": 1346.820290213297
        },
        "deepseek-v2.5-1210": {
            "rating": 1361.7477437785378,
            "rating_q975": 1376.4120855517447,
            "rating_q025": 1347.0834020053312
        },
        "magistral-medium-2506": {
            "rating": 1361.0223639396172,
            "rating_q975": 1372.0442158376766,
            "rating_q025": 1350.000512041558
        },
        "gpt-4o-2024-05-13": {
            "rating": 1360.897962948585,
            "rating_q975": 1366.3742584261702,
            "rating_q025": 1355.4216674709999
        },
        "yi-lightning": {
            "rating": 1360.708778588848,
            "rating_q975": 1369.2489998263698,
            "rating_q025": 1352.1685573513262
        },
        "step-1o-turbo-202506": {
            "rating": 1360.1589372767403,
            "rating_q975": 1371.4942627028895,
            "rating_q025": 1348.8236118505913
        },
        "athene-v2-chat": {
            "rating": 1358.493367485174,
            "rating_q975": 1366.375527558185,
            "rating_q025": 1350.6112074121631
        },
        "llama-4-maverick-17b-128e-instruct": {
            "rating": 1357.7777619867913,
            "rating_q975": 1365.3898514865803,
            "rating_q025": 1350.1656724870024
        },
        "gemini-1.5-pro-002": {
            "rating": 1357.5504665172175,
            "rating_q975": 1363.3722884414246,
            "rating_q025": 1351.7286445930106
        },
        "llama-3.1-405b-instruct-fp8": {
            "rating": 1357.04229437047,
            "rating_q975": 1363.193672330513,
            "rating_q025": 1350.8909164104273
        },
        "amazon-nova-experimental-chat-05-14": {
            "rating": 1356.1710086057867,
            "rating_q975": 1364.6712047919273,
            "rating_q025": 1347.670812419646
        },
        "hunyuan-large-2025-02-10": {
            "rating": 1354.322771913444,
            "rating_q975": 1376.2570582903998,
            "rating_q025": 1332.3884855364884
        },
        "gemini-2.0-flash-lite-preview-02-05": {
            "rating": 1353.8191922011365,
            "rating_q975": 1362.115244487307,
            "rating_q025": 1345.523139914966
        },
        "deepseek-v2.5": {
            "rating": 1353.6608318079604,
            "rating_q975": 1361.8530013769223,
            "rating_q025": 1345.4686622389986
        },
        "llama-4-scout-17b-16e-instruct": {
            "rating": 1351.7407472891225,
            "rating_q975": 1360.4393283753482,
            "rating_q025": 1343.042166202897
        },
        "gpt-4o-2024-08-06": {
            "rating": 1351.6472196792365,
            "rating_q975": 1358.4960299719696,
            "rating_q025": 1344.7984093865036
        },
        "step-2-16k-exp-202412": {
            "rating": 1349.755487794992,
            "rating_q975": 1367.2115311806365,
            "rating_q025": 1332.2994444093472
        },
        "grok-2-2024-08-13": {
            "rating": 1349.6661595381543,
            "rating_q975": 1355.4979698323837,
            "rating_q025": 1343.8343492439246
        },
        "qwen2.5-plus-1127": {
            "rating": 1347.5890901447126,
            "rating_q975": 1359.6138472338816,
            "rating_q025": 1335.5643330555436
        },
        "qwen2.5-72b-instruct": {
            "rating": 1346.6604875634043,
            "rating_q975": 1353.2623783167314,
            "rating_q025": 1340.0585968100775
        },
        "mistral-small-3.1-24b-instruct-2503": {
            "rating": 1344.7929035460152,
            "rating_q975": 1353.3900572052921,
            "rating_q025": 1336.1957498867384
        },
        "mistral-large-2407": {
            "rating": 1344.6821475711777,
            "rating_q975": 1351.3881763265438,
            "rating_q025": 1337.976118815812
        },
        "glm-4-plus": {
            "rating": 1344.6187296770054,
            "rating_q975": 1352.7120861478656,
            "rating_q025": 1336.5253732061456
        },
        "qwen-max-0919": {
            "rating": 1342.7675184154682,
            "rating_q975": 1352.406486937591,
            "rating_q025": 1333.1285498933455
        },
        "gpt-4o-mini-2024-07-18": {
            "rating": 1341.3147967647678,
            "rating_q975": 1346.8680456122224,
            "rating_q025": 1335.7615479173132
        },
        "gemini-1.5-pro-001": {
            "rating": 1341.118315580366,
            "rating_q975": 1347.690220544133,
            "rating_q025": 1334.5464106165991
        },
        "claude-3-opus-20240229": {
            "rating": 1340.6463850566374,
            "rating_q975": 1345.631535982835,
            "rating_q025": 1335.66123413044
        },
        "gpt-4-turbo-2024-04-09": {
            "rating": 1340.6351617901519,
            "rating_q975": 1346.8291702021106,
            "rating_q025": 1334.4411533781933
        },
        "gemini-advanced-0514": {
            "rating": 1339.2473352331594,
            "rating_q975": 1347.1354707482994,
            "rating_q025": 1331.3591997180192
        },
        "glm-4-plus-0111": {
            "rating": 1339.1364937982837,
            "rating_q975": 1354.8392881559312,
            "rating_q025": 1323.4336994406362
        },
        "llama-3.3-70b-instruct": {
            "rating": 1338.7076134821828,
            "rating_q975": 1344.4929609442327,
            "rating_q025": 1332.9222660201326
        },
        "hunyuan-large-vision": {
            "rating": 1337.5764257472022,
            "rating_q975": 1352.3606134508143,
            "rating_q025": 1322.79223804359
        },
        "athene-70b-0725": {
            "rating": 1337.4992923764034,
            "rating_q975": 1347.0288285771844,
            "rating_q025": 1327.9697561756227
        },
        "mistral-large-2411": {
            "rating": 1335.7584915557454,
            "rating_q975": 1343.285442032536,
            "rating_q025": 1328.2315410789547
        },
        "gpt-4-1106-preview": {
            "rating": 1333.7092590940488,
            "rating_q975": 1340.1187791157201,
            "rating_q025": 1327.2997390723774
        },
        "amazon-nova-pro-v1.0": {
            "rating": 1333.669738700079,
            "rating_q975": 1341.3888367224845,
            "rating_q025": 1325.9506406776736
        },
        "hunyuan-standard-2025-02-10": {
            "rating": 1333.551810914561,
            "rating_q975": 1354.2353492618079,
            "rating_q025": 1312.8682725673143
        },
        "gemma-3-12b-it": {
            "rating": 1332.8557933443885,
            "rating_q975": 1353.1992230583285,
            "rating_q025": 1312.5123636304486
        },
        "gemma-3n-e4b-it": {
            "rating": 1331.4478916059822,
            "rating_q975": 1340.5950659333048,
            "rating_q025": 1322.3007172786597
        },
        "deepseek-coder-v2": {
            "rating": 1330.260482443643,
            "rating_q975": 1341.056268029954,
            "rating_q025": 1319.4646968573318
        },
        "llama-3.1-nemotron-70b-instruct": {
            "rating": 1328.0133590232338,
            "rating_q975": 1341.5262895774454,
            "rating_q025": 1314.5004284690222
        },
        "grok-2-mini-2024-08-13": {
            "rating": 1327.4747380835288,
            "rating_q975": 1333.589997118994,
            "rating_q025": 1321.3594790480633
        },
        "qwen2.5-coder-32b-instruct": {
            "rating": 1326.6042265486062,
            "rating_q975": 1342.140174226361,
            "rating_q025": 1311.0682788708514
        },
        "gpt-4-0125-preview": {
            "rating": 1323.6235345791772,
            "rating_q975": 1330.190483979645,
            "rating_q025": 1317.0565851787094
        },
        "llama-3.1-70b-instruct": {
            "rating": 1319.7539331592136,
            "rating_q975": 1325.719262147568,
            "rating_q025": 1313.7886041708591
        },
        "gpt-4-0314": {
            "rating": 1313.5980675408064,
            "rating_q975": 1322.1101112583606,
            "rating_q025": 1305.086023823252
        },
        "gemini-1.5-flash-002": {
            "rating": 1312.4363987255847,
            "rating_q975": 1319.387659779769,
            "rating_q025": 1305.4851376714005
        },
        "jamba-1.5-large": {
            "rating": 1307.4764829826963,
            "rating_q975": 1320.3110455749918,
            "rating_q025": 1294.6419203904009
        },
        "claude-3-sonnet-20240229": {
            "rating": 1307.2462102504833,
            "rating_q975": 1313.5966726293766,
            "rating_q025": 1300.8957478715897
        },
        "gemini-1.5-flash-001": {
            "rating": 1306.1748663668236,
            "rating_q975": 1312.796258342024,
            "rating_q025": 1299.5534743916235
        },
        "llama-3.1-tulu-3-70b": {
            "rating": 1302.7916458133782,
            "rating_q975": 1323.3894626220888,
            "rating_q025": 1282.1938290046671
        },
        "gemma-2-27b-it": {
            "rating": 1302.3312654514802,
            "rating_q975": 1307.7905165922602,
            "rating_q025": 1296.8720143107005
        },
        "reka-core-20240904": {
            "rating": 1300.553338626876,
            "rating_q975": 1313.7903259876537,
            "rating_q025": 1287.3163512660983
        },
        "mistral-small-24b-instruct-2501": {
            "rating": 1299.9680276951972,
            "rating_q975": 1310.601831422604,
            "rating_q025": 1289.3342239677906
        },
        "amazon-nova-lite-v1.0": {
            "rating": 1299.9084444571213,
            "rating_q975": 1308.7536152480243,
            "rating_q025": 1291.063273666218
        },
        "gemma-3-4b-it": {
            "rating": 1298.9015517079133,
            "rating_q975": 1318.7346649121416,
            "rating_q025": 1279.068438503685
        },
        "glm-4-0520": {
            "rating": 1298.0172108295515,
            "rating_q975": 1310.4245455319513,
            "rating_q025": 1285.6098761271517
        },
        "phi-4": {
            "rating": 1296.8963830482157,
            "rating_q975": 1305.491391927258,
            "rating_q025": 1288.3013741691734
        },
        "nemotron-4-340b-instruct": {
            "rating": 1296.3995541369268,
            "rating_q975": 1306.6461278652578,
            "rating_q025": 1286.1529804085956
        },
        "llama-3.1-nemotron-51b-instruct": {
            "rating": 1295.235240355869,
            "rating_q975": 1314.6687534767548,
            "rating_q025": 1275.8017272349834
        },
        "llama-3-70b-instruct": {
            "rating": 1294.0933311299275,
            "rating_q975": 1300.133485304385,
            "rating_q025": 1288.0531769554698
        },
        "hunyuan-standard-256k": {
            "rating": 1293.1117754495422,
            "rating_q975": 1314.519237190309,
            "rating_q025": 1271.7043137087755
        },
        "gpt-4-0613": {
            "rating": 1293.0225233430915,
            "rating_q975": 1300.153531416415,
            "rating_q025": 1285.891515269768
        },
        "claude-3-haiku-20240307": {
            "rating": 1288.9614502769928,
            "rating_q975": 1294.9154905256655,
            "rating_q025": 1283.0074100283202
        },
        "c4ai-aya-expanse-32b": {
            "rating": 1285.7801360329993,
            "rating_q975": 1293.8056973190628,
            "rating_q025": 1277.7545747469358
        },
        "reka-flash-20240904": {
            "rating": 1284.9666013247856,
            "rating_q975": 1298.2244236275155,
            "rating_q025": 1271.7087790220558
        },
        "qwen2-72b-instruct": {
            "rating": 1284.0647653078204,
            "rating_q975": 1292.02787693201,
            "rating_q025": 1276.1016536836307
        },
        "mistral-large-2402": {
            "rating": 1281.756751494499,
            "rating_q975": 1289.4091435940882,
            "rating_q025": 1274.1043593949096
        },
        "amazon-nova-micro-v1.0": {
            "rating": 1278.8336345145394,
            "rating_q975": 1287.677815700016,
            "rating_q025": 1269.989453329063
        },
        "gemma-2-9b-it-simpo": {
            "rating": 1276.1960456994134,
            "rating_q975": 1289.4258745648376,
            "rating_q025": 1262.9662168339894
        },
        "ministral-8b-2410": {
            "rating": 1273.1981482884448,
            "rating_q975": 1289.5329123550862,
            "rating_q025": 1256.8633842218035
        },
        "gemma-2-9b-it": {
            "rating": 1272.5191759676936,
            "rating_q975": 1278.7454025297163,
            "rating_q025": 1266.2929494056707
        },
        "command-r-plus-08-2024": {
            "rating": 1271.3397392736354,
            "rating_q975": 1283.6243602379272,
            "rating_q025": 1259.0551183093435
        },
        "granite-3.1-8b-instruct": {
            "rating": 1270.0445148537415,
            "rating_q975": 1292.5848734203535,
            "rating_q025": 1247.5041562871293
        },
        "gemini-1.5-flash-8b-001": {
            "rating": 1269.8903764300346,
            "rating_q975": 1276.8704950225458,
            "rating_q025": 1262.9102578375234
        },
        "qwen1.5-110b-chat": {
            "rating": 1267.1547819444838,
            "rating_q975": 1276.4920555618114,
            "rating_q025": 1257.8175083271565
        },
        "command-r-08-2024": {
            "rating": 1266.4838667119498,
            "rating_q975": 1278.4838559734578,
            "rating_q025": 1254.4838774504417
        },
        "olmo-2-0325-32b-instruct": {
            "rating": 1266.0498847294332,
            "rating_q975": 1289.8921153948554,
            "rating_q025": 1242.207654064011
        },
        "jamba-1.5-mini": {
            "rating": 1263.5173927232072,
            "rating_q975": 1277.0467383651753,
            "rating_q025": 1249.988047081239
        },
        "mixtral-8x22b-instruct-v0.1": {
            "rating": 1261.7782034782745,
            "rating_q975": 1269.5046521804295,
            "rating_q025": 1254.0517547761194
        },
        "command-r-plus": {
            "rating": 1261.04041388535,
            "rating_q975": 1267.9282504645832,
            "rating_q025": 1254.1525773061169
        },
        "qwen1.5-72b-chat": {
            "rating": 1260.4486945410968,
            "rating_q975": 1269.1745495910677,
            "rating_q025": 1251.7228394911256
        },
        "gpt-3.5-turbo-0125": {
            "rating": 1257.4450809702323,
            "rating_q975": 1264.794475057664,
            "rating_q025": 1250.0956868828007
        },
        "c4ai-aya-expanse-8b": {
            "rating": 1256.1088115472724,
            "rating_q975": 1268.7360546168015,
            "rating_q025": 1243.4815684777432
        },
        "reka-flash-21b-20240226-online": {
            "rating": 1254.289513736339,
            "rating_q975": 1265.7348268207566,
            "rating_q025": 1242.8442006519213
        },
        "reka-flash-21b-20240226": {
            "rating": 1252.7260516382955,
            "rating_q975": 1262.1326212763076,
            "rating_q025": 1243.3194820002834
        },
        "mistral-medium": {
            "rating": 1248.8439626158588,
            "rating_q975": 1258.3932453042962,
            "rating_q025": 1239.2946799274214
        },
        "qwen1.5-32b-chat": {
            "rating": 1246.196835748241,
            "rating_q975": 1256.1430259968065,
            "rating_q025": 1236.2506454996756
        },
        "llama-3.1-8b-instruct": {
            "rating": 1243.5745096565033,
            "rating_q975": 1249.7723341969217,
            "rating_q025": 1237.376685116085
        },
        "llama-3-8b-instruct": {
            "rating": 1243.217774153421,
            "rating_q975": 1249.8513375555442,
            "rating_q025": 1236.5842107512983
        },
        "internlm2_5-20b-chat": {
            "rating": 1242.9930866789307,
            "rating_q975": 1255.4647713744612,
            "rating_q025": 1230.5214019834004
        },
        "llama-3.1-tulu-3-8b": {
            "rating": 1242.5819505263444,
            "rating_q975": 1263.243229925524,
            "rating_q025": 1221.9206711271645
        },
        "gpt-3.5-turbo-1106": {
            "rating": 1242.1626299397287,
            "rating_q975": 1256.9566469618953,
            "rating_q025": 1227.368612917562
        },
        "granite-3.1-2b-instruct": {
            "rating": 1241.8356063737094,
            "rating_q975": 1263.4688182415175,
            "rating_q025": 1220.2023945059013
        },
        "yi-1.5-34b-chat": {
            "rating": 1239.5062219051522,
            "rating_q975": 1248.9228897363325,
            "rating_q025": 1230.0895540739718
        },
        "dbrx-instruct-preview": {
            "rating": 1234.8041448513964,
            "rating_q975": 1244.8094805206445,
            "rating_q025": 1224.7988091821483
        },
        "zephyr-orpo-141b-A35b-v0.1": {
            "rating": 1234.3717811768645,
            "rating_q975": 1253.5551513611042,
            "rating_q025": 1215.1884109926248
        },
        "command-r": {
            "rating": 1230.4922022407259,
            "rating_q975": 1238.3465834272113,
            "rating_q025": 1222.6378210542405
        },
        "gemini-pro-dev-api": {
            "rating": 1228.829384857419,
            "rating_q975": 1241.2913353725455,
            "rating_q025": 1216.3674343422922
        },
        "gemini-pro": {
            "rating": 1228.713080814599,
            "rating_q975": 1250.0896900960754,
            "rating_q025": 1207.3364715331227
        },
        "mixtral-8x7b-instruct-v0.1": {
            "rating": 1224.7644732428193,
            "rating_q975": 1232.024331423148,
            "rating_q025": 1217.504615062491
        },
        "qwen1.5-14b-chat": {
            "rating": 1223.8302897511471,
            "rating_q975": 1235.7480082037955,
            "rating_q025": 1211.9125712984987
        },
        "phi-3-medium-4k-instruct": {
            "rating": 1222.771171129546,
            "rating_q975": 1231.874095162858,
            "rating_q025": 1213.6682470962342
        },
        "starling-lm-7b-beta": {
            "rating": 1219.338437981171,
            "rating_q975": 1231.096385831329,
            "rating_q025": 1207.580490131013
        },
        "granite-3.0-8b-instruct": {
            "rating": 1219.290867984295,
            "rating_q975": 1235.5263275749212,
            "rating_q025": 1203.0554083936684
        },
        "gemma-1.1-7b-it": {
            "rating": 1212.7589872353124,
            "rating_q975": 1222.0916603645785,
            "rating_q025": 1203.4263141060462
        },
        "openchat-3.5-0106": {
            "rating": 1212.0132763513147,
            "rating_q975": 1225.154019068985,
            "rating_q025": 1198.8725336336447
        },
        "snowflake-arctic-instruct": {
            "rating": 1206.0568543267277,
            "rating_q975": 1216.277948818107,
            "rating_q025": 1195.8357598353482
        },
        "phi-3-small-8k-instruct": {
            "rating": 1201.7522238108422,
            "rating_q975": 1212.4106105780209,
            "rating_q025": 1191.0938370436636
        },
        "deepseek-llm-67b-chat": {
            "rating": 1201.7089416733968,
            "rating_q975": 1223.3540775490194,
            "rating_q025": 1180.0638057977742
        },
        "granite-3.0-2b-instruct": {
            "rating": 1199.533467645489,
            "rating_q975": 1215.0238776396097,
            "rating_q025": 1184.0430576513684
        },
        "yi-34b-chat": {
            "rating": 1199.1464500587163,
            "rating_q975": 1210.9317474453078,
            "rating_q025": 1187.3611526721243
        },
        "tulu-2-dpo-70b": {
            "rating": 1196.6631366043791,
            "rating_q975": 1216.0637658091332,
            "rating_q025": 1177.262507399625
        },
        "gemma-2-2b-it": {
            "rating": 1194.1819373727474,
            "rating_q975": 1201.0756874905512,
            "rating_q025": 1187.2881872549435
        },
        "qwen1.5-7b-chat": {
            "rating": 1190.208529548786,
            "rating_q975": 1208.908069487096,
            "rating_q025": 1171.5089896104757
        },
        "starling-lm-7b-alpha": {
            "rating": 1187.8658796739269,
            "rating_q975": 1202.9289744936764,
            "rating_q025": 1172.8027848541774
        },
        "qwen-14b-chat": {
            "rating": 1183.0303797425172,
            "rating_q975": 1205.6779289446517,
            "rating_q025": 1160.3828305403827
        },
        "vicuna-33b": {
            "rating": 1180.9000251960924,
            "rating_q975": 1192.5841263605053,
            "rating_q025": 1169.2159240316794
        },
        "wizardlm-70b": {
            "rating": 1179.8075060386298,
            "rating_q975": 1198.153462459535,
            "rating_q025": 1161.4615496177246
        },
        "openhermes-2.5-mistral-7b": {
            "rating": 1179.5919442098516,
            "rating_q975": 1200.839158463978,
            "rating_q025": 1158.3447299557247
        },
        "openchat-3.5": {
            "rating": 1178.4996658509265,
            "rating_q975": 1196.831847693201,
            "rating_q025": 1160.1674840086519
        },
        "nous-hermes-2-mixtral-8x7b-dpo": {
            "rating": 1177.6553580561363,
            "rating_q975": 1199.457648553434,
            "rating_q025": 1155.8530675588386
        },
        "phi-3-mini-4k-instruct-june-2024": {
            "rating": 1177.2959080416613,
            "rating_q975": 1189.5340391241923,
            "rating_q025": 1165.0577769591305
        },
        "llama-2-70b-chat": {
            "rating": 1176.2524648502992,
            "rating_q975": 1185.3358233797378,
            "rating_q025": 1167.1691063208607
        },
        "mistral-7b-instruct-v0.2": {
            "rating": 1174.7438689887408,
            "rating_q975": 1185.437809970664,
            "rating_q025": 1164.0499280068175
        },
        "phi-3-mini-4k-instruct": {
            "rating": 1173.5377287363126,
            "rating_q975": 1184.1963498686064,
            "rating_q025": 1162.8791076040186
        },
        "qwq-32b-preview": {
            "rating": 1172.201879354417,
            "rating_q975": 1194.2229210399364,
            "rating_q025": 1150.1808376688975
        },
        "solar-10.7b-instruct-v1.0": {
            "rating": 1167.6286721612203,
            "rating_q975": 1193.0700326110777,
            "rating_q025": 1142.187311711363
        },
        "gemma-1.1-2b-it": {
            "rating": 1163.9142987830114,
            "rating_q975": 1176.5929753043963,
            "rating_q025": 1151.2356222616265
        },
        "codellama-70b-instruct": {
            "rating": 1162.4986098207455,
            "rating_q975": 1200.3695362810192,
            "rating_q025": 1124.627683360472
        },
        "gemma-7b-it": {
            "rating": 1160.723796992566,
            "rating_q975": 1175.8371608068292,
            "rating_q025": 1145.6104331783026
        },
        "mpt-30b-chat": {
            "rating": 1156.902371872236,
            "rating_q975": 1190.4385338823297,
            "rating_q025": 1123.3662098621426
        },
        "llama-2-13b-chat": {
            "rating": 1155.641214563875,
            "rating_q975": 1167.414648025317,
            "rating_q025": 1143.8677811024334
        },
        "codellama-34b-instruct": {
            "rating": 1153.7255160421205,
            "rating_q975": 1172.4576858284902,
            "rating_q025": 1134.993346255751
        },
        "zephyr-7b-alpha": {
            "rating": 1152.4849540209123,
            "rating_q975": 1189.0966188255197,
            "rating_q025": 1115.873289216305
        },
        "llama-3.2-3b-instruct": {
            "rating": 1149.9210017483347,
            "rating_q975": 1164.0447689764521,
            "rating_q025": 1135.7972345202174
        },
        "vicuna-13b": {
            "rating": 1149.0986342291872,
            "rating_q975": 1162.0855408863902,
            "rating_q025": 1136.1117275719841
        },
        "smollm2-1.7b-instruct": {
            "rating": 1148.1636993129785,
            "rating_q975": 1176.3576351907857,
            "rating_q025": 1119.9697634351714
        },
        "dolphin-2.2.1-mistral-7b": {
            "rating": 1146.5336476412647,
            "rating_q975": 1183.6601992397862,
            "rating_q025": 1109.4070960427432
        },
        "phi-3-mini-128k-instruct": {
            "rating": 1144.2577403491498,
            "rating_q975": 1156.314609066239,
            "rating_q025": 1132.2008716320606
        },
        "palm-2": {
            "rating": 1142.1761314113282,
            "rating_q975": 1160.9885579656968,
            "rating_q025": 1123.3637048569597
        },
        "wizardlm-13b": {
            "rating": 1141.6434260080025,
            "rating_q975": 1161.8590460842734,
            "rating_q025": 1121.4278059317317
        },
        "llama2-70b-steerlm-chat": {
            "rating": 1138.038773177396,
            "rating_q975": 1163.2747574022906,
            "rating_q025": 1112.8027889525015
        },
        "zephyr-7b-beta": {
            "rating": 1136.99190727358,
            "rating_q975": 1153.9982383279446,
            "rating_q025": 1119.9855762192155
        },
        "mistral-7b-instruct": {
            "rating": 1130.8337548075565,
            "rating_q975": 1149.0925096634446,
            "rating_q025": 1112.5749999516681
        },
        "stripedhyena-nous-7b": {
            "rating": 1128.2615968304976,
            "rating_q975": 1149.2734867998895,
            "rating_q025": 1107.2497068611056
        },
        "gemma-2b-it": {
            "rating": 1122.4141008503466,
            "rating_q975": 1142.3762073207135,
            "rating_q025": 1102.4519943799794
        },
        "qwen1.5-4b-chat": {
            "rating": 1115.5860560618646,
            "rating_q975": 1131.9204552744202,
            "rating_q025": 1099.251656849309
        },
        "llama-3.2-1b-instruct": {
            "rating": 1111.2545825675636,
            "rating_q975": 1124.9831975021432,
            "rating_q025": 1097.525967632984
        },
        "olmo-7b-instruct": {
            "rating": 1108.0122668787549,
            "rating_q975": 1127.8339744314544,
            "rating_q025": 1088.1905593260553
        },
        "vicuna-7b": {
            "rating": 1106.488058304562,
            "rating_q975": 1127.9446660904161,
            "rating_q025": 1085.031450518708
        },
        "llama-2-7b-chat": {
            "rating": 1101.6562560215862,
            "rating_q975": 1114.5354201780851,
            "rating_q025": 1088.7770918650874
        },
        "guanaco-33b": {
            "rating": 1079.7302561341585,
            "rating_q975": 1111.7736552379777,
            "rating_q025": 1047.6868570303395
        },
        "chatglm3-6b": {
            "rating": 1076.6563133948655,
            "rating_q975": 1101.4190815449758,
            "rating_q025": 1051.8935452447552
        },
        "gpt4all-13b-snoozy": {
            "rating": 1056.9763333531766,
            "rating_q975": 1096.4407531306258,
            "rating_q025": 1017.5119135757275
        },
        "koala-13b": {
            "rating": 1050.5452597817587,
            "rating_q975": 1072.8890717515565,
            "rating_q025": 1028.2014478119609
        },
        "mpt-7b-chat": {
            "rating": 1050.4518647763734,
            "rating_q975": 1080.8969466569386,
            "rating_q025": 1020.0067828958083
        },
        "RWKV-4-Raven-14B": {
            "rating": 1027.335541827557,
            "rating_q975": 1052.8997465024688,
            "rating_q025": 1001.7713371526454
        },
        "oasst-pythia-12b": {
            "rating": 1017.4617680715495,
            "rating_q975": 1040.7163804798083,
            "rating_q025": 994.2071556632906
        },
        "chatglm2-6b": {
            "rating": 1014.1561298148962,
            "rating_q975": 1046.4570151793368,
            "rating_q025": 981.8552444504553
        },
        "chatglm-6b": {
            "rating": 1000.541317523381,
            "rating_q975": 1025.4667228405879,
            "rating_q025": 975.6159122061742
        },
        "alpaca-13b": {
            "rating": 983.6634044416451,
            "rating_q975": 1009.8491647517648,
            "rating_q025": 957.4776441315253
        },
        "stablelm-tuned-alpha-7b": {
            "rating": 975.480247724389,
            "rating_q975": 1005.4883714473165,
            "rating_q025": 945.4721240014615
        },
        "dolly-v2-12b": {
            "rating": 926.8741455380161,
            "rating_q975": 958.9232799838553,
            "rating_q025": 894.825011092177
        },
        "fastchat-t5-3b": {
            "rating": 900.0767208393165,
            "rating_q975": 928.018017515986,
            "rating_q025": 872.1354241626468
        },
        "llama-13b": {
            "rating": 857.1352146291202,
            "rating_q975": 896.5210912599327,
            "rating_q025": 817.7493379983077
        }
    },
    "creative_writing": {
        "gemini-2.5-pro": {
            "rating": 1450.7327315876012,
            "rating_q975": 1460.5220458818208,
            "rating_q025": 1440.9434172933816
        },
        "claude-opus-4-1-20250805-thinking-16k": {
            "rating": 1439.1002970312895,
            "rating_q975": 1457.1532429697675,
            "rating_q025": 1421.0473510928118
        },
        "claude-opus-4-1-20250805": {
            "rating": 1434.960824342852,
            "rating_q975": 1450.26899506986,
            "rating_q025": 1419.6526536158442
        },
        "gpt-4.5-preview-2025-02-27": {
            "rating": 1431.6082120087801,
            "rating_q975": 1442.8557448709944,
            "rating_q025": 1420.3606791465659
        },
        "chatgpt-4o-latest-20250326": {
            "rating": 1423.033278651295,
            "rating_q975": 1431.9018114976323,
            "rating_q025": 1414.1647458049579
        },
        "claude-opus-4-20250514-thinking-16k": {
            "rating": 1422.5221502652669,
            "rating_q975": 1433.6720858299875,
            "rating_q025": 1411.372214700546
        },
        "claude-opus-4-20250514": {
            "rating": 1411.5231855720142,
            "rating_q975": 1421.4844179973304,
            "rating_q025": 1401.5619531466982
        },
        "grok-4-0709": {
            "rating": 1406.4205645808524,
            "rating_q975": 1418.4647796088798,
            "rating_q025": 1394.3763495528253
        },
        "gemini-2.5-flash": {
            "rating": 1402.8931781662218,
            "rating_q975": 1412.119345236452,
            "rating_q025": 1393.6670110959913
        },
        "gpt-5-high": {
            "rating": 1402.0704762434127,
            "rating_q975": 1417.2761914623895,
            "rating_q025": 1386.8647610244361
        },
        "grok-3-preview-02-24": {
            "rating": 1398.083976804365,
            "rating_q975": 1406.6053570090485,
            "rating_q025": 1389.5625965996815
        },
        "gpt-4.1-2025-04-14": {
            "rating": 1397.7562247779954,
            "rating_q975": 1407.3018942857161,
            "rating_q025": 1388.2105552702744
        },
        "deepseek-v3.1": {
            "rating": 1396.7454189730156,
            "rating_q975": 1418.0501125734431,
            "rating_q025": 1375.440725372588
        },
        "gpt-5-chat": {
            "rating": 1394.6629194103903,
            "rating_q975": 1412.499251272125,
            "rating_q025": 1376.8265875486554
        },
        "o3-2025-04-16": {
            "rating": 1393.6915110584052,
            "rating_q975": 1402.4075287880914,
            "rating_q025": 1384.975493328719
        },
        "claude-sonnet-4-20250514-thinking-32k": {
            "rating": 1392.698949787971,
            "rating_q975": 1403.9293313904889,
            "rating_q025": 1381.4685681854533
        },
        "qwen-max-2025-08-15": {
            "rating": 1392.4827595923318,
            "rating_q975": 1413.9742116400785,
            "rating_q025": 1370.9913075445854
        },
        "deepseek-r1-0528": {
            "rating": 1391.932205968508,
            "rating_q975": 1403.4408347488497,
            "rating_q025": 1380.4235771881663
        },
        "deepseek-v3.1-thinking": {
            "rating": 1391.8335988302001,
            "rating_q975": 1414.6272115248646,
            "rating_q025": 1369.0399861355356
        },
        "deepseek-v3-0324": {
            "rating": 1388.7999098220184,
            "rating_q975": 1397.8841217462948,
            "rating_q025": 1379.715697897742
        },
        "claude-3-7-sonnet-20250219-thinking-32k": {
            "rating": 1388.4344699094925,
            "rating_q975": 1396.8813477087126,
            "rating_q025": 1379.9875921102723
        },
        "qwen3-235b-a22b-thinking-2507": {
            "rating": 1382.2437303931022,
            "rating_q975": 1399.5999190458342,
            "rating_q025": 1364.88754174037
        },
        "hunyuan-t1-20250711": {
            "rating": 1382.0671095305931,
            "rating_q975": 1403.2602382528953,
            "rating_q025": 1360.873980808291
        },
        "kimi-k2-0711-preview": {
            "rating": 1379.8151598113818,
            "rating_q975": 1391.7290552856011,
            "rating_q025": 1367.9012643371623
        },
        "o1-2024-12-17": {
            "rating": 1378.4622005514989,
            "rating_q975": 1386.7893934837919,
            "rating_q025": 1370.135007619206
        },
        "claude-sonnet-4-20250514": {
            "rating": 1376.082169195748,
            "rating_q975": 1386.1731477808808,
            "rating_q025": 1365.9911906106156
        },
        "qwen3-235b-a22b-instruct-2507": {
            "rating": 1375.5372894034451,
            "rating_q975": 1389.8532356062549,
            "rating_q025": 1361.2213432006356
        },
        "claude-3-7-sonnet-20250219": {
            "rating": 1374.9741788534104,
            "rating_q975": 1382.8484007123238,
            "rating_q025": 1367.0999569944972
        },
        "deepseek-r1": {
            "rating": 1374.2459275544563,
            "rating_q975": 1383.9803706606483,
            "rating_q025": 1364.5114844482641
        },
        "glm-4.5": {
            "rating": 1370.6881930839902,
            "rating_q975": 1385.9489000994402,
            "rating_q025": 1355.4274860685402
        },
        "mistral-medium-2508": {
            "rating": 1369.113430803963,
            "rating_q975": 1387.7024546708103,
            "rating_q025": 1350.5244069371156
        },
        "claude-3-5-sonnet-20241022": {
            "rating": 1366.619271895831,
            "rating_q975": 1372.366045499741,
            "rating_q025": 1360.8724982919207
        },
        "qwen3-235b-a22b-no-thinking": {
            "rating": 1365.9834103084954,
            "rating_q975": 1376.0682019364488,
            "rating_q025": 1355.8986186805419
        },
        "mai-1-preview": {
            "rating": 1365.4240805398665,
            "rating_q975": 1388.4417512032385,
            "rating_q025": 1342.4064098764945
        },
        "o1-preview": {
            "rating": 1364.9588001379566,
            "rating_q975": 1373.9753715069264,
            "rating_q025": 1355.9422287689868
        },
        "hunyuan-turbos-20250416": {
            "rating": 1364.291134046571,
            "rating_q975": 1378.5863288597036,
            "rating_q025": 1349.9959392334383
        },
        "mistral-medium-2505": {
            "rating": 1363.9691452506768,
            "rating_q975": 1373.3069968123057,
            "rating_q025": 1354.6312936890477
        },
        "gemini-1.5-pro-002": {
            "rating": 1359.4957964566072,
            "rating_q975": 1366.1152575560316,
            "rating_q025": 1352.8763353571828
        },
        "qwen2.5-max": {
            "rating": 1357.3526290142843,
            "rating_q975": 1365.3073366482083,
            "rating_q025": 1349.39792138036
        },
        "qwen3-coder-480b-a35b-instruct": {
            "rating": 1355.8204949509923,
            "rating_q975": 1369.632001333172,
            "rating_q025": 1342.0089885688126
        },
        "deepseek-v3": {
            "rating": 1350.0004899390588,
            "rating_q975": 1359.375341470653,
            "rating_q025": 1340.6256384074645
        },
        "o4-mini-2025-04-16": {
            "rating": 1349.2523439112827,
            "rating_q975": 1358.8703863738267,
            "rating_q025": 1339.6343014487386
        },
        "gemma-3-27b-it": {
            "rating": 1349.0113560018012,
            "rating_q975": 1357.3586351772678,
            "rating_q025": 1340.6640768263346
        },
        "gemini-2.0-flash-001": {
            "rating": 1347.9817471086876,
            "rating_q975": 1355.500125327959,
            "rating_q025": 1340.4633688894164
        },
        "gpt-4.1-mini-2025-04-14": {
            "rating": 1347.7294795314133,
            "rating_q975": 1357.3991543969319,
            "rating_q025": 1338.0598046658947
        },
        "glm-4.5-air": {
            "rating": 1346.8246328225653,
            "rating_q975": 1362.9145716113471,
            "rating_q025": 1330.7346940337834
        },
        "gemini-2.0-flash-lite-preview-02-05": {
            "rating": 1345.7585908664773,
            "rating_q975": 1354.4107392931157,
            "rating_q025": 1337.1064424398392
        },
        "gemini-advanced-0514": {
            "rating": 1344.833013206618,
            "rating_q975": 1354.0390190614673,
            "rating_q025": 1335.6270073517685
        },
        "grok-3-mini-beta": {
            "rating": 1341.152141544193,
            "rating_q975": 1352.360961352883,
            "rating_q025": 1329.943321735503
        },
        "gpt-4o-2024-05-13": {
            "rating": 1339.2584898170148,
            "rating_q975": 1345.57947698958,
            "rating_q025": 1332.93750264445
        },
        "step-2-16k-exp-202412": {
            "rating": 1337.7056493415998,
            "rating_q975": 1357.344188975571,
            "rating_q025": 1318.0671097076288
        },
        "qwen3-30b-a3b-instruct-2507": {
            "rating": 1337.3225780865857,
            "rating_q975": 1354.5423895688182,
            "rating_q025": 1320.1027666043535
        },
        "minimax-m1": {
            "rating": 1335.3800511870127,
            "rating_q975": 1346.3011608286045,
            "rating_q025": 1324.4589415454207
        },
        "qwen3-235b-a22b": {
            "rating": 1334.7868276779193,
            "rating_q975": 1344.933309741402,
            "rating_q025": 1324.6403456144365
        },
        "command-a-03-2025": {
            "rating": 1334.1212510877538,
            "rating_q975": 1342.6033237198599,
            "rating_q025": 1325.6391784556477
        },
        "llama-3.1-nemotron-ultra-253b-v1": {
            "rating": 1333.9132183997392,
            "rating_q975": 1359.747727143118,
            "rating_q025": 1308.0787096563604
        },
        "gemma-3-12b-it": {
            "rating": 1333.2221392453755,
            "rating_q975": 1355.4760597470954,
            "rating_q025": 1310.9682187436554
        },
        "mistral-small-2506": {
            "rating": 1332.735462996171,
            "rating_q975": 1345.887880711171,
            "rating_q025": 1319.583045281171
        },
        "grok-3-mini-high": {
            "rating": 1330.4868945705011,
            "rating_q975": 1343.6732645842735,
            "rating_q025": 1317.300524556729
        },
        "gpt-4o-2024-08-06": {
            "rating": 1327.8204893980571,
            "rating_q975": 1335.5079392226885,
            "rating_q025": 1320.133039573426
        },
        "gpt-4-turbo-2024-04-09": {
            "rating": 1325.946236299157,
            "rating_q975": 1332.9123532607643,
            "rating_q025": 1318.9801193375495
        },
        "gemini-1.5-pro-001": {
            "rating": 1324.6224696880977,
            "rating_q975": 1331.9467742493396,
            "rating_q025": 1317.2981651268558
        },
        "gpt-5-mini-high": {
            "rating": 1322.4561755045358,
            "rating_q975": 1341.892591563104,
            "rating_q025": 1303.0197594459678
        },
        "grok-2-2024-08-13": {
            "rating": 1318.5740097314015,
            "rating_q975": 1325.2224820447677,
            "rating_q025": 1311.9255374180352
        },
        "qwen-plus-0125": {
            "rating": 1316.3649693169693,
            "rating_q975": 1333.3441746576066,
            "rating_q025": 1299.385763976332
        },
        "glm-4-plus-0111": {
            "rating": 1316.077420387385,
            "rating_q975": 1334.0223397160312,
            "rating_q025": 1298.132501058739
        },
        "o3-mini-high": {
            "rating": 1315.9964402499083,
            "rating_q975": 1326.0997738524704,
            "rating_q025": 1305.893106647346
        },
        "deepseek-v2.5-1210": {
            "rating": 1312.5922913095287,
            "rating_q975": 1328.7155264048718,
            "rating_q025": 1296.4690562141855
        },
        "qwen3-32b": {
            "rating": 1310.490884366881,
            "rating_q975": 1332.356837579653,
            "rating_q025": 1288.6249311541087
        },
        "llama-3.1-405b-instruct-fp8": {
            "rating": 1308.6205813394677,
            "rating_q975": 1315.5640219696081,
            "rating_q025": 1301.6771407093272
        },
        "gpt-4.1-nano-2025-04-14": {
            "rating": 1308.2082669709412,
            "rating_q975": 1326.043866487294,
            "rating_q025": 1290.372667454588
        },
        "hunyuan-turbo-0110": {
            "rating": 1307.3414474694384,
            "rating_q975": 1329.7588607383227,
            "rating_q025": 1284.924034200554
        },
        "nvidia-llama-3.3-nemotron-super-49b-v1.5": {
            "rating": 1307.1542876856429,
            "rating_q975": 1333.5382629978567,
            "rating_q025": 1280.7703123734289
        },
        "hunyuan-turbos-20250226": {
            "rating": 1306.7177507267604,
            "rating_q975": 1329.4513493759719,
            "rating_q025": 1283.984152077549
        },
        "o3-mini": {
            "rating": 1306.6472523958132,
            "rating_q975": 1313.8226727884373,
            "rating_q025": 1299.471832003189
        },
        "claude-3-5-sonnet-20240620": {
            "rating": 1306.58762022799,
            "rating_q975": 1313.343734246362,
            "rating_q025": 1299.831506209618
        },
        "llama-4-maverick-17b-128e-instruct": {
            "rating": 1306.281618032479,
            "rating_q975": 1315.8094401704047,
            "rating_q025": 1296.7537958945531
        },
        "llama-3.1-405b-instruct-bf16": {
            "rating": 1306.076900088673,
            "rating_q975": 1313.0306469179807,
            "rating_q025": 1299.1231532593654
        },
        "hunyuan-large-2025-02-10": {
            "rating": 1305.5222507991703,
            "rating_q975": 1328.4172837069575,
            "rating_q025": 1282.6272178913832
        },
        "gemini-1.5-flash-002": {
            "rating": 1303.480347824865,
            "rating_q975": 1311.5844320024862,
            "rating_q025": 1295.3762636472438
        },
        "gemma-3n-e4b-it": {
            "rating": 1302.7305550938402,
            "rating_q975": 1314.6139510617288,
            "rating_q025": 1290.8471591259515
        },
        "step-3": {
            "rating": 1302.3672570975173,
            "rating_q975": 1330.9433286656015,
            "rating_q025": 1273.791185529433
        },
        "claude-3-5-haiku-20241022": {
            "rating": 1302.299558207662,
            "rating_q975": 1308.7870365973556,
            "rating_q025": 1295.8120798179682
        },
        "yi-lightning": {
            "rating": 1301.7326063040614,
            "rating_q975": 1311.4136000018987,
            "rating_q025": 1292.0516126062241
        },
        "qwq-32b": {
            "rating": 1301.6285182691586,
            "rating_q975": 1311.4390682919866,
            "rating_q025": 1291.8179682463303
        },
        "step-1o-turbo-202506": {
            "rating": 1301.0931712555898,
            "rating_q975": 1317.920811185332,
            "rating_q025": 1284.2655313258476
        },
        "llama-3.3-nemotron-49b-super-v1": {
            "rating": 1299.8669051647835,
            "rating_q975": 1324.8876421762775,
            "rating_q025": 1274.8461681532897
        },
        "gpt-4o-mini-2024-07-18": {
            "rating": 1298.1878446982628,
            "rating_q975": 1304.36642472482,
            "rating_q025": 1292.0092646717058
        },
        "gemma-2-27b-it": {
            "rating": 1295.5825995688517,
            "rating_q975": 1301.6081463799317,
            "rating_q025": 1289.5570527577718
        },
        "claude-3-opus-20240229": {
            "rating": 1293.9892824274816,
            "rating_q975": 1299.6514980268817,
            "rating_q025": 1288.3270668280813
        },
        "glm-4-plus": {
            "rating": 1293.451362606123,
            "rating_q975": 1302.9246874726884,
            "rating_q025": 1283.9780377395577
        },
        "gpt-4-1106-preview": {
            "rating": 1292.9573224514888,
            "rating_q975": 1300.0707925346032,
            "rating_q025": 1285.8438523683744
        },
        "hunyuan-large-vision": {
            "rating": 1292.799155735957,
            "rating_q975": 1314.4718876865857,
            "rating_q025": 1271.126423785328
        },
        "mistral-large-2407": {
            "rating": 1292.2505356963848,
            "rating_q975": 1300.0778970315885,
            "rating_q025": 1284.4231743611808
        },
        "llama-3.3-70b-instruct": {
            "rating": 1292.0369510237101,
            "rating_q975": 1298.6337516506476,
            "rating_q025": 1285.4401503967722
        },
        "qwen3-30b-a3b": {
            "rating": 1291.7006868618255,
            "rating_q975": 1301.9821039220574,
            "rating_q025": 1281.419269801594
        },
        "gemma-2-9b-it-simpo": {
            "rating": 1289.4827701046936,
            "rating_q975": 1303.144687530981,
            "rating_q025": 1275.8208526784065
        },
        "llama-4-scout-17b-16e-instruct": {
            "rating": 1289.4466230019505,
            "rating_q975": 1301.094641061717,
            "rating_q025": 1277.7986049421838
        },
        "gpt-oss-120b": {
            "rating": 1289.1424865898132,
            "rating_q975": 1306.944314374922,
            "rating_q025": 1271.3406588047044
        },
        "qwen-max-0919": {
            "rating": 1289.0504276051329,
            "rating_q975": 1300.2252643604381,
            "rating_q025": 1277.8755908498279
        },
        "amazon-nova-experimental-chat-05-14": {
            "rating": 1288.9055154272673,
            "rating_q975": 1300.8944866413633,
            "rating_q025": 1276.9165442131716
        },
        "magistral-medium-2506": {
            "rating": 1287.2621411354771,
            "rating_q975": 1304.0962256294472,
            "rating_q025": 1270.428056641507
        },
        "gpt-4-0125-preview": {
            "rating": 1286.405646399457,
            "rating_q975": 1293.7707315271937,
            "rating_q025": 1279.0405612717207
        },
        "o1-mini": {
            "rating": 1285.1404830288575,
            "rating_q975": 1292.0408863681264,
            "rating_q025": 1278.2400796895886
        },
        "llama-3.1-nemotron-70b-instruct": {
            "rating": 1283.053440736785,
            "rating_q975": 1300.7427229005766,
            "rating_q025": 1265.3641585729933
        },
        "gemma-3-4b-it": {
            "rating": 1282.2073965129784,
            "rating_q975": 1303.1791736402358,
            "rating_q025": 1261.2356193857208
        },
        "mistral-small-3.1-24b-instruct-2503": {
            "rating": 1281.0049497479845,
            "rating_q975": 1292.7580943248213,
            "rating_q025": 1269.2518051711477
        },
        "mistral-large-2411": {
            "rating": 1280.6950002836984,
            "rating_q975": 1289.0465433106594,
            "rating_q025": 1272.343457256737
        },
        "hunyuan-standard-2025-02-10": {
            "rating": 1277.9754575385973,
            "rating_q975": 1301.0055333863104,
            "rating_q025": 1254.9453816908845
        },
        "grok-2-mini-2024-08-13": {
            "rating": 1276.648993518164,
            "rating_q975": 1283.5571496854889,
            "rating_q025": 1269.7408373508392
        },
        "athene-70b-0725": {
            "rating": 1276.2954859040387,
            "rating_q975": 1286.914390008051,
            "rating_q025": 1265.6765818000263
        },
        "qwen2.5-plus-1127": {
            "rating": 1275.376397586746,
            "rating_q975": 1288.804541583521,
            "rating_q025": 1261.9482535899708
        },
        "reka-core-20240904": {
            "rating": 1274.047322530792,
            "rating_q975": 1290.9566745789161,
            "rating_q025": 1257.1379704826677
        },
        "gpt-5-nano-high": {
            "rating": 1271.3194288182108,
            "rating_q975": 1296.1361419382158,
            "rating_q025": 1246.5027156982057
        },
        "gpt-4-0613": {
            "rating": 1271.0076899838675,
            "rating_q975": 1278.5994585225426,
            "rating_q025": 1263.4159214451922
        },
        "deepseek-v2.5": {
            "rating": 1270.1565349244224,
            "rating_q975": 1279.9566144402165,
            "rating_q025": 1260.3564554086283
        },
        "command-r-plus-08-2024": {
            "rating": 1269.2274374320607,
            "rating_q975": 1283.243920080762,
            "rating_q025": 1255.210954783359
        },
        "gemini-1.5-flash-001": {
            "rating": 1268.5067351937212,
            "rating_q975": 1276.1752056355372,
            "rating_q025": 1260.838264751905
        },
        "jamba-1.5-large": {
            "rating": 1266.7398622726828,
            "rating_q975": 1281.765438109848,
            "rating_q025": 1251.7142864355174
        },
        "llama-3.1-70b-instruct": {
            "rating": 1264.885910478889,
            "rating_q975": 1271.9128248277448,
            "rating_q025": 1257.8589961300331
        },
        "llama-3.1-nemotron-51b-instruct": {
            "rating": 1264.4080220669357,
            "rating_q975": 1289.0159589934267,
            "rating_q025": 1239.8000851404447
        },
        "gemma-2-9b-it": {
            "rating": 1263.298360405544,
            "rating_q975": 1269.9963265983467,
            "rating_q025": 1256.600394212741
        },
        "qwen2.5-72b-instruct": {
            "rating": 1260.340524037228,
            "rating_q975": 1268.0108949049663,
            "rating_q025": 1252.6701531694898
        },
        "gpt-4-0314": {
            "rating": 1260.2804481588469,
            "rating_q975": 1269.5823993017248,
            "rating_q025": 1250.978497015969
        },
        "llama-3-70b-instruct": {
            "rating": 1260.266163146418,
            "rating_q975": 1267.0577663892866,
            "rating_q025": 1253.474559903549
        },
        "athene-v2-chat": {
            "rating": 1259.8396269267005,
            "rating_q975": 1268.912160386284,
            "rating_q025": 1250.767093467117
        },
        "gpt-oss-20b": {
            "rating": 1256.3111443924922,
            "rating_q975": 1276.0350056406437,
            "rating_q025": 1236.5872831443405
        },
        "llama-3.1-tulu-3-70b": {
            "rating": 1255.0354974118634,
            "rating_q975": 1278.9211238433088,
            "rating_q025": 1231.149870980418
        },
        "claude-3-sonnet-20240229": {
            "rating": 1253.1107872636235,
            "rating_q975": 1260.5840727008954,
            "rating_q025": 1245.6375018263518
        },
        "glm-4-0520": {
            "rating": 1251.4636235392609,
            "rating_q975": 1265.760829959489,
            "rating_q025": 1237.1664171190325
        },
        "reka-flash-20240904": {
            "rating": 1250.113845037306,
            "rating_q975": 1266.5368870583613,
            "rating_q025": 1233.6908030162504
        },
        "gemini-1.5-flash-8b-001": {
            "rating": 1246.4848439632988,
            "rating_q975": 1254.5817013932083,
            "rating_q025": 1238.3879865333893
        },
        "nemotron-4-340b-instruct": {
            "rating": 1245.694166333794,
            "rating_q975": 1256.5125425685976,
            "rating_q025": 1234.8757900989906
        },
        "command-r-plus": {
            "rating": 1244.0718537669009,
            "rating_q975": 1251.9669337609812,
            "rating_q025": 1236.1767737728205
        },
        "amazon-nova-pro-v1.0": {
            "rating": 1243.6764336515066,
            "rating_q975": 1252.4992366006759,
            "rating_q025": 1234.8536307023371
        },
        "mistral-small-24b-instruct-2501": {
            "rating": 1236.9162341478695,
            "rating_q975": 1248.5464862792107,
            "rating_q025": 1225.2859820165281
        },
        "c4ai-aya-expanse-32b": {
            "rating": 1235.2557959176665,
            "rating_q975": 1244.3614567252978,
            "rating_q025": 1226.150135110035
        },
        "qwen2-72b-instruct": {
            "rating": 1232.0680231047027,
            "rating_q975": 1240.8849352276975,
            "rating_q025": 1223.2511109817078
        },
        "amazon-nova-lite-v1.0": {
            "rating": 1231.0680539775292,
            "rating_q975": 1240.7736155145274,
            "rating_q025": 1221.362492440531
        },
        "olmo-2-0325-32b-instruct": {
            "rating": 1230.4657905141955,
            "rating_q975": 1254.2476955969562,
            "rating_q025": 1206.6838854314349
        },
        "ministral-8b-2410": {
            "rating": 1226.6418101971212,
            "rating_q975": 1247.2620835645937,
            "rating_q025": 1206.0215368296485
        },
        "claude-3-haiku-20240307": {
            "rating": 1223.5624030588237,
            "rating_q975": 1230.3845718939785,
            "rating_q025": 1216.7402342236687
        },
        "command-r-08-2024": {
            "rating": 1221.6052927824076,
            "rating_q975": 1235.9884862461442,
            "rating_q025": 1207.2220993186709
        },
        "phi-4": {
            "rating": 1220.7464163936877,
            "rating_q975": 1229.701032591659,
            "rating_q025": 1211.7918001957166
        },
        "jamba-1.5-mini": {
            "rating": 1218.0774672181865,
            "rating_q975": 1232.8519098099284,
            "rating_q025": 1203.3030246264448
        },
        "mistral-large-2402": {
            "rating": 1217.9328018897,
            "rating_q975": 1226.6608815948312,
            "rating_q025": 1209.2047221845683
        },
        "deepseek-coder-v2": {
            "rating": 1212.9441123236306,
            "rating_q975": 1225.204377776884,
            "rating_q025": 1200.6838468703772
        },
        "qwen2.5-coder-32b-instruct": {
            "rating": 1212.0558594534386,
            "rating_q975": 1230.6903439837993,
            "rating_q025": 1193.4213749230778
        },
        "amazon-nova-micro-v1.0": {
            "rating": 1209.3263016135447,
            "rating_q975": 1219.2959668222113,
            "rating_q025": 1199.3566364048781
        },
        "gemini-pro-dev-api": {
            "rating": 1209.2970774141284,
            "rating_q975": 1222.6254405124416,
            "rating_q025": 1195.968714315815
        },
        "hunyuan-standard-256k": {
            "rating": 1208.3397247168728,
            "rating_q975": 1235.31528490621,
            "rating_q025": 1181.3641645275354
        },
        "wizardlm-70b": {
            "rating": 1207.5014599494434,
            "rating_q975": 1223.9505998880811,
            "rating_q025": 1191.0523200108055
        },
        "command-r": {
            "rating": 1204.9315243091007,
            "rating_q975": 1213.977110960561,
            "rating_q025": 1195.8859376576404
        },
        "llama-3-8b-instruct": {
            "rating": 1204.500806157383,
            "rating_q975": 1211.897670611928,
            "rating_q025": 1197.103941702838
        },
        "mistral-medium": {
            "rating": 1204.0745005758138,
            "rating_q975": 1214.388179284102,
            "rating_q025": 1193.7608218675255
        },
        "c4ai-aya-expanse-8b": {
            "rating": 1203.4261330753147,
            "rating_q975": 1217.406848315156,
            "rating_q025": 1189.4454178354736
        },
        "qwen1.5-110b-chat": {
            "rating": 1202.8286744101756,
            "rating_q975": 1213.7644275359683,
            "rating_q025": 1191.8929212843832
        },
        "llama-3.1-tulu-3-8b": {
            "rating": 1201.6217222680752,
            "rating_q975": 1225.6426627242586,
            "rating_q025": 1177.6007818118917
        },
        "mixtral-8x22b-instruct-v0.1": {
            "rating": 1199.9380505614245,
            "rating_q975": 1208.5130301336108,
            "rating_q025": 1191.3630709892382
        },
        "qwen1.5-72b-chat": {
            "rating": 1196.3198795469334,
            "rating_q975": 1205.8321827485547,
            "rating_q025": 1186.8075763453119
        },
        "gpt-3.5-turbo-0125": {
            "rating": 1195.6153688243917,
            "rating_q975": 1203.7619822610286,
            "rating_q025": 1187.4687553877548
        },
        "openchat-3.5": {
            "rating": 1194.0769093567644,
            "rating_q975": 1211.329211757981,
            "rating_q025": 1176.8246069555476
        },
        "gemma-2-2b-it": {
            "rating": 1193.1181831391311,
            "rating_q975": 1200.6461507047638,
            "rating_q025": 1185.5902155734984
        },
        "reka-flash-21b-20240226-online": {
            "rating": 1190.413843911243,
            "rating_q975": 1204.1880447752474,
            "rating_q025": 1176.6396430472385
        },
        "gemini-pro": {
            "rating": 1189.7906570969105,
            "rating_q975": 1210.5652273186,
            "rating_q025": 1169.0160868752212
        },
        "llama-3.1-8b-instruct": {
            "rating": 1187.6870771927265,
            "rating_q975": 1195.2956185719288,
            "rating_q025": 1180.0785358135245
        },
        "granite-3.1-8b-instruct": {
            "rating": 1184.9794592680755,
            "rating_q975": 1209.7433506502775,
            "rating_q025": 1160.2155678858737
        },
        "reka-flash-21b-20240226": {
            "rating": 1184.3209381004403,
            "rating_q975": 1195.8645783691973,
            "rating_q025": 1172.7772978316834
        },
        "vicuna-33b": {
            "rating": 1182.8324162219812,
            "rating_q975": 1194.3094405141455,
            "rating_q025": 1171.355391929817
        },
        "zephyr-orpo-141b-A35b-v0.1": {
            "rating": 1176.4684315264524,
            "rating_q975": 1198.5767115390136,
            "rating_q025": 1154.3601515138912
        },
        "dbrx-instruct-preview": {
            "rating": 1171.7554735867816,
            "rating_q975": 1182.7394821672854,
            "rating_q025": 1160.771465006278
        },
        "yi-1.5-34b-chat": {
            "rating": 1170.5952931342401,
            "rating_q975": 1181.0219297283993,
            "rating_q025": 1160.168656540081
        },
        "mixtral-8x7b-instruct-v0.1": {
            "rating": 1169.5143463136621,
            "rating_q975": 1177.43334259378,
            "rating_q025": 1161.5953500335443
        },
        "openhermes-2.5-mistral-7b": {
            "rating": 1166.239785614038,
            "rating_q975": 1187.711821463263,
            "rating_q025": 1144.767749764813
        },
        "yi-34b-chat": {
            "rating": 1163.6610745513158,
            "rating_q975": 1176.7574935271386,
            "rating_q025": 1150.5646555754931
        },
        "falcon-180b-chat": {
            "rating": 1163.6163106981892,
            "rating_q975": 1199.9084588810317,
            "rating_q025": 1127.3241625153466
        },
        "granite-3.1-2b-instruct": {
            "rating": 1160.948758486921,
            "rating_q975": 1187.7418254316703,
            "rating_q025": 1134.1556915421716
        },
        "phi-3-medium-4k-instruct": {
            "rating": 1160.7719696040326,
            "rating_q975": 1170.9430573406055,
            "rating_q025": 1150.6008818674602
        },
        "gpt-3.5-turbo-1106": {
            "rating": 1158.058137023275,
            "rating_q975": 1172.6857553014613,
            "rating_q025": 1143.4305187450889
        },
        "openchat-3.5-0106": {
            "rating": 1156.3396053431766,
            "rating_q975": 1170.7028631143696,
            "rating_q025": 1141.9763475719833
        },
        "tulu-2-dpo-70b": {
            "rating": 1155.9132603530998,
            "rating_q975": 1174.8187742596647,
            "rating_q025": 1137.007746446535
        },
        "gemma-1.1-7b-it": {
            "rating": 1154.129301211442,
            "rating_q975": 1165.0247497046612,
            "rating_q025": 1143.2338527182228
        },
        "llama-3.2-3b-instruct": {
            "rating": 1153.7251980626365,
            "rating_q975": 1172.1958947494,
            "rating_q025": 1135.2545013758731
        },
        "snowflake-arctic-instruct": {
            "rating": 1152.2289885993864,
            "rating_q975": 1163.6499669927164,
            "rating_q025": 1140.8080102060567
        },
        "wizardlm-13b": {
            "rating": 1150.4861761546301,
            "rating_q975": 1167.7994615075193,
            "rating_q025": 1133.172890801741
        },
        "granite-3.0-8b-instruct": {
            "rating": 1148.8504079015952,
            "rating_q975": 1168.9637362002877,
            "rating_q025": 1128.7370796029024
        },
        "solar-10.7b-instruct-v1.0": {
            "rating": 1148.6265386221244,
            "rating_q975": 1171.9302894994444,
            "rating_q025": 1125.3227877448046
        },
        "qwen1.5-14b-chat": {
            "rating": 1148.4748377621881,
            "rating_q975": 1161.9346895406466,
            "rating_q025": 1135.0149859837297
        },
        "zephyr-7b-beta": {
            "rating": 1146.6244076551059,
            "rating_q975": 1162.1911817406456,
            "rating_q025": 1131.0576335695662
        },
        "nous-hermes-2-mixtral-8x7b-dpo": {
            "rating": 1146.3569694697314,
            "rating_q975": 1169.271079716523,
            "rating_q025": 1123.44285922294
        },
        "dolphin-2.2.1-mistral-7b": {
            "rating": 1146.1368185862527,
            "rating_q975": 1179.3027676239103,
            "rating_q025": 1112.9708695485951
        },
        "internlm2_5-20b-chat": {
            "rating": 1146.1286932645469,
            "rating_q975": 1161.1089518880779,
            "rating_q025": 1131.148434641016
        },
        "starling-lm-7b-alpha": {
            "rating": 1145.6123158101057,
            "rating_q975": 1160.7836355433146,
            "rating_q025": 1130.4409960768967
        },
        "phi-3-small-8k-instruct": {
            "rating": 1145.3947524213518,
            "rating_q975": 1157.7078383837907,
            "rating_q025": 1133.0816664589129
        },
        "qwen1.5-32b-chat": {
            "rating": 1143.8508988036056,
            "rating_q975": 1155.583526896898,
            "rating_q025": 1132.1182707103133
        },
        "mpt-30b-chat": {
            "rating": 1142.5957426973068,
            "rating_q975": 1171.3549513183393,
            "rating_q025": 1113.8365340762746
        },
        "guanaco-33b": {
            "rating": 1142.5721872536617,
            "rating_q975": 1169.8430583832462,
            "rating_q025": 1115.3013161240772
        },
        "deepseek-llm-67b-chat": {
            "rating": 1140.9628696509044,
            "rating_q975": 1162.3902691940214,
            "rating_q025": 1119.5354701077874
        },
        "vicuna-13b": {
            "rating": 1133.9326068418359,
            "rating_q975": 1146.1222947018327,
            "rating_q025": 1121.742918981839
        },
        "llama2-70b-steerlm-chat": {
            "rating": 1132.2687005911926,
            "rating_q975": 1157.1641531348962,
            "rating_q025": 1107.3732480474887
        },
        "qwq-32b-preview": {
            "rating": 1127.6863939291568,
            "rating_q975": 1155.6131851933337,
            "rating_q025": 1099.7596026649799
        },
        "llama-2-70b-chat": {
            "rating": 1124.4503245590852,
            "rating_q975": 1133.982640040863,
            "rating_q025": 1114.9180090773073
        },
        "starling-lm-7b-beta": {
            "rating": 1119.9998018958104,
            "rating_q975": 1134.0185617696784,
            "rating_q025": 1105.9810420219426
        },
        "mistral-7b-instruct-v0.2": {
            "rating": 1117.1966231850233,
            "rating_q975": 1129.1598162379305,
            "rating_q025": 1105.2334301321162
        },
        "zephyr-7b-alpha": {
            "rating": 1114.4138771411044,
            "rating_q975": 1143.8970224260804,
            "rating_q025": 1084.9307318561284
        },
        "granite-3.0-2b-instruct": {
            "rating": 1114.2011880986302,
            "rating_q975": 1134.8214330918975,
            "rating_q025": 1093.5809431053626
        },
        "phi-3-mini-4k-instruct-june-2024": {
            "rating": 1109.295051833005,
            "rating_q975": 1122.957239632719,
            "rating_q025": 1095.6328640332908
        },
        "qwen-14b-chat": {
            "rating": 1109.2374867687824,
            "rating_q975": 1129.6011954767419,
            "rating_q025": 1088.873778060823
        },
        "gemma-7b-it": {
            "rating": 1107.0970555853985,
            "rating_q975": 1124.4193259563808,
            "rating_q025": 1089.7747852144162
        },
        "llama-2-13b-chat": {
            "rating": 1104.0400011914207,
            "rating_q975": 1116.01408889042,
            "rating_q025": 1092.0659134924217
        },
        "mistral-7b-instruct": {
            "rating": 1103.6867652794808,
            "rating_q975": 1120.0205960482035,
            "rating_q025": 1087.3529345107581
        },
        "smollm2-1.7b-instruct": {
            "rating": 1100.7126530116734,
            "rating_q975": 1133.1278370552304,
            "rating_q025": 1068.2974689681164
        },
        "stripedhyena-nous-7b": {
            "rating": 1100.5512789817867,
            "rating_q975": 1120.9184827847155,
            "rating_q025": 1080.1840751788577
        },
        "gemma-1.1-2b-it": {
            "rating": 1100.5126199478027,
            "rating_q975": 1116.5605208999268,
            "rating_q025": 1084.4647189956788
        },
        "phi-3-mini-128k-instruct": {
            "rating": 1100.1039545739018,
            "rating_q975": 1113.6278686385674,
            "rating_q025": 1086.5800405092364
        },
        "llama-3.2-1b-instruct": {
            "rating": 1099.7455878539843,
            "rating_q975": 1118.9132864173635,
            "rating_q025": 1080.577889290605
        },
        "vicuna-7b": {
            "rating": 1098.2228506502238,
            "rating_q975": 1115.9012870036192,
            "rating_q025": 1080.544414296828
        },
        "codellama-34b-instruct": {
            "rating": 1096.8205516625708,
            "rating_q975": 1113.0095757343029,
            "rating_q025": 1080.6315275908385
        },
        "alpaca-13b": {
            "rating": 1095.0013274671687,
            "rating_q975": 1116.7300872746698,
            "rating_q025": 1073.2725676596674
        },
        "palm-2": {
            "rating": 1093.8035934699951,
            "rating_q975": 1110.9064540901447,
            "rating_q025": 1076.7007328498457
        },
        "qwen1.5-7b-chat": {
            "rating": 1091.2590948451489,
            "rating_q975": 1113.2206918569798,
            "rating_q025": 1069.2974978333182
        },
        "llama-2-7b-chat": {
            "rating": 1085.5940852714778,
            "rating_q975": 1098.599957463913,
            "rating_q025": 1072.5882130790428
        },
        "gemma-2b-it": {
            "rating": 1084.1939783695716,
            "rating_q975": 1106.999709067032,
            "rating_q025": 1061.388247672111
        },
        "phi-3-mini-4k-instruct": {
            "rating": 1083.3950402740224,
            "rating_q975": 1095.6097372535207,
            "rating_q025": 1071.1803432945244
        },
        "gpt4all-13b-snoozy": {
            "rating": 1067.4121593737923,
            "rating_q975": 1104.1067451803822,
            "rating_q025": 1030.7175735672024
        },
        "qwen1.5-4b-chat": {
            "rating": 1057.8728055655847,
            "rating_q975": 1076.0609568163907,
            "rating_q025": 1039.684654314779
        },
        "mpt-7b-chat": {
            "rating": 1056.1104466453753,
            "rating_q975": 1080.0785311933219,
            "rating_q025": 1032.1423620974285
        },
        "koala-13b": {
            "rating": 1052.4058236430633,
            "rating_q975": 1072.7758270558736,
            "rating_q025": 1032.0358202302532
        },
        "chatglm3-6b": {
            "rating": 1048.1327114709654,
            "rating_q975": 1070.8175570482906,
            "rating_q025": 1025.4478658936403
        },
        "oasst-pythia-12b": {
            "rating": 1017.423137221791,
            "rating_q975": 1037.5881513955715,
            "rating_q025": 997.2581230480106
        },
        "chatglm2-6b": {
            "rating": 1017.2693059415633,
            "rating_q975": 1042.9672402805347,
            "rating_q025": 991.5713716025919
        },
        "olmo-7b-instruct": {
            "rating": 1016.763456457478,
            "rating_q975": 1036.7000210356687,
            "rating_q025": 996.8268918792872
        },
        "RWKV-4-Raven-14B": {
            "rating": 1013.0456838735383,
            "rating_q975": 1035.267277436006,
            "rating_q025": 990.8240903110708
        },
        "fastchat-t5-3b": {
            "rating": 996.4956740340016,
            "rating_q975": 1020.2692957322424,
            "rating_q025": 972.7220523357607
        },
        "dolly-v2-12b": {
            "rating": 973.4798523692396,
            "rating_q975": 1000.8861603745177,
            "rating_q025": 946.0735443639614
        },
        "chatglm-6b": {
            "rating": 961.6433420201699,
            "rating_q975": 986.0392405190167,
            "rating_q025": 937.247443521323
        },
        "stablelm-tuned-alpha-7b": {
            "rating": 940.3328036707904,
            "rating_q975": 968.5654132585859,
            "rating_q025": 912.100194082995
        },
        "llama-13b": {
            "rating": 936.2828322902872,
            "rating_q975": 969.7033828012493,
            "rating_q025": 902.8622817793248
        }
    },
    "english": {
        "claude-opus-4-1-20250805-thinking-16k": {
            "rating": 1465.9414871098816,
            "rating_q975": 1475.339607448664,
            "rating_q025": 1456.543366771099
        },
        "gemini-2.5-pro": {
            "rating": 1457.4342020696085,
            "rating_q975": 1463.4663585921355,
            "rating_q025": 1451.4020455470816
        },
        "gpt-5-high": {
            "rating": 1454.3592893359516,
            "rating_q975": 1462.7128072757178,
            "rating_q025": 1446.0057713961855
        },
        "claude-opus-4-1-20250805": {
            "rating": 1451.361178817761,
            "rating_q975": 1459.5514069325495,
            "rating_q025": 1443.1709507029725
        },
        "o3-2025-04-16": {
            "rating": 1448.069713311309,
            "rating_q975": 1453.5590056304293,
            "rating_q025": 1442.5804209921887
        },
        "chatgpt-4o-latest-20250326": {
            "rating": 1446.8641907768197,
            "rating_q975": 1452.3532000357332,
            "rating_q025": 1441.3751815179062
        },
        "gpt-4.5-preview-2025-02-27": {
            "rating": 1442.0503059093385,
            "rating_q975": 1448.8672759188191,
            "rating_q025": 1435.2333358998578
        },
        "grok-4-0709": {
            "rating": 1431.8564345820198,
            "rating_q975": 1438.8330825763092,
            "rating_q025": 1424.8797865877305
        },
        "gpt-5-chat": {
            "rating": 1431.3277873391735,
            "rating_q975": 1440.5791264282475,
            "rating_q025": 1422.0764482500995
        },
        "deepseek-v3.1": {
            "rating": 1431.0844014241593,
            "rating_q975": 1443.1657297432357,
            "rating_q025": 1419.0030731050826
        },
        "claude-opus-4-20250514-thinking-16k": {
            "rating": 1430.741503684535,
            "rating_q975": 1437.2110781777906,
            "rating_q025": 1424.2719291912795
        },
        "deepseek-r1-0528": {
            "rating": 1428.8374815195218,
            "rating_q975": 1435.7256761594222,
            "rating_q025": 1421.9492868796217
        },
        "mistral-medium-2508": {
            "rating": 1428.1928408622884,
            "rating_q975": 1438.2657011843667,
            "rating_q025": 1418.1199805402102
        },
        "qwen-max-2025-08-15": {
            "rating": 1427.5629543989373,
            "rating_q975": 1438.8854855685813,
            "rating_q025": 1416.2404232292931
        },
        "kimi-k2-0711-preview": {
            "rating": 1426.6792625804153,
            "rating_q975": 1433.4715041639452,
            "rating_q025": 1419.8870209968854
        },
        "qwen3-235b-a22b-instruct-2507": {
            "rating": 1425.284354423843,
            "rating_q975": 1432.9745008181644,
            "rating_q025": 1417.5942080295217
        },
        "deepseek-v3.1-thinking": {
            "rating": 1424.6377678605768,
            "rating_q975": 1437.406371925838,
            "rating_q025": 1411.869163795316
        },
        "glm-4.5": {
            "rating": 1422.2313264665402,
            "rating_q975": 1430.5172930584044,
            "rating_q025": 1413.945359874676
        },
        "claude-opus-4-20250514": {
            "rating": 1420.0253969054202,
            "rating_q975": 1426.1493743313183,
            "rating_q025": 1413.9014194795222
        },
        "grok-3-preview-02-24": {
            "rating": 1419.379593937713,
            "rating_q975": 1424.5409025646434,
            "rating_q025": 1414.2182853107824
        },
        "gpt-5-old": {
            "rating": 1418.8852467202926,
            "rating_q975": 1447.6695852292235,
            "rating_q025": 1390.1009082113617
        },
        "gpt-4.1-2025-04-14": {
            "rating": 1418.5751694453647,
            "rating_q975": 1424.423345196787,
            "rating_q025": 1412.7269936939422
        },
        "claude-sonnet-4-20250514-thinking-32k": {
            "rating": 1413.2268515519463,
            "rating_q975": 1419.715741473582,
            "rating_q025": 1406.7379616303103
        },
        "deepseek-r1": {
            "rating": 1408.7890111431684,
            "rating_q975": 1414.6851311679297,
            "rating_q025": 1402.8928911184069
        },
        "o1-2024-12-17": {
            "rating": 1408.2406949359645,
            "rating_q975": 1413.5026748291798,
            "rating_q025": 1402.9787150427492
        },
        "o4-mini-2025-04-16": {
            "rating": 1407.9768052603356,
            "rating_q975": 1413.833756638048,
            "rating_q025": 1402.1198538826231
        },
        "gemini-2.5-flash": {
            "rating": 1407.8116078281555,
            "rating_q975": 1413.5759059031473,
            "rating_q025": 1402.0473097531637
        },
        "mai-1-preview": {
            "rating": 1407.2873695260694,
            "rating_q975": 1419.7127245420547,
            "rating_q025": 1394.8620145100842
        },
        "o1-preview": {
            "rating": 1406.8701478493574,
            "rating_q975": 1412.7660658578059,
            "rating_q025": 1400.974229840909
        },
        "qwen3-235b-a22b-thinking-2507": {
            "rating": 1406.2080791725275,
            "rating_q975": 1415.3586682268465,
            "rating_q025": 1397.0574901182088
        },
        "qwen-vl-max-2025-08-13": {
            "rating": 1405.7871222956703,
            "rating_q975": 1427.2593300669987,
            "rating_q025": 1384.314914524342
        },
        "deepseek-v3-0324": {
            "rating": 1405.0901748737074,
            "rating_q975": 1410.6144217454253,
            "rating_q025": 1399.5659280019897
        },
        "qwen3-235b-a22b-no-thinking": {
            "rating": 1402.6552962597252,
            "rating_q975": 1408.790504251773,
            "rating_q025": 1396.5200882676775
        },
        "claude-3-7-sonnet-20250219-thinking-32k": {
            "rating": 1401.086363279141,
            "rating_q975": 1406.3604495978175,
            "rating_q025": 1395.8122769604645
        },
        "gpt-5-mini-high": {
            "rating": 1398.1871800554288,
            "rating_q975": 1408.2793911118163,
            "rating_q025": 1388.0949689990414
        },
        "mistral-medium-2505": {
            "rating": 1396.843817401509,
            "rating_q975": 1402.751140165898,
            "rating_q025": 1390.9364946371202
        },
        "minimax-m1": {
            "rating": 1395.9947899065405,
            "rating_q975": 1402.3873839474463,
            "rating_q025": 1389.6021958656345
        },
        "qwen3-coder-480b-a35b-instruct": {
            "rating": 1395.5307586752056,
            "rating_q975": 1403.1508892555103,
            "rating_q025": 1387.9106280949009
        },
        "claude-sonnet-4-20250514": {
            "rating": 1394.2756595054739,
            "rating_q975": 1400.5113255202555,
            "rating_q025": 1388.0399934906925
        },
        "gpt-4.1-mini-2025-04-14": {
            "rating": 1393.4562825488413,
            "rating_q975": 1399.3080238571729,
            "rating_q025": 1387.6045412405097
        },
        "hunyuan-turbos-20250416": {
            "rating": 1392.1516680998639,
            "rating_q975": 1400.0373910817086,
            "rating_q025": 1384.265945118019
        },
        "glm-4.5-air": {
            "rating": 1391.6846778315187,
            "rating_q975": 1400.2124505485199,
            "rating_q025": 1383.1569051145173
        },
        "hunyuan-t1-20250711": {
            "rating": 1390.5249154968485,
            "rating_q975": 1401.530022690159,
            "rating_q025": 1379.5198083035382
        },
        "qwen3-30b-a3b-instruct-2507": {
            "rating": 1387.0314225276145,
            "rating_q975": 1396.0754862445208,
            "rating_q025": 1377.9873588107082
        },
        "qwen3-235b-a22b": {
            "rating": 1386.745956443482,
            "rating_q975": 1392.8051227761064,
            "rating_q025": 1380.686790110858
        },
        "qwen2.5-max": {
            "rating": 1382.3482154313608,
            "rating_q975": 1387.2124283839207,
            "rating_q025": 1377.4840024788007
        },
        "claude-3-7-sonnet-20250219": {
            "rating": 1381.9296648803847,
            "rating_q975": 1386.8479111966496,
            "rating_q025": 1377.0114185641198
        },
        "step-3": {
            "rating": 1380.7942389378318,
            "rating_q975": 1395.1130162097058,
            "rating_q025": 1366.475461665958
        },
        "o3-mini-high": {
            "rating": 1378.3580434512398,
            "rating_q975": 1384.5970243313545,
            "rating_q025": 1372.1190625711251
        },
        "claude-3-5-sonnet-20241022": {
            "rating": 1377.2640443836078,
            "rating_q975": 1380.944714076871,
            "rating_q025": 1373.5833746903445
        },
        "mistral-small-2506": {
            "rating": 1374.8653294038413,
            "rating_q975": 1382.1081790023195,
            "rating_q025": 1367.6224798053631
        },
        "grok-3-mini-high": {
            "rating": 1373.8612224799456,
            "rating_q975": 1381.0399605696493,
            "rating_q025": 1366.682484390242
        },
        "llama-3.1-nemotron-ultra-253b-v1": {
            "rating": 1372.9934539493347,
            "rating_q975": 1387.6090515351932,
            "rating_q025": 1358.3778563634764
        },
        "glm-4.5v": {
            "rating": 1372.2981681588785,
            "rating_q975": 1395.5338569478797,
            "rating_q025": 1349.0624793698773
        },
        "llama-3.3-nemotron-49b-super-v1": {
            "rating": 1370.6434292579575,
            "rating_q975": 1385.509327844729,
            "rating_q025": 1355.7775306711858
        },
        "gemma-3-27b-it": {
            "rating": 1370.1366320784186,
            "rating_q975": 1375.2409931712389,
            "rating_q025": 1365.0322709855986
        },
        "deepseek-v3": {
            "rating": 1369.669395062824,
            "rating_q975": 1375.3059736245616,
            "rating_q025": 1364.0328165010865
        },
        "grok-3-mini-beta": {
            "rating": 1368.337999066017,
            "rating_q975": 1374.8509941934228,
            "rating_q025": 1361.825003938611
        },
        "gemini-2.0-flash-001": {
            "rating": 1368.2361827904244,
            "rating_q975": 1372.905689488842,
            "rating_q025": 1363.566676092007
        },
        "qwen3-32b": {
            "rating": 1366.1022368328847,
            "rating_q975": 1378.3966249347238,
            "rating_q025": 1353.8078487310456
        },
        "nvidia-llama-3.3-nemotron-super-49b-v1.5": {
            "rating": 1366.0948396378037,
            "rating_q975": 1379.3428917037988,
            "rating_q025": 1352.8467875718086
        },
        "gpt-oss-120b": {
            "rating": 1364.8492180974488,
            "rating_q975": 1374.1847992922567,
            "rating_q025": 1355.513636902641
        },
        "o3-mini": {
            "rating": 1363.1973031180635,
            "rating_q975": 1367.6872013973614,
            "rating_q025": 1358.7074048387656
        },
        "hunyuan-turbos-20250226": {
            "rating": 1362.0406255281334,
            "rating_q975": 1375.5355259362445,
            "rating_q025": 1348.5457251200223
        },
        "command-a-03-2025": {
            "rating": 1359.9430665014795,
            "rating_q975": 1365.1105320611287,
            "rating_q025": 1354.7756009418306
        },
        "llama-3.1-405b-instruct-bf16": {
            "rating": 1359.864771804307,
            "rating_q975": 1364.1389078338266,
            "rating_q025": 1355.5906357747876
        },
        "hunyuan-turbo-0110": {
            "rating": 1359.840981479227,
            "rating_q975": 1372.9373252568626,
            "rating_q025": 1346.7446377015915
        },
        "qwq-32b": {
            "rating": 1358.1790908251885,
            "rating_q975": 1363.9257691908265,
            "rating_q025": 1352.4324124595503
        },
        "gpt-5-nano-high": {
            "rating": 1356.0445036590727,
            "rating_q975": 1367.8508573935767,
            "rating_q025": 1344.2381499245687
        },
        "llama-3.1-405b-instruct-fp8": {
            "rating": 1355.8488609243661,
            "rating_q975": 1360.2004654890047,
            "rating_q025": 1351.4972563597275
        },
        "qwen-plus-0125": {
            "rating": 1355.2735652348804,
            "rating_q975": 1365.4554719887599,
            "rating_q025": 1345.0916584810009
        },
        "gemini-1.5-pro-002": {
            "rating": 1355.1190245574185,
            "rating_q975": 1359.1854686347715,
            "rating_q025": 1351.0525804800654
        },
        "gpt-4o-2024-05-13": {
            "rating": 1354.8798376242735,
            "rating_q975": 1359.0414358161784,
            "rating_q025": 1350.7182394323686
        },
        "gemini-2.0-flash-lite-preview-02-05": {
            "rating": 1354.1075027876216,
            "rating_q975": 1359.324021089576,
            "rating_q025": 1348.890984485667
        },
        "yi-lightning": {
            "rating": 1353.6894890702179,
            "rating_q975": 1359.8437128274256,
            "rating_q025": 1347.53526531301
        },
        "step-2-16k-exp-202412": {
            "rating": 1353.3356571014417,
            "rating_q975": 1363.6009591128204,
            "rating_q025": 1343.070355090063
        },
        "o1-mini": {
            "rating": 1353.3165533876966,
            "rating_q975": 1357.7400354057952,
            "rating_q025": 1348.893071369598
        },
        "glm-4-plus-0111": {
            "rating": 1349.781074581775,
            "rating_q975": 1359.739113169483,
            "rating_q025": 1339.8230359940667
        },
        "gemma-3-12b-it": {
            "rating": 1347.3949181969558,
            "rating_q975": 1359.0781702305694,
            "rating_q025": 1335.711666163342
        },
        "qwen3-30b-a3b": {
            "rating": 1346.6947137195932,
            "rating_q975": 1352.8520557777358,
            "rating_q025": 1340.5373716614506
        },
        "gpt-4o-2024-08-06": {
            "rating": 1346.082724597687,
            "rating_q975": 1351.0165941931784,
            "rating_q025": 1341.1488550021957
        },
        "claude-3-5-sonnet-20240620": {
            "rating": 1345.7151245108678,
            "rating_q975": 1349.8406082146876,
            "rating_q025": 1341.589640807048
        },
        "llama-3.3-70b-instruct": {
            "rating": 1344.1862826218621,
            "rating_q975": 1348.3181081971434,
            "rating_q025": 1340.054457046581
        },
        "gpt-oss-20b": {
            "rating": 1343.9895911607896,
            "rating_q975": 1353.7116245907896,
            "rating_q025": 1334.2675577307896
        },
        "grok-2-2024-08-13": {
            "rating": 1343.6085660172034,
            "rating_q975": 1347.7667961061204,
            "rating_q025": 1339.4503359282864
        },
        "hunyuan-large-2025-02-10": {
            "rating": 1343.045259087625,
            "rating_q975": 1355.1123427545276,
            "rating_q025": 1330.9781754207224
        },
        "gpt-4-turbo-2024-04-09": {
            "rating": 1341.156579570022,
            "rating_q975": 1345.6445615236876,
            "rating_q025": 1336.6685976163562
        },
        "llama-4-maverick-17b-128e-instruct": {
            "rating": 1340.5642179661759,
            "rating_q975": 1346.3042979418942,
            "rating_q025": 1334.8241379904578
        },
        "gemini-advanced-0514": {
            "rating": 1339.2139259185747,
            "rating_q975": 1344.9888915508877,
            "rating_q025": 1333.4389602862616
        },
        "gpt-4.1-nano-2025-04-14": {
            "rating": 1338.3425074437187,
            "rating_q975": 1348.1224748936177,
            "rating_q025": 1328.5625399938194
        },
        "step-1o-turbo-202506": {
            "rating": 1338.2601149152508,
            "rating_q975": 1346.855427992606,
            "rating_q025": 1329.6648018378955
        },
        "llama-4-scout-17b-16e-instruct": {
            "rating": 1337.3067373828487,
            "rating_q975": 1343.891549987575,
            "rating_q025": 1330.7219247781222
        },
        "deepseek-v2.5-1210": {
            "rating": 1335.7348028963631,
            "rating_q975": 1345.6549521136212,
            "rating_q025": 1325.8146536791048
        },
        "mistral-large-2407": {
            "rating": 1335.691658794704,
            "rating_q975": 1340.3808936795267,
            "rating_q025": 1331.0024239098814
        },
        "qwen2.5-plus-1127": {
            "rating": 1332.5276199914786,
            "rating_q975": 1340.0325527754935,
            "rating_q025": 1325.0226872074636
        },
        "claude-3-5-haiku-20241022": {
            "rating": 1331.892966325791,
            "rating_q975": 1335.9763973377271,
            "rating_q025": 1327.8095353138544
        },
        "athene-v2-chat": {
            "rating": 1331.5249391194666,
            "rating_q975": 1336.9011132265678,
            "rating_q025": 1326.1487650123654
        },
        "amazon-nova-experimental-chat-05-14": {
            "rating": 1330.2439019958833,
            "rating_q975": 1336.9689597788986,
            "rating_q025": 1323.5188442128683
        },
        "gpt-4o-mini-2024-07-18": {
            "rating": 1328.0881544662511,
            "rating_q975": 1331.994843566447,
            "rating_q025": 1324.1814653660556
        },
        "gemma-3n-e4b-it": {
            "rating": 1328.068667161695,
            "rating_q975": 1334.950167844992,
            "rating_q025": 1321.1871664783978
        },
        "llama-3.1-nemotron-70b-instruct": {
            "rating": 1327.7994816100927,
            "rating_q975": 1337.3221329389633,
            "rating_q025": 1318.276830281222
        },
        "qwen-max-0919": {
            "rating": 1327.4740295732104,
            "rating_q975": 1334.4037483393884,
            "rating_q025": 1320.5443108070326
        },
        "gemini-1.5-pro-001": {
            "rating": 1327.3235209574254,
            "rating_q975": 1332.055199213334,
            "rating_q025": 1322.591842701517
        },
        "gpt-4-1106-preview": {
            "rating": 1326.471500619494,
            "rating_q975": 1330.960618954564,
            "rating_q025": 1321.9823822844241
        },
        "athene-70b-0725": {
            "rating": 1326.1721458137938,
            "rating_q975": 1332.720997886713,
            "rating_q025": 1319.6232937408747
        },
        "gpt-4-0125-preview": {
            "rating": 1325.8150046066708,
            "rating_q975": 1330.5035562608837,
            "rating_q025": 1321.126452952458
        },
        "magistral-medium-2506": {
            "rating": 1325.2221123542877,
            "rating_q975": 1334.6164274063515,
            "rating_q025": 1315.8277973022239
        },
        "llama-3-70b-instruct": {
            "rating": 1325.1560284762388,
            "rating_q975": 1329.4321393295234,
            "rating_q025": 1320.8799176229545
        },
        "glm-4-plus": {
            "rating": 1324.5312244876725,
            "rating_q975": 1330.563412897493,
            "rating_q025": 1318.499036077852
        },
        "claude-3-opus-20240229": {
            "rating": 1323.8074479595016,
            "rating_q975": 1327.390533396299,
            "rating_q025": 1320.224362522704
        },
        "llama-3.1-70b-instruct": {
            "rating": 1321.3158031409619,
            "rating_q975": 1325.7265615645447,
            "rating_q025": 1316.905044717379
        },
        "mistral-small-3.1-24b-instruct-2503": {
            "rating": 1320.9742531188351,
            "rating_q975": 1327.6448002229988,
            "rating_q025": 1314.3037060146714
        },
        "mistral-large-2411": {
            "rating": 1320.8565205623836,
            "rating_q975": 1325.9504083658344,
            "rating_q025": 1315.7626327589333
        },
        "deepseek-v2.5": {
            "rating": 1319.644148319503,
            "rating_q975": 1325.3845109631447,
            "rating_q025": 1313.903785675861
        },
        "grok-2-mini-2024-08-13": {
            "rating": 1319.1612771396044,
            "rating_q975": 1323.5938363123,
            "rating_q025": 1314.728717966909
        },
        "hunyuan-standard-2025-02-10": {
            "rating": 1318.817864517348,
            "rating_q975": 1330.972101950622,
            "rating_q025": 1306.6636270840743
        },
        "llama-3.1-nemotron-51b-instruct": {
            "rating": 1317.417881037616,
            "rating_q975": 1330.549884396266,
            "rating_q025": 1304.285877678966
        },
        "gemini-1.5-flash-002": {
            "rating": 1316.667056319794,
            "rating_q975": 1321.7320259338162,
            "rating_q025": 1311.6020867057719
        },
        "qwen2.5-72b-instruct": {
            "rating": 1316.5361201657815,
            "rating_q975": 1321.2970970290255,
            "rating_q025": 1311.7751433025378
        },
        "hunyuan-large-vision": {
            "rating": 1315.8342021363646,
            "rating_q975": 1326.9588580379052,
            "rating_q025": 1304.709546234824
        },
        "jamba-1.5-large": {
            "rating": 1315.5561805448851,
            "rating_q975": 1324.4099893390678,
            "rating_q025": 1306.7023717507022
        },
        "gemma-3-4b-it": {
            "rating": 1308.4533774049044,
            "rating_q975": 1319.8700097472567,
            "rating_q025": 1297.036745062552
        },
        "amazon-nova-pro-v1.0": {
            "rating": 1304.8088941226663,
            "rating_q975": 1310.0469085363309,
            "rating_q025": 1299.570879709002
        },
        "llama-3.1-tulu-3-70b": {
            "rating": 1303.545695958356,
            "rating_q975": 1316.3046636822148,
            "rating_q025": 1290.7867282344969
        },
        "gpt-4-0314": {
            "rating": 1300.566414343671,
            "rating_q975": 1306.0820443312991,
            "rating_q025": 1295.0507843560429
        },
        "gemma-2-27b-it": {
            "rating": 1296.4334204464367,
            "rating_q975": 1300.3212413953854,
            "rating_q025": 1292.545599497488
        },
        "gemma-2-9b-it-simpo": {
            "rating": 1295.7281921643885,
            "rating_q975": 1304.0690595176663,
            "rating_q025": 1287.3873248111104
        },
        "mistral-small-24b-instruct-2501": {
            "rating": 1295.36903253549,
            "rating_q975": 1302.1566470307537,
            "rating_q025": 1288.5814180402263
        },
        "reka-core-20240904": {
            "rating": 1292.233927045489,
            "rating_q975": 1301.020436960211,
            "rating_q025": 1283.4474171307672
        },
        "gpt-4-0613": {
            "rating": 1291.9085576266925,
            "rating_q975": 1296.6158135795372,
            "rating_q025": 1287.2013016738474
        },
        "glm-4-0520": {
            "rating": 1289.8003900924418,
            "rating_q975": 1298.6808456625067,
            "rating_q025": 1280.919934522377
        },
        "nemotron-4-340b-instruct": {
            "rating": 1289.7163339433569,
            "rating_q975": 1296.6307774415661,
            "rating_q025": 1282.8018904451474
        },
        "olmo-2-0325-32b-instruct": {
            "rating": 1289.3812253781873,
            "rating_q975": 1302.0618309174922,
            "rating_q025": 1276.7006198388824
        },
        "gemini-1.5-flash-001": {
            "rating": 1288.8532257575375,
            "rating_q975": 1293.8584151926539,
            "rating_q025": 1283.8480363224212
        },
        "claude-3-sonnet-20240229": {
            "rating": 1288.816074281042,
            "rating_q975": 1293.3683309007617,
            "rating_q025": 1284.2638176613218
        },
        "qwen2.5-coder-32b-instruct": {
            "rating": 1287.5688091395518,
            "rating_q975": 1298.3011142834073,
            "rating_q025": 1276.8365039956966
        },
        "command-r-plus-08-2024": {
            "rating": 1287.3455905963922,
            "rating_q975": 1295.218880844367,
            "rating_q025": 1279.4723003484173
        },
        "reka-flash-20240904": {
            "rating": 1279.4510592368188,
            "rating_q975": 1288.1047891308053,
            "rating_q025": 1270.7973293428317
        },
        "qwen2-72b-instruct": {
            "rating": 1277.7597408113543,
            "rating_q975": 1283.4657435998163,
            "rating_q025": 1272.0537380228923
        },
        "amazon-nova-lite-v1.0": {
            "rating": 1276.4489151376488,
            "rating_q975": 1282.4071310056738,
            "rating_q025": 1270.4906992696237
        },
        "gemma-2-9b-it": {
            "rating": 1275.9847780567288,
            "rating_q975": 1280.3779133927142,
            "rating_q025": 1271.5916427207433
        },
        "c4ai-aya-expanse-32b": {
            "rating": 1274.934497524981,
            "rating_q975": 1280.712986740141,
            "rating_q025": 1269.1560083098207
        },
        "phi-4": {
            "rating": 1273.6966007386295,
            "rating_q975": 1279.1469618717945,
            "rating_q025": 1268.2462396054646
        },
        "command-r-plus": {
            "rating": 1273.0954457241444,
            "rating_q975": 1278.0609806055834,
            "rating_q025": 1268.1299108427054
        },
        "jamba-1.5-mini": {
            "rating": 1272.3201885491662,
            "rating_q975": 1281.012080143936,
            "rating_q025": 1263.6282969543963
        },
        "claude-3-haiku-20240307": {
            "rating": 1270.705639879304,
            "rating_q975": 1275.1528205846464,
            "rating_q025": 1266.2584591739615
        },
        "gemini-1.5-flash-8b-001": {
            "rating": 1268.9676264072086,
            "rating_q975": 1274.1321778918823,
            "rating_q025": 1263.8030749225347
        },
        "deepseek-coder-v2": {
            "rating": 1268.572207654293,
            "rating_q975": 1276.1543030057712,
            "rating_q025": 1260.9901123028149
        },
        "mistral-large-2402": {
            "rating": 1266.694447516155,
            "rating_q975": 1272.1822559857737,
            "rating_q025": 1261.206639046536
        },
        "llama-3-8b-instruct": {
            "rating": 1265.9094255316188,
            "rating_q975": 1270.4099020059557,
            "rating_q025": 1261.408949057282
        },
        "command-r-08-2024": {
            "rating": 1265.083417914826,
            "rating_q975": 1272.91310727826,
            "rating_q025": 1257.2537285513922
        },
        "amazon-nova-micro-v1.0": {
            "rating": 1258.914693030455,
            "rating_q975": 1264.7947715126052,
            "rating_q025": 1253.0346145483052
        },
        "ministral-8b-2410": {
            "rating": 1258.6702371410663,
            "rating_q975": 1270.1653078823365,
            "rating_q025": 1247.1751663997961
        },
        "qwen1.5-110b-chat": {
            "rating": 1258.2948433951024,
            "rating_q975": 1265.2450210188051,
            "rating_q025": 1251.3446657713998
        },
        "mixtral-8x22b-instruct-v0.1": {
            "rating": 1254.1968981154998,
            "rating_q975": 1259.5308943397367,
            "rating_q025": 1248.8629018912632
        },
        "yi-1.5-34b-chat": {
            "rating": 1252.5950463225977,
            "rating_q975": 1259.125019554536,
            "rating_q025": 1246.0650730906596
        },
        "granite-3.1-8b-instruct": {
            "rating": 1252.2917860088373,
            "rating_q975": 1265.5198009612816,
            "rating_q025": 1239.0637710563929
        },
        "qwen1.5-72b-chat": {
            "rating": 1252.2712197184871,
            "rating_q975": 1258.2505468588658,
            "rating_q025": 1246.2918925781084
        },
        "hunyuan-standard-256k": {
            "rating": 1250.385915383745,
            "rating_q975": 1266.146722923804,
            "rating_q025": 1234.625107843686
        },
        "mistral-medium": {
            "rating": 1250.3748197465452,
            "rating_q975": 1256.5763182900869,
            "rating_q025": 1244.1733212030033
        },
        "gemini-pro-dev-api": {
            "rating": 1244.5871136576895,
            "rating_q975": 1252.831809719881,
            "rating_q025": 1236.3424175954983
        },
        "reka-flash-21b-20240226-online": {
            "rating": 1243.8820575424197,
            "rating_q975": 1252.7074441074094,
            "rating_q025": 1235.0566709774298
        },
        "llama-3.1-tulu-3-8b": {
            "rating": 1242.3515986161997,
            "rating_q975": 1255.4697919034677,
            "rating_q025": 1229.2334053289314
        },
        "internlm2_5-20b-chat": {
            "rating": 1241.4714911128117,
            "rating_q975": 1250.2691577519024,
            "rating_q025": 1232.673824473721
        },
        "llama-3.1-8b-instruct": {
            "rating": 1241.0601534746831,
            "rating_q975": 1245.8303108722666,
            "rating_q025": 1236.2899960770997
        },
        "zephyr-orpo-141b-A35b-v0.1": {
            "rating": 1240.7174474593276,
            "rating_q975": 1253.661526997976,
            "rating_q025": 1227.7733679206794
        },
        "gemini-pro": {
            "rating": 1240.01698027165,
            "rating_q975": 1252.6886166708293,
            "rating_q025": 1227.3453438724705
        },
        "command-r": {
            "rating": 1239.920267512095,
            "rating_q975": 1245.5219342484309,
            "rating_q025": 1234.3186007757593
        },
        "granite-3.0-8b-instruct": {
            "rating": 1239.6282368774073,
            "rating_q975": 1250.6286904579517,
            "rating_q025": 1228.627783296863
        },
        "reka-flash-21b-20240226": {
            "rating": 1239.132743464127,
            "rating_q975": 1246.2356673433865,
            "rating_q025": 1232.0298195848675
        },
        "gpt-3.5-turbo-0125": {
            "rating": 1236.656923042779,
            "rating_q975": 1241.9291268297184,
            "rating_q025": 1231.3847192558399
        },
        "c4ai-aya-expanse-8b": {
            "rating": 1236.5111736049944,
            "rating_q975": 1244.7754049260177,
            "rating_q025": 1228.2469422839708
        },
        "mixtral-8x7b-instruct-v0.1": {
            "rating": 1232.464875235401,
            "rating_q975": 1237.4040644787722,
            "rating_q025": 1227.52568599203
        },
        "phi-3-medium-4k-instruct": {
            "rating": 1232.1618248191344,
            "rating_q975": 1238.4489693169114,
            "rating_q025": 1225.8746803213573
        },
        "granite-3.1-2b-instruct": {
            "rating": 1230.34764057081,
            "rating_q975": 1243.942964472938,
            "rating_q025": 1216.752316668682
        },
        "llama-3.2-3b-instruct": {
            "rating": 1228.5306462622984,
            "rating_q975": 1237.7466123243223,
            "rating_q025": 1219.3146802002748
        },
        "dbrx-instruct-preview": {
            "rating": 1227.4417145652924,
            "rating_q975": 1234.730816083851,
            "rating_q025": 1220.152613046734
        },
        "qwen1.5-32b-chat": {
            "rating": 1226.4521625358002,
            "rating_q975": 1233.8252070135302,
            "rating_q025": 1219.07911805807
        },
        "gemma-2-2b-it": {
            "rating": 1223.1472357272723,
            "rating_q975": 1227.8342334621898,
            "rating_q025": 1218.460237992355
        },
        "gpt-3.5-turbo-1106": {
            "rating": 1218.6520865361588,
            "rating_q975": 1228.044264015968,
            "rating_q025": 1209.2599090563497
        },
        "wizardlm-70b": {
            "rating": 1215.2118996641111,
            "rating_q975": 1225.329818850549,
            "rating_q025": 1205.093980477673
        },
        "phi-3-small-8k-instruct": {
            "rating": 1213.9247231739625,
            "rating_q975": 1221.5534857156626,
            "rating_q025": 1206.2959606322624
        },
        "yi-34b-chat": {
            "rating": 1212.3306321610767,
            "rating_q975": 1220.0090769119147,
            "rating_q025": 1204.6521874102389
        },
        "qwen1.5-14b-chat": {
            "rating": 1211.536274683891,
            "rating_q975": 1220.090326049809,
            "rating_q025": 1202.9822233179727
        },
        "llama-2-70b-chat": {
            "rating": 1210.8080805103334,
            "rating_q975": 1216.9943296677943,
            "rating_q025": 1204.6218313528725
        },
        "openchat-3.5-0106": {
            "rating": 1209.1602423058378,
            "rating_q975": 1217.7434322706877,
            "rating_q025": 1200.577052340988
        },
        "tulu-2-dpo-70b": {
            "rating": 1208.828586680169,
            "rating_q975": 1219.494244159415,
            "rating_q025": 1198.162929200923
        },
        "openhermes-2.5-mistral-7b": {
            "rating": 1208.3620180632638,
            "rating_q975": 1219.709123965566,
            "rating_q025": 1197.0149121609616
        },
        "deepseek-llm-67b-chat": {
            "rating": 1206.443440163618,
            "rating_q975": 1219.0168796208882,
            "rating_q025": 1193.8700007063478
        },
        "granite-3.0-2b-instruct": {
            "rating": 1205.9638566664382,
            "rating_q975": 1216.8337023721974,
            "rating_q025": 1195.094010960679
        },
        "gemma-1.1-7b-it": {
            "rating": 1205.9075273135154,
            "rating_q975": 1212.7496412148319,
            "rating_q025": 1199.065413412199
        },
        "starling-lm-7b-beta": {
            "rating": 1204.7563376375092,
            "rating_q975": 1213.4196060776812,
            "rating_q025": 1196.093069197337
        },
        "vicuna-33b": {
            "rating": 1202.703161230465,
            "rating_q975": 1209.7525800406315,
            "rating_q025": 1195.6537424202986
        },
        "snowflake-arctic-instruct": {
            "rating": 1202.5825598933338,
            "rating_q975": 1209.7903597649388,
            "rating_q025": 1195.3747600217291
        },
        "openchat-3.5": {
            "rating": 1201.5831415622704,
            "rating_q975": 1212.0630069328988,
            "rating_q025": 1191.103276191642
        },
        "starling-lm-7b-alpha": {
            "rating": 1199.079289674537,
            "rating_q975": 1207.969171960856,
            "rating_q025": 1190.1894073882181
        },
        "nous-hermes-2-mixtral-8x7b-dpo": {
            "rating": 1195.7212576224804,
            "rating_q975": 1208.4161244801091,
            "rating_q025": 1183.0263907648516
        },
        "phi-3-mini-4k-instruct-june-2024": {
            "rating": 1195.5948235991382,
            "rating_q975": 1203.5328971393305,
            "rating_q025": 1187.6567500589458
        },
        "mistral-7b-instruct-v0.2": {
            "rating": 1193.2722250953605,
            "rating_q975": 1200.7481980592602,
            "rating_q025": 1185.796252131461
        },
        "solar-10.7b-instruct-v1.0": {
            "rating": 1188.6774995399787,
            "rating_q975": 1203.0082381912846,
            "rating_q025": 1174.346760888673
        },
        "qwq-32b-preview": {
            "rating": 1187.2973939257713,
            "rating_q975": 1201.5039765735446,
            "rating_q025": 1173.0908112779982
        },
        "dolphin-2.2.1-mistral-7b": {
            "rating": 1184.3790036629648,
            "rating_q975": 1201.095640182463,
            "rating_q025": 1167.6623671434668
        },
        "llama2-70b-steerlm-chat": {
            "rating": 1184.271134370893,
            "rating_q975": 1197.8770813766232,
            "rating_q025": 1170.6651873651629
        },
        "mpt-30b-chat": {
            "rating": 1183.4185538950267,
            "rating_q975": 1196.8845191659057,
            "rating_q025": 1169.9525886241477
        },
        "llama-2-13b-chat": {
            "rating": 1177.2110858766941,
            "rating_q975": 1184.6708849505117,
            "rating_q025": 1169.7512868028768
        },
        "phi-3-mini-4k-instruct": {
            "rating": 1175.2014162044707,
            "rating_q975": 1183.081082137162,
            "rating_q025": 1167.3217502717791
        },
        "wizardlm-13b": {
            "rating": 1174.77430111397,
            "rating_q975": 1184.9455256128704,
            "rating_q025": 1164.6030766150698
        },
        "llama-3.2-1b-instruct": {
            "rating": 1174.3915096634414,
            "rating_q975": 1183.603129237239,
            "rating_q025": 1165.179890089644
        },
        "smollm2-1.7b-instruct": {
            "rating": 1172.4518834152075,
            "rating_q975": 1190.0854233727216,
            "rating_q025": 1154.8183434576933
        },
        "falcon-180b-chat": {
            "rating": 1171.1740008994318,
            "rating_q975": 1189.7334102745488,
            "rating_q025": 1152.614591524315
        },
        "zephyr-7b-beta": {
            "rating": 1170.1441302423004,
            "rating_q975": 1179.6182040567924,
            "rating_q025": 1160.6700564278087
        },
        "phi-3-mini-128k-instruct": {
            "rating": 1166.632281862309,
            "rating_q975": 1175.4485642156333,
            "rating_q025": 1157.8159995089845
        },
        "gemma-7b-it": {
            "rating": 1166.5051091041394,
            "rating_q975": 1177.3636910813052,
            "rating_q025": 1155.6465271269735
        },
        "qwen1.5-7b-chat": {
            "rating": 1165.5451008065972,
            "rating_q975": 1176.6293390021558,
            "rating_q025": 1154.4608626110387
        },
        "vicuna-13b": {
            "rating": 1164.6540400203307,
            "rating_q975": 1171.948597643869,
            "rating_q025": 1157.3594823967926
        },
        "palm-2": {
            "rating": 1164.6334382781847,
            "rating_q975": 1174.5909625347813,
            "rating_q025": 1154.6759140215884
        },
        "zephyr-7b-alpha": {
            "rating": 1162.9450255297224,
            "rating_q975": 1180.1955062782508,
            "rating_q025": 1145.6945447811943
        },
        "codellama-34b-instruct": {
            "rating": 1162.8814398806371,
            "rating_q975": 1172.4482366355828,
            "rating_q025": 1153.3146431256912
        },
        "guanaco-33b": {
            "rating": 1159.3993616444327,
            "rating_q975": 1172.5880524647855,
            "rating_q025": 1146.2106708240804
        },
        "codellama-70b-instruct": {
            "rating": 1156.0035116054285,
            "rating_q975": 1177.5046321803848,
            "rating_q025": 1134.5023910304722
        },
        "qwen-14b-chat": {
            "rating": 1153.528418707158,
            "rating_q975": 1165.2378196458649,
            "rating_q025": 1141.819017768451
        },
        "stripedhyena-nous-7b": {
            "rating": 1153.1977932358222,
            "rating_q975": 1164.9301653276739,
            "rating_q025": 1141.4654211439708
        },
        "llama-2-7b-chat": {
            "rating": 1151.0834954331656,
            "rating_q975": 1158.7926467693976,
            "rating_q025": 1143.3743440969336
        },
        "mistral-7b-instruct": {
            "rating": 1144.6927218717271,
            "rating_q975": 1154.6946629830213,
            "rating_q025": 1134.690780760433
        },
        "gemma-1.1-2b-it": {
            "rating": 1137.9508393344327,
            "rating_q975": 1147.3424467376055,
            "rating_q025": 1128.5592319312595
        },
        "vicuna-7b": {
            "rating": 1134.8609551747236,
            "rating_q975": 1144.6353823052225,
            "rating_q025": 1125.0865280442245
        },
        "gemma-2b-it": {
            "rating": 1116.3820321853555,
            "rating_q975": 1129.43680365309,
            "rating_q025": 1103.3272607176207
        },
        "olmo-7b-instruct": {
            "rating": 1114.4908705047121,
            "rating_q975": 1127.2570578627187,
            "rating_q025": 1101.7246831467055
        },
        "qwen1.5-4b-chat": {
            "rating": 1108.2190356316985,
            "rating_q975": 1118.8539548036542,
            "rating_q025": 1097.5841164597427
        },
        "koala-13b": {
            "rating": 1101.4980572566365,
            "rating_q975": 1112.5384479001189,
            "rating_q025": 1090.457666613154
        },
        "gpt4all-13b-snoozy": {
            "rating": 1094.0213777983352,
            "rating_q975": 1110.8681076201588,
            "rating_q025": 1077.1746479765113
        },
        "alpaca-13b": {
            "rating": 1088.8820904134413,
            "rating_q975": 1101.0326391665287,
            "rating_q025": 1076.7315416603542
        },
        "chatglm3-6b": {
            "rating": 1087.9754452859238,
            "rating_q975": 1100.5685854614956,
            "rating_q025": 1075.3823051103523
        },
        "mpt-7b-chat": {
            "rating": 1086.7978687256882,
            "rating_q975": 1099.704691003877,
            "rating_q025": 1073.8910464474993
        },
        "RWKV-4-Raven-14B": {
            "rating": 1060.538881393413,
            "rating_q975": 1073.030895552945,
            "rating_q025": 1048.0468672338811
        },
        "chatglm2-6b": {
            "rating": 1058.858952485994,
            "rating_q975": 1073.6719474296317,
            "rating_q025": 1044.045957542356
        },
        "oasst-pythia-12b": {
            "rating": 1050.0142421890441,
            "rating_q975": 1061.751625983302,
            "rating_q025": 1038.2768583947866
        },
        "fastchat-t5-3b": {
            "rating": 1025.4014686403034,
            "rating_q975": 1038.7359528271013,
            "rating_q025": 1012.0669844535054
        },
        "chatglm-6b": {
            "rating": 1017.6067151492518,
            "rating_q975": 1031.1375397269262,
            "rating_q025": 1004.0758905715777
        },
        "dolly-v2-12b": {
            "rating": 992.3400088371792,
            "rating_q975": 1007.2033018386691,
            "rating_q025": 977.4767158356892
        },
        "llama-13b": {
            "rating": 978.7741944879658,
            "rating_q975": 995.892282527293,
            "rating_q025": 961.6561064486389
        },
        "stablelm-tuned-alpha-7b": {
            "rating": 978.4778187311728,
            "rating_q975": 992.4246543738868,
            "rating_q025": 964.5309830884587
        }
    },
    "french": {
        "o3-2025-04-16": {
            "rating": 1500.1578756629167,
            "rating_q975": 1532.2775418717542,
            "rating_q025": 1468.038209454079
        },
        "gemini-2.5-pro": {
            "rating": 1497.0511983605834,
            "rating_q975": 1530.5784463985126,
            "rating_q025": 1463.5239503226544
        },
        "chatgpt-4o-latest-20250326": {
            "rating": 1479.5416508342853,
            "rating_q975": 1510.5334792470626,
            "rating_q025": 1448.549822421508
        },
        "claude-opus-4-1-20250805": {
            "rating": 1473.8826784146863,
            "rating_q975": 1527.8881988473634,
            "rating_q025": 1419.8771579820093
        },
        "qwen3-235b-a22b-instruct-2507": {
            "rating": 1472.75977914777,
            "rating_q975": 1530.5161641573886,
            "rating_q025": 1415.003394138151
        },
        "claude-opus-4-20250514-thinking-16k": {
            "rating": 1465.3974585015944,
            "rating_q975": 1506.2246268227234,
            "rating_q025": 1424.5702901804652
        },
        "grok-3-preview-02-24": {
            "rating": 1454.6364746114048,
            "rating_q975": 1488.3590004465973,
            "rating_q025": 1420.9139487762125
        },
        "grok-4-0709": {
            "rating": 1452.0898410300915,
            "rating_q975": 1503.4419383670509,
            "rating_q025": 1400.737743693132
        },
        "gpt-4.5-preview-2025-02-27": {
            "rating": 1450.712612417791,
            "rating_q975": 1507.3413013522445,
            "rating_q025": 1394.0839234833375
        },
        "claude-sonnet-4-20250514-thinking-32k": {
            "rating": 1441.9920185051224,
            "rating_q975": 1480.0929917304934,
            "rating_q025": 1403.891045279751
        },
        "gpt-4.1-2025-04-14": {
            "rating": 1440.234166972659,
            "rating_q975": 1475.996803390077,
            "rating_q025": 1404.4715305552409
        },
        "gemini-2.5-flash": {
            "rating": 1438.0557828611063,
            "rating_q975": 1468.6863097140072,
            "rating_q025": 1407.4252560082055
        },
        "kimi-k2-0711-preview": {
            "rating": 1431.9951347776146,
            "rating_q975": 1478.0685033946909,
            "rating_q025": 1385.9217661605383
        },
        "deepseek-r1-0528": {
            "rating": 1428.5441662973376,
            "rating_q975": 1468.8723394896724,
            "rating_q025": 1388.2159931050028
        },
        "glm-4.5": {
            "rating": 1425.9772706796293,
            "rating_q975": 1483.6525984243167,
            "rating_q025": 1368.301942934942
        },
        "deepseek-v3-0324": {
            "rating": 1424.3185160722717,
            "rating_q975": 1457.1646965874127,
            "rating_q025": 1391.4723355571305
        },
        "minimax-m1": {
            "rating": 1419.4824744540686,
            "rating_q975": 1461.5367470770238,
            "rating_q025": 1377.4282018311133
        },
        "qwen2.5-max": {
            "rating": 1418.735455182916,
            "rating_q975": 1450.8270127856526,
            "rating_q025": 1386.643897580179
        },
        "claude-sonnet-4-20250514": {
            "rating": 1414.9585990676082,
            "rating_q975": 1450.9373140765813,
            "rating_q025": 1378.979884058635
        },
        "gpt-4.1-mini-2025-04-14": {
            "rating": 1413.7063547021442,
            "rating_q975": 1448.252262611688,
            "rating_q025": 1379.1604467926004
        },
        "gemma-3-27b-it": {
            "rating": 1407.457866600654,
            "rating_q975": 1437.6731234462716,
            "rating_q025": 1377.2426097550365
        },
        "gemini-2.0-flash-001": {
            "rating": 1406.0816868494283,
            "rating_q975": 1433.8520428071977,
            "rating_q025": 1378.3113308916586
        },
        "qwen3-235b-a22b-no-thinking": {
            "rating": 1400.664659387891,
            "rating_q975": 1435.9955184740836,
            "rating_q025": 1365.3338003016986
        },
        "claude-3-7-sonnet-20250219": {
            "rating": 1400.2231680298632,
            "rating_q975": 1429.9304650314593,
            "rating_q025": 1370.515871028267
        },
        "o4-mini-2025-04-16": {
            "rating": 1400.1367533666375,
            "rating_q975": 1435.0557515731598,
            "rating_q025": 1365.2177551601153
        },
        "hunyuan-turbos-20250416": {
            "rating": 1399.8559648083733,
            "rating_q975": 1450.2662185675724,
            "rating_q025": 1349.4457110491744
        },
        "deepseek-r1": {
            "rating": 1399.6922738626686,
            "rating_q975": 1439.0855832529596,
            "rating_q025": 1360.2989644723773
        },
        "o1-preview": {
            "rating": 1399.649936584872,
            "rating_q975": 1430.1266361863718,
            "rating_q025": 1369.173236983372
        },
        "mistral-medium-2505": {
            "rating": 1395.409407856887,
            "rating_q975": 1427.4761015852152,
            "rating_q025": 1363.3427141285586
        },
        "claude-3-5-sonnet-20241022": {
            "rating": 1394.9227979124676,
            "rating_q975": 1415.992748389536,
            "rating_q025": 1373.852847435399
        },
        "o1-2024-12-17": {
            "rating": 1394.1345254536632,
            "rating_q975": 1429.7467254783073,
            "rating_q025": 1358.5223254290192
        },
        "claude-3-7-sonnet-20250219-thinking-32k": {
            "rating": 1390.2524948035746,
            "rating_q975": 1421.468501884698,
            "rating_q025": 1359.036487722451
        },
        "claude-opus-4-20250514": {
            "rating": 1388.3457120209132,
            "rating_q975": 1422.7012389142808,
            "rating_q025": 1353.9901851275456
        },
        "gemini-2.0-flash-lite-preview-02-05": {
            "rating": 1387.9296863958803,
            "rating_q975": 1424.4295377564245,
            "rating_q025": 1351.4298350353363
        },
        "qwen-max-0919": {
            "rating": 1386.3681401732713,
            "rating_q975": 1425.3099812268763,
            "rating_q025": 1347.4262991196665
        },
        "qwen3-30b-a3b": {
            "rating": 1383.2394561432202,
            "rating_q975": 1419.4526718353975,
            "rating_q025": 1347.0262404510431
        },
        "o3-mini-high": {
            "rating": 1382.5810214061664,
            "rating_q975": 1425.7708802454204,
            "rating_q025": 1339.3911625669125
        },
        "command-a-03-2025": {
            "rating": 1382.355455906358,
            "rating_q975": 1414.9974000895902,
            "rating_q025": 1349.7135117231257
        },
        "gemini-advanced-0514": {
            "rating": 1380.7773018604662,
            "rating_q975": 1403.9600504359473,
            "rating_q025": 1357.594553284985
        },
        "mistral-large-2411": {
            "rating": 1380.3611846061085,
            "rating_q975": 1416.836307987566,
            "rating_q025": 1343.8860612246513
        },
        "claude-3-5-sonnet-20240620": {
            "rating": 1376.3250365635745,
            "rating_q975": 1396.2467215449813,
            "rating_q025": 1356.4033515821677
        },
        "deepseek-v3": {
            "rating": 1375.34580129723,
            "rating_q975": 1409.993768382903,
            "rating_q025": 1340.6978342115574
        },
        "qwen3-235b-a22b": {
            "rating": 1375.0361183480684,
            "rating_q975": 1412.2624378781597,
            "rating_q025": 1337.809798817977
        },
        "gpt-4o-2024-05-13": {
            "rating": 1373.0409159012231,
            "rating_q975": 1390.06453777032,
            "rating_q025": 1356.0172940321265
        },
        "athene-v2-chat": {
            "rating": 1365.7607808269852,
            "rating_q975": 1399.9286032437308,
            "rating_q025": 1331.5929584102396
        },
        "o3-mini": {
            "rating": 1363.138348870086,
            "rating_q975": 1390.8221151872704,
            "rating_q025": 1335.4545825529015
        },
        "gpt-4-1106-preview": {
            "rating": 1359.1089425156158,
            "rating_q975": 1376.2388390599301,
            "rating_q025": 1341.9790459713013
        },
        "gemini-1.5-pro-002": {
            "rating": 1358.9279250092904,
            "rating_q975": 1383.9279231864134,
            "rating_q025": 1333.9279268321675
        },
        "grok-2-2024-08-13": {
            "rating": 1356.811919325135,
            "rating_q975": 1378.4903902842939,
            "rating_q025": 1335.1334483659764
        },
        "gpt-4-0125-preview": {
            "rating": 1356.351067144368,
            "rating_q975": 1374.504293279416,
            "rating_q025": 1338.1978410093202
        },
        "qwq-32b": {
            "rating": 1355.4403932623297,
            "rating_q975": 1392.803813039583,
            "rating_q025": 1318.0769734850767
        },
        "claude-3-opus-20240229": {
            "rating": 1355.404750313279,
            "rating_q975": 1370.1802011905738,
            "rating_q025": 1340.6292994359844
        },
        "gemma-3n-e4b-it": {
            "rating": 1353.7788151282518,
            "rating_q975": 1396.0165171094498,
            "rating_q025": 1311.5411131470537
        },
        "llama-3.1-405b-instruct-bf16": {
            "rating": 1353.1756734988737,
            "rating_q975": 1380.993741599669,
            "rating_q025": 1325.3576053980787
        },
        "glm-4-plus": {
            "rating": 1352.822905175643,
            "rating_q975": 1385.4306468846983,
            "rating_q025": 1320.2151634665877
        },
        "claude-3-5-haiku-20241022": {
            "rating": 1352.5710780307481,
            "rating_q975": 1378.4011757046433,
            "rating_q025": 1326.7409803568528
        },
        "gpt-4-turbo-2024-04-09": {
            "rating": 1351.1271245737125,
            "rating_q975": 1368.8668682745367,
            "rating_q025": 1333.3873808728886
        },
        "grok-3-mini-beta": {
            "rating": 1350.3358026858323,
            "rating_q975": 1392.3345808000856,
            "rating_q025": 1308.337024571579
        },
        "gemini-1.5-pro-001": {
            "rating": 1347.6811561654658,
            "rating_q975": 1366.7929959750943,
            "rating_q025": 1328.5693163558371
        },
        "mistral-small-2506": {
            "rating": 1347.1470255332463,
            "rating_q975": 1401.3831267412397,
            "rating_q025": 1292.9109243252528
        },
        "amazon-nova-experimental-chat-05-14": {
            "rating": 1346.3792201034353,
            "rating_q975": 1391.485280946852,
            "rating_q025": 1301.2731592600185
        },
        "llama-3.1-405b-instruct-fp8": {
            "rating": 1346.0648185256327,
            "rating_q975": 1369.7449868370543,
            "rating_q025": 1322.3846502142112
        },
        "gpt-4o-mini-2024-07-18": {
            "rating": 1346.013170171309,
            "rating_q975": 1367.3681808938502,
            "rating_q025": 1324.6581594487682
        },
        "gpt-4o-2024-08-06": {
            "rating": 1343.2288864476477,
            "rating_q975": 1367.1867398745126,
            "rating_q025": 1319.2710330207826
        },
        "athene-70b-0725": {
            "rating": 1342.8070122626868,
            "rating_q975": 1379.716866424302,
            "rating_q025": 1305.8971581010715
        },
        "mistral-large-2407": {
            "rating": 1342.2586696980775,
            "rating_q975": 1367.5582863292545,
            "rating_q025": 1316.9590530669007
        },
        "yi-lightning": {
            "rating": 1341.744803557375,
            "rating_q975": 1374.2227593718533,
            "rating_q025": 1309.2668477428967
        },
        "llama-3.3-70b-instruct": {
            "rating": 1340.7210537653132,
            "rating_q975": 1366.6541263263005,
            "rating_q025": 1314.7879812043261
        },
        "llama-4-scout-17b-16e-instruct": {
            "rating": 1337.5442741781462,
            "rating_q975": 1382.703699961323,
            "rating_q025": 1292.3848483949691
        },
        "o1-mini": {
            "rating": 1335.2141054144677,
            "rating_q975": 1360.6783672889876,
            "rating_q025": 1309.749843539948
        },
        "deepseek-v2.5": {
            "rating": 1332.5100816882684,
            "rating_q975": 1365.4325015779534,
            "rating_q025": 1299.5876617985834
        },
        "qwen2.5-72b-instruct": {
            "rating": 1330.9837788386471,
            "rating_q975": 1360.025217346465,
            "rating_q025": 1301.9423403308292
        },
        "grok-2-mini-2024-08-13": {
            "rating": 1328.20954329171,
            "rating_q975": 1352.5005332196822,
            "rating_q025": 1303.9185533637376
        },
        "amazon-nova-pro-v1.0": {
            "rating": 1324.8244350591476,
            "rating_q975": 1360.5437238537745,
            "rating_q025": 1289.105146264521
        },
        "gpt-4-0314": {
            "rating": 1324.8120644986302,
            "rating_q975": 1347.7811118598956,
            "rating_q025": 1301.843017137365
        },
        "gemma-2-27b-it": {
            "rating": 1324.14039555348,
            "rating_q975": 1343.9357124252028,
            "rating_q025": 1304.345078681757
        },
        "grok-3-mini-high": {
            "rating": 1323.6566176222516,
            "rating_q975": 1380.8949596066468,
            "rating_q025": 1266.4182756378564
        },
        "llama-3.1-70b-instruct": {
            "rating": 1319.8975582615508,
            "rating_q975": 1344.351781256903,
            "rating_q025": 1295.4433352661988
        },
        "claude-3-sonnet-20240229": {
            "rating": 1319.2984280469136,
            "rating_q975": 1336.5443194849715,
            "rating_q025": 1302.0525366088555
        },
        "mistral-small-3.1-24b-instruct-2503": {
            "rating": 1317.0397009965093,
            "rating_q975": 1361.0860204234857,
            "rating_q025": 1272.9933815695326
        },
        "gemini-1.5-flash-001": {
            "rating": 1312.9746001126382,
            "rating_q975": 1333.5856420517391,
            "rating_q025": 1292.3635581735375
        },
        "llama-3-70b-instruct": {
            "rating": 1308.0923394284305,
            "rating_q975": 1323.4671088106595,
            "rating_q025": 1292.7175700462017
        },
        "c4ai-aya-expanse-32b": {
            "rating": 1307.673084319376,
            "rating_q975": 1339.7987197592922,
            "rating_q025": 1275.5474488794596
        },
        "mistral-large-2402": {
            "rating": 1304.2824105388554,
            "rating_q975": 1324.7990269221423,
            "rating_q025": 1283.7657941555688
        },
        "llama-4-maverick-17b-128e-instruct": {
            "rating": 1300.864387156179,
            "rating_q975": 1333.8984607497603,
            "rating_q025": 1267.830313562598
        },
        "gemini-1.5-flash-002": {
            "rating": 1300.0217696874365,
            "rating_q975": 1330.745678783565,
            "rating_q025": 1269.297860591308
        },
        "command-r-plus": {
            "rating": 1294.5288742693647,
            "rating_q975": 1313.983042972131,
            "rating_q025": 1275.0747055665986
        },
        "gemini-1.5-flash-8b-001": {
            "rating": 1293.6506309445977,
            "rating_q975": 1323.400099002103,
            "rating_q025": 1263.9011628870926
        },
        "claude-3-haiku-20240307": {
            "rating": 1293.012932098632,
            "rating_q975": 1310.0673605632173,
            "rating_q025": 1275.958503634047
        },
        "amazon-nova-micro-v1.0": {
            "rating": 1292.0829578606065,
            "rating_q975": 1332.834995356839,
            "rating_q025": 1251.330920364374
        },
        "gpt-4-0613": {
            "rating": 1289.5333375345535,
            "rating_q975": 1308.1505407385605,
            "rating_q025": 1270.9161343305464
        },
        "amazon-nova-lite-v1.0": {
            "rating": 1284.7813514027046,
            "rating_q975": 1327.4163737496344,
            "rating_q025": 1242.1463290557747
        },
        "nemotron-4-340b-instruct": {
            "rating": 1280.5130520921834,
            "rating_q975": 1312.7474756893382,
            "rating_q025": 1248.278628495029
        },
        "phi-4": {
            "rating": 1278.52139499468,
            "rating_q975": 1317.93182608377,
            "rating_q025": 1239.1109639055899
        },
        "deepseek-coder-v2": {
            "rating": 1274.4608722015769,
            "rating_q975": 1314.0201568358686,
            "rating_q025": 1234.901587567285
        },
        "gemma-2-9b-it": {
            "rating": 1274.0591130066437,
            "rating_q975": 1297.4539327788848,
            "rating_q025": 1250.6642932344023
        },
        "mixtral-8x22b-instruct-v0.1": {
            "rating": 1273.2937168391693,
            "rating_q975": 1296.2148016340625,
            "rating_q025": 1250.3726320442759
        },
        "qwen2-72b-instruct": {
            "rating": 1271.7672442529367,
            "rating_q975": 1295.3116515343584,
            "rating_q025": 1248.2228369715149
        },
        "mistral-medium": {
            "rating": 1266.907577475142,
            "rating_q975": 1291.4633296096526,
            "rating_q025": 1242.3518253406314
        },
        "mistral-small-24b-instruct-2501": {
            "rating": 1265.067680152073,
            "rating_q975": 1314.5122210305567,
            "rating_q025": 1215.62313927359
        },
        "gemini-pro-dev-api": {
            "rating": 1262.84833999602,
            "rating_q975": 1293.0622794157848,
            "rating_q025": 1232.6344005762558
        },
        "reka-flash-21b-20240226": {
            "rating": 1259.4226382935324,
            "rating_q975": 1288.3355903842732,
            "rating_q025": 1230.5096862027915
        },
        "mixtral-8x7b-instruct-v0.1": {
            "rating": 1258.871314984576,
            "rating_q975": 1278.174495385497,
            "rating_q025": 1239.568134583655
        },
        "qwen1.5-72b-chat": {
            "rating": 1256.2957721935645,
            "rating_q975": 1278.4406145623093,
            "rating_q025": 1234.1509298248195
        },
        "command-r": {
            "rating": 1253.7293441458278,
            "rating_q975": 1276.1378931635177,
            "rating_q025": 1231.320795128138
        },
        "gpt-3.5-turbo-0125": {
            "rating": 1250.0722857967826,
            "rating_q975": 1269.8878535557812,
            "rating_q025": 1230.2567180377837
        },
        "reka-flash-21b-20240226-online": {
            "rating": 1247.003321660026,
            "rating_q975": 1286.1756374980673,
            "rating_q025": 1207.8310058219845
        },
        "qwen1.5-110b-chat": {
            "rating": 1244.1742705714244,
            "rating_q975": 1274.192564951249,
            "rating_q025": 1214.1559761915996
        },
        "llama-3-8b-instruct": {
            "rating": 1239.832773656512,
            "rating_q975": 1257.7078954027588,
            "rating_q025": 1221.9576519102652
        },
        "snowflake-arctic-instruct": {
            "rating": 1237.9334691107838,
            "rating_q975": 1266.0218956125125,
            "rating_q025": 1209.8450426090549
        },
        "llama-3.1-8b-instruct": {
            "rating": 1233.41024537116,
            "rating_q975": 1258.6564408712184,
            "rating_q025": 1208.1640498711017
        },
        "gemma-2-2b-it": {
            "rating": 1230.5090384555535,
            "rating_q975": 1257.2420974657985,
            "rating_q025": 1203.7759794453086
        },
        "phi-3-small-8k-instruct": {
            "rating": 1229.9162319212128,
            "rating_q975": 1264.0262402535097,
            "rating_q025": 1195.8062235889156
        },
        "yi-1.5-34b-chat": {
            "rating": 1226.470221862855,
            "rating_q975": 1256.5261130755296,
            "rating_q025": 1196.4143306501803
        },
        "qwen1.5-14b-chat": {
            "rating": 1210.2425568953608,
            "rating_q975": 1247.2620884149646,
            "rating_q025": 1173.223025375757
        },
        "phi-3-medium-4k-instruct": {
            "rating": 1209.5237909457337,
            "rating_q975": 1240.977393857522,
            "rating_q025": 1178.0701880339452
        },
        "dbrx-instruct-preview": {
            "rating": 1206.892273321013,
            "rating_q975": 1234.6198667593173,
            "rating_q025": 1179.1646798827085
        },
        "gpt-3.5-turbo-1106": {
            "rating": 1205.3436451886805,
            "rating_q975": 1242.8412454509805,
            "rating_q025": 1167.8460449263805
        },
        "openchat-3.5-0106": {
            "rating": 1202.0204304382944,
            "rating_q975": 1244.0649654662202,
            "rating_q025": 1159.9758954103688
        },
        "qwen1.5-32b-chat": {
            "rating": 1197.8495503223678,
            "rating_q975": 1230.7991800208179,
            "rating_q025": 1164.8999206239178
        },
        "gemma-1.1-7b-it": {
            "rating": 1188.2360479396484,
            "rating_q975": 1218.5960025911165,
            "rating_q025": 1157.8760932881805
        },
        "vicuna-33b": {
            "rating": 1184.113541192689,
            "rating_q975": 1220.0720596412855,
            "rating_q025": 1148.1550227440923
        },
        "starling-lm-7b-alpha": {
            "rating": 1183.8651399852342,
            "rating_q975": 1226.0859489704553,
            "rating_q025": 1141.6443310000134
        },
        "starling-lm-7b-beta": {
            "rating": 1180.00692338991,
            "rating_q975": 1217.907285555133,
            "rating_q025": 1142.1065612246873
        },
        "yi-34b-chat": {
            "rating": 1172.7185535382723,
            "rating_q975": 1211.8022490807793,
            "rating_q025": 1133.634857995765
        },
        "llama-2-70b-chat": {
            "rating": 1171.045950912285,
            "rating_q975": 1196.4080130366822,
            "rating_q025": 1145.6838887878878
        },
        "phi-3-mini-4k-instruct": {
            "rating": 1163.363481239533,
            "rating_q975": 1197.8587416192695,
            "rating_q025": 1128.8682208597968
        },
        "phi-3-mini-128k-instruct": {
            "rating": 1147.130646979743,
            "rating_q975": 1180.8284020139824,
            "rating_q025": 1113.4328919455033
        },
        "gemma-7b-it": {
            "rating": 1140.8937898352242,
            "rating_q975": 1186.2098783029758,
            "rating_q025": 1095.5777013674726
        },
        "stripedhyena-nous-7b": {
            "rating": 1139.6055828233332,
            "rating_q975": 1187.81220218637,
            "rating_q025": 1091.3989634602963
        },
        "vicuna-13b": {
            "rating": 1135.1039882950847,
            "rating_q975": 1179.6239547077148,
            "rating_q025": 1090.5840218824546
        },
        "mistral-7b-instruct-v0.2": {
            "rating": 1134.815322178371,
            "rating_q975": 1164.928184297028,
            "rating_q025": 1104.7024600597138
        },
        "llama-2-13b-chat": {
            "rating": 1131.326351069162,
            "rating_q975": 1169.3837661227383,
            "rating_q025": 1093.2689360155857
        },
        "zephyr-7b-beta": {
            "rating": 1120.9823607722444,
            "rating_q975": 1169.3433210428848,
            "rating_q025": 1072.621400501604
        },
        "mistral-7b-instruct": {
            "rating": 1075.2643107815693,
            "rating_q975": 1122.1557895098242,
            "rating_q025": 1028.3728320533141
        },
        "llama-2-7b-chat": {
            "rating": 1055.1287127754108,
            "rating_q975": 1095.8807137940357,
            "rating_q025": 1014.3767117567861
        }
    },
    "full": {
        "gemini-2.5-pro": {
            "rating": 1455.5534109049693,
            "rating_q975": 1460.3894768449857,
            "rating_q025": 1450.717344964953
        },
        "gpt-5-high": {
            "rating": 1446.7504144606075,
            "rating_q975": 1453.3034361217092,
            "rating_q025": 1440.197392799506
        },
        "claude-opus-4-1-20250805-thinking-16k": {
            "rating": 1446.705358670016,
            "rating_q975": 1453.5129813558858,
            "rating_q025": 1439.8977359841463
        },
        "o3-2025-04-16": {
            "rating": 1443.496931299597,
            "rating_q975": 1447.9041769354922,
            "rating_q025": 1439.0896856637019
        },
        "chatgpt-4o-latest-20250326": {
            "rating": 1442.7805519610815,
            "rating_q975": 1447.2166710913855,
            "rating_q025": 1438.3444328307778
        },
        "gpt-4.5-preview-2025-02-27": {
            "rating": 1438.9817095692586,
            "rating_q975": 1444.5056731300936,
            "rating_q025": 1433.4577460084236
        },
        "gpt-5-old": {
            "rating": 1438.7597914683702,
            "rating_q975": 1459.624389683122,
            "rating_q025": 1417.8951932536186
        },
        "claude-opus-4-1-20250805": {
            "rating": 1435.4917693905875,
            "rating_q975": 1441.8220111964492,
            "rating_q025": 1429.1615275847257
        },
        "gpt-5-chat": {
            "rating": 1426.0655255007873,
            "rating_q975": 1432.8778332007237,
            "rating_q025": 1419.2532178008512
        },
        "qwen-max-2025-08-15": {
            "rating": 1424.596910641975,
            "rating_q975": 1432.8547249810438,
            "rating_q025": 1416.3390963029062
        },
        "grok-4-0709": {
            "rating": 1421.9112121188978,
            "rating_q975": 1427.44055468846,
            "rating_q025": 1416.3818695493355
        },
        "kimi-k2-0711-preview": {
            "rating": 1421.13780498526,
            "rating_q975": 1426.4491698199058,
            "rating_q025": 1415.8264401506142
        },
        "claude-opus-4-20250514-thinking-16k": {
            "rating": 1419.073020456711,
            "rating_q975": 1424.162005499096,
            "rating_q025": 1413.9840354143257
        },
        "qwen3-235b-a22b-instruct-2507": {
            "rating": 1418.1988171607177,
            "rating_q975": 1424.0006677775796,
            "rating_q025": 1412.3969665438556
        },
        "deepseek-v3.1": {
            "rating": 1417.4993549474623,
            "rating_q975": 1425.9846277919328,
            "rating_q025": 1409.0140821029918
        },
        "deepseek-r1-0528": {
            "rating": 1416.7073911443445,
            "rating_q975": 1422.223360977109,
            "rating_q025": 1411.19142131158
        },
        "deepseek-v3.1-thinking": {
            "rating": 1414.6500303753078,
            "rating_q975": 1423.711202101036,
            "rating_q025": 1405.5888586495794
        },
        "mistral-medium-2508": {
            "rating": 1410.5658471977679,
            "rating_q975": 1417.9244125745186,
            "rating_q025": 1403.2072818210172
        },
        "glm-4.5": {
            "rating": 1410.3086130874556,
            "rating_q975": 1416.521209697582,
            "rating_q025": 1404.096016477329
        },
        "claude-opus-4-20250514": {
            "rating": 1409.2752041019257,
            "rating_q975": 1414.2323911750557,
            "rating_q025": 1404.3180170287956
        },
        "gpt-4.1-2025-04-14": {
            "rating": 1408.9788227371369,
            "rating_q975": 1413.7204495627527,
            "rating_q025": 1404.237195911521
        },
        "grok-3-preview-02-24": {
            "rating": 1408.9340871221063,
            "rating_q975": 1413.1508742238293,
            "rating_q025": 1404.7173000203834
        },
        "gemini-2.5-flash": {
            "rating": 1405.1803832565706,
            "rating_q975": 1409.8901916851116,
            "rating_q025": 1400.4705748280296
        },
        "qwen3-235b-a22b-thinking-2507": {
            "rating": 1399.6986579478369,
            "rating_q975": 1406.4111491402202,
            "rating_q025": 1392.9861667554535
        },
        "o1-2024-12-17": {
            "rating": 1399.057787598896,
            "rating_q975": 1403.3496178924743,
            "rating_q025": 1394.7659573053177
        },
        "mai-1-preview": {
            "rating": 1398.6300789176623,
            "rating_q975": 1407.3319343834369,
            "rating_q025": 1389.9282234518878
        },
        "qwen3-235b-a22b-no-thinking": {
            "rating": 1398.4090536784572,
            "rating_q975": 1403.4436751875353,
            "rating_q025": 1393.3744321693794
        },
        "claude-sonnet-4-20250514-thinking-32k": {
            "rating": 1397.6814431911416,
            "rating_q975": 1402.8093463177347,
            "rating_q025": 1392.5535400645485
        },
        "deepseek-r1": {
            "rating": 1394.458770298759,
            "rating_q975": 1399.1951439844104,
            "rating_q025": 1389.7223966131078
        },
        "o4-mini-2025-04-16": {
            "rating": 1394.1214352002658,
            "rating_q975": 1398.8440045147631,
            "rating_q025": 1389.3988658857681
        },
        "deepseek-v3-0324": {
            "rating": 1391.9757415509923,
            "rating_q975": 1396.4215294850342,
            "rating_q025": 1387.5299536169507
        },
        "gpt-5-mini-high": {
            "rating": 1390.3162822747101,
            "rating_q975": 1397.7693098666878,
            "rating_q025": 1382.8632546827325
        },
        "hunyuan-t1-20250711": {
            "rating": 1387.9148383523277,
            "rating_q975": 1395.7347308186336,
            "rating_q025": 1380.0949458860218
        },
        "o1-preview": {
            "rating": 1386.2028613065581,
            "rating_q975": 1390.8977717543241,
            "rating_q025": 1381.5079508587921
        },
        "claude-3-7-sonnet-20250219-thinking-32k": {
            "rating": 1384.7124425654295,
            "rating_q975": 1388.986627833632,
            "rating_q025": 1380.4382572972272
        },
        "qwen-vl-max-2025-08-13": {
            "rating": 1383.8348927921747,
            "rating_q975": 1398.7955702806264,
            "rating_q025": 1368.874215303723
        },
        "mistral-medium-2505": {
            "rating": 1383.6886594418534,
            "rating_q975": 1388.5015393372141,
            "rating_q025": 1378.8757795464926
        },
        "claude-sonnet-4-20250514": {
            "rating": 1383.261112501224,
            "rating_q975": 1388.3187242384774,
            "rating_q025": 1378.2035007639706
        },
        "qwen3-coder-480b-a35b-instruct": {
            "rating": 1381.3797405801445,
            "rating_q975": 1387.3046242529804,
            "rating_q025": 1375.4548569073086
        },
        "hunyuan-turbos-20250416": {
            "rating": 1381.2201057288548,
            "rating_q975": 1387.4398693459198,
            "rating_q025": 1375.00034211179
        },
        "qwen3-30b-a3b-instruct-2507": {
            "rating": 1379.5058945883816,
            "rating_q975": 1386.0943670174977,
            "rating_q025": 1372.9174221592652
        },
        "gpt-4.1-mini-2025-04-14": {
            "rating": 1379.0609285041123,
            "rating_q975": 1383.7993797762506,
            "rating_q025": 1374.322477231974
        },
        "glm-4.5-air": {
            "rating": 1377.2439968903523,
            "rating_q975": 1383.5478897753678,
            "rating_q025": 1370.9401040053367
        },
        "qwen3-235b-a22b": {
            "rating": 1374.2954158028747,
            "rating_q975": 1379.1544095632667,
            "rating_q025": 1369.4364220424827
        },
        "qwen2.5-max": {
            "rating": 1372.4308994859534,
            "rating_q975": 1376.4064275519768,
            "rating_q025": 1368.45537141993
        },
        "claude-3-7-sonnet-20250219": {
            "rating": 1368.8460823151927,
            "rating_q975": 1372.821181006034,
            "rating_q025": 1364.8709836243515
        },
        "minimax-m1": {
            "rating": 1368.2108261520245,
            "rating_q975": 1373.3624758811084,
            "rating_q025": 1363.0591764229407
        },
        "claude-3-5-sonnet-20241022": {
            "rating": 1368.1627274094158,
            "rating_q975": 1371.227394278651,
            "rating_q025": 1365.0980605401805
        },
        "gemma-3-27b-it": {
            "rating": 1364.0850034323287,
            "rating_q975": 1368.2652703339968,
            "rating_q025": 1359.9047365306608
        },
        "o3-mini-high": {
            "rating": 1363.2977816863895,
            "rating_q975": 1368.3753725468814,
            "rating_q025": 1358.2201908258976
        },
        "gemini-2.0-flash-001": {
            "rating": 1362.476701342255,
            "rating_q975": 1366.3279664931788,
            "rating_q025": 1358.6254361913313
        },
        "grok-3-mini-high": {
            "rating": 1362.3556368200057,
            "rating_q975": 1367.9696698232833,
            "rating_q025": 1356.741603816728
        },
        "grok-3-mini-beta": {
            "rating": 1358.7498015509768,
            "rating_q975": 1364.001755509942,
            "rating_q025": 1353.4978475920116
        },
        "deepseek-v3": {
            "rating": 1356.6693528756173,
            "rating_q975": 1361.2267150052694,
            "rating_q025": 1352.1119907459652
        },
        "gpt-oss-120b": {
            "rating": 1354.6941579429372,
            "rating_q975": 1361.644516872002,
            "rating_q025": 1347.7437990138724
        },
        "mistral-small-2506": {
            "rating": 1354.5216707539546,
            "rating_q975": 1360.1233275137436,
            "rating_q025": 1348.9200139941654
        },
        "step-3": {
            "rating": 1353.1033642666696,
            "rating_q975": 1363.3494327877622,
            "rating_q025": 1342.8572957455772
        },
        "gemini-2.0-flash-lite-preview-02-05": {
            "rating": 1351.8657031374655,
            "rating_q975": 1356.0589858400126,
            "rating_q025": 1347.6724204349184
        },
        "gemini-1.5-pro-002": {
            "rating": 1350.4696730524938,
            "rating_q975": 1353.6291689198638,
            "rating_q025": 1347.3101771851236
        },
        "gpt-5-nano-high": {
            "rating": 1348.2276025831998,
            "rating_q975": 1356.7735348400631,
            "rating_q025": 1339.6816703263366
        },
        "o3-mini": {
            "rating": 1347.8287833551267,
            "rating_q975": 1351.5128041468593,
            "rating_q025": 1344.1447625633941
        },
        "command-a-03-2025": {
            "rating": 1347.0164858315657,
            "rating_q975": 1351.212742088937,
            "rating_q025": 1342.8202295741946
        },
        "hunyuan-turbos-20250226": {
            "rating": 1346.6763587508774,
            "rating_q975": 1357.5806369158825,
            "rating_q025": 1335.7720805858721
        },
        "qwen3-32b": {
            "rating": 1346.1272967844359,
            "rating_q975": 1355.462694947947,
            "rating_q025": 1336.7918986209247
        },
        "llama-3.1-nemotron-ultra-253b-v1": {
            "rating": 1345.024150648236,
            "rating_q975": 1356.4704001671191,
            "rating_q025": 1333.5779011293528
        },
        "qwen-plus-0125": {
            "rating": 1344.7123967401521,
            "rating_q975": 1352.8897570499876,
            "rating_q025": 1336.5350364303165
        },
        "gpt-4o-2024-05-13": {
            "rating": 1344.1595605847467,
            "rating_q975": 1347.3316987159549,
            "rating_q025": 1340.9874224535383
        },
        "glm-4.5v": {
            "rating": 1342.438744096492,
            "rating_q975": 1358.475730843123,
            "rating_q025": 1326.4017573498609
        },
        "glm-4-plus-0111": {
            "rating": 1342.2142432807525,
            "rating_q975": 1350.3936630565136,
            "rating_q025": 1334.0348235049912
        },
        "nvidia-llama-3.3-nemotron-super-49b-v1.5": {
            "rating": 1342.0002756239076,
            "rating_q975": 1351.3311088497223,
            "rating_q025": 1332.669442398093
        },
        "claude-3-5-sonnet-20240620": {
            "rating": 1340.905145336977,
            "rating_q975": 1344.1038292096118,
            "rating_q025": 1337.7064614643425
        },
        "gemma-3-12b-it": {
            "rating": 1340.7610560841504,
            "rating_q975": 1350.1151310989326,
            "rating_q025": 1331.406981069368
        },
        "hunyuan-turbo-0110": {
            "rating": 1340.351922516461,
            "rating_q975": 1351.1423586257215,
            "rating_q025": 1329.5614864072004
        },
        "qwq-32b": {
            "rating": 1337.1025834719194,
            "rating_q975": 1341.7228648760479,
            "rating_q025": 1332.4823020677911
        },
        "o1-mini": {
            "rating": 1335.6268822602385,
            "rating_q975": 1339.0422508362585,
            "rating_q025": 1332.2115136842185
        },
        "llama-3.1-405b-instruct-bf16": {
            "rating": 1335.3076180992252,
            "rating_q975": 1338.8142869508135,
            "rating_q025": 1331.8009492476372
        },
        "gpt-4o-2024-08-06": {
            "rating": 1333.5895125538627,
            "rating_q975": 1337.5061193514127,
            "rating_q025": 1329.6729057563125
        },
        "llama-3.1-405b-instruct-fp8": {
            "rating": 1333.5229492236936,
            "rating_q975": 1336.8335587705099,
            "rating_q025": 1330.2123396768775
        },
        "grok-2-2024-08-13": {
            "rating": 1332.59726282432,
            "rating_q975": 1336.0085400318585,
            "rating_q025": 1329.1859856167814
        },
        "gemini-advanced-0514": {
            "rating": 1332.434186906224,
            "rating_q975": 1337.4076844314254,
            "rating_q025": 1327.460689381023
        },
        "step-2-16k-exp-202412": {
            "rating": 1332.0836867458343,
            "rating_q975": 1340.3243379679243,
            "rating_q025": 1323.843035523744
        },
        "gpt-oss-20b": {
            "rating": 1329.4091207165889,
            "rating_q975": 1336.5896311797385,
            "rating_q025": 1322.2286102534395
        },
        "qwen3-30b-a3b": {
            "rating": 1329.171150969904,
            "rating_q975": 1334.0859959253903,
            "rating_q025": 1324.2563060144178
        },
        "yi-lightning": {
            "rating": 1327.9567566856153,
            "rating_q975": 1332.6140421271998,
            "rating_q025": 1323.2994712440307
        },
        "llama-4-maverick-17b-128e-instruct": {
            "rating": 1325.7921218575102,
            "rating_q975": 1330.4555538216657,
            "rating_q025": 1321.128689893355
        },
        "llama-3.3-nemotron-49b-super-v1": {
            "rating": 1325.4463388142276,
            "rating_q975": 1336.9708441228506,
            "rating_q025": 1313.9218335056048
        },
        "hunyuan-large-2025-02-10": {
            "rating": 1325.1864292734547,
            "rating_q975": 1334.7427826458447,
            "rating_q025": 1315.6300759010646
        },
        "gpt-4-turbo-2024-04-09": {
            "rating": 1324.452316391854,
            "rating_q975": 1328.0813736067682,
            "rating_q025": 1320.8232591769402
        },
        "step-1o-turbo-202506": {
            "rating": 1322.9151346638462,
            "rating_q975": 1329.3973065738608,
            "rating_q025": 1316.4329627538316
        },
        "claude-3-opus-20240229": {
            "rating": 1322.5597636783077,
            "rating_q975": 1325.3775817399633,
            "rating_q025": 1319.741945616652
        },
        "deepseek-v2.5-1210": {
            "rating": 1321.974980202796,
            "rating_q975": 1329.8433315609739,
            "rating_q025": 1314.1066288446182
        },
        "gemini-1.5-pro-001": {
            "rating": 1321.5477435259004,
            "rating_q975": 1325.2712379023374,
            "rating_q025": 1317.8242491494634
        },
        "gpt-4.1-nano-2025-04-14": {
            "rating": 1320.5267315658448,
            "rating_q975": 1328.1822313785394,
            "rating_q025": 1312.8712317531504
        },
        "amazon-nova-experimental-chat-05-14": {
            "rating": 1320.1873828094297,
            "rating_q975": 1325.4810276621934,
            "rating_q025": 1314.893737956666
        },
        "llama-3.3-70b-instruct": {
            "rating": 1319.986503426188,
            "rating_q975": 1323.4204383003778,
            "rating_q025": 1316.5525685519979
        },
        "llama-4-scout-17b-16e-instruct": {
            "rating": 1319.903593588101,
            "rating_q975": 1325.1910040620553,
            "rating_q025": 1314.616183114147
        },
        "claude-3-5-haiku-20241022": {
            "rating": 1318.376885264715,
            "rating_q975": 1321.7020812066446,
            "rating_q025": 1315.0516893227853
        },
        "glm-4-plus": {
            "rating": 1318.2826301848932,
            "rating_q975": 1322.9362296986883,
            "rating_q025": 1313.629030671098
        },
        "gemma-3n-e4b-it": {
            "rating": 1318.1297076924318,
            "rating_q975": 1323.620018109832,
            "rating_q025": 1312.6393972750316
        },
        "qwen-max-0919": {
            "rating": 1317.1590324718013,
            "rating_q975": 1322.549279891744,
            "rating_q025": 1311.768785051859
        },
        "gpt-4o-mini-2024-07-18": {
            "rating": 1316.4000774782455,
            "rating_q975": 1319.6937922494224,
            "rating_q025": 1313.1063627070687
        },
        "gpt-4-1106-preview": {
            "rating": 1315.0091978349628,
            "rating_q975": 1318.6221637473666,
            "rating_q025": 1311.3962319225593
        },
        "gpt-4-0125-preview": {
            "rating": 1314.9916391059796,
            "rating_q975": 1318.806077413519,
            "rating_q025": 1311.1772007984405
        },
        "qwen2.5-plus-1127": {
            "rating": 1314.8890150484513,
            "rating_q975": 1320.9774127954297,
            "rating_q025": 1308.8006173014726
        },
        "athene-v2-chat": {
            "rating": 1314.0211477662108,
            "rating_q975": 1318.3454842925737,
            "rating_q025": 1309.6968112398479
        },
        "mistral-large-2407": {
            "rating": 1313.9526206257342,
            "rating_q975": 1317.6009235102638,
            "rating_q025": 1310.3043177412044
        },
        "gemini-1.5-flash-002": {
            "rating": 1311.9430251526474,
            "rating_q975": 1315.9157776193283,
            "rating_q025": 1307.9702726859662
        },
        "hunyuan-standard-2025-02-10": {
            "rating": 1309.8117896575438,
            "rating_q975": 1319.3279653457005,
            "rating_q025": 1300.2956139693874
        },
        "deepseek-v2.5": {
            "rating": 1306.895410163294,
            "rating_q975": 1311.290139607072,
            "rating_q025": 1302.500680719516
        },
        "grok-2-mini-2024-08-13": {
            "rating": 1306.8265827443215,
            "rating_q975": 1310.2914812598065,
            "rating_q025": 1303.3616842288366
        },
        "mistral-large-2411": {
            "rating": 1305.4896897168633,
            "rating_q975": 1309.7310119559568,
            "rating_q025": 1301.24836747777
        },
        "athene-70b-0725": {
            "rating": 1305.1876222308788,
            "rating_q975": 1310.5441146922324,
            "rating_q025": 1299.8311297695257
        },
        "gemma-3-4b-it": {
            "rating": 1303.6912312251457,
            "rating_q975": 1312.863854237789,
            "rating_q025": 1294.5186082125026
        },
        "qwen2.5-72b-instruct": {
            "rating": 1302.5927102834844,
            "rating_q975": 1306.4193658151828,
            "rating_q025": 1298.7660547517862
        },
        "magistral-medium-2506": {
            "rating": 1300.658552072675,
            "rating_q975": 1307.556014458013,
            "rating_q025": 1293.7610896873373
        },
        "mistral-small-3.1-24b-instruct-2503": {
            "rating": 1300.499290869965,
            "rating_q975": 1305.8491536061524,
            "rating_q025": 1295.1494281337775
        },
        "llama-3.1-nemotron-70b-instruct": {
            "rating": 1298.0938714979106,
            "rating_q975": 1305.5695887464717,
            "rating_q025": 1290.6181542493491
        },
        "hunyuan-large-vision": {
            "rating": 1296.1715912515026,
            "rating_q975": 1304.9711666101848,
            "rating_q025": 1287.3720158928204
        },
        "llama-3.1-70b-instruct": {
            "rating": 1294.7537680650566,
            "rating_q975": 1298.1980167967693,
            "rating_q025": 1291.309519333344
        },
        "amazon-nova-pro-v1.0": {
            "rating": 1289.573416790381,
            "rating_q975": 1293.9444204611075,
            "rating_q025": 1285.202413119655
        },
        "jamba-1.5-large": {
            "rating": 1289.3287385213525,
            "rating_q975": 1296.309070622691,
            "rating_q025": 1282.3484064200143
        },
        "llama-3.1-tulu-3-70b": {
            "rating": 1289.1224984956452,
            "rating_q975": 1299.1827741141965,
            "rating_q025": 1279.0622228770942
        },
        "reka-core-20240904": {
            "rating": 1288.6176540204597,
            "rating_q975": 1295.264781478419,
            "rating_q025": 1281.9705265625
        },
        "gpt-4-0314": {
            "rating": 1287.8779511777016,
            "rating_q975": 1292.4786068216965,
            "rating_q025": 1283.2772955337068
        },
        "gemma-2-27b-it": {
            "rating": 1287.1474120365078,
            "rating_q975": 1290.2871398805667,
            "rating_q025": 1284.007684192449
        },
        "llama-3.1-nemotron-51b-instruct": {
            "rating": 1287.0453546176732,
            "rating_q975": 1296.6978084214743,
            "rating_q025": 1277.3929008138723
        },
        "gemini-1.5-flash-001": {
            "rating": 1285.2982174336248,
            "rating_q975": 1289.5194682655542,
            "rating_q025": 1281.0769666016959
        },
        "claude-3-sonnet-20240229": {
            "rating": 1283.1820815505275,
            "rating_q975": 1286.9819375971092,
            "rating_q025": 1279.382225503946
        },
        "gemma-2-9b-it-simpo": {
            "rating": 1280.3060546891418,
            "rating_q975": 1286.8652555225776,
            "rating_q025": 1273.746853855706
        },
        "nemotron-4-340b-instruct": {
            "rating": 1279.780695976497,
            "rating_q975": 1284.8628776271657,
            "rating_q025": 1274.6985143258287
        },
        "command-r-plus-08-2024": {
            "rating": 1279.3536081204838,
            "rating_q975": 1285.5850398412106,
            "rating_q025": 1273.1221763997573
        },
        "llama-3-70b-instruct": {
            "rating": 1276.7766228291225,
            "rating_q975": 1280.1264749518973,
            "rating_q025": 1273.426770706348
        },
        "gpt-4-0613": {
            "rating": 1276.3656487815115,
            "rating_q975": 1280.2308418428024,
            "rating_q025": 1272.5004557202205
        },
        "glm-4-0520": {
            "rating": 1275.8874630447394,
            "rating_q975": 1282.6528603335198,
            "rating_q025": 1269.122065755959
        },
        "reka-flash-20240904": {
            "rating": 1275.723341693029,
            "rating_q975": 1282.258496494355,
            "rating_q025": 1269.1881868917026
        },
        "mistral-small-24b-instruct-2501": {
            "rating": 1275.581806420697,
            "rating_q975": 1281.2944321894636,
            "rating_q025": 1269.8691806519305
        },
        "qwen2.5-coder-32b-instruct": {
            "rating": 1271.813859724265,
            "rating_q975": 1279.5688224075163,
            "rating_q025": 1264.0588970410136
        },
        "c4ai-aya-expanse-32b": {
            "rating": 1268.7717258853695,
            "rating_q975": 1273.3984091207487,
            "rating_q025": 1264.1450426499903
        },
        "command-r-plus": {
            "rating": 1265.654231926383,
            "rating_q975": 1269.7681525533392,
            "rating_q025": 1261.5403112994268
        },
        "gemma-2-9b-it": {
            "rating": 1265.3931318702068,
            "rating_q975": 1268.968385440565,
            "rating_q025": 1261.8178782998486
        },
        "deepseek-coder-v2": {
            "rating": 1264.9535074203159,
            "rating_q975": 1270.9893169617417,
            "rating_q025": 1258.91769787889
        },
        "qwen2-72b-instruct": {
            "rating": 1264.8565824363263,
            "rating_q975": 1269.5718540225748,
            "rating_q025": 1260.141310850078
        },
        "claude-3-haiku-20240307": {
            "rating": 1263.3277677447022,
            "rating_q975": 1266.823432877971,
            "rating_q025": 1259.8321026114331
        },
        "amazon-nova-lite-v1.0": {
            "rating": 1262.4289590507487,
            "rating_q975": 1267.3482709477278,
            "rating_q025": 1257.5096471537697
        },
        "gemini-1.5-flash-8b-001": {
            "rating": 1261.958276180319,
            "rating_q975": 1265.991661935106,
            "rating_q025": 1257.924890425532
        },
        "phi-4": {
            "rating": 1258.500242231943,
            "rating_q975": 1262.9041111831093,
            "rating_q025": 1254.0963732807763
        },
        "olmo-2-0325-32b-instruct": {
            "rating": 1256.2000247890328,
            "rating_q975": 1266.7081363461866,
            "rating_q025": 1245.6919132318792
        },
        "command-r-08-2024": {
            "rating": 1255.4210975001447,
            "rating_q975": 1261.6226169006845,
            "rating_q025": 1249.219578099605
        },
        "mistral-large-2402": {
            "rating": 1244.7036952115745,
            "rating_q975": 1249.2292540068308,
            "rating_q025": 1240.1781364163182
        },
        "amazon-nova-micro-v1.0": {
            "rating": 1244.5658579087826,
            "rating_q975": 1249.4444257137366,
            "rating_q025": 1239.687290103829
        },
        "jamba-1.5-mini": {
            "rating": 1241.3183707321432,
            "rating_q975": 1248.197681397858,
            "rating_q025": 1234.439060066428
        },
        "ministral-8b-2410": {
            "rating": 1240.5564381597878,
            "rating_q975": 1249.236935328294,
            "rating_q025": 1231.8759409912816
        },
        "qwen1.5-110b-chat": {
            "rating": 1237.6965689386702,
            "rating_q975": 1242.9852091509615,
            "rating_q025": 1232.407928726379
        },
        "hunyuan-standard-256k": {
            "rating": 1237.1771779791438,
            "rating_q975": 1248.377853453021,
            "rating_q025": 1225.9765025052666
        },
        "qwen1.5-72b-chat": {
            "rating": 1236.5745019859464,
            "rating_q975": 1241.6484621778873,
            "rating_q025": 1231.5005417940054
        },
        "reka-flash-21b-20240226-online": {
            "rating": 1236.3453727108272,
            "rating_q975": 1243.521718270109,
            "rating_q025": 1229.1690271515454
        },
        "gemini-pro-dev-api": {
            "rating": 1235.439352555457,
            "rating_q975": 1242.583089061159,
            "rating_q025": 1228.2956160497552
        },
        "mixtral-8x22b-instruct-v0.1": {
            "rating": 1232.653031452232,
            "rating_q975": 1236.981831734182,
            "rating_q025": 1228.3242311702822
        },
        "command-r": {
            "rating": 1231.721198962306,
            "rating_q975": 1236.2969750929478,
            "rating_q025": 1227.1454228316643
        },
        "reka-flash-21b-20240226": {
            "rating": 1229.5406893777474,
            "rating_q975": 1235.2627238935104,
            "rating_q025": 1223.8186548619842
        },
        "c4ai-aya-expanse-8b": {
            "rating": 1227.9477558999913,
            "rating_q975": 1234.601234770101,
            "rating_q025": 1221.2942770298816
        },
        "mistral-medium": {
            "rating": 1227.384503598029,
            "rating_q975": 1232.6888680990958,
            "rating_q025": 1222.080139096962
        },
        "gpt-3.5-turbo-0125": {
            "rating": 1225.8677041234162,
            "rating_q975": 1230.371076538765,
            "rating_q025": 1221.3643317080675
        },
        "llama-3-8b-instruct": {
            "rating": 1225.7585427827398,
            "rating_q975": 1229.2524310734395,
            "rating_q025": 1222.2646544920403
        },
        "llama-3.1-tulu-3-8b": {
            "rating": 1225.389437779117,
            "rating_q975": 1235.6310101306074,
            "rating_q025": 1215.147865427627
        },
        "gemini-pro": {
            "rating": 1223.0391213581527,
            "rating_q975": 1234.5461817630082,
            "rating_q025": 1211.5320609532973
        },
        "yi-1.5-34b-chat": {
            "rating": 1217.7539893126502,
            "rating_q975": 1222.558633867837,
            "rating_q025": 1212.9493447574635
        },
        "zephyr-orpo-141b-A35b-v0.1": {
            "rating": 1216.7272594190472,
            "rating_q975": 1227.2159063580957,
            "rating_q025": 1206.2386124799987
        },
        "llama-3.1-8b-instruct": {
            "rating": 1215.3862234506837,
            "rating_q975": 1219.2353974743385,
            "rating_q025": 1211.5370494270287
        },
        "granite-3.1-8b-instruct": {
            "rating": 1213.9720962420938,
            "rating_q975": 1224.4432549383107,
            "rating_q025": 1203.5009375458772
        },
        "qwen1.5-32b-chat": {
            "rating": 1209.13475548299,
            "rating_q975": 1215.0074446418885,
            "rating_q025": 1203.2620663240912
        },
        "gpt-3.5-turbo-1106": {
            "rating": 1203.5885268554202,
            "rating_q975": 1212.1738484540278,
            "rating_q025": 1195.0032052568129
        },
        "phi-3-medium-4k-instruct": {
            "rating": 1202.2499014974114,
            "rating_q975": 1207.1673597576405,
            "rating_q025": 1197.3324432371824
        },
        "mixtral-8x7b-instruct-v0.1": {
            "rating": 1201.783654254299,
            "rating_q975": 1205.854212323987,
            "rating_q025": 1197.713096184611
        },
        "gemma-2-2b-it": {
            "rating": 1201.6895768632698,
            "rating_q975": 1205.5378681934642,
            "rating_q025": 1197.8412855330757
        },
        "internlm2_5-20b-chat": {
            "rating": 1199.452438752379,
            "rating_q975": 1206.2425096681527,
            "rating_q025": 1192.6623678366054
        },
        "dbrx-instruct-preview": {
            "rating": 1199.06185912526,
            "rating_q975": 1204.9196182197777,
            "rating_q025": 1193.2041000307424
        },
        "qwen1.5-14b-chat": {
            "rating": 1196.5198356981464,
            "rating_q975": 1203.3541276160418,
            "rating_q025": 1189.6855437802512
        },
        "wizardlm-70b": {
            "rating": 1189.0212789948123,
            "rating_q975": 1198.3336502432026,
            "rating_q025": 1179.708907746422
        },
        "granite-3.0-8b-instruct": {
            "rating": 1188.628508858776,
            "rating_q975": 1196.874848358514,
            "rating_q025": 1180.3821693590382
        },
        "yi-34b-chat": {
            "rating": 1187.972178165388,
            "rating_q975": 1194.606151713896,
            "rating_q025": 1181.33820461688
        },
        "deepseek-llm-67b-chat": {
            "rating": 1187.6545528405597,
            "rating_q975": 1199.073004648692,
            "rating_q025": 1176.2361010324275
        },
        "openchat-3.5-0106": {
            "rating": 1186.6626672167426,
            "rating_q975": 1194.4968975149739,
            "rating_q025": 1178.8284369185114
        },
        "openchat-3.5": {
            "rating": 1184.9803971376455,
            "rating_q975": 1194.5223313588306,
            "rating_q025": 1175.4384629164606
        },
        "granite-3.1-2b-instruct": {
            "rating": 1184.6491877300782,
            "rating_q975": 1195.324703961383,
            "rating_q025": 1173.9736714987737
        },
        "snowflake-arctic-instruct": {
            "rating": 1184.3013697249055,
            "rating_q975": 1189.9661829770857,
            "rating_q025": 1178.6365564727253
        },
        "tulu-2-dpo-70b": {
            "rating": 1183.4550332194735,
            "rating_q975": 1193.1204179863187,
            "rating_q025": 1173.7896484526284
        },
        "gemma-1.1-7b-it": {
            "rating": 1181.5986854254897,
            "rating_q975": 1187.4455902212246,
            "rating_q025": 1175.7517806297546
        },
        "openhermes-2.5-mistral-7b": {
            "rating": 1179.4630635963774,
            "rating_q975": 1189.7229545055102,
            "rating_q025": 1169.2031726872447
        },
        "vicuna-33b": {
            "rating": 1178.1174348772402,
            "rating_q975": 1184.1481907862208,
            "rating_q025": 1172.0866789682595
        },
        "starling-lm-7b-beta": {
            "rating": 1177.2963288273618,
            "rating_q975": 1184.497375208456,
            "rating_q025": 1170.0952824462677
        },
        "phi-3-small-8k-instruct": {
            "rating": 1176.6630154803483,
            "rating_q975": 1182.3324559252856,
            "rating_q025": 1170.9935750354114
        },
        "llama-2-70b-chat": {
            "rating": 1176.1572127316615,
            "rating_q975": 1181.4811843971702,
            "rating_q025": 1170.8332410661526
        },
        "starling-lm-7b-alpha": {
            "rating": 1172.7028125597344,
            "rating_q975": 1180.625567573048,
            "rating_q025": 1164.780057546421
        },
        "llama-3.2-3b-instruct": {
            "rating": 1172.636263501291,
            "rating_q975": 1179.9722444204658,
            "rating_q025": 1165.300282582116
        },
        "nous-hermes-2-mixtral-8x7b-dpo": {
            "rating": 1170.9099076058374,
            "rating_q975": 1182.6855013951085,
            "rating_q025": 1159.134313816566
        },
        "qwq-32b-preview": {
            "rating": 1168.8065483393257,
            "rating_q975": 1179.857147649935,
            "rating_q025": 1157.7559490287163
        },
        "granite-3.0-2b-instruct": {
            "rating": 1163.1100759346953,
            "rating_q975": 1171.0853503480625,
            "rating_q025": 1155.134801521328
        },
        "llama2-70b-steerlm-chat": {
            "rating": 1162.7733654354663,
            "rating_q975": 1175.277905608461,
            "rating_q025": 1150.2688252624716
        },
        "solar-10.7b-instruct-v1.0": {
            "rating": 1159.191932771841,
            "rating_q975": 1172.166878465392,
            "rating_q025": 1146.21698707829
        },
        "dolphin-2.2.1-mistral-7b": {
            "rating": 1157.6254837328079,
            "rating_q975": 1172.8802625043907,
            "rating_q025": 1142.3707049612249
        },
        "mistral-7b-instruct-v0.2": {
            "rating": 1155.6841420973558,
            "rating_q975": 1162.1371271616608,
            "rating_q025": 1149.2311570330507
        },
        "mpt-30b-chat": {
            "rating": 1154.893877050747,
            "rating_q975": 1166.9410361560642,
            "rating_q025": 1142.8467179454299
        },
        "wizardlm-13b": {
            "rating": 1154.5441319477584,
            "rating_q975": 1163.682142613537,
            "rating_q025": 1145.4061212819797
        },
        "falcon-180b-chat": {
            "rating": 1150.1155228167831,
            "rating_q975": 1167.0560197824204,
            "rating_q025": 1133.1750258511458
        },
        "phi-3-mini-4k-instruct-june-2024": {
            "rating": 1148.8921429772774,
            "rating_q975": 1155.0269071720786,
            "rating_q025": 1142.7573787824765
        },
        "qwen1.5-7b-chat": {
            "rating": 1148.3585781636984,
            "rating_q975": 1158.0494525415875,
            "rating_q025": 1138.6677037858094
        },
        "llama-2-13b-chat": {
            "rating": 1147.9283095433248,
            "rating_q975": 1154.4520173300643,
            "rating_q025": 1141.4046017565852
        },
        "vicuna-13b": {
            "rating": 1146.1324219770129,
            "rating_q975": 1152.6786187477285,
            "rating_q025": 1139.5862252062973
        },
        "qwen-14b-chat": {
            "rating": 1142.2837483811168,
            "rating_q975": 1153.104333776148,
            "rating_q025": 1131.4631629860853
        },
        "codellama-34b-instruct": {
            "rating": 1141.5759592613626,
            "rating_q975": 1150.3241468070262,
            "rating_q025": 1132.8277717156986
        },
        "palm-2": {
            "rating": 1138.8982503016255,
            "rating_q975": 1148.1644205962916,
            "rating_q025": 1129.632080006959
        },
        "gemma-7b-it": {
            "rating": 1137.5460259852375,
            "rating_q975": 1146.863466404515,
            "rating_q025": 1128.22858556596
        },
        "phi-3-mini-128k-instruct": {
            "rating": 1137.233156843515,
            "rating_q975": 1144.365145760574,
            "rating_q025": 1130.101167926456
        },
        "zephyr-7b-beta": {
            "rating": 1136.653473496733,
            "rating_q975": 1145.3668766972673,
            "rating_q025": 1127.9400702961984
        },
        "phi-3-mini-4k-instruct": {
            "rating": 1135.1876635930712,
            "rating_q975": 1141.2895838030922,
            "rating_q025": 1129.0857433830502
        },
        "zephyr-7b-alpha": {
            "rating": 1133.1343619581298,
            "rating_q975": 1148.742447945142,
            "rating_q025": 1117.5262759711175
        },
        "guanaco-33b": {
            "rating": 1132.2523657812753,
            "rating_q975": 1144.2241109153101,
            "rating_q025": 1120.2806206472403
        },
        "smollm2-1.7b-instruct": {
            "rating": 1130.2459675697512,
            "rating_q975": 1143.6295827650183,
            "rating_q025": 1116.8623523744839
        },
        "codellama-70b-instruct": {
            "rating": 1125.1106855118378,
            "rating_q975": 1142.8228766692912,
            "rating_q025": 1107.3984943543844
        },
        "stripedhyena-nous-7b": {
            "rating": 1124.6386911874001,
            "rating_q975": 1135.510447584137,
            "rating_q025": 1113.766934790663
        },
        "llama-3.2-1b-instruct": {
            "rating": 1122.131483126258,
            "rating_q975": 1129.5604909943547,
            "rating_q025": 1114.7024752581613
        },
        "vicuna-7b": {
            "rating": 1119.4622152167863,
            "rating_q975": 1128.5433666302843,
            "rating_q025": 1110.381063803288
        },
        "gemma-1.1-2b-it": {
            "rating": 1116.9764002094594,
            "rating_q975": 1124.4324075896216,
            "rating_q025": 1109.5203928292974
        },
        "mistral-7b-instruct": {
            "rating": 1114.496852115277,
            "rating_q975": 1123.6576687054148,
            "rating_q025": 1105.3360355251393
        },
        "llama-2-7b-chat": {
            "rating": 1114.1828750126463,
            "rating_q975": 1121.0529247679829,
            "rating_q025": 1107.3128252573097
        },
        "qwen1.5-4b-chat": {
            "rating": 1095.5333222126278,
            "rating_q975": 1104.6847956208035,
            "rating_q025": 1086.3818488044521
        },
        "gemma-2b-it": {
            "rating": 1094.5111172059917,
            "rating_q975": 1105.8659282921851,
            "rating_q025": 1083.1563061197983
        },
        "olmo-7b-instruct": {
            "rating": 1080.4467033662818,
            "rating_q975": 1091.444523318187,
            "rating_q025": 1069.4488834143763
        },
        "koala-13b": {
            "rating": 1074.8684926559313,
            "rating_q975": 1084.7435954694731,
            "rating_q025": 1064.9933898423894
        },
        "gpt4all-13b-snoozy": {
            "rating": 1067.1300543848704,
            "rating_q975": 1082.2627523859048,
            "rating_q025": 1051.9973563838357
        },
        "alpaca-13b": {
            "rating": 1066.821563093357,
            "rating_q975": 1078.1993851099407,
            "rating_q025": 1055.4437410767732
        },
        "mpt-7b-chat": {
            "rating": 1065.0552100861357,
            "rating_q975": 1076.978873988003,
            "rating_q025": 1053.1315461842685
        },
        "chatglm3-6b": {
            "rating": 1060.41892694029,
            "rating_q975": 1071.9374882825996,
            "rating_q025": 1048.9003655979805
        },
        "RWKV-4-Raven-14B": {
            "rating": 1045.4069763242996,
            "rating_q975": 1056.7487844405437,
            "rating_q025": 1034.0651682080559
        },
        "chatglm2-6b": {
            "rating": 1030.6040077668586,
            "rating_q975": 1044.0367798192974,
            "rating_q025": 1017.1712357144195
        },
        "oasst-pythia-12b": {
            "rating": 1024.7427327261216,
            "rating_q975": 1035.628244706714,
            "rating_q025": 1013.8572207455294
        },
        "chatglm-6b": {
            "rating": 1000.5395984030472,
            "rating_q975": 1013.0633612709987,
            "rating_q025": 988.0158355350958
        },
        "fastchat-t5-3b": {
            "rating": 994.56722134194,
            "rating_q975": 1006.9010461517443,
            "rating_q025": 982.2333965321359
        },
        "dolly-v2-12b": {
            "rating": 979.7852184440459,
            "rating_q975": 993.3637942225132,
            "rating_q025": 966.2066426655786
        },
        "llama-13b": {
            "rating": 971.4001080372288,
            "rating_q975": 987.2395045150179,
            "rating_q025": 955.5607115594398
        },
        "stablelm-tuned-alpha-7b": {
            "rating": 956.4621877967302,
            "rating_q975": 969.257401211514,
            "rating_q025": 943.6669743819464
        }
    },
    "german": {
        "gpt-4.5-preview-2025-02-27": {
            "rating": 1466.7056484441289,
            "rating_q975": 1499.6410498082273,
            "rating_q025": 1433.7702470800305
        },
        "gpt-5-high": {
            "rating": 1463.3913756954914,
            "rating_q975": 1507.2239248411493,
            "rating_q025": 1419.5588265498338
        },
        "gpt-5-chat": {
            "rating": 1451.4446413555631,
            "rating_q975": 1501.7226679130795,
            "rating_q025": 1401.1666147980466
        },
        "gemini-2.5-pro": {
            "rating": 1449.814377864802,
            "rating_q975": 1473.1114039875138,
            "rating_q025": 1426.5173517420903
        },
        "claude-opus-4-1-20250805": {
            "rating": 1449.4233265963055,
            "rating_q975": 1493.8813482919968,
            "rating_q025": 1404.9653049006145
        },
        "o3-2025-04-16": {
            "rating": 1447.8704725812968,
            "rating_q975": 1468.848092114106,
            "rating_q025": 1426.8928530484875
        },
        "qwen3-235b-a22b-instruct-2507": {
            "rating": 1435.379147090111,
            "rating_q975": 1473.295043014032,
            "rating_q025": 1397.4632511661898
        },
        "claude-opus-4-20250514-thinking-16k": {
            "rating": 1433.2855971509073,
            "rating_q975": 1459.968339269449,
            "rating_q025": 1406.6028550323656
        },
        "grok-4-0709": {
            "rating": 1433.1710525108258,
            "rating_q975": 1466.34222888866,
            "rating_q025": 1399.9998761329919
        },
        "claude-opus-4-1-20250805-thinking-16k": {
            "rating": 1430.6971457318652,
            "rating_q975": 1477.4755503366277,
            "rating_q025": 1383.9187411271025
        },
        "claude-opus-4-20250514": {
            "rating": 1427.185059921113,
            "rating_q975": 1449.2695260657495,
            "rating_q025": 1405.1005937764767
        },
        "chatgpt-4o-latest-20250326": {
            "rating": 1422.5864299516682,
            "rating_q975": 1444.8446949052486,
            "rating_q025": 1400.3281649980877
        },
        "kimi-k2-0711-preview": {
            "rating": 1413.243474122568,
            "rating_q975": 1444.9758756461952,
            "rating_q025": 1381.5110725989407
        },
        "grok-3-preview-02-24": {
            "rating": 1406.9181922622554,
            "rating_q975": 1429.9555770981203,
            "rating_q025": 1383.8808074263907
        },
        "gemini-2.5-flash": {
            "rating": 1400.2455889018727,
            "rating_q975": 1421.0100026256905,
            "rating_q025": 1379.481175178055
        },
        "gpt-4.1-2025-04-14": {
            "rating": 1391.0124769274455,
            "rating_q975": 1413.3280305043127,
            "rating_q025": 1368.6969233505781
        },
        "claude-sonnet-4-20250514": {
            "rating": 1390.8017413850264,
            "rating_q975": 1414.5820541614553,
            "rating_q025": 1367.0214286085975
        },
        "deepseek-r1": {
            "rating": 1387.5194721035327,
            "rating_q975": 1415.865997755698,
            "rating_q025": 1359.1729464513676
        },
        "mistral-medium-2505": {
            "rating": 1385.7850404883395,
            "rating_q975": 1407.1382144297195,
            "rating_q025": 1364.4318665469596
        },
        "claude-3-7-sonnet-20250219-thinking-32k": {
            "rating": 1382.4778810925272,
            "rating_q975": 1404.0250231032167,
            "rating_q025": 1360.9307390818376
        },
        "deepseek-v3-0324": {
            "rating": 1382.2162712172565,
            "rating_q975": 1404.8979151914443,
            "rating_q025": 1359.5346272430686
        },
        "qwen3-235b-a22b-thinking-2507": {
            "rating": 1379.9233120955344,
            "rating_q975": 1426.7948168379571,
            "rating_q025": 1333.0518073531114
        },
        "mistral-small-2506": {
            "rating": 1379.5074711126163,
            "rating_q975": 1414.2262603939885,
            "rating_q025": 1344.788681831244
        },
        "gpt-4.1-mini-2025-04-14": {
            "rating": 1376.110375108203,
            "rating_q975": 1399.2747987223127,
            "rating_q025": 1352.9459514940932
        },
        "claude-sonnet-4-20250514-thinking-32k": {
            "rating": 1375.2307759293906,
            "rating_q975": 1401.5699972135562,
            "rating_q025": 1348.891554645225
        },
        "qwen3-235b-a22b": {
            "rating": 1373.249133328726,
            "rating_q975": 1397.4525112902406,
            "rating_q025": 1349.0457553672113
        },
        "qwen3-235b-a22b-no-thinking": {
            "rating": 1372.9140927294263,
            "rating_q975": 1396.1196795657627,
            "rating_q025": 1349.70850589309
        },
        "gemma-3-27b-it": {
            "rating": 1372.2461299317392,
            "rating_q975": 1393.7419035129133,
            "rating_q025": 1350.7503563505652
        },
        "deepseek-r1-0528": {
            "rating": 1371.9002430386329,
            "rating_q975": 1398.593502349686,
            "rating_q025": 1345.2069837275799
        },
        "qwen3-coder-480b-a35b-instruct": {
            "rating": 1370.4429994205937,
            "rating_q975": 1412.261664892149,
            "rating_q025": 1328.6243339490381
        },
        "claude-3-5-sonnet-20241022": {
            "rating": 1369.64280024613,
            "rating_q975": 1384.6573292803466,
            "rating_q025": 1354.6282712119134
        },
        "gemma-3-12b-it": {
            "rating": 1368.6393255056864,
            "rating_q975": 1411.3311633891494,
            "rating_q025": 1325.9474876222234
        },
        "o4-mini-2025-04-16": {
            "rating": 1367.1835757185017,
            "rating_q975": 1390.4107186528536,
            "rating_q025": 1343.9564327841497
        },
        "o1-2024-12-17": {
            "rating": 1364.8161669399653,
            "rating_q975": 1389.0165914147105,
            "rating_q025": 1340.61574246522
        },
        "glm-4.5": {
            "rating": 1364.3449701461566,
            "rating_q975": 1405.7383673842014,
            "rating_q025": 1322.9515729081118
        },
        "glm-4.5-air": {
            "rating": 1358.252897275316,
            "rating_q975": 1398.0191026640628,
            "rating_q025": 1318.4866918865691
        },
        "claude-3-7-sonnet-20250219": {
            "rating": 1355.2774737805478,
            "rating_q975": 1376.6461646686168,
            "rating_q025": 1333.9087828924787
        },
        "minimax-m1": {
            "rating": 1351.2567895908817,
            "rating_q975": 1378.8349228691955,
            "rating_q025": 1323.6786563125681
        },
        "gemini-2.0-flash-001": {
            "rating": 1349.9272387984054,
            "rating_q975": 1370.0334703469148,
            "rating_q025": 1329.821007249896
        },
        "command-a-03-2025": {
            "rating": 1349.8450324375854,
            "rating_q975": 1370.7649554986758,
            "rating_q025": 1328.9251093764951
        },
        "o1-preview": {
            "rating": 1345.7807019088677,
            "rating_q975": 1367.2528736685156,
            "rating_q025": 1324.3085301492197
        },
        "deepseek-v3": {
            "rating": 1341.998331397364,
            "rating_q975": 1367.3322628907322,
            "rating_q025": 1316.6643999039957
        },
        "qwen2.5-max": {
            "rating": 1341.6898919134067,
            "rating_q975": 1363.6789340573112,
            "rating_q025": 1319.700849769502
        },
        "glm-4-plus-0111": {
            "rating": 1339.5588992771563,
            "rating_q975": 1377.8840531502433,
            "rating_q025": 1301.2337454040692
        },
        "grok-3-mini-high": {
            "rating": 1336.2657993689015,
            "rating_q975": 1368.3820148458708,
            "rating_q025": 1304.1495838919325
        },
        "hunyuan-turbos-20250416": {
            "rating": 1331.3116606451415,
            "rating_q975": 1363.9310143513026,
            "rating_q025": 1298.6923069389804
        },
        "gemma-3n-e4b-it": {
            "rating": 1328.9070503770815,
            "rating_q975": 1354.8540126487287,
            "rating_q025": 1302.9600881054346
        },
        "claude-3-5-sonnet-20240620": {
            "rating": 1325.4580372125786,
            "rating_q975": 1340.2738384243485,
            "rating_q025": 1310.6422360008087
        },
        "qwen3-32b": {
            "rating": 1324.3285287029903,
            "rating_q975": 1364.9987055621182,
            "rating_q025": 1283.6583518438626
        },
        "o3-mini": {
            "rating": 1322.284379326813,
            "rating_q975": 1341.9702215041084,
            "rating_q025": 1302.5985371495176
        },
        "o3-mini-high": {
            "rating": 1322.1739022934182,
            "rating_q975": 1351.7444935251217,
            "rating_q025": 1292.6033110617145
        },
        "gemini-2.0-flash-lite-preview-02-05": {
            "rating": 1322.0467345221598,
            "rating_q975": 1344.8866801069098,
            "rating_q025": 1299.2067889374098
        },
        "grok-3-mini-beta": {
            "rating": 1321.4303848290037,
            "rating_q975": 1348.7775267207105,
            "rating_q025": 1294.0832429372972
        },
        "gpt-4o-2024-05-13": {
            "rating": 1320.5889011389875,
            "rating_q975": 1333.8382140174033,
            "rating_q025": 1307.3395882605719
        },
        "llama-4-maverick-17b-128e-instruct": {
            "rating": 1320.0039648515367,
            "rating_q975": 1343.2095263820756,
            "rating_q025": 1296.7984033209975
        },
        "gemini-advanced-0514": {
            "rating": 1317.8512403103448,
            "rating_q975": 1334.9761802254998,
            "rating_q025": 1300.7263003951896
        },
        "amazon-nova-experimental-chat-05-14": {
            "rating": 1316.2754992459056,
            "rating_q975": 1343.5843594492464,
            "rating_q025": 1288.966639042565
        },
        "gpt-4.1-nano-2025-04-14": {
            "rating": 1315.2543671097837,
            "rating_q975": 1352.8614120961215,
            "rating_q025": 1277.6473221234457
        },
        "claude-3-opus-20240229": {
            "rating": 1311.2495721664448,
            "rating_q975": 1323.824294826655,
            "rating_q025": 1298.6748495062345
        },
        "qwen3-30b-a3b-instruct-2507": {
            "rating": 1311.0708531240355,
            "rating_q975": 1356.1305335649784,
            "rating_q025": 1266.0111726830926
        },
        "gemini-1.5-pro-002": {
            "rating": 1307.8554336889606,
            "rating_q975": 1324.9780279777215,
            "rating_q025": 1290.7328394001997
        },
        "gpt-4o-2024-08-06": {
            "rating": 1305.4327096180982,
            "rating_q975": 1322.9025197191054,
            "rating_q025": 1287.962899517091
        },
        "gpt-4-turbo-2024-04-09": {
            "rating": 1305.2925835436395,
            "rating_q975": 1319.24916005494,
            "rating_q025": 1291.3360070323392
        },
        "grok-2-2024-08-13": {
            "rating": 1302.7103241945588,
            "rating_q975": 1318.7748426862108,
            "rating_q025": 1286.6458057029067
        },
        "claude-3-5-haiku-20241022": {
            "rating": 1302.0066949219802,
            "rating_q975": 1319.9977428097986,
            "rating_q025": 1284.0156470341615
        },
        "llama-3.1-405b-instruct-bf16": {
            "rating": 1298.340164333699,
            "rating_q975": 1318.1885112948949,
            "rating_q025": 1278.4918173725034
        },
        "qwen3-30b-a3b": {
            "rating": 1297.4807235631363,
            "rating_q975": 1321.9795665505485,
            "rating_q025": 1272.981880575724
        },
        "llama-3.1-405b-instruct-fp8": {
            "rating": 1296.0309282999417,
            "rating_q975": 1312.1348074706555,
            "rating_q025": 1279.927049129228
        },
        "glm-4-plus": {
            "rating": 1294.6846280798131,
            "rating_q975": 1317.6655851070877,
            "rating_q025": 1271.7036710525385
        },
        "magistral-medium-2506": {
            "rating": 1293.6482249600317,
            "rating_q975": 1330.6476755618394,
            "rating_q025": 1256.6487743582243
        },
        "gpt-4-1106-preview": {
            "rating": 1293.5837087212774,
            "rating_q975": 1308.6400597386346,
            "rating_q025": 1278.5273577039204
        },
        "mistral-large-2407": {
            "rating": 1293.0493084590828,
            "rating_q975": 1310.6248291396653,
            "rating_q025": 1275.4737877785003
        },
        "o1-mini": {
            "rating": 1291.8089915045857,
            "rating_q975": 1309.9745098191236,
            "rating_q025": 1273.643473190048
        },
        "gemini-1.5-pro-001": {
            "rating": 1291.63816035249,
            "rating_q975": 1306.328237602235,
            "rating_q025": 1276.948083102745
        },
        "llama-4-scout-17b-16e-instruct": {
            "rating": 1291.6320315687708,
            "rating_q975": 1320.0954097834076,
            "rating_q025": 1263.1686533541338
        },
        "gpt-4o-mini-2024-07-18": {
            "rating": 1289.590141829272,
            "rating_q975": 1304.9873080090501,
            "rating_q025": 1274.1929756494937
        },
        "qwq-32b": {
            "rating": 1289.5089695078923,
            "rating_q975": 1314.4529844425895,
            "rating_q025": 1264.5649545731949
        },
        "gpt-4-0125-preview": {
            "rating": 1288.588557444559,
            "rating_q975": 1303.3345092427373,
            "rating_q025": 1273.8426056463807
        },
        "step-1o-turbo-202506": {
            "rating": 1288.0216312103134,
            "rating_q975": 1320.1507871928175,
            "rating_q025": 1255.8924752278092
        },
        "gemma-3-4b-it": {
            "rating": 1284.9095481785691,
            "rating_q975": 1326.353202372796,
            "rating_q025": 1243.4658939843423
        },
        "grok-2-mini-2024-08-13": {
            "rating": 1283.3670602845789,
            "rating_q975": 1300.679940004198,
            "rating_q025": 1266.0541805649598
        },
        "yi-lightning": {
            "rating": 1283.1296753347247,
            "rating_q975": 1304.868535945433,
            "rating_q025": 1261.390814724016
        },
        "llama-3.3-70b-instruct": {
            "rating": 1283.1110986350916,
            "rating_q975": 1301.8987103731627,
            "rating_q025": 1264.3234868970205
        },
        "mistral-large-2411": {
            "rating": 1278.6369297807996,
            "rating_q975": 1301.5967236173758,
            "rating_q025": 1255.6771359442232
        },
        "athene-70b-0725": {
            "rating": 1277.3442103511964,
            "rating_q975": 1301.006059079265,
            "rating_q025": 1253.6823616231277
        },
        "deepseek-v2.5-1210": {
            "rating": 1276.1160121932805,
            "rating_q975": 1323.14494513679,
            "rating_q025": 1229.0870792497713
        },
        "gemini-1.5-flash-002": {
            "rating": 1275.3971803292566,
            "rating_q975": 1297.1819622204978,
            "rating_q025": 1253.6123984380151
        },
        "qwen-max-0919": {
            "rating": 1275.2555227572734,
            "rating_q975": 1301.1885345336188,
            "rating_q025": 1249.322510980928
        },
        "reka-core-20240904": {
            "rating": 1274.9280942698101,
            "rating_q975": 1315.311967037468,
            "rating_q025": 1234.5442215021521
        },
        "mistral-small-3.1-24b-instruct-2503": {
            "rating": 1271.7905323154027,
            "rating_q975": 1300.9273588849762,
            "rating_q025": 1242.6537057458295
        },
        "gpt-4-0314": {
            "rating": 1271.434298150928,
            "rating_q975": 1290.132744987637,
            "rating_q025": 1252.735851314219
        },
        "athene-v2-chat": {
            "rating": 1269.3054920531008,
            "rating_q975": 1292.2701928604351,
            "rating_q025": 1246.3407912457665
        },
        "claude-3-sonnet-20240229": {
            "rating": 1268.450195150615,
            "rating_q975": 1283.2699216984222,
            "rating_q025": 1253.6304686028075
        },
        "amazon-nova-pro-v1.0": {
            "rating": 1266.3657149806356,
            "rating_q975": 1290.1358453142814,
            "rating_q025": 1242.59558464699
        },
        "gemma-2-9b-it-simpo": {
            "rating": 1263.676339073048,
            "rating_q975": 1294.9583020626565,
            "rating_q025": 1232.3943760834393
        },
        "gemma-2-27b-it": {
            "rating": 1259.9657173268683,
            "rating_q975": 1274.4926879787004,
            "rating_q025": 1245.4387466750366
        },
        "gemini-1.5-flash-001": {
            "rating": 1256.99486411213,
            "rating_q975": 1272.1462188269406,
            "rating_q025": 1241.8435093973194
        },
        "qwen2.5-72b-instruct": {
            "rating": 1256.2736087229548,
            "rating_q975": 1275.6172328540265,
            "rating_q025": 1236.929984591883
        },
        "command-r-plus-08-2024": {
            "rating": 1255.3932275910242,
            "rating_q975": 1288.6199203235817,
            "rating_q025": 1222.1665348584665
        },
        "deepseek-v2.5": {
            "rating": 1252.0131347135932,
            "rating_q975": 1276.4895865265114,
            "rating_q025": 1227.536682900675
        },
        "amazon-nova-lite-v1.0": {
            "rating": 1251.9094268170302,
            "rating_q975": 1278.453213777154,
            "rating_q025": 1225.3656398569065
        },
        "phi-4": {
            "rating": 1249.7675902662022,
            "rating_q975": 1276.1584393855994,
            "rating_q025": 1223.376741146805
        },
        "llama-3.1-70b-instruct": {
            "rating": 1249.4800542887447,
            "rating_q975": 1266.5147514903708,
            "rating_q025": 1232.4453570871185
        },
        "mistral-small-24b-instruct-2501": {
            "rating": 1248.5696067567758,
            "rating_q975": 1281.9304239535459,
            "rating_q025": 1215.2087895600057
        },
        "gpt-4-0613": {
            "rating": 1248.2718912151358,
            "rating_q975": 1264.0356760414736,
            "rating_q025": 1232.5081063887978
        },
        "command-r-plus": {
            "rating": 1247.2633492023733,
            "rating_q975": 1262.2915822836055,
            "rating_q025": 1232.235116121141
        },
        "jamba-1.5-large": {
            "rating": 1242.7106966690899,
            "rating_q975": 1279.0201713675385,
            "rating_q025": 1206.4012219706415
        },
        "nemotron-4-340b-instruct": {
            "rating": 1240.9836533763187,
            "rating_q975": 1264.029883196633,
            "rating_q025": 1217.9374235560044
        },
        "mistral-large-2402": {
            "rating": 1240.619139099851,
            "rating_q975": 1257.4149068063434,
            "rating_q025": 1223.823371393359
        },
        "qwen2.5-plus-1127": {
            "rating": 1239.794626368663,
            "rating_q975": 1274.7855193616933,
            "rating_q025": 1204.8037333756326
        },
        "claude-3-haiku-20240307": {
            "rating": 1239.104255061874,
            "rating_q975": 1252.9250365882278,
            "rating_q025": 1225.28347353552
        },
        "command-r-08-2024": {
            "rating": 1238.1167931410214,
            "rating_q975": 1271.3716236052358,
            "rating_q025": 1204.8619626768068
        },
        "gemma-2-9b-it": {
            "rating": 1235.6931539010468,
            "rating_q975": 1251.77942489239,
            "rating_q025": 1219.6068829097037
        },
        "c4ai-aya-expanse-32b": {
            "rating": 1230.4476826383475,
            "rating_q975": 1254.4215692699383,
            "rating_q025": 1206.4737960067564
        },
        "deepseek-coder-v2": {
            "rating": 1227.7214948136611,
            "rating_q975": 1253.6973179084155,
            "rating_q025": 1201.7456717189066
        },
        "reka-flash-20240904": {
            "rating": 1224.2226806437216,
            "rating_q975": 1263.5767868956384,
            "rating_q025": 1184.8685743918045
        },
        "gemini-1.5-flash-8b-001": {
            "rating": 1221.8745432953501,
            "rating_q975": 1243.0333385934675,
            "rating_q025": 1200.715747997233
        },
        "llama-3-70b-instruct": {
            "rating": 1221.1701300160755,
            "rating_q975": 1234.4426156420916,
            "rating_q025": 1207.8976443900594
        },
        "glm-4-0520": {
            "rating": 1219.143395568795,
            "rating_q975": 1248.580173384006,
            "rating_q025": 1189.706617753584
        },
        "amazon-nova-micro-v1.0": {
            "rating": 1217.8515306232691,
            "rating_q975": 1245.5821766036884,
            "rating_q025": 1190.12088464285
        },
        "qwen2-72b-instruct": {
            "rating": 1215.8787435871418,
            "rating_q975": 1233.3272772621035,
            "rating_q025": 1198.4302099121803
        },
        "c4ai-aya-expanse-8b": {
            "rating": 1214.765463431062,
            "rating_q975": 1251.3759619463037,
            "rating_q025": 1178.1549649158203
        },
        "reka-flash-21b-20240226": {
            "rating": 1212.9889768558323,
            "rating_q975": 1234.4657110428618,
            "rating_q025": 1191.5122426688026
        },
        "mistral-medium": {
            "rating": 1211.815250136294,
            "rating_q975": 1234.0817187927764,
            "rating_q025": 1189.5487814798116
        },
        "reka-flash-21b-20240226-online": {
            "rating": 1211.1816782267829,
            "rating_q975": 1237.84098262431,
            "rating_q025": 1184.5223738292555
        },
        "mixtral-8x22b-instruct-v0.1": {
            "rating": 1210.7346068584352,
            "rating_q975": 1227.7433893717246,
            "rating_q025": 1193.7258243451456
        },
        "jamba-1.5-mini": {
            "rating": 1205.7241548165607,
            "rating_q975": 1243.1503298822147,
            "rating_q025": 1168.2979797509065
        },
        "gemini-pro-dev-api": {
            "rating": 1204.2233293919155,
            "rating_q975": 1233.382786727036,
            "rating_q025": 1175.0638720567952
        },
        "gpt-3.5-turbo-0125": {
            "rating": 1191.8860740178982,
            "rating_q975": 1208.6139071228038,
            "rating_q025": 1175.1582409129926
        },
        "command-r": {
            "rating": 1188.9296966382494,
            "rating_q975": 1206.8943956260623,
            "rating_q025": 1170.964997650436
        },
        "qwen1.5-110b-chat": {
            "rating": 1184.336994828142,
            "rating_q975": 1204.7543002818766,
            "rating_q025": 1163.9196893744072
        },
        "mixtral-8x7b-instruct-v0.1": {
            "rating": 1180.5887006531295,
            "rating_q975": 1196.5880808534848,
            "rating_q025": 1164.589320452774
        },
        "gpt-3.5-turbo-1106": {
            "rating": 1169.465211031987,
            "rating_q975": 1203.7751400318234,
            "rating_q025": 1135.155282032151
        },
        "phi-3-medium-4k-instruct": {
            "rating": 1167.7659182534521,
            "rating_q975": 1188.3592630128949,
            "rating_q025": 1147.1725734940096
        },
        "llama-3.1-8b-instruct": {
            "rating": 1162.2097471478949,
            "rating_q975": 1180.052211161881,
            "rating_q025": 1144.3672831339088
        },
        "llama-3-8b-instruct": {
            "rating": 1155.999617029142,
            "rating_q975": 1170.2492304377806,
            "rating_q025": 1141.750003620503
        },
        "qwen1.5-72b-chat": {
            "rating": 1152.0508029899863,
            "rating_q975": 1171.5469679836403,
            "rating_q025": 1132.5546379963325
        },
        "yi-1.5-34b-chat": {
            "rating": 1151.4262268621753,
            "rating_q975": 1172.0380860969958,
            "rating_q025": 1130.8143676273548
        },
        "gemma-2-2b-it": {
            "rating": 1147.0620868619517,
            "rating_q975": 1166.099499720166,
            "rating_q025": 1128.0246740037371
        },
        "gemma-1.1-7b-it": {
            "rating": 1144.5202577033208,
            "rating_q975": 1166.1358078100989,
            "rating_q025": 1122.9047075965427
        },
        "wizardlm-70b": {
            "rating": 1144.240112867219,
            "rating_q975": 1186.6484596480384,
            "rating_q025": 1101.8317660863995
        },
        "snowflake-arctic-instruct": {
            "rating": 1143.662548244541,
            "rating_q975": 1165.8935488453549,
            "rating_q025": 1121.4315476437273
        },
        "phi-3-small-8k-instruct": {
            "rating": 1140.73019016127,
            "rating_q975": 1164.7245398884902,
            "rating_q025": 1116.7358404340498
        },
        "dbrx-instruct-preview": {
            "rating": 1139.479007635834,
            "rating_q975": 1161.6721057609311,
            "rating_q025": 1117.2859095107367
        },
        "openchat-3.5-0106": {
            "rating": 1134.266709303574,
            "rating_q975": 1166.9699781057623,
            "rating_q025": 1101.5634405013857
        },
        "vicuna-33b": {
            "rating": 1126.8439323356279,
            "rating_q975": 1155.8684000398673,
            "rating_q025": 1097.8194646313884
        },
        "qwen1.5-32b-chat": {
            "rating": 1125.8083453004547,
            "rating_q975": 1147.9517013414845,
            "rating_q025": 1103.664989259425
        },
        "qwen1.5-14b-chat": {
            "rating": 1107.7870482809597,
            "rating_q975": 1132.7601549443232,
            "rating_q025": 1082.8139416175961
        },
        "llama-3.2-3b-instruct": {
            "rating": 1104.4919546163985,
            "rating_q975": 1145.5668661584396,
            "rating_q025": 1063.4170430743575
        },
        "phi-3-mini-4k-instruct-june-2024": {
            "rating": 1103.8634360234819,
            "rating_q975": 1135.1855670055827,
            "rating_q025": 1072.5413050413808
        },
        "starling-lm-7b-beta": {
            "rating": 1103.227215288306,
            "rating_q975": 1133.017936307449,
            "rating_q025": 1073.4364942691634
        },
        "phi-3-mini-4k-instruct": {
            "rating": 1101.9798633955418,
            "rating_q975": 1125.6599034354608,
            "rating_q025": 1078.2998233556227
        },
        "yi-34b-chat": {
            "rating": 1098.568894886783,
            "rating_q975": 1129.7456628817579,
            "rating_q025": 1067.3921268918082
        },
        "llama-2-70b-chat": {
            "rating": 1095.6749650529591,
            "rating_q975": 1117.3424120684112,
            "rating_q025": 1074.0075180375068
        },
        "phi-3-mini-128k-instruct": {
            "rating": 1087.487935767268,
            "rating_q975": 1111.7806458721973,
            "rating_q025": 1063.1952256623385
        },
        "starling-lm-7b-alpha": {
            "rating": 1083.3126208956382,
            "rating_q975": 1123.912960462386,
            "rating_q025": 1042.7122813288906
        },
        "internlm2_5-20b-chat": {
            "rating": 1081.5789031722636,
            "rating_q975": 1119.0888642847503,
            "rating_q025": 1044.0689420597769
        },
        "vicuna-13b": {
            "rating": 1076.3096361599532,
            "rating_q975": 1111.314144579026,
            "rating_q025": 1041.3051277408808
        },
        "palm-2": {
            "rating": 1074.0628837030135,
            "rating_q975": 1131.8568534811338,
            "rating_q025": 1016.2689139248935
        },
        "gemma-7b-it": {
            "rating": 1066.9130764585375,
            "rating_q975": 1109.253871177662,
            "rating_q025": 1024.572281739413
        },
        "llama-2-13b-chat": {
            "rating": 1063.3065095679976,
            "rating_q975": 1092.3077373168508,
            "rating_q025": 1034.3052818191447
        },
        "llama-3.2-1b-instruct": {
            "rating": 1060.60055524105,
            "rating_q975": 1100.6791681290624,
            "rating_q025": 1020.5219423530374
        },
        "zephyr-7b-beta": {
            "rating": 1054.90068112588,
            "rating_q975": 1101.6012210464771,
            "rating_q025": 1008.2001412052828
        },
        "mistral-7b-instruct-v0.2": {
            "rating": 1047.0750907536662,
            "rating_q975": 1073.9842447959472,
            "rating_q025": 1020.1659367113851
        },
        "gemma-1.1-2b-it": {
            "rating": 1043.1361644136457,
            "rating_q975": 1077.1584685967982,
            "rating_q025": 1009.1138602304933
        },
        "llama-2-7b-chat": {
            "rating": 1030.2999146872962,
            "rating_q975": 1064.0830493356002,
            "rating_q025": 996.5167800389922
        },
        "mistral-7b-instruct": {
            "rating": 1018.9385277431866,
            "rating_q975": 1063.4099346878695,
            "rating_q025": 974.4671207985036
        },
        "qwen1.5-4b-chat": {
            "rating": 998.6795289747411,
            "rating_q975": 1036.6474069210165,
            "rating_q025": 960.7116510284657
        }
    },
    "hard_6": {
        "claude-opus-4-1-20250805-thinking-16k": {
            "rating": 1480.9338532549623,
            "rating_q975": 1491.4593611826822,
            "rating_q025": 1470.4083453272422
        },
        "claude-opus-4-1-20250805": {
            "rating": 1466.6089218019006,
            "rating_q975": 1475.7476175003865,
            "rating_q025": 1457.4702261034147
        },
        "gemini-2.5-pro": {
            "rating": 1464.321395493692,
            "rating_q975": 1470.941824473888,
            "rating_q025": 1457.7009665134965
        },
        "gpt-5-high": {
            "rating": 1457.71440812162,
            "rating_q975": 1467.1861722467697,
            "rating_q025": 1448.2426439964702
        },
        "gpt-5-old": {
            "rating": 1455.804078746724,
            "rating_q975": 1490.3476542972048,
            "rating_q025": 1421.260503196243
        },
        "qwen3-235b-a22b-instruct-2507": {
            "rating": 1448.5126522520402,
            "rating_q975": 1456.9351391574169,
            "rating_q025": 1440.0901653466635
        },
        "o3-2025-04-16": {
            "rating": 1446.8752784010803,
            "rating_q975": 1453.106742974945,
            "rating_q025": 1440.6438138272154
        },
        "chatgpt-4o-latest-20250326": {
            "rating": 1446.157271569611,
            "rating_q975": 1452.4623297481874,
            "rating_q025": 1439.8522133910349
        },
        "qwen-max-2025-08-15": {
            "rating": 1445.7130044024073,
            "rating_q975": 1458.3829647307894,
            "rating_q025": 1433.0430440740251
        },
        "gpt-5-chat": {
            "rating": 1444.2052882834491,
            "rating_q975": 1454.5558628913946,
            "rating_q025": 1433.8547136755037
        },
        "claude-opus-4-20250514-thinking-16k": {
            "rating": 1443.9894355604279,
            "rating_q975": 1451.0100639772381,
            "rating_q025": 1436.9688071436176
        },
        "gpt-4.5-preview-2025-02-27": {
            "rating": 1433.9379593642616,
            "rating_q975": 1443.5879960813618,
            "rating_q025": 1424.2879226471614
        },
        "deepseek-v3.1-thinking": {
            "rating": 1432.85493988213,
            "rating_q975": 1446.9162472258624,
            "rating_q025": 1418.793632538398
        },
        "glm-4.5": {
            "rating": 1432.5189205119268,
            "rating_q975": 1441.6004002128777,
            "rating_q025": 1423.437440810976
        },
        "mistral-medium-2508": {
            "rating": 1431.811830165753,
            "rating_q975": 1442.8886134058969,
            "rating_q025": 1420.7350469256094
        },
        "kimi-k2-0711-preview": {
            "rating": 1431.1075207097522,
            "rating_q975": 1438.4187326323627,
            "rating_q025": 1423.7963087871417
        },
        "deepseek-r1-0528": {
            "rating": 1431.0451656691675,
            "rating_q975": 1438.6250056500705,
            "rating_q025": 1423.4653256882643
        },
        "claude-opus-4-20250514": {
            "rating": 1429.4246700155115,
            "rating_q975": 1436.0773732897944,
            "rating_q025": 1422.7719667412287
        },
        "deepseek-v3.1": {
            "rating": 1426.9673366192108,
            "rating_q975": 1440.0784075223955,
            "rating_q025": 1413.8562657160257
        },
        "grok-4-0709": {
            "rating": 1426.6561419035913,
            "rating_q975": 1434.1625007114515,
            "rating_q025": 1419.1497830957312
        },
        "claude-sonnet-4-20250514-thinking-32k": {
            "rating": 1426.492286244593,
            "rating_q975": 1433.5136508619603,
            "rating_q025": 1419.4709216272258
        },
        "gpt-4.1-2025-04-14": {
            "rating": 1425.212757071149,
            "rating_q975": 1431.8567990780766,
            "rating_q025": 1418.5687150642214
        },
        "grok-3-preview-02-24": {
            "rating": 1423.0592340388066,
            "rating_q975": 1429.3587736224636,
            "rating_q025": 1416.7596944551497
        },
        "qwen3-235b-a22b-thinking-2507": {
            "rating": 1416.292507515115,
            "rating_q975": 1426.2523151601847,
            "rating_q025": 1406.3326998700452
        },
        "qwen3-235b-a22b-no-thinking": {
            "rating": 1412.3468920873684,
            "rating_q975": 1419.0127617154915,
            "rating_q025": 1405.6810224592452
        },
        "o1-2024-12-17": {
            "rating": 1411.2204758966955,
            "rating_q975": 1418.5849764752254,
            "rating_q025": 1403.8559753181657
        },
        "deepseek-r1": {
            "rating": 1410.8959970478136,
            "rating_q975": 1419.563816066851,
            "rating_q025": 1402.228178028776
        },
        "qwen3-coder-480b-a35b-instruct": {
            "rating": 1410.4235258017684,
            "rating_q975": 1418.812499376464,
            "rating_q025": 1402.034552227073
        },
        "mai-1-preview": {
            "rating": 1410.1321277868649,
            "rating_q975": 1424.4627099164425,
            "rating_q025": 1395.8015456572873
        },
        "qwen-vl-max-2025-08-13": {
            "rating": 1409.0634374788158,
            "rating_q975": 1432.5943115939883,
            "rating_q025": 1385.5325633636435
        },
        "claude-3-7-sonnet-20250219-thinking-32k": {
            "rating": 1408.9549372867789,
            "rating_q975": 1415.2197079810724,
            "rating_q025": 1402.6901665924852
        },
        "gemini-2.5-flash": {
            "rating": 1408.6991089304513,
            "rating_q975": 1415.1080819280517,
            "rating_q025": 1402.290135932851
        },
        "gpt-5-mini-high": {
            "rating": 1407.7039546883702,
            "rating_q975": 1419.0756790998305,
            "rating_q025": 1396.3322302769097
        },
        "claude-sonnet-4-20250514": {
            "rating": 1405.561531464348,
            "rating_q975": 1412.3190093213989,
            "rating_q025": 1398.8040536072974
        },
        "o4-mini-2025-04-16": {
            "rating": 1404.7038144547555,
            "rating_q975": 1411.2605630449264,
            "rating_q025": 1398.1470658645844
        },
        "qwen3-30b-a3b-instruct-2507": {
            "rating": 1403.9673841715107,
            "rating_q975": 1413.7962923915713,
            "rating_q025": 1394.1384759514501
        },
        "deepseek-v3-0324": {
            "rating": 1400.678324392598,
            "rating_q975": 1407.0393432624037,
            "rating_q025": 1394.3173055227924
        },
        "hunyuan-t1-20250711": {
            "rating": 1396.259421742677,
            "rating_q975": 1408.3377478878244,
            "rating_q025": 1384.1810955975293
        },
        "o3-mini-high": {
            "rating": 1395.830425451738,
            "rating_q975": 1404.5952674250946,
            "rating_q025": 1387.0655834783815
        },
        "mistral-medium-2505": {
            "rating": 1395.7520618070077,
            "rating_q975": 1402.1346990829377,
            "rating_q025": 1389.3694245310776
        },
        "glm-4.5-air": {
            "rating": 1395.094263581112,
            "rating_q975": 1404.3482865529584,
            "rating_q025": 1385.8402406092657
        },
        "gpt-4.1-mini-2025-04-14": {
            "rating": 1393.7416712801626,
            "rating_q975": 1400.3276760515255,
            "rating_q025": 1387.1556665087996
        },
        "o1-preview": {
            "rating": 1392.517435481314,
            "rating_q975": 1399.674313892386,
            "rating_q025": 1385.360557070242
        },
        "claude-3-5-sonnet-20241022": {
            "rating": 1390.6112315964479,
            "rating_q975": 1394.9259776088588,
            "rating_q025": 1386.2964855840369
        },
        "qwen3-235b-a22b": {
            "rating": 1388.5960921038532,
            "rating_q975": 1395.3870265598416,
            "rating_q025": 1381.805157647865
        },
        "claude-3-7-sonnet-20250219": {
            "rating": 1387.4232499379307,
            "rating_q975": 1393.2933592871389,
            "rating_q025": 1381.5531405887227
        },
        "hunyuan-turbos-20250416": {
            "rating": 1386.8244195467364,
            "rating_q975": 1396.0725294299975,
            "rating_q025": 1377.5763096634753
        },
        "step-3": {
            "rating": 1382.384335574105,
            "rating_q975": 1398.4845545832522,
            "rating_q025": 1366.284116564958
        },
        "qwen2.5-max": {
            "rating": 1379.8153054234035,
            "rating_q975": 1385.9313007512467,
            "rating_q025": 1373.6993100955606
        },
        "minimax-m1": {
            "rating": 1379.2845686470707,
            "rating_q975": 1386.2776667891164,
            "rating_q025": 1372.291470505025
        },
        "grok-3-mini-high": {
            "rating": 1370.427718293124,
            "rating_q975": 1378.2689954960658,
            "rating_q025": 1362.586441090182
        },
        "o3-mini": {
            "rating": 1368.6733910824062,
            "rating_q975": 1374.0958540810796,
            "rating_q025": 1363.250928083733
        },
        "llama-3.1-nemotron-ultra-253b-v1": {
            "rating": 1366.0597419628211,
            "rating_q975": 1386.915747680605,
            "rating_q025": 1345.2037362450374
        },
        "grok-3-mini-beta": {
            "rating": 1365.218328736274,
            "rating_q975": 1372.37484943694,
            "rating_q025": 1358.0618080356082
        },
        "mistral-small-2506": {
            "rating": 1364.3561825528716,
            "rating_q975": 1372.1583526361605,
            "rating_q025": 1356.5540124695829
        },
        "gpt-5-nano-high": {
            "rating": 1364.2157638097788,
            "rating_q975": 1377.272081524346,
            "rating_q025": 1351.1594460952113
        },
        "hunyuan-turbos-20250226": {
            "rating": 1362.9533358173542,
            "rating_q975": 1384.1427149616782,
            "rating_q025": 1341.7639566730304
        },
        "qwen3-32b": {
            "rating": 1362.2466925014796,
            "rating_q975": 1378.184819538348,
            "rating_q025": 1346.3085654646115
        },
        "gemini-2.0-flash-001": {
            "rating": 1361.5568108963191,
            "rating_q975": 1367.322201985145,
            "rating_q025": 1355.7914198074932
        },
        "nvidia-llama-3.3-nemotron-super-49b-v1.5": {
            "rating": 1361.2542345708387,
            "rating_q975": 1375.0953752975975,
            "rating_q025": 1347.4130938440799
        },
        "gemma-3-27b-it": {
            "rating": 1360.353967107233,
            "rating_q975": 1366.6215206619686,
            "rating_q025": 1354.0864135524978
        },
        "gpt-oss-120b": {
            "rating": 1357.726121006592,
            "rating_q975": 1368.186134138825,
            "rating_q025": 1347.2661078743588
        },
        "o1-mini": {
            "rating": 1357.5238952167938,
            "rating_q975": 1363.1258514707006,
            "rating_q025": 1351.921938962887
        },
        "qwq-32b": {
            "rating": 1356.5561813386767,
            "rating_q975": 1363.5504103385288,
            "rating_q025": 1349.5619523388248
        },
        "command-a-03-2025": {
            "rating": 1356.445641605244,
            "rating_q975": 1362.5580931589618,
            "rating_q025": 1350.3331900515261
        },
        "claude-3-5-sonnet-20240620": {
            "rating": 1354.451187849486,
            "rating_q975": 1359.645314861612,
            "rating_q025": 1349.2570608373599
        },
        "glm-4.5v": {
            "rating": 1353.4835658228874,
            "rating_q975": 1379.222859815239,
            "rating_q025": 1327.744271830536
        },
        "llama-3.3-nemotron-49b-super-v1": {
            "rating": 1352.9096298868433,
            "rating_q975": 1376.03493812089,
            "rating_q025": 1329.7843216527965
        },
        "qwen-plus-0125": {
            "rating": 1349.0411867605476,
            "rating_q975": 1362.9945231123838,
            "rating_q025": 1335.0878504087113
        },
        "gemini-1.5-pro-002": {
            "rating": 1346.7617536284995,
            "rating_q975": 1351.939069346301,
            "rating_q025": 1341.5844379106982
        },
        "gemini-2.0-flash-lite-preview-02-05": {
            "rating": 1346.6122671684225,
            "rating_q975": 1353.8163766134503,
            "rating_q025": 1339.4081577233949
        },
        "deepseek-v3": {
            "rating": 1345.4612523376743,
            "rating_q975": 1353.2589681546067,
            "rating_q025": 1337.663536520742
        },
        "hunyuan-turbo-0110": {
            "rating": 1345.3824342984062,
            "rating_q975": 1367.1668888125394,
            "rating_q025": 1323.5979797842733
        },
        "qwen3-30b-a3b": {
            "rating": 1342.425161839368,
            "rating_q975": 1349.312556934987,
            "rating_q025": 1335.5377667437488
        },
        "gpt-oss-20b": {
            "rating": 1338.7655393213256,
            "rating_q975": 1349.5366108638452,
            "rating_q025": 1327.9944677788062
        },
        "llama-3.1-405b-instruct-bf16": {
            "rating": 1336.3885318123926,
            "rating_q975": 1342.0188515939926,
            "rating_q025": 1330.7582120307927
        },
        "claude-3-5-haiku-20241022": {
            "rating": 1336.1131811798048,
            "rating_q975": 1341.0845075741418,
            "rating_q025": 1331.1418547854678
        },
        "yi-lightning": {
            "rating": 1335.2771401538607,
            "rating_q975": 1342.6318772932598,
            "rating_q025": 1327.9224030144615
        },
        "amazon-nova-experimental-chat-05-14": {
            "rating": 1334.4533844017055,
            "rating_q975": 1341.8898653352085,
            "rating_q025": 1327.0169034682026
        },
        "gpt-4o-2024-05-13": {
            "rating": 1333.0623766283386,
            "rating_q975": 1337.9698395258474,
            "rating_q025": 1328.15491373083
        },
        "step-2-16k-exp-202412": {
            "rating": 1332.1803615158474,
            "rating_q975": 1346.8239008237024,
            "rating_q025": 1317.5368222079921
        },
        "llama-3.1-405b-instruct-fp8": {
            "rating": 1332.145086774403,
            "rating_q975": 1337.5553333626908,
            "rating_q025": 1326.7348401861148
        },
        "llama-4-maverick-17b-128e-instruct": {
            "rating": 1331.4408924550357,
            "rating_q975": 1338.109811477195,
            "rating_q025": 1324.7719734328764
        },
        "step-1o-turbo-202506": {
            "rating": 1331.43364429613,
            "rating_q975": 1340.953150065319,
            "rating_q025": 1321.914138526941
        },
        "gemma-3-12b-it": {
            "rating": 1329.9109509910013,
            "rating_q975": 1347.6033641379393,
            "rating_q025": 1312.2185378440636
        },
        "athene-v2-chat": {
            "rating": 1329.570393690768,
            "rating_q975": 1336.511379512555,
            "rating_q025": 1322.629407868981
        },
        "gpt-4.1-nano-2025-04-14": {
            "rating": 1326.862154988396,
            "rating_q975": 1340.3661601295148,
            "rating_q025": 1313.358149847277
        },
        "hunyuan-large-2025-02-10": {
            "rating": 1325.3525953459068,
            "rating_q975": 1344.0001274535848,
            "rating_q025": 1306.7050632382288
        },
        "deepseek-v2.5-1210": {
            "rating": 1324.9723382866666,
            "rating_q975": 1337.469614850089,
            "rating_q025": 1312.4750617232442
        },
        "claude-3-opus-20240229": {
            "rating": 1324.0441612268578,
            "rating_q975": 1328.4628619270277,
            "rating_q025": 1319.6254605266877
        },
        "qwen2.5-plus-1127": {
            "rating": 1323.1001226046335,
            "rating_q975": 1333.2794894320732,
            "rating_q025": 1312.920755777194
        },
        "magistral-medium-2506": {
            "rating": 1322.2205745553954,
            "rating_q975": 1331.4649831805461,
            "rating_q025": 1312.9761659302446
        },
        "gemini-1.5-pro-001": {
            "rating": 1321.947472558638,
            "rating_q975": 1327.7590867862134,
            "rating_q025": 1316.1358583310628
        },
        "grok-2-2024-08-13": {
            "rating": 1321.7375461623092,
            "rating_q975": 1326.8563380852452,
            "rating_q025": 1316.6187542393732
        },
        "gpt-4o-2024-08-06": {
            "rating": 1321.5934637463797,
            "rating_q975": 1327.5299765929879,
            "rating_q025": 1315.6569508997713
        },
        "glm-4-plus-0111": {
            "rating": 1321.5802219703069,
            "rating_q975": 1335.4668276454343,
            "rating_q025": 1307.6936162951793
        },
        "gemini-advanced-0514": {
            "rating": 1320.3962585161776,
            "rating_q975": 1327.3380513985167,
            "rating_q025": 1313.454465633838
        },
        "llama-4-scout-17b-16e-instruct": {
            "rating": 1320.2005209935733,
            "rating_q975": 1327.5478928478954,
            "rating_q025": 1312.853149139251
        },
        "deepseek-v2.5": {
            "rating": 1318.2172113718598,
            "rating_q975": 1325.1681967106813,
            "rating_q025": 1311.2662260330383
        },
        "llama-3.3-70b-instruct": {
            "rating": 1317.3680158080197,
            "rating_q975": 1322.421474587816,
            "rating_q025": 1312.3145570282236
        },
        "mistral-large-2407": {
            "rating": 1316.4572968955024,
            "rating_q975": 1322.262870540436,
            "rating_q025": 1310.6517232505687
        },
        "qwen-max-0919": {
            "rating": 1315.3325649103554,
            "rating_q975": 1323.9179429599203,
            "rating_q025": 1306.7471868607909
        },
        "glm-4-plus": {
            "rating": 1314.9058148798422,
            "rating_q975": 1322.0466430970403,
            "rating_q025": 1307.7649866626446
        },
        "qwen2.5-72b-instruct": {
            "rating": 1314.4051889004063,
            "rating_q975": 1320.3076685454837,
            "rating_q025": 1308.502709255329
        },
        "gemma-3n-e4b-it": {
            "rating": 1313.0150740416627,
            "rating_q975": 1320.871392727409,
            "rating_q025": 1305.1587553559161
        },
        "mistral-small-3.1-24b-instruct-2503": {
            "rating": 1312.8338348788843,
            "rating_q975": 1320.2414522513143,
            "rating_q025": 1305.426217506454
        },
        "gpt-4-turbo-2024-04-09": {
            "rating": 1312.8044189731245,
            "rating_q975": 1318.2706841074453,
            "rating_q025": 1307.3381538388035
        },
        "gpt-4-1106-preview": {
            "rating": 1309.7577685283904,
            "rating_q975": 1315.3839738011882,
            "rating_q025": 1304.131563255593
        },
        "mistral-large-2411": {
            "rating": 1309.348531684835,
            "rating_q975": 1315.9995370224071,
            "rating_q025": 1302.6975263472627
        },
        "athene-70b-0725": {
            "rating": 1308.6826548418092,
            "rating_q975": 1316.934696812001,
            "rating_q025": 1300.4306128716173
        },
        "gpt-4o-mini-2024-07-18": {
            "rating": 1307.9581561239206,
            "rating_q975": 1312.8520700816116,
            "rating_q025": 1303.0642421662296
        },
        "llama-3.1-nemotron-70b-instruct": {
            "rating": 1307.6375422750036,
            "rating_q975": 1319.4825798704692,
            "rating_q025": 1295.792504679538
        },
        "hunyuan-standard-2025-02-10": {
            "rating": 1306.4170162395308,
            "rating_q975": 1325.0104906198999,
            "rating_q025": 1287.8235418591614
        },
        "gpt-4-0125-preview": {
            "rating": 1303.7272623934623,
            "rating_q975": 1309.4580736769396,
            "rating_q025": 1297.9964511099847
        },
        "gemini-1.5-flash-002": {
            "rating": 1302.4162040312094,
            "rating_q975": 1308.654427230052,
            "rating_q025": 1296.1779808323665
        },
        "qwen2.5-coder-32b-instruct": {
            "rating": 1300.8854552611083,
            "rating_q975": 1314.378911087588,
            "rating_q025": 1287.3919994346286
        },
        "grok-2-mini-2024-08-13": {
            "rating": 1300.6702322482763,
            "rating_q975": 1306.101097801455,
            "rating_q025": 1295.2393666950977
        },
        "hunyuan-large-vision": {
            "rating": 1300.3459916922475,
            "rating_q975": 1312.9226622034482,
            "rating_q025": 1287.769321181047
        },
        "gpt-4-0314": {
            "rating": 1300.1412358201082,
            "rating_q975": 1307.662296678968,
            "rating_q025": 1292.6201749612485
        },
        "amazon-nova-pro-v1.0": {
            "rating": 1298.441841284499,
            "rating_q975": 1305.3348389316463,
            "rating_q025": 1291.5488436373519
        },
        "llama-3.1-70b-instruct": {
            "rating": 1295.8401973293626,
            "rating_q975": 1301.2121342857774,
            "rating_q025": 1290.4682603729475
        },
        "gemini-1.5-flash-001": {
            "rating": 1284.6795898028013,
            "rating_q975": 1290.572322280773,
            "rating_q025": 1278.786857324829
        },
        "deepseek-coder-v2": {
            "rating": 1284.6306623763785,
            "rating_q975": 1294.0393919335297,
            "rating_q025": 1275.2219328192273
        },
        "gpt-4-0613": {
            "rating": 1282.6847130302085,
            "rating_q975": 1288.8950867861145,
            "rating_q025": 1276.4743392743023
        },
        "gemma-3-4b-it": {
            "rating": 1281.4218995005103,
            "rating_q975": 1298.5102046529075,
            "rating_q025": 1264.3335943481134
        },
        "jamba-1.5-large": {
            "rating": 1280.7328450190994,
            "rating_q975": 1291.9897659455653,
            "rating_q025": 1269.4759240926335
        },
        "mistral-small-24b-instruct-2501": {
            "rating": 1280.532320836217,
            "rating_q975": 1289.8971938193613,
            "rating_q025": 1271.1674478530724
        },
        "claude-3-sonnet-20240229": {
            "rating": 1278.8852353783498,
            "rating_q975": 1284.5195092134975,
            "rating_q025": 1273.250961543202
        },
        "llama-3.1-nemotron-51b-instruct": {
            "rating": 1277.9792104733315,
            "rating_q975": 1294.5615959067234,
            "rating_q025": 1261.39682503994
        },
        "gemma-2-27b-it": {
            "rating": 1277.6820480722981,
            "rating_q975": 1282.4928721104468,
            "rating_q025": 1272.8712240341497
        },
        "reka-core-20240904": {
            "rating": 1277.6354794780573,
            "rating_q975": 1288.4176902560591,
            "rating_q025": 1266.8532687000559
        },
        "nemotron-4-340b-instruct": {
            "rating": 1277.6156113380302,
            "rating_q975": 1286.221871438049,
            "rating_q025": 1269.0093512380117
        },
        "glm-4-0520": {
            "rating": 1276.0478433264539,
            "rating_q975": 1286.8059460175198,
            "rating_q025": 1265.2897406353877
        },
        "llama-3-70b-instruct": {
            "rating": 1275.786845316355,
            "rating_q975": 1281.040678268482,
            "rating_q025": 1270.533012364228
        },
        "phi-4": {
            "rating": 1275.7117422460624,
            "rating_q975": 1283.18982370275,
            "rating_q025": 1268.2336607893747
        },
        "llama-3.1-tulu-3-70b": {
            "rating": 1273.666310136579,
            "rating_q975": 1291.5551293258607,
            "rating_q025": 1255.7774909472973
        },
        "amazon-nova-lite-v1.0": {
            "rating": 1270.5616067683654,
            "rating_q975": 1278.4448265032172,
            "rating_q025": 1262.6783870335137
        },
        "c4ai-aya-expanse-32b": {
            "rating": 1269.1218955619208,
            "rating_q975": 1276.1668013307376,
            "rating_q025": 1262.0769897931038
        },
        "hunyuan-standard-256k": {
            "rating": 1269.0855241265622,
            "rating_q975": 1288.5836751788931,
            "rating_q025": 1249.587373074231
        },
        "gemma-2-9b-it-simpo": {
            "rating": 1269.0144793424147,
            "rating_q975": 1280.1058183583434,
            "rating_q025": 1257.9231403264862
        },
        "qwen2-72b-instruct": {
            "rating": 1268.9403532668202,
            "rating_q975": 1275.9011089396572,
            "rating_q025": 1261.979597593983
        },
        "reka-flash-20240904": {
            "rating": 1265.5485504644166,
            "rating_q975": 1276.1384800029805,
            "rating_q025": 1254.9586209258525
        },
        "claude-3-haiku-20240307": {
            "rating": 1262.079890633994,
            "rating_q975": 1267.392958966125,
            "rating_q025": 1256.7668223018627
        },
        "olmo-2-0325-32b-instruct": {
            "rating": 1259.6245088273845,
            "rating_q975": 1279.017746067358,
            "rating_q025": 1240.2312715874111
        },
        "gemini-1.5-flash-8b-001": {
            "rating": 1259.5113792849736,
            "rating_q975": 1265.7266842621777,
            "rating_q025": 1253.2960743077695
        },
        "command-r-plus-08-2024": {
            "rating": 1258.736992658291,
            "rating_q975": 1268.757686047695,
            "rating_q025": 1248.7162992688868
        },
        "mistral-large-2402": {
            "rating": 1257.7315804251857,
            "rating_q975": 1264.3936986753467,
            "rating_q025": 1251.0694621750245
        },
        "gemma-2-9b-it": {
            "rating": 1254.5699670268082,
            "rating_q975": 1260.0534729101705,
            "rating_q025": 1249.0864611434456
        },
        "command-r-08-2024": {
            "rating": 1254.1451752225823,
            "rating_q975": 1263.9057792063065,
            "rating_q025": 1244.3845712388581
        },
        "ministral-8b-2410": {
            "rating": 1253.4807213626082,
            "rating_q975": 1267.5422379103034,
            "rating_q025": 1239.419204814913
        },
        "command-r-plus": {
            "rating": 1248.9243133574041,
            "rating_q975": 1254.9961357060245,
            "rating_q025": 1242.8524910087838
        },
        "amazon-nova-micro-v1.0": {
            "rating": 1244.765827730108,
            "rating_q975": 1252.553532918319,
            "rating_q025": 1236.9781225418967
        },
        "qwen1.5-110b-chat": {
            "rating": 1243.7986175046185,
            "rating_q975": 1252.232952102445,
            "rating_q025": 1235.364282906792
        },
        "mixtral-8x22b-instruct-v0.1": {
            "rating": 1239.4755604854668,
            "rating_q975": 1246.1284181017593,
            "rating_q025": 1232.8227028691745
        },
        "qwen1.5-72b-chat": {
            "rating": 1235.3644718648766,
            "rating_q975": 1242.9430025089393,
            "rating_q025": 1227.7859412208136
        },
        "jamba-1.5-mini": {
            "rating": 1233.6742405615014,
            "rating_q975": 1245.229275198446,
            "rating_q025": 1222.1192059245568
        },
        "mistral-medium": {
            "rating": 1232.9131902164447,
            "rating_q975": 1241.3559296303742,
            "rating_q025": 1224.4704508025152
        },
        "reka-flash-21b-20240226-online": {
            "rating": 1232.7092843514833,
            "rating_q975": 1243.1899616039611,
            "rating_q025": 1222.2286070990056
        },
        "reka-flash-21b-20240226": {
            "rating": 1230.2898879692873,
            "rating_q975": 1238.8771260233098,
            "rating_q025": 1221.7026499152648
        },
        "c4ai-aya-expanse-8b": {
            "rating": 1229.9752649811462,
            "rating_q975": 1240.7186238891402,
            "rating_q025": 1219.231906073152
        },
        "internlm2_5-20b-chat": {
            "rating": 1229.3508045770473,
            "rating_q975": 1239.8621381476169,
            "rating_q025": 1218.8394710064777
        },
        "granite-3.1-8b-instruct": {
            "rating": 1226.567463613179,
            "rating_q975": 1245.7181996819954,
            "rating_q025": 1207.4167275443624
        },
        "gemini-pro-dev-api": {
            "rating": 1225.4488057280957,
            "rating_q975": 1236.5492553298634,
            "rating_q025": 1214.348356126328
        },
        "llama-3.1-tulu-3-8b": {
            "rating": 1224.931580475955,
            "rating_q975": 1243.9826548813949,
            "rating_q025": 1205.880506070515
        },
        "yi-1.5-34b-chat": {
            "rating": 1223.8991912152476,
            "rating_q975": 1231.9066762520756,
            "rating_q025": 1215.8917061784193
        },
        "gpt-3.5-turbo-0125": {
            "rating": 1223.6245083263254,
            "rating_q975": 1230.0137980396598,
            "rating_q025": 1217.235218612991
        },
        "llama-3.1-8b-instruct": {
            "rating": 1223.5720394738476,
            "rating_q975": 1229.2357016167196,
            "rating_q025": 1217.9083773309756
        },
        "gpt-3.5-turbo-1106": {
            "rating": 1222.0325383964341,
            "rating_q975": 1234.607465778798,
            "rating_q025": 1209.45761101407
        },
        "gemini-pro": {
            "rating": 1221.7219548359737,
            "rating_q975": 1239.7213194177539,
            "rating_q025": 1203.7225902541934
        },
        "granite-3.1-2b-instruct": {
            "rating": 1219.0619355078582,
            "rating_q975": 1237.390899888078,
            "rating_q025": 1200.7329711276384
        },
        "qwen1.5-32b-chat": {
            "rating": 1218.6066922955483,
            "rating_q975": 1227.6094104214656,
            "rating_q025": 1209.603974169631
        },
        "llama-3-8b-instruct": {
            "rating": 1217.2497177100504,
            "rating_q975": 1223.036001525213,
            "rating_q025": 1211.4634338948879
        },
        "zephyr-orpo-141b-A35b-v0.1": {
            "rating": 1213.5648959476225,
            "rating_q975": 1230.1614565477396,
            "rating_q025": 1196.9683353475054
        },
        "dbrx-instruct-preview": {
            "rating": 1213.5052497622257,
            "rating_q975": 1222.262664703164,
            "rating_q025": 1204.7478348212874
        },
        "command-r": {
            "rating": 1211.9704285181142,
            "rating_q975": 1218.84630784016,
            "rating_q025": 1205.0945491960683
        },
        "phi-3-medium-4k-instruct": {
            "rating": 1210.1687135702464,
            "rating_q975": 1217.9425081484778,
            "rating_q025": 1202.394918992015
        },
        "mixtral-8x7b-instruct-v0.1": {
            "rating": 1208.488843594257,
            "rating_q975": 1214.9181644360945,
            "rating_q025": 1202.0595227524198
        },
        "granite-3.0-8b-instruct": {
            "rating": 1207.5842255240284,
            "rating_q975": 1221.1386400290328,
            "rating_q025": 1194.029811019024
        },
        "qwen1.5-14b-chat": {
            "rating": 1198.5527553881602,
            "rating_q975": 1208.9881222470501,
            "rating_q025": 1188.1173885292703
        },
        "starling-lm-7b-beta": {
            "rating": 1194.3158259872764,
            "rating_q975": 1204.8069162089312,
            "rating_q025": 1183.8247357656214
        },
        "gemma-1.1-7b-it": {
            "rating": 1187.3453506912304,
            "rating_q975": 1195.616961394252,
            "rating_q025": 1179.0737399882084
        },
        "phi-3-small-8k-instruct": {
            "rating": 1187.3067870911018,
            "rating_q975": 1196.488369513745,
            "rating_q025": 1178.1252046684585
        },
        "gemma-2-2b-it": {
            "rating": 1186.8735810580586,
            "rating_q975": 1192.872242032636,
            "rating_q025": 1180.8749200834814
        },
        "tulu-2-dpo-70b": {
            "rating": 1184.651490936662,
            "rating_q975": 1200.8925704220742,
            "rating_q025": 1168.4104114512495
        },
        "openchat-3.5-0106": {
            "rating": 1183.9539423631868,
            "rating_q975": 1194.936805523158,
            "rating_q025": 1172.9710792032156
        },
        "snowflake-arctic-instruct": {
            "rating": 1183.7488425846277,
            "rating_q975": 1192.5786650268278,
            "rating_q025": 1174.9190201424276
        },
        "yi-34b-chat": {
            "rating": 1182.7222507339443,
            "rating_q975": 1193.041143323127,
            "rating_q025": 1172.4033581447616
        },
        "granite-3.0-2b-instruct": {
            "rating": 1182.530657072681,
            "rating_q975": 1196.056779346819,
            "rating_q025": 1169.004534798543
        },
        "qwq-32b-preview": {
            "rating": 1181.0182453263117,
            "rating_q975": 1199.017886092735,
            "rating_q025": 1163.0186045598884
        },
        "openhermes-2.5-mistral-7b": {
            "rating": 1176.81093859736,
            "rating_q975": 1193.5780410882046,
            "rating_q025": 1160.0438361065155
        },
        "phi-3-mini-4k-instruct-june-2024": {
            "rating": 1174.9685768124912,
            "rating_q975": 1185.4110144127962,
            "rating_q025": 1164.5261392121859
        },
        "deepseek-llm-67b-chat": {
            "rating": 1171.440089313682,
            "rating_q975": 1189.8221119337377,
            "rating_q025": 1153.0580666936264
        },
        "openchat-3.5": {
            "rating": 1171.2783147132077,
            "rating_q975": 1186.8554430644033,
            "rating_q025": 1155.7011863620119
        },
        "wizardlm-70b": {
            "rating": 1169.7848736077963,
            "rating_q975": 1184.9142430923837,
            "rating_q025": 1154.6555041232089
        },
        "llama-3.2-3b-instruct": {
            "rating": 1169.1272564523083,
            "rating_q975": 1181.106217902483,
            "rating_q025": 1157.1482950021336
        },
        "starling-lm-7b-alpha": {
            "rating": 1166.4104853291358,
            "rating_q975": 1178.8817044935238,
            "rating_q025": 1153.9392661647478
        },
        "smollm2-1.7b-instruct": {
            "rating": 1165.0597711063433,
            "rating_q975": 1187.2296056363227,
            "rating_q025": 1142.8899365763639
        },
        "vicuna-33b": {
            "rating": 1162.3992192002,
            "rating_q975": 1172.230550189187,
            "rating_q025": 1152.567888211213
        },
        "llama-2-70b-chat": {
            "rating": 1159.122235713044,
            "rating_q975": 1167.0660397865827,
            "rating_q025": 1151.1784316395053
        },
        "mistral-7b-instruct-v0.2": {
            "rating": 1156.1680023969518,
            "rating_q975": 1165.5392166172032,
            "rating_q025": 1146.7967881767004
        },
        "solar-10.7b-instruct-v1.0": {
            "rating": 1153.6524084898524,
            "rating_q975": 1173.3237672418152,
            "rating_q025": 1133.9810497378899
        },
        "mpt-30b-chat": {
            "rating": 1152.90783358196,
            "rating_q975": 1179.7617851573314,
            "rating_q025": 1126.0538820065885
        },
        "codellama-70b-instruct": {
            "rating": 1152.8693843907022,
            "rating_q975": 1183.8195252544037,
            "rating_q025": 1121.9192435270004
        },
        "dolphin-2.2.1-mistral-7b": {
            "rating": 1152.1766577936896,
            "rating_q975": 1180.0626270949438,
            "rating_q025": 1124.2906884924355
        },
        "phi-3-mini-4k-instruct": {
            "rating": 1151.628633448862,
            "rating_q975": 1160.8607907633425,
            "rating_q025": 1142.3964761343818
        },
        "qwen1.5-7b-chat": {
            "rating": 1149.6623339030862,
            "rating_q975": 1165.0310720378845,
            "rating_q025": 1134.293595768288
        },
        "gemma-7b-it": {
            "rating": 1148.7867191040125,
            "rating_q975": 1162.0728652414389,
            "rating_q025": 1135.500572966586
        },
        "llama2-70b-steerlm-chat": {
            "rating": 1143.0823237474451,
            "rating_q975": 1163.4459262836363,
            "rating_q025": 1122.718721211254
        },
        "llama-2-13b-chat": {
            "rating": 1138.534650316079,
            "rating_q975": 1148.5348391247276,
            "rating_q025": 1128.5344615074307
        },
        "palm-2": {
            "rating": 1137.90380384141,
            "rating_q975": 1153.3573428452273,
            "rating_q025": 1122.4502648375928
        },
        "qwen-14b-chat": {
            "rating": 1137.3765203613002,
            "rating_q975": 1156.240290200426,
            "rating_q025": 1118.5127505221747
        },
        "gemma-1.1-2b-it": {
            "rating": 1133.557234820113,
            "rating_q975": 1144.9837242514195,
            "rating_q025": 1122.1307453888066
        },
        "nous-hermes-2-mixtral-8x7b-dpo": {
            "rating": 1130.6677209523457,
            "rating_q975": 1148.2386242003151,
            "rating_q025": 1113.096817704376
        },
        "phi-3-mini-128k-instruct": {
            "rating": 1129.4008103095603,
            "rating_q975": 1139.9532377637133,
            "rating_q025": 1118.8483828554072
        },
        "codellama-34b-instruct": {
            "rating": 1129.0950178206494,
            "rating_q975": 1143.707749322268,
            "rating_q025": 1114.482286319031
        },
        "vicuna-13b": {
            "rating": 1127.5964392535197,
            "rating_q975": 1138.1158810722065,
            "rating_q025": 1117.076997434833
        },
        "zephyr-7b-alpha": {
            "rating": 1120.9851443444059,
            "rating_q975": 1150.8703831708156,
            "rating_q025": 1091.099905517996
        },
        "llama-3.2-1b-instruct": {
            "rating": 1120.8055125082299,
            "rating_q975": 1132.896011484127,
            "rating_q025": 1108.7150135323327
        },
        "falcon-180b-chat": {
            "rating": 1118.9202756912373,
            "rating_q975": 1154.6945289689013,
            "rating_q025": 1083.146022413573
        },
        "zephyr-7b-beta": {
            "rating": 1115.1760755357063,
            "rating_q975": 1129.4113711971095,
            "rating_q025": 1100.9407798743032
        },
        "wizardlm-13b": {
            "rating": 1111.8434338930902,
            "rating_q975": 1128.2753841163433,
            "rating_q025": 1095.4114836698368
        },
        "mistral-7b-instruct": {
            "rating": 1110.5998925008857,
            "rating_q975": 1125.7816256069336,
            "rating_q025": 1095.4181593948379
        },
        "gemma-2b-it": {
            "rating": 1106.5874195159645,
            "rating_q975": 1123.8355674947634,
            "rating_q025": 1089.3392715371658
        },
        "stripedhyena-nous-7b": {
            "rating": 1103.7785861354735,
            "rating_q975": 1120.6122212335674,
            "rating_q025": 1086.9449510373797
        },
        "guanaco-33b": {
            "rating": 1101.6524993540875,
            "rating_q975": 1127.1884670228858,
            "rating_q025": 1076.1165316852891
        },
        "vicuna-7b": {
            "rating": 1100.8111768263561,
            "rating_q975": 1117.738812309964,
            "rating_q025": 1083.8835413427482
        },
        "llama-2-7b-chat": {
            "rating": 1096.162056923532,
            "rating_q975": 1106.8078343907055,
            "rating_q025": 1085.516279456358
        },
        "qwen1.5-4b-chat": {
            "rating": 1090.2499273685107,
            "rating_q975": 1104.2203201998714,
            "rating_q025": 1076.2795345371503
        },
        "olmo-7b-instruct": {
            "rating": 1069.8863919057712,
            "rating_q975": 1086.5249853741766,
            "rating_q025": 1053.2477984373663
        },
        "gpt4all-13b-snoozy": {
            "rating": 1057.4961490611406,
            "rating_q975": 1088.0184867195928,
            "rating_q025": 1026.9738114026884
        },
        "chatglm3-6b": {
            "rating": 1055.4811122983976,
            "rating_q975": 1075.2092146703112,
            "rating_q025": 1035.753009926484
        },
        "koala-13b": {
            "rating": 1028.9879516631613,
            "rating_q975": 1047.4977277704786,
            "rating_q025": 1010.4781755558437
        },
        "mpt-7b-chat": {
            "rating": 1025.7716397458603,
            "rating_q975": 1047.9687857889285,
            "rating_q025": 1003.5744937027919
        },
        "chatglm2-6b": {
            "rating": 1023.8442795137245,
            "rating_q975": 1050.650409096503,
            "rating_q025": 997.038149930946
        },
        "oasst-pythia-12b": {
            "rating": 1013.3559450647095,
            "rating_q975": 1032.5057203041194,
            "rating_q025": 994.2061698252995
        },
        "RWKV-4-Raven-14B": {
            "rating": 1010.685687031601,
            "rating_q975": 1031.5853263292106,
            "rating_q025": 989.7860477339914
        },
        "chatglm-6b": {
            "rating": 996.4036009507186,
            "rating_q975": 1018.2577187150875,
            "rating_q025": 974.5494831863494
        },
        "alpaca-13b": {
            "rating": 994.9419900738221,
            "rating_q975": 1014.9636178061342,
            "rating_q025": 974.9203623415102
        },
        "dolly-v2-12b": {
            "rating": 960.4499427958519,
            "rating_q975": 985.1933962037235,
            "rating_q025": 935.7064893879801
        },
        "stablelm-tuned-alpha-7b": {
            "rating": 937.7653706032168,
            "rating_q975": 962.5268188667714,
            "rating_q025": 913.0039223396623
        },
        "fastchat-t5-3b": {
            "rating": 931.7020742766445,
            "rating_q975": 953.4149829191781,
            "rating_q025": 909.989165634111
        },
        "llama-13b": {
            "rating": 902.8886662095522,
            "rating_q975": 934.0295209402286,
            "rating_q025": 871.7478114788757
        }
    },
    "hard_english_6": {
        "claude-opus-4-1-20250805-thinking-16k": {
            "rating": 1498.1018116682935,
            "rating_q975": 1512.8254673616036,
            "rating_q025": 1483.3781559749834
        },
        "claude-opus-4-1-20250805": {
            "rating": 1473.4806946904794,
            "rating_q975": 1485.6931211947526,
            "rating_q025": 1461.2682681862061
        },
        "gpt-5-high": {
            "rating": 1470.9782331106544,
            "rating_q975": 1483.2222659844124,
            "rating_q025": 1458.7342002368962
        },
        "gemini-2.5-pro": {
            "rating": 1464.6762633040944,
            "rating_q975": 1472.7584191933875,
            "rating_q025": 1456.5941074148013
        },
        "claude-opus-4-20250514-thinking-16k": {
            "rating": 1454.2445450836283,
            "rating_q975": 1463.143731260976,
            "rating_q025": 1445.3453589062806
        },
        "o3-2025-04-16": {
            "rating": 1450.4618506251388,
            "rating_q975": 1457.9587589799874,
            "rating_q025": 1442.96494227029
        },
        "chatgpt-4o-latest-20250326": {
            "rating": 1448.8419581976143,
            "rating_q975": 1456.5203611850663,
            "rating_q025": 1441.1635552101623
        },
        "qwen3-235b-a22b-instruct-2507": {
            "rating": 1448.0263566036783,
            "rating_q975": 1459.5794334597667,
            "rating_q025": 1436.47327974759
        },
        "claude-sonnet-4-20250514-thinking-32k": {
            "rating": 1442.0254209490324,
            "rating_q975": 1450.9862590037244,
            "rating_q025": 1433.0645828943402
        },
        "qwen-max-2025-08-15": {
            "rating": 1441.6751397213543,
            "rating_q975": 1459.0718819815493,
            "rating_q025": 1424.278397461159
        },
        "gpt-5-chat": {
            "rating": 1439.736934050437,
            "rating_q975": 1453.974263107175,
            "rating_q025": 1425.4996049936992
        },
        "deepseek-v3.1-thinking": {
            "rating": 1439.3723400206154,
            "rating_q975": 1459.3670350378263,
            "rating_q025": 1419.3776450034047
        },
        "mistral-medium-2508": {
            "rating": 1438.7020753616393,
            "rating_q975": 1453.683044101052,
            "rating_q025": 1423.7211066222267
        },
        "deepseek-r1-0528": {
            "rating": 1438.3484543468717,
            "rating_q975": 1448.1714797808656,
            "rating_q025": 1428.5254289128777
        },
        "gpt-4.5-preview-2025-02-27": {
            "rating": 1437.9554727490856,
            "rating_q975": 1449.7244019455457,
            "rating_q025": 1426.1865435526254
        },
        "claude-opus-4-20250514": {
            "rating": 1435.4565360010954,
            "rating_q975": 1443.5912011952041,
            "rating_q025": 1427.321870806987
        },
        "deepseek-v3.1": {
            "rating": 1434.7310977698673,
            "rating_q975": 1453.2143142052955,
            "rating_q025": 1416.2478813344392
        },
        "grok-4-0709": {
            "rating": 1433.9244502532438,
            "rating_q975": 1443.5449298841495,
            "rating_q025": 1424.303970622338
        },
        "grok-3-preview-02-24": {
            "rating": 1433.3983737103401,
            "rating_q975": 1441.1476608041055,
            "rating_q025": 1425.6490866165746
        },
        "gpt-4.1-2025-04-14": {
            "rating": 1432.3328498445137,
            "rating_q975": 1440.4326792626875,
            "rating_q025": 1424.23302042634
        },
        "glm-4.5": {
            "rating": 1430.5382877008906,
            "rating_q975": 1442.9159213196235,
            "rating_q025": 1418.1606540821576
        },
        "qwen3-235b-a22b-thinking-2507": {
            "rating": 1428.510572307309,
            "rating_q975": 1442.1519139395696,
            "rating_q025": 1414.8692306750486
        },
        "kimi-k2-0711-preview": {
            "rating": 1428.2034702326275,
            "rating_q975": 1437.6779514570442,
            "rating_q025": 1418.7289890082106
        },
        "deepseek-r1": {
            "rating": 1424.4801438858099,
            "rating_q975": 1435.2372149333107,
            "rating_q025": 1413.723072838309
        },
        "qwen3-coder-480b-a35b-instruct": {
            "rating": 1422.0981928348763,
            "rating_q975": 1433.0676416115937,
            "rating_q025": 1411.1287440581586
        },
        "claude-3-7-sonnet-20250219-thinking-32k": {
            "rating": 1420.0218012998296,
            "rating_q975": 1427.6437563766856,
            "rating_q025": 1412.3998462229733
        },
        "mai-1-preview": {
            "rating": 1419.4510110191693,
            "rating_q975": 1439.708336850645,
            "rating_q025": 1399.1936851876935
        },
        "o1-2024-12-17": {
            "rating": 1415.5369066723902,
            "rating_q975": 1424.4791372702257,
            "rating_q025": 1406.5946760745546
        },
        "o4-mini-2025-04-16": {
            "rating": 1415.1832381708616,
            "rating_q975": 1423.249198302769,
            "rating_q025": 1407.117278038954
        },
        "qwen-vl-max-2025-08-13": {
            "rating": 1414.3866958268666,
            "rating_q975": 1446.8390639733384,
            "rating_q025": 1381.934327680395
        },
        "qwen3-235b-a22b-no-thinking": {
            "rating": 1413.1093941408994,
            "rating_q975": 1421.2985177276591,
            "rating_q025": 1404.9202705541395
        },
        "deepseek-v3-0324": {
            "rating": 1412.8028216611654,
            "rating_q975": 1420.596360640355,
            "rating_q025": 1405.0092826819757
        },
        "claude-sonnet-4-20250514": {
            "rating": 1411.7376630346075,
            "rating_q975": 1420.117835713608,
            "rating_q025": 1403.357490355607
        },
        "gemini-2.5-flash": {
            "rating": 1411.736250140814,
            "rating_q975": 1419.447577980313,
            "rating_q025": 1404.024922301315
        },
        "gpt-5-mini-high": {
            "rating": 1410.013457441508,
            "rating_q975": 1425.4722722857578,
            "rating_q025": 1394.5546425972586
        },
        "o1-preview": {
            "rating": 1408.9196424992335,
            "rating_q975": 1417.7122493698416,
            "rating_q025": 1400.1270356286252
        },
        "o3-mini-high": {
            "rating": 1407.0970488592905,
            "rating_q975": 1417.57519725542,
            "rating_q025": 1396.6189004631608
        },
        "qwen3-30b-a3b-instruct-2507": {
            "rating": 1406.0314053787738,
            "rating_q975": 1419.6720839444995,
            "rating_q025": 1392.390726813048
        },
        "mistral-medium-2505": {
            "rating": 1404.6205382967892,
            "rating_q975": 1412.4139596560049,
            "rating_q025": 1396.8271169375737
        },
        "gpt-4.1-mini-2025-04-14": {
            "rating": 1403.7628918142977,
            "rating_q975": 1411.800681360528,
            "rating_q025": 1395.7251022680673
        },
        "glm-4.5-air": {
            "rating": 1403.5738196355858,
            "rating_q975": 1416.1981370191743,
            "rating_q025": 1390.949502251997
        },
        "step-3": {
            "rating": 1402.994709115839,
            "rating_q975": 1425.1847904136728,
            "rating_q025": 1380.804627818005
        },
        "qwen3-235b-a22b": {
            "rating": 1400.0183316072776,
            "rating_q975": 1408.4753948078833,
            "rating_q025": 1391.5612684066718
        },
        "minimax-m1": {
            "rating": 1395.899042582678,
            "rating_q975": 1404.7147426838724,
            "rating_q025": 1387.083342481484
        },
        "claude-3-5-sonnet-20241022": {
            "rating": 1395.257094523579,
            "rating_q975": 1400.4488588837924,
            "rating_q025": 1390.065330163366
        },
        "claude-3-7-sonnet-20250219": {
            "rating": 1393.9941371120533,
            "rating_q975": 1401.1333116268968,
            "rating_q025": 1386.8549625972098
        },
        "hunyuan-t1-20250711": {
            "rating": 1392.496903144635,
            "rating_q975": 1409.7076938831178,
            "rating_q025": 1375.2861124061526
        },
        "hunyuan-turbos-20250416": {
            "rating": 1390.4319508672822,
            "rating_q975": 1402.5419186223983,
            "rating_q025": 1378.321983112166
        },
        "llama-3.1-nemotron-ultra-253b-v1": {
            "rating": 1388.1200320812336,
            "rating_q975": 1414.385052088652,
            "rating_q025": 1361.8550120738153
        },
        "mistral-small-2506": {
            "rating": 1384.6972879067062,
            "rating_q975": 1394.9900080138725,
            "rating_q025": 1374.4045677995398
        },
        "qwen2.5-max": {
            "rating": 1384.4536896338195,
            "rating_q975": 1391.909509140469,
            "rating_q025": 1376.99787012717
        },
        "glm-4.5v": {
            "rating": 1382.3240491870265,
            "rating_q975": 1417.877981008486,
            "rating_q025": 1346.770117365567
        },
        "o3-mini": {
            "rating": 1380.9662942995008,
            "rating_q975": 1387.5466532095409,
            "rating_q025": 1374.3859353894604
        },
        "qwen3-32b": {
            "rating": 1378.4036710832784,
            "rating_q975": 1399.0418781088094,
            "rating_q025": 1357.7654640577473
        },
        "llama-3.3-nemotron-49b-super-v1": {
            "rating": 1378.3927269378148,
            "rating_q975": 1405.8145662957077,
            "rating_q025": 1350.970887579922
        },
        "grok-3-mini-beta": {
            "rating": 1377.4464206101557,
            "rating_q975": 1386.3769184721564,
            "rating_q025": 1368.515922748155
        },
        "hunyuan-turbos-20250226": {
            "rating": 1377.299381219374,
            "rating_q975": 1402.7840409123119,
            "rating_q025": 1351.814721526436
        },
        "gpt-5-nano-high": {
            "rating": 1377.2869167688632,
            "rating_q975": 1395.1138180874925,
            "rating_q025": 1359.4600154502336
        },
        "grok-3-mini-high": {
            "rating": 1376.1964058795022,
            "rating_q975": 1386.3722897857347,
            "rating_q025": 1366.0205219732695
        },
        "nvidia-llama-3.3-nemotron-super-49b-v1.5": {
            "rating": 1374.5861538424285,
            "rating_q975": 1393.842415884837,
            "rating_q025": 1355.32989180002
        },
        "o1-mini": {
            "rating": 1373.3947274844052,
            "rating_q975": 1380.266756860424,
            "rating_q025": 1366.5226981083865
        },
        "qwq-32b": {
            "rating": 1370.6119959381735,
            "rating_q975": 1379.2758364838996,
            "rating_q025": 1361.9481553924475
        },
        "gpt-oss-120b": {
            "rating": 1365.8771080871504,
            "rating_q975": 1380.0108353570047,
            "rating_q025": 1351.7433808172962
        },
        "gemini-2.0-flash-001": {
            "rating": 1365.2755542709217,
            "rating_q975": 1372.2670635923557,
            "rating_q025": 1358.2840449494875
        },
        "hunyuan-turbo-0110": {
            "rating": 1364.556242691305,
            "rating_q975": 1389.7879592115305,
            "rating_q025": 1339.3245261710792
        },
        "qwen-plus-0125": {
            "rating": 1363.9845937036043,
            "rating_q975": 1380.855867096938,
            "rating_q025": 1347.1133203102704
        },
        "command-a-03-2025": {
            "rating": 1363.4660320532428,
            "rating_q975": 1370.9188931016547,
            "rating_q025": 1356.0131710048308
        },
        "gemma-3-27b-it": {
            "rating": 1363.423232723721,
            "rating_q975": 1370.97723880911,
            "rating_q025": 1355.8692266383318
        },
        "claude-3-5-sonnet-20240620": {
            "rating": 1357.7435794332264,
            "rating_q975": 1364.0174607193696,
            "rating_q025": 1351.4696981470831
        },
        "deepseek-v3": {
            "rating": 1357.2856319499322,
            "rating_q975": 1366.517353404189,
            "rating_q025": 1348.0539104956752
        },
        "qwen3-30b-a3b": {
            "rating": 1356.6098399143514,
            "rating_q975": 1365.2303964250532,
            "rating_q025": 1347.9892834036496
        },
        "gpt-oss-20b": {
            "rating": 1356.1745831757175,
            "rating_q975": 1370.773349458364,
            "rating_q025": 1341.5758168930709
        },
        "yi-lightning": {
            "rating": 1354.27831024684,
            "rating_q975": 1363.3524357026486,
            "rating_q025": 1345.2041847910314
        },
        "llama-3.1-405b-instruct-bf16": {
            "rating": 1353.0963402889572,
            "rating_q975": 1359.8925592252972,
            "rating_q025": 1346.300121352617
        },
        "gemini-2.0-flash-lite-preview-02-05": {
            "rating": 1350.6621640151454,
            "rating_q975": 1359.3146552602564,
            "rating_q025": 1342.0096727700343
        },
        "gemini-1.5-pro-002": {
            "rating": 1348.5080196900847,
            "rating_q975": 1354.7182246006507,
            "rating_q025": 1342.2978147795186
        },
        "step-1o-turbo-202506": {
            "rating": 1348.0371005454833,
            "rating_q975": 1360.7415997661706,
            "rating_q025": 1335.3326013247959
        },
        "llama-4-maverick-17b-128e-instruct": {
            "rating": 1346.7782581360461,
            "rating_q975": 1354.8991060535768,
            "rating_q025": 1338.6574102185152
        },
        "llama-3.1-405b-instruct-fp8": {
            "rating": 1346.1056927508794,
            "rating_q975": 1352.5901217569674,
            "rating_q025": 1339.6212637447911
        },
        "claude-3-5-haiku-20241022": {
            "rating": 1345.7004336535892,
            "rating_q975": 1351.7874933519574,
            "rating_q025": 1339.6133739552213
        },
        "athene-v2-chat": {
            "rating": 1343.627914487584,
            "rating_q975": 1352.172682156576,
            "rating_q025": 1335.083146818592
        },
        "gpt-4o-2024-05-13": {
            "rating": 1343.3101561310873,
            "rating_q975": 1349.063586872816,
            "rating_q025": 1337.5567253893585
        },
        "step-2-16k-exp-202412": {
            "rating": 1342.4459796621595,
            "rating_q975": 1360.1731123611896,
            "rating_q025": 1324.718846963129
        },
        "qwen2.5-plus-1127": {
            "rating": 1341.6650089955842,
            "rating_q975": 1354.0528339112016,
            "rating_q025": 1329.277184079967
        },
        "amazon-nova-experimental-chat-05-14": {
            "rating": 1340.2201575637425,
            "rating_q975": 1349.7266679330523,
            "rating_q025": 1330.713647194433
        },
        "llama-4-scout-17b-16e-instruct": {
            "rating": 1339.0405304304504,
            "rating_q975": 1348.337479292469,
            "rating_q025": 1329.7435815684314
        },
        "magistral-medium-2506": {
            "rating": 1336.6351307729929,
            "rating_q975": 1349.2665058876778,
            "rating_q025": 1324.0037556583075
        },
        "gemma-3-12b-it": {
            "rating": 1335.664911869434,
            "rating_q975": 1356.3294027804918,
            "rating_q025": 1315.0004209583763
        },
        "deepseek-v2.5-1210": {
            "rating": 1333.4402937254367,
            "rating_q975": 1348.9735289495611,
            "rating_q025": 1317.9070585013126
        },
        "gpt-4.1-nano-2025-04-14": {
            "rating": 1333.332791099212,
            "rating_q975": 1350.346096574834,
            "rating_q025": 1316.3194856235898
        },
        "gpt-4o-2024-08-06": {
            "rating": 1332.5174881907267,
            "rating_q975": 1339.585085217055,
            "rating_q025": 1325.4498911643984
        },
        "hunyuan-large-2025-02-10": {
            "rating": 1332.1305831939103,
            "rating_q975": 1354.426502508636,
            "rating_q025": 1309.8346638791845
        },
        "llama-3.3-70b-instruct": {
            "rating": 1329.339176584671,
            "rating_q975": 1335.444534349144,
            "rating_q025": 1323.233818820198
        },
        "mistral-large-2407": {
            "rating": 1329.0834655392125,
            "rating_q975": 1336.1357245309537,
            "rating_q025": 1322.0312065474711
        },
        "deepseek-v2.5": {
            "rating": 1327.9506228046846,
            "rating_q975": 1336.5451032480648,
            "rating_q025": 1319.3561423613041
        },
        "mistral-small-3.1-24b-instruct-2503": {
            "rating": 1327.7652186195355,
            "rating_q975": 1337.1666855277656,
            "rating_q025": 1318.3637517113054
        },
        "grok-2-2024-08-13": {
            "rating": 1326.7969784618992,
            "rating_q975": 1332.960162286517,
            "rating_q025": 1320.6337946372812
        },
        "qwen-max-0919": {
            "rating": 1325.9962963469748,
            "rating_q975": 1336.4872304802673,
            "rating_q025": 1315.5053622136822
        },
        "qwen2.5-72b-instruct": {
            "rating": 1324.4961883845808,
            "rating_q975": 1331.682142831853,
            "rating_q025": 1317.3102339373088
        },
        "gemini-1.5-pro-001": {
            "rating": 1324.2198805791843,
            "rating_q975": 1330.9677644219032,
            "rating_q025": 1317.4719967364654
        },
        "gpt-4-turbo-2024-04-09": {
            "rating": 1324.1561241813934,
            "rating_q975": 1330.5365307857367,
            "rating_q025": 1317.7757175770503
        },
        "llama-3.1-nemotron-70b-instruct": {
            "rating": 1323.9892428782664,
            "rating_q975": 1339.5715711591208,
            "rating_q025": 1308.4069145974122
        },
        "glm-4-plus": {
            "rating": 1322.945562251058,
            "rating_q975": 1331.8905560330531,
            "rating_q025": 1314.0005684690627
        },
        "gemini-advanced-0514": {
            "rating": 1321.342477592279,
            "rating_q975": 1329.6203284119033,
            "rating_q025": 1313.0646267726547
        },
        "hunyuan-large-vision": {
            "rating": 1321.0567817403803,
            "rating_q975": 1336.9886816711842,
            "rating_q025": 1305.124881809576
        },
        "claude-3-opus-20240229": {
            "rating": 1319.527496977581,
            "rating_q975": 1324.7491685113444,
            "rating_q025": 1314.3058254438172
        },
        "gpt-4-1106-preview": {
            "rating": 1319.3274440925047,
            "rating_q975": 1325.8471455933193,
            "rating_q025": 1312.8077425916902
        },
        "athene-70b-0725": {
            "rating": 1319.0590638386814,
            "rating_q975": 1328.7054283866144,
            "rating_q025": 1309.4126992907482
        },
        "glm-4-plus-0111": {
            "rating": 1318.972489693736,
            "rating_q975": 1336.0353349194422,
            "rating_q025": 1301.9096444680295
        },
        "mistral-large-2411": {
            "rating": 1318.8735033873309,
            "rating_q975": 1326.9464038809713,
            "rating_q025": 1310.8006028936904
        },
        "gemma-3n-e4b-it": {
            "rating": 1318.414560430123,
            "rating_q975": 1328.449173116698,
            "rating_q025": 1308.379947743548
        },
        "hunyuan-standard-2025-02-10": {
            "rating": 1318.383448147615,
            "rating_q975": 1341.4612152130608,
            "rating_q025": 1295.305681082169
        },
        "gpt-4o-mini-2024-07-18": {
            "rating": 1317.9186807578815,
            "rating_q975": 1323.7395976691844,
            "rating_q025": 1312.0977638465786
        },
        "qwen2.5-coder-32b-instruct": {
            "rating": 1316.5956238883075,
            "rating_q975": 1335.0911134697624,
            "rating_q025": 1298.1001343068526
        },
        "gpt-4-0125-preview": {
            "rating": 1313.8413045874554,
            "rating_q975": 1320.509801150675,
            "rating_q025": 1307.1728080242356
        },
        "gemini-1.5-flash-002": {
            "rating": 1310.8684037556523,
            "rating_q975": 1318.4398842122778,
            "rating_q025": 1303.2969232990267
        },
        "grok-2-mini-2024-08-13": {
            "rating": 1310.2846062606814,
            "rating_q975": 1316.804133360376,
            "rating_q025": 1303.7650791609867
        },
        "llama-3.1-70b-instruct": {
            "rating": 1309.9387588301065,
            "rating_q975": 1316.450373818068,
            "rating_q025": 1303.4271438421451
        },
        "amazon-nova-pro-v1.0": {
            "rating": 1309.7496833971315,
            "rating_q975": 1318.1008501615945,
            "rating_q025": 1301.3985166326686
        },
        "gpt-4-0314": {
            "rating": 1306.1041636381397,
            "rating_q975": 1314.5993597940096,
            "rating_q025": 1297.6089674822697
        },
        "llama-3-70b-instruct": {
            "rating": 1303.6442606850426,
            "rating_q975": 1309.8211743197642,
            "rating_q025": 1297.4673470503212
        },
        "olmo-2-0325-32b-instruct": {
            "rating": 1293.0927870219639,
            "rating_q975": 1316.3323687903144,
            "rating_q025": 1269.8532052536139
        },
        "deepseek-coder-v2": {
            "rating": 1292.1276352995317,
            "rating_q975": 1303.4224306635297,
            "rating_q025": 1280.8328399355337
        },
        "gpt-4-0613": {
            "rating": 1291.518663903026,
            "rating_q975": 1298.675498387399,
            "rating_q025": 1284.3618294186529
        },
        "jamba-1.5-large": {
            "rating": 1290.593546911794,
            "rating_q975": 1304.0540383834832,
            "rating_q025": 1277.133055440105
        },
        "mistral-small-24b-instruct-2501": {
            "rating": 1289.5094083754748,
            "rating_q975": 1300.8905021568605,
            "rating_q025": 1278.1283145940888
        },
        "gemini-1.5-flash-001": {
            "rating": 1287.7068382524776,
            "rating_q975": 1294.5861626041722,
            "rating_q025": 1280.827513900783
        },
        "llama-3.1-tulu-3-70b": {
            "rating": 1287.380316421745,
            "rating_q975": 1309.8749343989102,
            "rating_q025": 1264.8856984445797
        },
        "phi-4": {
            "rating": 1287.1983205598076,
            "rating_q975": 1296.1241945139554,
            "rating_q025": 1278.2724466056598
        },
        "gemma-2-27b-it": {
            "rating": 1281.963552018365,
            "rating_q975": 1287.721350310172,
            "rating_q025": 1276.2057537265578
        },
        "gemma-3-4b-it": {
            "rating": 1280.6029268611849,
            "rating_q975": 1300.78663855658,
            "rating_q025": 1260.4192151657896
        },
        "glm-4-0520": {
            "rating": 1280.0443108969012,
            "rating_q975": 1293.0985996271988,
            "rating_q025": 1266.9900221666032
        },
        "claude-3-sonnet-20240229": {
            "rating": 1279.3478137737395,
            "rating_q975": 1286.0866311637733,
            "rating_q025": 1272.608996383706
        },
        "qwen2-72b-instruct": {
            "rating": 1277.7173538929835,
            "rating_q975": 1285.9505433913664,
            "rating_q025": 1269.4841643946006
        },
        "hunyuan-standard-256k": {
            "rating": 1277.1175279532981,
            "rating_q975": 1304.2231126546817,
            "rating_q025": 1250.011943251915
        },
        "reka-core-20240904": {
            "rating": 1276.2703311000444,
            "rating_q975": 1289.5364784512333,
            "rating_q025": 1263.0041837488554
        },
        "amazon-nova-lite-v1.0": {
            "rating": 1276.0090616015564,
            "rating_q975": 1285.6576332879085,
            "rating_q025": 1266.360489915204
        },
        "nemotron-4-340b-instruct": {
            "rating": 1275.4183527254827,
            "rating_q975": 1286.0349107508678,
            "rating_q025": 1264.8017947000978
        },
        "gemma-2-9b-it-simpo": {
            "rating": 1273.1562376634856,
            "rating_q975": 1286.5387658161285,
            "rating_q025": 1259.773709510843
        },
        "llama-3.1-nemotron-51b-instruct": {
            "rating": 1272.0632746160682,
            "rating_q975": 1293.6832516715801,
            "rating_q025": 1250.4432975605564
        },
        "c4ai-aya-expanse-32b": {
            "rating": 1270.979345151508,
            "rating_q975": 1279.6468316296887,
            "rating_q025": 1262.3118586733272
        },
        "ministral-8b-2410": {
            "rating": 1266.3272464451868,
            "rating_q975": 1285.4427007363897,
            "rating_q025": 1247.2117921539839
        },
        "reka-flash-20240904": {
            "rating": 1266.0114841352329,
            "rating_q975": 1279.0289017993339,
            "rating_q025": 1252.9940664711316
        },
        "mistral-large-2402": {
            "rating": 1265.82220326062,
            "rating_q975": 1273.6646121298265,
            "rating_q025": 1257.979794391413
        },
        "gemini-1.5-flash-8b-001": {
            "rating": 1264.633098962612,
            "rating_q975": 1272.2404780870868,
            "rating_q025": 1257.0257198381369
        },
        "command-r-plus-08-2024": {
            "rating": 1264.3027245981189,
            "rating_q975": 1276.7692261237148,
            "rating_q025": 1251.8362230725227
        },
        "claude-3-haiku-20240307": {
            "rating": 1262.811295065362,
            "rating_q975": 1268.9667860913323,
            "rating_q025": 1256.6558040393916
        },
        "qwen1.5-110b-chat": {
            "rating": 1258.1972399513138,
            "rating_q975": 1268.1208937091278,
            "rating_q025": 1248.2735861934998
        },
        "command-r-08-2024": {
            "rating": 1258.0705677877859,
            "rating_q975": 1270.2302813968681,
            "rating_q025": 1245.9108541787036
        },
        "gemma-2-9b-it": {
            "rating": 1257.0156189506476,
            "rating_q975": 1263.6084721480318,
            "rating_q025": 1250.4227657532635
        },
        "internlm2_5-20b-chat": {
            "rating": 1256.5277929841382,
            "rating_q975": 1269.820758434848,
            "rating_q025": 1243.2348275334282
        },
        "amazon-nova-micro-v1.0": {
            "rating": 1256.2126009653284,
            "rating_q975": 1265.6783304279434,
            "rating_q025": 1246.7468715027137
        },
        "command-r-plus": {
            "rating": 1251.2939039957846,
            "rating_q975": 1258.4518346788507,
            "rating_q025": 1244.1359733127185
        },
        "mixtral-8x22b-instruct-v0.1": {
            "rating": 1248.5520398714293,
            "rating_q975": 1256.3856816520981,
            "rating_q025": 1240.7183980907603
        },
        "qwen1.5-72b-chat": {
            "rating": 1244.824225520107,
            "rating_q975": 1253.335532071413,
            "rating_q025": 1236.3129189688007
        },
        "granite-3.1-8b-instruct": {
            "rating": 1244.1308257240503,
            "rating_q975": 1267.2844081685541,
            "rating_q025": 1220.9772432795467
        },
        "jamba-1.5-mini": {
            "rating": 1242.5441723960303,
            "rating_q975": 1256.4651617874058,
            "rating_q025": 1228.623183004655
        },
        "llama-3-8b-instruct": {
            "rating": 1239.8181154039216,
            "rating_q975": 1246.5271244989788,
            "rating_q025": 1233.1091063088645
        },
        "llama-3.1-8b-instruct": {
            "rating": 1239.3973999591803,
            "rating_q975": 1246.3270644178651,
            "rating_q025": 1232.4677355004956
        },
        "mistral-medium": {
            "rating": 1237.4207552366672,
            "rating_q975": 1246.8648229493447,
            "rating_q025": 1227.9766875239898
        },
        "yi-1.5-34b-chat": {
            "rating": 1236.88172939152,
            "rating_q975": 1246.523986897002,
            "rating_q025": 1227.2394718860376
        },
        "reka-flash-21b-20240226-online": {
            "rating": 1236.7858099150133,
            "rating_q975": 1248.9463088072048,
            "rating_q025": 1224.6253110228217
        },
        "granite-3.1-2b-instruct": {
            "rating": 1235.4037958459667,
            "rating_q975": 1258.7331074060564,
            "rating_q025": 1212.0744842858767
        },
        "granite-3.0-8b-instruct": {
            "rating": 1233.860478875189,
            "rating_q975": 1252.0144328261767,
            "rating_q025": 1215.7065249242012
        },
        "reka-flash-21b-20240226": {
            "rating": 1232.9508110450402,
            "rating_q975": 1243.0068353682188,
            "rating_q025": 1222.8947867218617
        },
        "gpt-3.5-turbo-0125": {
            "rating": 1231.833790578303,
            "rating_q975": 1239.0984412878836,
            "rating_q025": 1224.5691398687225
        },
        "gpt-3.5-turbo-1106": {
            "rating": 1231.1516274039323,
            "rating_q975": 1244.6408658899438,
            "rating_q025": 1217.662388917921
        },
        "dbrx-instruct-preview": {
            "rating": 1230.5974723460147,
            "rating_q975": 1240.9632882073004,
            "rating_q025": 1220.231656484729
        },
        "gemini-pro": {
            "rating": 1230.4255304523356,
            "rating_q975": 1249.5982634513455,
            "rating_q025": 1211.2527974533255
        },
        "qwen1.5-32b-chat": {
            "rating": 1229.3202817450465,
            "rating_q975": 1239.9655619806294,
            "rating_q025": 1218.675001509463
        },
        "c4ai-aya-expanse-8b": {
            "rating": 1228.522291236215,
            "rating_q975": 1242.1847950916756,
            "rating_q025": 1214.8597873807548
        },
        "llama-3.1-tulu-3-8b": {
            "rating": 1227.2281508630601,
            "rating_q975": 1251.595385954802,
            "rating_q025": 1202.8609157713186
        },
        "gemini-pro-dev-api": {
            "rating": 1226.9967165549651,
            "rating_q975": 1239.3717599950583,
            "rating_q025": 1214.621673114872
        },
        "phi-3-medium-4k-instruct": {
            "rating": 1223.2743614919516,
            "rating_q975": 1232.6341181872783,
            "rating_q025": 1213.9146047966249
        },
        "mixtral-8x7b-instruct-v0.1": {
            "rating": 1222.9181141855129,
            "rating_q975": 1230.2176958535513,
            "rating_q025": 1215.6185325174743
        },
        "zephyr-orpo-141b-A35b-v0.1": {
            "rating": 1222.5205584026232,
            "rating_q975": 1242.6152752611697,
            "rating_q025": 1202.4258415440768
        },
        "command-r": {
            "rating": 1216.175655323312,
            "rating_q975": 1224.3418296047614,
            "rating_q025": 1208.0094810418625
        },
        "phi-3-small-8k-instruct": {
            "rating": 1208.1962416862048,
            "rating_q975": 1219.350317395129,
            "rating_q025": 1197.042165977281
        },
        "llama-3.2-3b-instruct": {
            "rating": 1206.5358292936999,
            "rating_q975": 1220.9832732617717,
            "rating_q025": 1192.0883853256278
        },
        "qwen1.5-14b-chat": {
            "rating": 1203.563443938529,
            "rating_q975": 1215.9165457771257,
            "rating_q025": 1191.2103420999322
        },
        "starling-lm-7b-beta": {
            "rating": 1202.3877357954484,
            "rating_q975": 1214.687333942559,
            "rating_q025": 1190.088137648338
        },
        "tulu-2-dpo-70b": {
            "rating": 1199.999811310373,
            "rating_q975": 1217.3927408578397,
            "rating_q025": 1182.6068817629057
        },
        "gemma-1.1-7b-it": {
            "rating": 1199.178888441983,
            "rating_q975": 1209.0442444837267,
            "rating_q025": 1189.3135324002392
        },
        "phi-3-mini-4k-instruct-june-2024": {
            "rating": 1197.804826790477,
            "rating_q975": 1210.1993436849132,
            "rating_q025": 1185.4103098960406
        },
        "granite-3.0-2b-instruct": {
            "rating": 1195.5471678332315,
            "rating_q975": 1213.2161855800675,
            "rating_q025": 1177.8781500863952
        },
        "snowflake-arctic-instruct": {
            "rating": 1195.5282668921886,
            "rating_q975": 1205.880830659008,
            "rating_q025": 1185.1757031253687
        },
        "gemma-2-2b-it": {
            "rating": 1195.1613677838182,
            "rating_q975": 1202.4153669983964,
            "rating_q025": 1187.90736856924
        },
        "yi-34b-chat": {
            "rating": 1193.1617912077436,
            "rating_q975": 1204.8329075648903,
            "rating_q025": 1181.4906748505966
        },
        "openchat-3.5-0106": {
            "rating": 1190.5483467624626,
            "rating_q975": 1202.6881982649495,
            "rating_q025": 1178.408495259976
        },
        "openhermes-2.5-mistral-7b": {
            "rating": 1188.1339911490313,
            "rating_q975": 1206.5295086114675,
            "rating_q025": 1169.7384736865954
        },
        "qwq-32b-preview": {
            "rating": 1186.2492202026206,
            "rating_q975": 1209.7456217149415,
            "rating_q025": 1162.7528186902996
        },
        "deepseek-llm-67b-chat": {
            "rating": 1182.3853622371525,
            "rating_q975": 1202.1019097275607,
            "rating_q025": 1162.6688147467444
        },
        "wizardlm-70b": {
            "rating": 1180.7672573164866,
            "rating_q975": 1196.9273897026658,
            "rating_q025": 1164.6071249303072
        },
        "starling-lm-7b-alpha": {
            "rating": 1180.1754109800495,
            "rating_q975": 1194.1270147063983,
            "rating_q025": 1166.223807253701
        },
        "mpt-30b-chat": {
            "rating": 1179.6338002518369,
            "rating_q975": 1209.3200852767436,
            "rating_q025": 1149.94751522693
        },
        "openchat-3.5": {
            "rating": 1172.0015507485955,
            "rating_q975": 1188.6371790265907,
            "rating_q025": 1155.3659224706003
        },
        "mistral-7b-instruct-v0.2": {
            "rating": 1171.6906197995104,
            "rating_q975": 1182.3117866688722,
            "rating_q025": 1161.0694529301484
        },
        "llama-2-70b-chat": {
            "rating": 1171.5588067594044,
            "rating_q975": 1180.3811929541082,
            "rating_q025": 1162.736420564701
        },
        "codellama-70b-instruct": {
            "rating": 1170.9574745637517,
            "rating_q975": 1207.4874423199394,
            "rating_q025": 1134.427506807564
        },
        "vicuna-33b": {
            "rating": 1170.6722298302034,
            "rating_q975": 1181.6623171900924,
            "rating_q025": 1159.6821424703144
        },
        "phi-3-mini-4k-instruct": {
            "rating": 1170.6499994884794,
            "rating_q975": 1181.7816695835281,
            "rating_q025": 1159.5183293934303
        },
        "smollm2-1.7b-instruct": {
            "rating": 1168.425064381744,
            "rating_q975": 1197.9301965230595,
            "rating_q025": 1138.9199322404284
        },
        "gemma-7b-it": {
            "rating": 1162.6391587593635,
            "rating_q975": 1177.5824136936476,
            "rating_q025": 1147.6959038250789
        },
        "solar-10.7b-instruct-v1.0": {
            "rating": 1161.633057555624,
            "rating_q975": 1183.202482097257,
            "rating_q025": 1140.063633013991
        },
        "dolphin-2.2.1-mistral-7b": {
            "rating": 1160.7204708218924,
            "rating_q975": 1192.26050788471,
            "rating_q025": 1129.1804337590747
        },
        "palm-2": {
            "rating": 1157.325529060556,
            "rating_q975": 1173.815733017363,
            "rating_q025": 1140.8353251037488
        },
        "llama-3.2-1b-instruct": {
            "rating": 1156.5054770266252,
            "rating_q975": 1170.6557427530909,
            "rating_q025": 1142.3552113001597
        },
        "llama-2-13b-chat": {
            "rating": 1154.4333893512164,
            "rating_q975": 1165.9226753483294,
            "rating_q025": 1142.9441033541034
        },
        "qwen1.5-7b-chat": {
            "rating": 1154.4126325924929,
            "rating_q975": 1171.6974834270777,
            "rating_q025": 1137.127781757908
        },
        "llama2-70b-steerlm-chat": {
            "rating": 1149.3829510104115,
            "rating_q975": 1171.8154834081977,
            "rating_q025": 1126.9504186126255
        },
        "phi-3-mini-128k-instruct": {
            "rating": 1147.6641967768096,
            "rating_q975": 1159.6972749831018,
            "rating_q025": 1135.6311185705176
        },
        "qwen-14b-chat": {
            "rating": 1145.1822008999964,
            "rating_q975": 1165.4544346710718,
            "rating_q025": 1124.9099671289207
        },
        "gemma-1.1-2b-it": {
            "rating": 1143.1925827741504,
            "rating_q975": 1157.0802983915626,
            "rating_q025": 1129.3048671567383
        },
        "nous-hermes-2-mixtral-8x7b-dpo": {
            "rating": 1140.5582343957071,
            "rating_q975": 1159.0677532608884,
            "rating_q025": 1122.0487155305257
        },
        "codellama-34b-instruct": {
            "rating": 1138.569837831164,
            "rating_q975": 1154.4138773103007,
            "rating_q025": 1122.7257983520271
        },
        "vicuna-13b": {
            "rating": 1135.1416967869172,
            "rating_q975": 1146.8682081390157,
            "rating_q025": 1123.4151854348186
        },
        "zephyr-7b-alpha": {
            "rating": 1133.1006449749316,
            "rating_q975": 1166.2534388695121,
            "rating_q025": 1099.9478510803513
        },
        "zephyr-7b-beta": {
            "rating": 1131.0543007133604,
            "rating_q975": 1146.3450358012658,
            "rating_q025": 1115.763565625455
        },
        "mistral-7b-instruct": {
            "rating": 1125.5655156659063,
            "rating_q975": 1141.8746685816295,
            "rating_q025": 1109.2563627501834
        },
        "wizardlm-13b": {
            "rating": 1123.700510930794,
            "rating_q975": 1141.7602621132892,
            "rating_q025": 1105.6407597482992
        },
        "stripedhyena-nous-7b": {
            "rating": 1115.5971162362791,
            "rating_q975": 1133.5860579464813,
            "rating_q025": 1097.608174526077
        },
        "guanaco-33b": {
            "rating": 1112.6782510234634,
            "rating_q975": 1140.757701483522,
            "rating_q025": 1084.5988005634051
        },
        "llama-2-7b-chat": {
            "rating": 1112.6366899591271,
            "rating_q975": 1124.681846982412,
            "rating_q025": 1100.591532935842
        },
        "gemma-2b-it": {
            "rating": 1106.769312754685,
            "rating_q975": 1126.5864388744285,
            "rating_q025": 1086.9521866349417
        },
        "vicuna-7b": {
            "rating": 1105.5240323669761,
            "rating_q975": 1124.007942166705,
            "rating_q025": 1087.0401225672472
        },
        "qwen1.5-4b-chat": {
            "rating": 1091.4724223590451,
            "rating_q975": 1107.3883607474672,
            "rating_q025": 1075.5564839706233
        },
        "olmo-7b-instruct": {
            "rating": 1083.451258663068,
            "rating_q975": 1101.9841877720767,
            "rating_q025": 1064.9183295540593
        },
        "chatglm3-6b": {
            "rating": 1076.2295683949646,
            "rating_q975": 1097.1339510495382,
            "rating_q025": 1055.3251857403911
        },
        "gpt4all-13b-snoozy": {
            "rating": 1072.7217040345192,
            "rating_q975": 1106.4071933307248,
            "rating_q025": 1039.0362147383134
        },
        "chatglm2-6b": {
            "rating": 1041.0172173119313,
            "rating_q975": 1070.062301126296,
            "rating_q025": 1011.9721334975668
        },
        "koala-13b": {
            "rating": 1036.9433917556175,
            "rating_q975": 1056.7438158909254,
            "rating_q025": 1017.14296762031
        },
        "mpt-7b-chat": {
            "rating": 1034.731889126538,
            "rating_q975": 1058.8070345797155,
            "rating_q025": 1010.6567436733604
        },
        "oasst-pythia-12b": {
            "rating": 1021.366774714088,
            "rating_q975": 1041.9492535499742,
            "rating_q025": 1000.7842958782021
        },
        "RWKV-4-Raven-14B": {
            "rating": 1012.8398431571263,
            "rating_q975": 1035.2976814192325,
            "rating_q025": 990.3820048950204
        },
        "alpaca-13b": {
            "rating": 1004.0857957561582,
            "rating_q975": 1025.7467949294382,
            "rating_q025": 982.424796582878
        },
        "chatglm-6b": {
            "rating": 990.7794488821368,
            "rating_q975": 1014.4567585684937,
            "rating_q025": 967.1021391957797
        },
        "dolly-v2-12b": {
            "rating": 958.2210655340679,
            "rating_q975": 985.2143469692317,
            "rating_q025": 931.2277840989041
        },
        "stablelm-tuned-alpha-7b": {
            "rating": 948.7420251907055,
            "rating_q975": 975.7649453672825,
            "rating_q025": 921.7191050141283
        },
        "fastchat-t5-3b": {
            "rating": 937.7594661808416,
            "rating_q975": 960.979398730359,
            "rating_q025": 914.5395336313243
        },
        "llama-13b": {
            "rating": 901.0952120924721,
            "rating_q975": 935.4513945263855,
            "rating_q025": 866.7390296585587
        }
    },
    "if": {
        "claude-opus-4-1-20250805-thinking-16k": {
            "rating": 1454.643763299768,
            "rating_q975": 1467.7037702559242,
            "rating_q025": 1441.5837563436119
        },
        "claude-opus-4-1-20250805": {
            "rating": 1444.0705206515709,
            "rating_q975": 1455.441379404539,
            "rating_q025": 1432.699661898603
        },
        "gemini-2.5-pro": {
            "rating": 1443.4418647460207,
            "rating_q975": 1450.9990313791666,
            "rating_q025": 1435.8846981128745
        },
        "claude-opus-4-20250514-thinking-16k": {
            "rating": 1430.381418722561,
            "rating_q975": 1438.6470564859383,
            "rating_q025": 1422.1157809591837
        },
        "gpt-4.5-preview-2025-02-27": {
            "rating": 1427.6647843386202,
            "rating_q975": 1435.6313510319026,
            "rating_q025": 1419.698217645338
        },
        "gpt-5-high": {
            "rating": 1423.9791200006105,
            "rating_q975": 1435.240523920525,
            "rating_q025": 1412.7177160806962
        },
        "chatgpt-4o-latest-20250326": {
            "rating": 1416.334674346501,
            "rating_q975": 1422.8948470366693,
            "rating_q025": 1409.774501656333
        },
        "gpt-5-chat": {
            "rating": 1414.426687822116,
            "rating_q975": 1427.5234171902143,
            "rating_q025": 1401.3299584540177
        },
        "deepseek-v3.1-thinking": {
            "rating": 1412.633840845522,
            "rating_q975": 1429.9907412796244,
            "rating_q025": 1395.2769404114197
        },
        "qwen-max-2025-08-15": {
            "rating": 1412.027819022716,
            "rating_q975": 1427.6827988882737,
            "rating_q025": 1396.3728391571578
        },
        "qwen3-235b-a22b-instruct-2507": {
            "rating": 1410.7629720758707,
            "rating_q975": 1420.9976009256247,
            "rating_q025": 1400.5283432261165
        },
        "claude-opus-4-20250514": {
            "rating": 1409.495461378048,
            "rating_q975": 1417.1462218656472,
            "rating_q025": 1401.8447008904486
        },
        "claude-sonnet-4-20250514-thinking-32k": {
            "rating": 1408.4378258839465,
            "rating_q975": 1416.8326485118253,
            "rating_q025": 1400.0430032560678
        },
        "grok-4-0709": {
            "rating": 1407.7866252900533,
            "rating_q975": 1416.6694542875102,
            "rating_q025": 1398.903796292596
        },
        "o3-2025-04-16": {
            "rating": 1407.2443125526047,
            "rating_q975": 1414.0080917295222,
            "rating_q025": 1400.4805333756872
        },
        "grok-3-preview-02-24": {
            "rating": 1401.464340722315,
            "rating_q975": 1407.7079769923223,
            "rating_q025": 1395.2207044523075
        },
        "glm-4.5": {
            "rating": 1399.5638356548775,
            "rating_q975": 1410.7484323503782,
            "rating_q025": 1388.3792389593768
        },
        "claude-3-7-sonnet-20250219-thinking-32k": {
            "rating": 1398.3073304022607,
            "rating_q975": 1404.7227584637774,
            "rating_q025": 1391.8919023407443
        },
        "o1-2024-12-17": {
            "rating": 1397.335884352815,
            "rating_q975": 1403.4708780582373,
            "rating_q025": 1391.2008906473925
        },
        "deepseek-v3.1": {
            "rating": 1396.780944949525,
            "rating_q975": 1412.8002818840362,
            "rating_q025": 1380.7616080150142
        },
        "mistral-medium-2508": {
            "rating": 1396.683372526097,
            "rating_q975": 1410.2633501796702,
            "rating_q025": 1383.1033948725237
        },
        "gpt-4.1-2025-04-14": {
            "rating": 1396.6535260507787,
            "rating_q975": 1403.9291484888827,
            "rating_q025": 1389.3779036126746
        },
        "gemini-2.5-flash": {
            "rating": 1395.4259647949448,
            "rating_q975": 1402.610754770775,
            "rating_q025": 1388.2411748191143
        },
        "qwen-vl-max-2025-08-13": {
            "rating": 1394.62656652407,
            "rating_q975": 1423.8068928036691,
            "rating_q025": 1365.446240244471
        },
        "qwen3-235b-a22b-thinking-2507": {
            "rating": 1393.868485719239,
            "rating_q975": 1406.3818650363564,
            "rating_q025": 1381.3551064021217
        },
        "deepseek-r1-0528": {
            "rating": 1390.101030925211,
            "rating_q975": 1399.065428243864,
            "rating_q025": 1381.1366336065582
        },
        "deepseek-r1": {
            "rating": 1388.44811422065,
            "rating_q975": 1395.5633804360145,
            "rating_q025": 1381.3328480052858
        },
        "claude-sonnet-4-20250514": {
            "rating": 1380.5762620730213,
            "rating_q975": 1388.3204089170426,
            "rating_q025": 1372.832115229
        },
        "kimi-k2-0711-preview": {
            "rating": 1380.390336047939,
            "rating_q975": 1389.05782979594,
            "rating_q025": 1371.7228422999378
        },
        "gpt-5-mini-high": {
            "rating": 1377.4741315510457,
            "rating_q975": 1391.8549019738457,
            "rating_q025": 1363.0933611282458
        },
        "qwen3-coder-480b-a35b-instruct": {
            "rating": 1377.1792668761773,
            "rating_q975": 1387.3537020495742,
            "rating_q025": 1367.0048317027804
        },
        "mai-1-preview": {
            "rating": 1377.117439321626,
            "rating_q975": 1394.53315073272,
            "rating_q025": 1359.701727910532
        },
        "o1-preview": {
            "rating": 1374.3204583369172,
            "rating_q975": 1380.636535576696,
            "rating_q025": 1368.0043810971383
        },
        "qwen3-235b-a22b-no-thinking": {
            "rating": 1373.8183722331544,
            "rating_q975": 1381.398189200746,
            "rating_q025": 1366.2385552655628
        },
        "deepseek-v3-0324": {
            "rating": 1372.2056353430119,
            "rating_q975": 1378.9289399758009,
            "rating_q025": 1365.482330710223
        },
        "hunyuan-t1-20250711": {
            "rating": 1371.914098953129,
            "rating_q975": 1387.0289085697477,
            "rating_q025": 1356.7992893365104
        },
        "claude-3-7-sonnet-20250219": {
            "rating": 1370.2372394655442,
            "rating_q975": 1376.0854447641068,
            "rating_q025": 1364.389034166982
        },
        "glm-4.5-air": {
            "rating": 1369.266428702604,
            "rating_q975": 1380.732694759859,
            "rating_q025": 1357.800162645349
        },
        "o4-mini-2025-04-16": {
            "rating": 1367.1660535944593,
            "rating_q975": 1374.4162417716523,
            "rating_q025": 1359.9158654172663
        },
        "qwen3-30b-a3b-instruct-2507": {
            "rating": 1363.829397647131,
            "rating_q975": 1376.3744266279798,
            "rating_q025": 1351.2843686662818
        },
        "gpt-4.1-mini-2025-04-14": {
            "rating": 1363.033371521071,
            "rating_q975": 1370.2006122549753,
            "rating_q025": 1355.866130787167
        },
        "claude-3-5-sonnet-20241022": {
            "rating": 1362.390930454256,
            "rating_q975": 1366.5282094462702,
            "rating_q025": 1358.2536514622416
        },
        "o3-mini-high": {
            "rating": 1360.693254415858,
            "rating_q975": 1367.9754321558635,
            "rating_q025": 1353.4110766758524
        },
        "mistral-medium-2505": {
            "rating": 1360.3144233896464,
            "rating_q975": 1367.5052668014662,
            "rating_q025": 1353.1235799778267
        },
        "grok-3-mini-high": {
            "rating": 1354.8376694525164,
            "rating_q975": 1364.2753778943268,
            "rating_q025": 1345.3999610107057
        },
        "qwen3-235b-a22b": {
            "rating": 1353.845697982792,
            "rating_q975": 1361.7211991889437,
            "rating_q025": 1345.9701967766403
        },
        "qwen2.5-max": {
            "rating": 1352.9133019058545,
            "rating_q975": 1358.642039151217,
            "rating_q025": 1347.1845646604922
        },
        "hunyuan-turbos-20250416": {
            "rating": 1351.2374495015447,
            "rating_q975": 1362.2794648406798,
            "rating_q025": 1340.1954341624098
        },
        "grok-3-mini-beta": {
            "rating": 1349.0154012772987,
            "rating_q975": 1357.30800073103,
            "rating_q025": 1340.7228018235676
        },
        "step-3": {
            "rating": 1348.644035357083,
            "rating_q975": 1369.356694948977,
            "rating_q025": 1327.9313757651892
        },
        "gemini-2.0-flash-001": {
            "rating": 1345.5565713652697,
            "rating_q975": 1351.050233276966,
            "rating_q025": 1340.0629094535732
        },
        "minimax-m1": {
            "rating": 1344.724250899214,
            "rating_q975": 1352.8967634556946,
            "rating_q025": 1336.5517383427334
        },
        "hunyuan-turbos-20250226": {
            "rating": 1343.827916596626,
            "rating_q975": 1360.3120906399504,
            "rating_q025": 1327.3437425533014
        },
        "o3-mini": {
            "rating": 1341.768826469148,
            "rating_q975": 1347.0956307569975,
            "rating_q025": 1336.4420221812989
        },
        "llama-3.1-nemotron-ultra-253b-v1": {
            "rating": 1340.4335868186245,
            "rating_q975": 1361.3118757639063,
            "rating_q025": 1319.5552978733424
        },
        "gemma-3-27b-it": {
            "rating": 1340.0026384276982,
            "rating_q975": 1346.340325617285,
            "rating_q025": 1333.6649512381111
        },
        "deepseek-v3": {
            "rating": 1338.7078593921553,
            "rating_q975": 1345.1908068423731,
            "rating_q025": 1332.2249119419373
        },
        "gpt-5-nano-high": {
            "rating": 1338.506104222624,
            "rating_q975": 1355.275879052834,
            "rating_q025": 1321.7363293924138
        },
        "mistral-small-2506": {
            "rating": 1336.7143966708825,
            "rating_q975": 1346.2766184714371,
            "rating_q025": 1327.1521748703278
        },
        "gemini-1.5-pro-002": {
            "rating": 1332.929483612053,
            "rating_q975": 1337.4278968426447,
            "rating_q025": 1328.431070381461
        },
        "command-a-03-2025": {
            "rating": 1332.1615641082483,
            "rating_q975": 1338.4681536422772,
            "rating_q025": 1325.8549745742196
        },
        "claude-3-5-sonnet-20240620": {
            "rating": 1329.2422960553065,
            "rating_q975": 1333.8408271264461,
            "rating_q025": 1324.6437649841669
        },
        "o1-mini": {
            "rating": 1328.5556537447692,
            "rating_q975": 1333.3383483756788,
            "rating_q025": 1323.7729591138593
        },
        "gemini-2.0-flash-lite-preview-02-05": {
            "rating": 1327.7008031905527,
            "rating_q975": 1333.7335845000234,
            "rating_q025": 1321.668021881082
        },
        "qwen-plus-0125": {
            "rating": 1326.7460698348193,
            "rating_q975": 1338.4807046630704,
            "rating_q025": 1315.0114350065685
        },
        "qwen3-32b": {
            "rating": 1326.7172463683423,
            "rating_q975": 1345.2858737055633,
            "rating_q025": 1308.1486190311214
        },
        "qwq-32b": {
            "rating": 1326.4912696159124,
            "rating_q975": 1333.6403340819468,
            "rating_q025": 1319.342205149878
        },
        "gpt-oss-120b": {
            "rating": 1326.1524473694521,
            "rating_q975": 1339.5100060228253,
            "rating_q025": 1312.794888716079
        },
        "nvidia-llama-3.3-nemotron-super-49b-v1.5": {
            "rating": 1325.8914715296746,
            "rating_q975": 1343.4761499833567,
            "rating_q025": 1308.3067930759923
        },
        "glm-4.5v": {
            "rating": 1321.8046358790243,
            "rating_q975": 1354.5237726458824,
            "rating_q025": 1289.0854991121662
        },
        "llama-3.3-nemotron-49b-super-v1": {
            "rating": 1319.449528157506,
            "rating_q975": 1337.7401034800355,
            "rating_q025": 1301.1589528349764
        },
        "gpt-4o-2024-05-13": {
            "rating": 1318.9037614618808,
            "rating_q975": 1323.3462565566313,
            "rating_q025": 1314.4612663671305
        },
        "gemma-3-12b-it": {
            "rating": 1317.1873118311069,
            "rating_q975": 1333.0997301333464,
            "rating_q025": 1301.2748935288673
        },
        "step-2-16k-exp-202412": {
            "rating": 1311.6401535790596,
            "rating_q975": 1323.4708481081962,
            "rating_q025": 1299.809459049923
        },
        "hunyuan-turbo-0110": {
            "rating": 1311.6386167471865,
            "rating_q975": 1328.4486357536537,
            "rating_q025": 1294.8285977407193
        },
        "gpt-4o-2024-08-06": {
            "rating": 1311.5760820314467,
            "rating_q975": 1316.8276520970137,
            "rating_q025": 1306.3245119658798
        },
        "glm-4-plus-0111": {
            "rating": 1311.2795745756807,
            "rating_q975": 1323.14918518053,
            "rating_q025": 1299.4099639708318
        },
        "hunyuan-large-2025-02-10": {
            "rating": 1310.9540310391476,
            "rating_q975": 1326.1056140061642,
            "rating_q025": 1295.8024480721313
        },
        "deepseek-v2.5-1210": {
            "rating": 1309.8527480353819,
            "rating_q975": 1320.3214146877247,
            "rating_q025": 1299.384081383039
        },
        "llama-3.1-405b-instruct-fp8": {
            "rating": 1308.3073944035043,
            "rating_q975": 1313.066710521194,
            "rating_q025": 1303.5480782858147
        },
        "llama-3.1-405b-instruct-bf16": {
            "rating": 1308.1949080477584,
            "rating_q975": 1313.0230232332501,
            "rating_q025": 1303.366792862267
        },
        "gemini-advanced-0514": {
            "rating": 1308.1315372998201,
            "rating_q975": 1314.4430034733286,
            "rating_q025": 1301.8200711263116
        },
        "qwen3-30b-a3b": {
            "rating": 1307.2461872121453,
            "rating_q975": 1315.2482438459797,
            "rating_q025": 1299.2441305783107
        },
        "claude-3-opus-20240229": {
            "rating": 1307.0781172163884,
            "rating_q975": 1311.0478976437755,
            "rating_q025": 1303.108336789001
        },
        "step-1o-turbo-202506": {
            "rating": 1306.769231578789,
            "rating_q975": 1318.5139234763772,
            "rating_q025": 1295.0245396812006
        },
        "grok-2-2024-08-13": {
            "rating": 1305.9346826640353,
            "rating_q975": 1310.3959250313458,
            "rating_q025": 1301.473440296725
        },
        "yi-lightning": {
            "rating": 1304.494060726094,
            "rating_q975": 1310.8345790981184,
            "rating_q025": 1298.1535423540695
        },
        "amazon-nova-experimental-chat-05-14": {
            "rating": 1304.0670544815246,
            "rating_q975": 1312.894276429177,
            "rating_q025": 1295.2398325338722
        },
        "gemini-1.5-pro-001": {
            "rating": 1304.0051245275927,
            "rating_q975": 1309.312165431159,
            "rating_q025": 1298.6980836240264
        },
        "llama-4-maverick-17b-128e-instruct": {
            "rating": 1303.2991835373232,
            "rating_q975": 1310.4254103010944,
            "rating_q025": 1296.1729567735517
        },
        "claude-3-5-haiku-20241022": {
            "rating": 1303.104011381115,
            "rating_q975": 1307.7827186378956,
            "rating_q025": 1298.4253041243342
        },
        "athene-v2-chat": {
            "rating": 1299.4099775892623,
            "rating_q975": 1305.2437544776976,
            "rating_q025": 1293.5762007008268
        },
        "gpt-4-turbo-2024-04-09": {
            "rating": 1297.8394512969671,
            "rating_q975": 1302.8231535839982,
            "rating_q025": 1292.855749009936
        },
        "qwen-max-0919": {
            "rating": 1297.8254708324803,
            "rating_q975": 1305.1259309518912,
            "rating_q025": 1290.5250107130694
        },
        "gpt-4.1-nano-2025-04-14": {
            "rating": 1295.8278588044213,
            "rating_q975": 1308.0833707544582,
            "rating_q025": 1283.5723468543847
        },
        "glm-4-plus": {
            "rating": 1295.5708552976926,
            "rating_q975": 1301.8803505547228,
            "rating_q025": 1289.2613600406626
        },
        "gpt-oss-20b": {
            "rating": 1294.7194704702795,
            "rating_q975": 1308.3651435769232,
            "rating_q025": 1281.0737973636358
        },
        "mistral-large-2407": {
            "rating": 1294.484009140825,
            "rating_q975": 1299.5746888316162,
            "rating_q025": 1289.393329450034
        },
        "qwen2.5-plus-1127": {
            "rating": 1292.735946468631,
            "rating_q975": 1301.2736863098442,
            "rating_q025": 1284.198206627418
        },
        "llama-4-scout-17b-16e-instruct": {
            "rating": 1292.0027677438243,
            "rating_q975": 1300.511462583731,
            "rating_q025": 1283.4940729039176
        },
        "gpt-4-1106-preview": {
            "rating": 1291.5901634616553,
            "rating_q975": 1296.7016253347704,
            "rating_q025": 1286.4787015885402
        },
        "magistral-medium-2506": {
            "rating": 1291.4683870186502,
            "rating_q975": 1303.021075983134,
            "rating_q025": 1279.9156980541663
        },
        "mistral-large-2411": {
            "rating": 1289.8704012846501,
            "rating_q975": 1295.5020217650501,
            "rating_q025": 1284.2387808042504
        },
        "gpt-4o-mini-2024-07-18": {
            "rating": 1289.3270561402342,
            "rating_q975": 1293.6574182502989,
            "rating_q025": 1284.9966940301692
        },
        "qwen2.5-72b-instruct": {
            "rating": 1289.1641626398082,
            "rating_q975": 1294.3003250948223,
            "rating_q025": 1284.0280001847939
        },
        "gemini-1.5-flash-002": {
            "rating": 1288.2390860830124,
            "rating_q975": 1293.6100585298243,
            "rating_q025": 1282.8681136362006
        },
        "llama-3.3-70b-instruct": {
            "rating": 1287.717809232459,
            "rating_q975": 1292.5024500825698,
            "rating_q025": 1282.9331683823484
        },
        "deepseek-v2.5": {
            "rating": 1287.4550832502382,
            "rating_q975": 1293.5472811594864,
            "rating_q025": 1281.3628853409903
        },
        "hunyuan-large-vision": {
            "rating": 1287.0842029808846,
            "rating_q975": 1302.6435256621064,
            "rating_q025": 1271.5248802996628
        },
        "gemma-3n-e4b-it": {
            "rating": 1286.8611027453044,
            "rating_q975": 1295.9092536750527,
            "rating_q025": 1277.812951815556
        },
        "gpt-4-0125-preview": {
            "rating": 1285.2305284229928,
            "rating_q975": 1290.486036340325,
            "rating_q025": 1279.9750205056607
        },
        "mistral-small-3.1-24b-instruct-2503": {
            "rating": 1282.7177494423972,
            "rating_q975": 1291.4967190438422,
            "rating_q025": 1273.9387798409525
        },
        "grok-2-mini-2024-08-13": {
            "rating": 1279.7503539486074,
            "rating_q975": 1284.4993119731532,
            "rating_q025": 1275.0013959240619
        },
        "llama-3.1-nemotron-70b-instruct": {
            "rating": 1277.3390890106648,
            "rating_q975": 1287.4560013197324,
            "rating_q025": 1267.222176701597
        },
        "hunyuan-standard-2025-02-10": {
            "rating": 1276.8592409531238,
            "rating_q975": 1291.7676001824968,
            "rating_q025": 1261.9508817237506
        },
        "gpt-4-0314": {
            "rating": 1275.8227647790684,
            "rating_q975": 1282.7113220464346,
            "rating_q025": 1268.9342075117022
        },
        "amazon-nova-pro-v1.0": {
            "rating": 1272.6093780352262,
            "rating_q975": 1278.4863487474408,
            "rating_q025": 1266.7324073230116
        },
        "athene-70b-0725": {
            "rating": 1272.4969032931717,
            "rating_q975": 1279.7854311845574,
            "rating_q025": 1265.2083754017863
        },
        "llama-3.1-tulu-3-70b": {
            "rating": 1271.1775153092908,
            "rating_q975": 1285.9301485191577,
            "rating_q025": 1256.424882099424
        },
        "llama-3.1-70b-instruct": {
            "rating": 1269.975480736442,
            "rating_q975": 1274.731642161793,
            "rating_q025": 1265.219319311091
        },
        "gpt-4-0613": {
            "rating": 1267.5169746348386,
            "rating_q975": 1273.1474946678943,
            "rating_q025": 1261.8864546017828
        },
        "gemma-3-4b-it": {
            "rating": 1266.6597722354245,
            "rating_q975": 1282.3986559011882,
            "rating_q025": 1250.9208885696605
        },
        "gemma-2-27b-it": {
            "rating": 1264.4014641753356,
            "rating_q975": 1268.6398130111472,
            "rating_q025": 1260.1631153395242
        },
        "jamba-1.5-large": {
            "rating": 1262.511711947598,
            "rating_q975": 1272.6927370691558,
            "rating_q025": 1252.3306868260406
        },
        "qwen2.5-coder-32b-instruct": {
            "rating": 1262.075524650038,
            "rating_q975": 1273.076697283371,
            "rating_q025": 1251.074352016705
        },
        "claude-3-sonnet-20240229": {
            "rating": 1262.0522652287987,
            "rating_q975": 1267.2590638149118,
            "rating_q025": 1256.8454666426858
        },
        "gemini-1.5-flash-001": {
            "rating": 1259.6491813875216,
            "rating_q975": 1265.155234424556,
            "rating_q025": 1254.1431283504871
        },
        "reka-core-20240904": {
            "rating": 1258.3971473746699,
            "rating_q975": 1267.7289516464632,
            "rating_q025": 1249.0653431028768
        },
        "llama-3.1-nemotron-51b-instruct": {
            "rating": 1256.9444800611323,
            "rating_q975": 1270.8762609605526,
            "rating_q025": 1243.012699161712
        },
        "nemotron-4-340b-instruct": {
            "rating": 1255.0947673427363,
            "rating_q975": 1262.8124449065874,
            "rating_q025": 1247.377089778885
        },
        "glm-4-0520": {
            "rating": 1253.687242084109,
            "rating_q975": 1263.5233271738969,
            "rating_q025": 1243.851156994321
        },
        "llama-3-70b-instruct": {
            "rating": 1252.8414928807738,
            "rating_q975": 1257.6740046267205,
            "rating_q025": 1248.008981134827
        },
        "mistral-small-24b-instruct-2501": {
            "rating": 1252.7592539218044,
            "rating_q975": 1260.6341486618503,
            "rating_q025": 1244.8843591817586
        },
        "command-r-plus-08-2024": {
            "rating": 1249.8533223730847,
            "rating_q975": 1258.5608448746516,
            "rating_q025": 1241.145799871518
        },
        "gemma-2-9b-it-simpo": {
            "rating": 1246.2835262517315,
            "rating_q975": 1255.8849028099446,
            "rating_q025": 1236.6821496935186
        },
        "deepseek-coder-v2": {
            "rating": 1246.085966648941,
            "rating_q975": 1254.6841797261297,
            "rating_q025": 1237.4877535717524
        },
        "c4ai-aya-expanse-32b": {
            "rating": 1245.9281117340283,
            "rating_q975": 1252.073184280218,
            "rating_q025": 1239.783039187839
        },
        "reka-flash-20240904": {
            "rating": 1245.353832353121,
            "rating_q975": 1254.7256521129343,
            "rating_q025": 1235.982012593308
        },
        "amazon-nova-lite-v1.0": {
            "rating": 1243.3181663715775,
            "rating_q975": 1249.918833432743,
            "rating_q025": 1236.717499310412
        },
        "phi-4": {
            "rating": 1242.977509634,
            "rating_q975": 1249.1908878715942,
            "rating_q025": 1236.7641313964054
        },
        "hunyuan-standard-256k": {
            "rating": 1241.8998817550403,
            "rating_q975": 1257.7238025805011,
            "rating_q025": 1226.0759609295794
        },
        "claude-3-haiku-20240307": {
            "rating": 1239.9389113044058,
            "rating_q975": 1244.7707996881434,
            "rating_q025": 1235.107022920668
        },
        "gemma-2-9b-it": {
            "rating": 1239.3104437353081,
            "rating_q975": 1244.0737182439123,
            "rating_q025": 1234.547169226704
        },
        "qwen2-72b-instruct": {
            "rating": 1237.8535705813922,
            "rating_q975": 1244.2051176484622,
            "rating_q025": 1231.502023514322
        },
        "gemini-1.5-flash-8b-001": {
            "rating": 1237.60173149288,
            "rating_q975": 1243.015447646948,
            "rating_q025": 1232.1880153388124
        },
        "command-r-plus": {
            "rating": 1236.7996493434257,
            "rating_q975": 1242.41947344247,
            "rating_q025": 1231.1798252443816
        },
        "command-r-08-2024": {
            "rating": 1232.566575249983,
            "rating_q975": 1241.1336243207452,
            "rating_q025": 1223.9995261792208
        },
        "mistral-large-2402": {
            "rating": 1231.9120647971,
            "rating_q975": 1238.1304072161483,
            "rating_q025": 1225.6937223780517
        },
        "olmo-2-0325-32b-instruct": {
            "rating": 1226.9961455400319,
            "rating_q975": 1243.6899544426287,
            "rating_q025": 1210.302336637435
        },
        "amazon-nova-micro-v1.0": {
            "rating": 1216.5665501104522,
            "rating_q975": 1223.132980297075,
            "rating_q025": 1210.0001199238295
        },
        "qwen1.5-110b-chat": {
            "rating": 1214.7968447682997,
            "rating_q975": 1222.468253616089,
            "rating_q025": 1207.1254359205102
        },
        "ministral-8b-2410": {
            "rating": 1211.7650250768936,
            "rating_q975": 1223.462257722776,
            "rating_q025": 1200.0677924310112
        },
        "mixtral-8x22b-instruct-v0.1": {
            "rating": 1210.09165320676,
            "rating_q975": 1216.1926206108726,
            "rating_q025": 1203.9906858026472
        },
        "llama-3.1-tulu-3-8b": {
            "rating": 1208.756682883553,
            "rating_q975": 1223.5864436413917,
            "rating_q025": 1193.9269221257143
        },
        "mistral-medium": {
            "rating": 1208.1486899724553,
            "rating_q975": 1215.9965952841937,
            "rating_q025": 1200.3007846607165
        },
        "gemini-pro": {
            "rating": 1207.58079126459,
            "rating_q975": 1223.932004725222,
            "rating_q025": 1191.2295778039584
        },
        "qwen1.5-72b-chat": {
            "rating": 1206.7227293975884,
            "rating_q975": 1213.7340967036612,
            "rating_q025": 1199.7113620915154
        },
        "gpt-3.5-turbo-0125": {
            "rating": 1206.1081422778855,
            "rating_q975": 1212.0712229656137,
            "rating_q025": 1200.1450615901572
        },
        "c4ai-aya-expanse-8b": {
            "rating": 1205.097539946497,
            "rating_q975": 1214.021799328698,
            "rating_q025": 1196.173280564296
        },
        "jamba-1.5-mini": {
            "rating": 1201.1137431026045,
            "rating_q975": 1211.2884676143929,
            "rating_q025": 1190.9390185908162
        },
        "gemini-pro-dev-api": {
            "rating": 1199.5832835077563,
            "rating_q975": 1209.8180485995058,
            "rating_q025": 1189.3485184160065
        },
        "reka-flash-21b-20240226-online": {
            "rating": 1197.5656258078607,
            "rating_q975": 1207.5027644195648,
            "rating_q025": 1187.6284871961568
        },
        "command-r": {
            "rating": 1195.070803117073,
            "rating_q975": 1201.3975788212597,
            "rating_q025": 1188.7440274128865
        },
        "llama-3.1-8b-instruct": {
            "rating": 1193.056306374853,
            "rating_q975": 1198.0664743809682,
            "rating_q025": 1188.0461383687377
        },
        "granite-3.1-8b-instruct": {
            "rating": 1192.1716403277812,
            "rating_q975": 1207.7383699581187,
            "rating_q025": 1176.6049106974438
        },
        "llama-3-8b-instruct": {
            "rating": 1188.5510481522756,
            "rating_q975": 1193.769072064814,
            "rating_q025": 1183.3330242397374
        },
        "zephyr-orpo-141b-A35b-v0.1": {
            "rating": 1188.2574000558154,
            "rating_q975": 1203.3687717161667,
            "rating_q025": 1173.1460283954643
        },
        "reka-flash-21b-20240226": {
            "rating": 1187.896261027587,
            "rating_q975": 1195.968352457177,
            "rating_q025": 1179.8241695979968
        },
        "yi-1.5-34b-chat": {
            "rating": 1187.0420102855055,
            "rating_q975": 1194.333440405974,
            "rating_q025": 1179.750580165037
        },
        "gpt-3.5-turbo-1106": {
            "rating": 1186.6789921746456,
            "rating_q975": 1198.5086142354794,
            "rating_q025": 1174.849370113812
        },
        "internlm2_5-20b-chat": {
            "rating": 1184.2010646090232,
            "rating_q975": 1193.5547396909235,
            "rating_q025": 1174.8473895271231
        },
        "dbrx-instruct-preview": {
            "rating": 1182.271300967267,
            "rating_q975": 1190.3733142428325,
            "rating_q025": 1174.1692876917014
        },
        "qwen1.5-32b-chat": {
            "rating": 1181.1495172483894,
            "rating_q975": 1189.3171228393994,
            "rating_q025": 1172.9819116573794
        },
        "mixtral-8x7b-instruct-v0.1": {
            "rating": 1176.5107130109984,
            "rating_q975": 1182.3867602538978,
            "rating_q025": 1170.634665768099
        },
        "phi-3-medium-4k-instruct": {
            "rating": 1174.5105919372672,
            "rating_q975": 1181.4509694030914,
            "rating_q025": 1167.5702144714428
        },
        "granite-3.1-2b-instruct": {
            "rating": 1171.4814268643695,
            "rating_q975": 1186.8654108270487,
            "rating_q025": 1156.0974429016906
        },
        "gemma-2-2b-it": {
            "rating": 1171.3360528457263,
            "rating_q975": 1176.459525591378,
            "rating_q025": 1166.2125801000745
        },
        "granite-3.0-8b-instruct": {
            "rating": 1170.9855861658111,
            "rating_q975": 1182.4533076228847,
            "rating_q025": 1159.5178647087378
        },
        "tulu-2-dpo-70b": {
            "rating": 1168.092856918261,
            "rating_q975": 1182.5407664562465,
            "rating_q025": 1153.6449473802754
        },
        "qwen1.5-14b-chat": {
            "rating": 1164.7703283863693,
            "rating_q975": 1174.3240591327406,
            "rating_q025": 1155.2165976399983
        },
        "qwq-32b-preview": {
            "rating": 1162.4724016501114,
            "rating_q975": 1177.4571043648011,
            "rating_q025": 1147.4876989354213
        },
        "wizardlm-70b": {
            "rating": 1158.7945535020965,
            "rating_q975": 1171.9970806457234,
            "rating_q025": 1145.5920263584696
        },
        "deepseek-llm-67b-chat": {
            "rating": 1151.6252752025418,
            "rating_q975": 1168.3012273883214,
            "rating_q025": 1134.9493230167625
        },
        "phi-3-small-8k-instruct": {
            "rating": 1151.4925944778433,
            "rating_q975": 1159.784534593338,
            "rating_q025": 1143.2006543623484
        },
        "openchat-3.5-0106": {
            "rating": 1150.5222048951255,
            "rating_q975": 1160.7128410857758,
            "rating_q025": 1140.331568704475
        },
        "yi-34b-chat": {
            "rating": 1149.5209273010578,
            "rating_q975": 1158.890959469217,
            "rating_q025": 1140.1508951328983
        },
        "snowflake-arctic-instruct": {
            "rating": 1147.7307304884373,
            "rating_q975": 1155.8153210794333,
            "rating_q025": 1139.6461398974413
        },
        "openchat-3.5": {
            "rating": 1147.3884621827706,
            "rating_q975": 1161.3199447323277,
            "rating_q025": 1133.4569796332137
        },
        "llama-3.2-3b-instruct": {
            "rating": 1147.2731280764422,
            "rating_q975": 1157.6174192545557,
            "rating_q025": 1136.9288368983287
        },
        "openhermes-2.5-mistral-7b": {
            "rating": 1147.0798360447689,
            "rating_q975": 1162.2212883747243,
            "rating_q025": 1131.9383837148132
        },
        "gemma-1.1-7b-it": {
            "rating": 1146.6439881858544,
            "rating_q975": 1154.2118378464988,
            "rating_q025": 1139.07613852521
        },
        "starling-lm-7b-beta": {
            "rating": 1146.33793161438,
            "rating_q975": 1156.0285685202368,
            "rating_q025": 1136.647294708523
        },
        "granite-3.0-2b-instruct": {
            "rating": 1135.5810032164152,
            "rating_q975": 1147.202227976142,
            "rating_q025": 1123.9597784566884
        },
        "vicuna-33b": {
            "rating": 1135.332863904282,
            "rating_q975": 1144.0191822077004,
            "rating_q025": 1126.6465456008634
        },
        "starling-lm-7b-alpha": {
            "rating": 1133.3881150112384,
            "rating_q975": 1144.585065190509,
            "rating_q025": 1122.1911648319679
        },
        "llama-2-70b-chat": {
            "rating": 1132.9435444042629,
            "rating_q975": 1140.2676500804869,
            "rating_q025": 1125.6194387280386
        },
        "mpt-30b-chat": {
            "rating": 1129.7347387085347,
            "rating_q975": 1150.5068081842537,
            "rating_q025": 1108.9626692328156
        },
        "falcon-180b-chat": {
            "rating": 1129.319857814777,
            "rating_q975": 1157.8271127558312,
            "rating_q025": 1100.8126028737227
        },
        "dolphin-2.2.1-mistral-7b": {
            "rating": 1124.7196418640287,
            "rating_q975": 1149.1037632599566,
            "rating_q025": 1100.3355204681009
        },
        "phi-3-mini-4k-instruct-june-2024": {
            "rating": 1123.7153501306616,
            "rating_q975": 1132.899996626029,
            "rating_q025": 1114.5307036352942
        },
        "llama2-70b-steerlm-chat": {
            "rating": 1122.6410500180318,
            "rating_q975": 1140.7234753368339,
            "rating_q025": 1104.5586246992295
        },
        "mistral-7b-instruct-v0.2": {
            "rating": 1122.0012318546264,
            "rating_q975": 1130.6282057782191,
            "rating_q025": 1113.3742579310338
        },
        "qwen1.5-7b-chat": {
            "rating": 1120.7563061827757,
            "rating_q975": 1134.5043740627248,
            "rating_q025": 1107.0082383028266
        },
        "smollm2-1.7b-instruct": {
            "rating": 1119.3023783118415,
            "rating_q975": 1138.22265463059,
            "rating_q025": 1100.382101993093
        },
        "wizardlm-13b": {
            "rating": 1119.1052790116357,
            "rating_q975": 1132.8127782933102,
            "rating_q025": 1105.3977797299613
        },
        "solar-10.7b-instruct-v1.0": {
            "rating": 1114.686169246035,
            "rating_q975": 1132.971710484187,
            "rating_q025": 1096.400628007883
        },
        "vicuna-13b": {
            "rating": 1111.7703711227587,
            "rating_q975": 1121.040806080242,
            "rating_q025": 1102.4999361652751
        },
        "qwen-14b-chat": {
            "rating": 1111.765389710109,
            "rating_q975": 1127.9558028871475,
            "rating_q025": 1095.5749765330704
        },
        "phi-3-mini-4k-instruct": {
            "rating": 1111.4131777638622,
            "rating_q975": 1119.853740383297,
            "rating_q025": 1102.9726151444274
        },
        "llama-2-13b-chat": {
            "rating": 1108.7686580792874,
            "rating_q975": 1117.7840409755415,
            "rating_q025": 1099.7532751830333
        },
        "nous-hermes-2-mixtral-8x7b-dpo": {
            "rating": 1108.4504026787063,
            "rating_q975": 1124.5579926892337,
            "rating_q025": 1092.3428126681788
        },
        "palm-2": {
            "rating": 1104.6876136574726,
            "rating_q975": 1117.8899172989495,
            "rating_q025": 1091.4853100159958
        },
        "codellama-34b-instruct": {
            "rating": 1099.7076453109805,
            "rating_q975": 1112.462181584026,
            "rating_q025": 1086.953109037935
        },
        "phi-3-mini-128k-instruct": {
            "rating": 1098.4074606176168,
            "rating_q975": 1108.2230373493794,
            "rating_q025": 1088.591883885854
        },
        "zephyr-7b-alpha": {
            "rating": 1097.4933825323633,
            "rating_q975": 1121.8979949045681,
            "rating_q025": 1073.0887701601582
        },
        "gemma-7b-it": {
            "rating": 1096.7148908686395,
            "rating_q975": 1109.1838907633373,
            "rating_q025": 1084.2458909739416
        },
        "codellama-70b-instruct": {
            "rating": 1094.2759576117232,
            "rating_q975": 1123.2959562371732,
            "rating_q025": 1065.255958986273
        },
        "llama-3.2-1b-instruct": {
            "rating": 1091.6088334951367,
            "rating_q975": 1102.1958845735317,
            "rating_q025": 1081.0217824167416
        },
        "gemma-1.1-2b-it": {
            "rating": 1091.0962976674855,
            "rating_q975": 1101.5907646367125,
            "rating_q025": 1080.6018306982583
        },
        "zephyr-7b-beta": {
            "rating": 1087.6526601028302,
            "rating_q975": 1100.1648241534526,
            "rating_q025": 1075.1404960522077
        },
        "stripedhyena-nous-7b": {
            "rating": 1085.1544884700743,
            "rating_q975": 1100.1733414792216,
            "rating_q025": 1070.1356354609272
        },
        "mistral-7b-instruct": {
            "rating": 1081.9251851681552,
            "rating_q975": 1095.2976975059364,
            "rating_q025": 1068.5526728303737
        },
        "vicuna-7b": {
            "rating": 1072.0313016851865,
            "rating_q975": 1085.9982574890269,
            "rating_q025": 1058.064345881346
        },
        "llama-2-7b-chat": {
            "rating": 1068.0832571513433,
            "rating_q975": 1077.6254565576357,
            "rating_q025": 1058.5410577450507
        },
        "qwen1.5-4b-chat": {
            "rating": 1063.7692060788543,
            "rating_q975": 1076.3583702117392,
            "rating_q025": 1051.1800419459694
        },
        "gemma-2b-it": {
            "rating": 1061.961146650967,
            "rating_q975": 1077.7069628443332,
            "rating_q025": 1046.2153304576009
        },
        "guanaco-33b": {
            "rating": 1061.5527464177533,
            "rating_q975": 1082.2358790992578,
            "rating_q025": 1040.869613736249
        },
        "chatglm3-6b": {
            "rating": 1032.0017600020426,
            "rating_q975": 1049.2519959549397,
            "rating_q025": 1014.7515240491455
        },
        "olmo-7b-instruct": {
            "rating": 1031.5941322755273,
            "rating_q975": 1047.2289502238336,
            "rating_q025": 1015.9593143272208
        },
        "gpt4all-13b-snoozy": {
            "rating": 1030.8859006479693,
            "rating_q975": 1055.5389522124535,
            "rating_q025": 1006.2328490834848
        },
        "koala-13b": {
            "rating": 1021.1345969427389,
            "rating_q975": 1036.3081102415888,
            "rating_q025": 1005.961083643889
        },
        "alpaca-13b": {
            "rating": 1009.1521162857358,
            "rating_q975": 1025.2588135919084,
            "rating_q025": 993.0454189795632
        },
        "mpt-7b-chat": {
            "rating": 1002.1933359790987,
            "rating_q975": 1020.4088363098226,
            "rating_q025": 983.9778356483748
        },
        "chatglm2-6b": {
            "rating": 979.390870932874,
            "rating_q975": 1001.7564450478709,
            "rating_q025": 957.0252968178771
        },
        "oasst-pythia-12b": {
            "rating": 977.219784184768,
            "rating_q975": 993.1417252442668,
            "rating_q025": 961.2978431252691
        },
        "chatglm-6b": {
            "rating": 973.9206556448538,
            "rating_q975": 991.7353236378979,
            "rating_q025": 956.1059876518098
        },
        "RWKV-4-Raven-14B": {
            "rating": 964.2324112866577,
            "rating_q975": 980.961957184098,
            "rating_q025": 947.5028653892175
        },
        "fastchat-t5-3b": {
            "rating": 949.3391915077812,
            "rating_q975": 967.7919998068797,
            "rating_q025": 930.8863832086824
        },
        "dolly-v2-12b": {
            "rating": 925.8998020175861,
            "rating_q975": 946.9450974381557,
            "rating_q025": 904.8545065970167
        },
        "stablelm-tuned-alpha-7b": {
            "rating": 905.6500365888312,
            "rating_q975": 925.8537739202454,
            "rating_q025": 885.446299257417
        },
        "llama-13b": {
            "rating": 901.5865321890258,
            "rating_q975": 926.7409845354609,
            "rating_q025": 876.4320798425907
        }
    },
    "japanese": {
        "gpt-5-high": {
            "rating": 1463.0951760801827,
            "rating_q975": 1489.3393586585855,
            "rating_q025": 1436.8509935017798
        },
        "gemini-2.5-pro": {
            "rating": 1458.9501891101502,
            "rating_q975": 1480.1766517391216,
            "rating_q025": 1437.7237264811788
        },
        "o3-2025-04-16": {
            "rating": 1439.4601302830104,
            "rating_q975": 1458.944601971221,
            "rating_q025": 1419.9756585948
        },
        "gpt-4.5-preview-2025-02-27": {
            "rating": 1433.8778189683285,
            "rating_q975": 1470.1443284242841,
            "rating_q025": 1397.6113095123728
        },
        "claude-opus-4-1-20250805-thinking-16k": {
            "rating": 1427.3272813600317,
            "rating_q975": 1474.8549028952389,
            "rating_q025": 1379.7996598248244
        },
        "chatgpt-4o-latest-20250326": {
            "rating": 1412.0988707059505,
            "rating_q975": 1434.2907176628903,
            "rating_q025": 1389.9070237490107
        },
        "gpt-5-chat": {
            "rating": 1410.1389082448782,
            "rating_q975": 1458.8075712348077,
            "rating_q025": 1361.4702452549486
        },
        "gemini-2.5-flash": {
            "rating": 1390.5391132666662,
            "rating_q975": 1409.6877218881107,
            "rating_q025": 1371.3905046452219
        },
        "grok-4-0709": {
            "rating": 1387.9897189697226,
            "rating_q975": 1411.7748681179876,
            "rating_q025": 1364.2045698214577
        },
        "glm-4.5": {
            "rating": 1382.9817335888883,
            "rating_q975": 1409.7425650566158,
            "rating_q025": 1356.2209021211606
        },
        "claude-opus-4-20250514-thinking-16k": {
            "rating": 1382.21294816883,
            "rating_q975": 1407.1711459947794,
            "rating_q025": 1357.2547503428807
        },
        "kimi-k2-0711-preview": {
            "rating": 1381.8720640066244,
            "rating_q975": 1404.1556885078605,
            "rating_q025": 1359.5884395053884
        },
        "claude-opus-4-1-20250805": {
            "rating": 1381.8706893407495,
            "rating_q975": 1414.9219684013008,
            "rating_q025": 1348.819410280198
        },
        "deepseek-r1-0528": {
            "rating": 1378.7377690569447,
            "rating_q975": 1402.8392627835383,
            "rating_q025": 1354.6362753303508
        },
        "grok-3-preview-02-24": {
            "rating": 1375.7855764242593,
            "rating_q975": 1395.8831958488256,
            "rating_q025": 1355.687956999693
        },
        "qwen3-235b-a22b-no-thinking": {
            "rating": 1375.463496375333,
            "rating_q975": 1398.7691301472953,
            "rating_q025": 1352.1578626033706
        },
        "o1-2024-12-17": {
            "rating": 1373.1908736377736,
            "rating_q975": 1397.383024160105,
            "rating_q025": 1348.9987231154425
        },
        "qwen3-235b-a22b-thinking-2507": {
            "rating": 1368.125598496847,
            "rating_q975": 1397.1183204704378,
            "rating_q025": 1339.132876523256
        },
        "claude-opus-4-20250514": {
            "rating": 1367.1135682712538,
            "rating_q975": 1388.4127109108072,
            "rating_q025": 1345.8144256317007
        },
        "qwen3-235b-a22b-instruct-2507": {
            "rating": 1361.3172462358477,
            "rating_q975": 1387.128045534244,
            "rating_q025": 1335.5064469374515
        },
        "o1-preview": {
            "rating": 1358.4488695915422,
            "rating_q975": 1379.7140314726003,
            "rating_q025": 1337.1837077104842
        },
        "qwen3-30b-a3b-instruct-2507": {
            "rating": 1354.2037385134026,
            "rating_q975": 1381.7737719694055,
            "rating_q025": 1326.6337050573995
        },
        "o4-mini-2025-04-16": {
            "rating": 1350.6524188474566,
            "rating_q975": 1371.904734543573,
            "rating_q025": 1329.4001031513399
        },
        "gpt-4.1-2025-04-14": {
            "rating": 1347.4588274186237,
            "rating_q975": 1368.976153437397,
            "rating_q025": 1325.9415013998505
        },
        "claude-sonnet-4-20250514": {
            "rating": 1343.6868501391552,
            "rating_q975": 1365.6180959544017,
            "rating_q025": 1321.755604323909
        },
        "claude-3-7-sonnet-20250219-thinking-32k": {
            "rating": 1341.0675627214935,
            "rating_q975": 1360.4076617721034,
            "rating_q025": 1321.7274636708835
        },
        "deepseek-r1": {
            "rating": 1340.5735775006806,
            "rating_q975": 1364.965056864173,
            "rating_q025": 1316.1820981371882
        },
        "hunyuan-turbos-20250416": {
            "rating": 1340.2375576951138,
            "rating_q975": 1371.392580350895,
            "rating_q025": 1309.0825350393325
        },
        "gpt-oss-120b": {
            "rating": 1332.9478244247848,
            "rating_q975": 1373.4581791359353,
            "rating_q025": 1292.4374697136343
        },
        "claude-sonnet-4-20250514-thinking-32k": {
            "rating": 1331.0786097813443,
            "rating_q975": 1355.8297670717732,
            "rating_q025": 1306.3274524909154
        },
        "glm-4.5-air": {
            "rating": 1329.4101130309994,
            "rating_q975": 1355.6225073503288,
            "rating_q025": 1303.19771871167
        },
        "deepseek-v3-0324": {
            "rating": 1329.000765805777,
            "rating_q975": 1349.8615021558367,
            "rating_q025": 1308.1400294557175
        },
        "gpt-4.1-mini-2025-04-14": {
            "rating": 1327.0537160692431,
            "rating_q975": 1348.0978521804186,
            "rating_q025": 1306.0095799580677
        },
        "grok-3-mini-beta": {
            "rating": 1325.660136209728,
            "rating_q975": 1349.1767824732308,
            "rating_q025": 1302.1434899462251
        },
        "claude-3-7-sonnet-20250219": {
            "rating": 1325.161715195137,
            "rating_q975": 1344.1207638537367,
            "rating_q025": 1306.2026665365377
        },
        "qwen3-coder-480b-a35b-instruct": {
            "rating": 1324.1337275985454,
            "rating_q975": 1346.4169519675868,
            "rating_q025": 1301.850503229504
        },
        "gemini-2.0-flash-lite-preview-02-05": {
            "rating": 1322.789112024769,
            "rating_q975": 1346.2488177117511,
            "rating_q025": 1299.329406337787
        },
        "grok-3-mini-high": {
            "rating": 1322.5320587014419,
            "rating_q975": 1349.0064707276033,
            "rating_q025": 1296.0576466752805
        },
        "mistral-medium-2505": {
            "rating": 1320.3264194114777,
            "rating_q975": 1340.708913538575,
            "rating_q025": 1299.9439252843806
        },
        "gemini-1.5-pro-002": {
            "rating": 1320.1183108064529,
            "rating_q975": 1335.6154801159626,
            "rating_q025": 1304.6211414969432
        },
        "qwen2.5-max": {
            "rating": 1315.5861205578633,
            "rating_q975": 1335.8928163145947,
            "rating_q025": 1295.2794248011319
        },
        "qwen3-235b-a22b": {
            "rating": 1314.1493231578447,
            "rating_q975": 1336.7258836085564,
            "rating_q025": 1291.5727627071333
        },
        "o3-mini-high": {
            "rating": 1313.2491721854146,
            "rating_q975": 1341.3359634429075,
            "rating_q025": 1285.1623809279215
        },
        "command-a-03-2025": {
            "rating": 1312.3060287103017,
            "rating_q975": 1332.4474976055212,
            "rating_q025": 1292.1645598150824
        },
        "gemma-3-27b-it": {
            "rating": 1310.2365689386095,
            "rating_q975": 1330.2706588151116,
            "rating_q025": 1290.2024790621074
        },
        "claude-3-5-sonnet-20241022": {
            "rating": 1306.9514987914158,
            "rating_q975": 1319.7932935209112,
            "rating_q025": 1294.1097040619206
        },
        "gemini-2.0-flash-001": {
            "rating": 1306.184709398885,
            "rating_q975": 1324.6415091297267,
            "rating_q025": 1287.727909668043
        },
        "gpt-4o-2024-05-13": {
            "rating": 1304.3600887626023,
            "rating_q975": 1316.645160447321,
            "rating_q025": 1292.0750170778836
        },
        "mistral-small-2506": {
            "rating": 1301.481868487157,
            "rating_q975": 1326.9246095786057,
            "rating_q025": 1276.0391273957084
        },
        "o3-mini": {
            "rating": 1299.7594352789106,
            "rating_q975": 1316.5796935303579,
            "rating_q025": 1282.9391770274635
        },
        "gemma-3n-e4b-it": {
            "rating": 1297.2830885760345,
            "rating_q975": 1321.5980200819288,
            "rating_q025": 1272.9681570701403
        },
        "deepseek-v3": {
            "rating": 1294.5548163335313,
            "rating_q975": 1316.7461642858286,
            "rating_q025": 1272.3634683812343
        },
        "gpt-4o-2024-08-06": {
            "rating": 1293.4347069905957,
            "rating_q975": 1309.714780211988,
            "rating_q025": 1277.1546337692034
        },
        "gemini-advanced-0514": {
            "rating": 1287.5159559958797,
            "rating_q975": 1305.285040839679,
            "rating_q025": 1269.7468711520808
        },
        "nvidia-llama-3.3-nemotron-super-49b-v1.5": {
            "rating": 1287.067201959174,
            "rating_q975": 1316.255764610522,
            "rating_q025": 1257.878639307826
        },
        "claude-3-5-sonnet-20240620": {
            "rating": 1286.5385254323749,
            "rating_q975": 1299.6293898707752,
            "rating_q025": 1273.4476609939745
        },
        "gemini-1.5-pro-001": {
            "rating": 1283.1573708611836,
            "rating_q975": 1296.900803357114,
            "rating_q025": 1269.413938365253
        },
        "o1-mini": {
            "rating": 1280.0528827083683,
            "rating_q975": 1296.076790852735,
            "rating_q025": 1264.0289745640014
        },
        "qwen-plus-0125": {
            "rating": 1276.636471534387,
            "rating_q975": 1312.7027148945965,
            "rating_q025": 1240.5702281741774
        },
        "amazon-nova-experimental-chat-05-14": {
            "rating": 1274.3183686542657,
            "rating_q975": 1300.0657833037594,
            "rating_q025": 1248.5709540047721
        },
        "llama-3.1-405b-instruct-bf16": {
            "rating": 1274.1726135047425,
            "rating_q975": 1292.6094925967723,
            "rating_q025": 1255.7357344127126
        },
        "grok-2-2024-08-13": {
            "rating": 1271.2584347005616,
            "rating_q975": 1285.1349802606123,
            "rating_q025": 1257.3818891405106
        },
        "gemini-1.5-flash-002": {
            "rating": 1267.0603392898645,
            "rating_q975": 1286.7497834163332,
            "rating_q025": 1247.3708951633957
        },
        "gpt-oss-20b": {
            "rating": 1266.2006191170308,
            "rating_q975": 1308.5942435586467,
            "rating_q025": 1223.8069946754154
        },
        "claude-3-opus-20240229": {
            "rating": 1265.5713551955232,
            "rating_q975": 1276.7702302260193,
            "rating_q025": 1254.3724801650271
        },
        "yi-lightning": {
            "rating": 1260.6552868429983,
            "rating_q975": 1282.3877723972805,
            "rating_q025": 1238.922801288716
        },
        "llama-4-scout-17b-16e-instruct": {
            "rating": 1259.1364433227818,
            "rating_q975": 1283.4509457729323,
            "rating_q025": 1234.8219408726316
        },
        "step-1o-turbo-202506": {
            "rating": 1257.1183213509535,
            "rating_q975": 1296.5743678142308,
            "rating_q025": 1217.6622748876764
        },
        "gpt-4-1106-preview": {
            "rating": 1255.7355238173595,
            "rating_q975": 1270.2677723841364,
            "rating_q025": 1241.2032752505827
        },
        "qwen3-30b-a3b": {
            "rating": 1253.6948846830765,
            "rating_q975": 1276.099699004522,
            "rating_q025": 1231.2900703616306
        },
        "gpt-4o-mini-2024-07-18": {
            "rating": 1253.1061803020343,
            "rating_q975": 1265.801531654774,
            "rating_q025": 1240.410828949295
        },
        "gpt-4-0125-preview": {
            "rating": 1252.949204907277,
            "rating_q975": 1268.2211793219421,
            "rating_q025": 1237.677230492612
        },
        "deepseek-v2.5-1210": {
            "rating": 1252.7716766042067,
            "rating_q975": 1290.7839094874455,
            "rating_q025": 1214.7594437209677
        },
        "gpt-4-turbo-2024-04-09": {
            "rating": 1251.9808293667406,
            "rating_q975": 1265.1777753410997,
            "rating_q025": 1238.7838833923815
        },
        "llama-4-maverick-17b-128e-instruct": {
            "rating": 1251.5967472730872,
            "rating_q975": 1274.8214594522906,
            "rating_q025": 1228.3720350938838
        },
        "mistral-small-3.1-24b-instruct-2503": {
            "rating": 1250.6969890541536,
            "rating_q975": 1275.1624769004372,
            "rating_q025": 1226.2315012078702
        },
        "qwq-32b": {
            "rating": 1249.312755413052,
            "rating_q975": 1273.8029777311015,
            "rating_q025": 1224.8225330950022
        },
        "claude-3-5-haiku-20241022": {
            "rating": 1246.9607742124977,
            "rating_q975": 1263.0439392606322,
            "rating_q025": 1230.8776091643633
        },
        "qwen-max-0919": {
            "rating": 1245.3551638130232,
            "rating_q975": 1275.1022544421699,
            "rating_q025": 1215.6080731838767
        },
        "llama-3.1-405b-instruct-fp8": {
            "rating": 1242.0214196769402,
            "rating_q975": 1255.7831448987342,
            "rating_q025": 1228.2596944551465
        },
        "minimax-m1": {
            "rating": 1240.5233045248308,
            "rating_q975": 1264.4715604057833,
            "rating_q025": 1216.575048643878
        },
        "mistral-large-2407": {
            "rating": 1240.0253171640593,
            "rating_q975": 1254.6042987362246,
            "rating_q025": 1225.446335591894
        },
        "grok-2-mini-2024-08-13": {
            "rating": 1238.4485652857604,
            "rating_q975": 1253.5025628580252,
            "rating_q025": 1223.3945677134957
        },
        "reka-core-20240904": {
            "rating": 1238.3399308488981,
            "rating_q975": 1272.0660853565923,
            "rating_q025": 1204.613776341204
        },
        "qwen2.5-plus-1127": {
            "rating": 1237.8953354137734,
            "rating_q975": 1268.6531960217,
            "rating_q025": 1207.1374748058468
        },
        "glm-4-plus": {
            "rating": 1237.6719196870058,
            "rating_q975": 1261.661454206835,
            "rating_q025": 1213.682385167177
        },
        "athene-v2-chat": {
            "rating": 1237.3570139256753,
            "rating_q975": 1259.0620526184653,
            "rating_q025": 1215.6519752328857
        },
        "gpt-4.1-nano-2025-04-14": {
            "rating": 1235.6679202502676,
            "rating_q975": 1279.8452514028636,
            "rating_q025": 1191.4905890976715
        },
        "deepseek-v2.5": {
            "rating": 1234.4276445388455,
            "rating_q975": 1257.2428608728605,
            "rating_q025": 1211.6124282048304
        },
        "amazon-nova-pro-v1.0": {
            "rating": 1233.8605323482132,
            "rating_q975": 1257.64325586443,
            "rating_q025": 1210.077808831996
        },
        "glm-4-plus-0111": {
            "rating": 1232.9684212364918,
            "rating_q975": 1269.1718881593943,
            "rating_q025": 1196.7649543135892
        },
        "magistral-medium-2506": {
            "rating": 1231.8596637248766,
            "rating_q975": 1265.8166675199716,
            "rating_q025": 1197.9026599297815
        },
        "gemma-2-27b-it": {
            "rating": 1228.6779698756063,
            "rating_q975": 1241.3741809933908,
            "rating_q025": 1215.9817587578223
        },
        "gemini-1.5-flash-001": {
            "rating": 1224.2775857063511,
            "rating_q975": 1239.0459876625077,
            "rating_q025": 1209.5091837501943
        },
        "command-r-08-2024": {
            "rating": 1223.4670495653138,
            "rating_q975": 1252.0746896139312,
            "rating_q025": 1194.8594095166961
        },
        "command-r-plus": {
            "rating": 1221.8132047401778,
            "rating_q975": 1237.5458711844665,
            "rating_q025": 1206.0805382958888
        },
        "mistral-large-2411": {
            "rating": 1219.1754156299062,
            "rating_q975": 1240.1810316804658,
            "rating_q025": 1198.1697995793468
        },
        "llama-3.3-70b-instruct": {
            "rating": 1218.5615292274597,
            "rating_q975": 1235.543912860013,
            "rating_q025": 1201.5791455949065
        },
        "command-r-plus-08-2024": {
            "rating": 1217.0377385945553,
            "rating_q975": 1248.9925475647017,
            "rating_q025": 1185.0829296244092
        },
        "qwen2.5-72b-instruct": {
            "rating": 1215.898155668509,
            "rating_q975": 1234.5810630164283,
            "rating_q025": 1197.21524832059
        },
        "c4ai-aya-expanse-32b": {
            "rating": 1211.8449913812608,
            "rating_q975": 1232.8790290323643,
            "rating_q025": 1190.810953730157
        },
        "gpt-4-0314": {
            "rating": 1209.186166468918,
            "rating_q975": 1229.261559118591,
            "rating_q025": 1189.1107738192447
        },
        "claude-3-sonnet-20240229": {
            "rating": 1207.8019319401844,
            "rating_q975": 1222.857036710803,
            "rating_q025": 1192.746827169566
        },
        "deepseek-coder-v2": {
            "rating": 1207.2822810738762,
            "rating_q975": 1233.1109436720694,
            "rating_q025": 1181.4536184756828
        },
        "reka-flash-20240904": {
            "rating": 1205.468441072858,
            "rating_q975": 1237.9340600244218,
            "rating_q025": 1173.0028221212942
        },
        "gpt-4-0613": {
            "rating": 1203.0629605377048,
            "rating_q975": 1219.0299400382903,
            "rating_q025": 1187.0959810371191
        },
        "phi-4": {
            "rating": 1201.9773354533972,
            "rating_q975": 1227.4456245186063,
            "rating_q025": 1176.509046388188
        },
        "gemma-2-9b-it": {
            "rating": 1197.9677290641027,
            "rating_q975": 1212.4152683000952,
            "rating_q025": 1183.5201898281105
        },
        "gemma-2-9b-it-simpo": {
            "rating": 1195.8527641824742,
            "rating_q975": 1225.0512676768137,
            "rating_q025": 1166.6542606881349
        },
        "amazon-nova-lite-v1.0": {
            "rating": 1192.9709166033947,
            "rating_q975": 1218.602359048199,
            "rating_q025": 1167.3394741585903
        },
        "amazon-nova-micro-v1.0": {
            "rating": 1192.1253964173784,
            "rating_q975": 1216.8758540344802,
            "rating_q025": 1167.3749388002768
        },
        "athene-70b-0725": {
            "rating": 1190.1296539132304,
            "rating_q975": 1210.2098043685853,
            "rating_q025": 1170.0495034578753
        },
        "nemotron-4-340b-instruct": {
            "rating": 1186.4461269606304,
            "rating_q975": 1209.7356972686457,
            "rating_q025": 1163.156556652615
        },
        "qwen2-72b-instruct": {
            "rating": 1186.2402196970027,
            "rating_q975": 1204.6192315491442,
            "rating_q025": 1167.8612078448612
        },
        "jamba-1.5-large": {
            "rating": 1185.0039991797785,
            "rating_q975": 1218.7127807094523,
            "rating_q025": 1151.2952176501042
        },
        "llama-3.1-70b-instruct": {
            "rating": 1184.2131653371907,
            "rating_q975": 1198.3809007485224,
            "rating_q025": 1170.0454299258593
        },
        "glm-4-0520": {
            "rating": 1181.625647075548,
            "rating_q975": 1218.7538860929778,
            "rating_q025": 1144.497408058118
        },
        "claude-3-haiku-20240307": {
            "rating": 1180.2589074308466,
            "rating_q975": 1193.8871273772565,
            "rating_q025": 1166.630687484437
        },
        "gemini-1.5-flash-8b-001": {
            "rating": 1179.7879353877463,
            "rating_q975": 1200.0900048393332,
            "rating_q025": 1159.4858659361594
        },
        "command-r": {
            "rating": 1173.4829181161447,
            "rating_q975": 1192.5032944939635,
            "rating_q025": 1154.4625417383259
        },
        "c4ai-aya-expanse-8b": {
            "rating": 1169.3912977827706,
            "rating_q975": 1201.2528982954448,
            "rating_q025": 1137.5296972700964
        },
        "gpt-3.5-turbo-1106": {
            "rating": 1159.3765394335253,
            "rating_q975": 1191.3920909817716,
            "rating_q025": 1127.360987885279
        },
        "mistral-small-24b-instruct-2501": {
            "rating": 1156.1815054276794,
            "rating_q975": 1191.3977742092607,
            "rating_q025": 1120.9652366460982
        },
        "gpt-3.5-turbo-0125": {
            "rating": 1152.715244031661,
            "rating_q975": 1171.532965977641,
            "rating_q025": 1133.8975220856812
        },
        "reka-flash-21b-20240226-online": {
            "rating": 1150.650601560899,
            "rating_q975": 1181.235556490669,
            "rating_q025": 1120.0656466311289
        },
        "qwen1.5-110b-chat": {
            "rating": 1146.6741147499133,
            "rating_q975": 1171.1815470305085,
            "rating_q025": 1122.166682469318
        },
        "qwen1.5-72b-chat": {
            "rating": 1143.417134037615,
            "rating_q975": 1168.155081643005,
            "rating_q025": 1118.679186432225
        },
        "reka-flash-21b-20240226": {
            "rating": 1133.1361459065367,
            "rating_q975": 1157.8580889310335,
            "rating_q025": 1108.4142028820402
        },
        "phi-3-medium-4k-instruct": {
            "rating": 1129.3631748905389,
            "rating_q975": 1150.8156312145882,
            "rating_q025": 1107.9107185664895
        },
        "gemma-2-2b-it": {
            "rating": 1129.1211675953891,
            "rating_q975": 1144.9963175264952,
            "rating_q025": 1113.2460176642826
        },
        "gemini-pro-dev-api": {
            "rating": 1126.0087720245874,
            "rating_q975": 1161.5977856820348,
            "rating_q025": 1090.41975836714
        },
        "mixtral-8x22b-instruct-v0.1": {
            "rating": 1120.6970425117825,
            "rating_q975": 1138.7181223017983,
            "rating_q025": 1102.6759627217666
        },
        "qwen1.5-32b-chat": {
            "rating": 1116.2070492707035,
            "rating_q975": 1145.9245237288349,
            "rating_q025": 1086.4895748125723
        },
        "qwen1.5-14b-chat": {
            "rating": 1105.9648244864316,
            "rating_q975": 1140.7855579608595,
            "rating_q025": 1071.1440910120034
        },
        "mistral-medium": {
            "rating": 1099.8830077617138,
            "rating_q975": 1126.6497504894978,
            "rating_q025": 1073.1162650339295
        },
        "llama-3.1-8b-instruct": {
            "rating": 1098.5107544774971,
            "rating_q975": 1114.7512526157145,
            "rating_q025": 1082.2702563392797
        },
        "mistral-large-2402": {
            "rating": 1097.1056332961557,
            "rating_q975": 1116.4939050650337,
            "rating_q025": 1077.7173615272777
        },
        "llama-3-70b-instruct": {
            "rating": 1096.3459648719881,
            "rating_q975": 1108.8364953608943,
            "rating_q025": 1083.8554343830822
        },
        "dbrx-instruct-preview": {
            "rating": 1094.3397163643667,
            "rating_q975": 1120.8895582477392,
            "rating_q025": 1067.789874480994
        },
        "yi-1.5-34b-chat": {
            "rating": 1092.5053248845975,
            "rating_q975": 1116.722063608406,
            "rating_q025": 1068.288586160789
        },
        "jamba-1.5-mini": {
            "rating": 1089.954303881912,
            "rating_q975": 1122.438744698827,
            "rating_q025": 1057.4698630649973
        },
        "yi-34b-chat": {
            "rating": 1084.477080956574,
            "rating_q975": 1120.3771103497734,
            "rating_q025": 1048.5770515633744
        },
        "vicuna-33b": {
            "rating": 1065.4897874984003,
            "rating_q975": 1099.5274201952884,
            "rating_q025": 1031.4521548015125
        },
        "starling-lm-7b-beta": {
            "rating": 1064.4020817491726,
            "rating_q975": 1104.2215728703766,
            "rating_q025": 1024.5825906279686
        },
        "gemma-1.1-7b-it": {
            "rating": 1063.6782708028877,
            "rating_q975": 1089.6745791985034,
            "rating_q025": 1037.6819624072718
        },
        "snowflake-arctic-instruct": {
            "rating": 1062.716229763062,
            "rating_q975": 1084.5900556755687,
            "rating_q025": 1040.8424038505552
        },
        "llama-3-8b-instruct": {
            "rating": 1058.7505878004117,
            "rating_q975": 1073.196177335001,
            "rating_q025": 1044.3049982658226
        },
        "phi-3-small-8k-instruct": {
            "rating": 1051.2726871037044,
            "rating_q975": 1079.984661723867,
            "rating_q025": 1022.5607124835414
        },
        "phi-3-mini-4k-instruct-june-2024": {
            "rating": 1050.0722969306623,
            "rating_q975": 1078.911331362913,
            "rating_q025": 1021.2332624984117
        },
        "vicuna-13b": {
            "rating": 1047.1422306163734,
            "rating_q975": 1090.5090643391975,
            "rating_q025": 1003.775396893549
        },
        "mixtral-8x7b-instruct-v0.1": {
            "rating": 1036.3828402257138,
            "rating_q975": 1054.4226931104308,
            "rating_q025": 1018.342987340997
        },
        "llama-3.2-3b-instruct": {
            "rating": 1033.5973227682266,
            "rating_q975": 1075.5040831848403,
            "rating_q025": 991.6905623516133
        },
        "llama-2-70b-chat": {
            "rating": 1024.4968993803204,
            "rating_q975": 1052.1986655995877,
            "rating_q025": 996.795133161053
        },
        "phi-3-mini-4k-instruct": {
            "rating": 1020.5267462371033,
            "rating_q975": 1051.236912053347,
            "rating_q025": 989.8165804208597
        },
        "llama-3.2-1b-instruct": {
            "rating": 1019.9102196813327,
            "rating_q975": 1061.466307374089,
            "rating_q025": 978.3541319885765
        },
        "gemma-1.1-2b-it": {
            "rating": 1012.8189794862461,
            "rating_q975": 1052.8794284089795,
            "rating_q025": 972.7585305635127
        },
        "phi-3-mini-128k-instruct": {
            "rating": 1011.9716914878915,
            "rating_q975": 1039.1825659161714,
            "rating_q025": 984.7608170596116
        },
        "llama-2-13b-chat": {
            "rating": 991.7232817708204,
            "rating_q975": 1031.0295397801117,
            "rating_q025": 952.417023761529
        },
        "mistral-7b-instruct-v0.2": {
            "rating": 981.9641412895387,
            "rating_q975": 1022.4051548695768,
            "rating_q025": 941.5231277095006
        },
        "llama-2-7b-chat": {
            "rating": 968.9137972499032,
            "rating_q975": 1012.1353314918435,
            "rating_q025": 925.692263007963
        }
    },
    "korean": {
        "gemini-2.5-pro": {
            "rating": 1423.1206225561466,
            "rating_q975": 1445.4128456527712,
            "rating_q025": 1400.8283994595217
        },
        "gpt-4.5-preview-2025-02-27": {
            "rating": 1413.0019180862216,
            "rating_q975": 1453.7164226668294,
            "rating_q025": 1372.287413505614
        },
        "o1-2024-12-17": {
            "rating": 1412.580978559278,
            "rating_q975": 1440.9084408990946,
            "rating_q025": 1384.2535162194613
        },
        "gpt-5-high": {
            "rating": 1408.804371524565,
            "rating_q975": 1439.1732559783554,
            "rating_q025": 1378.4354870707746
        },
        "chatgpt-4o-latest-20250326": {
            "rating": 1406.508471826445,
            "rating_q975": 1429.6924855526408,
            "rating_q025": 1383.3244581002493
        },
        "claude-opus-4-1-20250805-thinking-16k": {
            "rating": 1385.0910132654315,
            "rating_q975": 1414.3065884779655,
            "rating_q025": 1355.8754380528972
        },
        "o3-2025-04-16": {
            "rating": 1382.0706048100633,
            "rating_q975": 1403.7367229366287,
            "rating_q025": 1360.404486683498
        },
        "gpt-4.1-2025-04-14": {
            "rating": 1372.9728129871767,
            "rating_q975": 1397.5056950768055,
            "rating_q025": 1348.4399308975476
        },
        "gemini-2.5-flash": {
            "rating": 1372.3879034538945,
            "rating_q975": 1394.8332470181224,
            "rating_q025": 1349.9425598896669
        },
        "grok-4-0709": {
            "rating": 1371.1101624327782,
            "rating_q975": 1402.8077235886644,
            "rating_q025": 1339.412601276892
        },
        "claude-opus-4-1-20250805": {
            "rating": 1369.6291955633499,
            "rating_q975": 1399.882010140861,
            "rating_q025": 1339.376380985839
        },
        "deepseek-v3.1-thinking": {
            "rating": 1369.0351198990709,
            "rating_q975": 1406.944542999628,
            "rating_q025": 1331.125696798514
        },
        "qwen-max-2025-08-15": {
            "rating": 1368.555282580394,
            "rating_q975": 1402.444976528459,
            "rating_q025": 1334.665588632329
        },
        "claude-opus-4-20250514-thinking-16k": {
            "rating": 1366.6492097424025,
            "rating_q975": 1395.6898282096713,
            "rating_q025": 1337.6085912751334
        },
        "qwen3-235b-a22b-instruct-2507": {
            "rating": 1366.0661088083302,
            "rating_q975": 1394.6241361742407,
            "rating_q025": 1337.5080814424196
        },
        "hunyuan-t1-20250711": {
            "rating": 1364.3618787597366,
            "rating_q975": 1398.8096193075112,
            "rating_q025": 1329.9141382119622
        },
        "gpt-5-chat": {
            "rating": 1362.3526775567373,
            "rating_q975": 1394.1483955417164,
            "rating_q025": 1330.5569595717584
        },
        "gpt-5-mini-high": {
            "rating": 1361.9176879761505,
            "rating_q975": 1396.213934894277,
            "rating_q025": 1327.6214410580244
        },
        "mistral-medium-2508": {
            "rating": 1361.7903961902484,
            "rating_q975": 1389.5613956748473,
            "rating_q025": 1334.0193967056493
        },
        "kimi-k2-0711-preview": {
            "rating": 1357.4696969146116,
            "rating_q975": 1386.427418034947,
            "rating_q025": 1328.5119757942764
        },
        "qwen3-235b-a22b-no-thinking": {
            "rating": 1356.7955271160342,
            "rating_q975": 1383.953030765354,
            "rating_q025": 1329.6380234667145
        },
        "claude-sonnet-4-20250514-thinking-32k": {
            "rating": 1356.0772947593348,
            "rating_q975": 1384.535152057677,
            "rating_q025": 1327.6194374609927
        },
        "glm-4.5": {
            "rating": 1352.880161260038,
            "rating_q975": 1385.2387457005348,
            "rating_q025": 1320.521576819541
        },
        "deepseek-r1": {
            "rating": 1352.7078588776333,
            "rating_q975": 1388.9089332313886,
            "rating_q025": 1316.506784523878
        },
        "deepseek-v3.1": {
            "rating": 1350.1052862391432,
            "rating_q975": 1383.575949112301,
            "rating_q025": 1316.6346233659856
        },
        "o4-mini-2025-04-16": {
            "rating": 1348.0535512063293,
            "rating_q975": 1371.2297790406162,
            "rating_q025": 1324.8773233720424
        },
        "o1-preview": {
            "rating": 1345.7329896489052,
            "rating_q975": 1369.9548611133978,
            "rating_q025": 1321.5111181844127
        },
        "claude-opus-4-20250514": {
            "rating": 1344.9413181219131,
            "rating_q975": 1367.4596845638623,
            "rating_q025": 1322.4229516799642
        },
        "hunyuan-turbos-20250416": {
            "rating": 1344.523971902933,
            "rating_q975": 1393.4292084838685,
            "rating_q025": 1295.6187353219973
        },
        "deepseek-r1-0528": {
            "rating": 1343.9365091395152,
            "rating_q975": 1374.7859901587233,
            "rating_q025": 1313.0870281203072
        },
        "gemini-2.0-flash-lite-preview-02-05": {
            "rating": 1342.4695466817452,
            "rating_q975": 1371.7209918132912,
            "rating_q025": 1313.2181015501992
        },
        "grok-3-preview-02-24": {
            "rating": 1339.7880816592494,
            "rating_q975": 1363.9830159875382,
            "rating_q025": 1315.5931473309604
        },
        "mai-1-preview": {
            "rating": 1338.069342723864,
            "rating_q975": 1376.0389609601445,
            "rating_q025": 1300.099724487584
        },
        "o3-mini-high": {
            "rating": 1336.9554380498382,
            "rating_q975": 1374.6911484118339,
            "rating_q025": 1299.2197276878426
        },
        "glm-4.5-air": {
            "rating": 1336.2752858178642,
            "rating_q975": 1370.888939694853,
            "rating_q025": 1301.6616319408752
        },
        "claude-sonnet-4-20250514": {
            "rating": 1335.0444645925015,
            "rating_q975": 1358.8857534471838,
            "rating_q025": 1311.203175737819
        },
        "gemini-2.0-flash-001": {
            "rating": 1334.5632973258641,
            "rating_q975": 1357.1320848836942,
            "rating_q025": 1311.994509768034
        },
        "gemini-1.5-pro-002": {
            "rating": 1333.7094984184055,
            "rating_q975": 1353.7424787433881,
            "rating_q025": 1313.6765180934226
        },
        "deepseek-v3-0324": {
            "rating": 1331.2657198696575,
            "rating_q975": 1354.7851059991228,
            "rating_q025": 1307.746333740192
        },
        "qwen3-235b-a22b-thinking-2507": {
            "rating": 1331.1836652245772,
            "rating_q975": 1369.100783678614,
            "rating_q025": 1293.2665467705406
        },
        "gpt-4.1-mini-2025-04-14": {
            "rating": 1329.243419830401,
            "rating_q975": 1353.5303512195396,
            "rating_q025": 1304.9564884412623
        },
        "claude-3-7-sonnet-20250219-thinking-32k": {
            "rating": 1326.8184322649886,
            "rating_q975": 1348.3082735984492,
            "rating_q025": 1305.3285909315282
        },
        "qwen2.5-max": {
            "rating": 1320.5173761211763,
            "rating_q975": 1346.1037699338656,
            "rating_q025": 1294.9309823084873
        },
        "grok-3-mini-high": {
            "rating": 1320.4564831294244,
            "rating_q975": 1354.2454081520693,
            "rating_q025": 1286.6675581067798
        },
        "qwen3-235b-a22b": {
            "rating": 1319.0778783342566,
            "rating_q975": 1344.987754522247,
            "rating_q025": 1293.168002146266
        },
        "gemma-3-27b-it": {
            "rating": 1317.9419333331637,
            "rating_q975": 1340.8999605152108,
            "rating_q025": 1294.9839061511168
        },
        "claude-3-7-sonnet-20250219": {
            "rating": 1314.1653150735017,
            "rating_q975": 1336.430830520291,
            "rating_q025": 1291.8997996267124
        },
        "mistral-small-2506": {
            "rating": 1307.6430181269059,
            "rating_q975": 1340.0958475736954,
            "rating_q025": 1275.1901886801165
        },
        "qwen3-coder-480b-a35b-instruct": {
            "rating": 1306.6648702154394,
            "rating_q975": 1340.9917853565976,
            "rating_q025": 1272.3379550742814
        },
        "o3-mini": {
            "rating": 1306.4367613486982,
            "rating_q975": 1326.1389820997188,
            "rating_q025": 1286.7345405976773
        },
        "mistral-medium-2505": {
            "rating": 1305.5445519191692,
            "rating_q975": 1328.9612307572468,
            "rating_q025": 1282.1278730810918
        },
        "gpt-oss-20b": {
            "rating": 1303.4343421542414,
            "rating_q975": 1341.579713422301,
            "rating_q025": 1265.2889708861821
        },
        "gpt-4o-2024-05-13": {
            "rating": 1303.3175882485593,
            "rating_q975": 1316.6344928966612,
            "rating_q025": 1290.0006836004573
        },
        "claude-3-5-sonnet-20241022": {
            "rating": 1302.689028176113,
            "rating_q975": 1319.07536904028,
            "rating_q025": 1286.302687311946
        },
        "gpt-4o-2024-08-06": {
            "rating": 1301.5887982899258,
            "rating_q975": 1322.057586417836,
            "rating_q025": 1281.1200101620157
        },
        "command-a-03-2025": {
            "rating": 1299.7199362567774,
            "rating_q975": 1322.0300380711437,
            "rating_q025": 1277.409834442411
        },
        "qwen3-30b-a3b-instruct-2507": {
            "rating": 1295.877728281829,
            "rating_q975": 1329.8123545480173,
            "rating_q025": 1261.9431020156403
        },
        "glm-4-plus": {
            "rating": 1294.9329969160276,
            "rating_q975": 1322.524827122343,
            "rating_q025": 1267.3411667097123
        },
        "claude-3-5-sonnet-20240620": {
            "rating": 1294.164722053281,
            "rating_q975": 1309.9087498060558,
            "rating_q025": 1278.4206943005063
        },
        "gemini-advanced-0514": {
            "rating": 1293.9498490059686,
            "rating_q975": 1311.186756986643,
            "rating_q025": 1276.712941025294
        },
        "grok-3-mini-beta": {
            "rating": 1293.9436659656947,
            "rating_q975": 1322.0816335916718,
            "rating_q025": 1265.8056983397175
        },
        "gpt-oss-120b": {
            "rating": 1293.8972171560858,
            "rating_q975": 1329.2162361456699,
            "rating_q025": 1258.5781981665016
        },
        "deepseek-v3": {
            "rating": 1286.9088950660578,
            "rating_q975": 1318.67266397434,
            "rating_q025": 1255.1451261577756
        },
        "grok-2-2024-08-13": {
            "rating": 1286.0353634712096,
            "rating_q975": 1303.5227364919372,
            "rating_q025": 1268.547990450482
        },
        "gpt-5-nano-high": {
            "rating": 1285.6131164653284,
            "rating_q975": 1327.6289276121217,
            "rating_q025": 1243.597305318535
        },
        "gemini-1.5-pro-001": {
            "rating": 1280.1425062356147,
            "rating_q975": 1294.9922099379976,
            "rating_q025": 1265.292802533232
        },
        "claude-3-opus-20240229": {
            "rating": 1279.1528232453381,
            "rating_q975": 1292.1172849100867,
            "rating_q025": 1266.1883615805898
        },
        "gemma-3n-e4b-it": {
            "rating": 1277.8754701978878,
            "rating_q975": 1307.088190262953,
            "rating_q025": 1248.6627501328228
        },
        "llama-4-maverick-17b-128e-instruct": {
            "rating": 1275.0499463450476,
            "rating_q975": 1298.8682676045983,
            "rating_q025": 1251.231625085497
        },
        "qwq-32b": {
            "rating": 1274.6236551718125,
            "rating_q975": 1305.5585301375254,
            "rating_q025": 1243.6887802060996
        },
        "gpt-4-turbo-2024-04-09": {
            "rating": 1273.368511688195,
            "rating_q975": 1287.9898889831497,
            "rating_q025": 1258.7471343932405
        },
        "qwen3-30b-a3b": {
            "rating": 1272.6467628433197,
            "rating_q975": 1300.1880094221071,
            "rating_q025": 1245.1055162645323
        },
        "minimax-m1": {
            "rating": 1267.6087141728538,
            "rating_q975": 1297.240251427983,
            "rating_q025": 1237.9771769177246
        },
        "mistral-large-2411": {
            "rating": 1267.3726014745093,
            "rating_q975": 1293.4530824461579,
            "rating_q025": 1241.292120502861
        },
        "llama-3.1-405b-instruct-fp8": {
            "rating": 1265.4295016643441,
            "rating_q975": 1283.227294515303,
            "rating_q025": 1247.631708813385
        },
        "llama-4-scout-17b-16e-instruct": {
            "rating": 1264.5755071177646,
            "rating_q975": 1295.9074140133162,
            "rating_q025": 1233.2436002222132
        },
        "amazon-nova-experimental-chat-05-14": {
            "rating": 1264.1601776843872,
            "rating_q975": 1294.5596643743688,
            "rating_q025": 1233.7606909944059
        },
        "o1-mini": {
            "rating": 1262.5347289559968,
            "rating_q975": 1282.5822350320163,
            "rating_q025": 1242.4872228799775
        },
        "gpt-4-1106-preview": {
            "rating": 1261.5110094709012,
            "rating_q975": 1278.938918538263,
            "rating_q025": 1244.0831004035394
        },
        "gpt-4-0125-preview": {
            "rating": 1257.7184047167054,
            "rating_q975": 1274.8372843193752,
            "rating_q025": 1240.5995251140357
        },
        "gemini-1.5-flash-001": {
            "rating": 1257.4592206270472,
            "rating_q975": 1272.8203487532571,
            "rating_q025": 1242.098092500837
        },
        "command-r-08-2024": {
            "rating": 1256.373808637794,
            "rating_q975": 1296.6389578182245,
            "rating_q025": 1216.1086594573633
        },
        "mistral-small-24b-instruct-2501": {
            "rating": 1255.8311950243083,
            "rating_q975": 1292.3450275762164,
            "rating_q025": 1219.3173624724004
        },
        "deepseek-v2.5": {
            "rating": 1254.5738597358804,
            "rating_q975": 1281.7243454057216,
            "rating_q025": 1227.423374066039
        },
        "step-3": {
            "rating": 1253.3429295376031,
            "rating_q975": 1296.0875825261924,
            "rating_q025": 1210.5982765490141
        },
        "gemini-1.5-flash-002": {
            "rating": 1253.2258747722276,
            "rating_q975": 1277.2059202646892,
            "rating_q025": 1229.245829279766
        },
        "claude-3-5-haiku-20241022": {
            "rating": 1251.7241886511883,
            "rating_q975": 1271.262903548408,
            "rating_q025": 1232.1854737539688
        },
        "mistral-large-2407": {
            "rating": 1251.39665032406,
            "rating_q975": 1270.4573346047152,
            "rating_q025": 1232.3359660434044
        },
        "llama-3.1-405b-instruct-bf16": {
            "rating": 1250.71247572786,
            "rating_q975": 1272.0753200761226,
            "rating_q025": 1229.3496313795974
        },
        "gpt-4o-mini-2024-07-18": {
            "rating": 1250.2779124476951,
            "rating_q975": 1267.276802584297,
            "rating_q025": 1233.2790223110933
        },
        "yi-lightning": {
            "rating": 1247.327031114012,
            "rating_q975": 1273.8868183122775,
            "rating_q025": 1220.7672439157466
        },
        "mistral-small-3.1-24b-instruct-2503": {
            "rating": 1246.956232055215,
            "rating_q975": 1277.6292530874173,
            "rating_q025": 1216.2832110230124
        },
        "command-r-plus-08-2024": {
            "rating": 1246.9196200812958,
            "rating_q975": 1286.5120871054453,
            "rating_q025": 1207.3271530571467
        },
        "gemma-2-27b-it": {
            "rating": 1244.6264015901993,
            "rating_q975": 1259.9051135094305,
            "rating_q025": 1229.3476896709683
        },
        "athene-v2-chat": {
            "rating": 1244.223279473802,
            "rating_q975": 1273.658380133415,
            "rating_q025": 1214.7881788141892
        },
        "amazon-nova-pro-v1.0": {
            "rating": 1243.3908339238315,
            "rating_q975": 1271.4105410589348,
            "rating_q025": 1215.371126788728
        },
        "grok-2-mini-2024-08-13": {
            "rating": 1242.949714243363,
            "rating_q975": 1261.6941579956565,
            "rating_q025": 1224.2052704910693
        },
        "qwen2.5-72b-instruct": {
            "rating": 1240.2894743653496,
            "rating_q975": 1263.8831647616714,
            "rating_q025": 1216.6957839690278
        },
        "llama-3.3-70b-instruct": {
            "rating": 1234.2753035534188,
            "rating_q975": 1253.992006501128,
            "rating_q025": 1214.55860060571
        },
        "nemotron-4-340b-instruct": {
            "rating": 1233.375910637501,
            "rating_q975": 1256.8194553482829,
            "rating_q025": 1209.932365926719
        },
        "claude-3-sonnet-20240229": {
            "rating": 1233.2406804007828,
            "rating_q975": 1249.2024875385266,
            "rating_q025": 1217.278873263039
        },
        "command-r-plus": {
            "rating": 1228.0886923575972,
            "rating_q975": 1244.583097639551,
            "rating_q025": 1211.5942870756433
        },
        "athene-70b-0725": {
            "rating": 1225.0047404240104,
            "rating_q975": 1252.032869832224,
            "rating_q025": 1197.9766110157964
        },
        "c4ai-aya-expanse-32b": {
            "rating": 1221.033409493933,
            "rating_q975": 1247.1608319789284,
            "rating_q025": 1194.9059870089377
        },
        "claude-3-haiku-20240307": {
            "rating": 1220.3278500110378,
            "rating_q975": 1235.3339747741122,
            "rating_q025": 1205.3217252479633
        },
        "jamba-1.5-large": {
            "rating": 1215.2732970695831,
            "rating_q975": 1254.3392409895794,
            "rating_q025": 1176.2073531495869
        },
        "deepseek-coder-v2": {
            "rating": 1213.845346976621,
            "rating_q975": 1242.0782413185061,
            "rating_q025": 1185.6124526347357
        },
        "gemma-2-9b-it": {
            "rating": 1211.5079321325743,
            "rating_q975": 1229.0316133688518,
            "rating_q025": 1193.984250896297
        },
        "llama-3.1-70b-instruct": {
            "rating": 1208.0881110110408,
            "rating_q975": 1226.2423409883409,
            "rating_q025": 1189.9338810337408
        },
        "phi-4": {
            "rating": 1206.9412038495288,
            "rating_q975": 1238.1442281920513,
            "rating_q025": 1175.738179507006
        },
        "gpt-4-0314": {
            "rating": 1206.3870962097035,
            "rating_q975": 1234.4843474230468,
            "rating_q025": 1178.28984499636
        },
        "qwen-max-0919": {
            "rating": 1202.2634313138028,
            "rating_q975": 1233.5389038120643,
            "rating_q025": 1170.9879588155416
        },
        "reka-flash-21b-20240226-online": {
            "rating": 1201.716046860241,
            "rating_q975": 1233.8250095740395,
            "rating_q025": 1169.6070841464425
        },
        "amazon-nova-micro-v1.0": {
            "rating": 1200.938220889905,
            "rating_q975": 1233.2752640343751,
            "rating_q025": 1168.6011777454348
        },
        "gemini-1.5-flash-8b-001": {
            "rating": 1200.3170908793377,
            "rating_q975": 1224.8118497429882,
            "rating_q025": 1175.8223320156872
        },
        "command-r": {
            "rating": 1199.9131879149068,
            "rating_q975": 1218.3320820103113,
            "rating_q025": 1181.4942938195024
        },
        "amazon-nova-lite-v1.0": {
            "rating": 1196.920787327511,
            "rating_q975": 1227.8434020124348,
            "rating_q025": 1165.9981726425874
        },
        "qwen2-72b-instruct": {
            "rating": 1190.243180189303,
            "rating_q975": 1208.0047296034802,
            "rating_q025": 1172.4816307751262
        },
        "gpt-4-0613": {
            "rating": 1189.8009759247252,
            "rating_q975": 1208.6294625674916,
            "rating_q025": 1170.9724892819593
        },
        "qwen2.5-plus-1127": {
            "rating": 1179.8717653947392,
            "rating_q975": 1228.342269185971,
            "rating_q025": 1131.4012616035077
        },
        "gemma-2-9b-it-simpo": {
            "rating": 1179.1014277250251,
            "rating_q975": 1217.0613865233304,
            "rating_q025": 1141.1414689267199
        },
        "reka-flash-21b-20240226": {
            "rating": 1173.8268346841985,
            "rating_q975": 1197.3695325003775,
            "rating_q025": 1150.2841368680197
        },
        "gpt-3.5-turbo-0125": {
            "rating": 1166.289908757837,
            "rating_q975": 1185.04629206448,
            "rating_q025": 1147.5335254511942
        },
        "c4ai-aya-expanse-8b": {
            "rating": 1166.180217017775,
            "rating_q975": 1208.9602756739052,
            "rating_q025": 1123.4001583616448
        },
        "mixtral-8x22b-instruct-v0.1": {
            "rating": 1160.096635892393,
            "rating_q975": 1178.4545855311285,
            "rating_q025": 1141.7386862536573
        },
        "qwen1.5-72b-chat": {
            "rating": 1153.4425405065813,
            "rating_q975": 1178.7124674800991,
            "rating_q025": 1128.1726135330637
        },
        "qwen1.5-110b-chat": {
            "rating": 1141.1540182575213,
            "rating_q975": 1158.7363154646714,
            "rating_q025": 1123.5717210503713
        },
        "mistral-large-2402": {
            "rating": 1124.5971000190934,
            "rating_q975": 1144.2713698475957,
            "rating_q025": 1104.922830190591
        },
        "glm-4-0520": {
            "rating": 1123.5301316671637,
            "rating_q975": 1156.808050131171,
            "rating_q025": 1090.2522132031563
        },
        "llama-3-70b-instruct": {
            "rating": 1123.4830026779623,
            "rating_q975": 1136.6188633190584,
            "rating_q025": 1110.3471420368662
        },
        "mistral-medium": {
            "rating": 1123.267947924045,
            "rating_q975": 1156.7355679039163,
            "rating_q025": 1089.8003279441741
        },
        "dbrx-instruct-preview": {
            "rating": 1122.5251225305442,
            "rating_q975": 1150.5676671911617,
            "rating_q025": 1094.4825778699264
        },
        "qwen1.5-32b-chat": {
            "rating": 1115.1904965944664,
            "rating_q975": 1143.5728176384334,
            "rating_q025": 1086.8081755504995
        },
        "jamba-1.5-mini": {
            "rating": 1113.6699728652611,
            "rating_q975": 1154.3406516865039,
            "rating_q025": 1072.9992940440184
        },
        "gemma-1.1-7b-it": {
            "rating": 1113.1753739149167,
            "rating_q975": 1134.640686116819,
            "rating_q025": 1091.7100617130145
        },
        "llama-3.1-8b-instruct": {
            "rating": 1112.7645090713531,
            "rating_q975": 1132.0344707334186,
            "rating_q025": 1093.4945474092879
        },
        "llama-3-8b-instruct": {
            "rating": 1109.8278838799629,
            "rating_q975": 1125.197658727899,
            "rating_q025": 1094.4581090320269
        },
        "gemma-2-2b-it": {
            "rating": 1108.2904388214574,
            "rating_q975": 1129.70392350701,
            "rating_q025": 1086.8769541359052
        },
        "yi-1.5-34b-chat": {
            "rating": 1099.2267598283058,
            "rating_q975": 1120.666111590548,
            "rating_q025": 1077.7874080660636
        },
        "mixtral-8x7b-instruct-v0.1": {
            "rating": 1084.8018319062064,
            "rating_q975": 1106.9040055038352,
            "rating_q025": 1062.6996583085777
        },
        "snowflake-arctic-instruct": {
            "rating": 1082.9500871382543,
            "rating_q975": 1108.8069288607564,
            "rating_q025": 1057.093245415752
        },
        "internlm2_5-20b-chat": {
            "rating": 1079.7356020650584,
            "rating_q975": 1124.1661518695664,
            "rating_q025": 1035.3050522605502
        },
        "llama-2-70b-chat": {
            "rating": 1076.3843181239317,
            "rating_q975": 1113.2422338215756,
            "rating_q025": 1039.5264024262879
        },
        "llama-2-13b-chat": {
            "rating": 1067.1259068507197,
            "rating_q975": 1112.4705780530776,
            "rating_q025": 1021.7812356483619
        },
        "yi-34b-chat": {
            "rating": 1061.5501213540308,
            "rating_q975": 1098.7234606801085,
            "rating_q025": 1024.3767820279531
        },
        "phi-3-medium-4k-instruct": {
            "rating": 1058.1941975326758,
            "rating_q975": 1079.658751859383,
            "rating_q025": 1036.7296432059684
        },
        "gemma-1.1-2b-it": {
            "rating": 1025.2381320490344,
            "rating_q975": 1054.5679941220894,
            "rating_q025": 995.9082699759792
        },
        "phi-3-small-8k-instruct": {
            "rating": 1015.0416418023391,
            "rating_q975": 1036.6548396346345,
            "rating_q025": 993.4284439700435
        },
        "phi-3-mini-4k-instruct": {
            "rating": 1005.2541274784086,
            "rating_q975": 1026.0875725724939,
            "rating_q025": 984.4206823843233
        },
        "phi-3-mini-128k-instruct": {
            "rating": 993.371247893845,
            "rating_q975": 1027.1291574845472,
            "rating_q025": 959.6133383031427
        },
        "phi-3-mini-4k-instruct-june-2024": {
            "rating": 985.4245961707526,
            "rating_q975": 1020.8403913496436,
            "rating_q025": 950.0088009918616
        }
    },
    "long_user": {
        "claude-opus-4-1-20250805-thinking-16k": {
            "rating": 1472.0614377643674,
            "rating_q975": 1487.3555492039313,
            "rating_q025": 1456.7673263248034
        },
        "claude-opus-4-1-20250805": {
            "rating": 1471.7491300180882,
            "rating_q975": 1485.1613627313238,
            "rating_q025": 1458.3368973048523
        },
        "gemini-2.5-pro": {
            "rating": 1457.844008360855,
            "rating_q975": 1466.3878023260288,
            "rating_q025": 1449.3002143956815
        },
        "claude-opus-4-20250514-thinking-16k": {
            "rating": 1452.4618015771803,
            "rating_q975": 1462.104342049241,
            "rating_q025": 1442.8192611051195
        },
        "gpt-5-chat": {
            "rating": 1442.6287063174661,
            "rating_q975": 1458.090412044004,
            "rating_q025": 1427.1670005909284
        },
        "qwen3-235b-a22b-instruct-2507": {
            "rating": 1442.0485509759262,
            "rating_q975": 1454.337561576962,
            "rating_q025": 1429.7595403748905
        },
        "claude-opus-4-20250514": {
            "rating": 1440.4881761200825,
            "rating_q975": 1449.162332197661,
            "rating_q025": 1431.8140200425041
        },
        "chatgpt-4o-latest-20250326": {
            "rating": 1439.2271821452127,
            "rating_q975": 1447.4999985865206,
            "rating_q025": 1430.9543657039048
        },
        "deepseek-v3.1-thinking": {
            "rating": 1437.50587620309,
            "rating_q975": 1458.0007940367525,
            "rating_q025": 1417.0109583694277
        },
        "gpt-4.5-preview-2025-02-27": {
            "rating": 1437.0863438485424,
            "rating_q975": 1449.904149904099,
            "rating_q025": 1424.2685377929856
        },
        "claude-sonnet-4-20250514-thinking-32k": {
            "rating": 1436.6733063334311,
            "rating_q975": 1446.3714467052748,
            "rating_q025": 1426.9751659615874
        },
        "qwen-max-2025-08-15": {
            "rating": 1432.0697950182678,
            "rating_q975": 1450.8672736255248,
            "rating_q025": 1413.2723164110105
        },
        "deepseek-v3.1": {
            "rating": 1430.7071275081983,
            "rating_q975": 1449.2815831168764,
            "rating_q025": 1412.1326718995201
        },
        "grok-3-preview-02-24": {
            "rating": 1424.215455506319,
            "rating_q975": 1432.503195391623,
            "rating_q025": 1415.9277156210146
        },
        "gpt-4.1-2025-04-14": {
            "rating": 1422.5380600546805,
            "rating_q975": 1431.2004547537922,
            "rating_q025": 1413.8756653555688
        },
        "mistral-medium-2508": {
            "rating": 1422.4311398078655,
            "rating_q975": 1438.5496724916682,
            "rating_q025": 1406.3126071240629
        },
        "glm-4.5": {
            "rating": 1421.3198914855952,
            "rating_q975": 1434.4662473726617,
            "rating_q025": 1408.173535598529
        },
        "gpt-5-high": {
            "rating": 1420.8233295721757,
            "rating_q975": 1434.2060859208373,
            "rating_q025": 1407.4405732235139
        },
        "grok-4-0709": {
            "rating": 1420.2588472281054,
            "rating_q975": 1430.5007594355702,
            "rating_q025": 1410.0169350206404
        },
        "gemini-2.5-flash": {
            "rating": 1419.9740548869142,
            "rating_q975": 1428.1820092117077,
            "rating_q025": 1411.7661005621208
        },
        "claude-3-7-sonnet-20250219-thinking-32k": {
            "rating": 1419.9081283099106,
            "rating_q975": 1428.028045179434,
            "rating_q025": 1411.7882114403872
        },
        "claude-sonnet-4-20250514": {
            "rating": 1413.7144921215222,
            "rating_q975": 1422.6301119182144,
            "rating_q025": 1404.79887232483
        },
        "o3-2025-04-16": {
            "rating": 1411.5041723340203,
            "rating_q975": 1419.395113534196,
            "rating_q025": 1403.6132311338445
        },
        "deepseek-r1-0528": {
            "rating": 1407.6620823504059,
            "rating_q975": 1417.8201738588457,
            "rating_q025": 1397.503990841966
        },
        "qwen3-235b-a22b-thinking-2507": {
            "rating": 1407.657456831496,
            "rating_q975": 1422.5201151896322,
            "rating_q025": 1392.7947984733596
        },
        "o1-2024-12-17": {
            "rating": 1405.483398476488,
            "rating_q975": 1414.6909925380385,
            "rating_q025": 1396.2758044149375
        },
        "claude-3-7-sonnet-20250219": {
            "rating": 1404.9025697528834,
            "rating_q975": 1412.5792418138483,
            "rating_q025": 1397.2258976919188
        },
        "kimi-k2-0711-preview": {
            "rating": 1401.1712045046124,
            "rating_q975": 1411.2064504387342,
            "rating_q025": 1391.1359585704909
        },
        "qwen3-coder-480b-a35b-instruct": {
            "rating": 1398.356296191492,
            "rating_q975": 1410.6951003831978,
            "rating_q025": 1386.017491999786
        },
        "qwen-vl-max-2025-08-13": {
            "rating": 1397.4729303232123,
            "rating_q975": 1433.3611016203618,
            "rating_q025": 1361.5847590260626
        },
        "qwen3-235b-a22b-no-thinking": {
            "rating": 1397.245642215827,
            "rating_q975": 1406.0164788756176,
            "rating_q025": 1388.4748055560362
        },
        "glm-4.5-air": {
            "rating": 1396.4734481001951,
            "rating_q975": 1409.7760908934213,
            "rating_q025": 1383.1708053069688
        },
        "deepseek-r1": {
            "rating": 1394.1356189715596,
            "rating_q975": 1405.2421877967536,
            "rating_q025": 1383.0290501463655
        },
        "mai-1-preview": {
            "rating": 1394.049992076271,
            "rating_q975": 1414.9576202944331,
            "rating_q025": 1373.1423638581093
        },
        "deepseek-v3-0324": {
            "rating": 1392.352347367136,
            "rating_q975": 1400.5460153505967,
            "rating_q025": 1384.1586793836755
        },
        "hunyuan-t1-20250711": {
            "rating": 1388.9585209286001,
            "rating_q975": 1407.2885169758194,
            "rating_q025": 1370.6285248813806
        },
        "mistral-medium-2505": {
            "rating": 1388.5139311496825,
            "rating_q975": 1396.785087076831,
            "rating_q025": 1380.2427752225342
        },
        "claude-3-5-sonnet-20241022": {
            "rating": 1387.3027810634467,
            "rating_q975": 1392.732812462029,
            "rating_q025": 1381.8727496648642
        },
        "gpt-4.1-mini-2025-04-14": {
            "rating": 1383.7063125073846,
            "rating_q975": 1392.439228115199,
            "rating_q025": 1374.97339689957
        },
        "qwen2.5-max": {
            "rating": 1382.3303382203787,
            "rating_q975": 1390.4273937543833,
            "rating_q025": 1374.2332826863742
        },
        "gpt-5-mini-high": {
            "rating": 1381.785569602326,
            "rating_q975": 1398.7712967288423,
            "rating_q025": 1364.7998424758096
        },
        "qwen3-30b-a3b-instruct-2507": {
            "rating": 1380.350963324014,
            "rating_q975": 1394.6423492871552,
            "rating_q025": 1366.0595773608727
        },
        "o1-preview": {
            "rating": 1379.0171375214018,
            "rating_q975": 1387.7585592719295,
            "rating_q025": 1370.275715770874
        },
        "hunyuan-turbos-20250416": {
            "rating": 1378.2404025722617,
            "rating_q975": 1391.9387098973116,
            "rating_q025": 1364.5420952472116
        },
        "grok-3-mini-high": {
            "rating": 1377.3189636684722,
            "rating_q975": 1388.261500372618,
            "rating_q025": 1366.3764269643264
        },
        "qwen3-235b-a22b": {
            "rating": 1376.2326249379355,
            "rating_q975": 1385.3321242983295,
            "rating_q025": 1367.1331255775417
        },
        "hunyuan-large-2025-02-10": {
            "rating": 1372.9462267989602,
            "rating_q975": 1400.2691417571166,
            "rating_q025": 1345.6233118408038
        },
        "o4-mini-2025-04-16": {
            "rating": 1370.5890098358616,
            "rating_q975": 1379.2815819736707,
            "rating_q025": 1361.8964376980523
        },
        "deepseek-v3": {
            "rating": 1369.842246067854,
            "rating_q975": 1379.757788646456,
            "rating_q025": 1359.9267034892518
        },
        "o3-mini-high": {
            "rating": 1368.8188594060248,
            "rating_q975": 1380.18347744253,
            "rating_q025": 1357.4542413695197
        },
        "step-3": {
            "rating": 1367.4983890657793,
            "rating_q975": 1392.2293962186764,
            "rating_q025": 1342.7673819128822
        },
        "grok-3-mini-beta": {
            "rating": 1367.2664231022,
            "rating_q975": 1377.0233160325622,
            "rating_q025": 1357.509530171838
        },
        "minimax-m1": {
            "rating": 1365.9085700637725,
            "rating_q975": 1375.340991516009,
            "rating_q025": 1356.4761486115362
        },
        "gemma-3-27b-it": {
            "rating": 1365.300910776958,
            "rating_q975": 1373.9591291986296,
            "rating_q025": 1356.6426923552865
        },
        "gemini-2.0-flash-001": {
            "rating": 1363.989074682063,
            "rating_q975": 1371.6166835035062,
            "rating_q025": 1356.3614658606195
        },
        "o3-mini": {
            "rating": 1358.8761595224066,
            "rating_q975": 1365.9462311637903,
            "rating_q025": 1351.8060878810231
        },
        "qwen3-32b": {
            "rating": 1358.589693947163,
            "rating_q975": 1381.735409943359,
            "rating_q025": 1335.4439779509667
        },
        "command-a-03-2025": {
            "rating": 1358.4931102489838,
            "rating_q975": 1366.4461444711071,
            "rating_q025": 1350.5400760268608
        },
        "mistral-small-2506": {
            "rating": 1357.871609099504,
            "rating_q975": 1369.0297293668266,
            "rating_q025": 1346.7134888321816
        },
        "gemini-1.5-pro-002": {
            "rating": 1354.6615746590267,
            "rating_q975": 1361.1083539962867,
            "rating_q025": 1348.2147953217666
        },
        "qwen-plus-0125": {
            "rating": 1353.8075068701073,
            "rating_q975": 1373.4042186070603,
            "rating_q025": 1334.2107951331543
        },
        "hunyuan-turbos-20250226": {
            "rating": 1352.9402486195354,
            "rating_q975": 1383.39208376634,
            "rating_q025": 1322.4884134727308
        },
        "claude-3-5-sonnet-20240620": {
            "rating": 1350.1029130432519,
            "rating_q975": 1357.1731799423428,
            "rating_q025": 1343.0326461441607
        },
        "gemini-2.0-flash-lite-preview-02-05": {
            "rating": 1347.8743508209477,
            "rating_q975": 1357.667768560208,
            "rating_q025": 1338.0809330816871
        },
        "gemini-1.5-pro-001": {
            "rating": 1347.6582057317971,
            "rating_q975": 1355.3806119206024,
            "rating_q025": 1339.9357995429918
        },
        "gemma-3-12b-it": {
            "rating": 1347.1844760509327,
            "rating_q975": 1374.2121299920802,
            "rating_q025": 1320.1568221097853
        },
        "nvidia-llama-3.3-nemotron-super-49b-v1.5": {
            "rating": 1346.1618404388362,
            "rating_q975": 1365.9706516904394,
            "rating_q025": 1326.3530291872328
        },
        "step-1o-turbo-202506": {
            "rating": 1343.3163877392487,
            "rating_q975": 1358.348256971871,
            "rating_q025": 1328.2845185066267
        },
        "o1-mini": {
            "rating": 1342.8794889904725,
            "rating_q975": 1349.7665220666445,
            "rating_q025": 1335.9924559143003
        },
        "hunyuan-turbo-0110": {
            "rating": 1341.1485249529082,
            "rating_q975": 1369.9639261215236,
            "rating_q025": 1312.333123784293
        },
        "step-2-16k-exp-202412": {
            "rating": 1340.224083929986,
            "rating_q975": 1360.3487566105523,
            "rating_q025": 1320.0994112494195
        },
        "qwq-32b": {
            "rating": 1337.7098639848705,
            "rating_q975": 1347.2377516164836,
            "rating_q025": 1328.1819763532576
        },
        "claude-3-5-haiku-20241022": {
            "rating": 1336.26902389744,
            "rating_q975": 1342.775349845862,
            "rating_q025": 1329.7626979490178
        },
        "gpt-4o-2024-08-06": {
            "rating": 1335.783444481202,
            "rating_q975": 1343.4233384564968,
            "rating_q025": 1328.1435505059073
        },
        "qwen3-30b-a3b": {
            "rating": 1335.522644068244,
            "rating_q975": 1344.757331411592,
            "rating_q025": 1326.2879567248963
        },
        "deepseek-v2.5-1210": {
            "rating": 1335.4151402217315,
            "rating_q975": 1351.2874526440041,
            "rating_q025": 1319.5428277994588
        },
        "llama-3.1-nemotron-ultra-253b-v1": {
            "rating": 1333.1938853106649,
            "rating_q975": 1361.8380345227886,
            "rating_q025": 1304.5497360985414
        },
        "grok-2-2024-08-13": {
            "rating": 1332.405116523542,
            "rating_q975": 1338.861899299988,
            "rating_q025": 1325.948333747096
        },
        "amazon-nova-experimental-chat-05-14": {
            "rating": 1331.9816583475967,
            "rating_q975": 1342.6741630760189,
            "rating_q025": 1321.2891536191748
        },
        "llama-3.3-nemotron-49b-super-v1": {
            "rating": 1331.239559093397,
            "rating_q975": 1360.267433529844,
            "rating_q025": 1302.2116846569502
        },
        "glm-4-plus-0111": {
            "rating": 1331.2101122523407,
            "rating_q975": 1350.2902946839438,
            "rating_q025": 1312.1299298207375
        },
        "gpt-5-nano-high": {
            "rating": 1330.5960511901462,
            "rating_q975": 1350.5875438030725,
            "rating_q025": 1310.6045585772194
        },
        "gpt-4o-2024-05-13": {
            "rating": 1329.7088695597868,
            "rating_q975": 1335.9067539736984,
            "rating_q025": 1323.5109851458753
        },
        "hunyuan-standard-2025-02-10": {
            "rating": 1328.2945095041403,
            "rating_q975": 1353.6079306385411,
            "rating_q025": 1302.9810883697394
        },
        "magistral-medium-2506": {
            "rating": 1328.059112200283,
            "rating_q975": 1341.3216703101177,
            "rating_q025": 1314.796554090448
        },
        "claude-3-opus-20240229": {
            "rating": 1326.5702519166648,
            "rating_q975": 1332.3066960688352,
            "rating_q025": 1320.8338077644948
        },
        "llama-4-maverick-17b-128e-instruct": {
            "rating": 1325.6982241278356,
            "rating_q975": 1334.4417217958003,
            "rating_q025": 1316.9547264598712
        },
        "llama-3.1-405b-instruct-bf16": {
            "rating": 1325.3863315323367,
            "rating_q975": 1332.7679855647864,
            "rating_q025": 1318.004677499887
        },
        "qwen-max-0919": {
            "rating": 1325.1327319697923,
            "rating_q975": 1336.116517223957,
            "rating_q025": 1314.1489467156273
        },
        "glm-4-plus": {
            "rating": 1323.955836977013,
            "rating_q975": 1333.1490546550654,
            "rating_q025": 1314.7626192989608
        },
        "yi-lightning": {
            "rating": 1323.8534329402391,
            "rating_q975": 1333.6250410351392,
            "rating_q025": 1314.081824845339
        },
        "gpt-4o-mini-2024-07-18": {
            "rating": 1323.595116590899,
            "rating_q975": 1329.9529962338604,
            "rating_q025": 1317.2372369479374
        },
        "gpt-oss-120b": {
            "rating": 1323.0505128206087,
            "rating_q975": 1338.8206368786493,
            "rating_q025": 1307.280388762568
        },
        "gemini-1.5-flash-002": {
            "rating": 1323.0143763880606,
            "rating_q975": 1330.670009523428,
            "rating_q025": 1315.358743252693
        },
        "gpt-4.1-nano-2025-04-14": {
            "rating": 1322.728661742367,
            "rating_q975": 1341.8718165403704,
            "rating_q025": 1303.5855069443635
        },
        "gemini-advanced-0514": {
            "rating": 1321.6955453455403,
            "rating_q975": 1331.472460887324,
            "rating_q025": 1311.9186298037564
        },
        "athene-v2-chat": {
            "rating": 1321.2578259020265,
            "rating_q975": 1330.0587414694694,
            "rating_q025": 1312.4569103345837
        },
        "glm-4.5v": {
            "rating": 1321.144169206424,
            "rating_q975": 1360.458403286627,
            "rating_q025": 1281.8299351262212
        },
        "llama-3.1-405b-instruct-fp8": {
            "rating": 1318.395400612751,
            "rating_q975": 1325.2427430391986,
            "rating_q025": 1311.5480581863033
        },
        "llama-4-scout-17b-16e-instruct": {
            "rating": 1317.486934814286,
            "rating_q975": 1328.0074860721186,
            "rating_q025": 1306.9663835564538
        },
        "gemma-3n-e4b-it": {
            "rating": 1317.4072366464943,
            "rating_q975": 1329.4661556920462,
            "rating_q025": 1305.3483176009427
        },
        "hunyuan-large-vision": {
            "rating": 1317.3864327960855,
            "rating_q975": 1335.8693791389185,
            "rating_q025": 1298.9034864532523
        },
        "qwen2.5-72b-instruct": {
            "rating": 1317.257974803426,
            "rating_q975": 1324.5678934483876,
            "rating_q025": 1309.9480561584644
        },
        "grok-2-mini-2024-08-13": {
            "rating": 1315.8888774062461,
            "rating_q975": 1322.795383365192,
            "rating_q025": 1308.9823714473005
        },
        "gemma-3-4b-it": {
            "rating": 1315.6754958021052,
            "rating_q975": 1340.922666720905,
            "rating_q025": 1290.428324883305
        },
        "gpt-4-turbo-2024-04-09": {
            "rating": 1315.0804862822142,
            "rating_q975": 1322.2701751555908,
            "rating_q025": 1307.890797408838
        },
        "deepseek-v2.5": {
            "rating": 1314.720253299297,
            "rating_q975": 1323.9839446485107,
            "rating_q025": 1305.456561950083
        },
        "mistral-small-3.1-24b-instruct-2503": {
            "rating": 1313.4867862860108,
            "rating_q975": 1323.704209054901,
            "rating_q025": 1303.2693635171206
        },
        "llama-3.3-70b-instruct": {
            "rating": 1311.5814210967073,
            "rating_q975": 1318.0729942341513,
            "rating_q025": 1305.0898479592636
        },
        "qwen2.5-plus-1127": {
            "rating": 1307.773552536179,
            "rating_q975": 1321.217415880949,
            "rating_q025": 1294.3296891914092
        },
        "gpt-4-0125-preview": {
            "rating": 1306.5562826575908,
            "rating_q975": 1314.388445066456,
            "rating_q025": 1298.7241202487257
        },
        "gpt-oss-20b": {
            "rating": 1305.7662577797446,
            "rating_q975": 1321.921310502114,
            "rating_q025": 1289.611205057375
        },
        "mistral-large-2407": {
            "rating": 1304.3931072664686,
            "rating_q975": 1312.2624823250426,
            "rating_q025": 1296.5237322078951
        },
        "mistral-large-2411": {
            "rating": 1303.9139134629,
            "rating_q975": 1312.7491463656193,
            "rating_q025": 1295.0786805601808
        },
        "gemini-1.5-flash-001": {
            "rating": 1300.8091678562178,
            "rating_q975": 1308.8831640151811,
            "rating_q025": 1292.7351716972546
        },
        "amazon-nova-pro-v1.0": {
            "rating": 1300.2273654247215,
            "rating_q975": 1309.210809389199,
            "rating_q025": 1291.243921460244
        },
        "gpt-4-1106-preview": {
            "rating": 1299.9323888624908,
            "rating_q975": 1307.658399997874,
            "rating_q025": 1292.2063777271073
        },
        "gemma-2-27b-it": {
            "rating": 1299.7138750104555,
            "rating_q975": 1305.921850293135,
            "rating_q025": 1293.5058997277758
        },
        "llama-3.1-70b-instruct": {
            "rating": 1295.232822914421,
            "rating_q975": 1302.1016450303357,
            "rating_q025": 1288.3640007985057
        },
        "athene-70b-0725": {
            "rating": 1292.1102818767774,
            "rating_q975": 1303.7019166979264,
            "rating_q025": 1280.5186470556284
        },
        "c4ai-aya-expanse-32b": {
            "rating": 1289.1197990465098,
            "rating_q975": 1297.5998156235955,
            "rating_q025": 1280.639782469424
        },
        "gemma-2-9b-it-simpo": {
            "rating": 1288.5494568866206,
            "rating_q975": 1306.4646032103542,
            "rating_q025": 1270.6343105628873
        },
        "nemotron-4-340b-instruct": {
            "rating": 1287.9783005770585,
            "rating_q975": 1300.6739852913342,
            "rating_q025": 1275.2826158627827
        },
        "qwen2.5-coder-32b-instruct": {
            "rating": 1287.56390441332,
            "rating_q975": 1305.0208540914366,
            "rating_q025": 1270.106954735203
        },
        "deepseek-coder-v2": {
            "rating": 1287.4953855849708,
            "rating_q975": 1300.8560561871427,
            "rating_q025": 1274.134714982799
        },
        "claude-3-sonnet-20240229": {
            "rating": 1286.541794216038,
            "rating_q975": 1294.6628895816718,
            "rating_q025": 1278.420698850404
        },
        "llama-3.1-nemotron-70b-instruct": {
            "rating": 1283.947340221268,
            "rating_q975": 1300.1431124432313,
            "rating_q025": 1267.7515679993048
        },
        "mistral-small-24b-instruct-2501": {
            "rating": 1283.4972324724217,
            "rating_q975": 1296.4427237672767,
            "rating_q025": 1270.5517411775668
        },
        "reka-core-20240904": {
            "rating": 1282.2016586791349,
            "rating_q975": 1298.8927517617528,
            "rating_q025": 1265.5105655965172
        },
        "command-r-plus-08-2024": {
            "rating": 1282.003277686119,
            "rating_q975": 1296.4512355994937,
            "rating_q025": 1267.5553197727443
        },
        "amazon-nova-lite-v1.0": {
            "rating": 1277.6093430866104,
            "rating_q975": 1287.476458712512,
            "rating_q025": 1267.7422274607088
        },
        "gpt-4-0613": {
            "rating": 1277.515541535957,
            "rating_q975": 1286.2979761267432,
            "rating_q025": 1268.733106945171
        },
        "gpt-4-0314": {
            "rating": 1276.1354505330532,
            "rating_q975": 1287.1079359839632,
            "rating_q025": 1265.1629650821433
        },
        "llama-3.1-tulu-3-70b": {
            "rating": 1274.293493888143,
            "rating_q975": 1298.0358348100954,
            "rating_q025": 1250.551152966191
        },
        "hunyuan-standard-256k": {
            "rating": 1273.3090233524395,
            "rating_q975": 1297.7092203111827,
            "rating_q025": 1248.9088263936965
        },
        "phi-4": {
            "rating": 1270.219677540144,
            "rating_q975": 1280.2895806468014,
            "rating_q025": 1260.1497744334865
        },
        "gemini-1.5-flash-8b-001": {
            "rating": 1269.6194781910267,
            "rating_q975": 1277.3004499701162,
            "rating_q025": 1261.9385064119374
        },
        "llama-3.1-nemotron-51b-instruct": {
            "rating": 1269.01119184657,
            "rating_q975": 1290.8835762240642,
            "rating_q025": 1247.1388074690758
        },
        "glm-4-0520": {
            "rating": 1268.1504254939666,
            "rating_q975": 1283.9641478219003,
            "rating_q025": 1252.336703166033
        },
        "gemma-2-9b-it": {
            "rating": 1267.9894231515543,
            "rating_q975": 1275.1279023938216,
            "rating_q025": 1260.8509439092873
        },
        "claude-3-haiku-20240307": {
            "rating": 1267.2763545628454,
            "rating_q975": 1274.2949185350903,
            "rating_q025": 1260.2577905906003
        },
        "reka-flash-20240904": {
            "rating": 1266.946517005105,
            "rating_q975": 1283.3791895953666,
            "rating_q025": 1250.5138444148436
        },
        "command-r-08-2024": {
            "rating": 1264.131111845385,
            "rating_q975": 1278.019917410675,
            "rating_q025": 1250.242306280095
        },
        "ministral-8b-2410": {
            "rating": 1263.3940492166087,
            "rating_q975": 1281.932757213961,
            "rating_q025": 1244.8553412192564
        },
        "command-r-plus": {
            "rating": 1263.0132938742915,
            "rating_q975": 1271.442874090684,
            "rating_q025": 1254.583713657899
        },
        "qwen2-72b-instruct": {
            "rating": 1261.1959168662054,
            "rating_q975": 1270.7821991473304,
            "rating_q025": 1251.6096345850804
        },
        "jamba-1.5-large": {
            "rating": 1260.729283183358,
            "rating_q975": 1277.2925492744682,
            "rating_q025": 1244.1660170922478
        },
        "c4ai-aya-expanse-8b": {
            "rating": 1254.3539953303307,
            "rating_q975": 1267.8562911641375,
            "rating_q025": 1240.8516994965241
        },
        "llama-3-70b-instruct": {
            "rating": 1252.817780447183,
            "rating_q975": 1259.8375383638968,
            "rating_q025": 1245.798022530469
        },
        "amazon-nova-micro-v1.0": {
            "rating": 1252.3315517437613,
            "rating_q975": 1262.6722632067392,
            "rating_q025": 1241.9908402807835
        },
        "olmo-2-0325-32b-instruct": {
            "rating": 1246.9262835905765,
            "rating_q975": 1279.1766930468432,
            "rating_q025": 1214.6758741343097
        },
        "mistral-large-2402": {
            "rating": 1245.7298759520513,
            "rating_q975": 1255.1008271737985,
            "rating_q025": 1236.358924730304
        },
        "qwen1.5-72b-chat": {
            "rating": 1235.0628349783346,
            "rating_q975": 1245.9985105873097,
            "rating_q025": 1224.1271593693596
        },
        "granite-3.1-8b-instruct": {
            "rating": 1233.8552928590243,
            "rating_q975": 1259.7470082316643,
            "rating_q025": 1207.9635774863846
        },
        "command-r": {
            "rating": 1233.5688181815335,
            "rating_q975": 1242.9875773693846,
            "rating_q025": 1224.1500589936825
        },
        "qwen1.5-110b-chat": {
            "rating": 1230.0503341331598,
            "rating_q975": 1241.2320464963695,
            "rating_q025": 1218.86862176995
        },
        "llama-3.1-8b-instruct": {
            "rating": 1228.2702520625596,
            "rating_q975": 1235.5352000144078,
            "rating_q025": 1221.0053041107112
        },
        "llama-3.1-tulu-3-8b": {
            "rating": 1228.194826370594,
            "rating_q975": 1253.2404650591056,
            "rating_q025": 1203.1491876820824
        },
        "granite-3.1-2b-instruct": {
            "rating": 1227.2417782850675,
            "rating_q975": 1252.2133068800056,
            "rating_q025": 1202.2702496901297
        },
        "qwen1.5-32b-chat": {
            "rating": 1225.194987648173,
            "rating_q975": 1237.2359079616274,
            "rating_q025": 1213.1540673347192
        },
        "gemini-pro-dev-api": {
            "rating": 1224.7684618143794,
            "rating_q975": 1241.9611321041743,
            "rating_q025": 1207.5757915245845
        },
        "gemini-pro": {
            "rating": 1223.2867699822928,
            "rating_q975": 1261.957854205997,
            "rating_q025": 1184.6156857585884
        },
        "gpt-3.5-turbo-0125": {
            "rating": 1222.3880692013545,
            "rating_q975": 1230.9981040974608,
            "rating_q025": 1213.778034305248
        },
        "mistral-medium": {
            "rating": 1222.120914060291,
            "rating_q975": 1234.450760481122,
            "rating_q025": 1209.79106763946
        },
        "jamba-1.5-mini": {
            "rating": 1220.4299721536552,
            "rating_q975": 1236.8459992695434,
            "rating_q025": 1204.013945037767
        },
        "reka-flash-21b-20240226": {
            "rating": 1219.0598790000695,
            "rating_q975": 1231.360669368357,
            "rating_q025": 1206.7590886317819
        },
        "reka-flash-21b-20240226-online": {
            "rating": 1219.0385040788242,
            "rating_q975": 1234.0210818650928,
            "rating_q025": 1204.0559262925556
        },
        "mixtral-8x22b-instruct-v0.1": {
            "rating": 1218.2277954102697,
            "rating_q975": 1227.4519788669288,
            "rating_q025": 1209.0036119536105
        },
        "internlm2_5-20b-chat": {
            "rating": 1209.8134328041483,
            "rating_q975": 1224.7621981039206,
            "rating_q025": 1194.864667504376
        },
        "llama-3-8b-instruct": {
            "rating": 1209.020970688191,
            "rating_q975": 1216.9908823823262,
            "rating_q025": 1201.0510589940561
        },
        "yi-1.5-34b-chat": {
            "rating": 1206.8465332958276,
            "rating_q975": 1219.4527865331809,
            "rating_q025": 1194.2402800584741
        },
        "granite-3.0-8b-instruct": {
            "rating": 1206.3836340122807,
            "rating_q975": 1228.4309984250729,
            "rating_q025": 1184.336269599488
        },
        "qwen1.5-14b-chat": {
            "rating": 1195.372137487403,
            "rating_q975": 1209.636126257216,
            "rating_q025": 1181.1081487175902
        },
        "gemma-2-2b-it": {
            "rating": 1195.3066704865355,
            "rating_q975": 1203.2077876127328,
            "rating_q025": 1187.4055533603384
        },
        "phi-3-medium-4k-instruct": {
            "rating": 1193.8504329991677,
            "rating_q975": 1206.0786594153437,
            "rating_q025": 1181.6222065829916
        },
        "dbrx-instruct-preview": {
            "rating": 1191.3774659378664,
            "rating_q975": 1203.425091341542,
            "rating_q025": 1179.3298405341911
        },
        "qwq-32b-preview": {
            "rating": 1189.863393909552,
            "rating_q975": 1214.0563729637202,
            "rating_q025": 1165.6704148553838
        },
        "zephyr-orpo-141b-A35b-v0.1": {
            "rating": 1186.8639536376731,
            "rating_q975": 1213.9641581733688,
            "rating_q025": 1159.7637491019775
        },
        "mixtral-8x7b-instruct-v0.1": {
            "rating": 1186.6092061398313,
            "rating_q975": 1195.5853018867456,
            "rating_q025": 1177.633110392917
        },
        "openchat-3.5": {
            "rating": 1186.387287579486,
            "rating_q975": 1213.9381765046608,
            "rating_q025": 1158.8363986543113
        },
        "gpt-3.5-turbo-1106": {
            "rating": 1186.2507606779334,
            "rating_q975": 1206.1481094149392,
            "rating_q025": 1166.3534119409276
        },
        "wizardlm-70b": {
            "rating": 1185.2848527463045,
            "rating_q975": 1216.2184911265508,
            "rating_q025": 1154.3512143660582
        },
        "deepseek-llm-67b-chat": {
            "rating": 1182.412659877851,
            "rating_q975": 1218.7769149206513,
            "rating_q025": 1146.0484048350506
        },
        "tulu-2-dpo-70b": {
            "rating": 1179.0558816563134,
            "rating_q975": 1211.9096856458682,
            "rating_q025": 1146.2020776667584
        },
        "yi-34b-chat": {
            "rating": 1174.0795836631273,
            "rating_q975": 1191.3859995407176,
            "rating_q025": 1156.7731677855372
        },
        "openchat-3.5-0106": {
            "rating": 1173.0502883918434,
            "rating_q975": 1190.9618258694413,
            "rating_q025": 1155.1387509142455
        },
        "starling-lm-7b-beta": {
            "rating": 1172.9851501542748,
            "rating_q975": 1188.0686956832742,
            "rating_q025": 1157.9016046252752
        },
        "llama-3.2-3b-instruct": {
            "rating": 1167.8401224619013,
            "rating_q975": 1185.0018383870233,
            "rating_q025": 1150.678406536779
        },
        "granite-3.0-2b-instruct": {
            "rating": 1167.4695297427977,
            "rating_q975": 1190.1990375788037,
            "rating_q025": 1144.740021906792
        },
        "gemma-1.1-7b-it": {
            "rating": 1166.6158496132093,
            "rating_q975": 1178.5678391431702,
            "rating_q025": 1154.6638600832484
        },
        "phi-3-small-8k-instruct": {
            "rating": 1165.1570223396388,
            "rating_q975": 1177.7379721228178,
            "rating_q025": 1152.5760725564596
        },
        "qwen1.5-7b-chat": {
            "rating": 1164.9541499977483,
            "rating_q975": 1194.768611750577,
            "rating_q025": 1135.1396882449196
        },
        "smollm2-1.7b-instruct": {
            "rating": 1157.5917035043808,
            "rating_q975": 1186.5268130894112,
            "rating_q025": 1128.6565939193506
        },
        "starling-lm-7b-alpha": {
            "rating": 1153.7971635614363,
            "rating_q975": 1176.2948525883082,
            "rating_q025": 1131.2994745345645
        },
        "wizardlm-13b": {
            "rating": 1149.6714213394325,
            "rating_q975": 1190.1738543128758,
            "rating_q025": 1109.1689883659897
        },
        "vicuna-13b": {
            "rating": 1148.7010656873422,
            "rating_q975": 1169.6609514147888,
            "rating_q025": 1127.7411799598956
        },
        "vicuna-7b": {
            "rating": 1148.2346914785703,
            "rating_q975": 1192.4925044173006,
            "rating_q025": 1103.97687853984
        },
        "llama-2-13b-chat": {
            "rating": 1145.975027720849,
            "rating_q975": 1162.8364178091997,
            "rating_q025": 1129.1136376324987
        },
        "openhermes-2.5-mistral-7b": {
            "rating": 1145.4555441335315,
            "rating_q975": 1177.9560171969438,
            "rating_q025": 1112.9550710701194
        },
        "llama-2-70b-chat": {
            "rating": 1141.7242457021962,
            "rating_q975": 1153.9856416324842,
            "rating_q025": 1129.462849771908
        },
        "mistral-7b-instruct-v0.2": {
            "rating": 1138.2225060817325,
            "rating_q975": 1152.8488975888206,
            "rating_q025": 1123.5961145746442
        },
        "vicuna-33b": {
            "rating": 1137.3293204240208,
            "rating_q975": 1155.7306791365495,
            "rating_q025": 1118.9279617114921
        },
        "palm-2": {
            "rating": 1134.0038220768033,
            "rating_q975": 1171.1806541066874,
            "rating_q025": 1096.826990046919
        },
        "snowflake-arctic-instruct": {
            "rating": 1132.139870669792,
            "rating_q975": 1145.7762353908508,
            "rating_q025": 1118.5035059487332
        },
        "qwen-14b-chat": {
            "rating": 1127.6262502795114,
            "rating_q975": 1165.1550637002993,
            "rating_q025": 1090.0974368587235
        },
        "nous-hermes-2-mixtral-8x7b-dpo": {
            "rating": 1120.9408621343669,
            "rating_q975": 1155.9120330991325,
            "rating_q025": 1085.9696911696012
        },
        "gemma-1.1-2b-it": {
            "rating": 1119.371194161757,
            "rating_q975": 1136.4350389484753,
            "rating_q025": 1102.3073493750387
        },
        "gemma-7b-it": {
            "rating": 1116.4265837675416,
            "rating_q975": 1138.5409180989773,
            "rating_q025": 1094.312249436106
        },
        "llama-3.2-1b-instruct": {
            "rating": 1112.5668588014591,
            "rating_q975": 1130.3728242464845,
            "rating_q025": 1094.7608933564336
        },
        "phi-3-mini-4k-instruct-june-2024": {
            "rating": 1111.7544911213656,
            "rating_q975": 1129.8552213639446,
            "rating_q025": 1093.6537608787867
        },
        "zephyr-7b-beta": {
            "rating": 1109.1224739260447,
            "rating_q975": 1136.0526191154122,
            "rating_q025": 1082.192328736677
        },
        "phi-3-mini-4k-instruct": {
            "rating": 1108.4962414220347,
            "rating_q975": 1123.026011192025,
            "rating_q025": 1093.9664716520447
        },
        "mistral-7b-instruct": {
            "rating": 1100.0210122475357,
            "rating_q975": 1126.4520557453243,
            "rating_q025": 1073.5899687497472
        },
        "codellama-34b-instruct": {
            "rating": 1096.5620806345723,
            "rating_q975": 1128.925307615852,
            "rating_q025": 1064.1988536532926
        },
        "gemma-2b-it": {
            "rating": 1089.0564199488072,
            "rating_q975": 1119.50856062908,
            "rating_q025": 1058.6042792685344
        },
        "qwen1.5-4b-chat": {
            "rating": 1083.7891823444313,
            "rating_q975": 1107.0134801415845,
            "rating_q025": 1060.564884547278
        },
        "llama-2-7b-chat": {
            "rating": 1082.861506490261,
            "rating_q975": 1102.1975951942597,
            "rating_q025": 1063.525417786262
        },
        "phi-3-mini-128k-instruct": {
            "rating": 1080.0281674888656,
            "rating_q975": 1095.4733428055538,
            "rating_q025": 1064.5829921721775
        },
        "stripedhyena-nous-7b": {
            "rating": 1074.8568648938858,
            "rating_q975": 1106.4846400614292,
            "rating_q025": 1043.2290897263424
        },
        "llama2-70b-steerlm-chat": {
            "rating": 1065.7169776920896,
            "rating_q975": 1108.176033236984,
            "rating_q025": 1023.257922147195
        },
        "chatglm3-6b": {
            "rating": 1054.612432046672,
            "rating_q975": 1092.6403514470387,
            "rating_q025": 1016.5845126463053
        }
    },
    "math": {
        "claude-opus-4-1-20250805-thinking-16k": {
            "rating": 1479.6960500414236,
            "rating_q975": 1506.558729790553,
            "rating_q025": 1452.8333702922944
        },
        "grok-4-0709": {
            "rating": 1479.3293885837215,
            "rating_q975": 1499.42828513495,
            "rating_q025": 1459.230492032493
        },
        "gemini-2.5-pro": {
            "rating": 1476.9497298471038,
            "rating_q975": 1490.2128015069545,
            "rating_q025": 1463.686658187253
        },
        "gpt-5-high": {
            "rating": 1469.8634025878935,
            "rating_q975": 1492.091767241579,
            "rating_q025": 1447.6350379342077
        },
        "qwen-max-2025-08-15": {
            "rating": 1468.4982851717884,
            "rating_q975": 1505.5433160619384,
            "rating_q025": 1431.4532542816387
        },
        "o3-2025-04-16": {
            "rating": 1465.1286209961468,
            "rating_q975": 1476.8469961443159,
            "rating_q025": 1453.4102458479776
        },
        "claude-opus-4-1-20250805": {
            "rating": 1449.8187030119882,
            "rating_q975": 1471.1153526523788,
            "rating_q025": 1428.5220533715976
        },
        "qwen3-235b-a22b-instruct-2507": {
            "rating": 1449.1418093817888,
            "rating_q975": 1470.5492902129495,
            "rating_q025": 1427.734328550628
        },
        "deepseek-v3.1": {
            "rating": 1443.8713768477587,
            "rating_q975": 1482.3094666770066,
            "rating_q025": 1405.433287018511
        },
        "gpt-5-mini-high": {
            "rating": 1436.206188617327,
            "rating_q975": 1466.8077615247314,
            "rating_q025": 1405.6046157099222
        },
        "o4-mini-2025-04-16": {
            "rating": 1431.4426452321002,
            "rating_q975": 1444.280738546513,
            "rating_q025": 1418.604551917687
        },
        "claude-opus-4-20250514-thinking-16k": {
            "rating": 1430.155847165374,
            "rating_q975": 1445.645927473803,
            "rating_q025": 1414.665766856945
        },
        "gemini-2.5-flash": {
            "rating": 1427.8882253219244,
            "rating_q975": 1439.5566113081018,
            "rating_q025": 1416.2198393357473
        },
        "glm-4.5": {
            "rating": 1419.7638046950717,
            "rating_q975": 1444.233984659466,
            "rating_q025": 1395.2936247306775
        },
        "gpt-oss-120b": {
            "rating": 1418.731064494668,
            "rating_q975": 1444.9574639361963,
            "rating_q025": 1392.50466505314
        },
        "mistral-medium-2508": {
            "rating": 1418.476294831597,
            "rating_q975": 1450.5681085642682,
            "rating_q025": 1386.3844810989258
        },
        "minimax-m1": {
            "rating": 1417.0452689813908,
            "rating_q975": 1433.9622068345202,
            "rating_q025": 1400.1283311282614
        },
        "gpt-4.5-preview-2025-02-27": {
            "rating": 1416.1822807999952,
            "rating_q975": 1430.645730555245,
            "rating_q025": 1401.7188310447455
        },
        "glm-4.5-air": {
            "rating": 1415.9842277076757,
            "rating_q975": 1441.8927005486048,
            "rating_q025": 1390.0757548667466
        },
        "deepseek-r1": {
            "rating": 1414.3974883122567,
            "rating_q975": 1427.7841009122885,
            "rating_q025": 1401.0108757122246
        },
        "gpt-5-chat": {
            "rating": 1413.923732743579,
            "rating_q975": 1440.3403509091881,
            "rating_q025": 1387.5071145779696
        },
        "qwen3-235b-a22b-thinking-2507": {
            "rating": 1413.6649782128789,
            "rating_q975": 1440.221256292591,
            "rating_q025": 1387.1087001331666
        },
        "claude-sonnet-4-20250514-thinking-32k": {
            "rating": 1411.8427675232226,
            "rating_q975": 1428.1067954897146,
            "rating_q025": 1395.5787395567304
        },
        "o1-2024-12-17": {
            "rating": 1410.736565853669,
            "rating_q975": 1420.7748223522867,
            "rating_q025": 1400.698309355051
        },
        "o3-mini-high": {
            "rating": 1409.0073485902321,
            "rating_q975": 1421.6241171865697,
            "rating_q025": 1396.3905799938943
        },
        "qwen3-235b-a22b": {
            "rating": 1408.9957779692122,
            "rating_q975": 1423.7748858411983,
            "rating_q025": 1394.2166700972264
        },
        "claude-opus-4-20250514": {
            "rating": 1407.9716829705624,
            "rating_q975": 1420.9222912336802,
            "rating_q025": 1395.0210747074443
        },
        "qwen3-32b": {
            "rating": 1406.7278817535966,
            "rating_q975": 1436.5600406452584,
            "rating_q025": 1376.8957228619352
        },
        "qwen3-235b-a22b-no-thinking": {
            "rating": 1405.9883130972594,
            "rating_q975": 1419.6867202893782,
            "rating_q025": 1392.2899059051404
        },
        "mai-1-preview": {
            "rating": 1405.773857660532,
            "rating_q975": 1445.0292338855768,
            "rating_q025": 1366.5184814354875
        },
        "hunyuan-t1-20250711": {
            "rating": 1403.287346904093,
            "rating_q975": 1440.9242763244401,
            "rating_q025": 1365.6504174837462
        },
        "deepseek-r1-0528": {
            "rating": 1402.456222337131,
            "rating_q975": 1421.1471926178788,
            "rating_q025": 1383.7652520563831
        },
        "nvidia-llama-3.3-nemotron-super-49b-v1.5": {
            "rating": 1398.4762352765745,
            "rating_q975": 1434.6834060041383,
            "rating_q025": 1362.2690645490109
        },
        "chatgpt-4o-latest-20250326": {
            "rating": 1397.2002487890056,
            "rating_q975": 1407.9352783731688,
            "rating_q025": 1386.4652192048425
        },
        "kimi-k2-0711-preview": {
            "rating": 1394.558681641172,
            "rating_q975": 1412.1673849535016,
            "rating_q025": 1376.9499783288425
        },
        "grok-3-mini-high": {
            "rating": 1393.2670113903037,
            "rating_q975": 1412.8402735055104,
            "rating_q025": 1373.6937492750972
        },
        "o3-mini": {
            "rating": 1391.6618535381917,
            "rating_q975": 1400.4176811628151,
            "rating_q025": 1382.906025913568
        },
        "qwen3-30b-a3b-instruct-2507": {
            "rating": 1391.3169827386223,
            "rating_q975": 1416.8842429121942,
            "rating_q025": 1365.7497225650507
        },
        "claude-sonnet-4-20250514": {
            "rating": 1390.1105718359436,
            "rating_q975": 1404.07834939872,
            "rating_q025": 1376.1427942731673
        },
        "o1-preview": {
            "rating": 1389.3846125351656,
            "rating_q975": 1397.9403402477853,
            "rating_q025": 1380.8288848225457
        },
        "claude-3-7-sonnet-20250219-thinking-32k": {
            "rating": 1386.9264071307819,
            "rating_q975": 1398.028072381626,
            "rating_q025": 1375.8247418799378
        },
        "grok-3-preview-02-24": {
            "rating": 1386.8241153332442,
            "rating_q975": 1397.491487666504,
            "rating_q025": 1376.1567429999843
        },
        "llama-3.1-nemotron-ultra-253b-v1": {
            "rating": 1383.3427258951854,
            "rating_q975": 1420.3505496768828,
            "rating_q025": 1346.3349021134882
        },
        "qwen3-coder-480b-a35b-instruct": {
            "rating": 1376.0889266239194,
            "rating_q975": 1397.2232184743384,
            "rating_q025": 1354.9546347735002
        },
        "grok-3-mini-beta": {
            "rating": 1375.0537754639417,
            "rating_q975": 1389.9362186175376,
            "rating_q025": 1360.1713323103456
        },
        "qwen3-30b-a3b": {
            "rating": 1373.2152332851738,
            "rating_q975": 1387.3353348754526,
            "rating_q025": 1359.0951316948947
        },
        "qwen2.5-max": {
            "rating": 1372.4499752435488,
            "rating_q975": 1381.7951937815865,
            "rating_q025": 1363.104756705511
        },
        "deepseek-v3-0324": {
            "rating": 1368.4147471208232,
            "rating_q975": 1380.2631100056278,
            "rating_q025": 1356.5663842360186
        },
        "qwq-32b": {
            "rating": 1368.2928240473,
            "rating_q975": 1381.8175253255195,
            "rating_q025": 1354.7681227690807
        },
        "o1-mini": {
            "rating": 1367.2383162808799,
            "rating_q975": 1374.0336059775852,
            "rating_q025": 1360.4430265841743
        },
        "gpt-5-nano-high": {
            "rating": 1364.292654283391,
            "rating_q975": 1398.2808601053566,
            "rating_q025": 1330.304448461425
        },
        "gpt-4.1-2025-04-14": {
            "rating": 1362.946719628348,
            "rating_q975": 1375.1794580296996,
            "rating_q025": 1350.7139812269966
        },
        "gemini-2.0-flash-001": {
            "rating": 1361.229423849774,
            "rating_q975": 1369.9319190880472,
            "rating_q025": 1352.526928611501
        },
        "claude-3-7-sonnet-20250219": {
            "rating": 1360.7847668016348,
            "rating_q975": 1370.586326347492,
            "rating_q025": 1350.9832072557772
        },
        "hunyuan-turbos-20250416": {
            "rating": 1357.2139292526292,
            "rating_q975": 1375.9750436569752,
            "rating_q025": 1338.4528148482832
        },
        "mistral-medium-2505": {
            "rating": 1354.344017663533,
            "rating_q975": 1366.6744482485244,
            "rating_q025": 1342.0135870785416
        },
        "gpt-4.1-mini-2025-04-14": {
            "rating": 1353.245143741022,
            "rating_q975": 1365.8618313029406,
            "rating_q025": 1340.6284561791035
        },
        "gpt-oss-20b": {
            "rating": 1346.8907126216793,
            "rating_q975": 1374.04389947144,
            "rating_q025": 1319.7375257719186
        },
        "claude-3-5-sonnet-20241022": {
            "rating": 1346.8774085186794,
            "rating_q975": 1352.7390106963403,
            "rating_q025": 1341.0158063410183
        },
        "llama-3.3-nemotron-49b-super-v1": {
            "rating": 1345.5689530265458,
            "rating_q975": 1382.1002443271943,
            "rating_q025": 1309.0376617258971
        },
        "mistral-small-2506": {
            "rating": 1344.175748189523,
            "rating_q975": 1364.0633718509355,
            "rating_q025": 1324.28812452811
        },
        "claude-3-5-sonnet-20240620": {
            "rating": 1340.4024416082643,
            "rating_q975": 1346.7727650343925,
            "rating_q025": 1334.0321181821362
        },
        "gemini-1.5-pro-002": {
            "rating": 1339.726762318302,
            "rating_q975": 1345.9977509170128,
            "rating_q025": 1333.4557737195914
        },
        "qwen-plus-0125": {
            "rating": 1332.2182908255463,
            "rating_q975": 1351.083989355337,
            "rating_q025": 1313.3525922957556
        },
        "llama-4-maverick-17b-128e-instruct": {
            "rating": 1331.5277818507316,
            "rating_q975": 1343.444265946838,
            "rating_q025": 1319.611297754625
        },
        "gemini-2.0-flash-lite-preview-02-05": {
            "rating": 1330.0826275849508,
            "rating_q975": 1339.795829065941,
            "rating_q025": 1320.3694261039607
        },
        "gemma-3-27b-it": {
            "rating": 1329.6087136618796,
            "rating_q975": 1339.8977951189595,
            "rating_q025": 1319.3196322047995
        },
        "gemma-3-12b-it": {
            "rating": 1323.448935150106,
            "rating_q975": 1350.176567811121,
            "rating_q025": 1296.7213024890914
        },
        "llama-3.1-405b-instruct-fp8": {
            "rating": 1320.7099583156823,
            "rating_q975": 1327.1086573431471,
            "rating_q025": 1314.3112592882176
        },
        "deepseek-v3": {
            "rating": 1320.3921584279674,
            "rating_q975": 1330.3264425260459,
            "rating_q025": 1310.4578743298887
        },
        "step-2-16k-exp-202412": {
            "rating": 1318.0927264541272,
            "rating_q975": 1336.447261499914,
            "rating_q025": 1299.7381914083403
        },
        "llama-3.1-405b-instruct-bf16": {
            "rating": 1317.7751479860278,
            "rating_q975": 1324.9114955844461,
            "rating_q025": 1310.6388003876095
        },
        "athene-v2-chat": {
            "rating": 1317.6196218662549,
            "rating_q975": 1326.0280947471629,
            "rating_q025": 1309.2111489853467
        },
        "step-1o-turbo-202506": {
            "rating": 1315.6314500919063,
            "rating_q975": 1337.264770578191,
            "rating_q025": 1293.9981296056217
        },
        "llama-4-scout-17b-16e-instruct": {
            "rating": 1314.9537189641476,
            "rating_q975": 1331.0927731285226,
            "rating_q025": 1298.8146647997726
        },
        "amazon-nova-experimental-chat-05-14": {
            "rating": 1313.581695327202,
            "rating_q975": 1329.9706891853693,
            "rating_q025": 1297.192701469034
        },
        "claude-3-opus-20240229": {
            "rating": 1312.8552954714187,
            "rating_q975": 1318.1180005571705,
            "rating_q025": 1307.5925903856669
        },
        "yi-lightning": {
            "rating": 1312.749868307651,
            "rating_q975": 1321.2585228476505,
            "rating_q025": 1304.2412137676517
        },
        "hunyuan-turbos-20250226": {
            "rating": 1312.5348529036664,
            "rating_q975": 1341.3766134600908,
            "rating_q025": 1283.6930923472419
        },
        "qwen2.5-plus-1127": {
            "rating": 1312.1462691366792,
            "rating_q975": 1324.659233475097,
            "rating_q025": 1299.6333047982614
        },
        "gpt-4o-2024-08-06": {
            "rating": 1310.6334939881697,
            "rating_q975": 1317.5020621243723,
            "rating_q025": 1303.7649258519673
        },
        "gpt-4o-2024-05-13": {
            "rating": 1309.612098954417,
            "rating_q975": 1315.2437634523492,
            "rating_q025": 1303.9804344564845
        },
        "command-a-03-2025": {
            "rating": 1307.822143685965,
            "rating_q975": 1318.4120976791655,
            "rating_q025": 1297.2321896927647
        },
        "gpt-4-1106-preview": {
            "rating": 1307.6288057735592,
            "rating_q975": 1314.3404621811192,
            "rating_q025": 1300.9171493659992
        },
        "gemini-advanced-0514": {
            "rating": 1304.794632620853,
            "rating_q975": 1313.3843156363632,
            "rating_q025": 1296.2049496053428
        },
        "gpt-4-0125-preview": {
            "rating": 1303.4224073709925,
            "rating_q975": 1310.191355791737,
            "rating_q025": 1296.653458950248
        },
        "qwen2.5-72b-instruct": {
            "rating": 1302.7478639890035,
            "rating_q975": 1309.8354372870683,
            "rating_q025": 1295.6602906909386
        },
        "gpt-4-turbo-2024-04-09": {
            "rating": 1301.2822559142733,
            "rating_q975": 1307.7173712697618,
            "rating_q025": 1294.847140558785
        },
        "llama-3.3-70b-instruct": {
            "rating": 1300.0106444808107,
            "rating_q975": 1307.1344307783638,
            "rating_q025": 1292.8868581832573
        },
        "hunyuan-large-2025-02-10": {
            "rating": 1299.3302979975215,
            "rating_q975": 1322.6794892324526,
            "rating_q025": 1275.9811067625903
        },
        "gemini-1.5-pro-001": {
            "rating": 1299.0553736946197,
            "rating_q975": 1305.9604862212025,
            "rating_q025": 1292.150261168037
        },
        "glm-4-plus-0111": {
            "rating": 1298.9642289229494,
            "rating_q975": 1317.1463807093362,
            "rating_q025": 1280.7820771365625
        },
        "deepseek-v2.5-1210": {
            "rating": 1298.8108647636063,
            "rating_q975": 1314.0546402122552,
            "rating_q025": 1283.5670893149572
        },
        "qwen-max-0919": {
            "rating": 1297.87815418443,
            "rating_q975": 1308.1527303664618,
            "rating_q025": 1287.6035780023983
        },
        "grok-2-2024-08-13": {
            "rating": 1297.0264928199394,
            "rating_q975": 1303.1400238714714,
            "rating_q025": 1290.9129617684077
        },
        "hunyuan-large-vision": {
            "rating": 1296.3867378111,
            "rating_q975": 1323.8732698285742,
            "rating_q025": 1268.9002057936254
        },
        "hunyuan-standard-2025-02-10": {
            "rating": 1295.5504219476293,
            "rating_q975": 1319.2465593972254,
            "rating_q025": 1271.8542844980334
        },
        "gemini-1.5-flash-002": {
            "rating": 1294.8357729314469,
            "rating_q975": 1302.231868391088,
            "rating_q025": 1287.4396774718055
        },
        "deepseek-v2.5": {
            "rating": 1294.5155065669373,
            "rating_q975": 1302.941053108211,
            "rating_q025": 1286.0899600256637
        },
        "mistral-large-2407": {
            "rating": 1293.7137623215228,
            "rating_q975": 1300.6316662236943,
            "rating_q025": 1286.7958584193514
        },
        "glm-4-plus": {
            "rating": 1293.166901296761,
            "rating_q975": 1301.791746130657,
            "rating_q025": 1284.5420564628648
        },
        "hunyuan-turbo-0110": {
            "rating": 1288.9053925559383,
            "rating_q975": 1317.8058515565915,
            "rating_q025": 1260.0049335552853
        },
        "mistral-large-2411": {
            "rating": 1286.8497987751439,
            "rating_q975": 1295.2616660640927,
            "rating_q025": 1278.4379314861953
        },
        "llama-3.1-nemotron-70b-instruct": {
            "rating": 1284.7617816346822,
            "rating_q975": 1299.5225292649106,
            "rating_q025": 1270.0010340044537
        },
        "gpt-4-0314": {
            "rating": 1284.3975971045659,
            "rating_q975": 1293.210288081802,
            "rating_q025": 1275.5849061273295
        },
        "gpt-4o-mini-2024-07-18": {
            "rating": 1283.214369078877,
            "rating_q975": 1289.1196607603056,
            "rating_q025": 1277.3090773974488
        },
        "claude-3-5-haiku-20241022": {
            "rating": 1282.902601023735,
            "rating_q975": 1290.2327578517147,
            "rating_q025": 1275.5724441957555
        },
        "gpt-4.1-nano-2025-04-14": {
            "rating": 1282.1866686439316,
            "rating_q975": 1305.0757832530674,
            "rating_q025": 1259.2975540347961
        },
        "qwen2.5-coder-32b-instruct": {
            "rating": 1279.2963208201347,
            "rating_q975": 1296.1959357009764,
            "rating_q025": 1262.396705939293
        },
        "grok-2-mini-2024-08-13": {
            "rating": 1278.0768180377022,
            "rating_q975": 1284.5733158232783,
            "rating_q025": 1271.5803202521258
        },
        "qwen2-72b-instruct": {
            "rating": 1277.15110619277,
            "rating_q975": 1285.5941229943844,
            "rating_q025": 1268.7080893911552
        },
        "llama-3.1-70b-instruct": {
            "rating": 1276.1043849288035,
            "rating_q975": 1282.5125298166624,
            "rating_q025": 1269.696240040944
        },
        "gpt-4-0613": {
            "rating": 1275.6711162457996,
            "rating_q975": 1283.1277814484558,
            "rating_q025": 1268.2144510431433
        },
        "amazon-nova-pro-v1.0": {
            "rating": 1275.0457826827578,
            "rating_q975": 1284.002385315182,
            "rating_q025": 1266.0891800503334
        },
        "deepseek-coder-v2": {
            "rating": 1275.0118870808121,
            "rating_q975": 1287.5616266648258,
            "rating_q025": 1262.4621474967983
        },
        "mistral-small-3.1-24b-instruct-2503": {
            "rating": 1274.9349893276858,
            "rating_q975": 1291.578613392461,
            "rating_q025": 1258.2913652629104
        },
        "llama-3.1-nemotron-51b-instruct": {
            "rating": 1274.8129452212752,
            "rating_q975": 1295.9860609880504,
            "rating_q025": 1253.6398294544997
        },
        "gemma-3n-e4b-it": {
            "rating": 1272.658127509903,
            "rating_q975": 1289.1766203620634,
            "rating_q025": 1256.1396346577424
        },
        "phi-4": {
            "rating": 1270.8331768479025,
            "rating_q975": 1280.6741212734896,
            "rating_q025": 1260.992232422315
        },
        "magistral-medium-2506": {
            "rating": 1269.8629557054046,
            "rating_q975": 1298.1289865562346,
            "rating_q025": 1241.5969248545746
        },
        "llama-3.1-tulu-3-70b": {
            "rating": 1267.1016586970309,
            "rating_q975": 1290.310312641118,
            "rating_q025": 1243.8930047529439
        },
        "mistral-small-24b-instruct-2501": {
            "rating": 1266.6705394682313,
            "rating_q975": 1279.342230844292,
            "rating_q025": 1253.9988480921704
        },
        "athene-70b-0725": {
            "rating": 1264.36941126708,
            "rating_q975": 1273.871491534679,
            "rating_q025": 1254.8673309994806
        },
        "hunyuan-standard-256k": {
            "rating": 1260.98899370857,
            "rating_q975": 1287.1729992607436,
            "rating_q025": 1234.8049881563961
        },
        "llama-3-70b-instruct": {
            "rating": 1260.814574830696,
            "rating_q975": 1267.1727835509537,
            "rating_q025": 1254.4563661104385
        },
        "gemini-1.5-flash-001": {
            "rating": 1260.3188099188583,
            "rating_q975": 1267.3349730605958,
            "rating_q025": 1253.3026467771208
        },
        "gemma-3-4b-it": {
            "rating": 1257.7356368253072,
            "rating_q975": 1285.6428976413922,
            "rating_q025": 1229.828376009222
        },
        "nemotron-4-340b-instruct": {
            "rating": 1256.8929450965952,
            "rating_q975": 1267.9300742220603,
            "rating_q025": 1245.8558159711304
        },
        "claude-3-sonnet-20240229": {
            "rating": 1256.8081623431726,
            "rating_q975": 1263.850321998011,
            "rating_q025": 1249.766002688334
        },
        "glm-4-0520": {
            "rating": 1254.1751587826716,
            "rating_q975": 1268.5425997566465,
            "rating_q025": 1239.8077178086965
        },
        "reka-core-20240904": {
            "rating": 1252.4828760100554,
            "rating_q975": 1265.3778875945407,
            "rating_q025": 1239.5878644255697
        },
        "amazon-nova-lite-v1.0": {
            "rating": 1251.574601297972,
            "rating_q975": 1261.4611548792,
            "rating_q025": 1241.6880477167444
        },
        "jamba-1.5-large": {
            "rating": 1250.2403257919482,
            "rating_q975": 1264.7624572024667,
            "rating_q025": 1235.7181943814296
        },
        "mistral-large-2402": {
            "rating": 1247.5777144657986,
            "rating_q975": 1255.6606266420347,
            "rating_q025": 1239.4948022895628
        },
        "gemma-2-27b-it": {
            "rating": 1247.2349020530282,
            "rating_q975": 1252.97348615807,
            "rating_q025": 1241.4963179479862
        },
        "reka-flash-20240904": {
            "rating": 1239.4843606278882,
            "rating_q975": 1252.1346633241499,
            "rating_q025": 1226.834057931627
        },
        "c4ai-aya-expanse-32b": {
            "rating": 1238.1775036084186,
            "rating_q975": 1246.6778036528826,
            "rating_q025": 1229.6772035639547
        },
        "gemini-1.5-flash-8b-001": {
            "rating": 1237.4410649304846,
            "rating_q975": 1244.6999408325316,
            "rating_q025": 1230.1821890284377
        },
        "command-r-plus-08-2024": {
            "rating": 1235.2625826778906,
            "rating_q975": 1247.7900919391686,
            "rating_q025": 1222.7350734166125
        },
        "claude-3-haiku-20240307": {
            "rating": 1234.4244312255041,
            "rating_q975": 1240.7777344616277,
            "rating_q025": 1228.0711279893803
        },
        "olmo-2-0325-32b-instruct": {
            "rating": 1234.0702861762181,
            "rating_q975": 1261.6865087893211,
            "rating_q025": 1206.4540635631154
        },
        "mixtral-8x22b-instruct-v0.1": {
            "rating": 1232.6632023118277,
            "rating_q975": 1240.6440484964571,
            "rating_q025": 1224.6823561271985
        },
        "qwq-32b-preview": {
            "rating": 1232.6167826263995,
            "rating_q975": 1255.034888602654,
            "rating_q025": 1210.1986766501448
        },
        "amazon-nova-micro-v1.0": {
            "rating": 1232.3897038695154,
            "rating_q975": 1242.1395074097722,
            "rating_q025": 1222.6399003292584
        },
        "qwen1.5-110b-chat": {
            "rating": 1227.109511272422,
            "rating_q975": 1237.4499203075377,
            "rating_q025": 1216.7691022373065
        },
        "mistral-medium": {
            "rating": 1225.2405873782968,
            "rating_q975": 1235.1830583294304,
            "rating_q025": 1215.298116427163
        },
        "ministral-8b-2410": {
            "rating": 1224.7617452744262,
            "rating_q975": 1242.170944484868,
            "rating_q025": 1207.352546063984
        },
        "internlm2_5-20b-chat": {
            "rating": 1221.0742247699654,
            "rating_q975": 1234.0339055566649,
            "rating_q025": 1208.1145439832665
        },
        "phi-3-medium-4k-instruct": {
            "rating": 1220.8404522347018,
            "rating_q975": 1230.4775056068963,
            "rating_q025": 1211.2033988625076
        },
        "gemma-2-9b-it": {
            "rating": 1220.752941634305,
            "rating_q975": 1227.3367836661434,
            "rating_q025": 1214.1690996024668
        },
        "llama-3.1-tulu-3-8b": {
            "rating": 1219.6034820952243,
            "rating_q975": 1242.9768683495454,
            "rating_q025": 1196.230095840903
        },
        "yi-1.5-34b-chat": {
            "rating": 1219.1089218880888,
            "rating_q975": 1229.2100950324066,
            "rating_q025": 1209.0077487437711
        },
        "command-r-plus": {
            "rating": 1216.6173481481478,
            "rating_q975": 1224.0626861064598,
            "rating_q025": 1209.1720101898356
        },
        "reka-flash-21b-20240226-online": {
            "rating": 1215.7082300079455,
            "rating_q975": 1228.6573342833588,
            "rating_q025": 1202.759125732532
        },
        "qwen1.5-72b-chat": {
            "rating": 1212.1074495891285,
            "rating_q975": 1220.9039218306527,
            "rating_q025": 1203.3109773476042
        },
        "command-r-08-2024": {
            "rating": 1210.9534416964002,
            "rating_q975": 1223.1956563287865,
            "rating_q025": 1198.7112270640139
        },
        "gemma-2-9b-it-simpo": {
            "rating": 1209.4066115289918,
            "rating_q975": 1223.6448738076654,
            "rating_q025": 1195.1683492503182
        },
        "c4ai-aya-expanse-8b": {
            "rating": 1206.5075673842282,
            "rating_q975": 1220.2494676959632,
            "rating_q025": 1192.765667072493
        },
        "granite-3.0-8b-instruct": {
            "rating": 1206.3145594863204,
            "rating_q975": 1222.9034923298857,
            "rating_q025": 1189.7256266427546
        },
        "qwen1.5-32b-chat": {
            "rating": 1205.2152275563317,
            "rating_q975": 1215.9865451265318,
            "rating_q025": 1194.4439099861315
        },
        "gpt-3.5-turbo-1106": {
            "rating": 1204.2405403927823,
            "rating_q975": 1218.7514899695086,
            "rating_q025": 1189.7295908160556
        },
        "reka-flash-21b-20240226": {
            "rating": 1202.5821838643328,
            "rating_q975": 1213.045984502198,
            "rating_q025": 1192.1183832264678
        },
        "llama-3.1-8b-instruct": {
            "rating": 1202.577650402045,
            "rating_q975": 1209.3796635437404,
            "rating_q025": 1195.7756372603499
        },
        "zephyr-orpo-141b-A35b-v0.1": {
            "rating": 1201.8565647235218,
            "rating_q975": 1223.261139979765,
            "rating_q025": 1180.4519894672785
        },
        "gpt-3.5-turbo-0125": {
            "rating": 1201.8060054643856,
            "rating_q975": 1209.3197928435677,
            "rating_q025": 1194.2922180852036
        },
        "dbrx-instruct-preview": {
            "rating": 1200.9097774256643,
            "rating_q975": 1211.4699328442948,
            "rating_q025": 1190.3496220070338
        },
        "granite-3.1-2b-instruct": {
            "rating": 1200.189931680995,
            "rating_q975": 1224.8010293254156,
            "rating_q025": 1175.5788340365743
        },
        "phi-3-mini-4k-instruct-june-2024": {
            "rating": 1199.2507145577838,
            "rating_q975": 1211.9355396486903,
            "rating_q025": 1186.565889466877
        },
        "phi-3-small-8k-instruct": {
            "rating": 1198.3489364058514,
            "rating_q975": 1210.0902556719877,
            "rating_q025": 1186.6076171397149
        },
        "granite-3.1-8b-instruct": {
            "rating": 1198.1613086030643,
            "rating_q975": 1224.2818988940287,
            "rating_q025": 1172.0407183121004
        },
        "llama-3-8b-instruct": {
            "rating": 1197.3230111683802,
            "rating_q975": 1204.1246594000581,
            "rating_q025": 1190.5213629367022
        },
        "gemini-pro": {
            "rating": 1197.0859711569592,
            "rating_q975": 1215.688818255493,
            "rating_q025": 1178.4831240584251
        },
        "mixtral-8x7b-instruct-v0.1": {
            "rating": 1196.2180217946336,
            "rating_q975": 1203.8189737070566,
            "rating_q025": 1188.6170698822107
        },
        "gemini-pro-dev-api": {
            "rating": 1193.943561747123,
            "rating_q975": 1207.0919359019658,
            "rating_q025": 1180.7951875922804
        },
        "jamba-1.5-mini": {
            "rating": 1192.8729043460255,
            "rating_q975": 1207.9372257691516,
            "rating_q025": 1177.8085829228994
        },
        "granite-3.0-2b-instruct": {
            "rating": 1181.682653020127,
            "rating_q975": 1198.3196953014663,
            "rating_q025": 1165.0456107387877
        },
        "command-r": {
            "rating": 1180.4568744768317,
            "rating_q975": 1188.9874743913606,
            "rating_q025": 1171.926274562303
        },
        "qwen1.5-14b-chat": {
            "rating": 1172.1574486667937,
            "rating_q975": 1184.8748999210861,
            "rating_q025": 1159.4399974125013
        },
        "llama-3.2-3b-instruct": {
            "rating": 1170.4745446418815,
            "rating_q975": 1185.408174958242,
            "rating_q025": 1155.5409143255213
        },
        "gemma-2-2b-it": {
            "rating": 1169.5281215012867,
            "rating_q975": 1176.531625854404,
            "rating_q025": 1162.5246171481697
        },
        "smollm2-1.7b-instruct": {
            "rating": 1168.9326700264623,
            "rating_q975": 1197.5498615756203,
            "rating_q025": 1140.3154784773044
        },
        "snowflake-arctic-instruct": {
            "rating": 1167.8609035022878,
            "rating_q975": 1178.225327133182,
            "rating_q025": 1157.4964798713934
        },
        "starling-lm-7b-beta": {
            "rating": 1166.6410009145602,
            "rating_q975": 1179.640514615601,
            "rating_q025": 1153.641487213519
        },
        "openchat-3.5-0106": {
            "rating": 1162.274339534293,
            "rating_q975": 1175.134359844987,
            "rating_q025": 1149.4143192235988
        },
        "gemma-1.1-7b-it": {
            "rating": 1160.9819596086058,
            "rating_q975": 1171.488911064973,
            "rating_q025": 1150.4750081522386
        },
        "wizardlm-70b": {
            "rating": 1159.563461614582,
            "rating_q975": 1177.8774960045646,
            "rating_q025": 1141.2494272245992
        },
        "deepseek-llm-67b-chat": {
            "rating": 1159.22557011439,
            "rating_q975": 1182.1764922771206,
            "rating_q025": 1136.2746479516595
        },
        "phi-3-mini-4k-instruct": {
            "rating": 1159.182808466456,
            "rating_q975": 1170.4006534702157,
            "rating_q025": 1147.9649634626962
        },
        "yi-34b-chat": {
            "rating": 1158.3563434910002,
            "rating_q975": 1170.7779406289208,
            "rating_q025": 1145.9347463530794
        },
        "openhermes-2.5-mistral-7b": {
            "rating": 1154.6257167908043,
            "rating_q975": 1174.1455450277588,
            "rating_q025": 1135.10588855385
        },
        "tulu-2-dpo-70b": {
            "rating": 1151.1124419913258,
            "rating_q975": 1169.630804799219,
            "rating_q025": 1132.5940791834323
        },
        "phi-3-mini-128k-instruct": {
            "rating": 1145.7109771895173,
            "rating_q975": 1158.0492551762945,
            "rating_q025": 1133.3726992027398
        },
        "llama-2-70b-chat": {
            "rating": 1141.0161173264426,
            "rating_q975": 1150.392045358414,
            "rating_q025": 1131.640189294471
        },
        "llama-3.2-1b-instruct": {
            "rating": 1135.6060594383666,
            "rating_q975": 1150.6128879856253,
            "rating_q025": 1120.5992308911082
        },
        "mistral-7b-instruct-v0.2": {
            "rating": 1134.8282412799035,
            "rating_q975": 1146.109935596046,
            "rating_q025": 1123.546546963761
        },
        "starling-lm-7b-alpha": {
            "rating": 1132.062347778737,
            "rating_q975": 1147.0806852647715,
            "rating_q025": 1117.0440102927023
        },
        "dolphin-2.2.1-mistral-7b": {
            "rating": 1129.1808515827438,
            "rating_q975": 1161.244280582255,
            "rating_q025": 1097.1174225832328
        },
        "qwen-14b-chat": {
            "rating": 1127.8379719751392,
            "rating_q975": 1150.8999122972184,
            "rating_q025": 1104.7760316530603
        },
        "openchat-3.5": {
            "rating": 1127.0349810162156,
            "rating_q975": 1144.8920521955897,
            "rating_q025": 1109.1779098368418
        },
        "qwen1.5-7b-chat": {
            "rating": 1126.4694036817395,
            "rating_q975": 1146.2091067759516,
            "rating_q025": 1106.7297005875278
        },
        "vicuna-33b": {
            "rating": 1120.96157084042,
            "rating_q975": 1132.8205680403355,
            "rating_q025": 1109.102573640505
        },
        "llama2-70b-steerlm-chat": {
            "rating": 1120.0578669749302,
            "rating_q975": 1146.131046423017,
            "rating_q025": 1093.9846875268436
        },
        "gemma-7b-it": {
            "rating": 1118.5832739353987,
            "rating_q975": 1134.3871981090278,
            "rating_q025": 1102.7793497617695
        },
        "llama-2-13b-chat": {
            "rating": 1118.2630340016647,
            "rating_q975": 1130.7843156920658,
            "rating_q025": 1105.7417523112636
        },
        "palm-2": {
            "rating": 1115.1655658927366,
            "rating_q975": 1133.8436466324479,
            "rating_q025": 1096.4874851530253
        },
        "solar-10.7b-instruct-v1.0": {
            "rating": 1114.172686052586,
            "rating_q975": 1135.4469334002376,
            "rating_q025": 1092.8984387049345
        },
        "codellama-34b-instruct": {
            "rating": 1112.6502239699382,
            "rating_q975": 1130.9909539186892,
            "rating_q025": 1094.3094940211872
        },
        "gemma-1.1-2b-it": {
            "rating": 1110.472134876492,
            "rating_q975": 1125.4692190271658,
            "rating_q025": 1095.4750507258184
        },
        "nous-hermes-2-mixtral-8x7b-dpo": {
            "rating": 1103.124336951047,
            "rating_q975": 1124.0153093212286,
            "rating_q025": 1082.2333645808658
        },
        "mpt-30b-chat": {
            "rating": 1100.2627576923555,
            "rating_q975": 1133.2389132179544,
            "rating_q025": 1067.2866021667564
        },
        "llama-2-7b-chat": {
            "rating": 1092.4813230804155,
            "rating_q975": 1105.6507175154413,
            "rating_q025": 1079.3119286453896
        },
        "qwen1.5-4b-chat": {
            "rating": 1088.8265830194255,
            "rating_q975": 1105.8340499308422,
            "rating_q025": 1071.8191161080085
        },
        "zephyr-7b-beta": {
            "rating": 1088.7750854580565,
            "rating_q975": 1105.2608124849557,
            "rating_q025": 1072.2893584311573
        },
        "stripedhyena-nous-7b": {
            "rating": 1088.0381387416974,
            "rating_q975": 1107.786022760789,
            "rating_q025": 1068.2902547226058
        },
        "vicuna-13b": {
            "rating": 1087.0199383710374,
            "rating_q975": 1099.9891107573683,
            "rating_q025": 1074.0507659847062
        },
        "mistral-7b-instruct": {
            "rating": 1086.27708149247,
            "rating_q975": 1104.5507993232322,
            "rating_q025": 1068.0033636617075
        },
        "guanaco-33b": {
            "rating": 1080.6844784198443,
            "rating_q975": 1112.2789351904107,
            "rating_q025": 1049.090021649278
        },
        "gemma-2b-it": {
            "rating": 1072.789844525145,
            "rating_q975": 1093.879501136205,
            "rating_q025": 1051.7001879140853
        },
        "wizardlm-13b": {
            "rating": 1071.8087193872045,
            "rating_q975": 1091.5796245932033,
            "rating_q025": 1052.0378141812057
        },
        "olmo-7b-instruct": {
            "rating": 1063.1404197867435,
            "rating_q975": 1081.4337708957296,
            "rating_q025": 1044.8470686777575
        },
        "vicuna-7b": {
            "rating": 1054.5284759927758,
            "rating_q975": 1075.3414830840675,
            "rating_q025": 1033.715468901484
        },
        "chatglm3-6b": {
            "rating": 1046.5692471691914,
            "rating_q975": 1069.4568648099057,
            "rating_q025": 1023.6816295284772
        },
        "gpt4all-13b-snoozy": {
            "rating": 998.0580257153022,
            "rating_q975": 1034.7434577210436,
            "rating_q025": 961.3725937095608
        },
        "mpt-7b-chat": {
            "rating": 986.6058575850216,
            "rating_q975": 1011.5558046474571,
            "rating_q025": 961.6559105225863
        },
        "alpaca-13b": {
            "rating": 986.4916142679783,
            "rating_q975": 1008.8532775638748,
            "rating_q025": 964.1299509720818
        },
        "chatglm2-6b": {
            "rating": 985.8104339637878,
            "rating_q975": 1018.6033531428277,
            "rating_q025": 953.0175147847478
        },
        "RWKV-4-Raven-14B": {
            "rating": 984.8506018160916,
            "rating_q975": 1008.7558829144666,
            "rating_q025": 960.9453207177168
        },
        "koala-13b": {
            "rating": 984.728519536008,
            "rating_q975": 1005.6384610102302,
            "rating_q025": 963.8185780617856
        },
        "chatglm-6b": {
            "rating": 980.5497640872147,
            "rating_q975": 1005.6239308830618,
            "rating_q025": 955.4755972913676
        },
        "oasst-pythia-12b": {
            "rating": 958.4395523844435,
            "rating_q975": 980.0546768745014,
            "rating_q025": 936.8244278943855
        },
        "dolly-v2-12b": {
            "rating": 947.3201555542473,
            "rating_q975": 975.6977093894791,
            "rating_q025": 918.9426017190156
        },
        "fastchat-t5-3b": {
            "rating": 921.8436911716581,
            "rating_q975": 947.3320710950384,
            "rating_q025": 896.3553112482779
        },
        "llama-13b": {
            "rating": 913.3298860684195,
            "rating_q975": 946.0931945128543,
            "rating_q025": 880.5665776239847
        },
        "stablelm-tuned-alpha-7b": {
            "rating": 893.2343281804617,
            "rating_q975": 921.6641758160088,
            "rating_q025": 864.8044805449147
        }
    },
    "multiturn": {
        "chatgpt-4o-latest-20250326": {
            "rating": 1471.814968349744,
            "rating_q975": 1480.3380938457492,
            "rating_q025": 1463.2918428537391
        },
        "claude-opus-4-1-20250805-thinking-16k": {
            "rating": 1468.6879434853151,
            "rating_q975": 1484.8084311453645,
            "rating_q025": 1452.5674558252658
        },
        "claude-opus-4-1-20250805": {
            "rating": 1462.9865247586736,
            "rating_q975": 1477.3273858848938,
            "rating_q025": 1448.6456636324533
        },
        "gpt-4.5-preview-2025-02-27": {
            "rating": 1462.6473812493107,
            "rating_q975": 1475.8343454026194,
            "rating_q025": 1449.4604170960022
        },
        "gemini-2.5-pro": {
            "rating": 1460.9702209786346,
            "rating_q975": 1470.0160983851108,
            "rating_q025": 1451.9243435721585
        },
        "gpt-5-chat": {
            "rating": 1452.3915121068276,
            "rating_q975": 1467.8885602313653,
            "rating_q025": 1436.89446398229
        },
        "qwen-max-2025-08-15": {
            "rating": 1443.232632886569,
            "rating_q975": 1464.116519067532,
            "rating_q025": 1422.3487467056061
        },
        "gpt-5-high": {
            "rating": 1434.8326504233696,
            "rating_q975": 1449.9568348836008,
            "rating_q025": 1419.7084659631387
        },
        "qwen3-235b-a22b-instruct-2507": {
            "rating": 1432.5579766354595,
            "rating_q975": 1445.9060385813882,
            "rating_q025": 1419.209914689531
        },
        "claude-opus-4-20250514-thinking-16k": {
            "rating": 1431.927994143796,
            "rating_q975": 1442.0209731539812,
            "rating_q025": 1421.8350151336106
        },
        "claude-opus-4-20250514": {
            "rating": 1425.35550405916,
            "rating_q975": 1434.427936291634,
            "rating_q025": 1416.283071826686
        },
        "o3-2025-04-16": {
            "rating": 1425.054913839357,
            "rating_q975": 1433.4735067982162,
            "rating_q025": 1416.6363208804974
        },
        "kimi-k2-0711-preview": {
            "rating": 1425.0031633631138,
            "rating_q975": 1436.290585284201,
            "rating_q025": 1413.7157414420265
        },
        "gpt-4.1-2025-04-14": {
            "rating": 1422.8700793975695,
            "rating_q975": 1431.7753123158664,
            "rating_q025": 1413.9648464792726
        },
        "grok-4-0709": {
            "rating": 1422.647338362898,
            "rating_q975": 1434.7970518396637,
            "rating_q025": 1410.4976248861324
        },
        "deepseek-v3.1-thinking": {
            "rating": 1412.2512152198876,
            "rating_q975": 1436.570466153243,
            "rating_q025": 1387.931964286532
        },
        "claude-sonnet-4-20250514-thinking-32k": {
            "rating": 1412.1012612795737,
            "rating_q975": 1422.302060174851,
            "rating_q025": 1401.9004623842964
        },
        "deepseek-v3-0324": {
            "rating": 1409.1044383644787,
            "rating_q975": 1417.791365780741,
            "rating_q025": 1400.4175109482164
        },
        "mistral-medium-2508": {
            "rating": 1407.8961211917938,
            "rating_q975": 1425.974452395675,
            "rating_q025": 1389.8177899879129
        },
        "grok-3-preview-02-24": {
            "rating": 1407.051474583927,
            "rating_q975": 1415.943187242183,
            "rating_q025": 1398.159761925671
        },
        "glm-4.5": {
            "rating": 1406.5728372089338,
            "rating_q975": 1421.3099957602835,
            "rating_q025": 1391.8356786575841
        },
        "deepseek-v3.1": {
            "rating": 1405.9472133259071,
            "rating_q975": 1426.9986176851774,
            "rating_q025": 1384.8958089666367
        },
        "deepseek-r1": {
            "rating": 1405.3648486648672,
            "rating_q975": 1416.954066488151,
            "rating_q025": 1393.7756308415833
        },
        "qwen-vl-max-2025-08-13": {
            "rating": 1404.627095743274,
            "rating_q975": 1444.085392024917,
            "rating_q025": 1365.1687994616311
        },
        "qwen3-235b-a22b-no-thinking": {
            "rating": 1404.3069477749596,
            "rating_q975": 1413.505816640511,
            "rating_q025": 1395.1080789094083
        },
        "deepseek-r1-0528": {
            "rating": 1402.9619067531626,
            "rating_q975": 1413.5559465579165,
            "rating_q025": 1392.3678669484084
        },
        "gemini-2.5-flash": {
            "rating": 1398.705297551119,
            "rating_q975": 1407.304552905478,
            "rating_q025": 1390.1060421967597
        },
        "claude-3-7-sonnet-20250219-thinking-32k": {
            "rating": 1398.0067061114678,
            "rating_q975": 1406.4676796364324,
            "rating_q025": 1389.5457325865034
        },
        "claude-sonnet-4-20250514": {
            "rating": 1396.8807277628953,
            "rating_q975": 1406.2368808610277,
            "rating_q025": 1387.524574664763
        },
        "mistral-medium-2505": {
            "rating": 1394.7619088448287,
            "rating_q975": 1403.5687745353275,
            "rating_q025": 1385.9550431543298
        },
        "claude-3-7-sonnet-20250219": {
            "rating": 1394.35237831897,
            "rating_q975": 1402.3153466927283,
            "rating_q025": 1386.3894099452116
        },
        "gpt-4.1-mini-2025-04-14": {
            "rating": 1392.3165812584255,
            "rating_q975": 1401.2215436351637,
            "rating_q025": 1383.411618881687
        },
        "qwen3-235b-a22b-thinking-2507": {
            "rating": 1390.791513602899,
            "rating_q975": 1407.0169261298806,
            "rating_q025": 1374.5661010759172
        },
        "hunyuan-turbos-20250416": {
            "rating": 1388.7028363304837,
            "rating_q975": 1402.4604769792468,
            "rating_q025": 1374.9451956817209
        },
        "o1-preview": {
            "rating": 1387.5455046512484,
            "rating_q975": 1396.343436362213,
            "rating_q025": 1378.7475729402838
        },
        "gpt-5-mini-high": {
            "rating": 1386.6977825323388,
            "rating_q975": 1404.347707897376,
            "rating_q025": 1369.0478571673016
        },
        "claude-3-5-sonnet-20241022": {
            "rating": 1384.9505403770902,
            "rating_q975": 1390.5688433076386,
            "rating_q025": 1379.3322374465417
        },
        "o4-mini-2025-04-16": {
            "rating": 1384.0244880430987,
            "rating_q975": 1393.0130561886833,
            "rating_q025": 1375.035919897514
        },
        "hunyuan-t1-20250711": {
            "rating": 1383.7295341086485,
            "rating_q975": 1403.7582421031448,
            "rating_q025": 1363.7008261141523
        },
        "o1-2024-12-17": {
            "rating": 1383.4933120942112,
            "rating_q975": 1392.3314423523561,
            "rating_q025": 1374.6551818360665
        },
        "qwen3-coder-480b-a35b-instruct": {
            "rating": 1382.5843863610467,
            "rating_q975": 1397.084367377799,
            "rating_q025": 1368.0844053442943
        },
        "mai-1-preview": {
            "rating": 1380.6502887762392,
            "rating_q975": 1404.7497927439301,
            "rating_q025": 1356.5507848085485
        },
        "glm-4.5-air": {
            "rating": 1380.0455797833984,
            "rating_q975": 1394.7379406920527,
            "rating_q025": 1365.353218874744
        },
        "qwen3-30b-a3b-instruct-2507": {
            "rating": 1374.8701203554604,
            "rating_q975": 1390.3803580488375,
            "rating_q025": 1359.3598826620832
        },
        "qwen3-235b-a22b": {
            "rating": 1373.049291096299,
            "rating_q975": 1382.8631017637802,
            "rating_q025": 1363.2354804288175
        },
        "qwen2.5-max": {
            "rating": 1369.279542948165,
            "rating_q975": 1377.649683060097,
            "rating_q025": 1360.909402836233
        },
        "mistral-small-2506": {
            "rating": 1368.9281337223267,
            "rating_q975": 1381.0449793311018,
            "rating_q025": 1356.8112881135517
        },
        "deepseek-v3": {
            "rating": 1368.2798364747287,
            "rating_q975": 1377.740603189094,
            "rating_q025": 1358.8190697603636
        },
        "gemma-3-27b-it": {
            "rating": 1363.355687087958,
            "rating_q975": 1371.914290161044,
            "rating_q025": 1354.7970840148719
        },
        "gemini-2.0-flash-001": {
            "rating": 1357.4301481024645,
            "rating_q975": 1365.1299595873036,
            "rating_q025": 1349.7303366176254
        },
        "command-a-03-2025": {
            "rating": 1356.0162860095454,
            "rating_q975": 1364.388319035285,
            "rating_q025": 1347.6442529838062
        },
        "minimax-m1": {
            "rating": 1355.8236815312223,
            "rating_q975": 1366.2162173235522,
            "rating_q025": 1345.4311457388926
        },
        "qwen-plus-0125": {
            "rating": 1349.2443251813795,
            "rating_q975": 1367.968164613265,
            "rating_q025": 1330.5204857494941
        },
        "grok-3-mini-beta": {
            "rating": 1347.9286361679656,
            "rating_q975": 1358.3151818101605,
            "rating_q025": 1337.5420905257704
        },
        "glm-4.5v": {
            "rating": 1347.4597792696138,
            "rating_q975": 1389.2684245068378,
            "rating_q025": 1305.65113403239
        },
        "claude-3-5-sonnet-20240620": {
            "rating": 1346.1139625070334,
            "rating_q975": 1352.8888472218537,
            "rating_q025": 1339.3390777922132
        },
        "gemma-3-12b-it": {
            "rating": 1344.7070311968414,
            "rating_q975": 1370.3005388658735,
            "rating_q025": 1319.113523527809
        },
        "grok-3-mini-high": {
            "rating": 1344.4447613293053,
            "rating_q975": 1356.557395718834,
            "rating_q025": 1332.3321269397763
        },
        "o3-mini-high": {
            "rating": 1343.5995982492907,
            "rating_q975": 1355.1393684971124,
            "rating_q025": 1332.0598280014692
        },
        "step-3": {
            "rating": 1343.516102628576,
            "rating_q975": 1368.1022992955714,
            "rating_q025": 1318.9299059615803
        },
        "llama-3.1-nemotron-ultra-253b-v1": {
            "rating": 1340.7668463291739,
            "rating_q975": 1370.911921078792,
            "rating_q025": 1310.621771579556
        },
        "llama-3.1-405b-instruct-bf16": {
            "rating": 1338.059625681663,
            "rating_q975": 1345.3022805946264,
            "rating_q025": 1330.8169707686998
        },
        "nvidia-llama-3.3-nemotron-super-49b-v1.5": {
            "rating": 1337.7484493546956,
            "rating_q975": 1360.1598988170026,
            "rating_q025": 1315.3369998923883
        },
        "qwen3-32b": {
            "rating": 1336.9210141544377,
            "rating_q975": 1360.1295287618523,
            "rating_q025": 1313.712499547023
        },
        "o3-mini": {
            "rating": 1336.5064850542071,
            "rating_q975": 1343.7850698904433,
            "rating_q025": 1329.2279002179707
        },
        "hunyuan-turbos-20250226": {
            "rating": 1336.3839479295386,
            "rating_q975": 1368.5155683590915,
            "rating_q025": 1304.2523274999858
        },
        "gpt-4o-2024-05-13": {
            "rating": 1336.3635264542436,
            "rating_q975": 1342.4500078551937,
            "rating_q025": 1330.2770450532933
        },
        "glm-4-plus-0111": {
            "rating": 1331.1054351727134,
            "rating_q975": 1350.090467563431,
            "rating_q025": 1312.1204027819956
        },
        "gpt-5-nano-high": {
            "rating": 1329.4324943377921,
            "rating_q975": 1349.9175609002416,
            "rating_q025": 1308.9474277753427
        },
        "llama-3.1-405b-instruct-fp8": {
            "rating": 1328.9634496600606,
            "rating_q975": 1335.6575190955182,
            "rating_q025": 1322.269380224603
        },
        "llama-3.3-nemotron-49b-super-v1": {
            "rating": 1328.850038914382,
            "rating_q975": 1359.8365532201908,
            "rating_q025": 1297.863524608573
        },
        "gemini-1.5-pro-002": {
            "rating": 1328.3566024091538,
            "rating_q975": 1334.8185143686894,
            "rating_q025": 1321.894690449618
        },
        "yi-lightning": {
            "rating": 1327.5272015647024,
            "rating_q975": 1336.9642262339796,
            "rating_q025": 1318.0901768954254
        },
        "gemini-2.0-flash-lite-preview-02-05": {
            "rating": 1326.9364511059243,
            "rating_q975": 1336.5236227272023,
            "rating_q025": 1317.3492794846463
        },
        "hunyuan-turbo-0110": {
            "rating": 1325.3087299739902,
            "rating_q975": 1354.3426579995162,
            "rating_q025": 1296.274801948464
        },
        "gpt-4o-2024-08-06": {
            "rating": 1323.7532513490305,
            "rating_q975": 1331.1326075188563,
            "rating_q025": 1316.3738951792047
        },
        "step-1o-turbo-202506": {
            "rating": 1322.5844532890123,
            "rating_q975": 1337.8382851868114,
            "rating_q025": 1307.3306213912135
        },
        "grok-2-2024-08-13": {
            "rating": 1321.910832898896,
            "rating_q975": 1328.4752508772558,
            "rating_q025": 1315.346414920536
        },
        "qwq-32b": {
            "rating": 1321.2853798571427,
            "rating_q975": 1331.4203341472542,
            "rating_q025": 1311.1504255670316
        },
        "claude-3-5-haiku-20241022": {
            "rating": 1321.2173519223877,
            "rating_q975": 1327.9192976768386,
            "rating_q025": 1314.5154061679368
        },
        "llama-4-maverick-17b-128e-instruct": {
            "rating": 1320.521494242321,
            "rating_q975": 1329.6466157324262,
            "rating_q025": 1311.396372752216
        },
        "gemini-advanced-0514": {
            "rating": 1320.3480476038112,
            "rating_q975": 1329.4809828813447,
            "rating_q025": 1311.215112326278
        },
        "claude-3-opus-20240229": {
            "rating": 1320.1850600951934,
            "rating_q975": 1325.861488508161,
            "rating_q025": 1314.5086316822255
        },
        "qwen3-30b-a3b": {
            "rating": 1319.7880278074447,
            "rating_q975": 1329.525816816811,
            "rating_q025": 1310.0502387980785
        },
        "llama-4-scout-17b-16e-instruct": {
            "rating": 1319.4044571917354,
            "rating_q975": 1330.1914394377604,
            "rating_q025": 1308.6174749457107
        },
        "o1-mini": {
            "rating": 1318.7751263341906,
            "rating_q975": 1325.6861953055761,
            "rating_q025": 1311.8640573628054
        },
        "deepseek-v2.5-1210": {
            "rating": 1318.2729603918838,
            "rating_q975": 1334.0564625631293,
            "rating_q025": 1302.4894582206384
        },
        "llama-3.3-70b-instruct": {
            "rating": 1316.4368492587682,
            "rating_q975": 1323.0848234920506,
            "rating_q025": 1309.788875025486
        },
        "gpt-oss-120b": {
            "rating": 1316.2709707960312,
            "rating_q975": 1332.7951541673738,
            "rating_q025": 1299.7467874246886
        },
        "gemini-1.5-pro-001": {
            "rating": 1313.8720834425542,
            "rating_q975": 1321.131708192011,
            "rating_q025": 1306.6124586930973
        },
        "gpt-4.1-nano-2025-04-14": {
            "rating": 1312.3758525466528,
            "rating_q975": 1330.2779500046588,
            "rating_q025": 1294.4737550886468
        },
        "magistral-medium-2506": {
            "rating": 1312.3047722723986,
            "rating_q975": 1328.550003816225,
            "rating_q025": 1296.059540728572
        },
        "gpt-4-turbo-2024-04-09": {
            "rating": 1310.9815957179069,
            "rating_q975": 1317.9080376950392,
            "rating_q025": 1304.0551537407744
        },
        "glm-4-plus": {
            "rating": 1309.6802199650706,
            "rating_q975": 1318.677851989905,
            "rating_q025": 1300.6825879402359
        },
        "hunyuan-large-2025-02-10": {
            "rating": 1308.7392788730253,
            "rating_q975": 1333.555049058389,
            "rating_q025": 1283.9235086876615
        },
        "gpt-4o-mini-2024-07-18": {
            "rating": 1306.5094744021603,
            "rating_q975": 1312.7254208215136,
            "rating_q025": 1300.293527982807
        },
        "athene-v2-chat": {
            "rating": 1303.5730442785039,
            "rating_q975": 1312.4028870487302,
            "rating_q025": 1294.7432015082775
        },
        "step-2-16k-exp-202412": {
            "rating": 1303.0498029413316,
            "rating_q975": 1322.5395704144012,
            "rating_q025": 1283.560035468262
        },
        "gpt-oss-20b": {
            "rating": 1302.6490252553472,
            "rating_q975": 1319.4570854687272,
            "rating_q025": 1285.840965041967
        },
        "qwen2.5-plus-1127": {
            "rating": 1302.3685174161565,
            "rating_q975": 1315.2877087113009,
            "rating_q025": 1289.4493261210116
        },
        "qwen-max-0919": {
            "rating": 1301.2014316436926,
            "rating_q975": 1311.7946237331616,
            "rating_q025": 1290.6082395542235
        },
        "gemma-3n-e4b-it": {
            "rating": 1299.192447556697,
            "rating_q975": 1311.0162487881153,
            "rating_q025": 1287.3686463252786
        },
        "gpt-4-1106-preview": {
            "rating": 1297.5312091319975,
            "rating_q975": 1304.7832288257744,
            "rating_q025": 1290.2791894382206
        },
        "hunyuan-standard-2025-02-10": {
            "rating": 1296.916041425005,
            "rating_q975": 1320.5909133353668,
            "rating_q025": 1273.2411695146432
        },
        "qwen2.5-72b-instruct": {
            "rating": 1295.1157385760607,
            "rating_q975": 1302.5409476742711,
            "rating_q025": 1287.6905294778503
        },
        "amazon-nova-experimental-chat-05-14": {
            "rating": 1294.7176287494058,
            "rating_q975": 1305.94866558957,
            "rating_q025": 1283.4865919092415
        },
        "mistral-large-2407": {
            "rating": 1294.5339670267444,
            "rating_q975": 1301.915069294055,
            "rating_q025": 1287.1528647594341
        },
        "grok-2-mini-2024-08-13": {
            "rating": 1293.9493143780082,
            "rating_q975": 1300.8333957107989,
            "rating_q025": 1287.0652330452176
        },
        "athene-70b-0725": {
            "rating": 1293.6346318288433,
            "rating_q975": 1304.054893240507,
            "rating_q025": 1283.21437041718
        },
        "mistral-large-2411": {
            "rating": 1291.9125218750064,
            "rating_q975": 1300.5245403578338,
            "rating_q025": 1283.300503392179
        },
        "gpt-4-0125-preview": {
            "rating": 1291.0628334262242,
            "rating_q975": 1298.3399007598196,
            "rating_q025": 1283.7857660926288
        },
        "llama-3.1-nemotron-70b-instruct": {
            "rating": 1290.871737168971,
            "rating_q975": 1307.2197734161928,
            "rating_q025": 1274.5237009217494
        },
        "deepseek-v2.5": {
            "rating": 1289.9130685446275,
            "rating_q975": 1299.102356871959,
            "rating_q025": 1280.7237802172963
        },
        "llama-3.1-70b-instruct": {
            "rating": 1287.7114911310252,
            "rating_q975": 1294.3765566343236,
            "rating_q025": 1281.046425627727
        },
        "hunyuan-large-vision": {
            "rating": 1280.9061294186977,
            "rating_q975": 1299.716114555624,
            "rating_q025": 1262.0961442817713
        },
        "gemma-2-27b-it": {
            "rating": 1278.5814986249738,
            "rating_q975": 1284.5897215047157,
            "rating_q025": 1272.5732757452317
        },
        "claude-3-sonnet-20240229": {
            "rating": 1277.8071329326376,
            "rating_q975": 1285.3352022318736,
            "rating_q025": 1270.2790636334012
        },
        "llama-3.1-tulu-3-70b": {
            "rating": 1277.2734766646258,
            "rating_q975": 1299.917452245697,
            "rating_q025": 1254.6295010835547
        },
        "gemini-1.5-flash-002": {
            "rating": 1277.1582358113787,
            "rating_q975": 1285.0159999875857,
            "rating_q025": 1269.3004716351718
        },
        "mistral-small-3.1-24b-instruct-2503": {
            "rating": 1276.3744852409873,
            "rating_q975": 1287.68314026302,
            "rating_q025": 1265.0658302189543
        },
        "llama-3.1-nemotron-51b-instruct": {
            "rating": 1275.786346874107,
            "rating_q975": 1295.3656886756596,
            "rating_q025": 1256.2070050725545
        },
        "amazon-nova-pro-v1.0": {
            "rating": 1274.8821894395705,
            "rating_q975": 1283.8290887245441,
            "rating_q025": 1265.9352901545974
        },
        "gemma-3-4b-it": {
            "rating": 1274.0971984973253,
            "rating_q975": 1297.5701145638661,
            "rating_q025": 1250.6242824307842
        },
        "llama-3-70b-instruct": {
            "rating": 1272.4665307075206,
            "rating_q975": 1279.2853879883028,
            "rating_q025": 1265.6476734267387
        },
        "gpt-4-0314": {
            "rating": 1271.7804187873494,
            "rating_q975": 1281.2528577299065,
            "rating_q025": 1262.3079798447923
        },
        "gemma-2-9b-it-simpo": {
            "rating": 1269.7729445119007,
            "rating_q975": 1283.910690157598,
            "rating_q025": 1255.6351988662036
        },
        "gemini-1.5-flash-001": {
            "rating": 1268.867681808722,
            "rating_q975": 1276.288702027523,
            "rating_q025": 1261.446661589921
        },
        "jamba-1.5-large": {
            "rating": 1264.372680704377,
            "rating_q975": 1278.4807645947362,
            "rating_q025": 1250.2645968140175
        },
        "reka-core-20240904": {
            "rating": 1261.8796600309154,
            "rating_q975": 1277.651114907105,
            "rating_q025": 1246.1082051547257
        },
        "gpt-4-0613": {
            "rating": 1260.052632446196,
            "rating_q975": 1267.9744604552784,
            "rating_q025": 1252.1308044371133
        },
        "nemotron-4-340b-instruct": {
            "rating": 1258.2650654869265,
            "rating_q975": 1269.4096075872797,
            "rating_q025": 1247.1205233865733
        },
        "glm-4-0520": {
            "rating": 1258.1171315595423,
            "rating_q975": 1272.2303077029849,
            "rating_q025": 1244.0039554160996
        },
        "gemma-2-9b-it": {
            "rating": 1250.8883513347737,
            "rating_q975": 1257.6851966142049,
            "rating_q025": 1244.0915060553423
        },
        "command-r-plus-08-2024": {
            "rating": 1250.2143839502664,
            "rating_q975": 1263.3685253943497,
            "rating_q025": 1237.0602425061827
        },
        "qwen2.5-coder-32b-instruct": {
            "rating": 1249.0819135892073,
            "rating_q975": 1266.575860054672,
            "rating_q025": 1231.5879671237426
        },
        "mistral-small-24b-instruct-2501": {
            "rating": 1248.8926592054925,
            "rating_q975": 1261.5489911782004,
            "rating_q025": 1236.2363272327846
        },
        "olmo-2-0325-32b-instruct": {
            "rating": 1247.9108620792463,
            "rating_q975": 1276.5236722382203,
            "rating_q025": 1219.2980519202722
        },
        "claude-3-haiku-20240307": {
            "rating": 1244.0474002154428,
            "rating_q975": 1250.838412711863,
            "rating_q025": 1237.256387719023
        },
        "qwen2-72b-instruct": {
            "rating": 1243.0105554724212,
            "rating_q975": 1251.7366897714803,
            "rating_q025": 1234.284421173362
        },
        "phi-4": {
            "rating": 1240.3294710661921,
            "rating_q975": 1250.2666742217934,
            "rating_q025": 1230.3922679105908
        },
        "command-r-plus": {
            "rating": 1237.7085577678868,
            "rating_q975": 1245.7138814558166,
            "rating_q025": 1229.7032340799572
        },
        "reka-flash-20240904": {
            "rating": 1237.602355049179,
            "rating_q975": 1253.181861397952,
            "rating_q025": 1222.0228487004058
        },
        "deepseek-coder-v2": {
            "rating": 1236.0112102351486,
            "rating_q975": 1247.9588174691519,
            "rating_q025": 1224.0636030011453
        },
        "c4ai-aya-expanse-32b": {
            "rating": 1231.6715835161099,
            "rating_q975": 1240.3229724576481,
            "rating_q025": 1223.0201945745719
        },
        "amazon-nova-lite-v1.0": {
            "rating": 1227.675076033659,
            "rating_q975": 1237.822002913932,
            "rating_q025": 1217.5281491533863
        },
        "mistral-large-2402": {
            "rating": 1225.589080232612,
            "rating_q975": 1234.3717158392003,
            "rating_q025": 1216.806444626024
        },
        "gemini-1.5-flash-8b-001": {
            "rating": 1223.0019342707276,
            "rating_q975": 1230.9448270886155,
            "rating_q025": 1215.0590414528397
        },
        "qwen1.5-72b-chat": {
            "rating": 1217.0472328167057,
            "rating_q975": 1226.9651535307958,
            "rating_q025": 1207.1293121026156
        },
        "qwen1.5-110b-chat": {
            "rating": 1213.9536723742071,
            "rating_q975": 1224.9120804201257,
            "rating_q025": 1202.9952643282886
        },
        "command-r-08-2024": {
            "rating": 1212.4069912758605,
            "rating_q975": 1225.6989903382348,
            "rating_q025": 1199.1149922134864
        },
        "amazon-nova-micro-v1.0": {
            "rating": 1210.803875135607,
            "rating_q975": 1221.2301883097227,
            "rating_q025": 1200.3775619614912
        },
        "hunyuan-standard-256k": {
            "rating": 1207.176312017348,
            "rating_q975": 1231.4141683485263,
            "rating_q025": 1182.9384556861696
        },
        "ministral-8b-2410": {
            "rating": 1206.1331435414636,
            "rating_q975": 1224.8091549142453,
            "rating_q025": 1187.4571321686817
        },
        "llama-3-8b-instruct": {
            "rating": 1205.0301543740788,
            "rating_q975": 1212.630422045061,
            "rating_q025": 1197.4298867030964
        },
        "reka-flash-21b-20240226-online": {
            "rating": 1204.8568576653686,
            "rating_q975": 1219.3389669966023,
            "rating_q025": 1190.374748334135
        },
        "jamba-1.5-mini": {
            "rating": 1204.7102180941895,
            "rating_q975": 1218.9751592283199,
            "rating_q025": 1190.4452769600591
        },
        "gemini-pro": {
            "rating": 1202.46109021852,
            "rating_q975": 1227.0692250805512,
            "rating_q025": 1177.8529553564886
        },
        "gpt-3.5-turbo-0125": {
            "rating": 1201.700798682207,
            "rating_q975": 1209.9114944752316,
            "rating_q025": 1193.4901028891825
        },
        "c4ai-aya-expanse-8b": {
            "rating": 1199.726069160979,
            "rating_q975": 1213.7599855462126,
            "rating_q025": 1185.6921527757454
        },
        "command-r": {
            "rating": 1198.362347873579,
            "rating_q975": 1207.4086944046974,
            "rating_q025": 1189.3160013424608
        },
        "llama-3.1-8b-instruct": {
            "rating": 1197.776346046283,
            "rating_q975": 1204.9587417210319,
            "rating_q025": 1190.5939503715338
        },
        "mistral-medium": {
            "rating": 1196.1382789864845,
            "rating_q975": 1207.1427704793957,
            "rating_q025": 1185.133787493573
        },
        "reka-flash-21b-20240226": {
            "rating": 1193.616724331476,
            "rating_q975": 1205.2617004435874,
            "rating_q025": 1181.9717482193648
        },
        "qwen1.5-32b-chat": {
            "rating": 1193.0923073162471,
            "rating_q975": 1205.0397024337792,
            "rating_q025": 1181.144912198715
        },
        "yi-1.5-34b-chat": {
            "rating": 1189.6884593648472,
            "rating_q975": 1200.4899362052543,
            "rating_q025": 1178.88698252444
        },
        "mixtral-8x22b-instruct-v0.1": {
            "rating": 1188.343839798555,
            "rating_q975": 1196.9465376633782,
            "rating_q025": 1179.7411419337318
        },
        "gemini-pro-dev-api": {
            "rating": 1187.5333912138026,
            "rating_q975": 1201.779091373773,
            "rating_q025": 1173.287691053832
        },
        "llama-3.1-tulu-3-8b": {
            "rating": 1177.9274680091733,
            "rating_q975": 1203.002938385232,
            "rating_q025": 1152.8519976331145
        },
        "dbrx-instruct-preview": {
            "rating": 1175.6520669204665,
            "rating_q975": 1186.9797862704147,
            "rating_q025": 1164.3243475705183
        },
        "gpt-3.5-turbo-1106": {
            "rating": 1172.4965470357065,
            "rating_q975": 1188.1004262104389,
            "rating_q025": 1156.8926678609741
        },
        "mixtral-8x7b-instruct-v0.1": {
            "rating": 1168.7862876864635,
            "rating_q975": 1176.9611703194005,
            "rating_q025": 1160.6114050535266
        },
        "internlm2_5-20b-chat": {
            "rating": 1167.683431486239,
            "rating_q975": 1181.857999563311,
            "rating_q025": 1153.5088634091665
        },
        "wizardlm-70b": {
            "rating": 1167.1974026870223,
            "rating_q975": 1186.2984695422997,
            "rating_q025": 1148.0963358317451
        },
        "qwen1.5-14b-chat": {
            "rating": 1166.1567003632194,
            "rating_q975": 1180.1363143446686,
            "rating_q025": 1152.1770863817703
        },
        "gemma-2-2b-it": {
            "rating": 1164.6609237604869,
            "rating_q975": 1172.3640206947566,
            "rating_q025": 1156.957826826217
        },
        "yi-34b-chat": {
            "rating": 1161.5040988083424,
            "rating_q975": 1175.9176087512615,
            "rating_q025": 1147.0905888654233
        },
        "zephyr-orpo-141b-A35b-v0.1": {
            "rating": 1161.0240562531112,
            "rating_q975": 1184.7855065685044,
            "rating_q025": 1137.262605937718
        },
        "granite-3.1-8b-instruct": {
            "rating": 1160.1836661495256,
            "rating_q975": 1185.151189401454,
            "rating_q025": 1135.2161428975974
        },
        "openchat-3.5": {
            "rating": 1156.9179409625285,
            "rating_q975": 1175.544652058332,
            "rating_q025": 1138.2912298667247
        },
        "openchat-3.5-0106": {
            "rating": 1154.9722700216985,
            "rating_q975": 1169.7337151774796,
            "rating_q025": 1140.2108248659174
        },
        "qwq-32b-preview": {
            "rating": 1153.1604058761475,
            "rating_q975": 1179.1296370034029,
            "rating_q025": 1127.191174748892
        },
        "deepseek-llm-67b-chat": {
            "rating": 1152.8992968449938,
            "rating_q975": 1177.1082929877048,
            "rating_q025": 1128.6903007022827
        },
        "llama-3.2-3b-instruct": {
            "rating": 1151.3890729310583,
            "rating_q975": 1167.9158934725779,
            "rating_q025": 1134.8622523895388
        },
        "granite-3.1-2b-instruct": {
            "rating": 1146.3721468661226,
            "rating_q975": 1172.8854073507937,
            "rating_q025": 1119.8588863814516
        },
        "starling-lm-7b-beta": {
            "rating": 1144.770119230493,
            "rating_q975": 1159.620123206633,
            "rating_q025": 1129.9201152543528
        },
        "snowflake-arctic-instruct": {
            "rating": 1144.4257951995928,
            "rating_q975": 1156.6344672511282,
            "rating_q025": 1132.2171231480577
        },
        "vicuna-33b": {
            "rating": 1141.045399382634,
            "rating_q975": 1153.7126070500096,
            "rating_q025": 1128.3781917152583
        },
        "phi-3-medium-4k-instruct": {
            "rating": 1139.9939997107238,
            "rating_q975": 1150.54655664484,
            "rating_q025": 1129.4414427766076
        },
        "granite-3.0-8b-instruct": {
            "rating": 1137.4219417820211,
            "rating_q975": 1156.9167303422184,
            "rating_q025": 1117.9271532218238
        },
        "tulu-2-dpo-70b": {
            "rating": 1136.2028239156507,
            "rating_q975": 1157.1916162887692,
            "rating_q025": 1115.2140315425322
        },
        "openhermes-2.5-mistral-7b": {
            "rating": 1135.8932458792565,
            "rating_q975": 1158.1389974123629,
            "rating_q025": 1113.6474943461503
        },
        "llama-2-70b-chat": {
            "rating": 1135.492795893872,
            "rating_q975": 1145.642294654613,
            "rating_q025": 1125.3432971331313
        },
        "starling-lm-7b-alpha": {
            "rating": 1134.8082986930099,
            "rating_q975": 1152.1258073321846,
            "rating_q025": 1117.4907900538349
        },
        "nous-hermes-2-mixtral-8x7b-dpo": {
            "rating": 1130.1511738938973,
            "rating_q975": 1155.7981870143387,
            "rating_q025": 1104.5041607734559
        },
        "mpt-30b-chat": {
            "rating": 1125.929910924624,
            "rating_q975": 1157.3186387937794,
            "rating_q025": 1094.541183055468
        },
        "gemma-1.1-7b-it": {
            "rating": 1124.5756405303239,
            "rating_q975": 1135.879271781834,
            "rating_q025": 1113.2720092788138
        },
        "granite-3.0-2b-instruct": {
            "rating": 1121.6994849886826,
            "rating_q975": 1140.0792992956399,
            "rating_q025": 1103.3196706817253
        },
        "phi-3-small-8k-instruct": {
            "rating": 1120.4053950185307,
            "rating_q975": 1132.2286599186957,
            "rating_q025": 1108.5821301183657
        },
        "llama2-70b-steerlm-chat": {
            "rating": 1117.3228035428149,
            "rating_q975": 1144.9555263440345,
            "rating_q025": 1089.690080741595
        },
        "mistral-7b-instruct-v0.2": {
            "rating": 1116.5143816398652,
            "rating_q975": 1129.2743056614288,
            "rating_q025": 1103.7544576183016
        },
        "qwen1.5-7b-chat": {
            "rating": 1112.759706884715,
            "rating_q975": 1137.462986363395,
            "rating_q025": 1088.0564274060348
        },
        "solar-10.7b-instruct-v1.0": {
            "rating": 1112.0586717509468,
            "rating_q975": 1137.0905599454732,
            "rating_q025": 1087.0267835564205
        },
        "wizardlm-13b": {
            "rating": 1109.1946229312869,
            "rating_q975": 1128.9249697203395,
            "rating_q025": 1089.4642761422342
        },
        "llama-2-13b-chat": {
            "rating": 1102.3173287533118,
            "rating_q975": 1115.9091729436125,
            "rating_q025": 1088.7254845630112
        },
        "vicuna-13b": {
            "rating": 1101.0654372574013,
            "rating_q975": 1114.8049774118917,
            "rating_q025": 1087.3258971029109
        },
        "phi-3-mini-4k-instruct-june-2024": {
            "rating": 1100.1606272448241,
            "rating_q975": 1114.505220938092,
            "rating_q025": 1085.8160335515563
        },
        "falcon-180b-chat": {
            "rating": 1098.6941691711486,
            "rating_q975": 1138.4126838913548,
            "rating_q025": 1058.975654450942
        },
        "qwen-14b-chat": {
            "rating": 1095.4931487698514,
            "rating_q975": 1118.6217674609939,
            "rating_q025": 1072.3645300787086
        },
        "palm-2": {
            "rating": 1091.3056109607944,
            "rating_q975": 1110.8577848799453,
            "rating_q025": 1071.7534370416436
        },
        "zephyr-7b-beta": {
            "rating": 1089.9058538808595,
            "rating_q975": 1107.2476426070543,
            "rating_q025": 1072.5640651546644
        },
        "dolphin-2.2.1-mistral-7b": {
            "rating": 1085.2266163448005,
            "rating_q975": 1126.6270146608651,
            "rating_q025": 1043.8262180287359
        },
        "mistral-7b-instruct": {
            "rating": 1082.370467884265,
            "rating_q975": 1101.4632854627189,
            "rating_q025": 1063.2776503058112
        },
        "llama-3.2-1b-instruct": {
            "rating": 1080.7198342406948,
            "rating_q975": 1098.868207089909,
            "rating_q025": 1062.5714613914806
        },
        "stripedhyena-nous-7b": {
            "rating": 1079.417299758486,
            "rating_q975": 1102.2128959013523,
            "rating_q025": 1056.62170361562
        },
        "llama-2-7b-chat": {
            "rating": 1077.4548264435148,
            "rating_q975": 1092.2174315625457,
            "rating_q025": 1062.6922213244836
        },
        "codellama-34b-instruct": {
            "rating": 1074.4838032639045,
            "rating_q975": 1092.8439042032282,
            "rating_q025": 1056.1237023245808
        },
        "zephyr-7b-alpha": {
            "rating": 1074.3771321875258,
            "rating_q975": 1108.3980573783317,
            "rating_q025": 1040.35620699672
        },
        "guanaco-33b": {
            "rating": 1073.0106906984072,
            "rating_q975": 1106.3473151727885,
            "rating_q025": 1039.6740662240259
        },
        "phi-3-mini-4k-instruct": {
            "rating": 1066.7123368457376,
            "rating_q975": 1079.7656101377265,
            "rating_q025": 1053.6590635537486
        },
        "vicuna-7b": {
            "rating": 1063.0825071416039,
            "rating_q975": 1083.8848138000658,
            "rating_q025": 1042.2802004831417
        },
        "phi-3-mini-128k-instruct": {
            "rating": 1060.840645353135,
            "rating_q975": 1076.161056422475,
            "rating_q025": 1045.5202342837947
        },
        "smollm2-1.7b-instruct": {
            "rating": 1056.8074631397428,
            "rating_q975": 1094.496815518261,
            "rating_q025": 1019.1181107612247
        },
        "qwen1.5-4b-chat": {
            "rating": 1055.6215570768982,
            "rating_q975": 1074.248493151027,
            "rating_q025": 1036.9946210027692
        },
        "gemma-1.1-2b-it": {
            "rating": 1052.0602782762633,
            "rating_q975": 1069.5717855722132,
            "rating_q025": 1034.5487709803133
        },
        "gemma-7b-it": {
            "rating": 1044.8340514810666,
            "rating_q975": 1063.2895420867337,
            "rating_q025": 1026.3785608753992
        },
        "olmo-7b-instruct": {
            "rating": 1041.8119034976362,
            "rating_q975": 1069.2859703215975,
            "rating_q025": 1014.3378366736752
        },
        "chatglm3-6b": {
            "rating": 1038.4677691331763,
            "rating_q975": 1063.8650936189524,
            "rating_q025": 1013.0704446474001
        },
        "gemma-2b-it": {
            "rating": 1033.3292111841786,
            "rating_q975": 1056.4524585427039,
            "rating_q025": 1010.205963825653
        },
        "gpt4all-13b-snoozy": {
            "rating": 1025.7999921188634,
            "rating_q975": 1063.637783202731,
            "rating_q025": 987.9622010349958
        },
        "alpaca-13b": {
            "rating": 1009.5158126860505,
            "rating_q975": 1035.0423673433147,
            "rating_q025": 983.9892580287863
        },
        "mpt-7b-chat": {
            "rating": 1001.9337588762597,
            "rating_q975": 1030.7782334197357,
            "rating_q025": 973.0892843327837
        },
        "koala-13b": {
            "rating": 996.3469655292429,
            "rating_q975": 1020.4553458263721,
            "rating_q025": 972.2385852321136
        },
        "RWKV-4-Raven-14B": {
            "rating": 979.9077011483,
            "rating_q975": 1007.0373675996741,
            "rating_q025": 952.7780346969259
        },
        "chatglm2-6b": {
            "rating": 979.7626427843037,
            "rating_q975": 1011.4633739898347,
            "rating_q025": 948.0619115787725
        },
        "oasst-pythia-12b": {
            "rating": 959.9911635307733,
            "rating_q975": 985.3981791748135,
            "rating_q025": 934.5841478867329
        },
        "fastchat-t5-3b": {
            "rating": 939.8236655374253,
            "rating_q975": 970.0854857572722,
            "rating_q025": 909.5618453175784
        },
        "chatglm-6b": {
            "rating": 924.2151738739456,
            "rating_q975": 953.5219183276947,
            "rating_q025": 894.9084294201964
        },
        "stablelm-tuned-alpha-7b": {
            "rating": 899.5663358416067,
            "rating_q975": 933.7412229150295,
            "rating_q025": 865.3914487681839
        },
        "llama-13b": {
            "rating": 891.1609144568025,
            "rating_q975": 933.1277071858601,
            "rating_q025": 849.1941217277449
        },
        "dolly-v2-12b": {
            "rating": 863.655907474375,
            "rating_q975": 898.9308599322867,
            "rating_q025": 828.3809550164633
        }
    },
    "no_refusal": {
        "gemini-2.5-pro": {
            "rating": 1454.6688067590237,
            "rating_q975": 1459.5224937463236,
            "rating_q025": 1449.8151197717239
        },
        "gpt-5-high": {
            "rating": 1445.6861950005712,
            "rating_q975": 1452.2539762413726,
            "rating_q025": 1439.1184137597697
        },
        "claude-opus-4-1-20250805-thinking-16k": {
            "rating": 1443.7720287498962,
            "rating_q975": 1450.6131347378516,
            "rating_q025": 1436.9309227619406
        },
        "o3-2025-04-16": {
            "rating": 1443.1060478119543,
            "rating_q975": 1447.5366169349659,
            "rating_q025": 1438.6754786889426
        },
        "chatgpt-4o-latest-20250326": {
            "rating": 1441.383350499902,
            "rating_q975": 1445.8429093596314,
            "rating_q025": 1436.9237916401726
        },
        "gpt-4.5-preview-2025-02-27": {
            "rating": 1438.0457062226046,
            "rating_q975": 1443.6211780529798,
            "rating_q025": 1432.4702343922295
        },
        "gpt-5-old": {
            "rating": 1437.1668875590465,
            "rating_q975": 1458.002839297372,
            "rating_q025": 1416.3309358207212
        },
        "claude-opus-4-1-20250805": {
            "rating": 1432.5940396040885,
            "rating_q975": 1438.9526981690678,
            "rating_q025": 1426.2353810391094
        },
        "gpt-5-chat": {
            "rating": 1424.1752996588202,
            "rating_q975": 1431.0132154341165,
            "rating_q025": 1417.3373838835237
        },
        "qwen-max-2025-08-15": {
            "rating": 1423.457895380463,
            "rating_q975": 1431.7831037679114,
            "rating_q025": 1415.1326869930147
        },
        "grok-4-0709": {
            "rating": 1422.0494746304948,
            "rating_q975": 1427.6096518377906,
            "rating_q025": 1416.4892974231989
        },
        "qwen3-235b-a22b-instruct-2507": {
            "rating": 1418.863547679305,
            "rating_q975": 1424.7279837574238,
            "rating_q025": 1412.999111601186
        },
        "kimi-k2-0711-preview": {
            "rating": 1418.2131413803609,
            "rating_q975": 1423.54049971349,
            "rating_q025": 1412.885783047232
        },
        "deepseek-v3.1": {
            "rating": 1416.8990688020783,
            "rating_q975": 1425.4493665541347,
            "rating_q025": 1408.3487710500222
        },
        "claude-opus-4-20250514-thinking-16k": {
            "rating": 1416.0592263548353,
            "rating_q975": 1421.174709695085,
            "rating_q025": 1410.9437430145856
        },
        "deepseek-r1-0528": {
            "rating": 1415.5859751893752,
            "rating_q975": 1421.125414182637,
            "rating_q025": 1410.046536196113
        },
        "deepseek-v3.1-thinking": {
            "rating": 1412.882848447499,
            "rating_q975": 1421.9990828206962,
            "rating_q025": 1403.766614074302
        },
        "mistral-medium-2508": {
            "rating": 1410.212080591857,
            "rating_q975": 1417.6039980198095,
            "rating_q025": 1402.8201631639047
        },
        "glm-4.5": {
            "rating": 1409.2240041103953,
            "rating_q975": 1415.4600429020195,
            "rating_q025": 1402.987965318771
        },
        "grok-3-preview-02-24": {
            "rating": 1408.0977732260997,
            "rating_q975": 1412.33105628312,
            "rating_q025": 1403.8644901690795
        },
        "gpt-4.1-2025-04-14": {
            "rating": 1406.7946533195473,
            "rating_q975": 1411.5674923496504,
            "rating_q025": 1402.0218142894444
        },
        "claude-opus-4-20250514": {
            "rating": 1406.1503580810336,
            "rating_q975": 1411.1306910849657,
            "rating_q025": 1401.1700250771014
        },
        "gemini-2.5-flash": {
            "rating": 1404.6324356648968,
            "rating_q975": 1409.3624510373418,
            "rating_q025": 1399.902420292452
        },
        "qwen3-235b-a22b-thinking-2507": {
            "rating": 1399.1389825692916,
            "rating_q975": 1405.8761202452154,
            "rating_q025": 1392.4018448933678
        },
        "o1-2024-12-17": {
            "rating": 1397.5224953622837,
            "rating_q975": 1401.8486647140242,
            "rating_q025": 1393.1963260105435
        },
        "qwen3-235b-a22b-no-thinking": {
            "rating": 1397.1526194643493,
            "rating_q975": 1402.218790218117,
            "rating_q025": 1392.0864487105816
        },
        "mai-1-preview": {
            "rating": 1396.909029890468,
            "rating_q975": 1405.6849227957944,
            "rating_q025": 1388.1331369851418
        },
        "claude-sonnet-4-20250514-thinking-32k": {
            "rating": 1394.4558262355076,
            "rating_q975": 1399.609088052874,
            "rating_q025": 1389.3025644181412
        },
        "deepseek-r1": {
            "rating": 1392.5854630784966,
            "rating_q975": 1397.3432930690194,
            "rating_q025": 1387.8276330879735
        },
        "o4-mini-2025-04-16": {
            "rating": 1392.3579554266266,
            "rating_q975": 1397.1022357534762,
            "rating_q025": 1387.613675099777
        },
        "gpt-5-mini-high": {
            "rating": 1391.1607666731454,
            "rating_q975": 1398.6544674908996,
            "rating_q025": 1383.667065855391
        },
        "deepseek-v3-0324": {
            "rating": 1389.9605783819984,
            "rating_q975": 1394.4245564570604,
            "rating_q025": 1385.4966003069364
        },
        "o1-preview": {
            "rating": 1388.4232203939623,
            "rating_q975": 1393.23365831049,
            "rating_q025": 1383.6127824774346
        },
        "hunyuan-t1-20250711": {
            "rating": 1387.7692725543532,
            "rating_q975": 1395.6885199234134,
            "rating_q025": 1379.8500251852927
        },
        "qwen-vl-max-2025-08-13": {
            "rating": 1382.3493169806036,
            "rating_q975": 1397.4608985344364,
            "rating_q025": 1367.237735426771
        },
        "mistral-medium-2505": {
            "rating": 1381.212752867735,
            "rating_q975": 1386.0436479163266,
            "rating_q025": 1376.381857819143
        },
        "claude-3-7-sonnet-20250219-thinking-32k": {
            "rating": 1380.8522854692692,
            "rating_q975": 1385.1517724970674,
            "rating_q025": 1376.5527984414712
        },
        "hunyuan-turbos-20250416": {
            "rating": 1380.3270184059006,
            "rating_q975": 1386.581844734194,
            "rating_q025": 1374.0721920776073
        },
        "claude-sonnet-4-20250514": {
            "rating": 1380.2290550216098,
            "rating_q975": 1385.3026416673906,
            "rating_q025": 1375.1554683758288
        },
        "qwen3-30b-a3b-instruct-2507": {
            "rating": 1379.8132654720757,
            "rating_q975": 1386.4617998789822,
            "rating_q025": 1373.1647310651692
        },
        "qwen3-coder-480b-a35b-instruct": {
            "rating": 1379.0487094122814,
            "rating_q975": 1385.0070002815244,
            "rating_q025": 1373.0904185430384
        },
        "glm-4.5-air": {
            "rating": 1376.5553693393222,
            "rating_q975": 1382.8809804751118,
            "rating_q025": 1370.2297582035324
        },
        "gpt-4.1-mini-2025-04-14": {
            "rating": 1376.447973009524,
            "rating_q975": 1381.2045824958977,
            "rating_q025": 1371.6913635231504
        },
        "qwen3-235b-a22b": {
            "rating": 1372.3730944521815,
            "rating_q975": 1377.251069017533,
            "rating_q025": 1367.49511988683
        },
        "qwen2.5-max": {
            "rating": 1371.3613061652065,
            "rating_q975": 1375.3698152702275,
            "rating_q025": 1367.3527970601856
        },
        "minimax-m1": {
            "rating": 1366.0585495688326,
            "rating_q975": 1371.2322627050812,
            "rating_q025": 1360.884836432584
        },
        "claude-3-5-sonnet-20241022": {
            "rating": 1365.7873104006549,
            "rating_q975": 1368.8903777903113,
            "rating_q025": 1362.6842430109984
        },
        "claude-3-7-sonnet-20250219": {
            "rating": 1364.8189830963022,
            "rating_q975": 1368.8193680075774,
            "rating_q025": 1360.818598185027
        },
        "gemma-3-27b-it": {
            "rating": 1362.9665177336462,
            "rating_q975": 1367.1718104906254,
            "rating_q025": 1358.7612249766673
        },
        "o3-mini-high": {
            "rating": 1362.9600441647674,
            "rating_q975": 1368.1064813421656,
            "rating_q025": 1357.813606987369
        },
        "grok-3-mini-high": {
            "rating": 1362.54409777512,
            "rating_q975": 1368.2065995947335,
            "rating_q025": 1356.8815959555068
        },
        "gemini-2.0-flash-001": {
            "rating": 1361.3473674175139,
            "rating_q975": 1365.222686185581,
            "rating_q025": 1357.4720486494466
        },
        "grok-3-mini-beta": {
            "rating": 1358.2250620316565,
            "rating_q975": 1363.5079433483265,
            "rating_q025": 1352.9421807149868
        },
        "gpt-oss-120b": {
            "rating": 1353.7396991472156,
            "rating_q975": 1360.7065549909473,
            "rating_q025": 1346.772843303484
        },
        "deepseek-v3": {
            "rating": 1353.4966889427596,
            "rating_q975": 1358.0948858442819,
            "rating_q025": 1348.8984920412374
        },
        "mistral-small-2506": {
            "rating": 1352.317801063923,
            "rating_q975": 1357.9343222423186,
            "rating_q025": 1346.7012798855274
        },
        "step-3": {
            "rating": 1351.407282483038,
            "rating_q975": 1361.685155477411,
            "rating_q025": 1341.129409488665
        },
        "gemini-2.0-flash-lite-preview-02-05": {
            "rating": 1350.3110497828727,
            "rating_q975": 1354.5231410916679,
            "rating_q025": 1346.0989584740776
        },
        "gpt-5-nano-high": {
            "rating": 1348.468882942103,
            "rating_q975": 1357.0507016538982,
            "rating_q025": 1339.8870642303077
        },
        "gemini-1.5-pro-002": {
            "rating": 1348.2937914947663,
            "rating_q975": 1351.4779600263032,
            "rating_q025": 1345.1096229632294
        },
        "o3-mini": {
            "rating": 1347.0633825045645,
            "rating_q975": 1350.7825167318351,
            "rating_q025": 1343.344248277294
        },
        "hunyuan-turbos-20250226": {
            "rating": 1346.3769327023724,
            "rating_q975": 1357.3838759389157,
            "rating_q025": 1335.369989465829
        },
        "command-a-03-2025": {
            "rating": 1344.8340195022474,
            "rating_q975": 1349.0508432810195,
            "rating_q025": 1340.617195723475
        },
        "qwen3-32b": {
            "rating": 1344.2373626502085,
            "rating_q975": 1353.631076013581,
            "rating_q025": 1334.8436492868361
        },
        "llama-3.1-nemotron-ultra-253b-v1": {
            "rating": 1343.2103039158274,
            "rating_q975": 1354.714785198387,
            "rating_q025": 1331.7058226332676
        },
        "qwen-plus-0125": {
            "rating": 1343.0015072070996,
            "rating_q975": 1351.2832224345875,
            "rating_q025": 1334.7197919796117
        },
        "claude-3-5-sonnet-20240620": {
            "rating": 1341.4587194747585,
            "rating_q975": 1344.7585838430743,
            "rating_q025": 1338.1588551064426
        },
        "gpt-4o-2024-05-13": {
            "rating": 1340.9402379396247,
            "rating_q975": 1344.1475215556654,
            "rating_q025": 1337.7329543235837
        },
        "glm-4-plus-0111": {
            "rating": 1340.814419480307,
            "rating_q975": 1349.0622254764307,
            "rating_q025": 1332.5666134841833
        },
        "nvidia-llama-3.3-nemotron-super-49b-v1.5": {
            "rating": 1340.6986845189185,
            "rating_q975": 1350.0876763307676,
            "rating_q025": 1331.3096927070694
        },
        "gemma-3-12b-it": {
            "rating": 1340.5408602884843,
            "rating_q975": 1349.9287023446902,
            "rating_q025": 1331.1530182322783
        },
        "glm-4.5v": {
            "rating": 1338.4520664318793,
            "rating_q975": 1354.5807071527245,
            "rating_q025": 1322.3234257110344
        },
        "hunyuan-turbo-0110": {
            "rating": 1337.053977262912,
            "rating_q975": 1347.986264424693,
            "rating_q025": 1326.121690101131
        },
        "o1-mini": {
            "rating": 1335.5400709686312,
            "rating_q975": 1339.0037496844725,
            "rating_q025": 1332.07639225279
        },
        "qwq-32b": {
            "rating": 1335.1641118555751,
            "rating_q975": 1339.812794530259,
            "rating_q025": 1330.5154291808913
        },
        "llama-3.1-405b-instruct-bf16": {
            "rating": 1331.8543112046996,
            "rating_q975": 1335.3820495851926,
            "rating_q025": 1328.3265728242063
        },
        "step-2-16k-exp-202412": {
            "rating": 1331.028527324303,
            "rating_q975": 1339.372642809076,
            "rating_q025": 1322.6844118395304
        },
        "gpt-4o-2024-08-06": {
            "rating": 1330.5291403650272,
            "rating_q975": 1334.486545260446,
            "rating_q025": 1326.5717354696087
        },
        "llama-3.1-405b-instruct-fp8": {
            "rating": 1330.2619703771002,
            "rating_q975": 1333.6074268373532,
            "rating_q025": 1326.9165139168474
        },
        "grok-2-2024-08-13": {
            "rating": 1329.7828923646387,
            "rating_q975": 1333.2204431599503,
            "rating_q025": 1326.3453415693268
        },
        "gemini-advanced-0514": {
            "rating": 1327.4778663547895,
            "rating_q975": 1332.4872623758288,
            "rating_q025": 1322.46847033375
        },
        "qwen3-30b-a3b": {
            "rating": 1327.4714548244372,
            "rating_q975": 1332.4109123802832,
            "rating_q025": 1322.531997268591
        },
        "claude-3-opus-20240229": {
            "rating": 1326.898765122899,
            "rating_q975": 1329.8121331462396,
            "rating_q025": 1323.9853970995584
        },
        "gpt-oss-20b": {
            "rating": 1326.5005657226754,
            "rating_q975": 1333.6995095188045,
            "rating_q025": 1319.3016219265462
        },
        "yi-lightning": {
            "rating": 1325.2207269616451,
            "rating_q975": 1329.8983405838762,
            "rating_q025": 1320.5431133394143
        },
        "llama-3.3-nemotron-49b-super-v1": {
            "rating": 1324.0730770383786,
            "rating_q975": 1335.7649366529063,
            "rating_q025": 1312.381217423851
        },
        "llama-4-maverick-17b-128e-instruct": {
            "rating": 1323.1145830514677,
            "rating_q975": 1327.7968819521614,
            "rating_q025": 1318.4322841507737
        },
        "hunyuan-large-2025-02-10": {
            "rating": 1322.5566465773877,
            "rating_q975": 1332.3361046051677,
            "rating_q025": 1312.777188549608
        },
        "step-1o-turbo-202506": {
            "rating": 1321.5947998275217,
            "rating_q975": 1328.1074038072434,
            "rating_q025": 1315.0821958478
        },
        "gpt-4-turbo-2024-04-09": {
            "rating": 1320.8824855053867,
            "rating_q975": 1324.5435347018456,
            "rating_q025": 1317.2214363089274
        },
        "deepseek-v2.5-1210": {
            "rating": 1320.1122932179228,
            "rating_q975": 1328.062503864937,
            "rating_q025": 1312.162082570908
        },
        "gemini-1.5-pro-001": {
            "rating": 1319.6732039406306,
            "rating_q975": 1323.4430652026595,
            "rating_q025": 1315.9033426786018
        },
        "claude-3-5-haiku-20241022": {
            "rating": 1319.490158882208,
            "rating_q975": 1322.9277609252713,
            "rating_q025": 1316.0525568391452
        },
        "amazon-nova-experimental-chat-05-14": {
            "rating": 1319.0304552101534,
            "rating_q975": 1324.3404259535255,
            "rating_q025": 1313.7204844667817
        },
        "gpt-4.1-nano-2025-04-14": {
            "rating": 1318.5014987205943,
            "rating_q975": 1326.228722932924,
            "rating_q025": 1310.7742745082646
        },
        "llama-4-scout-17b-16e-instruct": {
            "rating": 1317.4936595828417,
            "rating_q975": 1322.8049689374072,
            "rating_q025": 1312.182350228276
        },
        "llama-3.3-70b-instruct": {
            "rating": 1317.1122722347711,
            "rating_q975": 1320.5649223903513,
            "rating_q025": 1313.659622079191
        },
        "gemma-3n-e4b-it": {
            "rating": 1316.7922225193533,
            "rating_q975": 1322.309508516348,
            "rating_q025": 1311.274936522359
        },
        "glm-4-plus": {
            "rating": 1316.1874991901855,
            "rating_q975": 1320.885916008754,
            "rating_q025": 1311.4890823716169
        },
        "qwen-max-0919": {
            "rating": 1315.5058759306733,
            "rating_q975": 1320.9600118571625,
            "rating_q025": 1310.051740004184
        },
        "qwen2.5-plus-1127": {
            "rating": 1314.516152379303,
            "rating_q975": 1320.6626448427326,
            "rating_q025": 1308.3696599158736
        },
        "gpt-4-1106-preview": {
            "rating": 1313.9528479708688,
            "rating_q975": 1317.6510814590256,
            "rating_q025": 1310.254614482712
        },
        "gpt-4o-mini-2024-07-18": {
            "rating": 1313.5592946034199,
            "rating_q975": 1316.8821395321809,
            "rating_q025": 1310.236449674659
        },
        "gpt-4-0125-preview": {
            "rating": 1313.4081912987795,
            "rating_q975": 1317.2975340280345,
            "rating_q025": 1309.5188485695244
        },
        "athene-v2-chat": {
            "rating": 1311.587894919926,
            "rating_q975": 1315.9455756541986,
            "rating_q025": 1307.2302141856535
        },
        "mistral-large-2407": {
            "rating": 1310.581286714096,
            "rating_q975": 1314.2710770631177,
            "rating_q025": 1306.8914963650745
        },
        "gemini-1.5-flash-002": {
            "rating": 1310.2618375853651,
            "rating_q975": 1314.268415420188,
            "rating_q025": 1306.2552597505423
        },
        "hunyuan-standard-2025-02-10": {
            "rating": 1308.2618875015444,
            "rating_q975": 1317.9428480757613,
            "rating_q025": 1298.5809269273273
        },
        "grok-2-mini-2024-08-13": {
            "rating": 1304.3693502870601,
            "rating_q975": 1307.859235256015,
            "rating_q025": 1300.8794653181053
        },
        "deepseek-v2.5": {
            "rating": 1304.2286354724192,
            "rating_q975": 1308.6708107223244,
            "rating_q025": 1299.7864602225138
        },
        "mistral-large-2411": {
            "rating": 1302.8390986652348,
            "rating_q975": 1307.1147582814076,
            "rating_q025": 1298.5634390490618
        },
        "gemma-3-4b-it": {
            "rating": 1302.597096578396,
            "rating_q975": 1311.8119395430358,
            "rating_q025": 1293.3822536137563
        },
        "athene-70b-0725": {
            "rating": 1301.5600731471839,
            "rating_q975": 1306.9775978578616,
            "rating_q025": 1296.142548436506
        },
        "qwen2.5-72b-instruct": {
            "rating": 1300.2551051062337,
            "rating_q975": 1304.1122295020805,
            "rating_q025": 1296.397980710387
        },
        "mistral-small-3.1-24b-instruct-2503": {
            "rating": 1298.6540708099767,
            "rating_q975": 1304.040401652807,
            "rating_q025": 1293.2677399671463
        },
        "magistral-medium-2506": {
            "rating": 1298.3264563086889,
            "rating_q975": 1305.2405362106877,
            "rating_q025": 1291.41237640669
        },
        "llama-3.1-nemotron-70b-instruct": {
            "rating": 1295.7157950507155,
            "rating_q975": 1303.2386874670278,
            "rating_q025": 1288.1929026344033
        },
        "hunyuan-large-vision": {
            "rating": 1295.3871761657051,
            "rating_q975": 1304.3239402194208,
            "rating_q025": 1286.4504121119892
        },
        "llama-3.1-70b-instruct": {
            "rating": 1291.5106087446884,
            "rating_q975": 1294.9851130287427,
            "rating_q025": 1288.0361044606343
        },
        "amazon-nova-pro-v1.0": {
            "rating": 1287.3243872825365,
            "rating_q975": 1291.7216815512957,
            "rating_q025": 1282.927093013777
        },
        "llama-3.1-tulu-3-70b": {
            "rating": 1286.0846066484867,
            "rating_q975": 1296.3028118123802,
            "rating_q025": 1275.866401484593
        },
        "reka-core-20240904": {
            "rating": 1285.4128112419785,
            "rating_q975": 1292.1191320712776,
            "rating_q025": 1278.7064904126796
        },
        "jamba-1.5-large": {
            "rating": 1285.0310411194932,
            "rating_q975": 1292.1188877766074,
            "rating_q025": 1277.943194462379
        },
        "llama-3.1-nemotron-51b-instruct": {
            "rating": 1283.8052010486701,
            "rating_q975": 1293.5704431326724,
            "rating_q025": 1274.039958964668
        },
        "gemma-2-27b-it": {
            "rating": 1283.7059134075148,
            "rating_q975": 1286.8901835516524,
            "rating_q025": 1280.5216432633774
        },
        "claude-3-sonnet-20240229": {
            "rating": 1282.6916343920761,
            "rating_q975": 1286.574411409505,
            "rating_q025": 1278.8088573746472
        },
        "gemini-1.5-flash-001": {
            "rating": 1282.6831195260602,
            "rating_q975": 1286.965051050302,
            "rating_q025": 1278.4011880018181
        },
        "gpt-4-0314": {
            "rating": 1282.2785196583518,
            "rating_q975": 1286.9772997269233,
            "rating_q025": 1277.57973958978
        },
        "command-r-plus-08-2024": {
            "rating": 1279.1068869349763,
            "rating_q975": 1285.4589253115082,
            "rating_q025": 1272.7548485584443
        },
        "nemotron-4-340b-instruct": {
            "rating": 1276.8007555772103,
            "rating_q975": 1282.016512541395,
            "rating_q025": 1271.5849986130256
        },
        "gemma-2-9b-it-simpo": {
            "rating": 1275.2075220736901,
            "rating_q975": 1281.860800483127,
            "rating_q025": 1268.5542436642534
        },
        "deepseek-coder-v2": {
            "rating": 1274.219215121052,
            "rating_q975": 1280.5627494524902,
            "rating_q025": 1267.8756807896134
        },
        "mistral-small-24b-instruct-2501": {
            "rating": 1273.5692020635584,
            "rating_q975": 1279.3401773638575,
            "rating_q025": 1267.798226763259
        },
        "gpt-4-0613": {
            "rating": 1272.2923998013994,
            "rating_q975": 1276.2650483889818,
            "rating_q025": 1268.3197512138172
        },
        "reka-flash-20240904": {
            "rating": 1271.7653774258192,
            "rating_q975": 1278.3606008132706,
            "rating_q025": 1265.1701540383679
        },
        "glm-4-0520": {
            "rating": 1271.3287319396509,
            "rating_q975": 1278.1826265636114,
            "rating_q025": 1264.4748373156906
        },
        "llama-3-70b-instruct": {
            "rating": 1271.2966834902768,
            "rating_q975": 1274.6996582550346,
            "rating_q025": 1267.893708725519
        },
        "qwen2.5-coder-32b-instruct": {
            "rating": 1269.2795273898773,
            "rating_q975": 1277.1013441942166,
            "rating_q025": 1261.457710585538
        },
        "c4ai-aya-expanse-32b": {
            "rating": 1266.7985924280706,
            "rating_q975": 1271.4794161055408,
            "rating_q025": 1262.1177687506001
        },
        "claude-3-haiku-20240307": {
            "rating": 1264.0251030081067,
            "rating_q975": 1267.6037625794497,
            "rating_q025": 1260.4464434367635
        },
        "command-r-plus": {
            "rating": 1262.5044858423703,
            "rating_q975": 1266.6915881332038,
            "rating_q025": 1258.317383551537
        },
        "qwen2-72b-instruct": {
            "rating": 1262.2229751566797,
            "rating_q975": 1266.9897021128645,
            "rating_q025": 1257.456248200495
        },
        "gemma-2-9b-it": {
            "rating": 1261.5133177849432,
            "rating_q975": 1265.1289010934952,
            "rating_q025": 1257.8977344763912
        },
        "amazon-nova-lite-v1.0": {
            "rating": 1260.891144795396,
            "rating_q975": 1265.8429940355295,
            "rating_q025": 1255.9392955552623
        },
        "gemini-1.5-flash-8b-001": {
            "rating": 1260.4117256992527,
            "rating_q975": 1264.4832990157981,
            "rating_q025": 1256.3401523827072
        },
        "phi-4": {
            "rating": 1256.3334676342338,
            "rating_q975": 1260.8036030225712,
            "rating_q025": 1251.8633322458963
        },
        "olmo-2-0325-32b-instruct": {
            "rating": 1253.6809328817747,
            "rating_q975": 1264.3150828747014,
            "rating_q025": 1243.046782888848
        },
        "command-r-08-2024": {
            "rating": 1252.672315709856,
            "rating_q975": 1258.9629702080506,
            "rating_q025": 1246.3816612116614
        },
        "amazon-nova-micro-v1.0": {
            "rating": 1242.1744305601123,
            "rating_q975": 1247.088026030582,
            "rating_q025": 1237.260835089643
        },
        "mistral-large-2402": {
            "rating": 1239.858255134678,
            "rating_q975": 1244.4774077657348,
            "rating_q025": 1235.2391025036213
        },
        "jamba-1.5-mini": {
            "rating": 1237.713501676053,
            "rating_q975": 1244.6865597156961,
            "rating_q025": 1230.74044363641
        },
        "ministral-8b-2410": {
            "rating": 1236.9722262760629,
            "rating_q975": 1245.7148983486666,
            "rating_q025": 1228.2295542034592
        },
        "hunyuan-standard-256k": {
            "rating": 1234.7100780060975,
            "rating_q975": 1246.0878899453232,
            "rating_q025": 1223.3322660668719
        },
        "qwen1.5-110b-chat": {
            "rating": 1233.0272179735089,
            "rating_q975": 1238.4133594297703,
            "rating_q025": 1227.6410765172477
        },
        "qwen1.5-72b-chat": {
            "rating": 1232.147617210062,
            "rating_q975": 1237.344439719367,
            "rating_q025": 1226.950794700757
        },
        "reka-flash-21b-20240226-online": {
            "rating": 1230.9484235871942,
            "rating_q975": 1238.219172631444,
            "rating_q025": 1223.677674542944
        },
        "gemini-pro-dev-api": {
            "rating": 1228.8540140780478,
            "rating_q975": 1236.1901441462487,
            "rating_q025": 1221.5178840098474
        },
        "mixtral-8x22b-instruct-v0.1": {
            "rating": 1227.407251211092,
            "rating_q975": 1231.8239058269348,
            "rating_q025": 1222.9905965952491
        },
        "command-r": {
            "rating": 1227.345286109682,
            "rating_q975": 1231.986208851924,
            "rating_q025": 1222.7043633674402
        },
        "c4ai-aya-expanse-8b": {
            "rating": 1225.6335220439632,
            "rating_q975": 1232.350215465203,
            "rating_q025": 1218.9168286227232
        },
        "reka-flash-21b-20240226": {
            "rating": 1224.312152354708,
            "rating_q975": 1230.123903248924,
            "rating_q025": 1218.5004014604915
        },
        "llama-3.1-tulu-3-8b": {
            "rating": 1223.9896409018374,
            "rating_q975": 1234.3917299818213,
            "rating_q025": 1213.5875518218534
        },
        "mistral-medium": {
            "rating": 1221.775205921385,
            "rating_q975": 1227.2174015193589,
            "rating_q025": 1216.3330103234105
        },
        "gpt-3.5-turbo-0125": {
            "rating": 1221.1221703007434,
            "rating_q975": 1225.7513085378905,
            "rating_q025": 1216.4930320635963
        },
        "llama-3-8b-instruct": {
            "rating": 1220.1496058266562,
            "rating_q975": 1223.7022714791126,
            "rating_q025": 1216.5969401741997
        },
        "gemini-pro": {
            "rating": 1217.781941594642,
            "rating_q975": 1229.5884253952386,
            "rating_q025": 1205.9754577940453
        },
        "yi-1.5-34b-chat": {
            "rating": 1214.0896529201304,
            "rating_q975": 1218.9879459093615,
            "rating_q025": 1209.1913599308996
        },
        "llama-3.1-8b-instruct": {
            "rating": 1212.225886018644,
            "rating_q975": 1216.1086662820458,
            "rating_q025": 1208.3431057552423
        },
        "granite-3.1-8b-instruct": {
            "rating": 1211.3970166778922,
            "rating_q975": 1222.104287253527,
            "rating_q025": 1200.6897461022577
        },
        "zephyr-orpo-141b-A35b-v0.1": {
            "rating": 1210.2035020289607,
            "rating_q975": 1220.8660336219402,
            "rating_q025": 1199.540970435981
        },
        "gpt-3.5-turbo-1106": {
            "rating": 1205.614404656364,
            "rating_q975": 1214.6672908567907,
            "rating_q025": 1196.5615184559376
        },
        "qwen1.5-32b-chat": {
            "rating": 1204.2480389413702,
            "rating_q975": 1210.245078820113,
            "rating_q025": 1198.2509990626274
        },
        "phi-3-medium-4k-instruct": {
            "rating": 1198.2400473277085,
            "rating_q975": 1203.2140943432,
            "rating_q025": 1193.2660003122166
        },
        "gemma-2-2b-it": {
            "rating": 1197.8358279883023,
            "rating_q975": 1201.725228404751,
            "rating_q025": 1193.9464275718535
        },
        "internlm2_5-20b-chat": {
            "rating": 1197.5818706747673,
            "rating_q975": 1204.4749331002147,
            "rating_q025": 1190.6888082493201
        },
        "mixtral-8x7b-instruct-v0.1": {
            "rating": 1195.081215200282,
            "rating_q975": 1199.2388111919706,
            "rating_q025": 1190.9236192085934
        },
        "dbrx-instruct-preview": {
            "rating": 1192.5213344538965,
            "rating_q975": 1198.5373531443327,
            "rating_q025": 1186.5053157634607
        },
        "qwen1.5-14b-chat": {
            "rating": 1191.4097335899428,
            "rating_q975": 1198.4194614868857,
            "rating_q025": 1184.4000056930004
        },
        "yi-34b-chat": {
            "rating": 1184.6852938213697,
            "rating_q975": 1191.5306943623714,
            "rating_q025": 1177.8398932803682
        },
        "granite-3.0-8b-instruct": {
            "rating": 1183.548754877765,
            "rating_q975": 1191.979276646033,
            "rating_q025": 1175.1182331094972
        },
        "wizardlm-70b": {
            "rating": 1180.6084367511448,
            "rating_q975": 1190.1764839438874,
            "rating_q025": 1171.040389558402
        },
        "deepseek-llm-67b-chat": {
            "rating": 1180.369444945415,
            "rating_q975": 1192.0852652628678,
            "rating_q025": 1168.653624627962
        },
        "granite-3.1-2b-instruct": {
            "rating": 1180.336880320121,
            "rating_q975": 1191.1849475676001,
            "rating_q025": 1169.4888130726417
        },
        "openchat-3.5-0106": {
            "rating": 1178.9288723620282,
            "rating_q975": 1186.8786988426532,
            "rating_q025": 1170.9790458814032
        },
        "snowflake-arctic-instruct": {
            "rating": 1177.6842188238834,
            "rating_q975": 1183.4621551659307,
            "rating_q025": 1171.9062824818363
        },
        "tulu-2-dpo-70b": {
            "rating": 1176.6565799077493,
            "rating_q975": 1186.6653049135912,
            "rating_q025": 1166.6478549019077
        },
        "gemma-1.1-7b-it": {
            "rating": 1173.8506610658649,
            "rating_q975": 1179.7509461547052,
            "rating_q025": 1167.9503759770246
        },
        "starling-lm-7b-beta": {
            "rating": 1172.4755829034677,
            "rating_q975": 1179.7643785767737,
            "rating_q025": 1165.1867872301618
        },
        "phi-3-small-8k-instruct": {
            "rating": 1171.7537061967935,
            "rating_q975": 1177.5696009548067,
            "rating_q025": 1165.9378114387803
        },
        "llama-2-70b-chat": {
            "rating": 1170.8730756597208,
            "rating_q975": 1176.306751119978,
            "rating_q025": 1165.4394001994638
        },
        "openchat-3.5": {
            "rating": 1170.8580652681135,
            "rating_q975": 1180.7250971642939,
            "rating_q025": 1160.9910333719333
        },
        "llama-3.2-3b-instruct": {
            "rating": 1168.6564762523303,
            "rating_q975": 1176.0779280630286,
            "rating_q025": 1161.2350244416323
        },
        "qwq-32b-preview": {
            "rating": 1168.5856818093798,
            "rating_q975": 1179.8531295949335,
            "rating_q025": 1157.3182340238259
        },
        "vicuna-33b": {
            "rating": 1168.4734620685665,
            "rating_q975": 1174.6457939436086,
            "rating_q025": 1162.3011301935246
        },
        "openhermes-2.5-mistral-7b": {
            "rating": 1168.3841997963846,
            "rating_q975": 1178.8785516642533,
            "rating_q025": 1157.889847928516
        },
        "nous-hermes-2-mixtral-8x7b-dpo": {
            "rating": 1164.822280773445,
            "rating_q975": 1176.8374374383397,
            "rating_q025": 1152.8071241085504
        },
        "starling-lm-7b-alpha": {
            "rating": 1163.5316417948638,
            "rating_q975": 1171.6338176182762,
            "rating_q025": 1155.4294659714517
        },
        "granite-3.0-2b-instruct": {
            "rating": 1157.8627068009214,
            "rating_q975": 1166.0213864850596,
            "rating_q025": 1149.7040271167832
        },
        "llama2-70b-steerlm-chat": {
            "rating": 1153.8788824104804,
            "rating_q975": 1166.714654220322,
            "rating_q025": 1141.0431106006386
        },
        "solar-10.7b-instruct-v1.0": {
            "rating": 1149.0092340822798,
            "rating_q975": 1162.2459686271102,
            "rating_q025": 1135.7724995374497
        },
        "mistral-7b-instruct-v0.2": {
            "rating": 1148.754482734843,
            "rating_q975": 1155.3935772686739,
            "rating_q025": 1142.1153882010121
        },
        "dolphin-2.2.1-mistral-7b": {
            "rating": 1146.9771679556736,
            "rating_q975": 1162.5258419359507,
            "rating_q025": 1131.4284939753966
        },
        "wizardlm-13b": {
            "rating": 1146.397064776514,
            "rating_q975": 1155.8571564111203,
            "rating_q025": 1136.9369731419076
        },
        "llama-2-13b-chat": {
            "rating": 1145.5532828047876,
            "rating_q975": 1152.2143720740276,
            "rating_q025": 1138.8921935355477
        },
        "phi-3-mini-4k-instruct-june-2024": {
            "rating": 1143.1678579438349,
            "rating_q975": 1149.4478117046106,
            "rating_q025": 1136.8879041830594
        },
        "qwen1.5-7b-chat": {
            "rating": 1141.213500148441,
            "rating_q975": 1151.1381336766099,
            "rating_q025": 1131.288866620272
        },
        "mpt-30b-chat": {
            "rating": 1140.9299951483392,
            "rating_q975": 1153.496987206592,
            "rating_q025": 1128.3630030900865
        },
        "vicuna-13b": {
            "rating": 1138.6638695030676,
            "rating_q975": 1145.3877090324017,
            "rating_q025": 1131.9400299737335
        },
        "falcon-180b-chat": {
            "rating": 1138.0134898637507,
            "rating_q975": 1156.0341191147281,
            "rating_q025": 1119.9928606127733
        },
        "codellama-34b-instruct": {
            "rating": 1135.218285404106,
            "rating_q975": 1144.2615393716285,
            "rating_q025": 1126.1750314365831
        },
        "qwen-14b-chat": {
            "rating": 1134.4109409748985,
            "rating_q975": 1145.6904852606197,
            "rating_q025": 1123.1313966891773
        },
        "phi-3-mini-4k-instruct": {
            "rating": 1130.6841406334875,
            "rating_q975": 1136.951778504594,
            "rating_q025": 1124.4165027623812
        },
        "phi-3-mini-128k-instruct": {
            "rating": 1130.4345748689523,
            "rating_q975": 1137.7098938730921,
            "rating_q025": 1123.1592558648122
        },
        "gemma-7b-it": {
            "rating": 1129.5510569517944,
            "rating_q975": 1139.0313890048337,
            "rating_q025": 1120.070724898755
        },
        "codellama-70b-instruct": {
            "rating": 1128.0231540488803,
            "rating_q975": 1146.7170142737912,
            "rating_q025": 1109.3292938239692
        },
        "smollm2-1.7b-instruct": {
            "rating": 1127.1671991915155,
            "rating_q975": 1140.814090853846,
            "rating_q025": 1113.5203075291847
        },
        "guanaco-33b": {
            "rating": 1126.6691833021498,
            "rating_q975": 1139.2724554171868,
            "rating_q025": 1114.0659111871128
        },
        "zephyr-7b-beta": {
            "rating": 1126.6082967631942,
            "rating_q975": 1135.573191829421,
            "rating_q025": 1117.6434016969677
        },
        "palm-2": {
            "rating": 1122.3589903889201,
            "rating_q975": 1131.9662924108131,
            "rating_q025": 1112.751688367027
        },
        "llama-3.2-1b-instruct": {
            "rating": 1118.54142244186,
            "rating_q975": 1126.0351996700806,
            "rating_q025": 1111.0476452136397
        },
        "zephyr-7b-alpha": {
            "rating": 1118.5014541740245,
            "rating_q975": 1134.7336427474686,
            "rating_q025": 1102.2692656005804
        },
        "stripedhyena-nous-7b": {
            "rating": 1116.085883884948,
            "rating_q975": 1127.2665521313622,
            "rating_q025": 1104.905215638534
        },
        "llama-2-7b-chat": {
            "rating": 1113.655232098511,
            "rating_q975": 1120.737953629328,
            "rating_q025": 1106.5725105676943
        },
        "vicuna-7b": {
            "rating": 1110.2162466918742,
            "rating_q975": 1119.6097324535256,
            "rating_q025": 1100.822760930223
        },
        "gemma-1.1-2b-it": {
            "rating": 1109.700314086695,
            "rating_q975": 1117.2569317226926,
            "rating_q025": 1102.1436964506972
        },
        "mistral-7b-instruct": {
            "rating": 1098.3335436839939,
            "rating_q975": 1107.7894770458126,
            "rating_q025": 1088.8776103221753
        },
        "gemma-2b-it": {
            "rating": 1085.840780392115,
            "rating_q975": 1097.4655147334738,
            "rating_q025": 1074.216046050756
        },
        "qwen1.5-4b-chat": {
            "rating": 1084.985769946793,
            "rating_q975": 1094.422069623518,
            "rating_q025": 1075.549470270068
        },
        "olmo-7b-instruct": {
            "rating": 1072.5442548819544,
            "rating_q975": 1083.8226632177007,
            "rating_q025": 1061.265846546208
        },
        "koala-13b": {
            "rating": 1063.9082970707373,
            "rating_q975": 1074.396121275326,
            "rating_q025": 1053.4204728661482
        },
        "mpt-7b-chat": {
            "rating": 1053.4157189284776,
            "rating_q975": 1065.848694285327,
            "rating_q025": 1040.9827435716284
        },
        "gpt4all-13b-snoozy": {
            "rating": 1052.7919695775247,
            "rating_q975": 1068.826605188259,
            "rating_q025": 1036.7573339667904
        },
        "chatglm3-6b": {
            "rating": 1046.2178440120974,
            "rating_q975": 1058.4289232759547,
            "rating_q025": 1034.00676474824
        },
        "alpaca-13b": {
            "rating": 1043.6954036830864,
            "rating_q975": 1055.480465888177,
            "rating_q025": 1031.9103414779959
        },
        "RWKV-4-Raven-14B": {
            "rating": 1027.630129281743,
            "rating_q975": 1039.3675689630363,
            "rating_q025": 1015.8926896004494
        },
        "chatglm2-6b": {
            "rating": 1009.3783259808267,
            "rating_q975": 1023.8846649869723,
            "rating_q025": 994.871986974681
        },
        "oasst-pythia-12b": {
            "rating": 1006.4629868239417,
            "rating_q975": 1017.7885820358289,
            "rating_q025": 995.1373916120544
        },
        "chatglm-6b": {
            "rating": 979.013868092946,
            "rating_q975": 992.203715263436,
            "rating_q025": 965.8240209224559
        },
        "fastchat-t5-3b": {
            "rating": 973.0008631793132,
            "rating_q975": 985.9420949514188,
            "rating_q025": 960.0596314072077
        },
        "dolly-v2-12b": {
            "rating": 954.2265999209656,
            "rating_q975": 968.1517086691133,
            "rating_q025": 940.3014911728178
        },
        "llama-13b": {
            "rating": 946.0048421928775,
            "rating_q975": 962.3057071611127,
            "rating_q025": 929.7039772246424
        },
        "stablelm-tuned-alpha-7b": {
            "rating": 937.4717077210073,
            "rating_q975": 950.9454039061422,
            "rating_q025": 923.9980115358724
        }
    },
    "no_short": {
        "gemini-2.5-pro": {
            "rating": 1457.2939416871736,
            "rating_q975": 1462.152837000212,
            "rating_q025": 1452.4350463741353
        },
        "claude-opus-4-1-20250805-thinking-16k": {
            "rating": 1448.870208167689,
            "rating_q975": 1455.7436216119552,
            "rating_q025": 1441.9967947234227
        },
        "gpt-5-high": {
            "rating": 1447.2386009766565,
            "rating_q975": 1453.8441897777218,
            "rating_q025": 1440.6330121755911
        },
        "o3-2025-04-16": {
            "rating": 1444.1707879984372,
            "rating_q975": 1448.6025297322767,
            "rating_q025": 1439.7390462645978
        },
        "chatgpt-4o-latest-20250326": {
            "rating": 1443.5237401213426,
            "rating_q975": 1447.9744450047415,
            "rating_q025": 1439.0730352379435
        },
        "gpt-5-old": {
            "rating": 1442.5266465161699,
            "rating_q975": 1463.684665512553,
            "rating_q025": 1421.3686275197867
        },
        "gpt-4.5-preview-2025-02-27": {
            "rating": 1440.533417571411,
            "rating_q975": 1446.0972668882252,
            "rating_q025": 1434.9695682545967
        },
        "claude-opus-4-1-20250805": {
            "rating": 1437.7531905082378,
            "rating_q975": 1444.139655357818,
            "rating_q025": 1431.3667256586577
        },
        "gpt-5-chat": {
            "rating": 1427.5014615248497,
            "rating_q975": 1434.359597423292,
            "rating_q025": 1420.6433256264074
        },
        "qwen-max-2025-08-15": {
            "rating": 1426.3641418593966,
            "rating_q975": 1434.6913727872814,
            "rating_q025": 1418.0369109315118
        },
        "grok-4-0709": {
            "rating": 1422.6990901641009,
            "rating_q975": 1428.2571373147064,
            "rating_q025": 1417.1410430134952
        },
        "kimi-k2-0711-preview": {
            "rating": 1421.334709915426,
            "rating_q975": 1426.6786011028832,
            "rating_q025": 1415.9908187279686
        },
        "claude-opus-4-20250514-thinking-16k": {
            "rating": 1420.6438800463725,
            "rating_q975": 1425.764004728016,
            "rating_q025": 1415.5237553647287
        },
        "qwen3-235b-a22b-instruct-2507": {
            "rating": 1419.4993787173028,
            "rating_q975": 1425.3482736647713,
            "rating_q025": 1413.6504837698344
        },
        "deepseek-v3.1": {
            "rating": 1418.8888347458426,
            "rating_q975": 1427.446603235429,
            "rating_q025": 1410.3310662562565
        },
        "deepseek-r1-0528": {
            "rating": 1417.1565963818432,
            "rating_q975": 1422.6983198097262,
            "rating_q025": 1411.6148729539602
        },
        "deepseek-v3.1-thinking": {
            "rating": 1414.5537526832927,
            "rating_q975": 1423.7020738425276,
            "rating_q025": 1405.4054315240576
        },
        "mistral-medium-2508": {
            "rating": 1412.4530026255889,
            "rating_q975": 1419.8879851739598,
            "rating_q025": 1405.018020077218
        },
        "glm-4.5": {
            "rating": 1410.8308042529573,
            "rating_q975": 1417.0868976718496,
            "rating_q025": 1404.574710834065
        },
        "claude-opus-4-20250514": {
            "rating": 1410.0935306107317,
            "rating_q975": 1415.0720783542586,
            "rating_q025": 1405.1149828672046
        },
        "gpt-4.1-2025-04-14": {
            "rating": 1409.888197946342,
            "rating_q975": 1414.644426393724,
            "rating_q025": 1405.13196949896
        },
        "grok-3-preview-02-24": {
            "rating": 1408.9081965709559,
            "rating_q975": 1413.1368630353495,
            "rating_q025": 1404.6795301065622
        },
        "gemini-2.5-flash": {
            "rating": 1405.4334005875403,
            "rating_q975": 1410.1651127786997,
            "rating_q025": 1400.701688396381
        },
        "o1-2024-12-17": {
            "rating": 1400.1991073431923,
            "rating_q975": 1404.511341131598,
            "rating_q025": 1395.8868735547862
        },
        "qwen3-235b-a22b-no-thinking": {
            "rating": 1399.512208954108,
            "rating_q975": 1404.5669613716616,
            "rating_q025": 1394.4574565365542
        },
        "claude-sonnet-4-20250514-thinking-32k": {
            "rating": 1399.4154509937396,
            "rating_q975": 1404.5633795604385,
            "rating_q025": 1394.2675224270404
        },
        "qwen3-235b-a22b-thinking-2507": {
            "rating": 1399.3515136516278,
            "rating_q975": 1406.10925376259,
            "rating_q025": 1392.5937735406656
        },
        "mai-1-preview": {
            "rating": 1398.075582312051,
            "rating_q975": 1406.8679215357479,
            "rating_q025": 1389.2832430883543
        },
        "deepseek-r1": {
            "rating": 1395.2620078205364,
            "rating_q975": 1400.0180185496367,
            "rating_q025": 1390.505997091436
        },
        "o4-mini-2025-04-16": {
            "rating": 1394.3435570417869,
            "rating_q975": 1399.0880932931316,
            "rating_q025": 1389.5990207904422
        },
        "deepseek-v3-0324": {
            "rating": 1392.787172317509,
            "rating_q975": 1397.2458721599253,
            "rating_q025": 1388.3284724750924
        },
        "gpt-5-mini-high": {
            "rating": 1389.2010615903444,
            "rating_q975": 1396.724261797966,
            "rating_q025": 1381.6778613827225
        },
        "hunyuan-t1-20250711": {
            "rating": 1388.023529018169,
            "rating_q975": 1395.9158674576663,
            "rating_q025": 1380.1311905786717
        },
        "o1-preview": {
            "rating": 1386.410426082727,
            "rating_q975": 1391.1128827100456,
            "rating_q025": 1381.7079694554086
        },
        "claude-3-7-sonnet-20250219-thinking-32k": {
            "rating": 1386.2924147955512,
            "rating_q975": 1390.58684671137,
            "rating_q025": 1381.9979828797323
        },
        "qwen-vl-max-2025-08-13": {
            "rating": 1385.03933575411,
            "rating_q975": 1400.1796149809413,
            "rating_q025": 1369.8990565272786
        },
        "mistral-medium-2505": {
            "rating": 1384.918306543947,
            "rating_q975": 1389.7415678503328,
            "rating_q025": 1380.0950452375612
        },
        "claude-sonnet-4-20250514": {
            "rating": 1384.6699687592975,
            "rating_q975": 1389.7508517649371,
            "rating_q025": 1379.5890857536579
        },
        "hunyuan-turbos-20250416": {
            "rating": 1381.917946106857,
            "rating_q975": 1388.1817313584866,
            "rating_q025": 1375.6541608552275
        },
        "qwen3-coder-480b-a35b-instruct": {
            "rating": 1381.236498396756,
            "rating_q975": 1387.1923074886975,
            "rating_q025": 1375.2806893048146
        },
        "qwen3-30b-a3b-instruct-2507": {
            "rating": 1381.05315312721,
            "rating_q975": 1387.6864710219215,
            "rating_q025": 1374.4198352324986
        },
        "gpt-4.1-mini-2025-04-14": {
            "rating": 1379.5164583304702,
            "rating_q975": 1384.2765915902044,
            "rating_q025": 1374.7563250707362
        },
        "glm-4.5-air": {
            "rating": 1377.4925218603894,
            "rating_q975": 1383.8350806033582,
            "rating_q025": 1371.1499631174206
        },
        "qwen3-235b-a22b": {
            "rating": 1375.085959940646,
            "rating_q975": 1379.9723637182447,
            "rating_q025": 1370.1995561630474
        },
        "qwen2.5-max": {
            "rating": 1372.36084978085,
            "rating_q975": 1376.3449096785982,
            "rating_q025": 1368.3767898831018
        },
        "claude-3-7-sonnet-20250219": {
            "rating": 1370.0111254711614,
            "rating_q975": 1373.997287498656,
            "rating_q025": 1366.0249634436668
        },
        "claude-3-5-sonnet-20241022": {
            "rating": 1369.0395092895983,
            "rating_q975": 1372.1011747736193,
            "rating_q025": 1365.9778438055775
        },
        "minimax-m1": {
            "rating": 1368.877287364988,
            "rating_q975": 1374.0417833363801,
            "rating_q025": 1363.7127913935958
        },
        "gemma-3-27b-it": {
            "rating": 1364.5932701025995,
            "rating_q975": 1368.7861988759416,
            "rating_q025": 1360.4003413292573
        },
        "o3-mini-high": {
            "rating": 1363.810244985893,
            "rating_q975": 1368.9109899197676,
            "rating_q025": 1358.709500052018
        },
        "gemini-2.0-flash-001": {
            "rating": 1362.6006922850383,
            "rating_q975": 1366.458007632131,
            "rating_q025": 1358.7433769379454
        },
        "grok-3-mini-high": {
            "rating": 1362.2144442346523,
            "rating_q975": 1367.8545794389834,
            "rating_q025": 1356.5743090303215
        },
        "grok-3-mini-beta": {
            "rating": 1359.0736270067077,
            "rating_q975": 1364.3552552413944,
            "rating_q025": 1353.7919987720213
        },
        "deepseek-v3": {
            "rating": 1356.6032649875783,
            "rating_q975": 1361.1794195053903,
            "rating_q025": 1352.0271104697663
        },
        "mistral-small-2506": {
            "rating": 1354.7031866412578,
            "rating_q975": 1360.3300951591962,
            "rating_q025": 1349.0762781233195
        },
        "step-3": {
            "rating": 1354.3592807894802,
            "rating_q975": 1364.7240465319949,
            "rating_q025": 1343.9945150469655
        },
        "gpt-oss-120b": {
            "rating": 1353.656171514066,
            "rating_q975": 1360.6549377524184,
            "rating_q025": 1346.6574052757137
        },
        "gemini-2.0-flash-lite-preview-02-05": {
            "rating": 1351.2368785601989,
            "rating_q975": 1355.4368695585997,
            "rating_q025": 1347.0368875617983
        },
        "gemini-1.5-pro-002": {
            "rating": 1350.4594454347891,
            "rating_q975": 1353.6213593231075,
            "rating_q025": 1347.2975315464707
        },
        "o3-mini": {
            "rating": 1348.1100057763583,
            "rating_q975": 1351.8042362231508,
            "rating_q025": 1344.4157753295658
        },
        "gpt-5-nano-high": {
            "rating": 1347.9288423408086,
            "rating_q975": 1356.545677196604,
            "rating_q025": 1339.3120074850133
        },
        "command-a-03-2025": {
            "rating": 1347.5594409985872,
            "rating_q975": 1351.7727618428555,
            "rating_q025": 1343.346120154319
        },
        "hunyuan-turbos-20250226": {
            "rating": 1347.3208470698644,
            "rating_q975": 1358.254402623919,
            "rating_q025": 1336.38729151581
        },
        "qwen3-32b": {
            "rating": 1347.0996593962468,
            "rating_q975": 1356.502278962007,
            "rating_q025": 1337.6970398304866
        },
        "llama-3.1-nemotron-ultra-253b-v1": {
            "rating": 1346.2939088984367,
            "rating_q975": 1357.7877542125634,
            "rating_q025": 1334.8000635843098
        },
        "qwen-plus-0125": {
            "rating": 1344.9756950815445,
            "rating_q975": 1353.1914246705833,
            "rating_q025": 1336.7599654925057
        },
        "gpt-4o-2024-05-13": {
            "rating": 1344.4111212752277,
            "rating_q975": 1347.5823200825143,
            "rating_q025": 1341.2399224679411
        },
        "glm-4.5v": {
            "rating": 1343.8448605328556,
            "rating_q975": 1360.0665943190374,
            "rating_q025": 1327.6231267466735
        },
        "glm-4-plus-0111": {
            "rating": 1342.4821656626332,
            "rating_q975": 1350.7008349974296,
            "rating_q025": 1334.2634963278365
        },
        "nvidia-llama-3.3-nemotron-super-49b-v1.5": {
            "rating": 1341.745435848113,
            "rating_q975": 1351.1447758638876,
            "rating_q025": 1332.3460958323383
        },
        "gemma-3-12b-it": {
            "rating": 1341.566033904337,
            "rating_q975": 1350.9803647232561,
            "rating_q025": 1332.151703085418
        },
        "hunyuan-turbo-0110": {
            "rating": 1341.4134895811792,
            "rating_q975": 1352.264323412206,
            "rating_q025": 1330.5626557501525
        },
        "claude-3-5-sonnet-20240620": {
            "rating": 1341.1488141080192,
            "rating_q975": 1344.3537528213492,
            "rating_q025": 1337.9438753946893
        },
        "qwq-32b": {
            "rating": 1337.4801530841298,
            "rating_q975": 1342.1119883282358,
            "rating_q025": 1332.8483178400238
        },
        "o1-mini": {
            "rating": 1335.2555315911159,
            "rating_q975": 1338.6753385714242,
            "rating_q025": 1331.8357246108076
        },
        "llama-3.1-405b-instruct-bf16": {
            "rating": 1334.962560388238,
            "rating_q975": 1338.4737439739806,
            "rating_q025": 1331.4513768024954
        },
        "gpt-4o-2024-08-06": {
            "rating": 1333.8533270003354,
            "rating_q975": 1337.7757944129291,
            "rating_q025": 1329.9308595877415
        },
        "llama-3.1-405b-instruct-fp8": {
            "rating": 1333.5767396763272,
            "rating_q975": 1336.8903039281165,
            "rating_q025": 1330.2631754245378
        },
        "grok-2-2024-08-13": {
            "rating": 1333.21323963564,
            "rating_q975": 1336.6277034618056,
            "rating_q025": 1329.7987758094744
        },
        "gemini-advanced-0514": {
            "rating": 1332.7530311917499,
            "rating_q975": 1337.7454744307872,
            "rating_q025": 1327.7605879527125
        },
        "step-2-16k-exp-202412": {
            "rating": 1331.3762386864441,
            "rating_q975": 1339.657726160201,
            "rating_q025": 1323.094751212687
        },
        "qwen3-30b-a3b": {
            "rating": 1328.7722196920113,
            "rating_q975": 1333.7132169096885,
            "rating_q025": 1323.8312224743343
        },
        "yi-lightning": {
            "rating": 1328.2304122222858,
            "rating_q975": 1332.8860581084684,
            "rating_q025": 1323.5747663361035
        },
        "gpt-oss-20b": {
            "rating": 1327.9531429162093,
            "rating_q975": 1335.2024953287016,
            "rating_q025": 1320.7037905037173
        },
        "llama-3.3-nemotron-49b-super-v1": {
            "rating": 1327.5063211542406,
            "rating_q975": 1339.1080680695836,
            "rating_q025": 1315.9045742388976
        },
        "llama-4-maverick-17b-128e-instruct": {
            "rating": 1325.8808286791586,
            "rating_q975": 1330.5588906933958,
            "rating_q025": 1321.2027666649217
        },
        "hunyuan-large-2025-02-10": {
            "rating": 1325.5551360471673,
            "rating_q975": 1335.2191615876477,
            "rating_q025": 1315.8911105066866
        },
        "gpt-4-turbo-2024-04-09": {
            "rating": 1324.3857389893196,
            "rating_q975": 1328.0191812525218,
            "rating_q025": 1320.7522967261175
        },
        "claude-3-opus-20240229": {
            "rating": 1322.9309821026022,
            "rating_q975": 1325.7465305631683,
            "rating_q025": 1320.1154336420357
        },
        "step-1o-turbo-202506": {
            "rating": 1322.9024564759463,
            "rating_q975": 1329.4338058183303,
            "rating_q025": 1316.3711071335624
        },
        "amazon-nova-experimental-chat-05-14": {
            "rating": 1321.8845545286033,
            "rating_q975": 1327.199418815775,
            "rating_q025": 1316.5696902414318
        },
        "deepseek-v2.5-1210": {
            "rating": 1321.7406696146209,
            "rating_q975": 1329.6276865465936,
            "rating_q025": 1313.853652682648
        },
        "gemini-1.5-pro-001": {
            "rating": 1321.323363590338,
            "rating_q975": 1325.0505148189907,
            "rating_q025": 1317.5962123616848
        },
        "gpt-4.1-nano-2025-04-14": {
            "rating": 1321.0303996229468,
            "rating_q975": 1328.7569450531366,
            "rating_q025": 1313.3038541927572
        },
        "llama-4-scout-17b-16e-instruct": {
            "rating": 1319.8012202315776,
            "rating_q975": 1325.1148096050235,
            "rating_q025": 1314.487630858132
        },
        "llama-3.3-70b-instruct": {
            "rating": 1319.5594185041818,
            "rating_q975": 1322.9939851597194,
            "rating_q025": 1316.124851848644
        },
        "claude-3-5-haiku-20241022": {
            "rating": 1319.1389478205085,
            "rating_q975": 1322.468705657204,
            "rating_q025": 1315.809189983813
        },
        "gemma-3n-e4b-it": {
            "rating": 1318.042245831678,
            "rating_q975": 1323.5565847119915,
            "rating_q025": 1312.5279069513645
        },
        "glm-4-plus": {
            "rating": 1318.002413797204,
            "rating_q975": 1322.666210306339,
            "rating_q025": 1313.3386172880694
        },
        "qwen-max-0919": {
            "rating": 1317.4861503343557,
            "rating_q975": 1322.8993265951112,
            "rating_q025": 1312.0729740736
        },
        "gpt-4o-mini-2024-07-18": {
            "rating": 1315.5809319648451,
            "rating_q975": 1318.870569353202,
            "rating_q025": 1312.291294576488
        },
        "gpt-4-1106-preview": {
            "rating": 1314.7393954856602,
            "rating_q975": 1318.3723559566386,
            "rating_q025": 1311.106435014682
        },
        "mistral-large-2407": {
            "rating": 1314.1396833282997,
            "rating_q975": 1317.7848832708203,
            "rating_q025": 1310.4944833857794
        },
        "gpt-4-0125-preview": {
            "rating": 1314.12552539771,
            "rating_q975": 1317.9616771606254,
            "rating_q025": 1310.2893736347942
        },
        "qwen2.5-plus-1127": {
            "rating": 1314.053389642624,
            "rating_q975": 1320.159098374326,
            "rating_q025": 1307.9476809109224
        },
        "athene-v2-chat": {
            "rating": 1313.4533948717012,
            "rating_q975": 1317.788692450732,
            "rating_q025": 1309.1180972926702
        },
        "gemini-1.5-flash-002": {
            "rating": 1311.9069359232922,
            "rating_q975": 1315.8859980063141,
            "rating_q025": 1307.9278738402702
        },
        "hunyuan-standard-2025-02-10": {
            "rating": 1309.976086889369,
            "rating_q975": 1319.5978147224694,
            "rating_q025": 1300.3543590562688
        },
        "grok-2-mini-2024-08-13": {
            "rating": 1306.7371606878273,
            "rating_q975": 1310.2012991259273,
            "rating_q025": 1303.2730222497273
        },
        "deepseek-v2.5": {
            "rating": 1306.6026415780002,
            "rating_q975": 1311.0013394287164,
            "rating_q025": 1302.203943727284
        },
        "mistral-large-2411": {
            "rating": 1306.100213692143,
            "rating_q975": 1310.345856585011,
            "rating_q025": 1301.8545707992746
        },
        "athene-70b-0725": {
            "rating": 1304.5100716159905,
            "rating_q975": 1309.8805430225636,
            "rating_q025": 1299.139600209417
        },
        "qwen2.5-72b-instruct": {
            "rating": 1302.7653639448504,
            "rating_q975": 1306.5919831760045,
            "rating_q025": 1298.9387447136962
        },
        "gemma-3-4b-it": {
            "rating": 1301.9368389696347,
            "rating_q975": 1311.1884577765732,
            "rating_q025": 1292.685220162696
        },
        "magistral-medium-2506": {
            "rating": 1301.8329145697057,
            "rating_q975": 1308.7510225525116,
            "rating_q025": 1294.9148065869003
        },
        "mistral-small-3.1-24b-instruct-2503": {
            "rating": 1301.371515515662,
            "rating_q975": 1306.7461159013749,
            "rating_q025": 1295.9969151299488
        },
        "llama-3.1-nemotron-70b-instruct": {
            "rating": 1297.9954713967659,
            "rating_q975": 1305.4909534529081,
            "rating_q025": 1290.4999893406239
        },
        "hunyuan-large-vision": {
            "rating": 1297.529335066195,
            "rating_q975": 1306.3568714069536,
            "rating_q025": 1288.7017987254364
        },
        "llama-3.1-70b-instruct": {
            "rating": 1294.4849404692645,
            "rating_q975": 1297.9311866342687,
            "rating_q025": 1291.0386943042602
        },
        "amazon-nova-pro-v1.0": {
            "rating": 1290.3282543702326,
            "rating_q975": 1294.7126136826023,
            "rating_q025": 1285.9438950578628
        },
        "llama-3.1-tulu-3-70b": {
            "rating": 1289.938134663204,
            "rating_q975": 1300.0332753933742,
            "rating_q025": 1279.8429939330338
        },
        "jamba-1.5-large": {
            "rating": 1288.753170891116,
            "rating_q975": 1295.774755004321,
            "rating_q025": 1281.7315867779112
        },
        "gpt-4-0314": {
            "rating": 1288.1314563668766,
            "rating_q975": 1292.7726423563051,
            "rating_q025": 1283.4902703774483
        },
        "reka-core-20240904": {
            "rating": 1287.5895278391322,
            "rating_q975": 1294.2859356326837,
            "rating_q025": 1280.8931200455809
        },
        "gemma-2-27b-it": {
            "rating": 1287.3314444719263,
            "rating_q975": 1290.4720084017918,
            "rating_q025": 1284.1908805420608
        },
        "llama-3.1-nemotron-51b-instruct": {
            "rating": 1287.286557248398,
            "rating_q975": 1296.96487586683,
            "rating_q025": 1277.608238629966
        },
        "gemini-1.5-flash-001": {
            "rating": 1284.872308090516,
            "rating_q975": 1289.091200902951,
            "rating_q025": 1280.6534152780807
        },
        "claude-3-sonnet-20240229": {
            "rating": 1282.864802131304,
            "rating_q975": 1286.680932087231,
            "rating_q025": 1279.048672175377
        },
        "gemma-2-9b-it-simpo": {
            "rating": 1280.1152181122172,
            "rating_q975": 1286.7073032431072,
            "rating_q025": 1273.523132981327
        },
        "nemotron-4-340b-instruct": {
            "rating": 1279.4347575946522,
            "rating_q975": 1284.5412833202363,
            "rating_q025": 1274.3282318690683
        },
        "command-r-plus-08-2024": {
            "rating": 1279.3621373480332,
            "rating_q975": 1285.605941186132,
            "rating_q025": 1273.1183335099342
        },
        "gpt-4-0613": {
            "rating": 1276.7684330161314,
            "rating_q975": 1280.6585844106378,
            "rating_q025": 1272.8782816216253
        },
        "llama-3-70b-instruct": {
            "rating": 1275.8479684376566,
            "rating_q975": 1279.2082142752363,
            "rating_q025": 1272.487722600077
        },
        "glm-4-0520": {
            "rating": 1275.7052203065884,
            "rating_q975": 1282.5049187221323,
            "rating_q025": 1268.9055218910446
        },
        "reka-flash-20240904": {
            "rating": 1275.4739345103494,
            "rating_q975": 1282.0347162769867,
            "rating_q025": 1268.9131527437119
        },
        "mistral-small-24b-instruct-2501": {
            "rating": 1275.4612768107038,
            "rating_q975": 1281.2035946162468,
            "rating_q025": 1269.7189590051607
        },
        "qwen2.5-coder-32b-instruct": {
            "rating": 1271.3492877902268,
            "rating_q975": 1279.1326983416175,
            "rating_q025": 1263.565877238836
        },
        "c4ai-aya-expanse-32b": {
            "rating": 1269.48095613761,
            "rating_q975": 1274.121827804564,
            "rating_q025": 1264.8400844706562
        },
        "command-r-plus": {
            "rating": 1265.4850995791649,
            "rating_q975": 1269.6060695457056,
            "rating_q025": 1261.364129612624
        },
        "deepseek-coder-v2": {
            "rating": 1265.3239870612447,
            "rating_q975": 1271.3937662036687,
            "rating_q025": 1259.2542079188206
        },
        "gemma-2-9b-it": {
            "rating": 1265.1448276599435,
            "rating_q975": 1268.7239969727382,
            "rating_q025": 1261.5656583471489
        },
        "qwen2-72b-instruct": {
            "rating": 1264.1186129292603,
            "rating_q975": 1268.8407198027962,
            "rating_q025": 1259.3965060557243
        },
        "claude-3-haiku-20240307": {
            "rating": 1262.6218945839141,
            "rating_q975": 1266.126647853317,
            "rating_q025": 1259.1171413145112
        },
        "amazon-nova-lite-v1.0": {
            "rating": 1262.2891696981656,
            "rating_q975": 1267.2263229892567,
            "rating_q025": 1257.3520164070744
        },
        "gemini-1.5-flash-8b-001": {
            "rating": 1261.180995254234,
            "rating_q975": 1265.2051104429052,
            "rating_q025": 1257.156880065563
        },
        "phi-4": {
            "rating": 1258.0747675463413,
            "rating_q975": 1262.4932085455234,
            "rating_q025": 1253.6563265471593
        },
        "olmo-2-0325-32b-instruct": {
            "rating": 1255.8152559562054,
            "rating_q975": 1266.35928354414,
            "rating_q025": 1245.2712283682706
        },
        "command-r-08-2024": {
            "rating": 1254.9981663711396,
            "rating_q975": 1261.2209448746305,
            "rating_q025": 1248.7753878676485
        },
        "mistral-large-2402": {
            "rating": 1245.253730965127,
            "rating_q975": 1249.7912723788565,
            "rating_q025": 1240.7161895513975
        },
        "amazon-nova-micro-v1.0": {
            "rating": 1244.054926528539,
            "rating_q975": 1248.9502579506175,
            "rating_q025": 1239.1595951064605
        },
        "jamba-1.5-mini": {
            "rating": 1240.5498703376147,
            "rating_q975": 1247.4703034092277,
            "rating_q025": 1233.6294372660016
        },
        "ministral-8b-2410": {
            "rating": 1239.693120353289,
            "rating_q975": 1248.426047040421,
            "rating_q025": 1230.9601936661566
        },
        "hunyuan-standard-256k": {
            "rating": 1239.4243741704556,
            "rating_q975": 1250.648688879697,
            "rating_q025": 1228.2000594612143
        },
        "qwen1.5-110b-chat": {
            "rating": 1236.3021960437263,
            "rating_q975": 1241.6569056023957,
            "rating_q025": 1230.9474864850567
        },
        "reka-flash-21b-20240226-online": {
            "rating": 1236.2314770052078,
            "rating_q975": 1243.4806600966697,
            "rating_q025": 1228.982293913746
        },
        "qwen1.5-72b-chat": {
            "rating": 1235.1139176498575,
            "rating_q975": 1240.2186367283716,
            "rating_q025": 1230.0091985713432
        },
        "gemini-pro-dev-api": {
            "rating": 1235.029914663301,
            "rating_q975": 1242.24305927135,
            "rating_q025": 1227.8167700552522
        },
        "mixtral-8x22b-instruct-v0.1": {
            "rating": 1233.2681171825602,
            "rating_q975": 1237.616006294944,
            "rating_q025": 1228.920228070176
        },
        "command-r": {
            "rating": 1230.6089239611279,
            "rating_q975": 1235.2005230673353,
            "rating_q025": 1226.0173248549204
        },
        "reka-flash-21b-20240226": {
            "rating": 1228.2350138184538,
            "rating_q975": 1234.0036022266013,
            "rating_q025": 1222.4664254103063
        },
        "c4ai-aya-expanse-8b": {
            "rating": 1228.1325552216995,
            "rating_q975": 1234.809217930436,
            "rating_q025": 1221.455892512963
        },
        "mistral-medium": {
            "rating": 1227.2113838981204,
            "rating_q975": 1232.5559901157458,
            "rating_q025": 1221.866777680495
        },
        "llama-3.1-tulu-3-8b": {
            "rating": 1225.8640625810106,
            "rating_q975": 1236.1369824548524,
            "rating_q025": 1215.5911427071687
        },
        "gpt-3.5-turbo-0125": {
            "rating": 1224.9515318917365,
            "rating_q975": 1229.485189334695,
            "rating_q025": 1220.4178744487779
        },
        "llama-3-8b-instruct": {
            "rating": 1223.354526732795,
            "rating_q975": 1226.8696341488771,
            "rating_q025": 1219.839419316713
        },
        "gemini-pro": {
            "rating": 1222.708741059626,
            "rating_q975": 1234.3415333470823,
            "rating_q025": 1211.0759487721693
        },
        "zephyr-orpo-141b-A35b-v0.1": {
            "rating": 1217.4037459709639,
            "rating_q975": 1228.036149076639,
            "rating_q025": 1206.7713428652892
        },
        "yi-1.5-34b-chat": {
            "rating": 1216.294304577398,
            "rating_q975": 1221.1296916867184,
            "rating_q025": 1211.4589174680775
        },
        "llama-3.1-8b-instruct": {
            "rating": 1214.4914969886956,
            "rating_q975": 1218.3486390206385,
            "rating_q025": 1210.6343549567528
        },
        "granite-3.1-8b-instruct": {
            "rating": 1212.1655708585856,
            "rating_q975": 1222.713562728747,
            "rating_q025": 1201.6175789884242
        },
        "qwen1.5-32b-chat": {
            "rating": 1207.3773236117415,
            "rating_q975": 1213.3120926036888,
            "rating_q025": 1201.4425546197942
        },
        "gpt-3.5-turbo-1106": {
            "rating": 1202.2653209187288,
            "rating_q975": 1210.9313634919956,
            "rating_q025": 1193.5992783454617
        },
        "mixtral-8x7b-instruct-v0.1": {
            "rating": 1201.5527667137844,
            "rating_q975": 1205.6352013902983,
            "rating_q025": 1197.4703320372707
        },
        "phi-3-medium-4k-instruct": {
            "rating": 1201.1222817266298,
            "rating_q975": 1206.0511953650798,
            "rating_q025": 1196.1933680881798
        },
        "gemma-2-2b-it": {
            "rating": 1200.688272053765,
            "rating_q975": 1204.5447843561963,
            "rating_q025": 1196.831759751334
        },
        "dbrx-instruct-preview": {
            "rating": 1198.9214897198112,
            "rating_q975": 1204.8436333283148,
            "rating_q025": 1192.9993461113077
        },
        "internlm2_5-20b-chat": {
            "rating": 1198.4305319789585,
            "rating_q975": 1205.2564401629747,
            "rating_q025": 1191.6046237949424
        },
        "qwen1.5-14b-chat": {
            "rating": 1194.5104014314686,
            "rating_q975": 1201.4285882146037,
            "rating_q025": 1187.5922146483335
        },
        "granite-3.0-8b-instruct": {
            "rating": 1189.141620917855,
            "rating_q975": 1197.432712678451,
            "rating_q025": 1180.8505291572592
        },
        "yi-34b-chat": {
            "rating": 1187.4549118360555,
            "rating_q975": 1194.145012291015,
            "rating_q025": 1180.764811381096
        },
        "wizardlm-70b": {
            "rating": 1186.5252628529172,
            "rating_q975": 1195.903519821028,
            "rating_q025": 1177.1470058848063
        },
        "deepseek-llm-67b-chat": {
            "rating": 1185.541794287075,
            "rating_q975": 1197.0320110683242,
            "rating_q025": 1174.0515775058254
        },
        "granite-3.1-2b-instruct": {
            "rating": 1185.1228147574066,
            "rating_q975": 1195.838284637439,
            "rating_q025": 1174.407344877374
        },
        "openchat-3.5-0106": {
            "rating": 1184.2417232782366,
            "rating_q975": 1192.1201940723129,
            "rating_q025": 1176.3632524841603
        },
        "openchat-3.5": {
            "rating": 1182.8616773244567,
            "rating_q975": 1192.4800376746405,
            "rating_q025": 1173.2433169742728
        },
        "snowflake-arctic-instruct": {
            "rating": 1182.6721650146828,
            "rating_q975": 1188.4277618257406,
            "rating_q025": 1176.9165682036253
        },
        "tulu-2-dpo-70b": {
            "rating": 1182.0546537976302,
            "rating_q975": 1191.8380856376364,
            "rating_q025": 1172.271221957624
        },
        "gemma-1.1-7b-it": {
            "rating": 1179.926421321682,
            "rating_q975": 1185.8152828705024,
            "rating_q025": 1174.0375597728614
        },
        "openhermes-2.5-mistral-7b": {
            "rating": 1177.6086028780323,
            "rating_q975": 1187.9514757415102,
            "rating_q025": 1167.2657300145543
        },
        "starling-lm-7b-beta": {
            "rating": 1176.0696924135289,
            "rating_q975": 1183.3446504789422,
            "rating_q025": 1168.7947343481155
        },
        "vicuna-33b": {
            "rating": 1175.911953058735,
            "rating_q975": 1181.9971687241239,
            "rating_q025": 1169.8267373933463
        },
        "phi-3-small-8k-instruct": {
            "rating": 1175.8207997319153,
            "rating_q975": 1181.5176879242033,
            "rating_q025": 1170.1239115396274
        },
        "llama-2-70b-chat": {
            "rating": 1174.788575994934,
            "rating_q975": 1180.1605823528446,
            "rating_q025": 1169.4165696370235
        },
        "starling-lm-7b-alpha": {
            "rating": 1171.3527159405198,
            "rating_q975": 1179.3392190863174,
            "rating_q025": 1163.3662127947223
        },
        "llama-3.2-3b-instruct": {
            "rating": 1171.1345032609581,
            "rating_q975": 1178.5008179942506,
            "rating_q025": 1163.7681885276656
        },
        "nous-hermes-2-mixtral-8x7b-dpo": {
            "rating": 1168.8108570697311,
            "rating_q975": 1180.6497811735014,
            "rating_q025": 1156.9719329659608
        },
        "qwq-32b-preview": {
            "rating": 1166.2921860453496,
            "rating_q975": 1177.3790386083233,
            "rating_q025": 1155.2053334823759
        },
        "granite-3.0-2b-instruct": {
            "rating": 1162.3635872853006,
            "rating_q975": 1170.3857695160486,
            "rating_q025": 1154.341405054553
        },
        "llama2-70b-steerlm-chat": {
            "rating": 1161.1328420741884,
            "rating_q975": 1173.7268287205743,
            "rating_q025": 1148.5388554278027
        },
        "solar-10.7b-instruct-v1.0": {
            "rating": 1158.274858301018,
            "rating_q975": 1171.330190677133,
            "rating_q025": 1145.2195259249027
        },
        "dolphin-2.2.1-mistral-7b": {
            "rating": 1156.7070538493676,
            "rating_q975": 1172.0580356635544,
            "rating_q025": 1141.3560720351811
        },
        "mistral-7b-instruct-v0.2": {
            "rating": 1153.5896516590892,
            "rating_q975": 1160.121184980035,
            "rating_q025": 1147.0581183381435
        },
        "mpt-30b-chat": {
            "rating": 1151.951818175205,
            "rating_q975": 1164.1928195041694,
            "rating_q025": 1139.710816846241
        },
        "wizardlm-13b": {
            "rating": 1151.6544529614519,
            "rating_q975": 1160.9035256824448,
            "rating_q025": 1142.405380240459
        },
        "falcon-180b-chat": {
            "rating": 1149.7231394869464,
            "rating_q975": 1166.906577657424,
            "rating_q025": 1132.5397013164688
        },
        "phi-3-mini-4k-instruct-june-2024": {
            "rating": 1147.9323989851662,
            "rating_q975": 1154.1011320916768,
            "rating_q025": 1141.7636658786555
        },
        "llama-2-13b-chat": {
            "rating": 1145.8527147954073,
            "rating_q975": 1152.4418124700235,
            "rating_q025": 1139.2636171207914
        },
        "qwen1.5-7b-chat": {
            "rating": 1145.3265610089222,
            "rating_q975": 1155.102087119355,
            "rating_q025": 1135.5510348984894
        },
        "vicuna-13b": {
            "rating": 1143.763435893028,
            "rating_q975": 1150.357259317923,
            "rating_q025": 1137.1696124681328
        },
        "qwen-14b-chat": {
            "rating": 1139.8861641150302,
            "rating_q975": 1150.8089303477987,
            "rating_q025": 1128.963397882262
        },
        "codellama-34b-instruct": {
            "rating": 1138.63702377441,
            "rating_q975": 1147.4717176541346,
            "rating_q025": 1129.8023298946853
        },
        "palm-2": {
            "rating": 1135.8224077211203,
            "rating_q975": 1145.2426813439636,
            "rating_q025": 1126.402134098277
        },
        "gemma-7b-it": {
            "rating": 1135.7648197856554,
            "rating_q975": 1145.156188920481,
            "rating_q025": 1126.3734506508297
        },
        "zephyr-7b-beta": {
            "rating": 1133.9935795685756,
            "rating_q975": 1142.7927737644525,
            "rating_q025": 1125.194385372699
        },
        "phi-3-mini-128k-instruct": {
            "rating": 1133.9005072585546,
            "rating_q975": 1141.136085773597,
            "rating_q025": 1126.664928743512
        },
        "phi-3-mini-4k-instruct": {
            "rating": 1133.3298617959645,
            "rating_q975": 1139.4861834285375,
            "rating_q025": 1127.1735401633914
        },
        "zephyr-7b-alpha": {
            "rating": 1131.077410760149,
            "rating_q975": 1146.9292078167566,
            "rating_q025": 1115.225613703541
        },
        "guanaco-33b": {
            "rating": 1129.440520097814,
            "rating_q975": 1141.5101019872227,
            "rating_q025": 1117.3709382084053
        },
        "smollm2-1.7b-instruct": {
            "rating": 1128.487066765731,
            "rating_q975": 1142.0101106498041,
            "rating_q025": 1114.9640228816577
        },
        "codellama-70b-instruct": {
            "rating": 1123.5362515654529,
            "rating_q975": 1141.5324068627676,
            "rating_q025": 1105.5400962681379
        },
        "stripedhyena-nous-7b": {
            "rating": 1122.4865596844938,
            "rating_q975": 1133.4005845163806,
            "rating_q025": 1111.572534852607
        },
        "llama-3.2-1b-instruct": {
            "rating": 1119.6699709420868,
            "rating_q975": 1127.1544657744391,
            "rating_q025": 1112.1854761097345
        },
        "vicuna-7b": {
            "rating": 1117.030411258445,
            "rating_q975": 1126.2112286748866,
            "rating_q025": 1107.8495938420033
        },
        "gemma-1.1-2b-it": {
            "rating": 1114.8632321617006,
            "rating_q975": 1122.4406687761327,
            "rating_q025": 1107.2857955472684
        },
        "mistral-7b-instruct": {
            "rating": 1112.0731966920353,
            "rating_q975": 1121.3112967211555,
            "rating_q025": 1102.8350966629155
        },
        "llama-2-7b-chat": {
            "rating": 1111.7217675692154,
            "rating_q975": 1118.6439217129425,
            "rating_q025": 1104.7996134254884
        },
        "qwen1.5-4b-chat": {
            "rating": 1092.21733880847,
            "rating_q975": 1101.4909609805104,
            "rating_q025": 1082.9437166364296
        },
        "gemma-2b-it": {
            "rating": 1092.0523062463367,
            "rating_q975": 1103.5782814811178,
            "rating_q025": 1080.5263310115558
        },
        "olmo-7b-instruct": {
            "rating": 1078.2127264778535,
            "rating_q975": 1089.3192237391418,
            "rating_q025": 1067.1062292165652
        },
        "koala-13b": {
            "rating": 1070.0185348195325,
            "rating_q975": 1080.0123734685076,
            "rating_q025": 1060.0246961705575
        },
        "gpt4all-13b-snoozy": {
            "rating": 1064.0454207227076,
            "rating_q975": 1079.404828801216,
            "rating_q025": 1048.6860126441993
        },
        "mpt-7b-chat": {
            "rating": 1060.3690684090993,
            "rating_q975": 1072.4049478542597,
            "rating_q025": 1048.3331889639387
        },
        "alpaca-13b": {
            "rating": 1060.0407419685043,
            "rating_q975": 1071.4833098383374,
            "rating_q025": 1048.5981740986713
        },
        "chatglm3-6b": {
            "rating": 1056.9262338563249,
            "rating_q975": 1068.5445255074055,
            "rating_q025": 1045.307942205244
        },
        "RWKV-4-Raven-14B": {
            "rating": 1040.0838281568176,
            "rating_q975": 1051.4800789920646,
            "rating_q025": 1028.6875773215704
        },
        "chatglm2-6b": {
            "rating": 1024.8354131690262,
            "rating_q975": 1038.4898960512533,
            "rating_q025": 1011.1809302867994
        },
        "oasst-pythia-12b": {
            "rating": 1020.9479652750917,
            "rating_q975": 1031.8968060703648,
            "rating_q025": 1009.9991244798189
        },
        "chatglm-6b": {
            "rating": 993.4004797989438,
            "rating_q975": 1006.1606692934861,
            "rating_q025": 980.6402903044016
        },
        "fastchat-t5-3b": {
            "rating": 989.5488937821112,
            "rating_q975": 1002.1015831735381,
            "rating_q025": 976.9962043906844
        },
        "dolly-v2-12b": {
            "rating": 974.3699399477022,
            "rating_q975": 988.0361129322885,
            "rating_q025": 960.7037669631159
        },
        "llama-13b": {
            "rating": 968.5949774407902,
            "rating_q975": 984.5353717248049,
            "rating_q025": 952.6545831567755
        },
        "stablelm-tuned-alpha-7b": {
            "rating": 950.1793789899905,
            "rating_q975": 963.0967230192527,
            "rating_q025": 937.2620349607282
        }
    },
    "no_tie": {
        "gemini-2.5-pro": {
            "rating": 1458.3059577841655,
            "rating_q975": 1465.2967412490852,
            "rating_q025": 1451.315174319246
        },
        "claude-opus-4-1-20250805-thinking-16k": {
            "rating": 1450.8719477512227,
            "rating_q975": 1460.5079135715723,
            "rating_q025": 1441.235981930873
        },
        "gpt-4.5-preview-2025-02-27": {
            "rating": 1448.3590290202167,
            "rating_q975": 1456.902911914594,
            "rating_q025": 1439.8151461258394
        },
        "chatgpt-4o-latest-20250326": {
            "rating": 1446.2664598772005,
            "rating_q975": 1452.6251526541212,
            "rating_q025": 1439.90776710028
        },
        "gpt-5-high": {
            "rating": 1446.2462369295438,
            "rating_q975": 1455.2604587275735,
            "rating_q025": 1437.2320151315141
        },
        "o3-2025-04-16": {
            "rating": 1442.3301338057672,
            "rating_q975": 1448.6161873062051,
            "rating_q025": 1436.0440803053293
        },
        "claude-opus-4-1-20250805": {
            "rating": 1433.8037513509337,
            "rating_q975": 1442.490558919154,
            "rating_q025": 1425.1169437827134
        },
        "gpt-5-old": {
            "rating": 1429.868591725291,
            "rating_q975": 1458.5390219448852,
            "rating_q025": 1401.198161505697
        },
        "gpt-5-chat": {
            "rating": 1418.1728852291246,
            "rating_q975": 1427.8899688279207,
            "rating_q025": 1408.4558016303286
        },
        "qwen-max-2025-08-15": {
            "rating": 1416.9006253940333,
            "rating_q975": 1428.927166225576,
            "rating_q025": 1404.8740845624907
        },
        "kimi-k2-0711-preview": {
            "rating": 1413.7208418778137,
            "rating_q975": 1421.1008177573901,
            "rating_q025": 1406.3408659982372
        },
        "claude-opus-4-20250514-thinking-16k": {
            "rating": 1411.7337037233665,
            "rating_q975": 1418.654104466862,
            "rating_q025": 1404.813302979871
        },
        "qwen3-235b-a22b-instruct-2507": {
            "rating": 1410.7855027252435,
            "rating_q975": 1419.186390557935,
            "rating_q025": 1402.384614892552
        },
        "grok-4-0709": {
            "rating": 1410.591888940121,
            "rating_q975": 1418.367331741582,
            "rating_q025": 1402.81644613866
        },
        "deepseek-r1-0528": {
            "rating": 1406.3564166244078,
            "rating_q975": 1414.1679970624095,
            "rating_q025": 1398.5448361864062
        },
        "deepseek-v3.1": {
            "rating": 1405.845806959571,
            "rating_q975": 1418.18549881429,
            "rating_q025": 1393.506115104852
        },
        "deepseek-v3.1-thinking": {
            "rating": 1401.4135704672137,
            "rating_q975": 1414.5609986153825,
            "rating_q025": 1388.266142319045
        },
        "claude-opus-4-20250514": {
            "rating": 1397.758424623105,
            "rating_q975": 1404.5360898383549,
            "rating_q025": 1390.980759407855
        },
        "gpt-4.1-2025-04-14": {
            "rating": 1397.6937435550387,
            "rating_q975": 1404.3311078209695,
            "rating_q025": 1391.056379289108
        },
        "grok-3-preview-02-24": {
            "rating": 1396.2514877340836,
            "rating_q975": 1402.377971254264,
            "rating_q025": 1390.1250042139034
        },
        "glm-4.5": {
            "rating": 1394.8089466790939,
            "rating_q975": 1403.761036604537,
            "rating_q025": 1385.8568567536508
        },
        "mistral-medium-2508": {
            "rating": 1393.5866668440697,
            "rating_q975": 1404.1380617774892,
            "rating_q025": 1383.0352719106502
        },
        "gemini-2.5-flash": {
            "rating": 1387.5220378863887,
            "rating_q975": 1394.140579136445,
            "rating_q025": 1380.9034966363324
        },
        "o1-2024-12-17": {
            "rating": 1384.0433533250375,
            "rating_q975": 1390.4126422960958,
            "rating_q025": 1377.674064353979
        },
        "claude-sonnet-4-20250514-thinking-32k": {
            "rating": 1382.1604239893575,
            "rating_q975": 1389.0577656912265,
            "rating_q025": 1375.2630822874885
        },
        "qwen3-235b-a22b-no-thinking": {
            "rating": 1380.387047376435,
            "rating_q975": 1387.3727075392042,
            "rating_q025": 1373.4013872136659
        },
        "mai-1-preview": {
            "rating": 1379.9586176603195,
            "rating_q975": 1392.891298916877,
            "rating_q025": 1367.025936403762
        },
        "deepseek-r1": {
            "rating": 1379.7839667667108,
            "rating_q975": 1387.0470134422303,
            "rating_q025": 1372.5209200911913
        },
        "qwen3-235b-a22b-thinking-2507": {
            "rating": 1379.600989129061,
            "rating_q975": 1389.3245317218054,
            "rating_q025": 1369.8774465363165
        },
        "o4-mini-2025-04-16": {
            "rating": 1375.7463964785943,
            "rating_q975": 1382.438159713725,
            "rating_q025": 1369.0546332434633
        },
        "deepseek-v3-0324": {
            "rating": 1372.9845828253845,
            "rating_q975": 1379.4005901355904,
            "rating_q025": 1366.5685755151783
        },
        "claude-3-7-sonnet-20250219-thinking-32k": {
            "rating": 1367.6854874417324,
            "rating_q975": 1373.592698985089,
            "rating_q025": 1361.7782758983758
        },
        "o1-preview": {
            "rating": 1366.6006601513386,
            "rating_q975": 1373.7673461425738,
            "rating_q025": 1359.4339741601032
        },
        "gpt-5-mini-high": {
            "rating": 1364.5642339044864,
            "rating_q975": 1375.0584090899229,
            "rating_q025": 1354.0700587190502
        },
        "claude-sonnet-4-20250514": {
            "rating": 1364.0193682304769,
            "rating_q975": 1370.876119745879,
            "rating_q025": 1357.1626167150746
        },
        "hunyuan-t1-20250711": {
            "rating": 1361.5453046767516,
            "rating_q975": 1372.8912578200461,
            "rating_q025": 1350.1993515334573
        },
        "mistral-medium-2505": {
            "rating": 1360.8002645767344,
            "rating_q975": 1367.700410249687,
            "rating_q025": 1353.9001189037817
        },
        "qwen3-coder-480b-a35b-instruct": {
            "rating": 1357.6110968926403,
            "rating_q975": 1366.0501098699483,
            "rating_q025": 1349.172083915332
        },
        "qwen-vl-max-2025-08-13": {
            "rating": 1357.5009248862557,
            "rating_q975": 1379.4459004555958,
            "rating_q025": 1335.5559493169158
        },
        "hunyuan-turbos-20250416": {
            "rating": 1356.5144918421568,
            "rating_q975": 1365.405064020684,
            "rating_q025": 1347.6239196636295
        },
        "gpt-4.1-mini-2025-04-14": {
            "rating": 1355.7391991583988,
            "rating_q975": 1362.4386930661187,
            "rating_q025": 1349.039705250679
        },
        "qwen3-30b-a3b-instruct-2507": {
            "rating": 1353.1049809771575,
            "rating_q975": 1362.6189314110668,
            "rating_q025": 1343.5910305432483
        },
        "glm-4.5-air": {
            "rating": 1349.7610920789705,
            "rating_q975": 1358.8803621842496,
            "rating_q025": 1340.6418219736915
        },
        "qwen2.5-max": {
            "rating": 1346.6002868049354,
            "rating_q975": 1352.5807123856139,
            "rating_q025": 1340.6198612242572
        },
        "claude-3-7-sonnet-20250219": {
            "rating": 1345.889711390487,
            "rating_q975": 1351.4425414088128,
            "rating_q025": 1340.3368813721613
        },
        "qwen3-235b-a22b": {
            "rating": 1344.9535194075436,
            "rating_q975": 1351.9899478004556,
            "rating_q025": 1337.9170910146318
        },
        "claude-3-5-sonnet-20241022": {
            "rating": 1340.760673764343,
            "rating_q975": 1345.0701271351459,
            "rating_q025": 1336.4512203935399
        },
        "minimax-m1": {
            "rating": 1338.2859949417802,
            "rating_q975": 1345.5468849568545,
            "rating_q025": 1331.025104926706
        },
        "o3-mini-high": {
            "rating": 1329.4922447611787,
            "rating_q975": 1337.2014444837175,
            "rating_q025": 1321.7830450386398
        },
        "gemma-3-27b-it": {
            "rating": 1329.255489297916,
            "rating_q975": 1335.3201082972282,
            "rating_q025": 1323.190870298604
        },
        "gemini-2.0-flash-001": {
            "rating": 1328.364107452476,
            "rating_q975": 1334.0298454013137,
            "rating_q025": 1322.698369503638
        },
        "deepseek-v3": {
            "rating": 1325.9315381494334,
            "rating_q975": 1333.1971868920734,
            "rating_q025": 1318.6658894067934
        },
        "grok-3-mini-high": {
            "rating": 1324.6654249431388,
            "rating_q975": 1332.5728045222518,
            "rating_q025": 1316.7580453640257
        },
        "grok-3-mini-beta": {
            "rating": 1320.6498628640086,
            "rating_q975": 1328.053762242117,
            "rating_q025": 1313.2459634859003
        },
        "mistral-small-2506": {
            "rating": 1317.2810764684689,
            "rating_q975": 1325.4491655510512,
            "rating_q025": 1309.1129873858865
        },
        "step-3": {
            "rating": 1314.4005481967085,
            "rating_q975": 1329.332346247551,
            "rating_q025": 1299.4687501458664
        },
        "gpt-oss-120b": {
            "rating": 1313.753303704459,
            "rating_q975": 1323.709538734608,
            "rating_q025": 1303.7970686743101
        },
        "gemini-1.5-pro-002": {
            "rating": 1312.3178218670332,
            "rating_q975": 1317.3625159496123,
            "rating_q025": 1307.2731277844543
        },
        "gemini-2.0-flash-lite-preview-02-05": {
            "rating": 1311.58624093903,
            "rating_q975": 1318.2177997978006,
            "rating_q025": 1304.9546820802593
        },
        "o3-mini": {
            "rating": 1307.2658372098797,
            "rating_q975": 1312.5750147224678,
            "rating_q025": 1301.9566596972918
        },
        "command-a-03-2025": {
            "rating": 1305.8274787588105,
            "rating_q975": 1312.067810318661,
            "rating_q025": 1299.5871471989599
        },
        "gpt-5-nano-high": {
            "rating": 1305.6308669191326,
            "rating_q975": 1317.8759438871775,
            "rating_q025": 1293.3857899510876
        },
        "qwen3-32b": {
            "rating": 1305.142694569855,
            "rating_q975": 1319.8230815973948,
            "rating_q025": 1290.462307542315
        },
        "qwen-plus-0125": {
            "rating": 1305.112361217983,
            "rating_q975": 1317.913361640676,
            "rating_q025": 1292.3113607952903
        },
        "hunyuan-turbos-20250226": {
            "rating": 1303.3719315522328,
            "rating_q975": 1322.4802631551158,
            "rating_q025": 1284.26359994935
        },
        "gpt-4o-2024-05-13": {
            "rating": 1302.6721647759196,
            "rating_q975": 1307.8909425110917,
            "rating_q025": 1297.4533870407477
        },
        "llama-3.1-nemotron-ultra-253b-v1": {
            "rating": 1300.3593233268773,
            "rating_q975": 1318.0286911278326,
            "rating_q025": 1282.689955525922
        },
        "glm-4.5v": {
            "rating": 1298.5804812981416,
            "rating_q975": 1322.2589350255012,
            "rating_q025": 1274.902027570782
        },
        "glm-4-plus-0111": {
            "rating": 1298.41319954492,
            "rating_q975": 1311.0196231950401,
            "rating_q025": 1285.8067758947998
        },
        "nvidia-llama-3.3-nemotron-super-49b-v1.5": {
            "rating": 1297.8086086405958,
            "rating_q975": 1311.7851469256204,
            "rating_q025": 1283.832070355571
        },
        "claude-3-5-sonnet-20240620": {
            "rating": 1294.6931090660441,
            "rating_q975": 1299.7032271586288,
            "rating_q025": 1289.6829909734593
        },
        "gemma-3-12b-it": {
            "rating": 1293.8465036078583,
            "rating_q975": 1308.3128349813235,
            "rating_q025": 1279.380172234393
        },
        "qwq-32b": {
            "rating": 1289.2103317128601,
            "rating_q975": 1296.21916781021,
            "rating_q025": 1282.2014956155103
        },
        "o1-mini": {
            "rating": 1288.920025854766,
            "rating_q975": 1294.261724578822,
            "rating_q025": 1283.57832713071
        },
        "llama-3.1-405b-instruct-bf16": {
            "rating": 1286.6582622666494,
            "rating_q975": 1292.1051069086009,
            "rating_q025": 1281.2114176246982
        },
        "step-2-16k-exp-202412": {
            "rating": 1285.786097118551,
            "rating_q975": 1299.6544146496665,
            "rating_q025": 1271.9177795874355
        },
        "hunyuan-turbo-0110": {
            "rating": 1285.5371648274531,
            "rating_q975": 1304.8913330986768,
            "rating_q025": 1266.1829965562292
        },
        "gpt-4o-2024-08-06": {
            "rating": 1284.7511607447136,
            "rating_q975": 1291.014653790508,
            "rating_q025": 1278.4876676989193
        },
        "grok-2-2024-08-13": {
            "rating": 1284.2638141770274,
            "rating_q975": 1289.6165989196445,
            "rating_q025": 1278.9110294344102
        },
        "llama-3.1-405b-instruct-fp8": {
            "rating": 1282.6557399913315,
            "rating_q975": 1288.1803200445404,
            "rating_q025": 1277.1311599381227
        },
        "gemini-advanced-0514": {
            "rating": 1282.3101393440197,
            "rating_q975": 1289.5756070849886,
            "rating_q025": 1275.0446716030508
        },
        "yi-lightning": {
            "rating": 1279.8737055643353,
            "rating_q975": 1287.3563133598448,
            "rating_q025": 1272.391097768826
        },
        "qwen3-30b-a3b": {
            "rating": 1278.0488554499866,
            "rating_q975": 1285.213065885309,
            "rating_q025": 1270.8846450146639
        },
        "gpt-oss-20b": {
            "rating": 1278.037616536852,
            "rating_q975": 1288.415009164979,
            "rating_q025": 1267.6602239087254
        },
        "llama-4-maverick-17b-128e-instruct": {
            "rating": 1277.57522651877,
            "rating_q975": 1284.3393613140904,
            "rating_q025": 1270.8110917234499
        },
        "llama-3.3-nemotron-49b-super-v1": {
            "rating": 1274.4917726640192,
            "rating_q975": 1293.6052576109219,
            "rating_q025": 1255.3782877171166
        },
        "hunyuan-large-2025-02-10": {
            "rating": 1268.862038670963,
            "rating_q975": 1284.0509297115589,
            "rating_q025": 1253.673147630367
        },
        "deepseek-v2.5-1210": {
            "rating": 1267.8131916856714,
            "rating_q975": 1280.8892359490342,
            "rating_q025": 1254.7371474223087
        },
        "step-1o-turbo-202506": {
            "rating": 1267.446668370203,
            "rating_q975": 1276.7194491353152,
            "rating_q025": 1258.1738876050908
        },
        "gpt-4-turbo-2024-04-09": {
            "rating": 1267.0689258211073,
            "rating_q975": 1272.740000612259,
            "rating_q025": 1261.3978510299555
        },
        "llama-4-scout-17b-16e-instruct": {
            "rating": 1265.0219877299355,
            "rating_q975": 1272.7569322663194,
            "rating_q025": 1257.2870431935514
        },
        "gemini-1.5-pro-001": {
            "rating": 1264.8334049124092,
            "rating_q975": 1270.865963918274,
            "rating_q025": 1258.8008459065443
        },
        "gpt-4.1-nano-2025-04-14": {
            "rating": 1264.7620310781854,
            "rating_q975": 1277.1055566786536,
            "rating_q025": 1252.4185054777172
        },
        "llama-3.3-70b-instruct": {
            "rating": 1263.684934182425,
            "rating_q975": 1268.8305953789045,
            "rating_q025": 1258.5392729859454
        },
        "amazon-nova-experimental-chat-05-14": {
            "rating": 1263.463678060879,
            "rating_q975": 1271.1148917956996,
            "rating_q025": 1255.8124643260583
        },
        "claude-3-5-haiku-20241022": {
            "rating": 1263.0132187898816,
            "rating_q975": 1268.0242659711546,
            "rating_q025": 1258.0021716086087
        },
        "claude-3-opus-20240229": {
            "rating": 1262.3528999715738,
            "rating_q975": 1266.8496089734356,
            "rating_q025": 1257.856190969712
        },
        "glm-4-plus": {
            "rating": 1261.7997865972447,
            "rating_q975": 1269.3328609994605,
            "rating_q025": 1254.2667121950287
        },
        "gemma-3n-e4b-it": {
            "rating": 1260.625667392309,
            "rating_q975": 1268.4099560015147,
            "rating_q025": 1252.841378783103
        },
        "gpt-4o-mini-2024-07-18": {
            "rating": 1258.804971016713,
            "rating_q975": 1263.875537824055,
            "rating_q025": 1253.7344042093707
        },
        "qwen2.5-plus-1127": {
            "rating": 1257.2040866608386,
            "rating_q975": 1267.2683323234135,
            "rating_q025": 1247.1398409982637
        },
        "qwen-max-0919": {
            "rating": 1256.3066113884702,
            "rating_q975": 1264.7866659985607,
            "rating_q025": 1247.8265567783792
        },
        "athene-v2-chat": {
            "rating": 1255.3640310557244,
            "rating_q975": 1262.3154700670987,
            "rating_q025": 1248.41259204435
        },
        "mistral-large-2407": {
            "rating": 1253.610171761273,
            "rating_q975": 1259.536492399579,
            "rating_q025": 1247.683851122967
        },
        "hunyuan-standard-2025-02-10": {
            "rating": 1250.711472722055,
            "rating_q975": 1265.9802419684997,
            "rating_q025": 1235.4427034756104
        },
        "gemini-1.5-flash-002": {
            "rating": 1248.8729873641946,
            "rating_q975": 1255.2260866971565,
            "rating_q025": 1242.519888031233
        },
        "gpt-4-1106-preview": {
            "rating": 1246.5510733791368,
            "rating_q975": 1252.2968054225303,
            "rating_q025": 1240.8053413357434
        },
        "gpt-4-0125-preview": {
            "rating": 1245.9870254940688,
            "rating_q975": 1251.9644143279381,
            "rating_q025": 1240.0096366601995
        },
        "grok-2-mini-2024-08-13": {
            "rating": 1244.9978420435027,
            "rating_q975": 1250.5852985274028,
            "rating_q025": 1239.4103855596024
        },
        "magistral-medium-2506": {
            "rating": 1243.8399844059572,
            "rating_q975": 1253.7881999201,
            "rating_q025": 1233.8917688918143
        },
        "athene-70b-0725": {
            "rating": 1242.4205277108395,
            "rating_q975": 1251.080512295922,
            "rating_q025": 1233.7605431257566
        },
        "deepseek-v2.5": {
            "rating": 1242.3336454522807,
            "rating_q975": 1249.7002525364937,
            "rating_q025": 1234.9670383680675
        },
        "qwen2.5-72b-instruct": {
            "rating": 1236.2307924125457,
            "rating_q975": 1242.4572153951124,
            "rating_q025": 1230.0043694299793
        },
        "mistral-large-2411": {
            "rating": 1235.5853928749661,
            "rating_q975": 1242.3155549905412,
            "rating_q025": 1228.8552307593907
        },
        "hunyuan-large-vision": {
            "rating": 1235.5643467523469,
            "rating_q975": 1248.000533407997,
            "rating_q025": 1223.1281600966968
        },
        "mistral-small-3.1-24b-instruct-2503": {
            "rating": 1234.1681877697324,
            "rating_q975": 1242.015777942522,
            "rating_q025": 1226.320597596943
        },
        "gemma-3-4b-it": {
            "rating": 1233.1940323642339,
            "rating_q975": 1247.2636207663556,
            "rating_q025": 1219.124443962112
        },
        "llama-3.1-nemotron-70b-instruct": {
            "rating": 1229.3431070237875,
            "rating_q975": 1240.7589295033822,
            "rating_q025": 1217.9272845441928
        },
        "llama-3.1-70b-instruct": {
            "rating": 1222.1983889603644,
            "rating_q975": 1227.8749139152292,
            "rating_q025": 1216.5218640054995
        },
        "llama-3.1-tulu-3-70b": {
            "rating": 1213.6752429777353,
            "rating_q975": 1231.2111040419493,
            "rating_q025": 1196.1393819135214
        },
        "jamba-1.5-large": {
            "rating": 1212.0702502367437,
            "rating_q975": 1223.2620804117664,
            "rating_q025": 1200.878420061721
        },
        "amazon-nova-pro-v1.0": {
            "rating": 1211.9212061124954,
            "rating_q975": 1218.9718308728109,
            "rating_q025": 1204.87058135218
        },
        "reka-core-20240904": {
            "rating": 1210.561017709842,
            "rating_q975": 1222.1718077511912,
            "rating_q025": 1198.950227668493
        },
        "gemma-2-27b-it": {
            "rating": 1207.906551948313,
            "rating_q975": 1212.8761523879866,
            "rating_q025": 1202.9369515086398
        },
        "gemini-1.5-flash-001": {
            "rating": 1206.1311437097024,
            "rating_q975": 1212.7141522104566,
            "rating_q025": 1199.548135208948
        },
        "llama-3.1-nemotron-51b-instruct": {
            "rating": 1204.662395034116,
            "rating_q975": 1220.6638910182007,
            "rating_q025": 1188.6608990500308
        },
        "gpt-4-0314": {
            "rating": 1201.7804867368088,
            "rating_q975": 1208.7331109340225,
            "rating_q025": 1194.8278625395951
        },
        "claude-3-sonnet-20240229": {
            "rating": 1200.820562311031,
            "rating_q975": 1206.5140624744654,
            "rating_q025": 1195.1270621475965
        },
        "nemotron-4-340b-instruct": {
            "rating": 1198.3232439782155,
            "rating_q975": 1206.5617144933142,
            "rating_q025": 1190.0847734631168
        },
        "gemma-2-9b-it-simpo": {
            "rating": 1196.039791797945,
            "rating_q975": 1206.6543241780462,
            "rating_q025": 1185.425259417844
        },
        "glm-4-0520": {
            "rating": 1192.7035422362783,
            "rating_q975": 1203.5430253886877,
            "rating_q025": 1181.8640590838686
        },
        "llama-3-70b-instruct": {
            "rating": 1192.5362384549603,
            "rating_q975": 1197.886013207411,
            "rating_q025": 1187.1864637025099
        },
        "command-r-plus-08-2024": {
            "rating": 1190.6358375759805,
            "rating_q975": 1200.8974039323318,
            "rating_q025": 1180.3742712196295
        },
        "gpt-4-0613": {
            "rating": 1187.5680255275847,
            "rating_q975": 1193.3864329992657,
            "rating_q025": 1181.7496180559037
        },
        "mistral-small-24b-instruct-2501": {
            "rating": 1187.562892248508,
            "rating_q975": 1196.852287659001,
            "rating_q025": 1178.2734968380148
        },
        "qwen2.5-coder-32b-instruct": {
            "rating": 1182.9065479292522,
            "rating_q975": 1196.3050176452184,
            "rating_q025": 1169.5080782132861
        },
        "reka-flash-20240904": {
            "rating": 1181.2966566536888,
            "rating_q975": 1193.2272497477122,
            "rating_q025": 1169.3660635596652
        },
        "deepseek-coder-v2": {
            "rating": 1176.0130628146285,
            "rating_q975": 1185.2502759727902,
            "rating_q025": 1166.7758496564666
        },
        "c4ai-aya-expanse-32b": {
            "rating": 1175.7195028744406,
            "rating_q975": 1183.4256787887887,
            "rating_q025": 1168.0133269600926
        },
        "command-r-plus": {
            "rating": 1174.2158995321533,
            "rating_q975": 1180.406796452841,
            "rating_q025": 1168.0250026114654
        },
        "qwen2-72b-instruct": {
            "rating": 1172.8896587345353,
            "rating_q975": 1180.128604977226,
            "rating_q025": 1165.6507124918444
        },
        "claude-3-haiku-20240307": {
            "rating": 1171.4366830497856,
            "rating_q975": 1177.0813171117818,
            "rating_q025": 1165.7920489877893
        },
        "gemma-2-9b-it": {
            "rating": 1170.4580506982688,
            "rating_q975": 1176.1579222169275,
            "rating_q025": 1164.75817917961
        },
        "gemini-1.5-flash-8b-001": {
            "rating": 1165.554354971337,
            "rating_q975": 1172.1782817413894,
            "rating_q025": 1158.9304282012847
        },
        "amazon-nova-lite-v1.0": {
            "rating": 1165.1315493124043,
            "rating_q975": 1173.261436804187,
            "rating_q025": 1157.0016618206216
        },
        "olmo-2-0325-32b-instruct": {
            "rating": 1157.5489007273932,
            "rating_q975": 1174.7381600648862,
            "rating_q025": 1140.3596413899004
        },
        "phi-4": {
            "rating": 1157.0433059496886,
            "rating_q975": 1164.7218740611065,
            "rating_q025": 1149.3647378382705
        },
        "command-r-08-2024": {
            "rating": 1146.9819202279355,
            "rating_q975": 1157.5638331216153,
            "rating_q025": 1136.4000073342559
        },
        "mistral-large-2402": {
            "rating": 1142.2125172234448,
            "rating_q975": 1149.0064771911407,
            "rating_q025": 1135.418557255749
        },
        "reka-flash-21b-20240226-online": {
            "rating": 1132.169792956668,
            "rating_q975": 1143.1496378659579,
            "rating_q025": 1121.1899480473783
        },
        "amazon-nova-micro-v1.0": {
            "rating": 1131.4468308050225,
            "rating_q975": 1139.7344638953316,
            "rating_q025": 1123.1591977147134
        },
        "qwen1.5-110b-chat": {
            "rating": 1131.0415548331484,
            "rating_q975": 1139.565081491013,
            "rating_q025": 1122.5180281752841
        },
        "jamba-1.5-mini": {
            "rating": 1129.9658833303533,
            "rating_q975": 1141.7025155584479,
            "rating_q025": 1118.2292511022588
        },
        "qwen1.5-72b-chat": {
            "rating": 1129.5778003158448,
            "rating_q975": 1137.447156545057,
            "rating_q025": 1121.7084440866324
        },
        "gemini-pro-dev-api": {
            "rating": 1127.0135416420658,
            "rating_q975": 1137.7099541638572,
            "rating_q025": 1116.3171291202743
        },
        "ministral-8b-2410": {
            "rating": 1125.2222903143922,
            "rating_q975": 1140.2156703808478,
            "rating_q025": 1110.2289102479367
        },
        "hunyuan-standard-256k": {
            "rating": 1124.6270299794987,
            "rating_q975": 1143.216987896328,
            "rating_q025": 1106.0370720626697
        },
        "mixtral-8x22b-instruct-v0.1": {
            "rating": 1122.41664837854,
            "rating_q975": 1129.3055737828984,
            "rating_q025": 1115.5277229741816
        },
        "reka-flash-21b-20240226": {
            "rating": 1121.2523820608621,
            "rating_q975": 1130.456350354567,
            "rating_q025": 1112.0484137671576
        },
        "command-r": {
            "rating": 1119.8827349179987,
            "rating_q975": 1126.928506770881,
            "rating_q025": 1112.8369630651164
        },
        "mistral-medium": {
            "rating": 1114.6403445300866,
            "rating_q975": 1122.612893897882,
            "rating_q025": 1106.6677951622912
        },
        "gpt-3.5-turbo-0125": {
            "rating": 1112.0451005664186,
            "rating_q975": 1118.8086561256928,
            "rating_q025": 1105.2815450071446
        },
        "llama-3-8b-instruct": {
            "rating": 1110.7590168022393,
            "rating_q975": 1116.5756158645884,
            "rating_q025": 1104.9424177398905
        },
        "c4ai-aya-expanse-8b": {
            "rating": 1108.1813507822653,
            "rating_q975": 1119.7131999618086,
            "rating_q025": 1096.649501602722
        },
        "gemini-pro": {
            "rating": 1103.6094077074226,
            "rating_q975": 1120.3440767119073,
            "rating_q025": 1086.874738702938
        },
        "llama-3.1-tulu-3-8b": {
            "rating": 1101.319645227617,
            "rating_q975": 1120.5324963635674,
            "rating_q025": 1082.1067940916664
        },
        "zephyr-orpo-141b-A35b-v0.1": {
            "rating": 1100.4704959215642,
            "rating_q975": 1116.1920201420253,
            "rating_q025": 1084.7489717011035
        },
        "yi-1.5-34b-chat": {
            "rating": 1099.7745406151512,
            "rating_q975": 1107.9305577135906,
            "rating_q025": 1091.6185235167115
        },
        "llama-3.1-8b-instruct": {
            "rating": 1088.6107040178836,
            "rating_q975": 1095.0794761398363,
            "rating_q025": 1082.1419318959308
        },
        "qwen1.5-32b-chat": {
            "rating": 1087.9785510043885,
            "rating_q975": 1097.3292961962704,
            "rating_q025": 1078.627805812506
        },
        "gpt-3.5-turbo-1106": {
            "rating": 1079.8062486603972,
            "rating_q975": 1092.0811634328256,
            "rating_q025": 1067.5313338879687
        },
        "granite-3.1-8b-instruct": {
            "rating": 1076.2302030723893,
            "rating_q975": 1095.9903384268446,
            "rating_q025": 1056.470067717934
        },
        "mixtral-8x7b-instruct-v0.1": {
            "rating": 1073.2763803031296,
            "rating_q975": 1079.664007531985,
            "rating_q025": 1066.8887530742743
        },
        "dbrx-instruct-preview": {
            "rating": 1070.0541845612474,
            "rating_q975": 1079.2836179891697,
            "rating_q025": 1060.8247511333254
        },
        "qwen1.5-14b-chat": {
            "rating": 1069.1015390592368,
            "rating_q975": 1079.994139222806,
            "rating_q025": 1058.2089388956674
        },
        "phi-3-medium-4k-instruct": {
            "rating": 1066.120401658076,
            "rating_q975": 1074.5836454919254,
            "rating_q025": 1057.6571578242263
        },
        "gemma-2-2b-it": {
            "rating": 1061.7776196768,
            "rating_q975": 1068.3618377004732,
            "rating_q025": 1055.193401653127
        },
        "wizardlm-70b": {
            "rating": 1060.3693364025337,
            "rating_q975": 1073.5803738525274,
            "rating_q025": 1047.15829895254
        },
        "internlm2_5-20b-chat": {
            "rating": 1058.7919929230284,
            "rating_q975": 1070.9680168851312,
            "rating_q025": 1046.6159689609256
        },
        "deepseek-llm-67b-chat": {
            "rating": 1056.3842397357714,
            "rating_q975": 1073.1351323429535,
            "rating_q025": 1039.6333471285893
        },
        "yi-34b-chat": {
            "rating": 1054.1739644200106,
            "rating_q975": 1064.1570850813248,
            "rating_q025": 1044.1908437586962
        },
        "openchat-3.5-0106": {
            "rating": 1054.0912946197493,
            "rating_q975": 1065.7493154597594,
            "rating_q025": 1042.4332737797392
        },
        "openchat-3.5": {
            "rating": 1049.944469120517,
            "rating_q975": 1063.9470324783053,
            "rating_q025": 1035.9419057627285
        },
        "tulu-2-dpo-70b": {
            "rating": 1046.821354257056,
            "rating_q975": 1060.8710516364486,
            "rating_q025": 1032.7716568776636
        },
        "starling-lm-7b-beta": {
            "rating": 1043.0687719941077,
            "rating_q975": 1053.9525867339098,
            "rating_q025": 1032.1849572543053
        },
        "openhermes-2.5-mistral-7b": {
            "rating": 1042.3141712462284,
            "rating_q975": 1057.5636409257352,
            "rating_q025": 1027.0647015667216
        },
        "vicuna-33b": {
            "rating": 1042.0715636734844,
            "rating_q975": 1051.2612284810339,
            "rating_q025": 1032.8818988659348
        },
        "snowflake-arctic-instruct": {
            "rating": 1041.8104601931068,
            "rating_q975": 1051.301666106786,
            "rating_q025": 1032.3192542794272
        },
        "gemma-1.1-7b-it": {
            "rating": 1037.8820067965914,
            "rating_q975": 1046.8886403238187,
            "rating_q025": 1028.8753732693644
        },
        "granite-3.0-8b-instruct": {
            "rating": 1034.8769695337364,
            "rating_q975": 1050.9086682903796,
            "rating_q025": 1018.8452707770931
        },
        "llama-2-70b-chat": {
            "rating": 1034.8593733768662,
            "rating_q975": 1042.8944479901907,
            "rating_q025": 1026.824298763542
        },
        "starling-lm-7b-alpha": {
            "rating": 1031.0334545442947,
            "rating_q975": 1042.8549481480795,
            "rating_q025": 1019.21196094051
        },
        "nous-hermes-2-mixtral-8x7b-dpo": {
            "rating": 1028.667235475399,
            "rating_q975": 1045.8223029507803,
            "rating_q025": 1011.5121680000175
        },
        "phi-3-small-8k-instruct": {
            "rating": 1024.6025411826877,
            "rating_q975": 1034.9389566534828,
            "rating_q025": 1014.2661257118925
        },
        "qwq-32b-preview": {
            "rating": 1020.9403296631516,
            "rating_q975": 1039.3551860378652,
            "rating_q025": 1002.525473288438
        },
        "granite-3.1-2b-instruct": {
            "rating": 1019.3077364324953,
            "rating_q975": 1040.522710814637,
            "rating_q025": 998.0927620503535
        },
        "llama2-70b-steerlm-chat": {
            "rating": 1015.6747425725166,
            "rating_q975": 1033.3118552894484,
            "rating_q025": 998.0376298555846
        },
        "mpt-30b-chat": {
            "rating": 1014.9502278010797,
            "rating_q975": 1033.053286452256,
            "rating_q025": 996.8471691499032
        },
        "wizardlm-13b": {
            "rating": 1010.5017858862997,
            "rating_q975": 1023.8802778639127,
            "rating_q025": 997.1232939086866
        },
        "llama-3.2-3b-instruct": {
            "rating": 1009.6061219911724,
            "rating_q975": 1023.1837678851355,
            "rating_q025": 996.0284760972091
        },
        "solar-10.7b-instruct-v1.0": {
            "rating": 1009.5930373040077,
            "rating_q975": 1028.7026832844583,
            "rating_q025": 990.4833913235569
        },
        "dolphin-2.2.1-mistral-7b": {
            "rating": 1009.2275078283429,
            "rating_q975": 1031.6928108879436,
            "rating_q025": 986.7622047687422
        },
        "mistral-7b-instruct-v0.2": {
            "rating": 1002.3869064941459,
            "rating_q975": 1012.4664041999138,
            "rating_q025": 992.3074087883781
        },
        "falcon-180b-chat": {
            "rating": 1001.7568383888743,
            "rating_q975": 1025.7096585530967,
            "rating_q025": 977.8040182246517
        },
        "qwen1.5-7b-chat": {
            "rating": 995.0232273964792,
            "rating_q975": 1010.4718547768515,
            "rating_q025": 979.5746000161068
        },
        "llama-2-13b-chat": {
            "rating": 991.8888963467363,
            "rating_q975": 1001.8316131947431,
            "rating_q025": 981.9461794987294
        },
        "qwen-14b-chat": {
            "rating": 991.0886926983756,
            "rating_q975": 1006.8692257910859,
            "rating_q025": 975.3081596056654
        },
        "vicuna-13b": {
            "rating": 989.146666833642,
            "rating_q975": 999.1719611583667,
            "rating_q025": 979.1213725089174
        },
        "palm-2": {
            "rating": 986.596512100095,
            "rating_q975": 999.7323787961227,
            "rating_q025": 973.4606454040672
        },
        "codellama-34b-instruct": {
            "rating": 984.8706149305988,
            "rating_q975": 997.7550047012058,
            "rating_q025": 971.9862251599916
        },
        "granite-3.0-2b-instruct": {
            "rating": 983.5933191524256,
            "rating_q975": 1000.5976420068854,
            "rating_q025": 966.5889962979657
        },
        "guanaco-33b": {
            "rating": 977.5420656430523,
            "rating_q975": 995.6025755011719,
            "rating_q025": 959.4815557849327
        },
        "zephyr-7b-beta": {
            "rating": 976.8709144101124,
            "rating_q975": 989.4137768563141,
            "rating_q025": 964.3280519639106
        },
        "zephyr-7b-alpha": {
            "rating": 976.034942597684,
            "rating_q975": 998.5774940042502,
            "rating_q025": 953.4923911911179
        },
        "gemma-7b-it": {
            "rating": 973.4006735728651,
            "rating_q975": 987.6445908967976,
            "rating_q025": 959.1567562489327
        },
        "phi-3-mini-4k-instruct-june-2024": {
            "rating": 965.1690095164173,
            "rating_q975": 977.386202910166,
            "rating_q025": 952.9518161226686
        },
        "vicuna-7b": {
            "rating": 962.0052121408731,
            "rating_q975": 975.3725262819896,
            "rating_q025": 948.6378979997567
        },
        "phi-3-mini-128k-instruct": {
            "rating": 961.2764427230036,
            "rating_q975": 974.1500013746985,
            "rating_q025": 948.4028840713087
        },
        "codellama-70b-instruct": {
            "rating": 959.5863069571769,
            "rating_q975": 987.5690483092437,
            "rating_q025": 931.6035656051101
        },
        "stripedhyena-nous-7b": {
            "rating": 958.533408267386,
            "rating_q975": 975.1720764180805,
            "rating_q025": 941.8947401166914
        },
        "phi-3-mini-4k-instruct": {
            "rating": 952.3844700471714,
            "rating_q975": 963.7446481285097,
            "rating_q025": 941.0242919658331
        },
        "mistral-7b-instruct": {
            "rating": 942.8476524383311,
            "rating_q975": 956.5569585771887,
            "rating_q025": 929.1383462994736
        },
        "llama-2-7b-chat": {
            "rating": 939.9819858552956,
            "rating_q975": 950.4093498572909,
            "rating_q025": 929.5546218533004
        },
        "gemma-1.1-2b-it": {
            "rating": 923.6918317353311,
            "rating_q975": 937.1634278201082,
            "rating_q025": 910.2202356505543
        },
        "smollm2-1.7b-instruct": {
            "rating": 909.4372630606377,
            "rating_q975": 940.8151055697094,
            "rating_q025": 878.0594205515661
        },
        "llama-3.2-1b-instruct": {
            "rating": 902.7356915855798,
            "rating_q975": 918.5777059049329,
            "rating_q025": 886.8936772662269
        },
        "gemma-2b-it": {
            "rating": 901.9630765134042,
            "rating_q975": 920.0736447412951,
            "rating_q025": 883.8525082855133
        },
        "qwen1.5-4b-chat": {
            "rating": 898.15929014445,
            "rating_q975": 914.0502370579795,
            "rating_q025": 882.2683432309204
        },
        "koala-13b": {
            "rating": 897.9091576380079,
            "rating_q975": 913.364692739877,
            "rating_q025": 882.4536225361387
        },
        "alpaca-13b": {
            "rating": 887.5215693168843,
            "rating_q975": 904.621042172126,
            "rating_q025": 870.4220964616427
        },
        "olmo-7b-instruct": {
            "rating": 886.8690906153142,
            "rating_q975": 904.4801927762746,
            "rating_q025": 869.257988454354
        },
        "gpt4all-13b-snoozy": {
            "rating": 884.9089138390807,
            "rating_q975": 908.8006068581794,
            "rating_q025": 861.017220819982
        },
        "mpt-7b-chat": {
            "rating": 879.692642746023,
            "rating_q975": 898.0296138771287,
            "rating_q025": 861.3556716149174
        },
        "chatglm3-6b": {
            "rating": 862.7670557314112,
            "rating_q975": 881.0912764498526,
            "rating_q025": 844.4428350129699
        },
        "RWKV-4-Raven-14B": {
            "rating": 852.7824237974496,
            "rating_q975": 870.2389655097625,
            "rating_q025": 835.3258820851368
        },
        "oasst-pythia-12b": {
            "rating": 823.4770725246369,
            "rating_q975": 840.1180722468545,
            "rating_q025": 806.8360728024193
        },
        "chatglm2-6b": {
            "rating": 808.4503988383882,
            "rating_q975": 830.2937476405064,
            "rating_q025": 786.60705003627
        },
        "chatglm-6b": {
            "rating": 769.8134716999984,
            "rating_q975": 789.4783616483493,
            "rating_q025": 750.1485817516475
        },
        "fastchat-t5-3b": {
            "rating": 769.5094737587492,
            "rating_q975": 788.8118062116084,
            "rating_q025": 750.2071413058899
        },
        "dolly-v2-12b": {
            "rating": 749.0406861870607,
            "rating_q975": 771.1987099392898,
            "rating_q025": 726.8826624348317
        },
        "llama-13b": {
            "rating": 723.0696473693424,
            "rating_q975": 749.1420447423943,
            "rating_q025": 696.9972499962904
        },
        "stablelm-tuned-alpha-7b": {
            "rating": 702.752721440414,
            "rating_q975": 724.2678605539435,
            "rating_q025": 681.2375823268844
        }
    },
    "russian": {
        "gemini-2.5-pro": {
            "rating": 1478.530746823546,
            "rating_q975": 1492.411553049478,
            "rating_q025": 1464.6499405976142
        },
        "claude-opus-4-1-20250805": {
            "rating": 1448.5768417095435,
            "rating_q975": 1472.118210339378,
            "rating_q025": 1425.0354730797087
        },
        "grok-4-0709": {
            "rating": 1443.95185914575,
            "rating_q975": 1462.6781034166897,
            "rating_q025": 1425.2256148748102
        },
        "gpt-4.5-preview-2025-02-27": {
            "rating": 1441.7064655984643,
            "rating_q975": 1456.2357378698298,
            "rating_q025": 1427.1771933270988
        },
        "chatgpt-4o-latest-20250326": {
            "rating": 1440.31469400645,
            "rating_q975": 1452.0071936305399,
            "rating_q025": 1428.6221943823602
        },
        "gpt-5-high": {
            "rating": 1437.8663890269208,
            "rating_q975": 1464.4969374192362,
            "rating_q025": 1411.2358406346057
        },
        "o3-2025-04-16": {
            "rating": 1437.3094856818536,
            "rating_q975": 1448.8408552573708,
            "rating_q025": 1425.7781161063363
        },
        "claude-opus-4-20250514-thinking-16k": {
            "rating": 1436.8926042900296,
            "rating_q975": 1453.19948269085,
            "rating_q025": 1420.585725889209
        },
        "claude-opus-4-1-20250805-thinking-16k": {
            "rating": 1428.207684742976,
            "rating_q975": 1456.231599935225,
            "rating_q025": 1400.183769550727
        },
        "qwen-max-2025-08-15": {
            "rating": 1426.2862625259352,
            "rating_q975": 1467.3996538321308,
            "rating_q025": 1385.1728712197396
        },
        "kimi-k2-0711-preview": {
            "rating": 1425.1900828138007,
            "rating_q975": 1443.6473572651882,
            "rating_q025": 1406.732808362413
        },
        "gpt-5-chat": {
            "rating": 1422.6383951897267,
            "rating_q975": 1450.8476193391825,
            "rating_q025": 1394.429171040271
        },
        "claude-opus-4-20250514": {
            "rating": 1421.667051125034,
            "rating_q975": 1434.7076615252508,
            "rating_q025": 1408.626440724817
        },
        "gemini-2.5-flash": {
            "rating": 1419.5271545365943,
            "rating_q975": 1431.52902690289,
            "rating_q025": 1407.5252821702982
        },
        "glm-4.5": {
            "rating": 1417.2052295320705,
            "rating_q975": 1443.3158227259826,
            "rating_q025": 1391.0946363381584
        },
        "qwen3-235b-a22b-instruct-2507": {
            "rating": 1415.615007849422,
            "rating_q975": 1437.491183565981,
            "rating_q025": 1393.738832132863
        },
        "claude-sonnet-4-20250514-thinking-32k": {
            "rating": 1412.9423017231934,
            "rating_q975": 1429.7479328533311,
            "rating_q025": 1396.1366705930554
        },
        "grok-3-preview-02-24": {
            "rating": 1410.0800349656486,
            "rating_q975": 1421.2519351409494,
            "rating_q025": 1398.9081347903475
        },
        "deepseek-r1-0528": {
            "rating": 1409.1054623028735,
            "rating_q975": 1424.7176975784807,
            "rating_q025": 1393.4932270272661
        },
        "mistral-medium-2508": {
            "rating": 1408.4923452304722,
            "rating_q975": 1442.9882400283566,
            "rating_q025": 1373.9964504325876
        },
        "qwen3-235b-a22b-thinking-2507": {
            "rating": 1408.2821144399848,
            "rating_q975": 1436.7603241644524,
            "rating_q025": 1379.8039047155169
        },
        "gpt-4.1-2025-04-14": {
            "rating": 1406.409670374733,
            "rating_q975": 1419.1725648716288,
            "rating_q025": 1393.6467758778374
        },
        "qwen3-235b-a22b-no-thinking": {
            "rating": 1405.8125024525827,
            "rating_q975": 1419.6088051565116,
            "rating_q025": 1392.016199748654
        },
        "deepseek-v3-0324": {
            "rating": 1401.3532255952282,
            "rating_q975": 1412.9661413089343,
            "rating_q025": 1389.740309881522
        },
        "claude-sonnet-4-20250514": {
            "rating": 1392.6174563133025,
            "rating_q975": 1406.16183181681,
            "rating_q025": 1379.0730808097949
        },
        "hunyuan-t1-20250711": {
            "rating": 1386.5281885122665,
            "rating_q975": 1418.7765447932427,
            "rating_q025": 1354.2798322312904
        },
        "o1-2024-12-17": {
            "rating": 1385.1782662662824,
            "rating_q975": 1394.828339638836,
            "rating_q025": 1375.528192893729
        },
        "hunyuan-turbos-20250416": {
            "rating": 1378.2760722539795,
            "rating_q975": 1396.0087257534535,
            "rating_q025": 1360.5434187545052
        },
        "deepseek-r1": {
            "rating": 1378.264472295297,
            "rating_q975": 1390.2960067680008,
            "rating_q025": 1366.2329378225932
        },
        "qwen3-coder-480b-a35b-instruct": {
            "rating": 1377.7017798819486,
            "rating_q975": 1403.0301530351953,
            "rating_q025": 1352.3734067287016
        },
        "mistral-medium-2505": {
            "rating": 1376.4580401884457,
            "rating_q975": 1388.6866440063195,
            "rating_q025": 1364.2294363705719
        },
        "o4-mini-2025-04-16": {
            "rating": 1376.3518737927266,
            "rating_q975": 1389.2114634090765,
            "rating_q025": 1363.4922841763769
        },
        "gemma-3-27b-it": {
            "rating": 1374.6857714470461,
            "rating_q975": 1386.2658691726656,
            "rating_q025": 1363.105673721427
        },
        "claude-3-7-sonnet-20250219": {
            "rating": 1372.8993590693083,
            "rating_q975": 1383.1651646952093,
            "rating_q025": 1362.6335534434074
        },
        "claude-3-7-sonnet-20250219-thinking-32k": {
            "rating": 1372.8039029677732,
            "rating_q975": 1383.7102714575249,
            "rating_q025": 1361.8975344780213
        },
        "claude-3-5-sonnet-20241022": {
            "rating": 1371.6577936237786,
            "rating_q975": 1377.7961875514757,
            "rating_q025": 1365.5193996960818
        },
        "glm-4.5-air": {
            "rating": 1371.548797218673,
            "rating_q975": 1397.1359771385273,
            "rating_q025": 1345.9616172988183
        },
        "qwen2.5-max": {
            "rating": 1365.843722829017,
            "rating_q975": 1375.84267416514,
            "rating_q025": 1355.844771492894
        },
        "gemini-2.0-flash-001": {
            "rating": 1364.5931624672724,
            "rating_q975": 1374.2875893407347,
            "rating_q025": 1354.8987355938098
        },
        "gpt-5-mini-high": {
            "rating": 1360.8535347976197,
            "rating_q975": 1391.7399885883697,
            "rating_q025": 1329.9670810068696
        },
        "gemma-3-12b-it": {
            "rating": 1360.7798567590357,
            "rating_q975": 1391.6677204467678,
            "rating_q025": 1329.8919930713037
        },
        "qwen3-30b-a3b-instruct-2507": {
            "rating": 1360.5699135877676,
            "rating_q975": 1388.9231251129927,
            "rating_q025": 1332.2167020625425
        },
        "o1-preview": {
            "rating": 1359.0509611542159,
            "rating_q975": 1367.58598356817,
            "rating_q025": 1350.515938740262
        },
        "gpt-4.1-mini-2025-04-14": {
            "rating": 1357.1098866440261,
            "rating_q975": 1370.217462709961,
            "rating_q025": 1344.0023105780913
        },
        "mistral-small-2506": {
            "rating": 1355.1244562361014,
            "rating_q975": 1375.8123593456091,
            "rating_q025": 1334.4365531265937
        },
        "qwen3-235b-a22b": {
            "rating": 1354.479596352356,
            "rating_q975": 1368.18685271096,
            "rating_q025": 1340.7723399937524
        },
        "deepseek-v3": {
            "rating": 1354.2066394959554,
            "rating_q975": 1364.7984042774967,
            "rating_q025": 1343.614874714414
        },
        "gemini-2.0-flash-lite-preview-02-05": {
            "rating": 1352.8814738588524,
            "rating_q975": 1363.7101414098358,
            "rating_q025": 1342.052806307869
        },
        "qwen-plus-0125": {
            "rating": 1352.339530851698,
            "rating_q975": 1372.6951551607535,
            "rating_q025": 1331.9839065426424
        },
        "gemini-1.5-pro-002": {
            "rating": 1351.0574094679316,
            "rating_q975": 1357.6493391925276,
            "rating_q025": 1344.465479743336
        },
        "grok-3-mini-beta": {
            "rating": 1350.8311464717285,
            "rating_q975": 1367.2730345167495,
            "rating_q025": 1334.3892584267078
        },
        "minimax-m1": {
            "rating": 1350.577393585391,
            "rating_q975": 1367.4610323664865,
            "rating_q025": 1333.6937548042958
        },
        "grok-3-mini-high": {
            "rating": 1350.3898524130552,
            "rating_q975": 1370.7240668010484,
            "rating_q025": 1330.055638025062
        },
        "claude-3-5-sonnet-20240620": {
            "rating": 1344.3547979125165,
            "rating_q975": 1351.3656087179222,
            "rating_q025": 1337.3439871071107
        },
        "hunyuan-turbos-20250226": {
            "rating": 1342.7839558995797,
            "rating_q975": 1375.1894101767632,
            "rating_q025": 1310.3785016223962
        },
        "step-2-16k-exp-202412": {
            "rating": 1341.6440465315663,
            "rating_q975": 1362.2334016870332,
            "rating_q025": 1321.0546913760995
        },
        "nvidia-llama-3.3-nemotron-super-49b-v1.5": {
            "rating": 1340.1586923336426,
            "rating_q975": 1377.5582366920692,
            "rating_q025": 1302.759147975216
        },
        "claude-3-opus-20240229": {
            "rating": 1336.1826987050576,
            "rating_q975": 1341.9701771772127,
            "rating_q025": 1330.3952202329026
        },
        "gpt-oss-120b": {
            "rating": 1335.1643691983356,
            "rating_q975": 1364.585884967214,
            "rating_q025": 1305.7428534294575
        },
        "command-a-03-2025": {
            "rating": 1335.1432363499953,
            "rating_q975": 1346.2774881085068,
            "rating_q025": 1324.0089845914836
        },
        "step-1o-turbo-202506": {
            "rating": 1333.6370088650701,
            "rating_q975": 1356.7192758777976,
            "rating_q025": 1310.5547418523422
        },
        "hunyuan-turbo-0110": {
            "rating": 1333.0089051100394,
            "rating_q975": 1363.9970697723968,
            "rating_q025": 1302.0207404476816
        },
        "gemini-advanced-0514": {
            "rating": 1332.5825587397953,
            "rating_q975": 1342.0898785219038,
            "rating_q025": 1323.0752389576871
        },
        "o3-mini-high": {
            "rating": 1332.4574589133563,
            "rating_q975": 1345.0159332645787,
            "rating_q025": 1319.8989845621338
        },
        "gpt-4o-2024-05-13": {
            "rating": 1332.3782506392677,
            "rating_q975": 1338.6408711176528,
            "rating_q025": 1326.1156301608823
        },
        "llama-4-maverick-17b-128e-instruct": {
            "rating": 1332.1842991479575,
            "rating_q975": 1344.6320156688325,
            "rating_q025": 1319.7365826270823
        },
        "glm-4-plus-0111": {
            "rating": 1330.7192240290651,
            "rating_q975": 1351.1389443405646,
            "rating_q025": 1310.2995037175658
        },
        "o3-mini": {
            "rating": 1327.5168111863745,
            "rating_q975": 1336.558058853583,
            "rating_q025": 1318.4755635191664
        },
        "gemini-1.5-pro-001": {
            "rating": 1326.4413264501445,
            "rating_q975": 1334.10661071001,
            "rating_q025": 1318.776042190279
        },
        "grok-2-2024-08-13": {
            "rating": 1325.036903802426,
            "rating_q975": 1331.561371028439,
            "rating_q025": 1318.5124365764127
        },
        "qwen3-32b": {
            "rating": 1324.9826765437226,
            "rating_q975": 1350.1484856237162,
            "rating_q025": 1299.816867463729
        },
        "amazon-nova-experimental-chat-05-14": {
            "rating": 1324.8431575138507,
            "rating_q975": 1341.2287528936627,
            "rating_q025": 1308.4575621340387
        },
        "gpt-4o-2024-08-06": {
            "rating": 1324.2026920213902,
            "rating_q975": 1331.7910174930837,
            "rating_q025": 1316.614366549697
        },
        "deepseek-v2.5-1210": {
            "rating": 1322.684239089134,
            "rating_q975": 1338.585833498044,
            "rating_q025": 1306.7826446802242
        },
        "llama-3.1-405b-instruct-fp8": {
            "rating": 1318.7653915560031,
            "rating_q975": 1325.5700017414285,
            "rating_q025": 1311.9607813705775
        },
        "gpt-4-turbo-2024-04-09": {
            "rating": 1315.5539890905548,
            "rating_q975": 1322.7340921658356,
            "rating_q025": 1308.3738860152737
        },
        "gemma-3n-e4b-it": {
            "rating": 1315.2870953156244,
            "rating_q975": 1332.2317150700226,
            "rating_q025": 1298.3424755612261
        },
        "claude-3-5-haiku-20241022": {
            "rating": 1315.2196714251822,
            "rating_q975": 1322.8308181084556,
            "rating_q025": 1307.6085247419092
        },
        "gemma-3-4b-it": {
            "rating": 1314.7364749310716,
            "rating_q975": 1344.8793166284754,
            "rating_q025": 1284.593633233668
        },
        "gpt-5-nano-high": {
            "rating": 1313.3570545198113,
            "rating_q975": 1348.6746761194304,
            "rating_q025": 1278.039432920192
        },
        "llama-3.1-nemotron-ultra-253b-v1": {
            "rating": 1312.8627566441082,
            "rating_q975": 1342.1801803092615,
            "rating_q025": 1283.5453329789548
        },
        "qwen-max-0919": {
            "rating": 1312.128480973388,
            "rating_q975": 1322.5701509049866,
            "rating_q025": 1301.6868110417895
        },
        "gpt-oss-20b": {
            "rating": 1311.792925100294,
            "rating_q975": 1341.6972952697695,
            "rating_q025": 1281.8885549308186
        },
        "gemini-1.5-flash-002": {
            "rating": 1311.6207300718074,
            "rating_q975": 1319.3153708323548,
            "rating_q025": 1303.9260893112603
        },
        "o1-mini": {
            "rating": 1311.0192561390463,
            "rating_q975": 1317.7809988041856,
            "rating_q025": 1304.2575134739072
        },
        "qwen3-30b-a3b": {
            "rating": 1310.6080755389894,
            "rating_q975": 1324.4621168478586,
            "rating_q025": 1296.7540342301202
        },
        "llama-3.1-405b-instruct-bf16": {
            "rating": 1310.0175005152555,
            "rating_q975": 1317.7156049042594,
            "rating_q025": 1302.319396126252
        },
        "gpt-4o-mini-2024-07-18": {
            "rating": 1309.2999117816867,
            "rating_q975": 1315.6500887050574,
            "rating_q025": 1302.949734858316
        },
        "qwq-32b": {
            "rating": 1308.4658952761047,
            "rating_q975": 1321.8560790770916,
            "rating_q025": 1295.0757114751177
        },
        "glm-4-plus": {
            "rating": 1307.7770207618257,
            "rating_q975": 1316.6281600003208,
            "rating_q025": 1298.9258815233304
        },
        "mistral-large-2407": {
            "rating": 1305.2001417741212,
            "rating_q975": 1312.738235139618,
            "rating_q025": 1297.6620484086247
        },
        "athene-v2-chat": {
            "rating": 1304.4680205972038,
            "rating_q975": 1313.3773839249448,
            "rating_q025": 1295.5586572694629
        },
        "llama-4-scout-17b-16e-instruct": {
            "rating": 1304.2890380444737,
            "rating_q975": 1320.7823476376,
            "rating_q025": 1287.7957284513475
        },
        "gpt-4-1106-preview": {
            "rating": 1303.9380902565674,
            "rating_q975": 1312.0537309727267,
            "rating_q025": 1295.8224495404081
        },
        "hunyuan-large-2025-02-10": {
            "rating": 1303.5573195190977,
            "rating_q975": 1331.276652013623,
            "rating_q025": 1275.8379870245726
        },
        "gpt-4.1-nano-2025-04-14": {
            "rating": 1301.3537417270113,
            "rating_q975": 1321.798720407894,
            "rating_q025": 1280.9087630461286
        },
        "hunyuan-standard-2025-02-10": {
            "rating": 1299.0643311321442,
            "rating_q975": 1325.1889550932449,
            "rating_q025": 1272.9397071710434
        },
        "grok-2-mini-2024-08-13": {
            "rating": 1299.0470619727744,
            "rating_q975": 1305.8687554995768,
            "rating_q025": 1292.225368445972
        },
        "gpt-4-0125-preview": {
            "rating": 1298.6550254821582,
            "rating_q975": 1306.4718554115907,
            "rating_q025": 1290.8381955527257
        },
        "mistral-large-2411": {
            "rating": 1297.7922655086595,
            "rating_q975": 1306.9418711426626,
            "rating_q025": 1288.6426598746566
        },
        "qwen2.5-72b-instruct": {
            "rating": 1297.7557759899548,
            "rating_q975": 1305.119478058547,
            "rating_q025": 1290.3920739213625
        },
        "reka-core-20240904": {
            "rating": 1297.482311839475,
            "rating_q975": 1313.8871487028389,
            "rating_q025": 1281.077474976111
        },
        "qwen2.5-plus-1127": {
            "rating": 1297.4342159946616,
            "rating_q975": 1311.56544852628,
            "rating_q025": 1283.3029834630431
        },
        "llama-3.3-70b-instruct": {
            "rating": 1295.063879142504,
            "rating_q975": 1302.5991001217644,
            "rating_q025": 1287.5286581632436
        },
        "deepseek-v2.5": {
            "rating": 1291.1106093420985,
            "rating_q975": 1300.066736131086,
            "rating_q025": 1282.1544825531112
        },
        "claude-3-sonnet-20240229": {
            "rating": 1290.98815622341,
            "rating_q975": 1299.2039241220812,
            "rating_q025": 1282.7723883247384
        },
        "gemma-2-27b-it": {
            "rating": 1290.7132614205811,
            "rating_q975": 1296.793072078568,
            "rating_q025": 1284.633450762594
        },
        "athene-70b-0725": {
            "rating": 1289.772792937996,
            "rating_q975": 1301.880015203594,
            "rating_q025": 1277.6655706723982
        },
        "mistral-small-3.1-24b-instruct-2503": {
            "rating": 1288.9903095157836,
            "rating_q975": 1306.0308020107248,
            "rating_q025": 1271.9498170208424
        },
        "yi-lightning": {
            "rating": 1288.846803965669,
            "rating_q975": 1297.6032627239936,
            "rating_q025": 1280.0903452073446
        },
        "llama-3.3-nemotron-49b-super-v1": {
            "rating": 1287.9319552169854,
            "rating_q975": 1320.7428711372288,
            "rating_q025": 1255.1210392967419
        },
        "gemini-1.5-flash-001": {
            "rating": 1287.088484663033,
            "rating_q975": 1295.1724633337813,
            "rating_q025": 1279.0045059922847
        },
        "hunyuan-large-vision": {
            "rating": 1286.200825656455,
            "rating_q975": 1315.9732490285128,
            "rating_q025": 1256.4284022843974
        },
        "llama-3.1-tulu-3-70b": {
            "rating": 1282.9803645535621,
            "rating_q975": 1308.5157446125038,
            "rating_q025": 1257.4449844946207
        },
        "amazon-nova-pro-v1.0": {
            "rating": 1279.7851928715254,
            "rating_q975": 1289.2377351393957,
            "rating_q025": 1270.332650603655
        },
        "nemotron-4-340b-instruct": {
            "rating": 1277.2163988035259,
            "rating_q975": 1288.903369053453,
            "rating_q025": 1265.529428553599
        },
        "command-r-plus-08-2024": {
            "rating": 1275.6048884178601,
            "rating_q975": 1289.5057101746934,
            "rating_q025": 1261.7040666610271
        },
        "llama-3.1-70b-instruct": {
            "rating": 1274.8562908695435,
            "rating_q975": 1281.7609592173021,
            "rating_q025": 1267.9516225217847
        },
        "gemma-2-9b-it-simpo": {
            "rating": 1273.357150325407,
            "rating_q975": 1289.2345085960121,
            "rating_q025": 1257.4797920548021
        },
        "claude-3-haiku-20240307": {
            "rating": 1273.1087602345701,
            "rating_q975": 1280.2166120940378,
            "rating_q025": 1266.0009083751024
        },
        "magistral-medium-2506": {
            "rating": 1273.0044879906181,
            "rating_q975": 1298.0034546957193,
            "rating_q025": 1248.005521285517
        },
        "qwen2.5-coder-32b-instruct": {
            "rating": 1272.6251352320403,
            "rating_q975": 1289.3288528316095,
            "rating_q025": 1255.921417632471
        },
        "gpt-4-0314": {
            "rating": 1272.2347523217852,
            "rating_q975": 1283.5230618469536,
            "rating_q025": 1260.9464427966168
        },
        "reka-flash-20240904": {
            "rating": 1272.1922495124568,
            "rating_q975": 1288.4346934452326,
            "rating_q025": 1255.949805579681
        },
        "gemini-1.5-flash-8b-001": {
            "rating": 1271.1200720529152,
            "rating_q975": 1278.6884979449308,
            "rating_q025": 1263.5516461609
        },
        "gemini-pro-dev-api": {
            "rating": 1270.688259520653,
            "rating_q975": 1290.1292385593313,
            "rating_q025": 1251.247280481975
        },
        "c4ai-aya-expanse-32b": {
            "rating": 1270.1471749125253,
            "rating_q975": 1278.6770436368388,
            "rating_q025": 1261.6173061882116
        },
        "glm-4-0520": {
            "rating": 1265.1927662065796,
            "rating_q975": 1280.4776043593927,
            "rating_q025": 1249.9079280537665
        },
        "command-r-plus": {
            "rating": 1264.066008534704,
            "rating_q975": 1272.4579885808141,
            "rating_q025": 1255.674028488594
        },
        "deepseek-coder-v2": {
            "rating": 1262.5613757089354,
            "rating_q975": 1275.7366045757133,
            "rating_q025": 1249.3861468421574
        },
        "mistral-small-24b-instruct-2501": {
            "rating": 1262.521530656849,
            "rating_q975": 1276.2348179059006,
            "rating_q025": 1248.8082434077976
        },
        "gpt-4-0613": {
            "rating": 1261.0610423892085,
            "rating_q975": 1270.234578472883,
            "rating_q025": 1251.8875063055339
        },
        "gemma-2-9b-it": {
            "rating": 1260.9024923250072,
            "rating_q975": 1267.9118128474695,
            "rating_q025": 1253.8931718025447
        },
        "amazon-nova-lite-v1.0": {
            "rating": 1254.4719127860171,
            "rating_q975": 1264.9153564738094,
            "rating_q025": 1244.0284690982248
        },
        "jamba-1.5-large": {
            "rating": 1252.0887473062776,
            "rating_q975": 1269.108739935398,
            "rating_q025": 1235.0687546771571
        },
        "llama-3.1-nemotron-51b-instruct": {
            "rating": 1251.5749323966616,
            "rating_q975": 1272.9064821822678,
            "rating_q025": 1230.2433826110555
        },
        "ministral-8b-2410": {
            "rating": 1251.124950145041,
            "rating_q975": 1268.4743149882463,
            "rating_q025": 1233.7755853018357
        },
        "phi-4": {
            "rating": 1250.2471036937009,
            "rating_q975": 1260.6194064642789,
            "rating_q025": 1239.874800923123
        },
        "llama-3.1-nemotron-70b-instruct": {
            "rating": 1246.5944415331924,
            "rating_q975": 1262.3533908553227,
            "rating_q025": 1230.8354922110623
        },
        "qwen2-72b-instruct": {
            "rating": 1242.7048229988532,
            "rating_q975": 1252.2189255555134,
            "rating_q025": 1233.1907204421927
        },
        "mistral-large-2402": {
            "rating": 1242.6571543340701,
            "rating_q975": 1252.2845087308747,
            "rating_q025": 1233.0297999372658
        },
        "command-r-08-2024": {
            "rating": 1239.9083782914272,
            "rating_q975": 1254.2603599579209,
            "rating_q025": 1225.5563966249338
        },
        "c4ai-aya-expanse-8b": {
            "rating": 1237.7949643040547,
            "rating_q975": 1251.4036710338748,
            "rating_q025": 1224.1862575742348
        },
        "olmo-2-0325-32b-instruct": {
            "rating": 1236.4313326092583,
            "rating_q975": 1268.3950319058604,
            "rating_q025": 1204.4676333126565
        },
        "reka-flash-21b-20240226-online": {
            "rating": 1233.3198812325616,
            "rating_q975": 1248.8092404664671,
            "rating_q025": 1217.8305219986557
        },
        "reka-flash-21b-20240226": {
            "rating": 1229.9831105180417,
            "rating_q975": 1242.2874395102801,
            "rating_q025": 1217.6787815258033
        },
        "mixtral-8x22b-instruct-v0.1": {
            "rating": 1229.7845490547375,
            "rating_q975": 1238.999556479134,
            "rating_q025": 1220.5695416303413
        },
        "amazon-nova-micro-v1.0": {
            "rating": 1228.8059453177573,
            "rating_q975": 1239.4426307393214,
            "rating_q025": 1218.169259896193
        },
        "llama-3.1-tulu-3-8b": {
            "rating": 1228.6020729765612,
            "rating_q975": 1252.3519593476515,
            "rating_q025": 1204.8521866054707
        },
        "mistral-medium": {
            "rating": 1226.2203091536785,
            "rating_q975": 1240.3766305488298,
            "rating_q025": 1212.0639877585272
        },
        "llama-3-70b-instruct": {
            "rating": 1225.2469751032381,
            "rating_q975": 1232.507841107227,
            "rating_q025": 1217.9861090992495
        },
        "command-r": {
            "rating": 1223.7028369967697,
            "rating_q975": 1233.3255333757695,
            "rating_q025": 1214.0801406177702
        },
        "gpt-3.5-turbo-0125": {
            "rating": 1223.4267173426185,
            "rating_q975": 1232.8022043412384,
            "rating_q025": 1214.0512303439987
        },
        "jamba-1.5-mini": {
            "rating": 1221.6698298579554,
            "rating_q975": 1238.5751143846949,
            "rating_q025": 1204.764545331216
        },
        "wizardlm-70b": {
            "rating": 1213.280637513602,
            "rating_q975": 1257.4443297623034,
            "rating_q025": 1169.1169452649006
        },
        "hunyuan-standard-256k": {
            "rating": 1204.3469863577475,
            "rating_q975": 1228.0724701392137,
            "rating_q025": 1180.621502576281
        },
        "phi-3-medium-4k-instruct": {
            "rating": 1202.5187260951477,
            "rating_q975": 1213.0162055751553,
            "rating_q025": 1192.0212466151402
        },
        "llama-3.1-8b-instruct": {
            "rating": 1199.686399842305,
            "rating_q975": 1206.9283509057293,
            "rating_q025": 1192.4444487788808
        },
        "openchat-3.5": {
            "rating": 1196.473518591004,
            "rating_q975": 1237.2824791796952,
            "rating_q025": 1155.6645580023128
        },
        "zephyr-orpo-141b-A35b-v0.1": {
            "rating": 1193.2333934267874,
            "rating_q975": 1218.6933583543678,
            "rating_q025": 1167.773428499207
        },
        "qwen1.5-110b-chat": {
            "rating": 1184.6768721768058,
            "rating_q975": 1196.0005683583029,
            "rating_q025": 1173.3531759953087
        },
        "gpt-3.5-turbo-1106": {
            "rating": 1183.7698976492234,
            "rating_q975": 1211.9215119678809,
            "rating_q025": 1155.6182833305659
        },
        "llama-3-8b-instruct": {
            "rating": 1179.104961164029,
            "rating_q975": 1187.1086397365784,
            "rating_q025": 1171.1012825914797
        },
        "qwen1.5-72b-chat": {
            "rating": 1178.3253217451515,
            "rating_q975": 1190.236135458574,
            "rating_q025": 1166.414508031729
        },
        "gemma-2-2b-it": {
            "rating": 1178.0121837548465,
            "rating_q975": 1185.7327889969717,
            "rating_q025": 1170.2915785127213
        },
        "phi-3-small-8k-instruct": {
            "rating": 1177.6398420225544,
            "rating_q975": 1189.946018249358,
            "rating_q025": 1165.3336657957507
        },
        "snowflake-arctic-instruct": {
            "rating": 1176.1421782773264,
            "rating_q975": 1188.609198481093,
            "rating_q025": 1163.6751580735597
        },
        "mixtral-8x7b-instruct-v0.1": {
            "rating": 1167.0574758592559,
            "rating_q975": 1176.627311373371,
            "rating_q025": 1157.4876403451408
        },
        "dbrx-instruct-preview": {
            "rating": 1165.1513446844529,
            "rating_q975": 1177.2978442921449,
            "rating_q025": 1153.0048450767608
        },
        "granite-3.1-8b-instruct": {
            "rating": 1162.771717958386,
            "rating_q975": 1189.1369022998101,
            "rating_q025": 1136.406533616962
        },
        "starling-lm-7b-alpha": {
            "rating": 1161.2739713699561,
            "rating_q975": 1188.1733058060786,
            "rating_q025": 1134.3746369338337
        },
        "internlm2_5-20b-chat": {
            "rating": 1160.3006948464022,
            "rating_q975": 1174.6345163978149,
            "rating_q025": 1145.9668732949897
        },
        "openchat-3.5-0106": {
            "rating": 1158.4979593455782,
            "rating_q975": 1178.5352222035317,
            "rating_q025": 1138.460696487625
        },
        "granite-3.0-8b-instruct": {
            "rating": 1157.1243909009017,
            "rating_q975": 1174.7229230413109,
            "rating_q025": 1139.5258587604924
        },
        "codellama-34b-instruct": {
            "rating": 1155.0747724924854,
            "rating_q975": 1198.9514602433198,
            "rating_q025": 1111.1980847416507
        },
        "vicuna-33b": {
            "rating": 1152.4984729644702,
            "rating_q975": 1173.2882993849908,
            "rating_q025": 1131.7086465439495
        },
        "qwen1.5-32b-chat": {
            "rating": 1149.0166468635616,
            "rating_q975": 1161.7870761847926,
            "rating_q025": 1136.246217542331
        },
        "yi-1.5-34b-chat": {
            "rating": 1148.947514962913,
            "rating_q975": 1159.9671051227062,
            "rating_q025": 1137.9279248031198
        },
        "starling-lm-7b-beta": {
            "rating": 1146.8492597467107,
            "rating_q975": 1162.5083387147808,
            "rating_q025": 1131.1901807786403
        },
        "llama-2-70b-chat": {
            "rating": 1146.219323701656,
            "rating_q975": 1159.705726124646,
            "rating_q025": 1132.7329212786663
        },
        "gemma-1.1-7b-it": {
            "rating": 1141.6509958549357,
            "rating_q975": 1153.4246130224074,
            "rating_q025": 1129.877378687464
        },
        "zephyr-7b-beta": {
            "rating": 1139.6933219268533,
            "rating_q975": 1177.682007443265,
            "rating_q025": 1101.7046364104415
        },
        "vicuna-13b": {
            "rating": 1137.0304951289384,
            "rating_q975": 1162.58091697078,
            "rating_q025": 1111.480073287097
        },
        "qwq-32b-preview": {
            "rating": 1128.8205568772232,
            "rating_q975": 1153.5524249164616,
            "rating_q025": 1104.0886888379846
        },
        "granite-3.0-2b-instruct": {
            "rating": 1127.133392869675,
            "rating_q975": 1144.982680826561,
            "rating_q025": 1109.2841049127892
        },
        "llama-2-13b-chat": {
            "rating": 1123.7833735666522,
            "rating_q975": 1143.6348601768977,
            "rating_q025": 1103.9318869564067
        },
        "granite-3.1-2b-instruct": {
            "rating": 1121.3457632362843,
            "rating_q975": 1148.3305297581112,
            "rating_q025": 1094.3609967144573
        },
        "yi-34b-chat": {
            "rating": 1120.688444073784,
            "rating_q975": 1140.673556448909,
            "rating_q025": 1100.703331698659
        },
        "qwen1.5-14b-chat": {
            "rating": 1118.4026213213026,
            "rating_q975": 1133.1938896461024,
            "rating_q025": 1103.6113529965025
        },
        "mistral-7b-instruct-v0.2": {
            "rating": 1098.6221666602733,
            "rating_q975": 1115.0264462204125,
            "rating_q025": 1082.2178871001342
        },
        "mistral-7b-instruct": {
            "rating": 1093.3695594786236,
            "rating_q975": 1134.5806422330716,
            "rating_q025": 1052.1584767241757
        },
        "gemma-1.1-2b-it": {
            "rating": 1092.4786693098956,
            "rating_q975": 1109.7419582291614,
            "rating_q025": 1075.21538039063
        },
        "smollm2-1.7b-instruct": {
            "rating": 1084.297791355526,
            "rating_q975": 1112.393645655054,
            "rating_q025": 1056.201937055998
        },
        "phi-3-mini-4k-instruct-june-2024": {
            "rating": 1084.1741769897662,
            "rating_q975": 1099.9451540511382,
            "rating_q025": 1068.403199928394
        },
        "qwen1.5-7b-chat": {
            "rating": 1082.3011552553294,
            "rating_q975": 1115.47569053417,
            "rating_q025": 1049.1266199764887
        },
        "gemma-7b-it": {
            "rating": 1081.4745527960706,
            "rating_q975": 1104.132968301248,
            "rating_q025": 1058.8161372908933
        },
        "phi-3-mini-4k-instruct": {
            "rating": 1080.010769494225,
            "rating_q975": 1092.311293836312,
            "rating_q025": 1067.7102451521382
        },
        "phi-3-mini-128k-instruct": {
            "rating": 1079.3832402589187,
            "rating_q975": 1094.4944722008127,
            "rating_q025": 1064.2720083170248
        },
        "llama-2-7b-chat": {
            "rating": 1062.7977108504592,
            "rating_q975": 1085.380167013053,
            "rating_q025": 1040.2152546878654
        },
        "qwen1.5-4b-chat": {
            "rating": 1048.33034503115,
            "rating_q975": 1072.49424369356,
            "rating_q025": 1024.1664463687398
        },
        "gemma-2b-it": {
            "rating": 1037.0600870748262,
            "rating_q975": 1072.1470268938324,
            "rating_q025": 1001.9731472558201
        },
        "llama-3.2-3b-instruct": {
            "rating": 1027.3408601339133,
            "rating_q975": 1049.0950522220187,
            "rating_q025": 1005.586668045808
        },
        "llama-3.2-1b-instruct": {
            "rating": 1009.81459022066,
            "rating_q975": 1031.9132249034037,
            "rating_q025": 987.715955537916
        },
        "olmo-7b-instruct": {
            "rating": 992.3108245603228,
            "rating_q975": 1019.7008940742662,
            "rating_q025": 964.9207550463793
        }
    },
    "spanish": {
        "glm-4.5": {
            "rating": 1489.4801840583043,
            "rating_q975": 1548.3788101754892,
            "rating_q025": 1430.5815579411194
        },
        "gemini-2.5-pro": {
            "rating": 1461.1961743961137,
            "rating_q975": 1495.9813123821405,
            "rating_q025": 1426.4110364100873
        },
        "claude-opus-4-1-20250805": {
            "rating": 1455.7556321063894,
            "rating_q975": 1509.171125871307,
            "rating_q025": 1402.3401383414716
        },
        "o3-2025-04-16": {
            "rating": 1443.017658075742,
            "rating_q975": 1475.6418836835182,
            "rating_q025": 1410.393432467966
        },
        "qwen3-235b-a22b-instruct-2507": {
            "rating": 1440.4632048338667,
            "rating_q975": 1498.0159268184223,
            "rating_q025": 1382.9104828493112
        },
        "o4-mini-2025-04-16": {
            "rating": 1423.9253503860625,
            "rating_q975": 1457.9758855499015,
            "rating_q025": 1389.8748152222236
        },
        "gpt-5-high": {
            "rating": 1422.5802922458408,
            "rating_q975": 1476.1685103871746,
            "rating_q025": 1368.992074104507
        },
        "grok-4-0709": {
            "rating": 1417.6527002060018,
            "rating_q975": 1461.7024713481217,
            "rating_q025": 1373.602929063882
        },
        "chatgpt-4o-latest-20250326": {
            "rating": 1414.8773408762816,
            "rating_q975": 1447.0919315303825,
            "rating_q025": 1382.6627502221809
        },
        "claude-sonnet-4-20250514": {
            "rating": 1413.3248269147468,
            "rating_q975": 1448.353034127989,
            "rating_q025": 1378.2966197015048
        },
        "claude-opus-4-20250514": {
            "rating": 1410.217368425966,
            "rating_q975": 1444.0018524063576,
            "rating_q025": 1376.4328844455745
        },
        "claude-opus-4-20250514-thinking-16k": {
            "rating": 1410.132472184031,
            "rating_q975": 1450.0571054775767,
            "rating_q025": 1370.2078388904856
        },
        "grok-3-preview-02-24": {
            "rating": 1409.9070480424614,
            "rating_q975": 1442.36760719568,
            "rating_q025": 1377.4464888892428
        },
        "qwen3-235b-a22b-no-thinking": {
            "rating": 1408.7278028448668,
            "rating_q975": 1446.8855717641852,
            "rating_q025": 1370.5700339255486
        },
        "deepseek-r1-0528": {
            "rating": 1397.9692894444026,
            "rating_q975": 1438.6659771373543,
            "rating_q025": 1357.272601751451
        },
        "gpt-4.1-2025-04-14": {
            "rating": 1390.2676686655411,
            "rating_q975": 1424.0926233977625,
            "rating_q025": 1356.44271393332
        },
        "mistral-medium-2505": {
            "rating": 1389.6100926235688,
            "rating_q975": 1424.8305301165879,
            "rating_q025": 1354.3896551305497
        },
        "qwen3-235b-a22b": {
            "rating": 1389.3019703571622,
            "rating_q975": 1425.459677535656,
            "rating_q025": 1353.1442631786686
        },
        "command-a-03-2025": {
            "rating": 1389.0662601235242,
            "rating_q975": 1419.7430630456886,
            "rating_q025": 1358.3894572013598
        },
        "gemini-2.5-flash": {
            "rating": 1382.7482621575075,
            "rating_q975": 1414.775817042391,
            "rating_q025": 1350.720707272624
        },
        "qwen2.5-max": {
            "rating": 1377.0471070342426,
            "rating_q975": 1413.3286064447175,
            "rating_q025": 1340.765607623768
        },
        "deepseek-r1": {
            "rating": 1374.6062078121981,
            "rating_q975": 1422.945532158986,
            "rating_q025": 1326.26688346541
        },
        "grok-3-mini-beta": {
            "rating": 1373.5518017644229,
            "rating_q975": 1411.7647269884415,
            "rating_q025": 1335.3388765404043
        },
        "o1-2024-12-17": {
            "rating": 1369.90124868058,
            "rating_q975": 1415.4687318671276,
            "rating_q025": 1324.3337654940324
        },
        "gemini-2.0-flash-001": {
            "rating": 1367.5628884368964,
            "rating_q975": 1398.1590542627782,
            "rating_q025": 1336.9667226110146
        },
        "claude-3-7-sonnet-20250219-thinking-32k": {
            "rating": 1366.2222199017754,
            "rating_q975": 1398.6571869366476,
            "rating_q025": 1333.7872528669031
        },
        "mistral-small-2506": {
            "rating": 1363.7500633039347,
            "rating_q975": 1416.4770641982734,
            "rating_q025": 1311.023062409596
        },
        "deepseek-v3": {
            "rating": 1362.3057962278776,
            "rating_q975": 1407.61660601116,
            "rating_q025": 1316.994986444595
        },
        "kimi-k2-0711-preview": {
            "rating": 1359.989735130568,
            "rating_q975": 1410.7685325515777,
            "rating_q025": 1309.2109377095583
        },
        "claude-sonnet-4-20250514-thinking-32k": {
            "rating": 1359.0679167604042,
            "rating_q975": 1400.9916796810114,
            "rating_q025": 1317.1441538397971
        },
        "gpt-4.1-mini-2025-04-14": {
            "rating": 1355.0020555665167,
            "rating_q975": 1388.9693162426902,
            "rating_q025": 1321.0347948903434
        },
        "claude-3-7-sonnet-20250219": {
            "rating": 1353.8909442516124,
            "rating_q975": 1384.5315633894318,
            "rating_q025": 1323.250325113793
        },
        "minimax-m1": {
            "rating": 1348.8799200605554,
            "rating_q975": 1393.152933300362,
            "rating_q025": 1304.6069068207487
        },
        "o3-mini-high": {
            "rating": 1346.8479651853181,
            "rating_q975": 1394.3881059342332,
            "rating_q025": 1299.3078244364028
        },
        "claude-3-5-sonnet-20241022": {
            "rating": 1346.7155158541912,
            "rating_q975": 1367.362854716532,
            "rating_q025": 1326.0681769918504
        },
        "deepseek-v3-0324": {
            "rating": 1342.4935851911139,
            "rating_q975": 1375.461818270057,
            "rating_q025": 1309.5253521121708
        },
        "o1-preview": {
            "rating": 1341.5736351700348,
            "rating_q975": 1368.8695345336882,
            "rating_q025": 1314.2777358063813
        },
        "claude-3-5-sonnet-20240620": {
            "rating": 1340.946240174443,
            "rating_q975": 1358.7675774040558,
            "rating_q025": 1323.12490294483
        },
        "gemma-3-27b-it": {
            "rating": 1338.1361322472692,
            "rating_q975": 1370.1735622481087,
            "rating_q025": 1306.0987022464296
        },
        "o3-mini": {
            "rating": 1333.2581339719911,
            "rating_q975": 1362.9038591905646,
            "rating_q025": 1303.6124087534174
        },
        "yi-lightning": {
            "rating": 1331.3410578578864,
            "rating_q975": 1359.3326315907698,
            "rating_q025": 1303.349484125003
        },
        "grok-3-mini-high": {
            "rating": 1331.0181954726168,
            "rating_q975": 1378.2274784716317,
            "rating_q025": 1283.8089124736018
        },
        "gpt-4o-2024-05-13": {
            "rating": 1330.699203009722,
            "rating_q975": 1345.6189066102936,
            "rating_q025": 1315.77949940915
        },
        "gemini-1.5-pro-002": {
            "rating": 1329.9483027854808,
            "rating_q975": 1354.442838897447,
            "rating_q025": 1305.4537666735146
        },
        "gemini-2.0-flash-lite-preview-02-05": {
            "rating": 1326.9823830998037,
            "rating_q975": 1370.5586237061066,
            "rating_q025": 1283.4061424935007
        },
        "glm-4-plus": {
            "rating": 1326.545634205587,
            "rating_q975": 1353.7565251341694,
            "rating_q025": 1299.334743277005
        },
        "qwq-32b": {
            "rating": 1324.4044299972438,
            "rating_q975": 1366.085854093658,
            "rating_q025": 1282.7230059008295
        },
        "o1-mini": {
            "rating": 1322.1697284866837,
            "rating_q975": 1345.9002306543412,
            "rating_q025": 1298.4392263190261
        },
        "gpt-4o-2024-08-06": {
            "rating": 1321.2620905089439,
            "rating_q975": 1343.4392360833594,
            "rating_q025": 1299.0849449345283
        },
        "mistral-small-3.1-24b-instruct-2503": {
            "rating": 1316.1343077425445,
            "rating_q975": 1359.3770523597616,
            "rating_q025": 1272.8915631253274
        },
        "gpt-4-1106-preview": {
            "rating": 1315.0821588719505,
            "rating_q975": 1332.2060573809213,
            "rating_q025": 1297.9582603629797
        },
        "qwen-max-0919": {
            "rating": 1313.068914639619,
            "rating_q975": 1347.8928121049425,
            "rating_q025": 1278.2450171742955
        },
        "claude-3-5-haiku-20241022": {
            "rating": 1311.5445884231228,
            "rating_q975": 1339.1580971394064,
            "rating_q025": 1283.9310797068392
        },
        "qwen3-30b-a3b": {
            "rating": 1311.2253188066827,
            "rating_q975": 1348.6302011292205,
            "rating_q025": 1273.820436484145
        },
        "gpt-4-turbo-2024-04-09": {
            "rating": 1311.0877553420487,
            "rating_q975": 1327.1892907702486,
            "rating_q025": 1294.9862199138488
        },
        "mistral-small-24b-instruct-2501": {
            "rating": 1310.9234707862943,
            "rating_q975": 1363.7018386306831,
            "rating_q025": 1258.1451029419059
        },
        "llama-4-maverick-17b-128e-instruct": {
            "rating": 1310.4464442978049,
            "rating_q975": 1345.55948359157,
            "rating_q025": 1275.3334050040398
        },
        "llama-3.1-405b-instruct-bf16": {
            "rating": 1309.064195166065,
            "rating_q975": 1334.5554772203463,
            "rating_q025": 1283.5729131117835
        },
        "claude-3-opus-20240229": {
            "rating": 1308.0859014139435,
            "rating_q975": 1322.0833141763217,
            "rating_q025": 1294.0884886515655
        },
        "llama-3.1-405b-instruct-fp8": {
            "rating": 1305.5862553625477,
            "rating_q975": 1325.3933432971967,
            "rating_q025": 1285.7791674278988
        },
        "gpt-4-0125-preview": {
            "rating": 1304.2126612528532,
            "rating_q975": 1321.9003319457097,
            "rating_q025": 1286.5249905599967
        },
        "llama-4-scout-17b-16e-instruct": {
            "rating": 1303.5096165778855,
            "rating_q975": 1346.67179591844,
            "rating_q025": 1260.3474372373312
        },
        "gpt-4o-mini-2024-07-18": {
            "rating": 1301.8549232467979,
            "rating_q975": 1320.8173207213033,
            "rating_q025": 1282.8925257722926
        },
        "grok-2-2024-08-13": {
            "rating": 1299.272272298378,
            "rating_q975": 1318.4426599883582,
            "rating_q025": 1280.1018846083982
        },
        "grok-2-mini-2024-08-13": {
            "rating": 1296.703648853288,
            "rating_q975": 1316.6849209041604,
            "rating_q025": 1276.7223768024155
        },
        "mistral-large-2411": {
            "rating": 1296.3613073462438,
            "rating_q975": 1337.3918851426308,
            "rating_q025": 1255.3307295498566
        },
        "amazon-nova-experimental-chat-05-14": {
            "rating": 1294.7799579600955,
            "rating_q975": 1340.023063264299,
            "rating_q025": 1249.5368526558918
        },
        "llama-3.3-70b-instruct": {
            "rating": 1291.7224435324079,
            "rating_q975": 1319.9620048383122,
            "rating_q025": 1263.482882226504
        },
        "llama-3-70b-instruct": {
            "rating": 1291.1687299333698,
            "rating_q975": 1305.396188371788,
            "rating_q025": 1276.9412714949515
        },
        "athene-v2-chat": {
            "rating": 1288.8405076932154,
            "rating_q975": 1323.1668799542597,
            "rating_q025": 1254.5141354321713
        },
        "gemini-advanced-0514": {
            "rating": 1287.4236567016428,
            "rating_q975": 1307.040080314429,
            "rating_q025": 1267.8072330888567
        },
        "gemini-1.5-pro-001": {
            "rating": 1286.1556871616813,
            "rating_q975": 1303.0878646553617,
            "rating_q025": 1269.223509668001
        },
        "qwen2.5-72b-instruct": {
            "rating": 1283.079112493543,
            "rating_q975": 1309.511978942297,
            "rating_q025": 1256.646246044789
        },
        "mistral-large-2407": {
            "rating": 1281.4627156761835,
            "rating_q975": 1302.0034815788351,
            "rating_q025": 1260.9219497735317
        },
        "gpt-4-0314": {
            "rating": 1280.5293292557878,
            "rating_q975": 1304.5308736583577,
            "rating_q025": 1256.527784853218
        },
        "llama-3.1-70b-instruct": {
            "rating": 1280.2932891001751,
            "rating_q975": 1300.3614023096734,
            "rating_q025": 1260.2251758906766
        },
        "athene-70b-0725": {
            "rating": 1279.9594427397465,
            "rating_q975": 1310.7336888510383,
            "rating_q025": 1249.1851966284548
        },
        "gemma-2-27b-it": {
            "rating": 1277.7602574533062,
            "rating_q975": 1295.6290060155497,
            "rating_q025": 1259.8915088910628
        },
        "deepseek-v2.5": {
            "rating": 1276.7852697924623,
            "rating_q975": 1306.0145724576234,
            "rating_q025": 1247.5559671273013
        },
        "amazon-nova-lite-v1.0": {
            "rating": 1272.8679133454925,
            "rating_q975": 1320.2629066712902,
            "rating_q025": 1225.4729200196946
        },
        "claude-3-sonnet-20240229": {
            "rating": 1271.311656755091,
            "rating_q975": 1288.7456636060926,
            "rating_q025": 1253.8776499040891
        },
        "gemini-1.5-flash-001": {
            "rating": 1269.1258739360417,
            "rating_q975": 1286.3178706394249,
            "rating_q025": 1251.9338772326585
        },
        "gemini-1.5-flash-002": {
            "rating": 1265.9848821797113,
            "rating_q975": 1294.6291842028322,
            "rating_q025": 1237.3405801565905
        },
        "gpt-4-0613": {
            "rating": 1264.4046158879723,
            "rating_q975": 1282.333807247594,
            "rating_q025": 1246.4754245283505
        },
        "mistral-large-2402": {
            "rating": 1263.806424213229,
            "rating_q975": 1284.5224638824159,
            "rating_q025": 1243.090384544042
        },
        "phi-4": {
            "rating": 1259.4986449387584,
            "rating_q975": 1308.445936840138,
            "rating_q025": 1210.5513530373787
        },
        "gemma-3n-e4b-it": {
            "rating": 1255.4246590002178,
            "rating_q975": 1296.1135818956468,
            "rating_q025": 1214.7357361047889
        },
        "gemma-2-9b-it": {
            "rating": 1254.8380090189485,
            "rating_q975": 1276.1097948584202,
            "rating_q025": 1233.5662231794768
        },
        "command-r-plus": {
            "rating": 1254.1134423448025,
            "rating_q975": 1272.2598994861532,
            "rating_q025": 1235.9669852034517
        },
        "nemotron-4-340b-instruct": {
            "rating": 1253.8773589256677,
            "rating_q975": 1281.3231500253387,
            "rating_q025": 1226.4315678259968
        },
        "amazon-nova-micro-v1.0": {
            "rating": 1250.3905373656362,
            "rating_q975": 1292.7682839364097,
            "rating_q025": 1208.012790794863
        },
        "qwen2-72b-instruct": {
            "rating": 1250.338860593392,
            "rating_q975": 1273.7885137221333,
            "rating_q025": 1226.8892074646503
        },
        "gemini-1.5-flash-8b-001": {
            "rating": 1249.4313247964965,
            "rating_q975": 1276.3103613571823,
            "rating_q025": 1222.552288235811
        },
        "c4ai-aya-expanse-32b": {
            "rating": 1244.9788409400549,
            "rating_q975": 1275.812335296319,
            "rating_q025": 1214.145346583791
        },
        "claude-3-haiku-20240307": {
            "rating": 1239.990767427521,
            "rating_q975": 1255.7351955548156,
            "rating_q025": 1224.2463393002263
        },
        "amazon-nova-pro-v1.0": {
            "rating": 1233.1153074540453,
            "rating_q975": 1277.3425044154442,
            "rating_q025": 1188.8881104926463
        },
        "mixtral-8x22b-instruct-v0.1": {
            "rating": 1229.0254201553246,
            "rating_q975": 1250.2719427292084,
            "rating_q025": 1207.7788975814408
        },
        "llama-3-8b-instruct": {
            "rating": 1228.5807535241217,
            "rating_q975": 1244.7248400300641,
            "rating_q025": 1212.4366670181794
        },
        "command-r": {
            "rating": 1226.1202881651398,
            "rating_q975": 1248.7973368984,
            "rating_q025": 1203.4432394318794
        },
        "gpt-3.5-turbo-0125": {
            "rating": 1223.469775836763,
            "rating_q975": 1244.3328860798392,
            "rating_q025": 1202.6066655936863
        },
        "reka-flash-21b-20240226-online": {
            "rating": 1220.8775291966658,
            "rating_q975": 1259.7216267133242,
            "rating_q025": 1182.0334316800072
        },
        "deepseek-coder-v2": {
            "rating": 1219.4264455426078,
            "rating_q975": 1251.0526831427226,
            "rating_q025": 1187.800207942493
        },
        "qwen1.5-110b-chat": {
            "rating": 1215.6595645704226,
            "rating_q975": 1242.1536426048904,
            "rating_q025": 1189.1654865359549
        },
        "gemini-pro-dev-api": {
            "rating": 1214.7483539872926,
            "rating_q975": 1254.5172017346115,
            "rating_q025": 1174.979506239974
        },
        "mistral-medium": {
            "rating": 1209.8987247143118,
            "rating_q975": 1238.9972464228858,
            "rating_q025": 1180.8002030057378
        },
        "gpt-3.5-turbo-1106": {
            "rating": 1206.0005068723494,
            "rating_q975": 1243.6886264256773,
            "rating_q025": 1168.3123873190214
        },
        "llama-2-70b-chat": {
            "rating": 1202.5713221371504,
            "rating_q975": 1228.379777522959,
            "rating_q025": 1176.7628667513418
        },
        "reka-flash-21b-20240226": {
            "rating": 1202.2099219263773,
            "rating_q975": 1230.7390355443176,
            "rating_q025": 1173.6808083084372
        },
        "llama-3.1-8b-instruct": {
            "rating": 1189.2880019844247,
            "rating_q975": 1211.6997985183982,
            "rating_q025": 1166.8762054504512
        },
        "gemma-2-2b-it": {
            "rating": 1188.523399845963,
            "rating_q975": 1211.614364043825,
            "rating_q025": 1165.4324356481009
        },
        "qwen1.5-72b-chat": {
            "rating": 1186.2635956729962,
            "rating_q975": 1212.9192836866912,
            "rating_q025": 1159.6079076593014
        },
        "mixtral-8x7b-instruct-v0.1": {
            "rating": 1183.7137382794926,
            "rating_q975": 1203.3924859974097,
            "rating_q025": 1164.0349905615756
        },
        "phi-3-small-8k-instruct": {
            "rating": 1182.6103057123923,
            "rating_q975": 1215.8306124854066,
            "rating_q025": 1149.3899989393783
        },
        "snowflake-arctic-instruct": {
            "rating": 1177.6323779394304,
            "rating_q975": 1204.1742609489515,
            "rating_q025": 1151.0904949299093
        },
        "yi-1.5-34b-chat": {
            "rating": 1175.15001775864,
            "rating_q975": 1201.7467808998836,
            "rating_q025": 1148.553254617396
        },
        "phi-3-medium-4k-instruct": {
            "rating": 1171.1246942124897,
            "rating_q975": 1197.7212023938184,
            "rating_q025": 1144.5281860311609
        },
        "qwen1.5-32b-chat": {
            "rating": 1170.952149990445,
            "rating_q975": 1198.9397234314756,
            "rating_q025": 1142.9645765494142
        },
        "vicuna-13b": {
            "rating": 1166.9742998302463,
            "rating_q975": 1213.5944788118497,
            "rating_q025": 1120.3541208486427
        },
        "qwen1.5-14b-chat": {
            "rating": 1159.5546281005793,
            "rating_q975": 1192.1484261394342,
            "rating_q025": 1126.9608300617247
        },
        "dbrx-instruct-preview": {
            "rating": 1158.3535954585277,
            "rating_q975": 1187.40034913471,
            "rating_q025": 1129.3068417823456
        },
        "phi-3-mini-4k-instruct": {
            "rating": 1156.6475603770514,
            "rating_q975": 1183.977902454191,
            "rating_q025": 1129.317218299912
        },
        "llama-2-13b-chat": {
            "rating": 1151.9453241496074,
            "rating_q975": 1188.6904762697473,
            "rating_q025": 1115.2001720294675
        },
        "gemma-1.1-7b-it": {
            "rating": 1150.0068612652426,
            "rating_q975": 1178.279138332177,
            "rating_q025": 1121.734584198308
        },
        "vicuna-33b": {
            "rating": 1149.9077339161736,
            "rating_q975": 1184.753018559423,
            "rating_q025": 1115.0624492729244
        },
        "zephyr-7b-beta": {
            "rating": 1148.326961593691,
            "rating_q975": 1201.8182798245195,
            "rating_q025": 1094.8356433628626
        },
        "phi-3-mini-128k-instruct": {
            "rating": 1144.458506229985,
            "rating_q975": 1176.3490434496237,
            "rating_q025": 1112.5679690103466
        },
        "yi-34b-chat": {
            "rating": 1140.3276608367569,
            "rating_q975": 1178.7287045430112,
            "rating_q025": 1101.9266171305028
        },
        "mistral-7b-instruct-v0.2": {
            "rating": 1100.2253969924654,
            "rating_q975": 1143.1774414425304,
            "rating_q025": 1057.2733525424005
        },
        "gemma-1.1-2b-it": {
            "rating": 1086.254173702439,
            "rating_q975": 1133.065524183096,
            "rating_q025": 1039.4428232217815
        },
        "llama-2-7b-chat": {
            "rating": 1070.9490257758898,
            "rating_q975": 1120.5924576184323,
            "rating_q025": 1021.3055939333472
        }
    }
}