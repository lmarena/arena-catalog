{
    "chinese": {
        "gemini-2.5-pro": {
            "rating": 1494.4371676804847,
            "rating_q975": 1506.6792639247137,
            "rating_q025": 1482.1950714362556
        },
        "glm-4.6": {
            "rating": 1492.4199222910322,
            "rating_q975": 1527.8535539999627,
            "rating_q025": 1456.9862905821017
        },
        "qwen3-max-preview": {
            "rating": 1490.3189344374994,
            "rating_q975": 1507.8298290650055,
            "rating_q025": 1472.8080398099933
        },
        "deepseek-v3.1-thinking": {
            "rating": 1473.087971591467,
            "rating_q975": 1493.8149592180034,
            "rating_q025": 1452.3609839649307
        },
        "grok-4-fast": {
            "rating": 1471.7962825332552,
            "rating_q975": 1503.0515748368882,
            "rating_q025": 1440.5409902296221
        },
        "claude-sonnet-4-5-20250929": {
            "rating": 1468.6494424742011,
            "rating_q975": 1510.6702325077151,
            "rating_q025": 1426.6286524406871
        },
        "gemini-2.5-flash-preview-09-2025": {
            "rating": 1466.7118392125383,
            "rating_q975": 1495.6156935667527,
            "rating_q025": 1437.8079848583238
        },
        "deepseek-v3.1": {
            "rating": 1461.8969081811003,
            "rating_q975": 1480.2179260721998,
            "rating_q025": 1443.5758902900009
        },
        "chatgpt-4o-latest-20250326": {
            "rating": 1460.341887940663,
            "rating_q975": 1473.213032144634,
            "rating_q025": 1447.4707437366917
        },
        "o3-2025-04-16": {
            "rating": 1459.6325169701038,
            "rating_q975": 1471.7447631363336,
            "rating_q025": 1447.520270803874
        },
        "qwen3-vl-235b-a22b-instruct": {
            "rating": 1457.0715272834445,
            "rating_q975": 1487.765951001791,
            "rating_q025": 1426.377103565098
        },
        "qwen3-235b-a22b-instruct-2507": {
            "rating": 1456.4307455859955,
            "rating_q975": 1470.8265677627014,
            "rating_q025": 1442.0349234092896
        },
        "deepseek-v3.2-exp-thinking": {
            "rating": 1455.5166588868049,
            "rating_q975": 1490.3103065582825,
            "rating_q025": 1420.7230112153272
        },
        "qwen3-next-80b-a3b-instruct": {
            "rating": 1452.4535671781316,
            "rating_q975": 1472.362393329847,
            "rating_q025": 1432.5447410264162
        },
        "claude-opus-4-1-20250805": {
            "rating": 1451.1309504282972,
            "rating_q975": 1464.7995493508977,
            "rating_q025": 1437.4623515056967
        },
        "gpt-5-high": {
            "rating": 1450.4015784810124,
            "rating_q975": 1467.4798728610415,
            "rating_q025": 1433.3232841009833
        },
        "kimi-k2-0711-preview": {
            "rating": 1447.817860730834,
            "rating_q975": 1463.378436032589,
            "rating_q025": 1432.2572854290788
        },
        "gpt-4.5-preview-2025-02-27": {
            "rating": 1446.5359021547247,
            "rating_q975": 1465.7631763438842,
            "rating_q025": 1427.3086279655652
        },
        "claude-sonnet-4-5-20250929-thinking-32k": {
            "rating": 1446.3235050306093,
            "rating_q975": 1475.584231609657,
            "rating_q025": 1417.0627784515616
        },
        "qwen3-vl-235b-a22b-thinking": {
            "rating": 1443.9419163108444,
            "rating_q975": 1479.278777459428,
            "rating_q025": 1408.6050551622607
        },
        "qwen3-235b-a22b-thinking-2507": {
            "rating": 1442.7257708126729,
            "rating_q975": 1470.9640367966044,
            "rating_q025": 1414.4875048287413
        },
        "claude-opus-4-1-20250805-thinking-16k": {
            "rating": 1442.5957205459056,
            "rating_q975": 1458.8922718826693,
            "rating_q025": 1426.2991692091418
        },
        "qwen3-max-2025-09-23": {
            "rating": 1442.5318685656778,
            "rating_q975": 1472.9625800357774,
            "rating_q025": 1412.1011570955782
        },
        "gemini-2.5-flash": {
            "rating": 1442.382646438785,
            "rating_q975": 1454.1667077085815,
            "rating_q025": 1430.5985851689886
        },
        "deepseek-r1-0528": {
            "rating": 1441.0623057626258,
            "rating_q975": 1460.1319528537283,
            "rating_q025": 1421.9926586715233
        },
        "claude-opus-4-20250514-thinking-16k": {
            "rating": 1439.3727320103148,
            "rating_q975": 1453.3739778572453,
            "rating_q025": 1425.3714861633844
        },
        "kimi-k2-0905-preview": {
            "rating": 1437.8336158773432,
            "rating_q975": 1460.7735390480545,
            "rating_q025": 1414.8936927066318
        },
        "claude-opus-4-20250514": {
            "rating": 1436.250502704781,
            "rating_q975": 1448.7649813276767,
            "rating_q025": 1423.7360240818853
        },
        "glm-4.5": {
            "rating": 1435.0642482392282,
            "rating_q975": 1452.0635353398638,
            "rating_q025": 1418.0649611385925
        },
        "gpt-5-chat": {
            "rating": 1434.5832835946273,
            "rating_q975": 1450.8549071577095,
            "rating_q025": 1418.3116600315452
        },
        "qwen3-235b-a22b-no-thinking": {
            "rating": 1433.636700715787,
            "rating_q975": 1447.452119032606,
            "rating_q025": 1419.8212823989677
        },
        "qwen3-30b-a3b-instruct-2507": {
            "rating": 1430.9884743919865,
            "rating_q975": 1447.9084221597304,
            "rating_q025": 1414.0685266242426
        },
        "grok-4-0709": {
            "rating": 1427.763733497123,
            "rating_q975": 1443.154918508491,
            "rating_q025": 1412.372548485755
        },
        "grok-3-preview-02-24": {
            "rating": 1427.054612426062,
            "rating_q975": 1441.3424270443854,
            "rating_q025": 1412.7667978077386
        },
        "o1-2024-12-17": {
            "rating": 1424.342489044659,
            "rating_q975": 1438.0754083656434,
            "rating_q025": 1410.6095697236747
        },
        "hunyuan-turbos-20250416": {
            "rating": 1422.3124084345413,
            "rating_q975": 1449.1131105614527,
            "rating_q025": 1395.51170630763
        },
        "mistral-medium-2508": {
            "rating": 1419.8812744589557,
            "rating_q975": 1435.6054333111606,
            "rating_q025": 1404.1571156067507
        },
        "deepseek-r1": {
            "rating": 1418.9458432014708,
            "rating_q975": 1436.5628290309644,
            "rating_q025": 1401.3288573719772
        },
        "claude-haiku-4-5-20251001": {
            "rating": 1417.3119941931418,
            "rating_q975": 1448.5778419227718,
            "rating_q025": 1386.0461464635118
        },
        "hunyuan-t1-20250711": {
            "rating": 1414.2309307937608,
            "rating_q975": 1451.3233255505659,
            "rating_q025": 1377.1385360369557
        },
        "longcat-flash-chat": {
            "rating": 1412.7637498553147,
            "rating_q975": 1436.4232731841485,
            "rating_q025": 1389.104226526481
        },
        "gpt-5-mini-high": {
            "rating": 1410.2518636600691,
            "rating_q975": 1428.425709652908,
            "rating_q025": 1392.0780176672304
        },
        "gpt-4.1-2025-04-14": {
            "rating": 1409.5160316076428,
            "rating_q975": 1422.397107222541,
            "rating_q025": 1396.6349559927446
        },
        "claude-sonnet-4-20250514-thinking-32k": {
            "rating": 1405.6111390059323,
            "rating_q975": 1419.8169400615122,
            "rating_q025": 1391.4053379503523
        },
        "deepseek-v3-0324": {
            "rating": 1405.2173628087871,
            "rating_q975": 1417.5737131246085,
            "rating_q025": 1392.8610124929658
        },
        "o3-mini-high": {
            "rating": 1405.1753650998573,
            "rating_q975": 1422.05539106221,
            "rating_q025": 1388.2953391375047
        },
        "glm-4.5-air": {
            "rating": 1405.1497597935431,
            "rating_q975": 1421.4118063333995,
            "rating_q025": 1388.8877132536868
        },
        "qwen3-next-80b-a3b-thinking": {
            "rating": 1399.4121954890243,
            "rating_q975": 1421.437084726337,
            "rating_q025": 1377.3873062517116
        },
        "glm-4-plus-0111": {
            "rating": 1397.5222333598063,
            "rating_q975": 1427.4295036051135,
            "rating_q025": 1367.614963114499
        },
        "gemini-2.5-flash-lite-preview-06-17-thinking": {
            "rating": 1397.2885720735155,
            "rating_q975": 1412.0301339875025,
            "rating_q025": 1382.5470101595286
        },
        "gemini-2.5-flash-lite-preview-09-2025-no-thinking": {
            "rating": 1396.3028201379523,
            "rating_q975": 1423.5281509906506,
            "rating_q025": 1369.077489285254
        },
        "claude-sonnet-4-20250514": {
            "rating": 1394.8414594663607,
            "rating_q975": 1407.9922765254298,
            "rating_q025": 1381.6906424072915
        },
        "qwen3-coder-480b-a35b-instruct": {
            "rating": 1392.680226160646,
            "rating_q975": 1410.2358376598622,
            "rating_q025": 1375.1246146614299
        },
        "o4-mini-2025-04-16": {
            "rating": 1392.4079032654206,
            "rating_q975": 1405.2819275884947,
            "rating_q025": 1379.5338789423465
        },
        "hunyuan-turbo-0110": {
            "rating": 1388.5791957857618,
            "rating_q975": 1427.492999501848,
            "rating_q025": 1349.6653920696756
        },
        "qwen2.5-max": {
            "rating": 1388.5736303630947,
            "rating_q975": 1401.322211198036,
            "rating_q025": 1375.8250495281534
        },
        "qwen3-235b-a22b": {
            "rating": 1388.0014986095262,
            "rating_q975": 1404.504250300151,
            "rating_q025": 1371.4987469189014
        },
        "claude-3-7-sonnet-20250219-thinking-32k": {
            "rating": 1387.647474737807,
            "rating_q975": 1401.153528927284,
            "rating_q025": 1374.14142054833
        },
        "grok-3-mini-high": {
            "rating": 1386.442498649437,
            "rating_q975": 1408.5897966478963,
            "rating_q025": 1364.295200650978
        },
        "mai-1-preview": {
            "rating": 1386.4120248676386,
            "rating_q975": 1405.1983325747926,
            "rating_q025": 1367.6257171604846
        },
        "step-3": {
            "rating": 1384.2146676263185,
            "rating_q975": 1422.3338952463705,
            "rating_q025": 1346.0954400062665
        },
        "mistral-medium-2505": {
            "rating": 1383.489694376229,
            "rating_q975": 1398.0672967743387,
            "rating_q025": 1368.9120919781192
        },
        "ling-flash-2.0": {
            "rating": 1380.4317264800095,
            "rating_q975": 1413.2210975031257,
            "rating_q025": 1347.6423554568933
        },
        "hunyuan-large-2025-02-10": {
            "rating": 1378.982422825619,
            "rating_q975": 1411.4463978734873,
            "rating_q025": 1346.518447777751
        },
        "o1-preview": {
            "rating": 1378.9377264998411,
            "rating_q975": 1390.607790184592,
            "rating_q025": 1367.2676628150903
        },
        "minimax-m1": {
            "rating": 1377.5200202757576,
            "rating_q975": 1391.846789314286,
            "rating_q025": 1363.193251237229
        },
        "gpt-4.1-mini-2025-04-14": {
            "rating": 1377.0915601407662,
            "rating_q975": 1390.6330758882696,
            "rating_q025": 1363.5500443932629
        },
        "gpt-5-nano-high": {
            "rating": 1375.141510896587,
            "rating_q975": 1405.0996189591272,
            "rating_q025": 1345.183402834047
        },
        "qwq-32b": {
            "rating": 1371.8973909996841,
            "rating_q975": 1387.7012711281527,
            "rating_q025": 1356.0935108712156
        },
        "ring-flash-2.0": {
            "rating": 1371.421216520558,
            "rating_q975": 1403.1455561327484,
            "rating_q025": 1339.6968769083674
        },
        "grok-3-mini-beta": {
            "rating": 1370.9202818236624,
            "rating_q975": 1388.7903190995366,
            "rating_q025": 1353.0502445477882
        },
        "qwen-plus-0125": {
            "rating": 1367.9556294975127,
            "rating_q975": 1394.7615686503773,
            "rating_q025": 1341.1496903446482
        },
        "gemini-1.5-pro-002": {
            "rating": 1366.5185080971712,
            "rating_q975": 1375.6508499106728,
            "rating_q025": 1357.3861662836696
        },
        "qwen3-30b-a3b": {
            "rating": 1365.4922052520312,
            "rating_q975": 1382.2027966777268,
            "rating_q025": 1348.7816138263356
        },
        "gemma-3-27b-it": {
            "rating": 1363.2708951382735,
            "rating_q975": 1375.9953198957571,
            "rating_q025": 1350.54647038079
        },
        "gemini-2.0-flash-lite-preview-02-05": {
            "rating": 1362.1406709548096,
            "rating_q975": 1376.6273824142693,
            "rating_q025": 1347.65395949535
        },
        "deepseek-v3": {
            "rating": 1361.7407246394218,
            "rating_q975": 1376.604788578555,
            "rating_q025": 1346.8766607002888
        },
        "hunyuan-turbos-20250226": {
            "rating": 1360.8355388718307,
            "rating_q975": 1399.8488559381192,
            "rating_q025": 1321.8222218055423
        },
        "gpt-oss-120b": {
            "rating": 1357.8757766618676,
            "rating_q975": 1374.2441575995842,
            "rating_q025": 1341.507395724151
        },
        "o3-mini": {
            "rating": 1357.105438597935,
            "rating_q975": 1367.4524929228985,
            "rating_q025": 1346.7583842729716
        },
        "claude-3-5-sonnet-20241022": {
            "rating": 1356.7896318797732,
            "rating_q975": 1364.54351634463,
            "rating_q025": 1349.0357474149164
        },
        "step-2-16k-exp-202412": {
            "rating": 1356.422149755242,
            "rating_q975": 1389.9183817206758,
            "rating_q025": 1322.925917789808
        },
        "qwen3-32b": {
            "rating": 1355.5618909764082,
            "rating_q975": 1393.859120462947,
            "rating_q025": 1317.2646614898695
        },
        "step-1o-turbo-202506": {
            "rating": 1353.7947523199018,
            "rating_q975": 1380.2236153764034,
            "rating_q025": 1327.3658892634003
        },
        "yi-lightning": {
            "rating": 1353.5311877695676,
            "rating_q975": 1365.0337694152213,
            "rating_q025": 1342.028606123914
        },
        "hunyuan-standard-2025-02-10": {
            "rating": 1353.035516827753,
            "rating_q975": 1384.0605400835666,
            "rating_q025": 1322.0104935719396
        },
        "command-a-03-2025": {
            "rating": 1348.7034352834817,
            "rating_q975": 1360.489415021192,
            "rating_q025": 1336.9174555457714
        },
        "deepseek-v2.5-1210": {
            "rating": 1347.2590909533276,
            "rating_q975": 1373.277707825516,
            "rating_q025": 1321.2404740811392
        },
        "gpt-oss-20b": {
            "rating": 1346.662234127936,
            "rating_q975": 1373.6517977997707,
            "rating_q025": 1319.6726704561013
        },
        "amazon-nova-experimental-chat-10-09": {
            "rating": 1345.513008793019,
            "rating_q975": 1381.8829808319158,
            "rating_q025": 1309.1430367541222
        },
        "mistral-small-2506": {
            "rating": 1343.0225828249245,
            "rating_q975": 1362.7918424210352,
            "rating_q025": 1323.2533232288138
        },
        "o1-mini": {
            "rating": 1341.5329872873403,
            "rating_q975": 1350.8624002580373,
            "rating_q025": 1332.2035743166434
        },
        "glm-4.5v": {
            "rating": 1339.8682469770984,
            "rating_q975": 1383.0356647362385,
            "rating_q025": 1296.7008292179582
        },
        "gemini-advanced-0514": {
            "rating": 1337.9634090021314,
            "rating_q975": 1348.2963231970634,
            "rating_q025": 1327.6304948071993
        },
        "claude-3-5-sonnet-20240620": {
            "rating": 1336.7348547985519,
            "rating_q975": 1345.1411401592989,
            "rating_q025": 1328.3285694378048
        },
        "glm-4-plus": {
            "rating": 1333.5815163647835,
            "rating_q975": 1345.8376121374663,
            "rating_q025": 1321.3254205921007
        },
        "grok-2-2024-08-13": {
            "rating": 1332.4938965275103,
            "rating_q975": 1341.0542950376396,
            "rating_q025": 1323.933498017381
        },
        "gemini-1.5-pro-001": {
            "rating": 1332.292576657756,
            "rating_q975": 1341.1621560324913,
            "rating_q025": 1323.4229972830205
        },
        "gpt-4o-2024-05-13": {
            "rating": 1330.1565521969783,
            "rating_q975": 1337.6408039940807,
            "rating_q025": 1322.672300399876
        },
        "athene-v2-chat": {
            "rating": 1326.3894307250425,
            "rating_q975": 1339.8118428112023,
            "rating_q025": 1312.9670186388828
        },
        "llama-4-maverick-17b-128e-instruct": {
            "rating": 1325.396473907082,
            "rating_q975": 1338.883196121225,
            "rating_q025": 1311.9097516929392
        },
        "deepseek-v2.5": {
            "rating": 1322.6457712061858,
            "rating_q975": 1335.071144405607,
            "rating_q025": 1310.2203980067648
        },
        "qwen2.5-plus-1127": {
            "rating": 1322.4145985257364,
            "rating_q975": 1344.7393590944055,
            "rating_q025": 1300.0898379570674
        },
        "gemma-3n-e4b-it": {
            "rating": 1321.2567033308922,
            "rating_q975": 1338.9279996892833,
            "rating_q025": 1303.585406972501
        },
        "gpt-4o-2024-08-06": {
            "rating": 1320.6152655065985,
            "rating_q975": 1330.4185785673221,
            "rating_q025": 1310.8119524458748
        },
        "gemini-1.5-flash-002": {
            "rating": 1317.9099043446993,
            "rating_q975": 1328.6182545918286,
            "rating_q025": 1307.20155409757
        },
        "claude-3-opus-20240229": {
            "rating": 1317.438192867798,
            "rating_q975": 1324.3101761024125,
            "rating_q025": 1310.5662096331837
        },
        "qwen2.5-72b-instruct": {
            "rating": 1314.125574760026,
            "rating_q975": 1324.3341302939173,
            "rating_q025": 1303.9170192261347
        },
        "llama-3.1-405b-instruct-bf16": {
            "rating": 1314.107680106366,
            "rating_q975": 1324.4989136193362,
            "rating_q025": 1303.7164465933956
        },
        "gpt-4.1-nano-2025-04-14": {
            "rating": 1309.7240323402016,
            "rating_q975": 1345.896811922742,
            "rating_q025": 1273.5512527576611
        },
        "gpt-4-turbo-2024-04-09": {
            "rating": 1308.233920365211,
            "rating_q975": 1316.6213549760803,
            "rating_q025": 1299.8464857543415
        },
        "gpt-4-1106-preview": {
            "rating": 1307.5475390506022,
            "rating_q975": 1316.5633770335708,
            "rating_q025": 1298.5317010676335
        },
        "gpt-4o-mini-2024-07-18": {
            "rating": 1306.7629189806887,
            "rating_q975": 1314.9538564950199,
            "rating_q025": 1298.5719814663576
        },
        "llama-3.1-405b-instruct-fp8": {
            "rating": 1306.7555134184145,
            "rating_q975": 1315.516664459766,
            "rating_q025": 1297.994362377063
        },
        "claude-3-5-haiku-20241022": {
            "rating": 1305.6260229410275,
            "rating_q975": 1315.2147624474533,
            "rating_q025": 1296.0372834346017
        },
        "gpt-4-0125-preview": {
            "rating": 1303.8682012464942,
            "rating_q975": 1312.656662664845,
            "rating_q025": 1295.0797398281434
        },
        "hunyuan-large-vision": {
            "rating": 1303.1323141157227,
            "rating_q975": 1340.659254949507,
            "rating_q025": 1265.6053732819385
        },
        "llama-4-scout-17b-16e-instruct": {
            "rating": 1303.1111140335888,
            "rating_q975": 1318.8139800320162,
            "rating_q025": 1287.4082480351615
        },
        "qwen-max-0919": {
            "rating": 1302.777203661958,
            "rating_q975": 1317.7041907914606,
            "rating_q025": 1287.8502165324555
        },
        "grok-2-mini-2024-08-13": {
            "rating": 1302.6807728269162,
            "rating_q975": 1311.7647394678208,
            "rating_q025": 1293.5968061860115
        },
        "llama-3.3-nemotron-49b-super-v1": {
            "rating": 1301.9338448898022,
            "rating_q975": 1340.2533609211312,
            "rating_q025": 1263.6143288584733
        },
        "reka-core-20240904": {
            "rating": 1298.0225864137637,
            "rating_q975": 1320.6197846066204,
            "rating_q025": 1275.425388220907
        },
        "glm-4-0520": {
            "rating": 1296.7305451587424,
            "rating_q975": 1313.2079578059972,
            "rating_q025": 1280.2531325114876
        },
        "llama-3.1-nemotron-70b-instruct": {
            "rating": 1296.237323404452,
            "rating_q975": 1317.3755153818483,
            "rating_q025": 1275.0991314270555
        },
        "mistral-large-2407": {
            "rating": 1295.5771318214686,
            "rating_q975": 1305.347498700257,
            "rating_q025": 1285.8067649426803
        },
        "qwen2-72b-instruct": {
            "rating": 1291.9317610450673,
            "rating_q975": 1302.6389577808482,
            "rating_q025": 1281.2245643092865
        },
        "athene-70b-0725": {
            "rating": 1291.4096386715044,
            "rating_q975": 1305.4979239972645,
            "rating_q025": 1277.3213533457442
        },
        "llama-3.1-tulu-3-70b": {
            "rating": 1291.3893043700007,
            "rating_q975": 1327.431525780713,
            "rating_q025": 1255.3470829592884
        },
        "mistral-large-2411": {
            "rating": 1290.190860323176,
            "rating_q975": 1303.1264376535937,
            "rating_q025": 1277.255282992758
        },
        "reka-flash-20240904": {
            "rating": 1290.1686049558764,
            "rating_q975": 1312.9949592912467,
            "rating_q025": 1267.342250620506
        },
        "gemma-2-27b-it": {
            "rating": 1289.4288328624739,
            "rating_q975": 1297.2102079234296,
            "rating_q025": 1281.6474578015182
        },
        "command-r-plus-08-2024": {
            "rating": 1286.8437958486693,
            "rating_q975": 1305.9902630312372,
            "rating_q025": 1267.6973286661014
        },
        "gemini-1.5-flash-001": {
            "rating": 1286.6046712721766,
            "rating_q975": 1295.8532895703656,
            "rating_q025": 1277.3560529739875
        },
        "hunyuan-standard-256k": {
            "rating": 1285.262516147067,
            "rating_q975": 1318.2483625467962,
            "rating_q025": 1252.2766697473376
        },
        "llama-3.3-70b-instruct": {
            "rating": 1284.5229944750981,
            "rating_q975": 1294.8993484327239,
            "rating_q025": 1274.1466405174724
        },
        "mistral-small-3.1-24b-instruct-2503": {
            "rating": 1284.0238232863094,
            "rating_q975": 1299.6744686837649,
            "rating_q025": 1268.373177888854
        },
        "amazon-nova-pro-v1.0": {
            "rating": 1282.763065407099,
            "rating_q975": 1296.5668959241564,
            "rating_q025": 1268.9592348900417
        },
        "gemma-2-9b-it-simpo": {
            "rating": 1281.328898938732,
            "rating_q975": 1301.901148045128,
            "rating_q025": 1260.756649832336
        },
        "deepseek-coder-v2": {
            "rating": 1280.847767676439,
            "rating_q975": 1295.1969011485141,
            "rating_q025": 1266.4986342043637
        },
        "nemotron-4-340b-instruct": {
            "rating": 1279.0707323616102,
            "rating_q975": 1291.6541247292048,
            "rating_q025": 1266.4873399940157
        },
        "gpt-4-0314": {
            "rating": 1278.376584996547,
            "rating_q975": 1289.3457678407688,
            "rating_q025": 1267.4074021523254
        },
        "magistral-medium-2506": {
            "rating": 1276.4192333119972,
            "rating_q975": 1304.1680823173956,
            "rating_q025": 1248.6703843065989
        },
        "qwen1.5-72b-chat": {
            "rating": 1274.6848152195776,
            "rating_q975": 1286.1737304648937,
            "rating_q025": 1263.1958999742615
        },
        "qwen2.5-coder-32b-instruct": {
            "rating": 1271.3737802998257,
            "rating_q975": 1295.8877605548048,
            "rating_q025": 1246.8598000448467
        },
        "qwen1.5-110b-chat": {
            "rating": 1271.2781551235275,
            "rating_q975": 1283.7518880559278,
            "rating_q025": 1258.8044221911273
        },
        "claude-3-sonnet-20240229": {
            "rating": 1268.8003551792408,
            "rating_q975": 1277.0732085759148,
            "rating_q025": 1260.5275017825668
        },
        "llama-3.1-70b-instruct": {
            "rating": 1268.6725409289825,
            "rating_q975": 1277.626783472936,
            "rating_q025": 1259.718298385029
        },
        "llama-3.1-nemotron-51b-instruct": {
            "rating": 1268.597981497595,
            "rating_q975": 1296.128490485392,
            "rating_q025": 1241.0674725097979
        },
        "jamba-1.5-large": {
            "rating": 1266.716248871774,
            "rating_q975": 1288.177665467099,
            "rating_q025": 1245.2548322764492
        },
        "yi-1.5-34b-chat": {
            "rating": 1266.6405945225868,
            "rating_q975": 1278.753168800722,
            "rating_q025": 1254.5280202444515
        },
        "gemini-1.5-flash-8b-001": {
            "rating": 1265.8900621207285,
            "rating_q975": 1276.8235047656383,
            "rating_q025": 1254.9566194758188
        },
        "amazon-nova-lite-v1.0": {
            "rating": 1264.8505505520407,
            "rating_q975": 1280.4314489428155,
            "rating_q025": 1249.2696521612659
        },
        "c4ai-aya-expanse-32b": {
            "rating": 1263.2930169665694,
            "rating_q975": 1275.0983223583034,
            "rating_q025": 1251.4877115748354
        },
        "command-r-plus": {
            "rating": 1262.181791031663,
            "rating_q975": 1271.0766905383814,
            "rating_q025": 1253.2868915249444
        },
        "phi-4": {
            "rating": 1260.9715938920008,
            "rating_q975": 1276.0170021361564,
            "rating_q025": 1245.9261856478452
        },
        "qwen1.5-32b-chat": {
            "rating": 1259.4949133269538,
            "rating_q975": 1272.1242641204342,
            "rating_q025": 1246.8655625334734
        },
        "mistral-small-24b-instruct-2501": {
            "rating": 1257.4241371816074,
            "rating_q975": 1274.6383686026263,
            "rating_q025": 1240.2099057605885
        },
        "command-r-08-2024": {
            "rating": 1254.5508673313238,
            "rating_q975": 1274.3524047341791,
            "rating_q025": 1234.7493299284686
        },
        "gemma-2-9b-it": {
            "rating": 1254.3494182527174,
            "rating_q975": 1263.1284674786205,
            "rating_q025": 1245.5703690268144
        },
        "amazon-nova-micro-v1.0": {
            "rating": 1254.3383949514905,
            "rating_q975": 1270.0444503991123,
            "rating_q025": 1238.6323395038687
        },
        "ministral-8b-2410": {
            "rating": 1247.3441347185772,
            "rating_q975": 1272.5570886722505,
            "rating_q025": 1222.1311807649038
        },
        "gpt-4-0613": {
            "rating": 1247.3232253027084,
            "rating_q975": 1256.8550880463365,
            "rating_q025": 1237.7913625590802
        },
        "yi-34b-chat": {
            "rating": 1243.8503444737007,
            "rating_q975": 1261.5333182756203,
            "rating_q025": 1226.167370671781
        },
        "internlm2_5-20b-chat": {
            "rating": 1242.6086283693367,
            "rating_q975": 1260.813993941341,
            "rating_q025": 1224.4032627973322
        },
        "claude-3-haiku-20240307": {
            "rating": 1240.773412687735,
            "rating_q975": 1248.6700847097936,
            "rating_q025": 1232.8767406656762
        },
        "olmo-2-0325-32b-instruct": {
            "rating": 1235.5543645858113,
            "rating_q975": 1271.2948679058338,
            "rating_q025": 1199.8138612657888
        },
        "qwen1.5-14b-chat": {
            "rating": 1235.4217295022795,
            "rating_q975": 1248.6508599478273,
            "rating_q025": 1222.1925990567318
        },
        "qwq-32b-preview": {
            "rating": 1234.7788023755402,
            "rating_q975": 1274.150469279573,
            "rating_q025": 1195.4071354715074
        },
        "command-r": {
            "rating": 1231.6058400764452,
            "rating_q975": 1241.5233993338445,
            "rating_q025": 1221.688280819046
        },
        "reka-flash-21b-20240226-online": {
            "rating": 1228.1104205179045,
            "rating_q975": 1242.7265580540766,
            "rating_q025": 1213.4942829817323
        },
        "c4ai-aya-expanse-8b": {
            "rating": 1228.0248270039024,
            "rating_q975": 1250.9982269981697,
            "rating_q025": 1205.051427009635
        },
        "deepseek-llm-67b-chat": {
            "rating": 1224.6649104299902,
            "rating_q975": 1265.9252335863648,
            "rating_q025": 1183.4045872736156
        },
        "gemini-pro-dev-api": {
            "rating": 1224.2280381430182,
            "rating_q975": 1241.3295921911615,
            "rating_q025": 1207.126484094875
        },
        "qwen1.5-7b-chat": {
            "rating": 1218.6658710306717,
            "rating_q975": 1246.9393053549643,
            "rating_q025": 1190.3924367063792
        },
        "reka-flash-21b-20240226": {
            "rating": 1218.210266289217,
            "rating_q975": 1231.1626693404696,
            "rating_q025": 1205.2578632379646
        },
        "llama-3.1-tulu-3-8b": {
            "rating": 1214.9257819195386,
            "rating_q975": 1251.2667471361474,
            "rating_q025": 1178.5848167029299
        },
        "granite-3.1-8b-instruct": {
            "rating": 1212.1287884662365,
            "rating_q975": 1251.2837902758622,
            "rating_q025": 1172.9737866566109
        },
        "gemini-pro": {
            "rating": 1208.9397830698254,
            "rating_q975": 1246.9109577352053,
            "rating_q025": 1170.9686084044454
        },
        "jamba-1.5-mini": {
            "rating": 1208.8511549781097,
            "rating_q975": 1230.155137184963,
            "rating_q025": 1187.5471727712563
        },
        "mixtral-8x22b-instruct-v0.1": {
            "rating": 1203.640061603875,
            "rating_q975": 1213.9098601745416,
            "rating_q025": 1193.3702630332084
        },
        "mistral-large-2402": {
            "rating": 1201.7406251344983,
            "rating_q975": 1211.591560457492,
            "rating_q025": 1191.8896898115045
        },
        "granite-3.1-2b-instruct": {
            "rating": 1201.1094332157486,
            "rating_q975": 1239.2866171451844,
            "rating_q025": 1162.9322492863128
        },
        "gpt-3.5-turbo-0125": {
            "rating": 1200.1983375915024,
            "rating_q975": 1209.6976569140538,
            "rating_q025": 1190.699018268951
        },
        "llama-3.1-8b-instruct": {
            "rating": 1196.2305077255153,
            "rating_q975": 1205.9410212552732,
            "rating_q025": 1186.5199941957574
        },
        "qwen-14b-chat": {
            "rating": 1195.3427769742352,
            "rating_q975": 1238.1329473509595,
            "rating_q025": 1152.552606597511
        },
        "llama-3-70b-instruct": {
            "rating": 1194.6234968424228,
            "rating_q975": 1202.6629506138559,
            "rating_q025": 1186.5840430709898
        },
        "phi-3-medium-4k-instruct": {
            "rating": 1193.9100727341201,
            "rating_q975": 1206.0767239439917,
            "rating_q025": 1181.7434215242486
        },
        "mistral-medium": {
            "rating": 1189.937832102735,
            "rating_q975": 1202.8712196496433,
            "rating_q025": 1177.0044445558267
        },
        "gemma-2-2b-it": {
            "rating": 1189.9268526995133,
            "rating_q975": 1200.1896800164293,
            "rating_q025": 1179.6640253825974
        },
        "zephyr-orpo-141b-A35b-v0.1": {
            "rating": 1179.1943719516712,
            "rating_q975": 1201.4907213005179,
            "rating_q025": 1156.8980226028245
        },
        "dbrx-instruct-preview": {
            "rating": 1171.8567784319748,
            "rating_q975": 1184.233710567976,
            "rating_q025": 1159.4798462959736
        },
        "openchat-3.5-0106": {
            "rating": 1171.6945532005857,
            "rating_q975": 1188.7234954422117,
            "rating_q025": 1154.6656109589596
        },
        "openchat-3.5": {
            "rating": 1171.3084959804576,
            "rating_q975": 1203.1583324268283,
            "rating_q025": 1139.4586595340868
        },
        "starling-lm-7b-beta": {
            "rating": 1171.2769611097524,
            "rating_q975": 1185.6416995187958,
            "rating_q025": 1156.912222700709
        },
        "snowflake-arctic-instruct": {
            "rating": 1170.4977797541076,
            "rating_q975": 1183.6326433583472,
            "rating_q025": 1157.362916149868
        },
        "granite-3.0-2b-instruct": {
            "rating": 1168.3152417974518,
            "rating_q975": 1191.375177051903,
            "rating_q025": 1145.2553065430006
        },
        "gemma-1.1-7b-it": {
            "rating": 1166.1287931911256,
            "rating_q975": 1178.0548928790652,
            "rating_q025": 1154.202693503186
        },
        "granite-3.0-8b-instruct": {
            "rating": 1162.7449551613163,
            "rating_q975": 1185.9699547642244,
            "rating_q025": 1139.5199555584081
        },
        "chatglm3-6b": {
            "rating": 1160.858489331437,
            "rating_q975": 1203.6172243295566,
            "rating_q025": 1118.0997543333176
        },
        "llama-3-8b-instruct": {
            "rating": 1158.6387541692275,
            "rating_q975": 1167.407837870418,
            "rating_q025": 1149.869670468037
        },
        "chatglm-6b": {
            "rating": 1156.0853296467249,
            "rating_q975": 1194.9943632009297,
            "rating_q025": 1117.17629609252
        },
        "gpt-3.5-turbo-1106": {
            "rating": 1154.32327282678,
            "rating_q975": 1178.4279541174674,
            "rating_q025": 1130.2185915360928
        },
        "wizardlm-70b": {
            "rating": 1151.582686419728,
            "rating_q975": 1183.7886143116093,
            "rating_q025": 1119.3767585278465
        },
        "mixtral-8x7b-instruct-v0.1": {
            "rating": 1147.509407842957,
            "rating_q975": 1157.1096405015412,
            "rating_q025": 1137.9091751843728
        },
        "phi-3-small-8k-instruct": {
            "rating": 1143.9546664531401,
            "rating_q975": 1157.3790786824804,
            "rating_q025": 1130.5302542237998
        },
        "qwen1.5-4b-chat": {
            "rating": 1138.214986671747,
            "rating_q975": 1157.7045637694744,
            "rating_q025": 1118.7254095740197
        },
        "vicuna-13b": {
            "rating": 1138.134912917617,
            "rating_q975": 1157.3113254031216,
            "rating_q025": 1118.9585004321123
        },
        "starling-lm-7b-alpha": {
            "rating": 1130.2709483599028,
            "rating_q975": 1151.6749011442248,
            "rating_q025": 1108.8669955755809
        },
        "gemma-7b-it": {
            "rating": 1130.2362061397876,
            "rating_q975": 1149.6525680909979,
            "rating_q025": 1110.8198441885772
        },
        "gemma-1.1-2b-it": {
            "rating": 1128.9224944500697,
            "rating_q975": 1146.3343351596163,
            "rating_q025": 1111.5106537405231
        },
        "vicuna-33b": {
            "rating": 1127.15283804838,
            "rating_q975": 1143.7608826566357,
            "rating_q025": 1110.5447934401245
        },
        "llama-3.2-3b-instruct": {
            "rating": 1124.2510048235151,
            "rating_q975": 1149.06857776386,
            "rating_q025": 1099.4334318831702
        },
        "phi-3-mini-128k-instruct": {
            "rating": 1120.793926228493,
            "rating_q975": 1136.1735045072157,
            "rating_q025": 1105.4143479497704
        },
        "phi-3-mini-4k-instruct-june-2024": {
            "rating": 1118.0621278764386,
            "rating_q975": 1135.39360323235,
            "rating_q025": 1100.7306525205272
        },
        "wizardlm-13b": {
            "rating": 1114.0504207345023,
            "rating_q975": 1147.1932580584094,
            "rating_q025": 1080.9075834105952
        },
        "openhermes-2.5-mistral-7b": {
            "rating": 1109.2563191279528,
            "rating_q975": 1151.4720661536603,
            "rating_q025": 1067.0405721022453
        },
        "phi-3-mini-4k-instruct": {
            "rating": 1107.2987415505422,
            "rating_q975": 1121.15594012873,
            "rating_q025": 1093.4415429723545
        },
        "mistral-7b-instruct-v0.2": {
            "rating": 1094.398906415117,
            "rating_q975": 1109.0088784651086,
            "rating_q025": 1079.7889343651252
        },
        "gemma-2b-it": {
            "rating": 1093.7658789577715,
            "rating_q975": 1118.6510536292274,
            "rating_q025": 1068.8807042863157
        },
        "tulu-2-dpo-70b": {
            "rating": 1091.9489115258214,
            "rating_q975": 1126.9856499496643,
            "rating_q025": 1056.9121731019784
        },
        "llama-2-13b-chat": {
            "rating": 1084.3018928271676,
            "rating_q975": 1102.823966162229,
            "rating_q025": 1065.7798194921063
        },
        "mpt-7b-chat": {
            "rating": 1084.2621897918532,
            "rating_q975": 1126.0851397427948,
            "rating_q025": 1042.4392398409116
        },
        "vicuna-7b": {
            "rating": 1078.7536655523625,
            "rating_q975": 1112.339481007745,
            "rating_q025": 1045.16785009698
        },
        "codellama-34b-instruct": {
            "rating": 1076.4383649090892,
            "rating_q975": 1114.7980962419103,
            "rating_q025": 1038.078633576268
        },
        "llama-2-70b-chat": {
            "rating": 1075.617434769083,
            "rating_q975": 1088.4356394752754,
            "rating_q025": 1062.7992300628907
        },
        "olmo-7b-instruct": {
            "rating": 1073.1994506394344,
            "rating_q975": 1096.2183957096615,
            "rating_q025": 1050.1805055692073
        },
        "palm-2": {
            "rating": 1059.7770502655549,
            "rating_q975": 1093.9274387927455,
            "rating_q025": 1025.6266617383642
        },
        "llama-2-7b-chat": {
            "rating": 1056.0261621527582,
            "rating_q975": 1075.4423753565943,
            "rating_q025": 1036.609948948922
        },
        "zephyr-7b-beta": {
            "rating": 1044.3858252176533,
            "rating_q975": 1075.1429204368271,
            "rating_q025": 1013.6287299984796
        },
        "llama-3.2-1b-instruct": {
            "rating": 1041.446831516628,
            "rating_q975": 1069.2363737118753,
            "rating_q025": 1013.6572893213805
        },
        "mistral-7b-instruct": {
            "rating": 1037.170901185853,
            "rating_q975": 1070.6942250207192,
            "rating_q025": 1003.6475773509866
        },
        "RWKV-4-Raven-14B": {
            "rating": 1016.1429058745292,
            "rating_q975": 1056.373273170077,
            "rating_q025": 975.9125385789815
        },
        "koala-13b": {
            "rating": 985.5376261410206,
            "rating_q975": 1018.5504498877657,
            "rating_q025": 952.5248023942755
        },
        "dolly-v2-12b": {
            "rating": 977.1599215635883,
            "rating_q975": 1024.7752441748398,
            "rating_q025": 929.5445989523369
        },
        "oasst-pythia-12b": {
            "rating": 927.5997934451985,
            "rating_q975": 962.3747952202377,
            "rating_q025": 892.8247916701594
        },
        "fastchat-t5-3b": {
            "rating": 925.2579040052173,
            "rating_q975": 966.810273341561,
            "rating_q025": 883.7055346688735
        },
        "alpaca-13b": {
            "rating": 902.1767899001122,
            "rating_q975": 943.9454591839558,
            "rating_q025": 860.4081206162687
        }
    },
    "coding": {
        "claude-sonnet-4-5-20250929-thinking-32k": {
            "rating": 1526.0171237593183,
            "rating_q975": 1537.8631768112311,
            "rating_q025": 1514.1710707074055
        },
        "claude-opus-4-1-20250805-thinking-16k": {
            "rating": 1515.6339263333116,
            "rating_q975": 1524.3793900396643,
            "rating_q025": 1506.888462626959
        },
        "claude-opus-4-1-20250805": {
            "rating": 1500.8676517128756,
            "rating_q975": 1508.613937074861,
            "rating_q025": 1493.1213663508902
        },
        "claude-opus-4-20250514-thinking-16k": {
            "rating": 1495.4024682032748,
            "rating_q975": 1503.3319363734433,
            "rating_q025": 1487.4730000331062
        },
        "claude-sonnet-4-5-20250929": {
            "rating": 1485.2827323056613,
            "rating_q975": 1501.5834354178653,
            "rating_q025": 1468.9820291934573
        },
        "qwen3-max-preview": {
            "rating": 1483.1258197858629,
            "rating_q975": 1492.2663315003297,
            "rating_q025": 1473.985308071396
        },
        "claude-haiku-4-5-20251001": {
            "rating": 1480.721017555261,
            "rating_q975": 1493.3671862902847,
            "rating_q025": 1468.074848820237
        },
        "qwen3-max-2025-09-23": {
            "rating": 1474.3124792581953,
            "rating_q975": 1487.3461488831065,
            "rating_q025": 1461.278809633284
        },
        "glm-4.6": {
            "rating": 1473.9565171253307,
            "rating_q975": 1486.9179314599303,
            "rating_q025": 1460.9951027907312
        },
        "longcat-flash-chat": {
            "rating": 1473.9346651801136,
            "rating_q975": 1486.6628849449337,
            "rating_q025": 1461.2064454152935
        },
        "deepseek-v3.2-exp-thinking": {
            "rating": 1471.0978361850896,
            "rating_q975": 1484.5201011885447,
            "rating_q025": 1457.6755711816345
        },
        "gpt-5-high": {
            "rating": 1470.6224272345028,
            "rating_q975": 1479.3061977204184,
            "rating_q025": 1461.9386567485872
        },
        "gemini-2.5-pro": {
            "rating": 1470.164365903779,
            "rating_q975": 1477.005929268467,
            "rating_q025": 1463.322802539091
        },
        "claude-sonnet-4-20250514-thinking-32k": {
            "rating": 1469.2956180089536,
            "rating_q975": 1477.1948478666175,
            "rating_q025": 1461.3963881512898
        },
        "qwen3-235b-a22b-instruct-2507": {
            "rating": 1468.6621347315995,
            "rating_q975": 1476.460634992125,
            "rating_q025": 1460.863634471074
        },
        "kimi-k2-0905-preview": {
            "rating": 1465.2178753565418,
            "rating_q975": 1478.520791368616,
            "rating_q025": 1451.9149593444674
        },
        "qwen3-vl-235b-a22b-instruct": {
            "rating": 1464.7113895114146,
            "rating_q975": 1478.3911687765471,
            "rating_q025": 1451.031610246282
        },
        "chatgpt-4o-latest-20250326": {
            "rating": 1462.9790313832273,
            "rating_q975": 1469.9542513539143,
            "rating_q025": 1456.0038114125402
        },
        "deepseek-r1-0528": {
            "rating": 1462.5554759049196,
            "rating_q975": 1473.8595440940842,
            "rating_q025": 1451.251407715755
        },
        "claude-opus-4-20250514": {
            "rating": 1461.1394650789584,
            "rating_q975": 1468.5226268292342,
            "rating_q025": 1453.7563033286826
        },
        "gpt-5-chat": {
            "rating": 1459.088494333974,
            "rating_q975": 1467.6042198684872,
            "rating_q025": 1450.5727687994608
        },
        "deepseek-v3.1-terminus-thinking": {
            "rating": 1458.409946500413,
            "rating_q975": 1482.1190218275253,
            "rating_q025": 1434.7008711733008
        },
        "o3-2025-04-16": {
            "rating": 1457.5329535495853,
            "rating_q975": 1464.1284732032177,
            "rating_q025": 1450.9374338959528
        },
        "gpt-4.5-preview-2025-02-27": {
            "rating": 1456.3954708808888,
            "rating_q975": 1469.3542946799116,
            "rating_q025": 1443.4366470818659
        },
        "deepseek-v3.1-thinking": {
            "rating": 1456.0122258396846,
            "rating_q975": 1469.552172559501,
            "rating_q025": 1442.472279119868
        },
        "kimi-k2-0711-preview": {
            "rating": 1455.9476314041426,
            "rating_q975": 1464.5612031771584,
            "rating_q025": 1447.3340596311268
        },
        "gpt-4.1-2025-04-14": {
            "rating": 1455.700824031441,
            "rating_q975": 1462.755786533531,
            "rating_q025": 1448.6458615293511
        },
        "glm-4.5": {
            "rating": 1455.337739639798,
            "rating_q975": 1464.2885942347787,
            "rating_q025": 1446.3868850448173
        },
        "qwen3-vl-235b-a22b-thinking": {
            "rating": 1454.314740155659,
            "rating_q975": 1468.7644593194116,
            "rating_q025": 1439.8650209919062
        },
        "grok-4-fast": {
            "rating": 1454.1956112052264,
            "rating_q975": 1470.619615256385,
            "rating_q025": 1437.7716071540679
        },
        "mistral-medium-2508": {
            "rating": 1453.375308499029,
            "rating_q975": 1461.5948671470544,
            "rating_q025": 1445.1557498510035
        },
        "qwen3-coder-480b-a35b-instruct": {
            "rating": 1452.9903510417903,
            "rating_q975": 1462.2719270061543,
            "rating_q025": 1443.7087750774263
        },
        "qwen3-next-80b-a3b-instruct": {
            "rating": 1450.688252280532,
            "rating_q975": 1460.3430992181966,
            "rating_q025": 1441.0334053428674
        },
        "claude-3-7-sonnet-20250219-thinking-32k": {
            "rating": 1448.6440533850143,
            "rating_q975": 1456.5983107634909,
            "rating_q025": 1440.6897960065378
        },
        "deepseek-v3.1": {
            "rating": 1446.695985760891,
            "rating_q975": 1458.391982709763,
            "rating_q025": 1434.9999888120192
        },
        "claude-sonnet-4-20250514": {
            "rating": 1446.160088328771,
            "rating_q975": 1453.6520256436265,
            "rating_q025": 1438.6681510139156
        },
        "qwen3-235b-a22b-no-thinking": {
            "rating": 1443.2536242942608,
            "rating_q975": 1450.93577564394,
            "rating_q025": 1435.5714729445817
        },
        "deepseek-r1": {
            "rating": 1442.8288776425659,
            "rating_q975": 1454.5170460390884,
            "rating_q025": 1431.1407092460433
        },
        "grok-3-preview-02-24": {
            "rating": 1441.635183050728,
            "rating_q975": 1449.9913357619207,
            "rating_q025": 1433.2790303395354
        },
        "qwen3-235b-a22b-thinking-2507": {
            "rating": 1441.0357137797416,
            "rating_q975": 1455.7343673515145,
            "rating_q025": 1426.3370602079688
        },
        "deepseek-v3.1-terminus": {
            "rating": 1437.8959943989519,
            "rating_q975": 1458.8015580359395,
            "rating_q025": 1416.9904307619643
        },
        "qwen3-30b-a3b-instruct-2507": {
            "rating": 1437.8741694096495,
            "rating_q975": 1446.9021522086653,
            "rating_q025": 1428.8461866106338
        },
        "grok-4-0709": {
            "rating": 1434.9345080637506,
            "rating_q975": 1442.5656519281504,
            "rating_q025": 1427.3033641993509
        },
        "gpt-4.1-mini-2025-04-14": {
            "rating": 1432.0413294832942,
            "rating_q975": 1439.6303263976015,
            "rating_q025": 1424.452332568987
        },
        "o3-mini-high": {
            "rating": 1431.6460815200662,
            "rating_q975": 1443.086662876715,
            "rating_q025": 1420.2055001634174
        },
        "qwen3-235b-a22b": {
            "rating": 1431.51501488789,
            "rating_q975": 1440.5997272052143,
            "rating_q025": 1422.4303025705656
        },
        "claude-3-5-sonnet-20241022": {
            "rating": 1431.4009408226036,
            "rating_q975": 1436.7341639231938,
            "rating_q025": 1426.0677177220134
        },
        "o1-2024-12-17": {
            "rating": 1429.987830672881,
            "rating_q975": 1439.3801234996686,
            "rating_q025": 1420.5955378460935
        },
        "mai-1-preview": {
            "rating": 1429.7224804824002,
            "rating_q975": 1440.855734492316,
            "rating_q025": 1418.5892264724844
        },
        "mistral-medium-2505": {
            "rating": 1429.448270299954,
            "rating_q975": 1437.54019579431,
            "rating_q025": 1421.356344805598
        },
        "o4-mini-2025-04-16": {
            "rating": 1429.2859771430406,
            "rating_q975": 1436.3061135349283,
            "rating_q025": 1422.2658407511528
        },
        "gpt-5-mini-high": {
            "rating": 1428.2329370070147,
            "rating_q975": 1437.465249508364,
            "rating_q025": 1419.0006245056654
        },
        "glm-4.5-air": {
            "rating": 1427.0121256136285,
            "rating_q975": 1435.292828373804,
            "rating_q025": 1418.731422853453
        },
        "gemini-2.5-flash-preview-09-2025": {
            "rating": 1425.750690128875,
            "rating_q975": 1436.8801102659393,
            "rating_q025": 1414.6212699918108
        },
        "deepseek-v3-0324": {
            "rating": 1424.9790652061588,
            "rating_q975": 1431.8997503988971,
            "rating_q025": 1418.0583800134204
        },
        "qwen3-next-80b-a3b-thinking": {
            "rating": 1422.5590585576604,
            "rating_q975": 1434.1104881390888,
            "rating_q025": 1411.007628976232
        },
        "minimax-m1": {
            "rating": 1415.9223564284548,
            "rating_q975": 1423.6665028753064,
            "rating_q025": 1408.1782099816032
        },
        "gemini-2.5-flash": {
            "rating": 1414.791447484151,
            "rating_q975": 1421.5885552364657,
            "rating_q025": 1407.9943397318361
        },
        "o1-preview": {
            "rating": 1414.4320084146023,
            "rating_q975": 1423.5120387805764,
            "rating_q025": 1405.351978048628
        },
        "o3-mini": {
            "rating": 1413.1927758491718,
            "rating_q975": 1419.5881131870449,
            "rating_q025": 1406.7974385112987
        },
        "ling-flash-2.0": {
            "rating": 1412.887909353097,
            "rating_q975": 1427.6112332121143,
            "rating_q025": 1398.1645854940798
        },
        "mistral-small-2506": {
            "rating": 1411.2312641942224,
            "rating_q975": 1421.3411423254843,
            "rating_q025": 1401.1213860629605
        },
        "qwen3-32b": {
            "rating": 1404.7929956415376,
            "rating_q975": 1429.4362674746537,
            "rating_q025": 1380.1497238084214
        },
        "step-3": {
            "rating": 1403.5035069317037,
            "rating_q975": 1420.1677907289427,
            "rating_q025": 1386.8392231344646
        },
        "glm-4.5v": {
            "rating": 1401.8482229503934,
            "rating_q975": 1420.4661457714396,
            "rating_q025": 1383.2303001293471
        },
        "amazon-nova-experimental-chat-10-09": {
            "rating": 1401.6796429109518,
            "rating_q975": 1417.469614502488,
            "rating_q025": 1385.8896713194156
        },
        "qwen2.5-max": {
            "rating": 1400.219868788358,
            "rating_q975": 1408.3024498094444,
            "rating_q025": 1392.1372877672718
        },
        "hunyuan-turbos-20250226": {
            "rating": 1397.0348819802177,
            "rating_q975": 1427.836633796237,
            "rating_q025": 1366.2331301641984
        },
        "hunyuan-t1-20250711": {
            "rating": 1395.9222681898561,
            "rating_q975": 1415.906833961607,
            "rating_q025": 1375.9377024181053
        },
        "claude-3-5-sonnet-20240620": {
            "rating": 1395.0314612932793,
            "rating_q975": 1401.8216121094836,
            "rating_q025": 1388.241310477075
        },
        "gemini-2.5-flash-lite-preview-09-2025-no-thinking": {
            "rating": 1394.6116691417576,
            "rating_q975": 1405.6614613568545,
            "rating_q025": 1383.5618769266607
        },
        "nvidia-llama-3.3-nemotron-super-49b-v1.5": {
            "rating": 1394.5520648391587,
            "rating_q975": 1416.2461750680231,
            "rating_q025": 1372.8579546102942
        },
        "hunyuan-turbos-20250416": {
            "rating": 1392.5811831356446,
            "rating_q975": 1406.403307199255,
            "rating_q025": 1378.759059072034
        },
        "ring-flash-2.0": {
            "rating": 1390.940369267265,
            "rating_q975": 1405.721974288267,
            "rating_q025": 1376.158764246263
        },
        "llama-3.1-nemotron-ultra-253b-v1": {
            "rating": 1389.4057326271063,
            "rating_q975": 1419.544541379246,
            "rating_q025": 1359.2669238749666
        },
        "command-a-03-2025": {
            "rating": 1387.4384811410207,
            "rating_q975": 1393.980287485556,
            "rating_q025": 1380.8966747964855
        },
        "grok-3-mini-high": {
            "rating": 1387.0756328970372,
            "rating_q975": 1397.346515442749,
            "rating_q025": 1376.8047503513253
        },
        "o1-mini": {
            "rating": 1385.3605040115283,
            "rating_q975": 1392.5189274820598,
            "rating_q025": 1378.2020805409968
        },
        "deepseek-v3": {
            "rating": 1385.3257801363388,
            "rating_q975": 1395.228785963333,
            "rating_q025": 1375.4227743093447
        },
        "magistral-medium-2506": {
            "rating": 1384.8965089403894,
            "rating_q975": 1397.2074137068053,
            "rating_q025": 1372.5856041739735
        },
        "gpt-oss-120b": {
            "rating": 1384.5984332255284,
            "rating_q975": 1392.913609710403,
            "rating_q025": 1376.2832567406538
        },
        "grok-3-mini-beta": {
            "rating": 1384.4938096310877,
            "rating_q975": 1393.6033415411052,
            "rating_q025": 1375.3842777210702
        },
        "gemini-2.5-flash-lite-preview-06-17-thinking": {
            "rating": 1384.3545297123026,
            "rating_q975": 1392.4705637163977,
            "rating_q025": 1376.2384957082074
        },
        "qwq-32b": {
            "rating": 1384.32157088489,
            "rating_q975": 1393.3514733027391,
            "rating_q025": 1375.2916684670408
        },
        "qwen3-30b-a3b": {
            "rating": 1384.2897202375693,
            "rating_q975": 1393.1878629087628,
            "rating_q025": 1375.3915775663759
        },
        "claude-3-5-haiku-20241022": {
            "rating": 1382.5678037462637,
            "rating_q975": 1388.5570651586074,
            "rating_q025": 1376.57854233392
        },
        "gpt-5-nano-high": {
            "rating": 1380.5258285189327,
            "rating_q975": 1395.2901608075051,
            "rating_q025": 1365.7614962303603
        },
        "qwen-plus-0125": {
            "rating": 1377.0087331556924,
            "rating_q975": 1395.3853920199285,
            "rating_q025": 1358.6320742914563
        },
        "deepseek-v2.5-1210": {
            "rating": 1372.3781126464396,
            "rating_q975": 1389.1418605909857,
            "rating_q025": 1355.6143647018935
        },
        "gpt-4.1-nano-2025-04-14": {
            "rating": 1371.9912114523709,
            "rating_q975": 1391.3572356183072,
            "rating_q025": 1352.6251872864345
        },
        "llama-3.1-405b-instruct-bf16": {
            "rating": 1371.8610870236191,
            "rating_q975": 1379.1229956110571,
            "rating_q025": 1364.599178436181
        },
        "llama-4-maverick-17b-128e-instruct": {
            "rating": 1371.1860133268015,
            "rating_q975": 1378.7558414746115,
            "rating_q025": 1363.6161851789914
        },
        "hunyuan-turbo-0110": {
            "rating": 1369.2180484855007,
            "rating_q975": 1399.196852485162,
            "rating_q025": 1339.2392444858394
        },
        "gpt-oss-20b": {
            "rating": 1368.6699479496206,
            "rating_q975": 1381.8324556494874,
            "rating_q025": 1355.5074402497537
        },
        "step-2-16k-exp-202412": {
            "rating": 1367.9972185539946,
            "rating_q975": 1387.770620882502,
            "rating_q025": 1348.223816225487
        },
        "gpt-4o-2024-05-13": {
            "rating": 1366.26312972475,
            "rating_q975": 1372.3312067810102,
            "rating_q025": 1360.1950526684896
        },
        "yi-lightning": {
            "rating": 1366.263085317687,
            "rating_q975": 1375.7146642776147,
            "rating_q025": 1356.8115063577593
        },
        "athene-v2-chat": {
            "rating": 1366.2105284758031,
            "rating_q975": 1375.1047312897522,
            "rating_q025": 1357.316325661854
        },
        "deepseek-v2.5": {
            "rating": 1365.3890763773734,
            "rating_q975": 1374.5310020509883,
            "rating_q025": 1356.2471507037585
        },
        "llama-3.1-405b-instruct-fp8": {
            "rating": 1364.7956118602888,
            "rating_q975": 1371.652631107429,
            "rating_q025": 1357.9385926131486
        },
        "hunyuan-large-2025-02-10": {
            "rating": 1364.3076229159985,
            "rating_q975": 1389.0917238967947,
            "rating_q025": 1339.5235219352023
        },
        "llama-3.3-nemotron-49b-super-v1": {
            "rating": 1361.5703164139359,
            "rating_q975": 1393.0857045968282,
            "rating_q025": 1330.0549282310435
        },
        "llama-4-scout-17b-16e-instruct": {
            "rating": 1360.4806659376732,
            "rating_q975": 1369.0867369013745,
            "rating_q025": 1351.8745949739719
        },
        "mistral-small-3.1-24b-instruct-2503": {
            "rating": 1359.1871372825453,
            "rating_q975": 1367.183753780707,
            "rating_q025": 1351.1905207843836
        },
        "gemma-3-27b-it": {
            "rating": 1359.0791988544688,
            "rating_q975": 1366.0788076168046,
            "rating_q025": 1352.079590092133
        },
        "gpt-4o-2024-08-06": {
            "rating": 1358.1187938761666,
            "rating_q975": 1365.7234873293771,
            "rating_q025": 1350.514100422956
        },
        "hunyuan-large-vision": {
            "rating": 1357.2569859285513,
            "rating_q975": 1375.9240727906326,
            "rating_q025": 1338.58989906647
        },
        "grok-2-2024-08-13": {
            "rating": 1356.6646321097855,
            "rating_q975": 1363.2661397174916,
            "rating_q025": 1350.0631245020795
        },
        "qwen2.5-plus-1127": {
            "rating": 1354.6481160961873,
            "rating_q975": 1368.4738467753564,
            "rating_q025": 1340.8223854170183
        },
        "step-1o-turbo-202506": {
            "rating": 1354.4899976118795,
            "rating_q975": 1369.1404105531237,
            "rating_q025": 1339.8395846706353
        },
        "gemini-1.5-pro-002": {
            "rating": 1354.2786242327836,
            "rating_q975": 1360.8493168054458,
            "rating_q025": 1347.7079316601214
        },
        "qwen2.5-72b-instruct": {
            "rating": 1352.888882152918,
            "rating_q975": 1360.2412296908192,
            "rating_q025": 1345.536534615017
        },
        "claude-3-opus-20240229": {
            "rating": 1350.3145445924176,
            "rating_q975": 1355.88990312852,
            "rating_q025": 1344.7391860563152
        },
        "mistral-large-2407": {
            "rating": 1350.1366770662075,
            "rating_q975": 1357.7008594673985,
            "rating_q025": 1342.5724946650166
        },
        "qwen-max-0919": {
            "rating": 1349.9199041346146,
            "rating_q975": 1360.8645040983538,
            "rating_q025": 1338.9753041708755
        },
        "glm-4-plus": {
            "rating": 1349.6757087861079,
            "rating_q975": 1358.8273185201278,
            "rating_q025": 1340.5240990520879
        },
        "athene-70b-0725": {
            "rating": 1347.8647991774824,
            "rating_q975": 1358.5042829219408,
            "rating_q025": 1337.225315433024
        },
        "gpt-4o-mini-2024-07-18": {
            "rating": 1346.3678683987046,
            "rating_q975": 1352.580871561927,
            "rating_q025": 1340.154865235482
        },
        "gemini-1.5-pro-001": {
            "rating": 1345.1506454943392,
            "rating_q975": 1352.3980849311788,
            "rating_q025": 1337.9032060574996
        },
        "gpt-4-turbo-2024-04-09": {
            "rating": 1343.7002135978018,
            "rating_q975": 1350.4881891414238,
            "rating_q025": 1336.9122380541799
        },
        "mistral-large-2411": {
            "rating": 1343.0587275919243,
            "rating_q975": 1351.7053958785284,
            "rating_q025": 1334.41205930532
        },
        "llama-3.3-70b-instruct": {
            "rating": 1342.7478982588175,
            "rating_q975": 1349.1076344276157,
            "rating_q025": 1336.3881620900193
        },
        "gemini-2.0-flash-lite-preview-02-05": {
            "rating": 1341.8530833294817,
            "rating_q975": 1351.5376105613657,
            "rating_q025": 1332.1685560975977
        },
        "qwen2.5-coder-32b-instruct": {
            "rating": 1339.793686960974,
            "rating_q975": 1358.2622356173974,
            "rating_q025": 1321.3251383045504
        },
        "amazon-nova-pro-v1.0": {
            "rating": 1339.5208419461478,
            "rating_q975": 1348.4375591550634,
            "rating_q025": 1330.6041247372323
        },
        "deepseek-coder-v2": {
            "rating": 1338.9008395028532,
            "rating_q975": 1350.5719511419866,
            "rating_q025": 1327.2297278637197
        },
        "gemini-advanced-0514": {
            "rating": 1336.447588461188,
            "rating_q975": 1345.2422720449324,
            "rating_q025": 1327.6529048774435
        },
        "gpt-4-1106-preview": {
            "rating": 1335.6389535691906,
            "rating_q975": 1342.768335841494,
            "rating_q025": 1328.509571296887
        },
        "grok-2-mini-2024-08-13": {
            "rating": 1333.0445411099595,
            "rating_q975": 1339.9122665921416,
            "rating_q025": 1326.1768156277774
        },
        "llama-3.1-70b-instruct": {
            "rating": 1329.9638447979669,
            "rating_q975": 1336.779048233804,
            "rating_q025": 1323.1486413621299
        },
        "glm-4-plus-0111": {
            "rating": 1328.8377549990894,
            "rating_q975": 1346.9384013678573,
            "rating_q025": 1310.7371086303215
        },
        "hunyuan-standard-2025-02-10": {
            "rating": 1328.4266822402724,
            "rating_q975": 1352.1065715577959,
            "rating_q025": 1304.746792922749
        },
        "gpt-4-0125-preview": {
            "rating": 1327.4929561251915,
            "rating_q975": 1334.7647319946586,
            "rating_q025": 1320.2211802557244
        },
        "llama-3.1-nemotron-70b-instruct": {
            "rating": 1326.256248499365,
            "rating_q975": 1341.5779671580501,
            "rating_q025": 1310.93452984068
        },
        "gpt-4-0314": {
            "rating": 1323.7463259472524,
            "rating_q975": 1332.9715725256794,
            "rating_q025": 1314.5210793688254
        },
        "gemma-3-12b-it": {
            "rating": 1316.7246654771857,
            "rating_q975": 1340.1808592484049,
            "rating_q025": 1293.2684717059665
        },
        "claude-3-sonnet-20240229": {
            "rating": 1313.6912239398712,
            "rating_q975": 1320.747699433177,
            "rating_q025": 1306.6347484465653
        },
        "gemini-1.5-flash-002": {
            "rating": 1313.6332497560174,
            "rating_q975": 1321.4289548975225,
            "rating_q025": 1305.8375446145124
        },
        "reka-core-20240904": {
            "rating": 1312.2139253016016,
            "rating_q975": 1327.496237295766,
            "rating_q025": 1296.9316133074374
        },
        "gemma-3n-e4b-it": {
            "rating": 1311.2169463067796,
            "rating_q975": 1321.460708893917,
            "rating_q025": 1300.9731837196423
        },
        "mistral-small-24b-instruct-2501": {
            "rating": 1310.1775691794433,
            "rating_q975": 1322.5504716192806,
            "rating_q025": 1297.8046667396059
        },
        "jamba-1.5-large": {
            "rating": 1309.1569574632242,
            "rating_q975": 1323.5429502666134,
            "rating_q025": 1294.770964659835
        },
        "gpt-4-0613": {
            "rating": 1308.7513320707026,
            "rating_q975": 1316.5353426756299,
            "rating_q025": 1300.9673214657753
        },
        "gemini-1.5-flash-001": {
            "rating": 1307.8449571330598,
            "rating_q975": 1315.2285842696788,
            "rating_q025": 1300.4613299964408
        },
        "llama-3.1-nemotron-51b-instruct": {
            "rating": 1307.2031274460471,
            "rating_q975": 1328.858640679447,
            "rating_q025": 1285.5476142126472
        },
        "llama-3.1-tulu-3-70b": {
            "rating": 1304.6516567701642,
            "rating_q975": 1328.3185875098723,
            "rating_q025": 1280.9847260304562
        },
        "glm-4-0520": {
            "rating": 1304.4141244160128,
            "rating_q975": 1318.218672085984,
            "rating_q025": 1290.6095767460415
        },
        "phi-4": {
            "rating": 1303.7213290510233,
            "rating_q975": 1313.4795040236843,
            "rating_q025": 1293.9631540783623
        },
        "gemma-2-27b-it": {
            "rating": 1303.392773482521,
            "rating_q975": 1309.4773991402485,
            "rating_q025": 1297.3081478247937
        },
        "nemotron-4-340b-instruct": {
            "rating": 1303.1641890792823,
            "rating_q975": 1314.3209510401032,
            "rating_q025": 1292.0074271184615
        },
        "llama-3-70b-instruct": {
            "rating": 1302.5896476583905,
            "rating_q975": 1309.2574833868716,
            "rating_q025": 1295.9218119299094
        },
        "amazon-nova-lite-v1.0": {
            "rating": 1302.445069715641,
            "rating_q975": 1312.526479405646,
            "rating_q025": 1292.3636600256361
        },
        "claude-3-haiku-20240307": {
            "rating": 1297.1320831403382,
            "rating_q975": 1303.7072345092436,
            "rating_q025": 1290.5569317714328
        },
        "hunyuan-standard-256k": {
            "rating": 1296.7209684220252,
            "rating_q975": 1321.3122214402163,
            "rating_q025": 1272.129715403834
        },
        "qwen2-72b-instruct": {
            "rating": 1291.9771782666062,
            "rating_q975": 1300.7110387452083,
            "rating_q025": 1283.243317788004
        },
        "mistral-large-2402": {
            "rating": 1290.335065550984,
            "rating_q975": 1298.6404402368696,
            "rating_q025": 1282.0296908650982
        },
        "c4ai-aya-expanse-32b": {
            "rating": 1289.4212123582797,
            "rating_q975": 1298.300006296763,
            "rating_q025": 1280.5424184197964
        },
        "reka-flash-20240904": {
            "rating": 1287.9099531552229,
            "rating_q975": 1303.080879541635,
            "rating_q025": 1272.7390267688106
        },
        "granite-3.1-8b-instruct": {
            "rating": 1284.7254622116375,
            "rating_q975": 1310.295198059472,
            "rating_q025": 1259.1557263638028
        },
        "amazon-nova-micro-v1.0": {
            "rating": 1284.679232734278,
            "rating_q975": 1294.819856636766,
            "rating_q025": 1274.53860883179
        },
        "olmo-2-0325-32b-instruct": {
            "rating": 1276.7900520873845,
            "rating_q975": 1303.819871308003,
            "rating_q025": 1249.760232866766
        },
        "command-r-08-2024": {
            "rating": 1276.7421598982087,
            "rating_q975": 1290.0686207885117,
            "rating_q025": 1263.4156990079057
        },
        "command-r-plus-08-2024": {
            "rating": 1276.4780330916783,
            "rating_q975": 1290.1926857206017,
            "rating_q025": 1262.7633804627549
        },
        "qwen1.5-110b-chat": {
            "rating": 1275.2206227246907,
            "rating_q975": 1285.3019070484354,
            "rating_q025": 1265.139338400946
        },
        "gemma-3-4b-it": {
            "rating": 1273.8535253990392,
            "rating_q975": 1297.5945369610904,
            "rating_q025": 1250.112513836988
        },
        "reka-flash-21b-20240226-online": {
            "rating": 1272.940098438768,
            "rating_q975": 1285.5062242507906,
            "rating_q025": 1260.3739726267454
        },
        "mixtral-8x22b-instruct-v0.1": {
            "rating": 1272.2765308294292,
            "rating_q975": 1280.6876803538985,
            "rating_q025": 1263.86538130496
        },
        "gemma-2-9b-it-simpo": {
            "rating": 1271.0880919843646,
            "rating_q975": 1285.9042842851288,
            "rating_q025": 1256.2718996836004
        },
        "ministral-8b-2410": {
            "rating": 1271.0703071514188,
            "rating_q975": 1289.7745417809206,
            "rating_q025": 1252.366072521917
        },
        "gemini-1.5-flash-8b-001": {
            "rating": 1270.2819580698251,
            "rating_q975": 1278.166165139241,
            "rating_q025": 1262.3977510004092
        },
        "qwen1.5-72b-chat": {
            "rating": 1269.953656270261,
            "rating_q975": 1279.3882121870997,
            "rating_q025": 1260.5191003534223
        },
        "gpt-3.5-turbo-0125": {
            "rating": 1269.7402916939836,
            "rating_q975": 1277.6589860923298,
            "rating_q025": 1261.8215972956375
        },
        "gemma-2-9b-it": {
            "rating": 1269.0409044407497,
            "rating_q975": 1276.026827305859,
            "rating_q025": 1262.0549815756406
        },
        "command-r-plus": {
            "rating": 1268.047778825729,
            "rating_q975": 1275.5380045328648,
            "rating_q025": 1260.5575531185932
        },
        "jamba-1.5-mini": {
            "rating": 1262.81473016345,
            "rating_q975": 1278.0475052101854,
            "rating_q025": 1247.5819551167144
        },
        "reka-flash-21b-20240226": {
            "rating": 1261.7010601971801,
            "rating_q975": 1272.189388259285,
            "rating_q025": 1251.2127321350754
        },
        "mistral-medium": {
            "rating": 1256.8490475313633,
            "rating_q975": 1267.1452459417171,
            "rating_q025": 1246.5528491210096
        },
        "llama-3.1-8b-instruct": {
            "rating": 1256.848387006702,
            "rating_q975": 1264.0153087048084,
            "rating_q025": 1249.6814653085958
        },
        "qwen1.5-32b-chat": {
            "rating": 1256.7053368773281,
            "rating_q975": 1267.4329702189218,
            "rating_q025": 1245.9777035357345
        },
        "gpt-3.5-turbo-1106": {
            "rating": 1256.4469065062804,
            "rating_q975": 1271.9949361780311,
            "rating_q025": 1240.8988768345296
        },
        "c4ai-aya-expanse-8b": {
            "rating": 1253.4820160515776,
            "rating_q975": 1267.858277143143,
            "rating_q025": 1239.1057549600123
        },
        "llama-3.1-tulu-3-8b": {
            "rating": 1250.5049421040897,
            "rating_q975": 1275.3456488834597,
            "rating_q025": 1225.6642353247196
        },
        "llama-3-8b-instruct": {
            "rating": 1249.0460826383778,
            "rating_q975": 1256.3632560638334,
            "rating_q025": 1241.7289092129222
        },
        "granite-3.1-2b-instruct": {
            "rating": 1247.2069260741953,
            "rating_q975": 1271.6101159152638,
            "rating_q025": 1222.8037362331268
        },
        "dbrx-instruct-preview": {
            "rating": 1245.9453813409307,
            "rating_q975": 1256.7010961036422,
            "rating_q025": 1235.1896665782192
        },
        "internlm2_5-20b-chat": {
            "rating": 1245.2480326557088,
            "rating_q975": 1259.3476121399433,
            "rating_q025": 1231.1484531714743
        },
        "yi-1.5-34b-chat": {
            "rating": 1243.7393571647824,
            "rating_q975": 1254.0070175151004,
            "rating_q025": 1233.4716968144644
        },
        "gemini-pro": {
            "rating": 1243.7004180548838,
            "rating_q975": 1267.510275189893,
            "rating_q025": 1219.8905609198746
        },
        "zephyr-orpo-141b-A35b-v0.1": {
            "rating": 1240.1718437824652,
            "rating_q975": 1260.7865996692674,
            "rating_q025": 1219.557087895663
        },
        "command-r": {
            "rating": 1238.4607723929194,
            "rating_q975": 1246.9654774508745,
            "rating_q025": 1229.9560673349642
        },
        "gemini-pro-dev-api": {
            "rating": 1235.2986790268315,
            "rating_q975": 1249.2552804789818,
            "rating_q025": 1221.342077574681
        },
        "granite-3.0-8b-instruct": {
            "rating": 1235.1842354508972,
            "rating_q975": 1253.0757903488934,
            "rating_q025": 1217.292680552901
        },
        "qwen1.5-14b-chat": {
            "rating": 1234.9751302336927,
            "rating_q975": 1247.6710124453048,
            "rating_q025": 1222.2792480220805
        },
        "mixtral-8x7b-instruct-v0.1": {
            "rating": 1234.3705518859315,
            "rating_q975": 1242.2300055550056,
            "rating_q025": 1226.5110982168574
        },
        "starling-lm-7b-beta": {
            "rating": 1231.0916108555757,
            "rating_q975": 1243.7814808995581,
            "rating_q025": 1218.4017408115933
        },
        "phi-3-medium-4k-instruct": {
            "rating": 1226.2466214525825,
            "rating_q975": 1236.3047521653775,
            "rating_q025": 1216.1884907397875
        },
        "openchat-3.5-0106": {
            "rating": 1224.4825821946538,
            "rating_q975": 1238.4514637570737,
            "rating_q025": 1210.5137006322338
        },
        "snowflake-arctic-instruct": {
            "rating": 1219.582578282599,
            "rating_q975": 1230.6004975979,
            "rating_q025": 1208.5646589672979
        },
        "gemma-1.1-7b-it": {
            "rating": 1214.2371049916148,
            "rating_q975": 1224.4062883254635,
            "rating_q025": 1204.0679216577662
        },
        "deepseek-llm-67b-chat": {
            "rating": 1212.8776088079371,
            "rating_q975": 1236.5150861892134,
            "rating_q025": 1189.2401314266608
        },
        "tulu-2-dpo-70b": {
            "rating": 1209.5128048720794,
            "rating_q975": 1230.7898642459807,
            "rating_q025": 1188.2357454981782
        },
        "qwen1.5-7b-chat": {
            "rating": 1205.0232890156608,
            "rating_q975": 1225.7791944344779,
            "rating_q025": 1184.2673835968437
        },
        "granite-3.0-2b-instruct": {
            "rating": 1204.352914208948,
            "rating_q975": 1221.8224867203892,
            "rating_q025": 1186.883341697507
        },
        "starling-lm-7b-alpha": {
            "rating": 1202.3780808125355,
            "rating_q975": 1218.6677300057097,
            "rating_q025": 1186.0884316193612
        },
        "yi-34b-chat": {
            "rating": 1200.6099491761427,
            "rating_q975": 1213.4869844430812,
            "rating_q025": 1187.7329139092042
        },
        "phi-3-small-8k-instruct": {
            "rating": 1200.1218549528528,
            "rating_q975": 1211.5837888823874,
            "rating_q025": 1188.6599210233182
        },
        "openchat-3.5": {
            "rating": 1196.987508231196,
            "rating_q975": 1216.5893740093816,
            "rating_q025": 1177.3856424530104
        },
        "phi-3-mini-4k-instruct-june-2024": {
            "rating": 1193.0470426276074,
            "rating_q975": 1206.7511780855123,
            "rating_q025": 1179.3429071697026
        },
        "gemma-2-2b-it": {
            "rating": 1192.3254900359511,
            "rating_q975": 1200.1382658220518,
            "rating_q025": 1184.5127142498504
        },
        "qwen-14b-chat": {
            "rating": 1191.0452234382997,
            "rating_q975": 1214.8098546400054,
            "rating_q025": 1167.280592236594
        },
        "vicuna-33b": {
            "rating": 1187.5506584544235,
            "rating_q975": 1200.148654638126,
            "rating_q025": 1174.952662270721
        },
        "wizardlm-70b": {
            "rating": 1186.431937590486,
            "rating_q975": 1206.2094839218041,
            "rating_q025": 1166.654391259168
        },
        "phi-3-mini-4k-instruct": {
            "rating": 1183.0306345406916,
            "rating_q975": 1194.6194109774888,
            "rating_q025": 1171.4418581038944
        },
        "openhermes-2.5-mistral-7b": {
            "rating": 1181.286689137943,
            "rating_q975": 1204.5050140055846,
            "rating_q025": 1158.0683642703016
        },
        "mistral-7b-instruct-v0.2": {
            "rating": 1180.9397723004358,
            "rating_q975": 1192.5136579013488,
            "rating_q025": 1169.365886699523
        },
        "solar-10.7b-instruct-v1.0": {
            "rating": 1178.1633608537882,
            "rating_q975": 1205.4459359250184,
            "rating_q025": 1150.880785782558
        },
        "llama-2-70b-chat": {
            "rating": 1173.6213726196775,
            "rating_q975": 1183.3577884517601,
            "rating_q025": 1163.8849567875948
        },
        "llama-3.2-3b-instruct": {
            "rating": 1171.7434550310268,
            "rating_q975": 1188.026740230129,
            "rating_q025": 1155.4601698319245
        },
        "qwq-32b-preview": {
            "rating": 1171.5167735630498,
            "rating_q975": 1195.8484332241335,
            "rating_q025": 1147.1851139019661
        },
        "nous-hermes-2-mixtral-8x7b-dpo": {
            "rating": 1170.4095650365277,
            "rating_q975": 1194.002797103849,
            "rating_q025": 1146.8163329692065
        },
        "gemma-1.1-2b-it": {
            "rating": 1168.731601199355,
            "rating_q975": 1182.551784947504,
            "rating_q025": 1154.911417451206
        },
        "gemma-7b-it": {
            "rating": 1165.3974445429471,
            "rating_q975": 1181.9584963923778,
            "rating_q025": 1148.8363926935165
        },
        "zephyr-7b-alpha": {
            "rating": 1162.6792778817933,
            "rating_q975": 1202.782903517245,
            "rating_q025": 1122.5756522463416
        },
        "mpt-30b-chat": {
            "rating": 1160.1331796561483,
            "rating_q975": 1195.1730167300814,
            "rating_q025": 1125.0933425822152
        },
        "llama-2-13b-chat": {
            "rating": 1157.319523789347,
            "rating_q975": 1170.1421468359763,
            "rating_q025": 1144.4969007427176
        },
        "vicuna-13b": {
            "rating": 1156.8618575466833,
            "rating_q975": 1170.6033580654018,
            "rating_q025": 1143.1203570279647
        },
        "smollm2-1.7b-instruct": {
            "rating": 1155.9757651114342,
            "rating_q975": 1188.839514397349,
            "rating_q025": 1123.1120158255194
        },
        "codellama-34b-instruct": {
            "rating": 1153.806493552969,
            "rating_q975": 1174.151765947662,
            "rating_q025": 1133.461221158276
        },
        "phi-3-mini-128k-instruct": {
            "rating": 1150.1298674503917,
            "rating_q975": 1163.0240960205672,
            "rating_q025": 1137.2356388802161
        },
        "zephyr-7b-beta": {
            "rating": 1146.3401484721321,
            "rating_q975": 1164.5035655885436,
            "rating_q025": 1128.1767313557207
        },
        "palm-2": {
            "rating": 1146.05664898014,
            "rating_q975": 1166.9789923846627,
            "rating_q025": 1125.1343055756172
        },
        "llama-3.2-1b-instruct": {
            "rating": 1145.3424208838792,
            "rating_q975": 1161.5709031387746,
            "rating_q025": 1129.1139386289838
        },
        "wizardlm-13b": {
            "rating": 1144.868153902455,
            "rating_q975": 1166.9155361589092,
            "rating_q025": 1122.820771646001
        },
        "llama2-70b-steerlm-chat": {
            "rating": 1139.7979782130983,
            "rating_q975": 1167.7189722257608,
            "rating_q025": 1111.8769842004358
        },
        "mistral-7b-instruct": {
            "rating": 1138.9880214498576,
            "rating_q975": 1158.7428610302604,
            "rating_q025": 1119.2331818694547
        },
        "gemma-2b-it": {
            "rating": 1132.9967109901097,
            "rating_q975": 1154.9794962103433,
            "rating_q025": 1111.013925769876
        },
        "qwen1.5-4b-chat": {
            "rating": 1124.9293922881768,
            "rating_q975": 1142.3328734725214,
            "rating_q025": 1107.5259111038322
        },
        "vicuna-7b": {
            "rating": 1124.2604738254943,
            "rating_q975": 1147.2315994686276,
            "rating_q025": 1101.289348182361
        },
        "stripedhyena-nous-7b": {
            "rating": 1120.176699227805,
            "rating_q975": 1142.423023904382,
            "rating_q025": 1097.9303745512282
        },
        "guanaco-33b": {
            "rating": 1106.184160361308,
            "rating_q975": 1142.2885512626885,
            "rating_q025": 1070.0797694599273
        },
        "olmo-7b-instruct": {
            "rating": 1102.5133295394025,
            "rating_q975": 1124.4760767671555,
            "rating_q025": 1080.5505823116496
        },
        "llama-2-7b-chat": {
            "rating": 1097.8172443411154,
            "rating_q975": 1111.7882472667934,
            "rating_q025": 1083.8462414154374
        },
        "chatglm3-6b": {
            "rating": 1083.7149082021422,
            "rating_q975": 1109.9252793097828,
            "rating_q025": 1057.5045370945015
        },
        "mpt-7b-chat": {
            "rating": 1058.2746150593555,
            "rating_q975": 1090.1317634373238,
            "rating_q025": 1026.4174666813872
        },
        "koala-13b": {
            "rating": 1057.0667745797994,
            "rating_q975": 1081.487857730456,
            "rating_q025": 1032.6456914291427
        },
        "RWKV-4-Raven-14B": {
            "rating": 1050.8703816256166,
            "rating_q975": 1078.3011283280657,
            "rating_q025": 1023.4396349231675
        },
        "oasst-pythia-12b": {
            "rating": 1041.430523477846,
            "rating_q975": 1066.7402615750646,
            "rating_q025": 1016.1207853806275
        },
        "chatglm-6b": {
            "rating": 1026.4430011959125,
            "rating_q975": 1053.9696868262706,
            "rating_q025": 998.9163155655546
        },
        "chatglm2-6b": {
            "rating": 1025.5785295260803,
            "rating_q975": 1060.7463530995021,
            "rating_q025": 990.4107059526583
        },
        "stablelm-tuned-alpha-7b": {
            "rating": 995.2669689433837,
            "rating_q975": 1028.5911196486309,
            "rating_q025": 961.9428182381367
        },
        "alpaca-13b": {
            "rating": 990.3255776182416,
            "rating_q975": 1017.8410605504243,
            "rating_q025": 962.8100946860588
        },
        "dolly-v2-12b": {
            "rating": 952.796588655749,
            "rating_q975": 987.3708949529465,
            "rating_q025": 918.2222823585515
        },
        "fastchat-t5-3b": {
            "rating": 898.0852275580394,
            "rating_q975": 929.2199406350859,
            "rating_q025": 866.9505144809929
        },
        "llama-13b": {
            "rating": 871.168028718366,
            "rating_q975": 911.45913750375,
            "rating_q025": 830.8769199329821
        }
    },
    "creative_writing": {
        "gemini-2.5-pro": {
            "rating": 1451.1903797533146,
            "rating_q975": 1459.0995720937726,
            "rating_q025": 1443.2811874128565
        },
        "claude-sonnet-4-5-20250929": {
            "rating": 1440.781777706943,
            "rating_q975": 1460.8384233738889,
            "rating_q025": 1420.7251320399973
        },
        "claude-opus-4-1-20250805-thinking-16k": {
            "rating": 1439.49790558546,
            "rating_q975": 1449.946201967196,
            "rating_q025": 1429.0496092037242
        },
        "claude-sonnet-4-5-20250929-thinking-32k": {
            "rating": 1435.2521776008177,
            "rating_q975": 1450.2664982366168,
            "rating_q025": 1420.2378569650186
        },
        "gpt-4.5-preview-2025-02-27": {
            "rating": 1432.4196711196093,
            "rating_q975": 1444.1730504505786,
            "rating_q025": 1420.6662917886401
        },
        "claude-opus-4-1-20250805": {
            "rating": 1429.5601039796124,
            "rating_q975": 1438.4609895111118,
            "rating_q025": 1420.659218448113
        },
        "claude-opus-4-20250514-thinking-16k": {
            "rating": 1420.5555008887302,
            "rating_q975": 1429.6826950916334,
            "rating_q025": 1411.428306685827
        },
        "chatgpt-4o-latest-20250326": {
            "rating": 1420.2041371578528,
            "rating_q975": 1428.149274075133,
            "rating_q025": 1412.2590002405725
        },
        "glm-4.6": {
            "rating": 1410.6864008939422,
            "rating_q975": 1427.5963152053519,
            "rating_q025": 1393.7764865825325
        },
        "claude-opus-4-20250514": {
            "rating": 1410.5621654466179,
            "rating_q975": 1419.0585598144414,
            "rating_q025": 1402.0657710787943
        },
        "deepseek-v3.1-thinking": {
            "rating": 1403.9044467284607,
            "rating_q975": 1418.424211937377,
            "rating_q025": 1389.3846815195443
        },
        "deepseek-v3.1-terminus": {
            "rating": 1403.4191433404205,
            "rating_q975": 1430.3692709347852,
            "rating_q025": 1376.469015746056
        },
        "gemini-2.5-flash": {
            "rating": 1398.0004381462243,
            "rating_q975": 1405.6594402804826,
            "rating_q025": 1390.341436011966
        },
        "qwen3-max-2025-09-23": {
            "rating": 1397.9448305177348,
            "rating_q975": 1414.933599090953,
            "rating_q025": 1380.9560619445165
        },
        "grok-3-preview-02-24": {
            "rating": 1397.078777741402,
            "rating_q975": 1405.9729978268913,
            "rating_q025": 1388.1845576559128
        },
        "gpt-4.1-2025-04-14": {
            "rating": 1396.7863440002372,
            "rating_q975": 1404.7118225092267,
            "rating_q025": 1388.8608654912478
        },
        "deepseek-v3.2-exp-thinking": {
            "rating": 1396.097620654508,
            "rating_q975": 1413.3007148452248,
            "rating_q025": 1378.8945264637914
        },
        "grok-4-0709": {
            "rating": 1395.7866881781222,
            "rating_q975": 1404.932046595072,
            "rating_q025": 1386.6413297611723
        },
        "qwen3-max-preview": {
            "rating": 1393.2754219687265,
            "rating_q975": 1404.0541968004966,
            "rating_q025": 1382.4966471369564
        },
        "deepseek-v3.1": {
            "rating": 1392.6173597973539,
            "rating_q975": 1405.8593249792116,
            "rating_q025": 1379.3753946154961
        },
        "claude-sonnet-4-20250514-thinking-32k": {
            "rating": 1391.4884343846131,
            "rating_q975": 1400.6999896340894,
            "rating_q025": 1382.2768791351368
        },
        "claude-haiku-4-5-20251001": {
            "rating": 1388.8623980418322,
            "rating_q975": 1405.6153802246638,
            "rating_q025": 1372.1094158590006
        },
        "gpt-5-chat": {
            "rating": 1388.8393344208032,
            "rating_q975": 1399.0388176049853,
            "rating_q025": 1378.639851236621
        },
        "deepseek-r1-0528": {
            "rating": 1388.5656483186076,
            "rating_q975": 1400.7003631717482,
            "rating_q025": 1376.430933465467
        },
        "deepseek-v3-0324": {
            "rating": 1387.7993913314042,
            "rating_q975": 1395.798161083689,
            "rating_q025": 1379.8006215791195
        },
        "gemini-2.5-flash-preview-09-2025": {
            "rating": 1387.1123292908685,
            "rating_q975": 1401.4419765151497,
            "rating_q025": 1372.7826820665873
        },
        "claude-3-7-sonnet-20250219-thinking-32k": {
            "rating": 1386.721175842261,
            "rating_q975": 1395.1141292639734,
            "rating_q025": 1378.3282224205484
        },
        "o3-2025-04-16": {
            "rating": 1384.2824958454219,
            "rating_q975": 1391.806772656739,
            "rating_q025": 1376.7582190341047
        },
        "grok-4-fast": {
            "rating": 1383.1851886983907,
            "rating_q975": 1402.016462857696,
            "rating_q025": 1364.3539145390853
        },
        "gpt-5-high": {
            "rating": 1382.3412427734058,
            "rating_q975": 1392.5063008292689,
            "rating_q025": 1372.1761847175428
        },
        "kimi-k2-0905-preview": {
            "rating": 1380.8764380374273,
            "rating_q975": 1397.0147782416825,
            "rating_q025": 1364.738097833172
        },
        "qwen3-235b-a22b-instruct-2507": {
            "rating": 1380.2003823622827,
            "rating_q975": 1389.3274827155474,
            "rating_q025": 1371.073282009018
        },
        "claude-sonnet-4-20250514": {
            "rating": 1379.3395107461613,
            "rating_q975": 1388.03198632738,
            "rating_q025": 1370.6470351649425
        },
        "o1-2024-12-17": {
            "rating": 1378.812437567867,
            "rating_q975": 1387.4416910286548,
            "rating_q025": 1370.1831841070791
        },
        "deepseek-v3.1-terminus-thinking": {
            "rating": 1374.9819285240562,
            "rating_q975": 1403.2395748114345,
            "rating_q025": 1346.724282236678
        },
        "mistral-medium-2508": {
            "rating": 1374.739935959542,
            "rating_q975": 1384.6266193272766,
            "rating_q025": 1364.8532525918074
        },
        "hunyuan-t1-20250711": {
            "rating": 1374.1101431173847,
            "rating_q975": 1397.7999230732426,
            "rating_q025": 1350.420363161527
        },
        "glm-4.5": {
            "rating": 1373.4682867615923,
            "rating_q975": 1384.3486311210227,
            "rating_q025": 1362.5879424021618
        },
        "deepseek-r1": {
            "rating": 1371.6652318564113,
            "rating_q975": 1381.7880294016863,
            "rating_q025": 1361.5424343111363
        },
        "qwen3-235b-a22b-thinking-2507": {
            "rating": 1371.5918389309932,
            "rating_q975": 1389.107419378369,
            "rating_q025": 1354.0762584836173
        },
        "kimi-k2-0711-preview": {
            "rating": 1370.7304235852612,
            "rating_q975": 1380.8547738560017,
            "rating_q025": 1360.6060733145207
        },
        "gemini-2.5-flash-lite-preview-06-17-thinking": {
            "rating": 1370.1594431880435,
            "rating_q975": 1379.4004545491423,
            "rating_q025": 1360.9184318269447
        },
        "claude-3-5-sonnet-20241022": {
            "rating": 1365.858359498553,
            "rating_q975": 1371.7148163614033,
            "rating_q025": 1360.0019026357027
        },
        "qwen3-235b-a22b-no-thinking": {
            "rating": 1365.521655212588,
            "rating_q975": 1374.5031479188267,
            "rating_q025": 1356.5401625063494
        },
        "o1-preview": {
            "rating": 1362.7925730672916,
            "rating_q975": 1372.3051572724864,
            "rating_q025": 1353.2799888620968
        },
        "gemini-2.5-flash-lite-preview-09-2025-no-thinking": {
            "rating": 1362.6256905683256,
            "rating_q975": 1376.8155122484852,
            "rating_q025": 1348.435868888166
        },
        "hunyuan-turbos-20250416": {
            "rating": 1361.987539294113,
            "rating_q975": 1376.9620330077007,
            "rating_q025": 1347.0130455805254
        },
        "qwen3-coder-480b-a35b-instruct": {
            "rating": 1360.224318819801,
            "rating_q975": 1370.8633462957505,
            "rating_q025": 1349.5852913438516
        },
        "mistral-medium-2505": {
            "rating": 1359.5137187839487,
            "rating_q975": 1368.8218132432157,
            "rating_q025": 1350.2056243246816
        },
        "qwen3-vl-235b-a22b-instruct": {
            "rating": 1359.4879239940287,
            "rating_q975": 1377.0366316937102,
            "rating_q025": 1341.9392162943473
        },
        "mai-1-preview": {
            "rating": 1358.6254445840696,
            "rating_q975": 1371.4496539554518,
            "rating_q025": 1345.8012352126873
        },
        "gemini-1.5-pro-002": {
            "rating": 1356.57780551317,
            "rating_q975": 1363.560394676292,
            "rating_q025": 1349.595216350048
        },
        "qwen2.5-max": {
            "rating": 1351.6483520319755,
            "rating_q975": 1359.8786693677166,
            "rating_q025": 1343.4180346962344
        },
        "deepseek-v3": {
            "rating": 1346.986228239793,
            "rating_q975": 1356.7407484898704,
            "rating_q025": 1337.2317079897157
        },
        "gemma-3-27b-it": {
            "rating": 1346.58809245056,
            "rating_q975": 1354.1158098236333,
            "rating_q025": 1339.0603750774867
        },
        "gpt-4.1-mini-2025-04-14": {
            "rating": 1343.9293305330625,
            "rating_q975": 1352.6008670703222,
            "rating_q025": 1335.2577939958028
        },
        "gemini-2.0-flash-lite-preview-02-05": {
            "rating": 1343.3379531328646,
            "rating_q975": 1352.3349264058509,
            "rating_q025": 1334.3409798598784
        },
        "qwen3-vl-235b-a22b-thinking": {
            "rating": 1342.4861582772376,
            "rating_q975": 1360.7782518844926,
            "rating_q025": 1324.1940646699825
        },
        "gemini-advanced-0514": {
            "rating": 1339.9503549799645,
            "rating_q975": 1349.534895129044,
            "rating_q025": 1330.365814830885
        },
        "o4-mini-2025-04-16": {
            "rating": 1339.003458900917,
            "rating_q975": 1347.1077765019254,
            "rating_q025": 1330.8991412999085
        },
        "grok-3-mini-beta": {
            "rating": 1334.895786967282,
            "rating_q975": 1345.837261011549,
            "rating_q025": 1323.954312923015
        },
        "gpt-4o-2024-05-13": {
            "rating": 1333.9101331843483,
            "rating_q975": 1340.5862909191003,
            "rating_q025": 1327.2339754495963
        },
        "step-2-16k-exp-202412": {
            "rating": 1333.8097749212545,
            "rating_q975": 1354.4198742386945,
            "rating_q025": 1313.1996756038145
        },
        "command-a-03-2025": {
            "rating": 1333.3326509370497,
            "rating_q975": 1340.6915330782622,
            "rating_q025": 1325.9737687958373
        },
        "llama-3.1-nemotron-ultra-253b-v1": {
            "rating": 1331.9013149614764,
            "rating_q975": 1358.597984375158,
            "rating_q025": 1305.2046455477948
        },
        "longcat-flash-chat": {
            "rating": 1330.561531140378,
            "rating_q975": 1346.3588768845634,
            "rating_q025": 1314.7641853961927
        },
        "gemma-3-12b-it": {
            "rating": 1330.5342929063845,
            "rating_q975": 1353.554253271896,
            "rating_q025": 1307.514332540873
        },
        "grok-3-mini-high": {
            "rating": 1330.1611996829483,
            "rating_q975": 1342.9996551933164,
            "rating_q025": 1317.3227441725803
        },
        "qwen3-235b-a22b": {
            "rating": 1327.410972256469,
            "rating_q975": 1337.3406086566097,
            "rating_q025": 1317.4813358563283
        },
        "glm-4.5-air": {
            "rating": 1327.3836911778349,
            "rating_q975": 1337.4733356464037,
            "rating_q025": 1317.294046709266
        },
        "gpt-5-mini-high": {
            "rating": 1326.8782900212857,
            "rating_q975": 1337.965879505532,
            "rating_q025": 1315.7907005370394
        },
        "qwen3-30b-a3b-instruct-2507": {
            "rating": 1324.3261059569666,
            "rating_q975": 1335.2154314809843,
            "rating_q025": 1313.4367804329488
        },
        "minimax-m1": {
            "rating": 1324.0747111822734,
            "rating_q975": 1333.0115709920783,
            "rating_q025": 1315.1378513724685
        },
        "mistral-small-2506": {
            "rating": 1323.015838278592,
            "rating_q975": 1335.345034093409,
            "rating_q025": 1310.686642463775
        },
        "gpt-4o-2024-08-06": {
            "rating": 1322.463960780781,
            "rating_q975": 1330.5503474443392,
            "rating_q025": 1314.3775741172228
        },
        "qwen3-next-80b-a3b-thinking": {
            "rating": 1320.0655362076557,
            "rating_q975": 1334.458186134396,
            "rating_q025": 1305.6728862809152
        },
        "gpt-4-turbo-2024-04-09": {
            "rating": 1319.709429329367,
            "rating_q975": 1327.047563717653,
            "rating_q025": 1312.3712949410808
        },
        "gemini-1.5-pro-001": {
            "rating": 1319.104434482961,
            "rating_q975": 1326.7970618729432,
            "rating_q025": 1311.411807092979
        },
        "glm-4-plus-0111": {
            "rating": 1316.4497439637898,
            "rating_q975": 1335.3312644482967,
            "rating_q025": 1297.568223479283
        },
        "qwen3-next-80b-a3b-instruct": {
            "rating": 1314.8146978802777,
            "rating_q975": 1326.875952088061,
            "rating_q025": 1302.7534436724943
        },
        "grok-2-2024-08-13": {
            "rating": 1314.6141106940827,
            "rating_q975": 1321.6332581893612,
            "rating_q025": 1307.5949631988042
        },
        "qwen-plus-0125": {
            "rating": 1313.832630516415,
            "rating_q975": 1331.6996740296308,
            "rating_q025": 1295.9655870031993
        },
        "o3-mini-high": {
            "rating": 1309.677082916259,
            "rating_q975": 1320.2449291458142,
            "rating_q025": 1299.1092366867038
        },
        "glm-4.5v": {
            "rating": 1308.6284931349892,
            "rating_q975": 1331.4288747399037,
            "rating_q025": 1285.8281115300747
        },
        "deepseek-v2.5-1210": {
            "rating": 1306.7928707918363,
            "rating_q975": 1323.7200989257178,
            "rating_q025": 1289.8656426579548
        },
        "amazon-nova-experimental-chat-10-09": {
            "rating": 1305.8515547141433,
            "rating_q975": 1326.2167488302994,
            "rating_q025": 1285.4863605979872
        },
        "llama-4-maverick-17b-128e-instruct": {
            "rating": 1305.8306490876298,
            "rating_q975": 1314.2736131695385,
            "rating_q025": 1297.387685005721
        },
        "gpt-4.1-nano-2025-04-14": {
            "rating": 1305.556188077775,
            "rating_q975": 1323.9018686497657,
            "rating_q025": 1287.2105075057843
        },
        "nvidia-llama-3.3-nemotron-super-49b-v1.5": {
            "rating": 1305.1519529968568,
            "rating_q975": 1333.0897461477807,
            "rating_q025": 1277.214159845933
        },
        "qwen3-32b": {
            "rating": 1303.906475259179,
            "rating_q975": 1326.502601922515,
            "rating_q025": 1281.310348595843
        },
        "step-3": {
            "rating": 1302.6130545147726,
            "rating_q975": 1323.1748683195356,
            "rating_q025": 1282.0512407100096
        },
        "llama-3.1-405b-instruct-fp8": {
            "rating": 1301.8110197420783,
            "rating_q975": 1309.119681840192,
            "rating_q025": 1294.5023576439646
        },
        "o3-mini": {
            "rating": 1300.5522040587798,
            "rating_q975": 1307.3144164476369,
            "rating_q025": 1293.7899916699228
        },
        "hunyuan-turbos-20250226": {
            "rating": 1299.8925969637226,
            "rating_q975": 1325.4948206973895,
            "rating_q025": 1274.2903732300556
        },
        "claude-3-5-sonnet-20240620": {
            "rating": 1299.6273885774092,
            "rating_q975": 1306.7949289078979,
            "rating_q025": 1292.4598482469205
        },
        "hunyuan-large-2025-02-10": {
            "rating": 1299.485848802769,
            "rating_q975": 1323.2714415998187,
            "rating_q025": 1275.7002560057192
        },
        "llama-3.1-405b-instruct-bf16": {
            "rating": 1299.1355381383764,
            "rating_q975": 1306.4541168647634,
            "rating_q025": 1291.8169594119895
        },
        "hunyuan-turbo-0110": {
            "rating": 1298.9699956426862,
            "rating_q975": 1324.1299654155005,
            "rating_q025": 1273.8100258698719
        },
        "claude-3-5-haiku-20241022": {
            "rating": 1298.5010604032627,
            "rating_q975": 1304.7307760697483,
            "rating_q025": 1292.271344736777
        },
        "gemma-3n-e4b-it": {
            "rating": 1298.042670884961,
            "rating_q975": 1308.9597116296595,
            "rating_q025": 1287.1256301402623
        },
        "gemini-1.5-flash-002": {
            "rating": 1296.7429635980138,
            "rating_q975": 1305.3106848794484,
            "rating_q025": 1288.1752423165792
        },
        "yi-lightning": {
            "rating": 1295.49720069885,
            "rating_q975": 1305.6276664972756,
            "rating_q025": 1285.3667349004245
        },
        "llama-3.3-nemotron-49b-super-v1": {
            "rating": 1293.8605460487443,
            "rating_q975": 1320.8472931524666,
            "rating_q025": 1266.873798945022
        },
        "qwq-32b": {
            "rating": 1293.4985643501766,
            "rating_q975": 1303.1400239566099,
            "rating_q025": 1283.8571047437433
        },
        "gpt-4o-mini-2024-07-18": {
            "rating": 1291.848746290111,
            "rating_q975": 1298.3571446503774,
            "rating_q025": 1285.3403479298445
        },
        "gemma-2-27b-it": {
            "rating": 1289.3495973150189,
            "rating_q975": 1295.7144192084847,
            "rating_q025": 1282.984775421553
        },
        "llama-4-scout-17b-16e-instruct": {
            "rating": 1288.993278917499,
            "rating_q975": 1298.915022100939,
            "rating_q025": 1279.0715357340591
        },
        "step-1o-turbo-202506": {
            "rating": 1287.4635392909681,
            "rating_q975": 1305.555156455588,
            "rating_q025": 1269.3719221263482
        },
        "magistral-medium-2506": {
            "rating": 1286.6113516607952,
            "rating_q975": 1302.5864594880477,
            "rating_q025": 1270.6362438335427
        },
        "glm-4-plus": {
            "rating": 1286.5659288900583,
            "rating_q975": 1296.492151040998,
            "rating_q025": 1276.6397067391188
        },
        "qwen3-30b-a3b": {
            "rating": 1285.2047610705672,
            "rating_q975": 1295.3696567890631,
            "rating_q025": 1275.0398653520713
        },
        "claude-3-opus-20240229": {
            "rating": 1284.7885197861665,
            "rating_q975": 1290.7950305679024,
            "rating_q025": 1278.7820090044306
        },
        "llama-3.3-70b-instruct": {
            "rating": 1284.644247732403,
            "rating_q975": 1291.3205266807936,
            "rating_q025": 1277.9679687840126
        },
        "mistral-large-2407": {
            "rating": 1284.4701168375634,
            "rating_q975": 1292.7286251093822,
            "rating_q025": 1276.2116085657447
        },
        "gpt-4-1106-preview": {
            "rating": 1283.3407612237809,
            "rating_q975": 1290.8499027852113,
            "rating_q025": 1275.8316196623505
        },
        "hunyuan-large-vision": {
            "rating": 1282.7718411195553,
            "rating_q975": 1305.9052137414,
            "rating_q025": 1259.6384684977106
        },
        "qwen-max-0919": {
            "rating": 1282.307396706011,
            "rating_q975": 1294.0629638700136,
            "rating_q025": 1270.5518295420086
        },
        "gemma-2-9b-it-simpo": {
            "rating": 1281.144049686054,
            "rating_q975": 1295.5516402527503,
            "rating_q025": 1266.7364591193575
        },
        "gpt-oss-120b": {
            "rating": 1280.467918151835,
            "rating_q975": 1290.9275263052853,
            "rating_q025": 1270.0083099983847
        },
        "o1-mini": {
            "rating": 1278.447765851483,
            "rating_q975": 1285.695550326513,
            "rating_q025": 1271.1999813764528
        },
        "gpt-4-0125-preview": {
            "rating": 1277.479156218185,
            "rating_q975": 1285.189189730644,
            "rating_q025": 1269.7691227057257
        },
        "gemma-3-4b-it": {
            "rating": 1275.9202140033444,
            "rating_q975": 1297.9458287746688,
            "rating_q025": 1253.89459923202
        },
        "llama-3.1-nemotron-70b-instruct": {
            "rating": 1274.7495787249923,
            "rating_q975": 1293.3392857018607,
            "rating_q025": 1256.1598717481238
        },
        "mistral-large-2411": {
            "rating": 1273.1164583301977,
            "rating_q975": 1281.8315168824452,
            "rating_q025": 1264.4013997779502
        },
        "hunyuan-standard-2025-02-10": {
            "rating": 1272.9180690803062,
            "rating_q975": 1296.7387363356172,
            "rating_q025": 1249.0974018249951
        },
        "qwen2.5-plus-1127": {
            "rating": 1271.7820447138547,
            "rating_q975": 1285.888036133249,
            "rating_q025": 1257.6760532944604
        },
        "mistral-small-3.1-24b-instruct-2503": {
            "rating": 1271.6825662824529,
            "rating_q975": 1281.1362299458044,
            "rating_q025": 1262.2289026191013
        },
        "ling-flash-2.0": {
            "rating": 1270.4884192569734,
            "rating_q975": 1290.8063039916935,
            "rating_q025": 1250.1705345222533
        },
        "grok-2-mini-2024-08-13": {
            "rating": 1269.8879389255467,
            "rating_q975": 1277.1955150055724,
            "rating_q025": 1262.580362845521
        },
        "athene-70b-0725": {
            "rating": 1267.4102668903972,
            "rating_q975": 1278.4122375020256,
            "rating_q025": 1256.4082962787688
        },
        "reka-core-20240904": {
            "rating": 1264.0953359577293,
            "rating_q975": 1282.2164297054594,
            "rating_q025": 1245.9742422099991
        },
        "deepseek-v2.5": {
            "rating": 1262.7020520312017,
            "rating_q975": 1273.0902962376224,
            "rating_q025": 1252.313807824781
        },
        "command-r-plus-08-2024": {
            "rating": 1261.3216223787163,
            "rating_q975": 1276.1426802218634,
            "rating_q025": 1246.500564535569
        },
        "gpt-4-0613": {
            "rating": 1261.260679234204,
            "rating_q975": 1269.2008588848191,
            "rating_q025": 1253.3204995835888
        },
        "gemini-1.5-flash-001": {
            "rating": 1261.0467254309565,
            "rating_q975": 1269.097291965651,
            "rating_q025": 1252.996158896262
        },
        "ring-flash-2.0": {
            "rating": 1258.5754210509622,
            "rating_q975": 1278.4597872029422,
            "rating_q025": 1238.6910548989822
        },
        "llama-3.1-nemotron-51b-instruct": {
            "rating": 1258.3794330219384,
            "rating_q975": 1283.7174887655997,
            "rating_q025": 1233.0413772782772
        },
        "jamba-1.5-large": {
            "rating": 1258.0090568843566,
            "rating_q975": 1273.9645538418504,
            "rating_q025": 1242.0535599268628
        },
        "llama-3.1-70b-instruct": {
            "rating": 1256.0112976345613,
            "rating_q975": 1263.3951353235234,
            "rating_q025": 1248.6274599455992
        },
        "gemma-2-9b-it": {
            "rating": 1254.9270328251819,
            "rating_q975": 1261.9723007235718,
            "rating_q025": 1247.881764926792
        },
        "llama-3-70b-instruct": {
            "rating": 1252.067242276318,
            "rating_q975": 1259.2095345681907,
            "rating_q025": 1244.9249499844452
        },
        "gpt-5-nano-high": {
            "rating": 1251.7197401619458,
            "rating_q975": 1271.8226946746706,
            "rating_q025": 1231.616785649221
        },
        "qwen2.5-72b-instruct": {
            "rating": 1251.5603099678417,
            "rating_q975": 1259.6113923509029,
            "rating_q025": 1243.5092275847805
        },
        "gpt-4-0314": {
            "rating": 1250.5914418263378,
            "rating_q975": 1260.2246219048538,
            "rating_q025": 1240.9582617478218
        },
        "athene-v2-chat": {
            "rating": 1250.261084958523,
            "rating_q975": 1259.7344306315902,
            "rating_q025": 1240.787739285456
        },
        "llama-3.1-tulu-3-70b": {
            "rating": 1246.078884076447,
            "rating_q975": 1270.8418880940549,
            "rating_q025": 1221.315880058839
        },
        "claude-3-sonnet-20240229": {
            "rating": 1242.3049500421073,
            "rating_q975": 1250.14384642963,
            "rating_q025": 1234.4660536545846
        },
        "reka-flash-20240904": {
            "rating": 1239.797350229511,
            "rating_q975": 1257.1383920396988,
            "rating_q025": 1222.4563084193232
        },
        "glm-4-0520": {
            "rating": 1238.582311270597,
            "rating_q975": 1253.5828096444884,
            "rating_q025": 1223.5818128967057
        },
        "gpt-oss-20b": {
            "rating": 1238.2172245003374,
            "rating_q975": 1256.1616599444958,
            "rating_q025": 1220.272789056179
        },
        "gemini-1.5-flash-8b-001": {
            "rating": 1236.4957012383259,
            "rating_q975": 1244.9840431656953,
            "rating_q025": 1228.0073593109564
        },
        "nemotron-4-340b-instruct": {
            "rating": 1235.9670139853415,
            "rating_q975": 1247.2961791302553,
            "rating_q025": 1224.6378488404278
        },
        "amazon-nova-pro-v1.0": {
            "rating": 1234.0585201083836,
            "rating_q975": 1243.3143524861418,
            "rating_q025": 1224.8026877306254
        },
        "command-r-plus": {
            "rating": 1234.0327039006986,
            "rating_q975": 1242.3077842105956,
            "rating_q025": 1225.7576235908016
        },
        "c4ai-aya-expanse-32b": {
            "rating": 1225.5489939659606,
            "rating_q975": 1235.1958806345765,
            "rating_q025": 1215.9021072973446
        },
        "mistral-small-24b-instruct-2501": {
            "rating": 1225.2660473733176,
            "rating_q975": 1237.3722212144478,
            "rating_q025": 1213.1598735321875
        },
        "olmo-2-0325-32b-instruct": {
            "rating": 1223.781811035742,
            "rating_q975": 1248.149590435301,
            "rating_q025": 1199.4140316361832
        },
        "qwen2-72b-instruct": {
            "rating": 1221.1861085356315,
            "rating_q975": 1230.4361065750877,
            "rating_q025": 1211.9361104961754
        },
        "amazon-nova-lite-v1.0": {
            "rating": 1218.8075299958898,
            "rating_q975": 1229.0397369069522,
            "rating_q025": 1208.5753230848275
        },
        "ministral-8b-2410": {
            "rating": 1217.2024288507178,
            "rating_q975": 1239.1078268555784,
            "rating_q025": 1195.297030845857
        },
        "claude-3-haiku-20240307": {
            "rating": 1212.1597106583997,
            "rating_q975": 1219.3487548194387,
            "rating_q025": 1204.9706664973608
        },
        "mistral-large-2402": {
            "rating": 1208.4096772229177,
            "rating_q975": 1217.480626229007,
            "rating_q025": 1199.3387282168285
        },
        "phi-4": {
            "rating": 1208.3590462914462,
            "rating_q975": 1217.7827086271366,
            "rating_q025": 1198.935383955756
        },
        "command-r-08-2024": {
            "rating": 1207.858471992707,
            "rating_q975": 1223.215717463406,
            "rating_q025": 1192.5012265220082
        },
        "jamba-1.5-mini": {
            "rating": 1207.7841776401178,
            "rating_q975": 1223.351686587119,
            "rating_q025": 1192.2166686931166
        },
        "qwen2.5-coder-32b-instruct": {
            "rating": 1201.2568410325816,
            "rating_q975": 1220.3802211722598,
            "rating_q025": 1182.1334608929035
        },
        "deepseek-coder-v2": {
            "rating": 1200.4162368184163,
            "rating_q975": 1213.3739591125359,
            "rating_q025": 1187.4585145242968
        },
        "gemini-pro-dev-api": {
            "rating": 1199.098014785562,
            "rating_q975": 1212.794557642442,
            "rating_q025": 1185.4014719286822
        },
        "amazon-nova-micro-v1.0": {
            "rating": 1196.2546276831547,
            "rating_q975": 1206.7400142264617,
            "rating_q025": 1185.7692411398477
        },
        "wizardlm-70b": {
            "rating": 1195.1357563550928,
            "rating_q975": 1211.8215992709722,
            "rating_q025": 1178.4499134392133
        },
        "llama-3-8b-instruct": {
            "rating": 1194.1029548822014,
            "rating_q975": 1201.8724051574563,
            "rating_q025": 1186.3335046069465
        },
        "hunyuan-standard-256k": {
            "rating": 1193.429718758057,
            "rating_q975": 1222.604910310147,
            "rating_q025": 1164.2545272059672
        },
        "command-r": {
            "rating": 1193.4126898456097,
            "rating_q975": 1202.858421321598,
            "rating_q025": 1183.9669583696216
        },
        "llama-3.1-tulu-3-8b": {
            "rating": 1192.8205278154992,
            "rating_q975": 1217.9467227632133,
            "rating_q025": 1167.694332867785
        },
        "mistral-medium": {
            "rating": 1191.6630839572422,
            "rating_q975": 1202.280866663693,
            "rating_q025": 1181.0453012507915
        },
        "qwen1.5-110b-chat": {
            "rating": 1191.031128507038,
            "rating_q975": 1202.3536719406284,
            "rating_q025": 1179.7085850734475
        },
        "c4ai-aya-expanse-8b": {
            "rating": 1188.3586492837296,
            "rating_q975": 1203.119004518578,
            "rating_q025": 1173.5982940488811
        },
        "mixtral-8x22b-instruct-v0.1": {
            "rating": 1187.5864990933346,
            "rating_q975": 1196.5629928287462,
            "rating_q025": 1178.610005357923
        },
        "qwen1.5-72b-chat": {
            "rating": 1184.8653692426235,
            "rating_q975": 1194.6919889719359,
            "rating_q025": 1175.0387495133111
        },
        "gpt-3.5-turbo-0125": {
            "rating": 1184.6504319333749,
            "rating_q975": 1193.1215490186296,
            "rating_q025": 1176.1793148481202
        },
        "openchat-3.5": {
            "rating": 1181.470084760671,
            "rating_q975": 1198.9922911295646,
            "rating_q025": 1163.9478783917773
        },
        "gemma-2-2b-it": {
            "rating": 1181.2077156104688,
            "rating_q975": 1189.1182231646703,
            "rating_q025": 1173.2972080562672
        },
        "gemini-pro": {
            "rating": 1179.4151755644782,
            "rating_q975": 1200.5146683557466,
            "rating_q025": 1158.3156827732098
        },
        "reka-flash-21b-20240226-online": {
            "rating": 1178.650783451139,
            "rating_q975": 1192.9352368833408,
            "rating_q025": 1164.366330018937
        },
        "llama-3.1-8b-instruct": {
            "rating": 1176.1720391117697,
            "rating_q975": 1184.1950658216865,
            "rating_q025": 1168.1490124018528
        },
        "reka-flash-21b-20240226": {
            "rating": 1173.0676784418656,
            "rating_q975": 1184.994115554089,
            "rating_q025": 1161.1412413296423
        },
        "vicuna-33b": {
            "rating": 1170.577476377072,
            "rating_q975": 1182.3377957481484,
            "rating_q025": 1158.8171570059953
        },
        "granite-3.1-8b-instruct": {
            "rating": 1168.1391518952018,
            "rating_q975": 1194.382330904946,
            "rating_q025": 1141.8959728854577
        },
        "zephyr-orpo-141b-A35b-v0.1": {
            "rating": 1164.6980056304888,
            "rating_q975": 1187.8565733417033,
            "rating_q025": 1141.5394379192742
        },
        "dbrx-instruct-preview": {
            "rating": 1161.3834541603408,
            "rating_q975": 1172.8173991903277,
            "rating_q025": 1149.9495091303538
        },
        "yi-1.5-34b-chat": {
            "rating": 1156.858185534132,
            "rating_q975": 1167.6915541060298,
            "rating_q025": 1146.0248169622341
        },
        "mixtral-8x7b-instruct-v0.1": {
            "rating": 1156.5862104060898,
            "rating_q975": 1164.8649012779802,
            "rating_q025": 1148.3075195341994
        },
        "openhermes-2.5-mistral-7b": {
            "rating": 1154.3402617434513,
            "rating_q975": 1176.1076751391847,
            "rating_q025": 1132.5728483477178
        },
        "yi-34b-chat": {
            "rating": 1152.2490490792552,
            "rating_q975": 1165.687078897946,
            "rating_q025": 1138.8110192605643
        },
        "falcon-180b-chat": {
            "rating": 1149.9153083150013,
            "rating_q975": 1186.9908447427724,
            "rating_q025": 1112.8397718872302
        },
        "gpt-3.5-turbo-1106": {
            "rating": 1147.9094871020875,
            "rating_q975": 1162.8112200854382,
            "rating_q025": 1133.0077541187368
        },
        "granite-3.1-2b-instruct": {
            "rating": 1147.6448977802647,
            "rating_q975": 1176.3944068342603,
            "rating_q025": 1118.8953887262692
        },
        "phi-3-medium-4k-instruct": {
            "rating": 1147.3782189513222,
            "rating_q975": 1158.0160151325492,
            "rating_q025": 1136.7404227700952
        },
        "gemma-1.1-7b-it": {
            "rating": 1144.5201400290493,
            "rating_q975": 1155.8596384460132,
            "rating_q025": 1133.1806416120855
        },
        "openchat-3.5-0106": {
            "rating": 1143.9370702103208,
            "rating_q975": 1158.6313496100775,
            "rating_q025": 1129.2427908105642
        },
        "tulu-2-dpo-70b": {
            "rating": 1143.8525637472057,
            "rating_q975": 1163.0147679504894,
            "rating_q025": 1124.690359543922
        },
        "llama-3.2-3b-instruct": {
            "rating": 1142.1541218389689,
            "rating_q975": 1161.586623264798,
            "rating_q025": 1122.7216204131398
        },
        "snowflake-arctic-instruct": {
            "rating": 1140.266481538766,
            "rating_q975": 1152.093005288453,
            "rating_q025": 1128.4399577890788
        },
        "wizardlm-13b": {
            "rating": 1137.805272093988,
            "rating_q975": 1155.3132121938445,
            "rating_q025": 1120.2973319941314
        },
        "solar-10.7b-instruct-v1.0": {
            "rating": 1137.2750314740435,
            "rating_q975": 1160.8963871893618,
            "rating_q025": 1113.6536757587253
        },
        "qwen1.5-14b-chat": {
            "rating": 1135.4058910595027,
            "rating_q975": 1149.3499857849674,
            "rating_q025": 1121.461796334038
        },
        "granite-3.0-8b-instruct": {
            "rating": 1135.0027929184357,
            "rating_q975": 1156.0760143920045,
            "rating_q025": 1113.929571444867
        },
        "nous-hermes-2-mixtral-8x7b-dpo": {
            "rating": 1133.6315971370427,
            "rating_q975": 1156.861141252487,
            "rating_q025": 1110.4020530215985
        },
        "starling-lm-7b-alpha": {
            "rating": 1133.4227147381928,
            "rating_q975": 1148.862770550524,
            "rating_q025": 1117.9826589258616
        },
        "zephyr-7b-beta": {
            "rating": 1133.036748626387,
            "rating_q975": 1148.873625916316,
            "rating_q025": 1117.1998713364578
        },
        "dolphin-2.2.1-mistral-7b": {
            "rating": 1131.537701176277,
            "rating_q975": 1165.175723753125,
            "rating_q025": 1097.899678599429
        },
        "phi-3-small-8k-instruct": {
            "rating": 1131.2278935301206,
            "rating_q975": 1144.0715263763695,
            "rating_q025": 1118.3842606838716
        },
        "guanaco-33b": {
            "rating": 1131.1068450152657,
            "rating_q975": 1158.5531900845951,
            "rating_q025": 1103.6604999459362
        },
        "mpt-30b-chat": {
            "rating": 1130.4106258377778,
            "rating_q975": 1159.3648025195705,
            "rating_q025": 1101.4564491559852
        },
        "qwen1.5-32b-chat": {
            "rating": 1130.1448392388174,
            "rating_q975": 1142.3768354816273,
            "rating_q025": 1117.9128429960076
        },
        "internlm2_5-20b-chat": {
            "rating": 1129.6248501962991,
            "rating_q975": 1145.5055122964895,
            "rating_q025": 1113.7441880961087
        },
        "deepseek-llm-67b-chat": {
            "rating": 1129.3567430578473,
            "rating_q975": 1150.9553458074756,
            "rating_q025": 1107.758140308219
        },
        "vicuna-13b": {
            "rating": 1122.1320702502471,
            "rating_q975": 1134.6412432886345,
            "rating_q025": 1109.6228972118597
        },
        "llama2-70b-steerlm-chat": {
            "rating": 1117.4955899059569,
            "rating_q975": 1142.664511096715,
            "rating_q025": 1092.3266687151988
        },
        "llama-2-70b-chat": {
            "rating": 1110.5676493797364,
            "rating_q975": 1120.4037789665952,
            "rating_q025": 1100.7315197928776
        },
        "starling-lm-7b-beta": {
            "rating": 1107.8169223199475,
            "rating_q975": 1122.2449875913312,
            "rating_q025": 1093.3888570485638
        },
        "qwq-32b-preview": {
            "rating": 1106.6335869074878,
            "rating_q975": 1135.8460877569687,
            "rating_q025": 1077.421086058007
        },
        "mistral-7b-instruct-v0.2": {
            "rating": 1103.0580379298801,
            "rating_q975": 1115.3709862764852,
            "rating_q025": 1090.745089583275
        },
        "zephyr-7b-alpha": {
            "rating": 1099.8172271601854,
            "rating_q975": 1129.5618027398702,
            "rating_q025": 1070.0726515805006
        },
        "qwen-14b-chat": {
            "rating": 1098.034524842617,
            "rating_q975": 1118.7225810970633,
            "rating_q025": 1077.3464685881706
        },
        "gemma-7b-it": {
            "rating": 1096.7339752469632,
            "rating_q975": 1114.381341141007,
            "rating_q025": 1079.0866093529194
        },
        "granite-3.0-2b-instruct": {
            "rating": 1096.352831421736,
            "rating_q975": 1117.791959268362,
            "rating_q025": 1074.91370357511
        },
        "phi-3-mini-4k-instruct-june-2024": {
            "rating": 1092.5633898237534,
            "rating_q975": 1107.0231968684668,
            "rating_q025": 1078.10358277904
        },
        "mistral-7b-instruct": {
            "rating": 1089.9835268225072,
            "rating_q975": 1106.6477334875756,
            "rating_q025": 1073.3193201574388
        },
        "llama-2-13b-chat": {
            "rating": 1089.9737395269697,
            "rating_q975": 1102.2937552531039,
            "rating_q025": 1077.6537238008355
        },
        "stripedhyena-nous-7b": {
            "rating": 1088.0507861394885,
            "rating_q975": 1108.7625924709926,
            "rating_q025": 1067.3389798079845
        },
        "gemma-1.1-2b-it": {
            "rating": 1087.9743685262645,
            "rating_q975": 1104.633711087607,
            "rating_q025": 1071.315025964922
        },
        "alpaca-13b": {
            "rating": 1086.7181079688326,
            "rating_q975": 1108.6411532309187,
            "rating_q025": 1064.7950627067464
        },
        "vicuna-7b": {
            "rating": 1086.419367711856,
            "rating_q975": 1104.3030414105044,
            "rating_q025": 1068.5356940132076
        },
        "phi-3-mini-128k-instruct": {
            "rating": 1084.5505595803404,
            "rating_q975": 1098.7173181593134,
            "rating_q025": 1070.3838010013674
        },
        "palm-2": {
            "rating": 1083.8266974614346,
            "rating_q975": 1101.1658669702886,
            "rating_q025": 1066.4875279525806
        },
        "codellama-34b-instruct": {
            "rating": 1082.950050319606,
            "rating_q975": 1099.4171142008395,
            "rating_q025": 1066.4829864383723
        },
        "llama-3.2-1b-instruct": {
            "rating": 1082.6094553292587,
            "rating_q975": 1102.8870220001659,
            "rating_q025": 1062.3318886583515
        },
        "qwen1.5-7b-chat": {
            "rating": 1076.9383797689752,
            "rating_q975": 1099.8156440101266,
            "rating_q025": 1054.0611155278239
        },
        "smollm2-1.7b-instruct": {
            "rating": 1075.9186894136144,
            "rating_q975": 1110.951565892784,
            "rating_q025": 1040.8858129344449
        },
        "gemma-2b-it": {
            "rating": 1072.5537107125774,
            "rating_q975": 1095.804838468921,
            "rating_q025": 1049.302582956234
        },
        "llama-2-7b-chat": {
            "rating": 1070.9057606032868,
            "rating_q975": 1084.2585585217385,
            "rating_q025": 1057.5529626848352
        },
        "phi-3-mini-4k-instruct": {
            "rating": 1069.2375856904678,
            "rating_q975": 1081.8772389273768,
            "rating_q025": 1056.5979324535588
        },
        "gpt4all-13b-snoozy": {
            "rating": 1058.6456681832342,
            "rating_q975": 1095.6958522198718,
            "rating_q025": 1021.5954841465967
        },
        "mpt-7b-chat": {
            "rating": 1045.7247749327025,
            "rating_q975": 1069.8967074429875,
            "rating_q025": 1021.5528424224176
        },
        "qwen1.5-4b-chat": {
            "rating": 1045.0366421060185,
            "rating_q975": 1063.7488671143583,
            "rating_q025": 1026.3244170976786
        },
        "koala-13b": {
            "rating": 1040.8836954659307,
            "rating_q975": 1061.4508904535605,
            "rating_q025": 1020.316500478301
        },
        "chatglm3-6b": {
            "rating": 1037.1758212478926,
            "rating_q975": 1060.2067483395747,
            "rating_q025": 1014.1448941562105
        },
        "oasst-pythia-12b": {
            "rating": 1006.9467174207277,
            "rating_q975": 1027.3670799881631,
            "rating_q025": 986.5263548532923
        },
        "olmo-7b-instruct": {
            "rating": 1003.8998215222791,
            "rating_q975": 1024.1022870506672,
            "rating_q025": 983.697355993891
        },
        "chatglm2-6b": {
            "rating": 1002.0650771929434,
            "rating_q975": 1028.1546541742778,
            "rating_q025": 975.975500211609
        },
        "RWKV-4-Raven-14B": {
            "rating": 1001.2333525953345,
            "rating_q975": 1023.6916404720718,
            "rating_q025": 978.7750647185973
        },
        "fastchat-t5-3b": {
            "rating": 985.5535159797194,
            "rating_q975": 1009.5990047394679,
            "rating_q025": 961.5080272199708
        },
        "dolly-v2-12b": {
            "rating": 963.5525761763781,
            "rating_q975": 991.2052244965892,
            "rating_q025": 935.8999278561671
        },
        "chatglm-6b": {
            "rating": 948.6398209790249,
            "rating_q975": 973.2745859509405,
            "rating_q025": 924.0050560071093
        },
        "llama-13b": {
            "rating": 927.8862332271337,
            "rating_q975": 961.5601991643123,
            "rating_q025": 894.2122672899552
        },
        "stablelm-tuned-alpha-7b": {
            "rating": 927.0790201844954,
            "rating_q975": 955.5188349901039,
            "rating_q025": 898.639205378887
        }
    },
    "english": {
        "claude-sonnet-4-5-20250929-thinking-32k": {
            "rating": 1467.5050796837295,
            "rating_q975": 1475.421562595334,
            "rating_q025": 1459.588596772125
        },
        "claude-opus-4-1-20250805-thinking-16k": {
            "rating": 1465.8318262673556,
            "rating_q975": 1471.8585218149133,
            "rating_q025": 1459.805130719798
        },
        "claude-sonnet-4-5-20250929": {
            "rating": 1457.6777532641045,
            "rating_q975": 1467.8766698190875,
            "rating_q025": 1447.4788367091214
        },
        "gemini-2.5-pro": {
            "rating": 1454.1043827814683,
            "rating_q975": 1459.0869486852496,
            "rating_q025": 1449.121816877687
        },
        "claude-opus-4-1-20250805": {
            "rating": 1454.0644146223356,
            "rating_q975": 1459.6018552289809,
            "rating_q025": 1448.5269740156903
        },
        "gpt-4.5-preview-2025-02-27": {
            "rating": 1445.6689174627734,
            "rating_q975": 1452.6746410513647,
            "rating_q025": 1438.663193874182
        },
        "chatgpt-4o-latest-20250326": {
            "rating": 1445.42955885644,
            "rating_q975": 1450.2376718849282,
            "rating_q025": 1440.621445827952
        },
        "glm-4.6": {
            "rating": 1443.3432291786858,
            "rating_q975": 1451.8904346052223,
            "rating_q025": 1434.7960237521493
        },
        "o3-2025-04-16": {
            "rating": 1443.191936287739,
            "rating_q975": 1447.935600543219,
            "rating_q025": 1438.4482720322592
        },
        "qwen3-max-preview": {
            "rating": 1440.9410196092017,
            "rating_q975": 1447.251745040411,
            "rating_q025": 1434.6302941779925
        },
        "gpt-5-high": {
            "rating": 1440.747627038046,
            "rating_q975": 1446.8420977651706,
            "rating_q025": 1434.6531563109213
        },
        "deepseek-v3.2-exp-thinking": {
            "rating": 1438.1157040155208,
            "rating_q975": 1447.171014616302,
            "rating_q025": 1429.0603934147396
        },
        "claude-opus-4-20250514-thinking-16k": {
            "rating": 1434.3266157878845,
            "rating_q975": 1439.8493148327066,
            "rating_q025": 1428.8039167430625
        },
        "qwen3-max-2025-09-23": {
            "rating": 1433.4177412486854,
            "rating_q975": 1442.1348073237791,
            "rating_q025": 1424.7006751735917
        },
        "gpt-5-chat": {
            "rating": 1433.1427289407345,
            "rating_q975": 1439.0695107366594,
            "rating_q025": 1427.2159471448097
        },
        "deepseek-v3.1-thinking": {
            "rating": 1433.049698152929,
            "rating_q975": 1441.6122082793427,
            "rating_q025": 1424.4871880265155
        },
        "deepseek-v3.2-exp": {
            "rating": 1432.7332489232056,
            "rating_q975": 1472.426113293714,
            "rating_q025": 1393.040384552697
        },
        "claude-haiku-4-5-20251001": {
            "rating": 1431.1363359599661,
            "rating_q975": 1439.6618743215636,
            "rating_q025": 1422.6107975983687
        },
        "grok-4-fast": {
            "rating": 1430.7186962564724,
            "rating_q975": 1441.0510488534283,
            "rating_q025": 1420.3863436595166
        },
        "deepseek-r1-0528": {
            "rating": 1428.9834909874742,
            "rating_q975": 1436.0794008665862,
            "rating_q025": 1421.8875811083622
        },
        "deepseek-v3.1": {
            "rating": 1428.9296487079314,
            "rating_q975": 1436.7481912048484,
            "rating_q025": 1421.1111062110144
        },
        "qwen3-235b-a22b-instruct-2507": {
            "rating": 1428.568984777192,
            "rating_q975": 1434.1380882576577,
            "rating_q025": 1422.9998812967265
        },
        "qwen3-vl-235b-a22b-instruct": {
            "rating": 1428.2289863898313,
            "rating_q975": 1437.2846296690025,
            "rating_q025": 1419.1733431106602
        },
        "deepseek-v3.1-terminus-thinking": {
            "rating": 1426.9180522916834,
            "rating_q975": 1441.169051436234,
            "rating_q025": 1412.6670531471327
        },
        "mistral-medium-2508": {
            "rating": 1426.296162893399,
            "rating_q975": 1432.2689591940643,
            "rating_q025": 1420.3233665927337
        },
        "deepseek-v3.1-terminus": {
            "rating": 1424.2328563162205,
            "rating_q975": 1437.9727755879687,
            "rating_q025": 1410.4929370444722
        },
        "kimi-k2-0905-preview": {
            "rating": 1424.0982674306988,
            "rating_q975": 1432.8747870869208,
            "rating_q025": 1415.3217477744768
        },
        "claude-opus-4-20250514": {
            "rating": 1423.7864490345332,
            "rating_q975": 1429.12669387144,
            "rating_q025": 1418.4462041976265
        },
        "longcat-flash-chat": {
            "rating": 1423.7102007348478,
            "rating_q975": 1432.0177993266173,
            "rating_q025": 1415.4026021430784
        },
        "gpt-4.1-2025-04-14": {
            "rating": 1423.3252975980824,
            "rating_q975": 1428.2040064461241,
            "rating_q025": 1418.4465887500407
        },
        "kimi-k2-0711-preview": {
            "rating": 1423.2149623150544,
            "rating_q975": 1429.3263972087254,
            "rating_q025": 1417.1035274213834
        },
        "grok-4-0709": {
            "rating": 1421.412636830147,
            "rating_q975": 1426.845922553847,
            "rating_q025": 1415.979351106447
        },
        "grok-3-preview-02-24": {
            "rating": 1420.8648746240056,
            "rating_q975": 1426.138544973765,
            "rating_q025": 1415.5912042742461
        },
        "glm-4.5": {
            "rating": 1418.607331277954,
            "rating_q975": 1424.9526562391857,
            "rating_q025": 1412.2620063167224
        },
        "gemini-2.5-flash-preview-09-2025": {
            "rating": 1417.4580918137115,
            "rating_q975": 1425.0580968937015,
            "rating_q025": 1409.8580867337214
        },
        "claude-sonnet-4-20250514-thinking-32k": {
            "rating": 1417.0718322912464,
            "rating_q975": 1422.619515821802,
            "rating_q025": 1411.5241487606909
        },
        "qwen3-next-80b-a3b-instruct": {
            "rating": 1416.1301833678326,
            "rating_q975": 1422.84512876715,
            "rating_q025": 1409.4152379685152
        },
        "gemini-2.5-flash": {
            "rating": 1410.7336668673986,
            "rating_q975": 1415.5773687095766,
            "rating_q025": 1405.8899650252206
        },
        "deepseek-r1": {
            "rating": 1410.4260137888573,
            "rating_q975": 1416.4262766891604,
            "rating_q025": 1404.4257508885541
        },
        "o1-2024-12-17": {
            "rating": 1410.1527700865265,
            "rating_q975": 1415.5292385374921,
            "rating_q025": 1404.776301635561
        },
        "o1-preview": {
            "rating": 1407.3886646754465,
            "rating_q975": 1413.482324643503,
            "rating_q025": 1401.29500470739
        },
        "mai-1-preview": {
            "rating": 1406.9231009164203,
            "rating_q975": 1414.00544917356,
            "rating_q025": 1399.8407526592805
        },
        "deepseek-v3-0324": {
            "rating": 1405.772491890261,
            "rating_q975": 1410.6339880929363,
            "rating_q025": 1400.910995687586
        },
        "o4-mini-2025-04-16": {
            "rating": 1405.5886570387197,
            "rating_q975": 1410.5381290352357,
            "rating_q025": 1400.6391850422037
        },
        "qwen3-235b-a22b-thinking-2507": {
            "rating": 1405.0719188566118,
            "rating_q975": 1413.997029879547,
            "rating_q025": 1396.1468078336766
        },
        "qwen3-235b-a22b-no-thinking": {
            "rating": 1404.1604432255865,
            "rating_q975": 1409.668687130585,
            "rating_q025": 1398.652199320588
        },
        "claude-3-7-sonnet-20250219-thinking-32k": {
            "rating": 1402.363121129319,
            "rating_q975": 1407.48485486913,
            "rating_q025": 1397.2413873895082
        },
        "qwen3-vl-235b-a22b-thinking": {
            "rating": 1402.1379523079486,
            "rating_q975": 1411.5994244118504,
            "rating_q025": 1392.6764802040468
        },
        "gpt-5-mini-high": {
            "rating": 1400.7662882994869,
            "rating_q975": 1407.2476263045542,
            "rating_q025": 1394.2849502944196
        },
        "claude-sonnet-4-20250514": {
            "rating": 1399.7044922209893,
            "rating_q975": 1405.118761507741,
            "rating_q025": 1394.2902229342376
        },
        "qwen3-coder-480b-a35b-instruct": {
            "rating": 1398.610812117112,
            "rating_q975": 1404.9198812756854,
            "rating_q025": 1392.3017429585384
        },
        "mistral-medium-2505": {
            "rating": 1397.4969710405471,
            "rating_q975": 1403.229821124368,
            "rating_q025": 1391.7641209567262
        },
        "gpt-4.1-mini-2025-04-14": {
            "rating": 1396.7042647949886,
            "rating_q975": 1402.011254401478,
            "rating_q025": 1391.3972751884992
        },
        "qwen3-30b-a3b-instruct-2507": {
            "rating": 1393.57174545081,
            "rating_q975": 1399.9459495786316,
            "rating_q025": 1387.1975413229886
        },
        "minimax-m1": {
            "rating": 1393.4857965398833,
            "rating_q975": 1398.8432463619565,
            "rating_q025": 1388.12834671781
        },
        "hunyuan-turbos-20250416": {
            "rating": 1390.3047364844936,
            "rating_q975": 1398.4021542369355,
            "rating_q025": 1382.2073187320516
        },
        "glm-4.5-air": {
            "rating": 1388.3395520597671,
            "rating_q975": 1394.1815911275069,
            "rating_q025": 1382.4975129920274
        },
        "qwen3-235b-a22b": {
            "rating": 1387.2219948830266,
            "rating_q975": 1393.0908261621053,
            "rating_q025": 1381.353163603948
        },
        "hunyuan-t1-20250711": {
            "rating": 1386.665433738458,
            "rating_q975": 1399.2393736530505,
            "rating_q025": 1374.0914938238654
        },
        "qwen3-next-80b-a3b-thinking": {
            "rating": 1386.0419847184712,
            "rating_q975": 1393.6890329146509,
            "rating_q025": 1378.3949365222916
        },
        "gemini-2.5-flash-lite-preview-09-2025-no-thinking": {
            "rating": 1385.1200361974927,
            "rating_q975": 1392.554291521734,
            "rating_q025": 1377.6857808732514
        },
        "qwen2.5-max": {
            "rating": 1382.059402864761,
            "rating_q975": 1386.9829110419937,
            "rating_q025": 1377.1358946875284
        },
        "gemini-2.5-flash-lite-preview-06-17-thinking": {
            "rating": 1380.8703666839467,
            "rating_q975": 1386.544648269717,
            "rating_q025": 1375.1960850981764
        },
        "claude-3-5-sonnet-20241022": {
            "rating": 1380.3452807856677,
            "rating_q975": 1384.0450649522784,
            "rating_q025": 1376.645496619057
        },
        "mistral-small-2506": {
            "rating": 1379.5376291811247,
            "rating_q975": 1386.2590578553036,
            "rating_q025": 1372.8162005069457
        },
        "glm-4.5v": {
            "rating": 1378.420710381824,
            "rating_q975": 1390.4328810101597,
            "rating_q025": 1366.4085397534882
        },
        "o3-mini-high": {
            "rating": 1378.154321637463,
            "rating_q975": 1384.5378953477327,
            "rating_q025": 1371.7707479271933
        },
        "ling-flash-2.0": {
            "rating": 1376.9920726156965,
            "rating_q975": 1386.926538628774,
            "rating_q025": 1367.057606602619
        },
        "grok-3-mini-high": {
            "rating": 1375.029726841597,
            "rating_q975": 1381.8483168568093,
            "rating_q025": 1368.2111368263847
        },
        "llama-3.1-nemotron-ultra-253b-v1": {
            "rating": 1373.9391938737924,
            "rating_q975": 1388.8405098364276,
            "rating_q025": 1359.0378779111572
        },
        "gemma-3-27b-it": {
            "rating": 1372.7915969318185,
            "rating_q975": 1377.3534646773876,
            "rating_q025": 1368.2297291862494
        },
        "llama-3.3-nemotron-49b-super-v1": {
            "rating": 1372.235534199011,
            "rating_q975": 1387.8379508840137,
            "rating_q025": 1356.6331175140083
        },
        "step-3": {
            "rating": 1371.6938128896975,
            "rating_q975": 1382.0705621663274,
            "rating_q025": 1361.3170636130676
        },
        "grok-3-mini-beta": {
            "rating": 1369.8766389621435,
            "rating_q975": 1376.1058360436696,
            "rating_q025": 1363.6474418806174
        },
        "deepseek-v3": {
            "rating": 1369.8095270263616,
            "rating_q975": 1375.574822419079,
            "rating_q025": 1364.0442316336441
        },
        "amazon-nova-experimental-chat-10-09": {
            "rating": 1368.7353894870457,
            "rating_q975": 1379.250505955716,
            "rating_q025": 1358.2202730183753
        },
        "nvidia-llama-3.3-nemotron-super-49b-v1.5": {
            "rating": 1367.2575676995773,
            "rating_q975": 1381.333992161636,
            "rating_q025": 1353.1811432375187
        },
        "qwen3-32b": {
            "rating": 1364.488564735436,
            "rating_q975": 1376.913481577232,
            "rating_q025": 1352.06364789364
        },
        "gpt-oss-120b": {
            "rating": 1363.3106741078886,
            "rating_q975": 1369.331137674205,
            "rating_q025": 1357.2902105415724
        },
        "command-a-03-2025": {
            "rating": 1362.9592876452039,
            "rating_q975": 1367.4328398251937,
            "rating_q025": 1358.485735465214
        },
        "o3-mini": {
            "rating": 1362.838354040865,
            "rating_q975": 1367.0659282055135,
            "rating_q025": 1358.6107798762164
        },
        "llama-3.1-405b-instruct-bf16": {
            "rating": 1361.0792265678328,
            "rating_q975": 1365.4832141522702,
            "rating_q025": 1356.6752389833955
        },
        "hunyuan-turbos-20250226": {
            "rating": 1359.7915147098952,
            "rating_q975": 1374.607028196144,
            "rating_q025": 1344.9760012236463
        },
        "hunyuan-turbo-0110": {
            "rating": 1357.527855195819,
            "rating_q975": 1371.8096793993116,
            "rating_q025": 1343.2460309923265
        },
        "qwq-32b": {
            "rating": 1357.4288919068213,
            "rating_q975": 1362.9622652311082,
            "rating_q025": 1351.8955185825344
        },
        "llama-3.1-405b-instruct-fp8": {
            "rating": 1356.750825079106,
            "rating_q975": 1361.2779938412357,
            "rating_q025": 1352.2236563169765
        },
        "gemini-1.5-pro-002": {
            "rating": 1355.822565864064,
            "rating_q975": 1360.0123709373538,
            "rating_q025": 1351.6327607907742
        },
        "qwen-plus-0125": {
            "rating": 1355.4603172645425,
            "rating_q975": 1365.797308644999,
            "rating_q025": 1345.123325884086
        },
        "gpt-4o-2024-05-13": {
            "rating": 1355.2621586948526,
            "rating_q975": 1359.6039315354305,
            "rating_q025": 1350.9203858542746
        },
        "gemini-2.0-flash-lite-preview-02-05": {
            "rating": 1355.2562081220765,
            "rating_q975": 1360.5502140106826,
            "rating_q025": 1349.9622022334704
        },
        "yi-lightning": {
            "rating": 1354.2417238687265,
            "rating_q975": 1360.6166190037611,
            "rating_q025": 1347.8668287336918
        },
        "step-2-16k-exp-202412": {
            "rating": 1353.6586394987867,
            "rating_q975": 1364.29388299935,
            "rating_q025": 1343.0233959982234
        },
        "o1-mini": {
            "rating": 1352.2544510453004,
            "rating_q975": 1356.808407761917,
            "rating_q025": 1347.7004943286838
        },
        "glm-4-plus-0111": {
            "rating": 1351.6195812823464,
            "rating_q975": 1361.8150751845894,
            "rating_q025": 1341.4240873801034
        },
        "ring-flash-2.0": {
            "rating": 1349.742228105165,
            "rating_q975": 1359.6733899079175,
            "rating_q025": 1339.8110663024124
        },
        "gpt-5-nano-high": {
            "rating": 1347.3373257489263,
            "rating_q975": 1356.798304625499,
            "rating_q025": 1337.8763468723537
        },
        "gemma-3-12b-it": {
            "rating": 1347.2763368331994,
            "rating_q975": 1359.1400134545008,
            "rating_q025": 1335.412660211898
        },
        "gpt-4o-2024-08-06": {
            "rating": 1346.982992805466,
            "rating_q975": 1352.1040705216403,
            "rating_q025": 1341.8619150892916
        },
        "claude-3-5-sonnet-20240620": {
            "rating": 1346.9206740565508,
            "rating_q975": 1351.2065112248586,
            "rating_q025": 1342.634836888243
        },
        "qwen3-30b-a3b": {
            "rating": 1345.570529187052,
            "rating_q975": 1351.4938180953536,
            "rating_q025": 1339.6472402787504
        },
        "llama-3.3-70b-instruct": {
            "rating": 1344.9052391671526,
            "rating_q975": 1348.9931964940972,
            "rating_q025": 1340.817281840208
        },
        "grok-2-2024-08-13": {
            "rating": 1344.2705180863745,
            "rating_q975": 1348.593938349011,
            "rating_q025": 1339.947097823738
        },
        "hunyuan-large-2025-02-10": {
            "rating": 1342.9961683364268,
            "rating_q975": 1355.2366912193102,
            "rating_q025": 1330.7556454535434
        },
        "llama-4-maverick-17b-128e-instruct": {
            "rating": 1341.6813203124088,
            "rating_q975": 1346.8922511043918,
            "rating_q025": 1336.470389520426
        },
        "llama-4-scout-17b-16e-instruct": {
            "rating": 1340.9745288622316,
            "rating_q975": 1346.8042009700985,
            "rating_q025": 1335.1448567543648
        },
        "gpt-4-turbo-2024-04-09": {
            "rating": 1340.8765949102196,
            "rating_q975": 1345.5320064888037,
            "rating_q025": 1336.2211833316355
        },
        "gemini-advanced-0514": {
            "rating": 1340.1075521763346,
            "rating_q975": 1346.0082853671925,
            "rating_q025": 1334.2068189854767
        },
        "gpt-4.1-nano-2025-04-14": {
            "rating": 1339.0586137547998,
            "rating_q975": 1348.9474276273181,
            "rating_q025": 1329.1697998822815
        },
        "step-1o-turbo-202506": {
            "rating": 1335.7022814049915,
            "rating_q975": 1344.694724541291,
            "rating_q025": 1326.709838268692
        },
        "mistral-large-2407": {
            "rating": 1335.6395305207802,
            "rating_q975": 1340.5127101422781,
            "rating_q025": 1330.7663508992823
        },
        "deepseek-v2.5-1210": {
            "rating": 1335.2634639245878,
            "rating_q975": 1345.506078347435,
            "rating_q025": 1325.0208495017405
        },
        "claude-3-5-haiku-20241022": {
            "rating": 1334.7119010450626,
            "rating_q975": 1338.6335608491981,
            "rating_q025": 1330.7902412409271
        },
        "gpt-oss-20b": {
            "rating": 1333.743058788411,
            "rating_q975": 1342.3585844344607,
            "rating_q025": 1325.1275331423612
        },
        "qwen2.5-plus-1127": {
            "rating": 1331.6477901611347,
            "rating_q975": 1339.4003420555093,
            "rating_q025": 1323.89523826676
        },
        "athene-v2-chat": {
            "rating": 1330.0725410314335,
            "rating_q975": 1335.603281444222,
            "rating_q025": 1324.541800618645
        },
        "gemma-3n-e4b-it": {
            "rating": 1329.357588414121,
            "rating_q975": 1335.7852766575704,
            "rating_q025": 1322.9299001706715
        },
        "magistral-medium-2506": {
            "rating": 1328.8508633952574,
            "rating_q975": 1337.6504064022215,
            "rating_q025": 1320.0513203882933
        },
        "gpt-4o-mini-2024-07-18": {
            "rating": 1327.684780116308,
            "rating_q975": 1331.7193159288174,
            "rating_q025": 1323.6502443037987
        },
        "llama-3.1-nemotron-70b-instruct": {
            "rating": 1327.3803930386737,
            "rating_q975": 1337.2186732110583,
            "rating_q025": 1317.542112866289
        },
        "gemini-1.5-pro-001": {
            "rating": 1327.1870638121518,
            "rating_q975": 1332.0818635118271,
            "rating_q025": 1322.2922641124765
        },
        "qwen-max-0919": {
            "rating": 1326.8021798374689,
            "rating_q975": 1333.982436564283,
            "rating_q025": 1319.6219231106547
        },
        "athene-70b-0725": {
            "rating": 1326.1834069682718,
            "rating_q975": 1332.9726692638242,
            "rating_q025": 1319.3941446727194
        },
        "gpt-4-1106-preview": {
            "rating": 1325.491071937894,
            "rating_q975": 1330.1533640145938,
            "rating_q025": 1320.8287798611943
        },
        "llama-3-70b-instruct": {
            "rating": 1325.0005329714656,
            "rating_q975": 1329.4122020477746,
            "rating_q025": 1320.5888638951567
        },
        "gpt-4-0125-preview": {
            "rating": 1324.6883212483378,
            "rating_q975": 1329.5513724624848,
            "rating_q025": 1319.825270034191
        },
        "glm-4-plus": {
            "rating": 1324.2853327857642,
            "rating_q975": 1330.5188256414244,
            "rating_q025": 1318.051839930104
        },
        "claude-3-opus-20240229": {
            "rating": 1323.2631803586096,
            "rating_q975": 1327.0085015582038,
            "rating_q025": 1319.5178591590154
        },
        "mistral-small-3.1-24b-instruct-2503": {
            "rating": 1322.8627619310232,
            "rating_q975": 1328.4739071781155,
            "rating_q025": 1317.251616683931
        },
        "llama-3.1-70b-instruct": {
            "rating": 1320.6505498711304,
            "rating_q975": 1325.2377513888246,
            "rating_q025": 1316.0633483534361
        },
        "mistral-large-2411": {
            "rating": 1320.3343859779409,
            "rating_q975": 1325.5411674086508,
            "rating_q025": 1315.127604547231
        },
        "grok-2-mini-2024-08-13": {
            "rating": 1319.0958637121735,
            "rating_q975": 1323.6968979715764,
            "rating_q025": 1314.4948294527705
        },
        "hunyuan-standard-2025-02-10": {
            "rating": 1318.8271468232947,
            "rating_q975": 1331.1767492310248,
            "rating_q025": 1306.4775444155646
        },
        "deepseek-v2.5": {
            "rating": 1317.831335459974,
            "rating_q975": 1323.820316343543,
            "rating_q025": 1311.8423545764051
        },
        "llama-3.1-nemotron-51b-instruct": {
            "rating": 1317.6996599710742,
            "rating_q975": 1331.1806302200057,
            "rating_q025": 1304.2186897221427
        },
        "gemini-1.5-flash-002": {
            "rating": 1315.329860567168,
            "rating_q975": 1320.5558121990775,
            "rating_q025": 1310.1039089352585
        },
        "qwen2.5-72b-instruct": {
            "rating": 1315.3243491587193,
            "rating_q975": 1320.2493383917413,
            "rating_q025": 1310.3993599256974
        },
        "jamba-1.5-large": {
            "rating": 1314.7095256922908,
            "rating_q975": 1323.821501699764,
            "rating_q025": 1305.5975496848175
        },
        "hunyuan-large-vision": {
            "rating": 1314.1934150221214,
            "rating_q975": 1325.768169460499,
            "rating_q025": 1302.6186605837438
        },
        "gemma-3-4b-it": {
            "rating": 1307.7078398388144,
            "rating_q975": 1319.3439561508796,
            "rating_q025": 1296.071723526749
        },
        "amazon-nova-pro-v1.0": {
            "rating": 1304.0076388243212,
            "rating_q975": 1309.350761024326,
            "rating_q025": 1298.6645166243165
        },
        "llama-3.1-tulu-3-70b": {
            "rating": 1301.0653528310063,
            "rating_q975": 1314.283777037861,
            "rating_q025": 1287.8469286241516
        },
        "gpt-4-0314": {
            "rating": 1299.579454150631,
            "rating_q975": 1305.226111516686,
            "rating_q025": 1293.9327967845759
        },
        "gemma-2-27b-it": {
            "rating": 1296.2815599167843,
            "rating_q975": 1300.3104491560484,
            "rating_q025": 1292.2526706775202
        },
        "gemma-2-9b-it-simpo": {
            "rating": 1294.4637614425212,
            "rating_q975": 1303.0791198314416,
            "rating_q025": 1285.8484030536008
        },
        "mistral-small-24b-instruct-2501": {
            "rating": 1293.6646251206075,
            "rating_q975": 1300.5834988862819,
            "rating_q025": 1286.7457513549332
        },
        "gpt-4-0613": {
            "rating": 1292.015089733587,
            "rating_q975": 1296.8660494835024,
            "rating_q025": 1287.1641299836717
        },
        "reka-core-20240904": {
            "rating": 1291.0571030776557,
            "rating_q975": 1300.3325148941346,
            "rating_q025": 1281.7816912611768
        },
        "nemotron-4-340b-instruct": {
            "rating": 1288.726913085128,
            "rating_q975": 1295.787904563007,
            "rating_q025": 1281.665921607249
        },
        "olmo-2-0325-32b-instruct": {
            "rating": 1288.1640727411,
            "rating_q975": 1301.0216626491995,
            "rating_q025": 1275.3064828330005
        },
        "claude-3-sonnet-20240229": {
            "rating": 1288.1205501245377,
            "rating_q975": 1292.8113051409434,
            "rating_q025": 1283.4297951081319
        },
        "gemini-1.5-flash-001": {
            "rating": 1288.0609580692671,
            "rating_q975": 1293.2270263252449,
            "rating_q025": 1282.8948898132894
        },
        "glm-4-0520": {
            "rating": 1287.6273137517142,
            "rating_q975": 1296.6740970756664,
            "rating_q025": 1278.580530427762
        },
        "command-r-plus-08-2024": {
            "rating": 1286.9109794929027,
            "rating_q975": 1295.1479566857101,
            "rating_q025": 1278.6740023000953
        },
        "qwen2.5-coder-32b-instruct": {
            "rating": 1285.0099377817455,
            "rating_q975": 1296.1283614032757,
            "rating_q025": 1273.8915141602154
        },
        "qwen2-72b-instruct": {
            "rating": 1276.2958673932897,
            "rating_q975": 1282.1624641119213,
            "rating_q025": 1270.429270674658
        },
        "reka-flash-20240904": {
            "rating": 1275.7904539053302,
            "rating_q975": 1284.84087832366,
            "rating_q025": 1266.7400294870004
        },
        "gemma-2-9b-it": {
            "rating": 1275.3010260642827,
            "rating_q975": 1279.837126805467,
            "rating_q025": 1270.7649253230984
        },
        "amazon-nova-lite-v1.0": {
            "rating": 1273.8161834058571,
            "rating_q975": 1279.9552034866601,
            "rating_q025": 1267.6771633250542
        },
        "c4ai-aya-expanse-32b": {
            "rating": 1273.4690619358762,
            "rating_q975": 1279.442349565015,
            "rating_q025": 1267.4957743067373
        },
        "command-r-plus": {
            "rating": 1271.7550262413088,
            "rating_q975": 1276.8689355618283,
            "rating_q025": 1266.6411169207893
        },
        "jamba-1.5-mini": {
            "rating": 1271.2309575258694,
            "rating_q975": 1280.1568194004935,
            "rating_q025": 1262.3050956512452
        },
        "phi-4": {
            "rating": 1271.1043172252766,
            "rating_q975": 1276.6969332182048,
            "rating_q025": 1265.5117012323485
        },
        "claude-3-haiku-20240307": {
            "rating": 1269.594665959893,
            "rating_q975": 1274.2246558087127,
            "rating_q025": 1264.9646761110735
        },
        "deepseek-coder-v2": {
            "rating": 1268.1813432079516,
            "rating_q975": 1275.9284268997287,
            "rating_q025": 1260.4342595161745
        },
        "gemini-1.5-flash-8b-001": {
            "rating": 1267.0209513730526,
            "rating_q975": 1272.3635564978242,
            "rating_q025": 1261.678346248281
        },
        "mistral-large-2402": {
            "rating": 1265.9746359550877,
            "rating_q975": 1271.612811466471,
            "rating_q025": 1260.3364604437045
        },
        "llama-3-8b-instruct": {
            "rating": 1264.7849285476007,
            "rating_q975": 1269.4368726047621,
            "rating_q025": 1260.1329844904392
        },
        "command-r-08-2024": {
            "rating": 1262.421200594326,
            "rating_q975": 1270.6534661333126,
            "rating_q025": 1254.1889350553392
        },
        "qwen1.5-110b-chat": {
            "rating": 1256.7165830635668,
            "rating_q975": 1263.8022614966676,
            "rating_q025": 1249.630904630466
        },
        "ministral-8b-2410": {
            "rating": 1256.0240030882176,
            "rating_q975": 1267.8685187833048,
            "rating_q025": 1244.1794873931303
        },
        "amazon-nova-micro-v1.0": {
            "rating": 1255.6230330712838,
            "rating_q975": 1261.6878065039125,
            "rating_q025": 1249.558259638655
        },
        "mixtral-8x22b-instruct-v0.1": {
            "rating": 1252.7822093725026,
            "rating_q975": 1258.2619526676383,
            "rating_q025": 1247.302466077367
        },
        "qwen1.5-72b-chat": {
            "rating": 1250.778188668006,
            "rating_q975": 1256.9094164606738,
            "rating_q025": 1244.646960875338
        },
        "yi-1.5-34b-chat": {
            "rating": 1250.127858537423,
            "rating_q975": 1256.7966916984763,
            "rating_q025": 1243.4590253763697
        },
        "granite-3.1-8b-instruct": {
            "rating": 1250.1210700499005,
            "rating_q975": 1263.971695885126,
            "rating_q025": 1236.2704442146749
        },
        "mistral-medium": {
            "rating": 1248.6933920712404,
            "rating_q975": 1255.0196841013276,
            "rating_q025": 1242.3671000411532
        },
        "hunyuan-standard-256k": {
            "rating": 1245.8217168923775,
            "rating_q975": 1262.067684582142,
            "rating_q025": 1229.575749202613
        },
        "gemini-pro-dev-api": {
            "rating": 1244.21387122118,
            "rating_q975": 1252.6029814798187,
            "rating_q025": 1235.8247609625412
        },
        "reka-flash-21b-20240226-online": {
            "rating": 1242.0998429621645,
            "rating_q975": 1251.0740538958937,
            "rating_q025": 1233.1256320284353
        },
        "zephyr-orpo-141b-A35b-v0.1": {
            "rating": 1240.3301991818516,
            "rating_q975": 1253.500239826897,
            "rating_q025": 1227.1601585368062
        },
        "llama-3.1-tulu-3-8b": {
            "rating": 1239.4663768591827,
            "rating_q975": 1253.0951390665473,
            "rating_q025": 1225.837614651818
        },
        "gemini-pro": {
            "rating": 1239.3882232574133,
            "rating_q975": 1252.2221058569078,
            "rating_q025": 1226.5543406579188
        },
        "command-r": {
            "rating": 1238.187431770872,
            "rating_q975": 1243.9439294389654,
            "rating_q025": 1232.4309341027788
        },
        "reka-flash-21b-20240226": {
            "rating": 1237.6570136808095,
            "rating_q975": 1244.9039877782054,
            "rating_q025": 1230.4100395834137
        },
        "llama-3.1-8b-instruct": {
            "rating": 1237.5412646066243,
            "rating_q975": 1242.4943333861374,
            "rating_q025": 1232.5881958271111
        },
        "granite-3.0-8b-instruct": {
            "rating": 1236.4686582269787,
            "rating_q975": 1247.8729569189281,
            "rating_q025": 1225.0643595350293
        },
        "internlm2_5-20b-chat": {
            "rating": 1236.132739150089,
            "rating_q975": 1245.324603384578,
            "rating_q025": 1226.9408749156
        },
        "gpt-3.5-turbo-0125": {
            "rating": 1235.8955331464133,
            "rating_q975": 1241.301567614566,
            "rating_q025": 1230.4894986782606
        },
        "c4ai-aya-expanse-8b": {
            "rating": 1232.6546287276674,
            "rating_q975": 1241.2270370787921,
            "rating_q025": 1224.0822203765426
        },
        "mixtral-8x7b-instruct-v0.1": {
            "rating": 1230.5834709865085,
            "rating_q975": 1235.6586292662837,
            "rating_q025": 1225.5083127067332
        },
        "phi-3-medium-4k-instruct": {
            "rating": 1230.1737357474426,
            "rating_q975": 1236.6255242330171,
            "rating_q025": 1223.721947261868
        },
        "granite-3.1-2b-instruct": {
            "rating": 1228.1007614062087,
            "rating_q975": 1242.288468059985,
            "rating_q025": 1213.9130547524323
        },
        "dbrx-instruct-preview": {
            "rating": 1225.9585959867877,
            "rating_q975": 1233.4252989383376,
            "rating_q025": 1218.4918930352378
        },
        "llama-3.2-3b-instruct": {
            "rating": 1224.541173909285,
            "rating_q975": 1234.0784346854243,
            "rating_q025": 1215.0039131331455
        },
        "qwen1.5-32b-chat": {
            "rating": 1224.283592104743,
            "rating_q975": 1231.8456904370903,
            "rating_q025": 1216.721493772396
        },
        "gemma-2-2b-it": {
            "rating": 1219.90864931332,
            "rating_q975": 1224.7415518123319,
            "rating_q025": 1215.075746814308
        },
        "gpt-3.5-turbo-1106": {
            "rating": 1218.3436336857703,
            "rating_q975": 1227.8720285947923,
            "rating_q025": 1208.8152387767484
        },
        "wizardlm-70b": {
            "rating": 1213.1550750130764,
            "rating_q975": 1223.3752929980824,
            "rating_q025": 1202.9348570280704
        },
        "phi-3-small-8k-instruct": {
            "rating": 1211.6597042804588,
            "rating_q975": 1219.4355017150372,
            "rating_q025": 1203.8839068458803
        },
        "yi-34b-chat": {
            "rating": 1210.2119204317455,
            "rating_q975": 1218.0120225983628,
            "rating_q025": 1202.4118182651282
        },
        "qwen1.5-14b-chat": {
            "rating": 1208.8244537316082,
            "rating_q975": 1217.6178230635235,
            "rating_q025": 1200.0310843996929
        },
        "llama-2-70b-chat": {
            "rating": 1208.4679133726656,
            "rating_q975": 1214.781293205223,
            "rating_q025": 1202.1545335401083
        },
        "openhermes-2.5-mistral-7b": {
            "rating": 1207.561919467902,
            "rating_q975": 1219.0279993669076,
            "rating_q025": 1196.0958395688965
        },
        "openchat-3.5-0106": {
            "rating": 1207.305731655611,
            "rating_q975": 1216.0453746059377,
            "rating_q025": 1198.5660887052843
        },
        "tulu-2-dpo-70b": {
            "rating": 1206.8461455703389,
            "rating_q975": 1217.6211327983594,
            "rating_q025": 1196.0711583423183
        },
        "gemma-1.1-7b-it": {
            "rating": 1205.2991709456137,
            "rating_q975": 1212.3141691521641,
            "rating_q025": 1198.2841727390633
        },
        "deepseek-llm-67b-chat": {
            "rating": 1204.7711221577924,
            "rating_q975": 1217.4444416121253,
            "rating_q025": 1192.0978027034596
        },
        "starling-lm-7b-beta": {
            "rating": 1202.8225676875497,
            "rating_q975": 1211.6884031948111,
            "rating_q025": 1193.9567321802883
        },
        "snowflake-arctic-instruct": {
            "rating": 1200.8819246303333,
            "rating_q975": 1208.2575515177116,
            "rating_q025": 1193.506297742955
        },
        "vicuna-33b": {
            "rating": 1200.5455759653842,
            "rating_q975": 1207.7374611886155,
            "rating_q025": 1193.3536907421528
        },
        "openchat-3.5": {
            "rating": 1200.443639323969,
            "rating_q975": 1211.0179671443866,
            "rating_q025": 1189.8693115035512
        },
        "granite-3.0-2b-instruct": {
            "rating": 1200.053527606267,
            "rating_q975": 1211.4099660719712,
            "rating_q025": 1188.6970891405626
        },
        "starling-lm-7b-alpha": {
            "rating": 1196.799458642725,
            "rating_q975": 1205.7912550691678,
            "rating_q025": 1187.8076622162823
        },
        "nous-hermes-2-mixtral-8x7b-dpo": {
            "rating": 1192.7395773494882,
            "rating_q975": 1205.5491629807802,
            "rating_q025": 1179.929991718196
        },
        "phi-3-mini-4k-instruct-june-2024": {
            "rating": 1192.0567402383572,
            "rating_q975": 1200.2133822519402,
            "rating_q025": 1183.9000982247742
        },
        "mistral-7b-instruct-v0.2": {
            "rating": 1190.9157551160347,
            "rating_q975": 1198.5722819781415,
            "rating_q025": 1183.2592282539279
        },
        "solar-10.7b-instruct-v1.0": {
            "rating": 1186.3919514086979,
            "rating_q975": 1200.8815515658061,
            "rating_q025": 1171.9023512515896
        },
        "dolphin-2.2.1-mistral-7b": {
            "rating": 1182.2835941516096,
            "rating_q975": 1199.0817858910993,
            "rating_q025": 1165.4854024121198
        },
        "mpt-30b-chat": {
            "rating": 1181.545643332352,
            "rating_q975": 1195.1903128969886,
            "rating_q025": 1167.9009737677154
        },
        "llama2-70b-steerlm-chat": {
            "rating": 1180.9734109974986,
            "rating_q975": 1194.6999049949752,
            "rating_q025": 1167.246917000022
        },
        "qwq-32b-preview": {
            "rating": 1180.2368580598775,
            "rating_q975": 1194.874907544134,
            "rating_q025": 1165.598808575621
        },
        "llama-2-13b-chat": {
            "rating": 1174.067201004643,
            "rating_q975": 1181.6689577762322,
            "rating_q025": 1166.4654442330539
        },
        "wizardlm-13b": {
            "rating": 1172.3156077083586,
            "rating_q975": 1182.6006479113853,
            "rating_q025": 1162.0305675053319
        },
        "phi-3-mini-4k-instruct": {
            "rating": 1171.7593070626622,
            "rating_q975": 1179.7964482150949,
            "rating_q025": 1163.7221659102295
        },
        "falcon-180b-chat": {
            "rating": 1170.6052647904462,
            "rating_q975": 1189.2643991596995,
            "rating_q025": 1151.946130421193
        },
        "llama-3.2-1b-instruct": {
            "rating": 1168.2601972312032,
            "rating_q975": 1177.849140966681,
            "rating_q025": 1158.6712534957253
        },
        "zephyr-7b-beta": {
            "rating": 1167.9936125693798,
            "rating_q975": 1177.5602373855122,
            "rating_q025": 1158.4269877532474
        },
        "gemma-7b-it": {
            "rating": 1164.7304547462593,
            "rating_q975": 1175.7444091163286,
            "rating_q025": 1153.71650037619
        },
        "palm-2": {
            "rating": 1164.2602244288835,
            "rating_q975": 1174.310737559362,
            "rating_q025": 1154.209711298405
        },
        "smollm2-1.7b-instruct": {
            "rating": 1163.9470813365747,
            "rating_q975": 1182.6942459687084,
            "rating_q025": 1145.199916704441
        },
        "phi-3-mini-128k-instruct": {
            "rating": 1163.5451300944633,
            "rating_q975": 1172.5561473933215,
            "rating_q025": 1154.534112795605
        },
        "qwen1.5-7b-chat": {
            "rating": 1163.2007044916325,
            "rating_q975": 1174.43897484061,
            "rating_q025": 1151.962434142655
        },
        "vicuna-13b": {
            "rating": 1162.6140824645875,
            "rating_q975": 1170.0323241206443,
            "rating_q025": 1155.1958408085306
        },
        "codellama-34b-instruct": {
            "rating": 1160.836182462956,
            "rating_q975": 1170.508034776338,
            "rating_q025": 1151.164330149574
        },
        "zephyr-7b-alpha": {
            "rating": 1160.5485689581596,
            "rating_q975": 1177.8567644627421,
            "rating_q025": 1143.2403734535771
        },
        "guanaco-33b": {
            "rating": 1156.9757938359512,
            "rating_q975": 1170.3260251555423,
            "rating_q025": 1143.62556251636
        },
        "qwen-14b-chat": {
            "rating": 1152.8502614171296,
            "rating_q975": 1164.6530859899976,
            "rating_q025": 1141.0474368442615
        },
        "codellama-70b-instruct": {
            "rating": 1152.1634128949481,
            "rating_q975": 1174.1814937520599,
            "rating_q025": 1130.1453320378364
        },
        "stripedhyena-nous-7b": {
            "rating": 1151.9237300509371,
            "rating_q975": 1163.776837377654,
            "rating_q025": 1140.0706227242204
        },
        "llama-2-7b-chat": {
            "rating": 1147.4271456777997,
            "rating_q975": 1155.2808949168239,
            "rating_q025": 1139.5733964387755
        },
        "mistral-7b-instruct": {
            "rating": 1143.0939964982174,
            "rating_q975": 1153.1907370567758,
            "rating_q025": 1132.997255939659
        },
        "gemma-1.1-2b-it": {
            "rating": 1135.536865983849,
            "rating_q975": 1145.1570704534322,
            "rating_q025": 1125.916661514266
        },
        "vicuna-7b": {
            "rating": 1132.883764483796,
            "rating_q975": 1142.747631750751,
            "rating_q025": 1123.0198972168412
        },
        "gemma-2b-it": {
            "rating": 1116.0148346724295,
            "rating_q975": 1129.2682529238464,
            "rating_q025": 1102.7614164210127
        },
        "olmo-7b-instruct": {
            "rating": 1112.2539751993686,
            "rating_q975": 1125.1927619801468,
            "rating_q025": 1099.3151884185904
        },
        "qwen1.5-4b-chat": {
            "rating": 1105.8728104883555,
            "rating_q975": 1116.706411280724,
            "rating_q025": 1095.039209695987
        },
        "koala-13b": {
            "rating": 1098.933816795821,
            "rating_q975": 1110.0491302136927,
            "rating_q025": 1087.8185033779494
        },
        "gpt4all-13b-snoozy": {
            "rating": 1092.7758904414527,
            "rating_q975": 1109.7202589564347,
            "rating_q025": 1075.8315219264707
        },
        "alpaca-13b": {
            "rating": 1089.2426672126953,
            "rating_q975": 1101.5584530376168,
            "rating_q025": 1076.9268813877738
        },
        "chatglm3-6b": {
            "rating": 1086.85150626935,
            "rating_q975": 1099.568005383788,
            "rating_q025": 1074.135007154912
        },
        "mpt-7b-chat": {
            "rating": 1085.265586600416,
            "rating_q975": 1098.2709557137332,
            "rating_q025": 1072.260217487099
        },
        "RWKV-4-Raven-14B": {
            "rating": 1058.5701417524156,
            "rating_q975": 1071.1989322940485,
            "rating_q025": 1045.9413512107826
        },
        "chatglm2-6b": {
            "rating": 1056.9757882486156,
            "rating_q975": 1071.8872269869166,
            "rating_q025": 1042.0643495103145
        },
        "oasst-pythia-12b": {
            "rating": 1049.309612779321,
            "rating_q975": 1061.121161148943,
            "rating_q025": 1037.498064409699
        },
        "fastchat-t5-3b": {
            "rating": 1023.4074291204481,
            "rating_q975": 1036.8151234662353,
            "rating_q025": 1009.9997347746609
        },
        "chatglm-6b": {
            "rating": 1015.2882934742495,
            "rating_q975": 1028.9251096870992,
            "rating_q025": 1001.6514772613999
        },
        "dolly-v2-12b": {
            "rating": 992.3537271492075,
            "rating_q975": 1007.2955898553201,
            "rating_q025": 977.4118644430949
        },
        "llama-13b": {
            "rating": 979.3123117859063,
            "rating_q975": 996.4913152209723,
            "rating_q025": 962.1333083508404
        },
        "stablelm-tuned-alpha-7b": {
            "rating": 976.2484334715964,
            "rating_q975": 990.2776580567208,
            "rating_q025": 962.219208886472
        }
    },
    "expert": {
        "claude-sonnet-4-5-20250929-thinking-32k": {
            "rating": 1501.9017232653623,
            "rating_q975": 1527.356905008671,
            "rating_q025": 1476.4465415220536
        },
        "claude-opus-4-1-20250805-thinking-16k": {
            "rating": 1485.9794115994007,
            "rating_q975": 1503.4432627122628,
            "rating_q025": 1468.5155604865386
        },
        "claude-sonnet-4-5-20250929": {
            "rating": 1478.7086050596658,
            "rating_q975": 1512.5443610222248,
            "rating_q025": 1444.8728490971068
        },
        "qwen3-max-preview": {
            "rating": 1464.3899957199826,
            "rating_q975": 1482.6554070842544,
            "rating_q025": 1446.1245843557108
        },
        "gemini-2.5-pro": {
            "rating": 1463.9619905872278,
            "rating_q975": 1475.7699252549805,
            "rating_q025": 1452.154055919475
        },
        "qwen3-235b-a22b-thinking-2507": {
            "rating": 1461.0368455047992,
            "rating_q975": 1489.1688697473996,
            "rating_q025": 1432.9048212621988
        },
        "gpt-5-high": {
            "rating": 1458.8540163903178,
            "rating_q975": 1475.6445664326532,
            "rating_q025": 1442.0634663479825
        },
        "claude-opus-4-1-20250805": {
            "rating": 1458.5542452082345,
            "rating_q975": 1473.2184845184615,
            "rating_q025": 1443.8900058980075
        },
        "gemini-2.5-flash-preview-09-2025": {
            "rating": 1453.5882482556249,
            "rating_q975": 1478.0652662739408,
            "rating_q025": 1429.111230237309
        },
        "qwen3-235b-a22b-instruct-2507": {
            "rating": 1445.1051845376692,
            "rating_q975": 1460.3074443694736,
            "rating_q025": 1429.9029247058647
        },
        "o3-2025-04-16": {
            "rating": 1443.7309078899646,
            "rating_q975": 1455.6508977351111,
            "rating_q025": 1431.810918044818
        },
        "claude-opus-4-20250514-thinking-16k": {
            "rating": 1442.2024281649335,
            "rating_q975": 1456.5691611167963,
            "rating_q025": 1427.8356952130707
        },
        "gpt-5-chat": {
            "rating": 1440.6228261843944,
            "rating_q975": 1457.4120360659158,
            "rating_q025": 1423.833616302873
        },
        "glm-4.5": {
            "rating": 1439.1614789597459,
            "rating_q975": 1456.961317921053,
            "rating_q025": 1421.3616399984387
        },
        "qwen3-vl-235b-a22b-thinking": {
            "rating": 1438.9448172826783,
            "rating_q975": 1469.2017422281706,
            "rating_q025": 1408.687892337186
        },
        "qwen3-vl-235b-a22b-instruct": {
            "rating": 1438.4950957009296,
            "rating_q975": 1465.3405502301919,
            "rating_q025": 1411.6496411716673
        },
        "deepseek-v3.2-exp-thinking": {
            "rating": 1436.6239851978612,
            "rating_q975": 1466.4941932395939,
            "rating_q025": 1406.7537771561285
        },
        "glm-4.6": {
            "rating": 1436.2591593117427,
            "rating_q975": 1463.1831617997177,
            "rating_q025": 1409.3351568237676
        },
        "grok-4-0709": {
            "rating": 1434.6606768950373,
            "rating_q975": 1449.7830397027567,
            "rating_q025": 1419.538314087318
        },
        "claude-sonnet-4-20250514-thinking-32k": {
            "rating": 1431.4305464299666,
            "rating_q975": 1445.8855955760482,
            "rating_q025": 1416.975497283885
        },
        "gemini-2.5-flash": {
            "rating": 1430.4802698241936,
            "rating_q975": 1441.922152136648,
            "rating_q025": 1419.038387511739
        },
        "deepseek-v3.1-thinking": {
            "rating": 1430.2232936892683,
            "rating_q975": 1455.1134453151064,
            "rating_q025": 1405.3331420634302
        },
        "kimi-k2-0905-preview": {
            "rating": 1428.1691142279833,
            "rating_q975": 1454.9299676480807,
            "rating_q025": 1401.4082608078859
        },
        "claude-opus-4-20250514": {
            "rating": 1428.0201458512252,
            "rating_q975": 1440.6494534158996,
            "rating_q025": 1415.3908382865507
        },
        "deepseek-v3.1": {
            "rating": 1427.3899765105157,
            "rating_q975": 1449.6205744567185,
            "rating_q025": 1405.1593785643129
        },
        "claude-haiku-4-5-20251001": {
            "rating": 1427.2942964880372,
            "rating_q975": 1452.2958356407248,
            "rating_q025": 1402.2927573353495
        },
        "gpt-4.5-preview-2025-02-27": {
            "rating": 1425.4742665008512,
            "rating_q975": 1448.8990935477716,
            "rating_q025": 1402.0494394539307
        },
        "qwen3-max-2025-09-23": {
            "rating": 1424.5237070444575,
            "rating_q975": 1451.31539466558,
            "rating_q025": 1397.732019423335
        },
        "grok-4-fast": {
            "rating": 1422.9222939447775,
            "rating_q975": 1456.5846700670531,
            "rating_q025": 1389.2599178225018
        },
        "chatgpt-4o-latest-20250326": {
            "rating": 1418.3129373175238,
            "rating_q975": 1431.0171958317044,
            "rating_q025": 1405.6086788033433
        },
        "longcat-flash-chat": {
            "rating": 1417.4029438277105,
            "rating_q975": 1443.633765050679,
            "rating_q025": 1391.172122604742
        },
        "deepseek-r1-0528": {
            "rating": 1412.355880682726,
            "rating_q975": 1431.5808767546375,
            "rating_q025": 1393.1308846108143
        },
        "kimi-k2-0711-preview": {
            "rating": 1407.4277747492492,
            "rating_q975": 1423.2422098441589,
            "rating_q025": 1391.6133396543396
        },
        "gpt-5-mini-high": {
            "rating": 1405.7456669665323,
            "rating_q975": 1425.5351429769596,
            "rating_q025": 1385.956190956105
        },
        "o4-mini-2025-04-16": {
            "rating": 1405.7022878697755,
            "rating_q975": 1418.3693467365038,
            "rating_q025": 1393.0352290030473
        },
        "claude-3-7-sonnet-20250219-thinking-32k": {
            "rating": 1405.3314685311582,
            "rating_q975": 1419.1580051285491,
            "rating_q025": 1391.5049319337672
        },
        "mistral-medium-2508": {
            "rating": 1404.6266591015512,
            "rating_q975": 1420.7319776010431,
            "rating_q025": 1388.5213406020594
        },
        "grok-3-preview-02-24": {
            "rating": 1403.1290157334772,
            "rating_q975": 1418.3520161714553,
            "rating_q025": 1387.9060152954992
        },
        "glm-4.5v": {
            "rating": 1402.0631388444851,
            "rating_q975": 1444.3533126936443,
            "rating_q025": 1359.772964995326
        },
        "gpt-4.1-2025-04-14": {
            "rating": 1401.855434088233,
            "rating_q975": 1414.3251390861378,
            "rating_q025": 1389.3857290903284
        },
        "qwen3-next-80b-a3b-instruct": {
            "rating": 1401.6165652468467,
            "rating_q975": 1422.0150885507246,
            "rating_q025": 1381.2180419429687
        },
        "hunyuan-t1-20250711": {
            "rating": 1399.5563177135634,
            "rating_q975": 1438.2006031552553,
            "rating_q025": 1360.9120322718716
        },
        "grok-3-mini-high": {
            "rating": 1399.4901355613574,
            "rating_q975": 1418.0649852016345,
            "rating_q025": 1380.9152859210803
        },
        "mai-1-preview": {
            "rating": 1399.0248718872258,
            "rating_q975": 1419.864341601334,
            "rating_q025": 1378.1854021731176
        },
        "o1-2024-12-17": {
            "rating": 1397.8536191839012,
            "rating_q975": 1414.2597001059912,
            "rating_q025": 1381.4475382618111
        },
        "claude-sonnet-4-20250514": {
            "rating": 1397.1089585469497,
            "rating_q975": 1410.2816434324845,
            "rating_q025": 1383.9362736614148
        },
        "qwen3-32b": {
            "rating": 1395.121434085592,
            "rating_q975": 1432.7457211086576,
            "rating_q025": 1357.4971470625264
        },
        "deepseek-r1": {
            "rating": 1394.1649698199262,
            "rating_q975": 1413.582149087712,
            "rating_q025": 1374.7477905521405
        },
        "qwen3-235b-a22b-no-thinking": {
            "rating": 1394.1318825665899,
            "rating_q975": 1408.0122970935577,
            "rating_q025": 1380.251468039622
        },
        "o3-mini-high": {
            "rating": 1393.2667321691376,
            "rating_q975": 1413.3771301259146,
            "rating_q025": 1373.1563342123607
        },
        "deepseek-v3-0324": {
            "rating": 1390.5360090609809,
            "rating_q975": 1403.0971920155703,
            "rating_q025": 1377.9748261063914
        },
        "qwen3-next-80b-a3b-thinking": {
            "rating": 1385.205827807754,
            "rating_q975": 1408.884289429341,
            "rating_q025": 1361.5273661861672
        },
        "qwen3-30b-a3b-instruct-2507": {
            "rating": 1385.0926233865978,
            "rating_q975": 1402.5446551872978,
            "rating_q025": 1367.6405915858977
        },
        "glm-4.5-air": {
            "rating": 1382.238901927988,
            "rating_q975": 1398.8792046796834,
            "rating_q025": 1365.5985991762927
        },
        "qwen3-235b-a22b": {
            "rating": 1381.1636470178241,
            "rating_q975": 1397.1486359390015,
            "rating_q025": 1365.1786580966468
        },
        "gpt-4.1-mini-2025-04-14": {
            "rating": 1380.8288942244742,
            "rating_q975": 1394.0391956085996,
            "rating_q025": 1367.6185928403488
        },
        "gemini-2.5-flash-lite-preview-09-2025-no-thinking": {
            "rating": 1377.573208316882,
            "rating_q975": 1400.25944522477,
            "rating_q025": 1354.8869714089942
        },
        "mistral-medium-2505": {
            "rating": 1377.322935583103,
            "rating_q975": 1390.9924587599317,
            "rating_q025": 1363.6534124062741
        },
        "qwen3-coder-480b-a35b-instruct": {
            "rating": 1377.0550683742663,
            "rating_q975": 1393.8550854705957,
            "rating_q025": 1360.255051277937
        },
        "o1-preview": {
            "rating": 1376.2708127550095,
            "rating_q975": 1390.08682472068,
            "rating_q025": 1362.454800789339
        },
        "grok-3-mini-beta": {
            "rating": 1374.480681770166,
            "rating_q975": 1391.4121563651836,
            "rating_q025": 1357.5492071751485
        },
        "minimax-m1": {
            "rating": 1369.8572242405505,
            "rating_q975": 1384.44087017154,
            "rating_q025": 1355.2735783095611
        },
        "nvidia-llama-3.3-nemotron-super-49b-v1.5": {
            "rating": 1369.2908298374655,
            "rating_q975": 1408.3123353390097,
            "rating_q025": 1330.2693243359213
        },
        "gemini-2.5-flash-lite-preview-06-17-thinking": {
            "rating": 1368.1951072308611,
            "rating_q975": 1383.0551054888322,
            "rating_q025": 1353.33510897289
        },
        "qwen-plus-0125": {
            "rating": 1366.4766366692245,
            "rating_q975": 1396.100984822177,
            "rating_q025": 1336.852288516272
        },
        "claude-3-5-sonnet-20241022": {
            "rating": 1364.4898518970876,
            "rating_q975": 1373.1661011788735,
            "rating_q025": 1355.8136026153018
        },
        "qwen2.5-max": {
            "rating": 1364.226337920332,
            "rating_q975": 1377.755022830501,
            "rating_q025": 1350.697653010163
        },
        "o3-mini": {
            "rating": 1362.5875653001854,
            "rating_q975": 1373.7707508630454,
            "rating_q025": 1351.4043797373254
        },
        "gpt-5-nano-high": {
            "rating": 1360.0155402298574,
            "rating_q975": 1393.8559172962725,
            "rating_q025": 1326.1751631634422
        },
        "gpt-oss-120b": {
            "rating": 1359.3913049919802,
            "rating_q975": 1377.0901313937447,
            "rating_q025": 1341.6924785902156
        },
        "qwq-32b": {
            "rating": 1357.9172745066778,
            "rating_q975": 1374.5985503856687,
            "rating_q025": 1341.235998627687
        },
        "step-3": {
            "rating": 1357.880383904637,
            "rating_q975": 1393.6207156896023,
            "rating_q025": 1322.1400521196717
        },
        "ling-flash-2.0": {
            "rating": 1356.4532989622958,
            "rating_q975": 1386.0590536440152,
            "rating_q025": 1326.8475442805764
        },
        "ring-flash-2.0": {
            "rating": 1356.0699927428952,
            "rating_q975": 1387.7260099667176,
            "rating_q025": 1324.413975519073
        },
        "hunyuan-turbos-20250416": {
            "rating": 1352.8180683446556,
            "rating_q975": 1376.4382476616915,
            "rating_q025": 1329.1978890276196
        },
        "amazon-nova-experimental-chat-10-09": {
            "rating": 1352.300466423997,
            "rating_q975": 1388.2390869100973,
            "rating_q025": 1316.3618459378968
        },
        "o1-mini": {
            "rating": 1346.8298119937965,
            "rating_q975": 1357.6774660035824,
            "rating_q025": 1335.9821579840107
        },
        "deepseek-v3": {
            "rating": 1342.6753013455173,
            "rating_q975": 1358.779582036833,
            "rating_q025": 1326.5710206542014
        },
        "qwen3-30b-a3b": {
            "rating": 1342.0638769481125,
            "rating_q975": 1358.4500676787147,
            "rating_q025": 1325.6776862175102
        },
        "command-a-03-2025": {
            "rating": 1336.3519109794381,
            "rating_q975": 1348.116067024977,
            "rating_q025": 1324.5877549338993
        },
        "claude-3-5-sonnet-20240620": {
            "rating": 1336.2916375437326,
            "rating_q975": 1346.576362972434,
            "rating_q025": 1326.0069121150311
        },
        "gemma-3-27b-it": {
            "rating": 1332.280302373945,
            "rating_q975": 1344.9804636598412,
            "rating_q025": 1319.5801410880488
        },
        "gemini-1.5-pro-002": {
            "rating": 1331.7718991965835,
            "rating_q975": 1341.8872411996374,
            "rating_q025": 1321.6565571935296
        },
        "mistral-small-2506": {
            "rating": 1327.888855963427,
            "rating_q975": 1347.3128055504706,
            "rating_q025": 1308.4649063763834
        },
        "gemini-2.0-flash-lite-preview-02-05": {
            "rating": 1326.6008600773303,
            "rating_q975": 1342.6464598272507,
            "rating_q025": 1310.5552603274098
        },
        "yi-lightning": {
            "rating": 1326.3984517517356,
            "rating_q975": 1340.3408070910702,
            "rating_q025": 1312.456096412401
        },
        "llama-4-maverick-17b-128e-instruct": {
            "rating": 1322.7391306883967,
            "rating_q975": 1336.0852450811285,
            "rating_q025": 1309.393016295665
        },
        "step-2-16k-exp-202412": {
            "rating": 1321.1161612857413,
            "rating_q975": 1352.2055779908756,
            "rating_q025": 1290.026744580607
        },
        "qwen2.5-plus-1127": {
            "rating": 1318.5588776748168,
            "rating_q975": 1339.4350653618253,
            "rating_q025": 1297.6826899878083
        },
        "hunyuan-large-2025-02-10": {
            "rating": 1318.3387437933166,
            "rating_q975": 1354.5688257905285,
            "rating_q025": 1282.1086617961046
        },
        "llama-3.1-405b-instruct-fp8": {
            "rating": 1317.3582238167646,
            "rating_q975": 1327.9147477148194,
            "rating_q025": 1306.8016999187098
        },
        "gpt-oss-20b": {
            "rating": 1315.7411780258374,
            "rating_q975": 1343.8282902106073,
            "rating_q025": 1287.6540658410674
        },
        "gemini-1.5-pro-001": {
            "rating": 1310.7919059112628,
            "rating_q975": 1321.8863299613608,
            "rating_q025": 1299.6974818611648
        },
        "claude-3-opus-20240229": {
            "rating": 1310.7859868935238,
            "rating_q975": 1319.0824245194306,
            "rating_q025": 1302.4895492676171
        },
        "gpt-4.1-nano-2025-04-14": {
            "rating": 1309.7077928987799,
            "rating_q975": 1340.4616172494189,
            "rating_q025": 1278.953968548141
        },
        "grok-2-2024-08-13": {
            "rating": 1308.623847481527,
            "rating_q975": 1318.5164121973944,
            "rating_q025": 1298.7312827656597
        },
        "athene-v2-chat": {
            "rating": 1306.79398394711,
            "rating_q975": 1321.1601459777892,
            "rating_q025": 1292.427821916431
        },
        "claude-3-5-haiku-20241022": {
            "rating": 1306.7931020123542,
            "rating_q975": 1317.1584022252946,
            "rating_q025": 1296.4278017994138
        },
        "mistral-small-3.1-24b-instruct-2503": {
            "rating": 1306.6777493020286,
            "rating_q975": 1321.8010339022396,
            "rating_q025": 1291.5544647018176
        },
        "glm-4-plus-0111": {
            "rating": 1306.0622161946073,
            "rating_q975": 1335.1334186124755,
            "rating_q025": 1276.9910137767392
        },
        "gpt-4o-2024-05-13": {
            "rating": 1305.597664331192,
            "rating_q975": 1314.6201266465935,
            "rating_q025": 1296.5752020157904
        },
        "gpt-4o-2024-08-06": {
            "rating": 1304.8848038611873,
            "rating_q975": 1316.7263112443695,
            "rating_q025": 1293.043296478005
        },
        "llama-3.1-405b-instruct-bf16": {
            "rating": 1304.7293939943788,
            "rating_q975": 1316.988403238189,
            "rating_q025": 1292.4703847505687
        },
        "llama-4-scout-17b-16e-instruct": {
            "rating": 1303.4290814034553,
            "rating_q975": 1319.078041188411,
            "rating_q025": 1287.7801216184996
        },
        "deepseek-v2.5-1210": {
            "rating": 1302.2728052538605,
            "rating_q975": 1328.1944840412602,
            "rating_q025": 1276.3511264664608
        },
        "hunyuan-large-vision": {
            "rating": 1301.0127226333718,
            "rating_q975": 1333.8633557832304,
            "rating_q025": 1268.1620894835132
        },
        "glm-4-plus": {
            "rating": 1298.6811205873914,
            "rating_q975": 1312.7208308441627,
            "rating_q025": 1284.6414103306201
        },
        "qwen-max-0919": {
            "rating": 1295.347394479462,
            "rating_q975": 1312.807901980065,
            "rating_q025": 1277.8868869788591
        },
        "mistral-large-2407": {
            "rating": 1295.249752844325,
            "rating_q975": 1306.882519101671,
            "rating_q025": 1283.616986586979
        },
        "step-1o-turbo-202506": {
            "rating": 1292.460521480346,
            "rating_q975": 1318.9113426549088,
            "rating_q025": 1266.009700305783
        },
        "athene-70b-0725": {
            "rating": 1291.964864120617,
            "rating_q975": 1310.6520141682286,
            "rating_q025": 1273.2777140730054
        },
        "deepseek-v2.5": {
            "rating": 1291.280289880696,
            "rating_q975": 1305.4303578380386,
            "rating_q025": 1277.1302219233535
        },
        "gpt-4-turbo-2024-04-09": {
            "rating": 1291.0714771234698,
            "rating_q975": 1301.0799299974092,
            "rating_q025": 1281.0630242495304
        },
        "llama-3.3-70b-instruct": {
            "rating": 1290.876929735651,
            "rating_q975": 1301.4802207990801,
            "rating_q025": 1280.2736386722218
        },
        "qwen2.5-72b-instruct": {
            "rating": 1290.617587395433,
            "rating_q975": 1301.9214244535758,
            "rating_q025": 1279.3137503372902
        },
        "llama-3.1-nemotron-70b-instruct": {
            "rating": 1289.3049325878085,
            "rating_q975": 1316.1675034961893,
            "rating_q025": 1262.4423616794277
        },
        "magistral-medium-2506": {
            "rating": 1289.242274524021,
            "rating_q975": 1315.6296490348286,
            "rating_q025": 1262.8549000132134
        },
        "grok-2-mini-2024-08-13": {
            "rating": 1288.5479344112007,
            "rating_q975": 1299.4046604349558,
            "rating_q025": 1277.6912083874456
        },
        "gemini-advanced-0514": {
            "rating": 1288.2775765465499,
            "rating_q975": 1301.914191409885,
            "rating_q025": 1274.6409616832148
        },
        "hunyuan-standard-2025-02-10": {
            "rating": 1286.0363710154675,
            "rating_q975": 1325.0118825435043,
            "rating_q025": 1247.0608594874307
        },
        "reka-core-20240904": {
            "rating": 1283.5361201826045,
            "rating_q975": 1307.740618271742,
            "rating_q025": 1259.3316220934669
        },
        "gpt-4-1106-preview": {
            "rating": 1283.1051212479197,
            "rating_q975": 1294.1397046865754,
            "rating_q025": 1272.070537809264
        },
        "gpt-4o-mini-2024-07-18": {
            "rating": 1279.363015541638,
            "rating_q975": 1289.2400177589598,
            "rating_q025": 1269.4860133243164
        },
        "jamba-1.5-large": {
            "rating": 1278.7588152693781,
            "rating_q975": 1307.3932869658317,
            "rating_q025": 1250.1243435729245
        },
        "gemma-3n-e4b-it": {
            "rating": 1278.4374476938635,
            "rating_q975": 1296.5250231873438,
            "rating_q025": 1260.3498722003833
        },
        "gemini-1.5-flash-002": {
            "rating": 1277.7012197798094,
            "rating_q975": 1290.0284279029815,
            "rating_q025": 1265.3740116566373
        },
        "gpt-4-0125-preview": {
            "rating": 1274.1660192277766,
            "rating_q975": 1285.1310047488191,
            "rating_q025": 1263.201033706734
        },
        "qwen2.5-coder-32b-instruct": {
            "rating": 1272.1382054052324,
            "rating_q975": 1304.660410168987,
            "rating_q025": 1239.6160006414777
        },
        "gemma-3-12b-it": {
            "rating": 1269.754093718091,
            "rating_q975": 1311.4335253114336,
            "rating_q025": 1228.0746621247486
        },
        "reka-flash-20240904": {
            "rating": 1268.182922377951,
            "rating_q975": 1290.9535423833509,
            "rating_q025": 1245.412302372551
        },
        "amazon-nova-pro-v1.0": {
            "rating": 1268.0913955115943,
            "rating_q975": 1283.3727555657833,
            "rating_q025": 1252.8100354574053
        },
        "llama-3.1-70b-instruct": {
            "rating": 1267.6889366892908,
            "rating_q975": 1278.2665164113305,
            "rating_q025": 1257.1113569672511
        },
        "mistral-large-2411": {
            "rating": 1265.1523837494317,
            "rating_q975": 1279.5805513650334,
            "rating_q025": 1250.72421613383
        },
        "claude-3-sonnet-20240229": {
            "rating": 1264.2940880896292,
            "rating_q975": 1275.257945267768,
            "rating_q025": 1253.3302309114904
        },
        "phi-4": {
            "rating": 1262.4671240895857,
            "rating_q975": 1279.2586188403995,
            "rating_q025": 1245.6756293387718
        },
        "gemini-1.5-flash-001": {
            "rating": 1259.7282238504567,
            "rating_q975": 1271.1943163785743,
            "rating_q025": 1248.2621313223392
        },
        "deepseek-coder-v2": {
            "rating": 1259.4897914191915,
            "rating_q975": 1280.3916574271047,
            "rating_q025": 1238.5879254112783
        },
        "c4ai-aya-expanse-32b": {
            "rating": 1257.6603828913094,
            "rating_q975": 1270.8639064352753,
            "rating_q025": 1244.4568593473434
        },
        "amazon-nova-lite-v1.0": {
            "rating": 1256.642011818742,
            "rating_q975": 1272.797868742606,
            "rating_q025": 1240.4861548948782
        },
        "gpt-4-0314": {
            "rating": 1255.448487496814,
            "rating_q975": 1270.1767939894116,
            "rating_q025": 1240.7201810042166
        },
        "gemma-3-4b-it": {
            "rating": 1254.0217906425478,
            "rating_q975": 1295.3868994480472,
            "rating_q025": 1212.6566818370484
        },
        "mistral-small-24b-instruct-2501": {
            "rating": 1253.1403947381036,
            "rating_q975": 1273.4778438378764,
            "rating_q025": 1232.8029456383308
        },
        "qwen2-72b-instruct": {
            "rating": 1253.0689443717692,
            "rating_q975": 1266.9214211514998,
            "rating_q025": 1239.2164675920387
        },
        "nemotron-4-340b-instruct": {
            "rating": 1252.320539195211,
            "rating_q975": 1270.5186680605,
            "rating_q025": 1234.122410329922
        },
        "gemma-2-27b-it": {
            "rating": 1249.615916628335,
            "rating_q975": 1259.1619612119166,
            "rating_q025": 1240.0698720447535
        },
        "llama-3.1-nemotron-51b-instruct": {
            "rating": 1245.7236652657525,
            "rating_q975": 1278.8759266403429,
            "rating_q025": 1212.5714038911622
        },
        "glm-4-0520": {
            "rating": 1245.5200640407174,
            "rating_q975": 1269.9326958547963,
            "rating_q025": 1221.1074322266386
        },
        "claude-3-haiku-20240307": {
            "rating": 1244.2687104197482,
            "rating_q975": 1254.1698153629438,
            "rating_q025": 1234.3676054765526
        },
        "gpt-4-0613": {
            "rating": 1243.7965112539941,
            "rating_q975": 1255.7869170257254,
            "rating_q025": 1231.8061054822629
        },
        "command-r-plus-08-2024": {
            "rating": 1242.9654605433525,
            "rating_q975": 1267.1961855179284,
            "rating_q025": 1218.7347355687766
        },
        "amazon-nova-micro-v1.0": {
            "rating": 1238.4417635348268,
            "rating_q975": 1255.2219882467846,
            "rating_q025": 1221.661538822869
        },
        "llama-3-70b-instruct": {
            "rating": 1236.284010302586,
            "rating_q975": 1246.0623881779036,
            "rating_q025": 1226.5056324272684
        },
        "gemini-1.5-flash-8b-001": {
            "rating": 1235.1407214538613,
            "rating_q975": 1247.4573992267942,
            "rating_q025": 1222.8240436809283
        },
        "command-r-plus": {
            "rating": 1234.2580378455086,
            "rating_q975": 1245.7436886064922,
            "rating_q025": 1222.772387084525
        },
        "ministral-8b-2410": {
            "rating": 1231.383054771222,
            "rating_q975": 1261.1998957672938,
            "rating_q025": 1201.5662137751503
        },
        "granite-3.1-8b-instruct": {
            "rating": 1228.1075494232812,
            "rating_q975": 1263.1091078162956,
            "rating_q025": 1193.1059910302668
        },
        "qwen1.5-72b-chat": {
            "rating": 1227.542837278262,
            "rating_q975": 1242.0429023579152,
            "rating_q025": 1213.0427721986086
        },
        "gemma-2-9b-it": {
            "rating": 1227.1015626319347,
            "rating_q975": 1238.1685299937408,
            "rating_q025": 1216.0345952701286
        },
        "gemma-2-9b-it-simpo": {
            "rating": 1225.7089016770024,
            "rating_q975": 1254.8770432810575,
            "rating_q025": 1196.5407600729473
        },
        "c4ai-aya-expanse-8b": {
            "rating": 1224.824511075808,
            "rating_q975": 1248.1119475694975,
            "rating_q025": 1201.5370745821185
        },
        "command-r-08-2024": {
            "rating": 1224.3910909170972,
            "rating_q975": 1246.0610142416488,
            "rating_q025": 1202.7211675925457
        },
        "qwen1.5-110b-chat": {
            "rating": 1220.8060909834148,
            "rating_q975": 1236.582793003823,
            "rating_q025": 1205.0293889630066
        },
        "mistral-large-2402": {
            "rating": 1219.8178104587282,
            "rating_q975": 1232.680959048197,
            "rating_q025": 1206.9546618692593
        },
        "mistral-medium": {
            "rating": 1218.834653342423,
            "rating_q975": 1235.2804300885687,
            "rating_q025": 1202.3888765962774
        },
        "reka-flash-21b-20240226-online": {
            "rating": 1217.8881723535555,
            "rating_q975": 1238.6180016621925,
            "rating_q025": 1197.1583430449186
        },
        "qwen1.5-32b-chat": {
            "rating": 1215.585220535289,
            "rating_q975": 1233.1615417494959,
            "rating_q025": 1198.008899321082
        },
        "internlm2_5-20b-chat": {
            "rating": 1213.8996688537843,
            "rating_q975": 1235.4203981991348,
            "rating_q025": 1192.3789395084339
        },
        "yi-1.5-34b-chat": {
            "rating": 1213.5821799633525,
            "rating_q975": 1231.473674963352,
            "rating_q025": 1195.6906849633529
        },
        "granite-3.1-2b-instruct": {
            "rating": 1211.0118807092076,
            "rating_q975": 1246.2903185569107,
            "rating_q025": 1175.7334428615045
        },
        "mixtral-8x22b-instruct-v0.1": {
            "rating": 1210.3778000337886,
            "rating_q975": 1223.379228819488,
            "rating_q025": 1197.3763712480893
        },
        "reka-flash-21b-20240226": {
            "rating": 1207.4159998337257,
            "rating_q975": 1223.9257551043886,
            "rating_q025": 1190.9062445630627
        },
        "command-r": {
            "rating": 1206.4287122057221,
            "rating_q975": 1219.4545552502673,
            "rating_q025": 1193.402869161177
        },
        "jamba-1.5-mini": {
            "rating": 1205.2850005813102,
            "rating_q975": 1235.941413730167,
            "rating_q025": 1174.6285874324535
        },
        "gpt-3.5-turbo-1106": {
            "rating": 1203.936352272649,
            "rating_q975": 1231.639465972432,
            "rating_q025": 1176.233238572866
        },
        "llama-3-8b-instruct": {
            "rating": 1202.4827159734573,
            "rating_q975": 1213.270483395136,
            "rating_q025": 1191.6949485517787
        },
        "phi-3-medium-4k-instruct": {
            "rating": 1197.4046321569272,
            "rating_q975": 1214.695029874213,
            "rating_q025": 1180.1142344396412
        },
        "granite-3.0-8b-instruct": {
            "rating": 1195.111648192908,
            "rating_q975": 1226.0057859007397,
            "rating_q025": 1164.2175104850762
        },
        "llama-3.1-8b-instruct": {
            "rating": 1191.8529295834157,
            "rating_q975": 1203.2196947201505,
            "rating_q025": 1180.486164446681
        },
        "mixtral-8x7b-instruct-v0.1": {
            "rating": 1187.4687422749917,
            "rating_q975": 1199.607025863052,
            "rating_q025": 1175.3304586869313
        },
        "gpt-3.5-turbo-0125": {
            "rating": 1187.3415691877162,
            "rating_q975": 1199.3672104668638,
            "rating_q025": 1175.3159279085687
        },
        "qwen1.5-14b-chat": {
            "rating": 1186.6332588752489,
            "rating_q975": 1206.0999276055866,
            "rating_q025": 1167.1665901449112
        },
        "dbrx-instruct-preview": {
            "rating": 1180.70835614703,
            "rating_q975": 1196.2206339997865,
            "rating_q025": 1165.1960782942733
        },
        "llama-3.2-3b-instruct": {
            "rating": 1170.8614027202589,
            "rating_q975": 1195.4340450824066,
            "rating_q025": 1146.2887603581112
        },
        "gemini-pro-dev-api": {
            "rating": 1169.8798582539548,
            "rating_q975": 1192.899391573701,
            "rating_q025": 1146.8603249342086
        },
        "granite-3.0-2b-instruct": {
            "rating": 1168.0789849544435,
            "rating_q975": 1196.385885734327,
            "rating_q025": 1139.77208417456
        },
        "starling-lm-7b-beta": {
            "rating": 1167.9943198781934,
            "rating_q975": 1187.2437118853716,
            "rating_q025": 1148.7449278710153
        },
        "zephyr-orpo-141b-A35b-v0.1": {
            "rating": 1165.250892832667,
            "rating_q975": 1204.9067316007433,
            "rating_q025": 1125.5950540645906
        },
        "gemma-2-2b-it": {
            "rating": 1162.9829850195713,
            "rating_q975": 1174.9859794657025,
            "rating_q025": 1150.97999057344
        },
        "gemma-1.1-7b-it": {
            "rating": 1161.4958199200132,
            "rating_q975": 1178.5893095306963,
            "rating_q025": 1144.4023303093302
        },
        "phi-3-small-8k-instruct": {
            "rating": 1158.3865964942913,
            "rating_q975": 1176.9211555030265,
            "rating_q025": 1139.8520374855561
        },
        "snowflake-arctic-instruct": {
            "rating": 1154.668782640873,
            "rating_q975": 1171.2054869973126,
            "rating_q025": 1138.1320782844332
        },
        "openchat-3.5": {
            "rating": 1154.2643933383715,
            "rating_q975": 1195.765673677209,
            "rating_q025": 1112.763112999534
        },
        "openchat-3.5-0106": {
            "rating": 1152.8130698832392,
            "rating_q975": 1175.3270594717435,
            "rating_q025": 1130.299080294735
        },
        "qwq-32b-preview": {
            "rating": 1151.4098409140763,
            "rating_q975": 1186.9895603644702,
            "rating_q025": 1115.8301214636824
        },
        "yi-34b-chat": {
            "rating": 1147.834206405079,
            "rating_q975": 1172.4026777198208,
            "rating_q025": 1123.265735090337
        },
        "phi-3-mini-4k-instruct-june-2024": {
            "rating": 1142.6798944002787,
            "rating_q975": 1168.3834172173954,
            "rating_q025": 1116.976371583162
        },
        "qwen1.5-7b-chat": {
            "rating": 1140.6286463759168,
            "rating_q975": 1177.0324536691783,
            "rating_q025": 1104.2248390826553
        },
        "vicuna-33b": {
            "rating": 1137.7903459983827,
            "rating_q975": 1164.0279642380997,
            "rating_q025": 1111.5527277586657
        },
        "phi-3-mini-4k-instruct": {
            "rating": 1134.267893120193,
            "rating_q975": 1153.2769345464797,
            "rating_q025": 1115.2588516939065
        },
        "mistral-7b-instruct-v0.2": {
            "rating": 1132.832464281424,
            "rating_q975": 1152.8154473566792,
            "rating_q025": 1112.849481206169
        },
        "starling-lm-7b-alpha": {
            "rating": 1131.371179485134,
            "rating_q975": 1161.7173098210988,
            "rating_q025": 1101.0250491491693
        },
        "llama-2-70b-chat": {
            "rating": 1129.7775416297147,
            "rating_q975": 1146.4528194786944,
            "rating_q025": 1113.102263780735
        },
        "llama-2-7b-chat": {
            "rating": 1124.392814998996,
            "rating_q975": 1151.8655304680894,
            "rating_q025": 1096.9200995299027
        },
        "llama-2-13b-chat": {
            "rating": 1122.6631656484356,
            "rating_q975": 1147.533901202997,
            "rating_q025": 1097.7924300938741
        },
        "gemma-7b-it": {
            "rating": 1111.3389734690602,
            "rating_q975": 1141.7860748342173,
            "rating_q025": 1080.891872103903
        },
        "vicuna-13b": {
            "rating": 1107.7679953757954,
            "rating_q975": 1138.8227288667538,
            "rating_q025": 1076.713261884837
        },
        "olmo-7b-instruct": {
            "rating": 1107.2935655776364,
            "rating_q975": 1145.3498841160804,
            "rating_q025": 1069.2372470391924
        },
        "zephyr-7b-beta": {
            "rating": 1104.5264529109968,
            "rating_q975": 1142.7842162577317,
            "rating_q025": 1066.2686895642619
        },
        "gemma-1.1-2b-it": {
            "rating": 1103.2350006516135,
            "rating_q975": 1128.6604246207037,
            "rating_q025": 1077.8095766825234
        },
        "qwen1.5-4b-chat": {
            "rating": 1097.4838367924604,
            "rating_q975": 1128.28277827623,
            "rating_q025": 1066.6848953086908
        },
        "phi-3-mini-128k-instruct": {
            "rating": 1090.5155704310887,
            "rating_q975": 1110.380065570684,
            "rating_q025": 1070.6510752914933
        },
        "llama-3.2-1b-instruct": {
            "rating": 1076.1352172246616,
            "rating_q975": 1103.8742309197999,
            "rating_q025": 1048.3962035295233
        },
        "mistral-7b-instruct": {
            "rating": 1074.4439328804115,
            "rating_q975": 1113.8750904461717,
            "rating_q025": 1035.0127753146512
        }
    },
    "french": {
        "claude-opus-4-1-20250805-thinking-16k": {
            "rating": 1488.993478124951,
            "rating_q975": 1522.1565061558929,
            "rating_q025": 1455.8304500940092
        },
        "o3-2025-04-16": {
            "rating": 1482.844369920952,
            "rating_q975": 1508.4354313555607,
            "rating_q025": 1457.2533084863433
        },
        "glm-4.6": {
            "rating": 1473.8872742422298,
            "rating_q975": 1529.2689810597549,
            "rating_q025": 1418.5055674247046
        },
        "claude-opus-4-1-20250805": {
            "rating": 1471.5155690216855,
            "rating_q975": 1499.3627268324049,
            "rating_q025": 1443.668411210966
        },
        "chatgpt-4o-latest-20250326": {
            "rating": 1468.2113524610716,
            "rating_q975": 1495.4652012644904,
            "rating_q025": 1440.9575036576528
        },
        "qwen3-235b-a22b-instruct-2507": {
            "rating": 1465.1993102960919,
            "rating_q975": 1494.6718540888203,
            "rating_q025": 1435.7267665033635
        },
        "gemini-2.5-pro": {
            "rating": 1460.8239001015043,
            "rating_q975": 1485.5475622687636,
            "rating_q025": 1436.100237934245
        },
        "claude-opus-4-20250514-thinking-16k": {
            "rating": 1458.5764170403606,
            "rating_q975": 1488.4179483776243,
            "rating_q025": 1428.734885703097
        },
        "deepseek-v3.1": {
            "rating": 1452.250400594471,
            "rating_q975": 1492.0606945802565,
            "rating_q025": 1412.4401066086857
        },
        "qwen3-max-preview": {
            "rating": 1450.4855737247074,
            "rating_q975": 1484.679048354145,
            "rating_q025": 1416.2920990952698
        },
        "grok-3-preview-02-24": {
            "rating": 1449.5620272718156,
            "rating_q975": 1482.9873964228796,
            "rating_q025": 1416.1366581207517
        },
        "gpt-5-chat": {
            "rating": 1449.0796961313965,
            "rating_q975": 1482.839815199802,
            "rating_q025": 1415.3195770629911
        },
        "mistral-medium-2508": {
            "rating": 1448.9415813702735,
            "rating_q975": 1481.247307722214,
            "rating_q025": 1416.6358550183331
        },
        "gpt-4.5-preview-2025-02-27": {
            "rating": 1446.071023354727,
            "rating_q975": 1503.254862386286,
            "rating_q025": 1388.887184323168
        },
        "qwen3-coder-480b-a35b-instruct": {
            "rating": 1445.0104344203075,
            "rating_q975": 1481.760950082795,
            "rating_q025": 1408.25991875782
        },
        "claude-sonnet-4-20250514": {
            "rating": 1439.5541614744347,
            "rating_q975": 1467.40302848466,
            "rating_q025": 1411.7052944642096
        },
        "gpt-4.1-2025-04-14": {
            "rating": 1436.5556938605139,
            "rating_q975": 1462.912846126575,
            "rating_q025": 1410.1985415944528
        },
        "gemini-2.5-flash-preview-09-2025": {
            "rating": 1435.9297991889916,
            "rating_q975": 1480.1655992168824,
            "rating_q025": 1391.693999161101
        },
        "gpt-5-high": {
            "rating": 1431.5684615827117,
            "rating_q975": 1465.5414976147158,
            "rating_q025": 1397.5954255507077
        },
        "claude-sonnet-4-20250514-thinking-32k": {
            "rating": 1431.3745402479879,
            "rating_q975": 1460.7860993229945,
            "rating_q025": 1401.9629811729812
        },
        "longcat-flash-chat": {
            "rating": 1429.686374380435,
            "rating_q975": 1479.1882720255046,
            "rating_q025": 1380.1844767353653
        },
        "kimi-k2-0711-preview": {
            "rating": 1428.691551235211,
            "rating_q975": 1462.0479359717845,
            "rating_q025": 1395.3351664986374
        },
        "claude-sonnet-4-5-20250929-thinking-32k": {
            "rating": 1427.864622040906,
            "rating_q975": 1477.108900707506,
            "rating_q025": 1378.6203433743058
        },
        "deepseek-r1-0528": {
            "rating": 1427.519476490004,
            "rating_q975": 1467.9111490269966,
            "rating_q025": 1387.1278039530116
        },
        "grok-4-0709": {
            "rating": 1425.6887385571536,
            "rating_q975": 1457.4735071790299,
            "rating_q025": 1393.9039699352772
        },
        "mai-1-preview": {
            "rating": 1423.9901695169763,
            "rating_q975": 1461.6680773213184,
            "rating_q025": 1386.3122617126342
        },
        "glm-4.5": {
            "rating": 1423.8361738986025,
            "rating_q975": 1459.3857126801984,
            "rating_q025": 1388.2866351170067
        },
        "claude-opus-4-20250514": {
            "rating": 1422.2304650133258,
            "rating_q975": 1449.5648462950371,
            "rating_q025": 1394.8960837316145
        },
        "gemini-2.5-flash": {
            "rating": 1421.3799879902338,
            "rating_q975": 1445.4729078405373,
            "rating_q025": 1397.2870681399302
        },
        "deepseek-v3-0324": {
            "rating": 1420.6718738075713,
            "rating_q975": 1448.1187436856353,
            "rating_q025": 1393.2250039295072
        },
        "deepseek-v3.2-exp-thinking": {
            "rating": 1419.303612572687,
            "rating_q975": 1469.4350752121277,
            "rating_q025": 1369.1721499332461
        },
        "gpt-5-mini-high": {
            "rating": 1417.0487164090712,
            "rating_q975": 1454.2700569596398,
            "rating_q025": 1379.8273758585026
        },
        "glm-4.5-air": {
            "rating": 1414.2874439556288,
            "rating_q975": 1446.2357520926262,
            "rating_q025": 1382.3391358186313
        },
        "o4-mini-2025-04-16": {
            "rating": 1413.9481846992871,
            "rating_q975": 1441.0747880090632,
            "rating_q025": 1386.821581389511
        },
        "qwen2.5-max": {
            "rating": 1412.6730893149538,
            "rating_q975": 1445.257723878017,
            "rating_q025": 1380.0884547518906
        },
        "qwen3-30b-a3b-instruct-2507": {
            "rating": 1406.7586874236913,
            "rating_q975": 1442.0645642980742,
            "rating_q025": 1371.4528105493084
        },
        "gpt-4.1-mini-2025-04-14": {
            "rating": 1406.4155259001384,
            "rating_q975": 1434.4028882782466,
            "rating_q025": 1378.4281635220302
        },
        "qwen3-next-80b-a3b-instruct": {
            "rating": 1405.5828436490215,
            "rating_q975": 1443.9663920875405,
            "rating_q025": 1367.1992952105024
        },
        "minimax-m1": {
            "rating": 1403.8970916261765,
            "rating_q975": 1434.225216508008,
            "rating_q025": 1373.5689667443448
        },
        "gemini-2.5-flash-lite-preview-06-17-thinking": {
            "rating": 1401.5082262787766,
            "rating_q975": 1433.3441151876827,
            "rating_q025": 1369.6723373698705
        },
        "gemini-2.5-flash-lite-preview-09-2025-no-thinking": {
            "rating": 1400.5149832828313,
            "rating_q975": 1444.5779098985588,
            "rating_q025": 1356.4520566671038
        },
        "claude-haiku-4-5-20251001": {
            "rating": 1400.5084490620875,
            "rating_q975": 1452.2555938756723,
            "rating_q025": 1348.7613042485027
        },
        "o1-preview": {
            "rating": 1398.728929098876,
            "rating_q975": 1432.4568471748466,
            "rating_q025": 1365.0010110229055
        },
        "gemma-3-27b-it": {
            "rating": 1398.6467428198566,
            "rating_q975": 1424.563415564366,
            "rating_q025": 1372.7300700753472
        },
        "claude-3-5-sonnet-20241022": {
            "rating": 1396.8635601085005,
            "rating_q975": 1417.994959814179,
            "rating_q025": 1375.7321604028218
        },
        "mistral-medium-2505": {
            "rating": 1396.1886853684568,
            "rating_q975": 1425.807761115569,
            "rating_q025": 1366.5696096213446
        },
        "qwen3-next-80b-a3b-thinking": {
            "rating": 1395.065684692333,
            "rating_q975": 1436.7991448346104,
            "rating_q025": 1353.3322245500556
        },
        "qwen3-235b-a22b-no-thinking": {
            "rating": 1394.7683513317954,
            "rating_q975": 1423.7936628226535,
            "rating_q025": 1365.7430398409374
        },
        "deepseek-r1": {
            "rating": 1393.6035169204256,
            "rating_q975": 1435.5414334131524,
            "rating_q025": 1351.6656004276988
        },
        "o1-2024-12-17": {
            "rating": 1392.4117937822004,
            "rating_q975": 1428.859937808872,
            "rating_q025": 1355.9636497555289
        },
        "hunyuan-turbos-20250416": {
            "rating": 1387.035145558303,
            "rating_q975": 1436.516081172964,
            "rating_q025": 1337.5542099436418
        },
        "gemini-2.0-flash-lite-preview-02-05": {
            "rating": 1384.9097293220073,
            "rating_q975": 1423.0405433477601,
            "rating_q025": 1346.7789152962544
        },
        "qwen-max-0919": {
            "rating": 1382.7040292470383,
            "rating_q975": 1423.9553073877785,
            "rating_q025": 1341.4527511062981
        },
        "command-a-03-2025": {
            "rating": 1382.5438311518913,
            "rating_q975": 1408.4489633709638,
            "rating_q025": 1356.6386989328187
        },
        "mistral-large-2411": {
            "rating": 1380.2181716030486,
            "rating_q975": 1419.982245306443,
            "rating_q025": 1340.4540978996542
        },
        "o3-mini-high": {
            "rating": 1378.2296286744368,
            "rating_q975": 1422.2263495069055,
            "rating_q025": 1334.232907841968
        },
        "claude-3-7-sonnet-20250219-thinking-32k": {
            "rating": 1377.1995520608666,
            "rating_q975": 1406.4658178705035,
            "rating_q025": 1347.9332862512297
        },
        "deepseek-v3": {
            "rating": 1376.0789147436042,
            "rating_q975": 1412.4420495383429,
            "rating_q025": 1339.7157799488655
        },
        "gemini-advanced-0514": {
            "rating": 1375.0647931364208,
            "rating_q975": 1398.9719755249687,
            "rating_q025": 1351.157610747873
        },
        "claude-3-5-sonnet-20240620": {
            "rating": 1372.5438718223488,
            "rating_q975": 1393.9795934097922,
            "rating_q025": 1351.1081502349055
        },
        "qwen3-30b-a3b": {
            "rating": 1370.7255648744824,
            "rating_q975": 1404.47601674609,
            "rating_q025": 1336.9751130028749
        },
        "o3-mini": {
            "rating": 1370.2304721802693,
            "rating_q975": 1394.406473214296,
            "rating_q025": 1346.0544711462426
        },
        "qwen3-235b-a22b": {
            "rating": 1369.7410204420162,
            "rating_q975": 1403.677264341919,
            "rating_q025": 1335.8047765421134
        },
        "gpt-4o-2024-05-13": {
            "rating": 1368.795479904358,
            "rating_q975": 1386.9024690721196,
            "rating_q025": 1350.6884907365963
        },
        "grok-3-mini-beta": {
            "rating": 1364.4409977490784,
            "rating_q975": 1402.1355132284127,
            "rating_q025": 1326.746482269744
        },
        "athene-v2-chat": {
            "rating": 1362.5406900945804,
            "rating_q975": 1398.8400715645578,
            "rating_q025": 1326.241308624603
        },
        "mistral-small-2506": {
            "rating": 1359.8332778056229,
            "rating_q975": 1400.8692595206835,
            "rating_q025": 1318.7972960905622
        },
        "grok-2-2024-08-13": {
            "rating": 1357.2344372338869,
            "rating_q975": 1381.590756376959,
            "rating_q025": 1332.8781180908147
        },
        "gemini-1.5-pro-002": {
            "rating": 1352.423282577378,
            "rating_q975": 1379.507640339326,
            "rating_q025": 1325.33892481543
        },
        "glm-4-plus": {
            "rating": 1351.5346562425193,
            "rating_q975": 1386.5723833470313,
            "rating_q025": 1316.4969291380073
        },
        "qwq-32b": {
            "rating": 1351.1419990768163,
            "rating_q975": 1385.8329834185017,
            "rating_q025": 1316.451014735131
        },
        "gpt-4-1106-preview": {
            "rating": 1350.721468836712,
            "rating_q975": 1369.0487692842962,
            "rating_q025": 1332.3941683891276
        },
        "gemma-3n-e4b-it": {
            "rating": 1350.4246981762783,
            "rating_q975": 1385.815031382612,
            "rating_q025": 1315.0343649699446
        },
        "llama-3.1-405b-instruct-bf16": {
            "rating": 1349.823124983026,
            "rating_q975": 1379.585163324327,
            "rating_q025": 1320.061086641725
        },
        "claude-3-opus-20240229": {
            "rating": 1349.1744403765738,
            "rating_q975": 1365.0541252610822,
            "rating_q025": 1333.2947554920654
        },
        "claude-3-5-haiku-20241022": {
            "rating": 1348.75426940948,
            "rating_q975": 1372.296815842407,
            "rating_q025": 1325.211722976553
        },
        "gpt-4-0125-preview": {
            "rating": 1348.5214740113556,
            "rating_q975": 1367.774232154989,
            "rating_q025": 1329.2687158677222
        },
        "yi-lightning": {
            "rating": 1345.8073885814995,
            "rating_q975": 1381.6311273838592,
            "rating_q025": 1309.9836497791398
        },
        "gpt-4-turbo-2024-04-09": {
            "rating": 1344.9341214104502,
            "rating_q975": 1363.8775510191927,
            "rating_q025": 1325.9906918017077
        },
        "grok-3-mini-high": {
            "rating": 1343.7953975907062,
            "rating_q975": 1388.899722550139,
            "rating_q025": 1298.6910726312735
        },
        "gpt-4o-mini-2024-07-18": {
            "rating": 1342.7154016970283,
            "rating_q975": 1365.2783415008894,
            "rating_q025": 1320.1524618931671
        },
        "llama-3.1-405b-instruct-fp8": {
            "rating": 1340.9344801362934,
            "rating_q975": 1366.7413427148495,
            "rating_q025": 1315.1276175577373
        },
        "llama-4-scout-17b-16e-instruct": {
            "rating": 1340.874822716665,
            "rating_q975": 1372.6968420948915,
            "rating_q025": 1309.0528033384385
        },
        "gemini-1.5-pro-001": {
            "rating": 1339.8080851041848,
            "rating_q975": 1360.1226992844133,
            "rating_q025": 1319.4934709239562
        },
        "llama-3.3-70b-instruct": {
            "rating": 1337.374370889916,
            "rating_q975": 1363.10951198022,
            "rating_q025": 1311.639229799612
        },
        "gpt-4o-2024-08-06": {
            "rating": 1336.156659099732,
            "rating_q975": 1363.0855610684232,
            "rating_q025": 1309.2277571310408
        },
        "athene-70b-0725": {
            "rating": 1335.7065809974501,
            "rating_q975": 1376.469499889693,
            "rating_q025": 1294.9436621052073
        },
        "mistral-large-2407": {
            "rating": 1335.0478605458366,
            "rating_q975": 1362.707520878216,
            "rating_q025": 1307.3882002134571
        },
        "gpt-oss-120b": {
            "rating": 1333.7044605268338,
            "rating_q975": 1367.3057982438506,
            "rating_q025": 1300.103122809817
        },
        "deepseek-v2.5": {
            "rating": 1329.0841693417042,
            "rating_q975": 1365.878079643655,
            "rating_q025": 1292.2902590397534
        },
        "o1-mini": {
            "rating": 1328.8685699400696,
            "rating_q975": 1357.2938491266898,
            "rating_q025": 1300.4432907534494
        },
        "magistral-medium-2506": {
            "rating": 1326.5035688229505,
            "rating_q975": 1376.3917286664664,
            "rating_q025": 1276.6154089794345
        },
        "grok-2-mini-2024-08-13": {
            "rating": 1326.180138187719,
            "rating_q975": 1353.3828316488232,
            "rating_q025": 1298.9774447266147
        },
        "qwen2.5-72b-instruct": {
            "rating": 1323.7434828679213,
            "rating_q975": 1355.4536952750027,
            "rating_q025": 1292.03327046084
        },
        "amazon-nova-pro-v1.0": {
            "rating": 1322.1574520347908,
            "rating_q975": 1360.3577189637413,
            "rating_q025": 1283.9571851058404
        },
        "gpt-4-0314": {
            "rating": 1319.2589469191562,
            "rating_q975": 1342.9740205096905,
            "rating_q025": 1295.5438733286219
        },
        "gemma-2-27b-it": {
            "rating": 1319.2150492860492,
            "rating_q975": 1340.2494483269631,
            "rating_q025": 1298.1806502451352
        },
        "claude-3-sonnet-20240229": {
            "rating": 1312.2222975573281,
            "rating_q975": 1330.4034223177557,
            "rating_q025": 1294.0411727969006
        },
        "llama-3.1-70b-instruct": {
            "rating": 1309.5034888476705,
            "rating_q975": 1336.5207193447777,
            "rating_q025": 1282.4862583505633
        },
        "gemini-1.5-flash-001": {
            "rating": 1304.0502786294694,
            "rating_q975": 1325.8449078668025,
            "rating_q025": 1282.2556493921363
        },
        "c4ai-aya-expanse-32b": {
            "rating": 1301.4270408452899,
            "rating_q975": 1335.2234544951257,
            "rating_q025": 1267.630627195454
        },
        "llama-3-70b-instruct": {
            "rating": 1301.0357880536599,
            "rating_q975": 1317.4814235704364,
            "rating_q025": 1284.5901525368834
        },
        "llama-4-maverick-17b-128e-instruct": {
            "rating": 1299.3097517851709,
            "rating_q975": 1326.6070344335365,
            "rating_q025": 1272.0124691368053
        },
        "mistral-small-3.1-24b-instruct-2503": {
            "rating": 1298.0477863636943,
            "rating_q975": 1330.6484591674068,
            "rating_q025": 1265.4471135599817
        },
        "mistral-large-2402": {
            "rating": 1297.274274256068,
            "rating_q975": 1318.651982910609,
            "rating_q025": 1275.8965656015273
        },
        "gemini-1.5-flash-002": {
            "rating": 1294.4844509695793,
            "rating_q975": 1328.0542649824035,
            "rating_q025": 1260.914636956755
        },
        "command-r-plus": {
            "rating": 1287.4454996030895,
            "rating_q975": 1307.802782823027,
            "rating_q025": 1267.088216383152
        },
        "claude-3-haiku-20240307": {
            "rating": 1286.4972922253487,
            "rating_q975": 1304.5092931493314,
            "rating_q025": 1268.485291301366
        },
        "gemini-1.5-flash-8b-001": {
            "rating": 1285.5959294557583,
            "rating_q975": 1317.6329107159897,
            "rating_q025": 1253.558948195527
        },
        "amazon-nova-micro-v1.0": {
            "rating": 1283.7557318542717,
            "rating_q975": 1328.0812627829926,
            "rating_q025": 1239.430200925551
        },
        "gpt-4-0613": {
            "rating": 1283.1918192110966,
            "rating_q975": 1302.7135684194168,
            "rating_q025": 1263.6700700027764
        },
        "nemotron-4-340b-instruct": {
            "rating": 1275.4103190559706,
            "rating_q975": 1308.3858372393302,
            "rating_q025": 1242.434800872611
        },
        "amazon-nova-lite-v1.0": {
            "rating": 1274.57061696858,
            "rating_q975": 1319.653122830742,
            "rating_q025": 1229.488111106418
        },
        "phi-4": {
            "rating": 1273.60335860268,
            "rating_q975": 1313.6395415454729,
            "rating_q025": 1233.567175659887
        },
        "gemma-2-9b-it": {
            "rating": 1267.5184367053807,
            "rating_q975": 1292.1544726979541,
            "rating_q025": 1242.8824007128073
        },
        "deepseek-coder-v2": {
            "rating": 1266.8827176866646,
            "rating_q975": 1307.752600161599,
            "rating_q025": 1226.0128352117301
        },
        "mixtral-8x22b-instruct-v0.1": {
            "rating": 1265.7034895914574,
            "rating_q975": 1289.601563008024,
            "rating_q025": 1241.8054161748908
        },
        "qwen2-72b-instruct": {
            "rating": 1263.8526761086346,
            "rating_q975": 1288.385990057985,
            "rating_q025": 1239.319362159284
        },
        "mistral-small-24b-instruct-2501": {
            "rating": 1259.8841316185608,
            "rating_q975": 1309.8225000205018,
            "rating_q025": 1209.9457632166198
        },
        "mistral-medium": {
            "rating": 1259.5819605508648,
            "rating_q975": 1284.8815006246018,
            "rating_q025": 1234.2824204771277
        },
        "gemini-pro-dev-api": {
            "rating": 1256.6844921076101,
            "rating_q975": 1287.5773718510154,
            "rating_q025": 1225.7916123642049
        },
        "reka-flash-21b-20240226": {
            "rating": 1256.3426679564195,
            "rating_q975": 1286.097706988913,
            "rating_q025": 1226.587628923926
        },
        "mixtral-8x7b-instruct-v0.1": {
            "rating": 1251.6800494243844,
            "rating_q975": 1271.849997055502,
            "rating_q025": 1231.5101017932668
        },
        "qwen1.5-72b-chat": {
            "rating": 1248.5665919212115,
            "rating_q975": 1271.4916701854233,
            "rating_q025": 1225.6415136569997
        },
        "command-r": {
            "rating": 1245.9230765030065,
            "rating_q975": 1269.2145921708832,
            "rating_q025": 1222.63156083513
        },
        "gpt-3.5-turbo-0125": {
            "rating": 1243.8419783946968,
            "rating_q975": 1264.4762885006185,
            "rating_q025": 1223.207668288775
        },
        "reka-flash-21b-20240226-online": {
            "rating": 1242.2237080501939,
            "rating_q975": 1282.319339973772,
            "rating_q025": 1202.1280761266157
        },
        "qwen1.5-110b-chat": {
            "rating": 1238.405911349789,
            "rating_q975": 1269.3697897270215,
            "rating_q025": 1207.4420329725565
        },
        "llama-3-8b-instruct": {
            "rating": 1233.2760156926388,
            "rating_q975": 1252.1241076045446,
            "rating_q025": 1214.427923780733
        },
        "snowflake-arctic-instruct": {
            "rating": 1228.7759623941602,
            "rating_q975": 1257.778623433846,
            "rating_q025": 1199.7733013544744
        },
        "phi-3-small-8k-instruct": {
            "rating": 1222.4048597251278,
            "rating_q975": 1257.0890078146329,
            "rating_q025": 1187.7207116356228
        },
        "yi-1.5-34b-chat": {
            "rating": 1217.474385482497,
            "rating_q975": 1248.2914472533341,
            "rating_q025": 1186.6573237116597
        },
        "gemma-2-2b-it": {
            "rating": 1215.9273344841279,
            "rating_q975": 1244.7640889979582,
            "rating_q025": 1187.0905799702975
        },
        "llama-3.1-8b-instruct": {
            "rating": 1214.6066956335048,
            "rating_q975": 1242.7260965074672,
            "rating_q025": 1186.4872947595425
        },
        "qwen1.5-14b-chat": {
            "rating": 1204.3828227219717,
            "rating_q975": 1242.1787857729678,
            "rating_q025": 1166.5868596709756
        },
        "gpt-3.5-turbo-1106": {
            "rating": 1200.7911549556395,
            "rating_q975": 1238.7395743351883,
            "rating_q025": 1162.8427355760907
        },
        "phi-3-medium-4k-instruct": {
            "rating": 1199.9458208206115,
            "rating_q975": 1232.3439211733908,
            "rating_q025": 1167.5477204678323
        },
        "dbrx-instruct-preview": {
            "rating": 1199.052257466046,
            "rating_q975": 1227.5081484228497,
            "rating_q025": 1170.5963665092424
        },
        "openchat-3.5-0106": {
            "rating": 1194.2943705966454,
            "rating_q975": 1236.9343852394613,
            "rating_q025": 1151.6543559538295
        },
        "qwen1.5-32b-chat": {
            "rating": 1189.117542937654,
            "rating_q975": 1223.0745688001189,
            "rating_q025": 1155.160517075189
        },
        "gemma-1.1-7b-it": {
            "rating": 1183.7886295846847,
            "rating_q975": 1214.880343129933,
            "rating_q025": 1152.6969160394365
        },
        "vicuna-33b": {
            "rating": 1175.4547675557815,
            "rating_q975": 1211.9248846725054,
            "rating_q025": 1138.9846504390575
        },
        "starling-lm-7b-alpha": {
            "rating": 1173.7414167781253,
            "rating_q975": 1216.4086432318861,
            "rating_q025": 1131.0741903243645
        },
        "starling-lm-7b-beta": {
            "rating": 1171.6960717088964,
            "rating_q975": 1210.0707496645814,
            "rating_q025": 1133.3213937532114
        },
        "yi-34b-chat": {
            "rating": 1165.4476430057366,
            "rating_q975": 1205.1439749616798,
            "rating_q025": 1125.7513110497935
        },
        "llama-2-70b-chat": {
            "rating": 1163.0671486256342,
            "rating_q975": 1189.1242363886881,
            "rating_q025": 1137.0100608625803
        },
        "phi-3-mini-4k-instruct": {
            "rating": 1160.4463625414242,
            "rating_q975": 1195.5650533484245,
            "rating_q025": 1125.3276717344238
        },
        "phi-3-mini-128k-instruct": {
            "rating": 1142.7127456779408,
            "rating_q975": 1177.132696130543,
            "rating_q025": 1108.2927952253385
        },
        "gemma-7b-it": {
            "rating": 1135.3035831317638,
            "rating_q975": 1181.0943387006175,
            "rating_q025": 1089.5128275629102
        },
        "stripedhyena-nous-7b": {
            "rating": 1131.7662474252288,
            "rating_q975": 1180.3451548717462,
            "rating_q025": 1083.1873399787114
        },
        "vicuna-13b": {
            "rating": 1125.9938311141332,
            "rating_q975": 1171.130001822665,
            "rating_q025": 1080.8576604056013
        },
        "mistral-7b-instruct-v0.2": {
            "rating": 1125.9092926918224,
            "rating_q975": 1156.8261833655156,
            "rating_q025": 1094.9924020181293
        },
        "llama-2-13b-chat": {
            "rating": 1119.9259035213038,
            "rating_q975": 1158.4762020548337,
            "rating_q025": 1081.3756049877738
        },
        "zephyr-7b-beta": {
            "rating": 1112.1499689350148,
            "rating_q975": 1161.003651523462,
            "rating_q025": 1063.2962863465677
        },
        "mistral-7b-instruct": {
            "rating": 1068.0510630135714,
            "rating_q975": 1115.3262229098657,
            "rating_q025": 1020.775903117277
        },
        "llama-2-7b-chat": {
            "rating": 1048.3970380951152,
            "rating_q975": 1089.6931620078817,
            "rating_q025": 1007.1009141823488
        }
    },
    "full": {
        "gemini-2.5-pro": {
            "rating": 1452.0914099800939,
            "rating_q975": 1456.0833897559273,
            "rating_q025": 1448.0994302042604
        },
        "claude-sonnet-4-5-20250929-thinking-32k": {
            "rating": 1448.0504443284915,
            "rating_q975": 1453.9324090243283,
            "rating_q025": 1442.1684796326547
        },
        "claude-opus-4-1-20250805-thinking-16k": {
            "rating": 1447.8964390907906,
            "rating_q975": 1452.4933878882662,
            "rating_q025": 1443.299490293315
        },
        "gpt-4.5-preview-2025-02-27": {
            "rating": 1441.7544476226744,
            "rating_q975": 1447.3910690819503,
            "rating_q025": 1436.1178261633986
        },
        "claude-sonnet-4-5-20250929": {
            "rating": 1441.0075372098315,
            "rating_q975": 1448.512884483818,
            "rating_q025": 1433.502189935845
        },
        "claude-opus-4-1-20250805": {
            "rating": 1438.6803068594152,
            "rating_q975": 1443.066150617153,
            "rating_q025": 1434.2944631016774
        },
        "chatgpt-4o-latest-20250326": {
            "rating": 1438.2598652401737,
            "rating_q975": 1442.0965442228598,
            "rating_q025": 1434.4231862574875
        },
        "gpt-5-high": {
            "rating": 1436.2122234589658,
            "rating_q975": 1441.0127296348467,
            "rating_q025": 1431.411717283085
        },
        "o3-2025-04-16": {
            "rating": 1433.8405450529303,
            "rating_q975": 1437.6205780369476,
            "rating_q025": 1430.060512068913
        },
        "qwen3-max-preview": {
            "rating": 1432.2652615917625,
            "rating_q975": 1437.0957679355536,
            "rating_q025": 1427.4347552479715
        },
        "deepseek-v3.2-exp": {
            "rating": 1430.235916722208,
            "rating_q975": 1457.1188863058842,
            "rating_q025": 1403.3529471385318
        },
        "glm-4.6": {
            "rating": 1429.0302149942845,
            "rating_q975": 1435.3908591782592,
            "rating_q025": 1422.6695708103098
        },
        "gpt-5-chat": {
            "rating": 1424.9114159517383,
            "rating_q975": 1429.4877731375557,
            "rating_q025": 1420.3350587659208
        },
        "qwen3-max-2025-09-23": {
            "rating": 1423.3895708608811,
            "rating_q975": 1429.827092886865,
            "rating_q025": 1416.9520488348971
        },
        "claude-opus-4-20250514-thinking-16k": {
            "rating": 1422.638457981719,
            "rating_q975": 1426.9935311486383,
            "rating_q025": 1418.2833848147998
        },
        "deepseek-v3.2-exp-thinking": {
            "rating": 1420.7762359424366,
            "rating_q975": 1427.3508838139787,
            "rating_q025": 1414.2015880708946
        },
        "grok-4-fast": {
            "rating": 1419.5811484326205,
            "rating_q975": 1427.172750601874,
            "rating_q025": 1411.989546263367
        },
        "qwen3-235b-a22b-instruct-2507": {
            "rating": 1419.55681499393,
            "rating_q975": 1423.9099067404334,
            "rating_q025": 1415.2037232474265
        },
        "deepseek-r1-0528": {
            "rating": 1417.2869516866838,
            "rating_q975": 1422.8998691973325,
            "rating_q025": 1411.674034176035
        },
        "kimi-k2-0905-preview": {
            "rating": 1416.542034147461,
            "rating_q975": 1423.3817692359248,
            "rating_q025": 1409.7022990589971
        },
        "deepseek-v3.1": {
            "rating": 1415.9305186127374,
            "rating_q975": 1421.9646767718505,
            "rating_q025": 1409.8963604536243
        },
        "deepseek-v3.1-thinking": {
            "rating": 1415.7691156890871,
            "rating_q975": 1422.3707645588402,
            "rating_q025": 1409.167466819334
        },
        "kimi-k2-0711-preview": {
            "rating": 1415.2967412141822,
            "rating_q975": 1420.1409757391746,
            "rating_q025": 1410.45250668919
        },
        "qwen3-vl-235b-a22b-instruct": {
            "rating": 1414.8076267318165,
            "rating_q975": 1421.4827850338886,
            "rating_q025": 1408.1324684297444
        },
        "deepseek-v3.1-terminus": {
            "rating": 1414.5290606436968,
            "rating_q975": 1424.1199524481754,
            "rating_q025": 1404.9381688392182
        },
        "deepseek-v3.1-terminus-thinking": {
            "rating": 1413.6510219094125,
            "rating_q975": 1423.5459210660479,
            "rating_q025": 1403.7561227527772
        },
        "gpt-4.1-2025-04-14": {
            "rating": 1412.3740939040092,
            "rating_q975": 1416.2605607478874,
            "rating_q025": 1408.487627060131
        },
        "claude-opus-4-20250514": {
            "rating": 1411.725496243104,
            "rating_q975": 1416.0070707829552,
            "rating_q025": 1407.443921703253
        },
        "mistral-medium-2508": {
            "rating": 1410.9585935373016,
            "rating_q975": 1415.6228007514417,
            "rating_q025": 1406.2943863231615
        },
        "grok-3-preview-02-24": {
            "rating": 1409.6780938726602,
            "rating_q975": 1413.9335005534394,
            "rating_q025": 1405.4226871918809
        },
        "grok-4-0709": {
            "rating": 1409.3255389057583,
            "rating_q975": 1413.5990456556872,
            "rating_q025": 1405.0520321558295
        },
        "glm-4.5": {
            "rating": 1408.1595423020433,
            "rating_q975": 1413.0616306076902,
            "rating_q025": 1403.2574539963964
        },
        "gemini-2.5-flash": {
            "rating": 1407.715761686987,
            "rating_q975": 1411.6204972950027,
            "rating_q025": 1403.8110260789713
        },
        "gemini-2.5-flash-preview-09-2025": {
            "rating": 1406.0433802659227,
            "rating_q975": 1411.6941067407136,
            "rating_q025": 1400.3926537911318
        },
        "claude-haiku-4-5-20251001": {
            "rating": 1403.0428463090732,
            "rating_q975": 1409.3632693355412,
            "rating_q025": 1396.7224232826052
        },
        "qwen3-next-80b-a3b-instruct": {
            "rating": 1401.2010543688282,
            "rating_q975": 1406.386110616163,
            "rating_q025": 1396.0159981214933
        },
        "o1-2024-12-17": {
            "rating": 1399.9674641920153,
            "rating_q975": 1404.3019636512538,
            "rating_q025": 1395.6329647327768
        },
        "claude-sonnet-4-20250514-thinking-32k": {
            "rating": 1399.052628595794,
            "rating_q975": 1403.4546364710757,
            "rating_q025": 1394.6506207205123
        },
        "longcat-flash-chat": {
            "rating": 1398.8591703042487,
            "rating_q975": 1405.2706801233264,
            "rating_q025": 1392.447660485171
        },
        "qwen3-235b-a22b-no-thinking": {
            "rating": 1398.6451579142727,
            "rating_q975": 1403.15844328713,
            "rating_q025": 1394.1318725414153
        },
        "qwen3-235b-a22b-thinking-2507": {
            "rating": 1397.0562885659908,
            "rating_q975": 1403.5230551246234,
            "rating_q025": 1390.5895220073583
        },
        "deepseek-r1": {
            "rating": 1394.9270490089993,
            "rating_q975": 1399.716261699803,
            "rating_q025": 1390.1378363181957
        },
        "qwen3-vl-235b-a22b-thinking": {
            "rating": 1393.1253518518781,
            "rating_q975": 1399.9446883995822,
            "rating_q025": 1386.306015304174
        },
        "gpt-5-mini-high": {
            "rating": 1391.8988406606397,
            "rating_q975": 1396.874820361443,
            "rating_q025": 1386.9228609598365
        },
        "deepseek-v3-0324": {
            "rating": 1391.1672387688675,
            "rating_q975": 1395.046738277876,
            "rating_q025": 1387.2877392598589
        },
        "o4-mini-2025-04-16": {
            "rating": 1390.7535782928117,
            "rating_q975": 1394.735565220204,
            "rating_q025": 1386.7715913654192
        },
        "mai-1-preview": {
            "rating": 1390.427788741815,
            "rating_q975": 1395.899213069935,
            "rating_q025": 1384.956364413695
        },
        "claude-sonnet-4-20250514": {
            "rating": 1388.9672105382303,
            "rating_q975": 1393.3272937777015,
            "rating_q025": 1384.6071272987592
        },
        "o1-preview": {
            "rating": 1386.3375038216027,
            "rating_q975": 1391.1925345000411,
            "rating_q025": 1381.4824731431643
        },
        "claude-3-7-sonnet-20250219-thinking-32k": {
            "rating": 1386.3076084079523,
            "rating_q975": 1390.4568664507035,
            "rating_q025": 1382.1583503652012
        },
        "qwen3-coder-480b-a35b-instruct": {
            "rating": 1384.8385442297317,
            "rating_q975": 1389.8365325483617,
            "rating_q025": 1379.8405559111018
        },
        "hunyuan-t1-20250711": {
            "rating": 1384.5735313947193,
            "rating_q975": 1393.125079771079,
            "rating_q025": 1376.0219830183596
        },
        "mistral-medium-2505": {
            "rating": 1382.3480102891165,
            "rating_q975": 1387.039704946511,
            "rating_q025": 1377.656315631722
        },
        "qwen3-30b-a3b-instruct-2507": {
            "rating": 1381.9462553149435,
            "rating_q975": 1386.8544673874155,
            "rating_q025": 1377.0380432424715
        },
        "gpt-4.1-mini-2025-04-14": {
            "rating": 1379.927789974296,
            "rating_q975": 1384.2289790542297,
            "rating_q025": 1375.6266008943624
        },
        "gemini-2.5-flash-lite-preview-09-2025-no-thinking": {
            "rating": 1379.6314492677507,
            "rating_q975": 1385.26378079372,
            "rating_q025": 1373.9991177417814
        },
        "hunyuan-turbos-20250416": {
            "rating": 1379.6151721330193,
            "rating_q975": 1385.9478512572641,
            "rating_q025": 1373.2824930087745
        },
        "gemini-2.5-flash-lite-preview-06-17-thinking": {
            "rating": 1375.4353923557803,
            "rating_q975": 1379.9452516519164,
            "rating_q025": 1370.9255330596443
        },
        "qwen3-235b-a22b": {
            "rating": 1373.0779507983734,
            "rating_q975": 1377.7753070889507,
            "rating_q025": 1368.380594507796
        },
        "qwen2.5-max": {
            "rating": 1372.0509613217498,
            "rating_q975": 1376.034820138085,
            "rating_q025": 1368.0671025054146
        },
        "claude-3-5-sonnet-20241022": {
            "rating": 1370.9730238822192,
            "rating_q975": 1374.0277337409582,
            "rating_q025": 1367.9183140234802
        },
        "glm-4.5-air": {
            "rating": 1370.5462245342933,
            "rating_q975": 1375.0617527076654,
            "rating_q025": 1366.0306963609212
        },
        "qwen3-next-80b-a3b-thinking": {
            "rating": 1367.0352658374345,
            "rating_q975": 1372.9191672068494,
            "rating_q025": 1361.1513644680197
        },
        "minimax-m1": {
            "rating": 1365.9265916792178,
            "rating_q975": 1370.1949523104513,
            "rating_q025": 1361.6582310479844
        },
        "gemma-3-27b-it": {
            "rating": 1364.464906266267,
            "rating_q975": 1368.124390590137,
            "rating_q025": 1360.805421942397
        },
        "grok-3-mini-high": {
            "rating": 1362.2673969636398,
            "rating_q975": 1367.5877710422023,
            "rating_q025": 1356.9470228850773
        },
        "o3-mini-high": {
            "rating": 1362.0874385114957,
            "rating_q975": 1367.255342024093,
            "rating_q025": 1356.9195349988986
        },
        "grok-3-mini-beta": {
            "rating": 1356.7150205395797,
            "rating_q975": 1361.7132240162564,
            "rating_q025": 1351.716817062903
        },
        "deepseek-v3": {
            "rating": 1356.6080206524614,
            "rating_q975": 1361.2238061444496,
            "rating_q025": 1351.9922351604732
        },
        "mistral-small-2506": {
            "rating": 1354.037858428934,
            "rating_q975": 1359.2395369298001,
            "rating_q025": 1348.8361799280678
        },
        "gemini-2.0-flash-lite-preview-02-05": {
            "rating": 1352.033089159524,
            "rating_q975": 1356.2448417853723,
            "rating_q025": 1347.8213365336758
        },
        "glm-4.5v": {
            "rating": 1351.170706659784,
            "rating_q975": 1359.5594485939798,
            "rating_q025": 1342.781964725588
        },
        "gemini-1.5-pro-002": {
            "rating": 1350.6680831069143,
            "rating_q975": 1353.8761907359103,
            "rating_q025": 1347.4599754779183
        },
        "gpt-oss-120b": {
            "rating": 1350.5470332711845,
            "rating_q975": 1355.2006732424102,
            "rating_q025": 1345.893393299959
        },
        "command-a-03-2025": {
            "rating": 1350.3547339015902,
            "rating_q975": 1353.920977357408,
            "rating_q025": 1346.7884904457724
        },
        "o3-mini": {
            "rating": 1347.2804270869378,
            "rating_q975": 1350.7343030847162,
            "rating_q025": 1343.8265510891595
        },
        "hunyuan-turbos-20250226": {
            "rating": 1345.4037103055152,
            "rating_q975": 1357.0527665673858,
            "rating_q025": 1333.7546540436447
        },
        "ling-flash-2.0": {
            "rating": 1345.2682805890347,
            "rating_q975": 1352.50688028463,
            "rating_q025": 1338.0296808934395
        },
        "llama-3.1-nemotron-ultra-253b-v1": {
            "rating": 1344.9725922135092,
            "rating_q975": 1356.6508381738063,
            "rating_q025": 1333.294346253212
        },
        "step-3": {
            "rating": 1344.50167215575,
            "rating_q975": 1351.8862721481203,
            "rating_q025": 1337.1170721633796
        },
        "qwen3-32b": {
            "rating": 1344.0066485298607,
            "rating_q975": 1353.4851391400055,
            "rating_q025": 1334.528157919716
        },
        "amazon-nova-experimental-chat-10-09": {
            "rating": 1343.9949200314277,
            "rating_q975": 1351.6763032008855,
            "rating_q025": 1336.3135368619699
        },
        "gpt-4o-2024-05-13": {
            "rating": 1343.766855687193,
            "rating_q975": 1347.0368832589459,
            "rating_q025": 1340.49682811544
        },
        "qwen-plus-0125": {
            "rating": 1343.6244865449416,
            "rating_q975": 1351.9135358938472,
            "rating_q025": 1335.335437196036
        },
        "glm-4-plus-0111": {
            "rating": 1342.5388503649433,
            "rating_q975": 1350.887447171284,
            "rating_q025": 1334.1902535586025
        },
        "claude-3-5-sonnet-20240620": {
            "rating": 1341.115706982011,
            "rating_q975": 1344.4105885456038,
            "rating_q025": 1337.8208254184183
        },
        "gemma-3-12b-it": {
            "rating": 1340.060212898355,
            "rating_q975": 1349.5481368718808,
            "rating_q025": 1330.5722889248293
        },
        "nvidia-llama-3.3-nemotron-super-49b-v1.5": {
            "rating": 1339.129759087755,
            "rating_q975": 1348.912509843365,
            "rating_q025": 1329.3470083321452
        },
        "gpt-5-nano-high": {
            "rating": 1338.3566593427213,
            "rating_q975": 1345.2679522681537,
            "rating_q025": 1331.4453664172888
        },
        "hunyuan-turbo-0110": {
            "rating": 1337.8908040187212,
            "rating_q975": 1349.351125041933,
            "rating_q025": 1326.4304829955092
        },
        "llama-3.1-405b-instruct-bf16": {
            "rating": 1334.832029318173,
            "rating_q975": 1338.3882488355787,
            "rating_q025": 1331.2758098007673
        },
        "o1-mini": {
            "rating": 1334.402034919387,
            "rating_q975": 1337.883597522086,
            "rating_q025": 1330.9204723166881
        },
        "gpt-4o-2024-08-06": {
            "rating": 1333.4363917813857,
            "rating_q975": 1337.4834229940614,
            "rating_q025": 1329.3893605687101
        },
        "qwq-32b": {
            "rating": 1333.0519475574451,
            "rating_q975": 1337.4439455946886,
            "rating_q025": 1328.6599495202017
        },
        "grok-2-2024-08-13": {
            "rating": 1332.94428728633,
            "rating_q975": 1336.4547693747386,
            "rating_q025": 1329.4338051979216
        },
        "llama-3.1-405b-instruct-fp8": {
            "rating": 1332.7485125897658,
            "rating_q975": 1336.159408948429,
            "rating_q025": 1329.3376162311026
        },
        "gemini-advanced-0514": {
            "rating": 1332.4633653665483,
            "rating_q975": 1337.5283234372027,
            "rating_q025": 1327.3984072958938
        },
        "step-2-16k-exp-202412": {
            "rating": 1331.6163200231235,
            "rating_q975": 1340.1116225938558,
            "rating_q025": 1323.1210174523912
        },
        "llama-4-maverick-17b-128e-instruct": {
            "rating": 1327.2950224053566,
            "rating_q975": 1331.529200397685,
            "rating_q025": 1323.0608444130282
        },
        "yi-lightning": {
            "rating": 1327.1298933135645,
            "rating_q975": 1331.9340566257335,
            "rating_q025": 1322.3257300013954
        },
        "qwen3-30b-a3b": {
            "rating": 1325.5858323588031,
            "rating_q975": 1330.2967852542106,
            "rating_q025": 1320.8748794633957
        },
        "llama-3.3-nemotron-49b-super-v1": {
            "rating": 1324.6601012426752,
            "rating_q975": 1336.733117887808,
            "rating_q025": 1312.5870845975423
        },
        "hunyuan-large-2025-02-10": {
            "rating": 1323.8531208308875,
            "rating_q975": 1333.552696792223,
            "rating_q025": 1314.153544869552
        },
        "gpt-4-turbo-2024-04-09": {
            "rating": 1322.7035224287338,
            "rating_q975": 1326.4642997258218,
            "rating_q025": 1318.9427451316458
        },
        "llama-4-scout-17b-16e-instruct": {
            "rating": 1322.0970091205152,
            "rating_q975": 1326.788510774087,
            "rating_q025": 1317.4055074669434
        },
        "claude-3-5-haiku-20241022": {
            "rating": 1321.6225003631469,
            "rating_q975": 1324.7884480662683,
            "rating_q025": 1318.4565526600254
        },
        "deepseek-v2.5-1210": {
            "rating": 1321.3326517161167,
            "rating_q975": 1329.5143694193198,
            "rating_q025": 1313.1509340129137
        },
        "claude-3-opus-20240229": {
            "rating": 1321.1777017277936,
            "rating_q975": 1324.0662939692045,
            "rating_q025": 1318.2891094863828
        },
        "gemini-1.5-pro-001": {
            "rating": 1320.6619727089726,
            "rating_q975": 1324.4909311151544,
            "rating_q025": 1316.8330143027908
        },
        "gpt-4.1-nano-2025-04-14": {
            "rating": 1319.8247793640703,
            "rating_q975": 1327.5484807087948,
            "rating_q025": 1312.1010780193458
        },
        "ring-flash-2.0": {
            "rating": 1319.4908586389804,
            "rating_q975": 1326.6939027086335,
            "rating_q025": 1312.2878145693273
        },
        "step-1o-turbo-202506": {
            "rating": 1319.4535180171458,
            "rating_q975": 1326.0925998680013,
            "rating_q025": 1312.8144361662903
        },
        "llama-3.3-70b-instruct": {
            "rating": 1319.0160185061532,
            "rating_q975": 1322.365939282951,
            "rating_q025": 1315.6660977293552
        },
        "gemma-3n-e4b-it": {
            "rating": 1318.2799450992975,
            "rating_q975": 1323.400233579334,
            "rating_q025": 1313.1596566192609
        },
        "gpt-oss-20b": {
            "rating": 1317.4969293456666,
            "rating_q975": 1323.8550266119769,
            "rating_q025": 1311.1388320793562
        },
        "glm-4-plus": {
            "rating": 1317.1705515645713,
            "rating_q975": 1321.969362868317,
            "rating_q025": 1312.3717402608256
        },
        "qwen-max-0919": {
            "rating": 1316.1047048678429,
            "rating_q975": 1321.684540370185,
            "rating_q025": 1310.5248693655008
        },
        "gpt-4o-mini-2024-07-18": {
            "rating": 1315.3312229398457,
            "rating_q975": 1318.6774580659476,
            "rating_q025": 1311.9849878137438
        },
        "qwen2.5-plus-1127": {
            "rating": 1313.289937221129,
            "rating_q975": 1319.546040214633,
            "rating_q025": 1307.0338342276252
        },
        "gpt-4-1106-preview": {
            "rating": 1312.4370730501437,
            "rating_q975": 1316.1700309151895,
            "rating_q025": 1308.7041151850979
        },
        "athene-v2-chat": {
            "rating": 1312.3449403805116,
            "rating_q975": 1316.7720480382588,
            "rating_q025": 1307.9178327227644
        },
        "mistral-large-2407": {
            "rating": 1312.276067123674,
            "rating_q975": 1316.0322082943594,
            "rating_q025": 1308.5199259529886
        },
        "gpt-4-0125-preview": {
            "rating": 1312.2208003815738,
            "rating_q975": 1316.1519348374616,
            "rating_q025": 1308.289665925686
        },
        "gemini-1.5-flash-002": {
            "rating": 1309.7501910015587,
            "rating_q975": 1313.8146270643977,
            "rating_q025": 1305.6857549387198
        },
        "hunyuan-standard-2025-02-10": {
            "rating": 1309.227583507426,
            "rating_q975": 1318.88443933012,
            "rating_q025": 1299.5707276847322
        },
        "grok-2-mini-2024-08-13": {
            "rating": 1305.9103750468166,
            "rating_q975": 1309.4603095917785,
            "rating_q025": 1302.3604405018548
        },
        "deepseek-v2.5": {
            "rating": 1304.95313748794,
            "rating_q975": 1309.5225912180565,
            "rating_q025": 1300.3836837578235
        },
        "magistral-medium-2506": {
            "rating": 1304.4354780483236,
            "rating_q975": 1310.81161170608,
            "rating_q025": 1298.0593443905673
        },
        "mistral-large-2411": {
            "rating": 1303.8978091264862,
            "rating_q975": 1308.1939452284957,
            "rating_q025": 1299.6016730244767
        },
        "athene-70b-0725": {
            "rating": 1303.6155860896706,
            "rating_q975": 1309.1772303013022,
            "rating_q025": 1298.053941878039
        },
        "mistral-small-3.1-24b-instruct-2503": {
            "rating": 1302.7061279292602,
            "rating_q975": 1307.2049936524734,
            "rating_q025": 1298.207262206047
        },
        "gemma-3-4b-it": {
            "rating": 1302.3717631051113,
            "rating_q975": 1311.686912300398,
            "rating_q025": 1293.0566139098246
        },
        "qwen2.5-72b-instruct": {
            "rating": 1300.7412933470273,
            "rating_q975": 1304.658377665886,
            "rating_q025": 1296.8242090281685
        },
        "llama-3.1-nemotron-70b-instruct": {
            "rating": 1296.345715432214,
            "rating_q975": 1304.0411213641717,
            "rating_q025": 1288.6503095002565
        },
        "hunyuan-large-vision": {
            "rating": 1293.9214480530536,
            "rating_q975": 1302.9557023452187,
            "rating_q025": 1284.8871937608885
        },
        "llama-3.1-70b-instruct": {
            "rating": 1292.2839292434962,
            "rating_q975": 1295.8272145100989,
            "rating_q025": 1288.7406439768936
        },
        "amazon-nova-pro-v1.0": {
            "rating": 1287.5326846984324,
            "rating_q975": 1291.9584612433162,
            "rating_q025": 1283.1069081535486
        },
        "jamba-1.5-large": {
            "rating": 1287.0314531686886,
            "rating_q975": 1294.2606867051481,
            "rating_q025": 1279.802219632229
        },
        "reka-core-20240904": {
            "rating": 1286.2588114336422,
            "rating_q975": 1293.3225635764575,
            "rating_q025": 1279.195059290827
        },
        "gemma-2-27b-it": {
            "rating": 1286.014014931849,
            "rating_q975": 1289.2097597333081,
            "rating_q025": 1282.81827013039
        },
        "llama-3.1-tulu-3-70b": {
            "rating": 1285.4495774019906,
            "rating_q975": 1295.834562549284,
            "rating_q025": 1275.0645922546971
        },
        "llama-3.1-nemotron-51b-instruct": {
            "rating": 1285.1861923702616,
            "rating_q975": 1295.0793499538336,
            "rating_q025": 1275.2930347866895
        },
        "gpt-4-0314": {
            "rating": 1285.0695427381288,
            "rating_q975": 1289.7549014116437,
            "rating_q025": 1280.384184064614
        },
        "gemini-1.5-flash-001": {
            "rating": 1283.0707905500974,
            "rating_q975": 1287.4305552399785,
            "rating_q025": 1278.7110258602163
        },
        "claude-3-sonnet-20240229": {
            "rating": 1279.975546669385,
            "rating_q975": 1283.847688419416,
            "rating_q025": 1276.103404919354
        },
        "gemma-2-9b-it-simpo": {
            "rating": 1277.439168398511,
            "rating_q975": 1284.2291738701597,
            "rating_q025": 1270.6491629268621
        },
        "nemotron-4-340b-instruct": {
            "rating": 1276.8556007935426,
            "rating_q975": 1282.0630936209034,
            "rating_q025": 1271.648107966182
        },
        "command-r-plus-08-2024": {
            "rating": 1276.3728514605457,
            "rating_q975": 1282.8557325090815,
            "rating_q025": 1269.88997041201
        },
        "llama-3-70b-instruct": {
            "rating": 1274.6876824015549,
            "rating_q975": 1278.1178274292638,
            "rating_q025": 1271.257537373846
        },
        "gpt-4-0613": {
            "rating": 1273.7816680716312,
            "rating_q975": 1277.7311882343988,
            "rating_q025": 1269.8321479088636
        },
        "mistral-small-24b-instruct-2501": {
            "rating": 1272.9296680828547,
            "rating_q975": 1278.7397513061196,
            "rating_q025": 1267.1195848595898
        },
        "glm-4-0520": {
            "rating": 1272.0347319643276,
            "rating_q975": 1278.9423088559065,
            "rating_q025": 1265.1271550727488
        },
        "reka-flash-20240904": {
            "rating": 1271.7943886284643,
            "rating_q975": 1278.7037235541152,
            "rating_q025": 1264.8850537028134
        },
        "qwen2.5-coder-32b-instruct": {
            "rating": 1268.4509700931144,
            "rating_q975": 1276.5007180627415,
            "rating_q025": 1260.4012221234873
        },
        "c4ai-aya-expanse-32b": {
            "rating": 1266.0349449024172,
            "rating_q975": 1270.783897176541,
            "rating_q025": 1261.2859926282936
        },
        "gemma-2-9b-it": {
            "rating": 1263.3319753167734,
            "rating_q975": 1266.9864029883834,
            "rating_q025": 1259.6775476451635
        },
        "deepseek-coder-v2": {
            "rating": 1262.2836066570896,
            "rating_q975": 1268.474404886406,
            "rating_q025": 1256.0928084277732
        },
        "command-r-plus": {
            "rating": 1261.9423586952214,
            "rating_q975": 1266.1474998042195,
            "rating_q025": 1257.7372175862233
        },
        "qwen2-72b-instruct": {
            "rating": 1260.9422923483967,
            "rating_q975": 1265.770073992885,
            "rating_q025": 1256.1145107039083
        },
        "claude-3-haiku-20240307": {
            "rating": 1260.2593213149887,
            "rating_q975": 1263.8737044028474,
            "rating_q025": 1256.64493822713
        },
        "amazon-nova-lite-v1.0": {
            "rating": 1258.9248539057146,
            "rating_q975": 1263.9480447391618,
            "rating_q025": 1253.9016630722674
        },
        "gemini-1.5-flash-8b-001": {
            "rating": 1258.7415954337694,
            "rating_q975": 1262.8803269199188,
            "rating_q025": 1254.6028639476199
        },
        "phi-4": {
            "rating": 1254.5984537999284,
            "rating_q975": 1259.0753334746544,
            "rating_q025": 1250.1215741252024
        },
        "olmo-2-0325-32b-instruct": {
            "rating": 1252.158120535038,
            "rating_q975": 1262.875523049446,
            "rating_q025": 1241.4407180206301
        },
        "command-r-08-2024": {
            "rating": 1250.600637801581,
            "rating_q975": 1257.1016933433455,
            "rating_q025": 1244.0995822598163
        },
        "mistral-large-2402": {
            "rating": 1241.0437543259345,
            "rating_q975": 1245.6571673091319,
            "rating_q025": 1236.4303413427372
        },
        "amazon-nova-micro-v1.0": {
            "rating": 1240.5818709910704,
            "rating_q975": 1245.5725184784974,
            "rating_q025": 1235.5912235036435
        },
        "jamba-1.5-mini": {
            "rating": 1237.6245096083312,
            "rating_q975": 1244.7570837339779,
            "rating_q025": 1230.4919354826845
        },
        "ministral-8b-2410": {
            "rating": 1235.762353292348,
            "rating_q975": 1244.7587204999727,
            "rating_q025": 1226.7659860847234
        },
        "qwen1.5-110b-chat": {
            "rating": 1233.3536881623852,
            "rating_q975": 1238.7680421020104,
            "rating_q025": 1227.93933422276
        },
        "gemini-pro-dev-api": {
            "rating": 1232.4182510535538,
            "rating_q975": 1239.6727197272585,
            "rating_q025": 1225.1637823798492
        },
        "qwen1.5-72b-chat": {
            "rating": 1232.41810239232,
            "rating_q975": 1237.593498928688,
            "rating_q025": 1227.242705855952
        },
        "reka-flash-21b-20240226-online": {
            "rating": 1232.3153928455836,
            "rating_q975": 1239.6359838649337,
            "rating_q025": 1224.9948018262335
        },
        "hunyuan-standard-256k": {
            "rating": 1232.0132229785668,
            "rating_q975": 1243.6795214482845,
            "rating_q025": 1220.346924508849
        },
        "mixtral-8x22b-instruct-v0.1": {
            "rating": 1228.8720323772302,
            "rating_q975": 1233.3002989902059,
            "rating_q025": 1224.4437657642545
        },
        "command-r": {
            "rating": 1227.0430793802902,
            "rating_q975": 1231.7158300634185,
            "rating_q025": 1222.370328697162
        },
        "reka-flash-21b-20240226": {
            "rating": 1225.5744640590888,
            "rating_q975": 1231.4325976223981,
            "rating_q025": 1219.7163304957794
        },
        "gpt-3.5-turbo-0125": {
            "rating": 1222.772191232561,
            "rating_q975": 1227.3609946404633,
            "rating_q025": 1218.1833878246587
        },
        "c4ai-aya-expanse-8b": {
            "rating": 1222.693212678773,
            "rating_q975": 1229.5481539624072,
            "rating_q025": 1215.838271395139
        },
        "mistral-medium": {
            "rating": 1222.4859106602448,
            "rating_q975": 1227.8797976174758,
            "rating_q025": 1217.0920237030139
        },
        "llama-3-8b-instruct": {
            "rating": 1222.1707208662458,
            "rating_q975": 1225.7544758352853,
            "rating_q025": 1218.5869658972063
        },
        "llama-3.1-tulu-3-8b": {
            "rating": 1221.3777098547016,
            "rating_q975": 1231.9460303714773,
            "rating_q025": 1210.809389337926
        },
        "gemini-pro": {
            "rating": 1219.5430421226433,
            "rating_q975": 1231.257917117254,
            "rating_q025": 1207.8281671280326
        },
        "yi-1.5-34b-chat": {
            "rating": 1212.621954301338,
            "rating_q975": 1217.543484432737,
            "rating_q025": 1207.7004241699392
        },
        "zephyr-orpo-141b-A35b-v0.1": {
            "rating": 1212.586647768832,
            "rating_q975": 1223.3032258309806,
            "rating_q025": 1201.8700697066836
        },
        "llama-3.1-8b-instruct": {
            "rating": 1210.358521285908,
            "rating_q975": 1214.328283559548,
            "rating_q025": 1206.3887590122679
        },
        "granite-3.1-8b-instruct": {
            "rating": 1209.5021222948453,
            "rating_q975": 1220.43658756601,
            "rating_q025": 1198.5676570236806
        },
        "qwen1.5-32b-chat": {
            "rating": 1204.2810256850453,
            "rating_q975": 1210.3019036344697,
            "rating_q025": 1198.2601477356209
        },
        "gpt-3.5-turbo-1106": {
            "rating": 1200.0270778329277,
            "rating_q975": 1208.7325619086519,
            "rating_q025": 1191.3215937572036
        },
        "phi-3-medium-4k-instruct": {
            "rating": 1197.609029250999,
            "rating_q975": 1202.6532516256307,
            "rating_q025": 1192.5648068763671
        },
        "gemma-2-2b-it": {
            "rating": 1196.9990021607125,
            "rating_q975": 1200.9434423353714,
            "rating_q025": 1193.0545619860536
        },
        "mixtral-8x7b-instruct-v0.1": {
            "rating": 1196.8812992253097,
            "rating_q975": 1201.0364830137362,
            "rating_q025": 1192.7261154368832
        },
        "dbrx-instruct-preview": {
            "rating": 1194.6816288300417,
            "rating_q975": 1200.6785738195517,
            "rating_q025": 1188.6846838405318
        },
        "internlm2_5-20b-chat": {
            "rating": 1191.7116044993375,
            "rating_q975": 1198.7958299311636,
            "rating_q025": 1184.6273790675114
        },
        "qwen1.5-14b-chat": {
            "rating": 1191.6607651664922,
            "rating_q975": 1198.6864668469882,
            "rating_q025": 1184.6350634859962
        },
        "wizardlm-70b": {
            "rating": 1183.8021698282087,
            "rating_q975": 1193.2077384796335,
            "rating_q025": 1174.3966011767839
        },
        "yi-34b-chat": {
            "rating": 1182.8631160294879,
            "rating_q975": 1189.6058803280434,
            "rating_q025": 1176.1203517309323
        },
        "deepseek-llm-67b-chat": {
            "rating": 1182.6498902177823,
            "rating_q975": 1194.1387820534296,
            "rating_q025": 1171.160998382135
        },
        "granite-3.0-8b-instruct": {
            "rating": 1182.6106094169618,
            "rating_q975": 1191.1933875827365,
            "rating_q025": 1174.027831251187
        },
        "openchat-3.5-0106": {
            "rating": 1181.4678262909213,
            "rating_q975": 1189.4110697753515,
            "rating_q025": 1173.524582806491
        },
        "openchat-3.5": {
            "rating": 1180.6283716775495,
            "rating_q975": 1190.2632916408672,
            "rating_q025": 1170.9934517142317
        },
        "granite-3.1-2b-instruct": {
            "rating": 1180.235552561846,
            "rating_q975": 1191.3019335359363,
            "rating_q025": 1169.1691715877555
        },
        "snowflake-arctic-instruct": {
            "rating": 1179.285433568926,
            "rating_q975": 1185.106351788772,
            "rating_q025": 1173.46451534908
        },
        "gemma-1.1-7b-it": {
            "rating": 1177.983943698763,
            "rating_q975": 1183.9519837948858,
            "rating_q025": 1172.01590360264
        },
        "tulu-2-dpo-70b": {
            "rating": 1177.877326363346,
            "rating_q975": 1187.642681337871,
            "rating_q025": 1168.1119713888208
        },
        "openhermes-2.5-mistral-7b": {
            "rating": 1174.6888338322524,
            "rating_q975": 1185.078438216466,
            "rating_q025": 1164.2992294480387
        },
        "vicuna-33b": {
            "rating": 1172.1039552876812,
            "rating_q975": 1178.2373425221717,
            "rating_q025": 1165.9705680531906
        },
        "starling-lm-7b-beta": {
            "rating": 1171.7958427388394,
            "rating_q975": 1179.1395701488318,
            "rating_q025": 1164.452115328847
        },
        "phi-3-small-8k-instruct": {
            "rating": 1171.137802080842,
            "rating_q975": 1176.9541570968963,
            "rating_q025": 1165.3214470647877
        },
        "llama-2-70b-chat": {
            "rating": 1170.3680211980077,
            "rating_q975": 1175.7877449901696,
            "rating_q025": 1164.9482974058458
        },
        "starling-lm-7b-alpha": {
            "rating": 1167.0113351674604,
            "rating_q975": 1175.0306199792535,
            "rating_q025": 1158.9920503556673
        },
        "llama-3.2-3b-instruct": {
            "rating": 1166.1813728899153,
            "rating_q975": 1173.7701260723957,
            "rating_q025": 1158.592619707435
        },
        "nous-hermes-2-mixtral-8x7b-dpo": {
            "rating": 1164.695695289852,
            "rating_q975": 1176.5808678186693,
            "rating_q025": 1152.8105227610347
        },
        "qwq-32b-preview": {
            "rating": 1159.3004172055398,
            "rating_q975": 1170.7661529950792,
            "rating_q025": 1147.8346814160004
        },
        "granite-3.0-2b-instruct": {
            "rating": 1155.8618383372964,
            "rating_q975": 1164.1579688704921,
            "rating_q025": 1147.5657078041006
        },
        "llama2-70b-steerlm-chat": {
            "rating": 1155.8133822951204,
            "rating_q975": 1168.4065276795543,
            "rating_q025": 1143.2202369106865
        },
        "solar-10.7b-instruct-v1.0": {
            "rating": 1152.544923447079,
            "rating_q975": 1165.7287467089457,
            "rating_q025": 1139.3611001852125
        },
        "dolphin-2.2.1-mistral-7b": {
            "rating": 1150.3211735696154,
            "rating_q975": 1165.7425361283665,
            "rating_q025": 1134.8998110108644
        },
        "mistral-7b-instruct-v0.2": {
            "rating": 1149.5531932208307,
            "rating_q975": 1156.1194317411312,
            "rating_q025": 1142.9869547005303
        },
        "mpt-30b-chat": {
            "rating": 1149.1853013724403,
            "rating_q975": 1161.374061234944,
            "rating_q025": 1136.9965415099366
        },
        "wizardlm-13b": {
            "rating": 1148.420959736989,
            "rating_q975": 1157.6424701335004,
            "rating_q025": 1139.1994493404777
        },
        "falcon-180b-chat": {
            "rating": 1145.5243184456651,
            "rating_q975": 1162.6236973209675,
            "rating_q025": 1128.4249395703628
        },
        "qwen1.5-7b-chat": {
            "rating": 1142.871101057193,
            "rating_q975": 1152.68748493786,
            "rating_q025": 1133.054717176526
        },
        "phi-3-mini-4k-instruct-june-2024": {
            "rating": 1142.418819292611,
            "rating_q975": 1148.755363262342,
            "rating_q025": 1136.0822753228802
        },
        "llama-2-13b-chat": {
            "rating": 1141.2983596415816,
            "rating_q975": 1147.9366660621017,
            "rating_q025": 1134.6600532210614
        },
        "vicuna-13b": {
            "rating": 1140.311291740457,
            "rating_q975": 1146.948848296757,
            "rating_q025": 1133.6737351841568
        },
        "qwen-14b-chat": {
            "rating": 1137.4690420236343,
            "rating_q975": 1148.3815848251643,
            "rating_q025": 1126.5564992221043
        },
        "codellama-34b-instruct": {
            "rating": 1135.556512773331,
            "rating_q975": 1144.3895459739624,
            "rating_q025": 1126.7234795726995
        },
        "palm-2": {
            "rating": 1134.7618646895626,
            "rating_q975": 1144.1073760309546,
            "rating_q025": 1125.4163533481706
        },
        "gemma-7b-it": {
            "rating": 1133.2296484540443,
            "rating_q975": 1142.6783044062618,
            "rating_q025": 1123.7809925018269
        },
        "zephyr-7b-beta": {
            "rating": 1130.5027702336251,
            "rating_q975": 1139.292066546501,
            "rating_q025": 1121.7134739207493
        },
        "phi-3-mini-128k-instruct": {
            "rating": 1130.0241908449932,
            "rating_q975": 1137.3204956448885,
            "rating_q025": 1122.7278860450979
        },
        "phi-3-mini-4k-instruct": {
            "rating": 1128.4360974791005,
            "rating_q975": 1134.6877684193805,
            "rating_q025": 1122.1844265388204
        },
        "zephyr-7b-alpha": {
            "rating": 1126.9100717947415,
            "rating_q975": 1142.5801056710714,
            "rating_q025": 1111.2400379184116
        },
        "guanaco-33b": {
            "rating": 1126.3266513639837,
            "rating_q975": 1138.4201680174933,
            "rating_q025": 1114.2331347104741
        },
        "stripedhyena-nous-7b": {
            "rating": 1119.495106142965,
            "rating_q975": 1130.4744566272861,
            "rating_q025": 1108.5157556586437
        },
        "smollm2-1.7b-instruct": {
            "rating": 1119.220309358463,
            "rating_q975": 1133.3972840190672,
            "rating_q025": 1105.0433346978589
        },
        "codellama-70b-instruct": {
            "rating": 1118.226379127621,
            "rating_q975": 1136.4107392324236,
            "rating_q025": 1100.0420190228183
        },
        "vicuna-7b": {
            "rating": 1113.3512739754854,
            "rating_q975": 1122.5002740858097,
            "rating_q025": 1104.202273865161
        },
        "llama-3.2-1b-instruct": {
            "rating": 1112.620348630774,
            "rating_q975": 1120.3628077084813,
            "rating_q025": 1104.8778895530668
        },
        "gemma-1.1-2b-it": {
            "rating": 1111.957296588987,
            "rating_q975": 1119.5855329459914,
            "rating_q025": 1104.3290602319826
        },
        "mistral-7b-instruct": {
            "rating": 1109.014157882079,
            "rating_q975": 1118.2624624886653,
            "rating_q025": 1099.7658532754926
        },
        "llama-2-7b-chat": {
            "rating": 1107.508518026967,
            "rating_q975": 1114.4937214087645,
            "rating_q025": 1100.5233146451696
        },
        "qwen1.5-4b-chat": {
            "rating": 1089.6665997739053,
            "rating_q975": 1098.958214171626,
            "rating_q025": 1080.3749853761847
        },
        "gemma-2b-it": {
            "rating": 1089.1059460203683,
            "rating_q975": 1100.6172252931742,
            "rating_q025": 1077.5946667475623
        },
        "olmo-7b-instruct": {
            "rating": 1073.6204772781498,
            "rating_q975": 1084.775987148702,
            "rating_q025": 1062.4649674075977
        },
        "koala-13b": {
            "rating": 1068.4504744473466,
            "rating_q975": 1078.376584060342,
            "rating_q025": 1058.524364834351
        },
        "alpaca-13b": {
            "rating": 1063.8731709692338,
            "rating_q975": 1075.3661301444201,
            "rating_q025": 1052.3802117940475
        },
        "gpt4all-13b-snoozy": {
            "rating": 1062.871182288607,
            "rating_q975": 1078.094217647515,
            "rating_q025": 1047.6481469296991
        },
        "mpt-7b-chat": {
            "rating": 1059.4335655784396,
            "rating_q975": 1071.4215609635532,
            "rating_q025": 1047.445570193326
        },
        "chatglm3-6b": {
            "rating": 1055.5796680849926,
            "rating_q975": 1067.2120091342385,
            "rating_q025": 1043.9473270357466
        },
        "RWKV-4-Raven-14B": {
            "rating": 1039.6599047465947,
            "rating_q975": 1051.0954932763125,
            "rating_q025": 1028.224316216877
        },
        "chatglm2-6b": {
            "rating": 1023.8459840969572,
            "rating_q975": 1037.4117175563076,
            "rating_q025": 1010.2802506376067
        },
        "oasst-pythia-12b": {
            "rating": 1019.8765050160791,
            "rating_q975": 1030.8134870040192,
            "rating_q025": 1008.939523028139
        },
        "chatglm-6b": {
            "rating": 993.8864920264267,
            "rating_q975": 1006.4897599029697,
            "rating_q025": 981.2832241498837
        },
        "fastchat-t5-3b": {
            "rating": 989.0254152688597,
            "rating_q975": 1001.4180280699004,
            "rating_q025": 976.6328024678189
        },
        "dolly-v2-12b": {
            "rating": 976.4607670167356,
            "rating_q975": 990.0837350851638,
            "rating_q025": 962.8377989483075
        },
        "llama-13b": {
            "rating": 967.2874452434427,
            "rating_q975": 983.1887508087179,
            "rating_q025": 951.3861396781674
        },
        "stablelm-tuned-alpha-7b": {
            "rating": 950.5370449107235,
            "rating_q975": 963.3813732771017,
            "rating_q025": 937.6927165443452
        }
    },
    "german": {
        "gpt-4.5-preview-2025-02-27": {
            "rating": 1468.4710907951965,
            "rating_q975": 1500.650459797472,
            "rating_q025": 1436.291721792921
        },
        "gemini-2.5-pro": {
            "rating": 1462.5605781372326,
            "rating_q975": 1480.4062739848105,
            "rating_q025": 1444.7148822896547
        },
        "claude-sonnet-4-5-20250929-thinking-32k": {
            "rating": 1453.55138616629,
            "rating_q975": 1492.9509536706869,
            "rating_q025": 1414.1518186618932
        },
        "claude-opus-4-1-20250805-thinking-16k": {
            "rating": 1452.764789169022,
            "rating_q975": 1477.446343137736,
            "rating_q025": 1428.0832352003079
        },
        "gpt-5-high": {
            "rating": 1444.7333082339765,
            "rating_q975": 1469.8531827162258,
            "rating_q025": 1419.6134337517271
        },
        "o3-2025-04-16": {
            "rating": 1437.1565210308625,
            "rating_q975": 1454.3809375512856,
            "rating_q025": 1419.9321045104393
        },
        "claude-opus-4-20250514-thinking-16k": {
            "rating": 1434.2304591913537,
            "rating_q975": 1454.7734623637884,
            "rating_q025": 1413.687456018919
        },
        "qwen3-max-preview": {
            "rating": 1432.1411565352166,
            "rating_q975": 1459.7821962532685,
            "rating_q025": 1404.5001168171648
        },
        "kimi-k2-0905-preview": {
            "rating": 1429.9132748900572,
            "rating_q975": 1468.4187091775912,
            "rating_q025": 1391.4078406025233
        },
        "glm-4.6": {
            "rating": 1428.403677973791,
            "rating_q975": 1470.6725747006599,
            "rating_q025": 1386.134781246922
        },
        "claude-opus-4-1-20250805": {
            "rating": 1425.4401529526199,
            "rating_q975": 1447.2321491790594,
            "rating_q025": 1403.6481567261803
        },
        "claude-opus-4-20250514": {
            "rating": 1424.14985082919,
            "rating_q975": 1442.0510617100047,
            "rating_q025": 1406.2486399483753
        },
        "chatgpt-4o-latest-20250326": {
            "rating": 1423.533151904526,
            "rating_q975": 1442.645542570479,
            "rating_q025": 1404.420761238573
        },
        "deepseek-v3.2-exp-thinking": {
            "rating": 1420.8494861755582,
            "rating_q975": 1465.9385407825707,
            "rating_q025": 1375.7604315685458
        },
        "gpt-5-chat": {
            "rating": 1420.6546013669245,
            "rating_q975": 1446.613232333197,
            "rating_q025": 1394.695970400652
        },
        "qwen3-max-2025-09-23": {
            "rating": 1419.8678272260822,
            "rating_q975": 1461.3902752341753,
            "rating_q025": 1378.3453792179891
        },
        "grok-4-0709": {
            "rating": 1415.2250388429825,
            "rating_q975": 1437.9539773496717,
            "rating_q025": 1392.4961003362932
        },
        "qwen3-235b-a22b-instruct-2507": {
            "rating": 1413.4757333385517,
            "rating_q975": 1436.4306104817365,
            "rating_q025": 1390.5208561953668
        },
        "qwen3-vl-235b-a22b-thinking": {
            "rating": 1410.6204144083952,
            "rating_q975": 1456.7732145273592,
            "rating_q025": 1364.4676142894311
        },
        "kimi-k2-0711-preview": {
            "rating": 1410.3789423911026,
            "rating_q975": 1434.14337136893,
            "rating_q025": 1386.614513413275
        },
        "gemini-2.5-flash": {
            "rating": 1403.7092412157567,
            "rating_q975": 1420.3681438113765,
            "rating_q025": 1387.050338620137
        },
        "gemini-2.5-flash-preview-09-2025": {
            "rating": 1402.8946511423633,
            "rating_q975": 1440.860981458405,
            "rating_q025": 1364.9283208263216
        },
        "grok-3-preview-02-24": {
            "rating": 1402.5161458679431,
            "rating_q975": 1424.1847992823327,
            "rating_q025": 1380.8474924535535
        },
        "deepseek-v3.1": {
            "rating": 1398.7686472612943,
            "rating_q975": 1429.9975082918518,
            "rating_q025": 1367.5397862307368
        },
        "gpt-4.1-2025-04-14": {
            "rating": 1398.6640277721729,
            "rating_q975": 1416.5536653556571,
            "rating_q025": 1380.7743901886886
        },
        "claude-sonnet-4-20250514": {
            "rating": 1390.1308512011858,
            "rating_q975": 1409.5927526160035,
            "rating_q025": 1370.668949786368
        },
        "deepseek-r1": {
            "rating": 1389.2799652599426,
            "rating_q975": 1417.1429638394827,
            "rating_q025": 1361.4169666804025
        },
        "deepseek-v3.1-thinking": {
            "rating": 1387.6978531522395,
            "rating_q975": 1420.8747211178452,
            "rating_q025": 1354.5209851866339
        },
        "gpt-5-mini-high": {
            "rating": 1387.6346672456712,
            "rating_q975": 1415.1854228718078,
            "rating_q025": 1360.0839116195345
        },
        "deepseek-v3-0324": {
            "rating": 1386.2901699067602,
            "rating_q975": 1404.8515471825806,
            "rating_q025": 1367.7287926309398
        },
        "mistral-medium-2505": {
            "rating": 1385.9970471375304,
            "rating_q975": 1405.212739547288,
            "rating_q025": 1366.7813547277729
        },
        "qwen3-235b-a22b-thinking-2507": {
            "rating": 1385.1423523423687,
            "rating_q975": 1425.9300919076222,
            "rating_q025": 1344.354612777115
        },
        "mai-1-preview": {
            "rating": 1384.4877459078007,
            "rating_q975": 1414.777326578267,
            "rating_q025": 1354.1981652373343
        },
        "gpt-4.1-mini-2025-04-14": {
            "rating": 1380.3938433132193,
            "rating_q975": 1399.6096829829191,
            "rating_q025": 1361.1780036435196
        },
        "qwen3-vl-235b-a22b-instruct": {
            "rating": 1379.9397664965604,
            "rating_q975": 1422.2673650916106,
            "rating_q025": 1337.6121679015102
        },
        "qwen3-next-80b-a3b-instruct": {
            "rating": 1379.5744642123857,
            "rating_q975": 1409.7403374629523,
            "rating_q025": 1349.408590961819
        },
        "longcat-flash-chat": {
            "rating": 1379.142139014234,
            "rating_q975": 1416.2852294425213,
            "rating_q025": 1341.9990485859469
        },
        "mistral-medium-2508": {
            "rating": 1378.1547231246807,
            "rating_q975": 1402.8919913022992,
            "rating_q025": 1353.4174549470622
        },
        "claude-3-7-sonnet-20250219-thinking-32k": {
            "rating": 1377.9585687126867,
            "rating_q975": 1397.4975395492577,
            "rating_q025": 1358.4195978761156
        },
        "claude-sonnet-4-20250514-thinking-32k": {
            "rating": 1377.5754359413374,
            "rating_q975": 1398.9314703275738,
            "rating_q025": 1356.219401555101
        },
        "qwen3-235b-a22b-no-thinking": {
            "rating": 1376.6623665039808,
            "rating_q975": 1396.0656185332318,
            "rating_q025": 1357.2591144747298
        },
        "deepseek-r1-0528": {
            "rating": 1375.3485043209023,
            "rating_q975": 1401.2228431668602,
            "rating_q025": 1349.4741654749444
        },
        "qwen3-235b-a22b": {
            "rating": 1374.6224975048196,
            "rating_q975": 1396.6654620527888,
            "rating_q025": 1352.5795329568505
        },
        "claude-3-5-sonnet-20241022": {
            "rating": 1372.9691149927314,
            "rating_q975": 1386.0653529779834,
            "rating_q025": 1359.8728770074795
        },
        "gemini-2.5-flash-lite-preview-06-17-thinking": {
            "rating": 1371.7325595726375,
            "rating_q975": 1393.3025455459212,
            "rating_q025": 1350.1625735993537
        },
        "gemma-3-12b-it": {
            "rating": 1370.8402582004944,
            "rating_q975": 1413.51595462085,
            "rating_q025": 1328.164561780139
        },
        "o4-mini-2025-04-16": {
            "rating": 1370.052208125974,
            "rating_q975": 1388.5073311950255,
            "rating_q025": 1351.5970850569224
        },
        "o1-2024-12-17": {
            "rating": 1367.415048468374,
            "rating_q975": 1390.8023984012714,
            "rating_q025": 1344.0276985354765
        },
        "gemini-2.5-flash-lite-preview-09-2025-no-thinking": {
            "rating": 1365.0245439258308,
            "rating_q975": 1403.7637108159256,
            "rating_q025": 1326.285377035736
        },
        "gemma-3-27b-it": {
            "rating": 1364.566366363753,
            "rating_q975": 1382.5271535581546,
            "rating_q025": 1346.6055791693516
        },
        "claude-haiku-4-5-20251001": {
            "rating": 1363.5255303514195,
            "rating_q975": 1407.4138249054668,
            "rating_q025": 1319.6372357973723
        },
        "glm-4.5": {
            "rating": 1362.6506404601168,
            "rating_q975": 1389.2392222292465,
            "rating_q025": 1336.0620586909872
        },
        "qwen3-next-80b-a3b-thinking": {
            "rating": 1358.7391749061069,
            "rating_q975": 1392.7436878663293,
            "rating_q025": 1324.7346619458845
        },
        "command-a-03-2025": {
            "rating": 1351.3506351438793,
            "rating_q975": 1368.685270875368,
            "rating_q025": 1334.0159994123908
        },
        "mistral-small-2506": {
            "rating": 1350.5906160704942,
            "rating_q975": 1380.1436176709735,
            "rating_q025": 1321.037614470015
        },
        "qwen3-30b-a3b-instruct-2507": {
            "rating": 1349.126266874445,
            "rating_q975": 1376.4366666587027,
            "rating_q025": 1321.8158670901873
        },
        "o1-preview": {
            "rating": 1348.238280718485,
            "rating_q975": 1368.8184038007369,
            "rating_q025": 1327.658157636233
        },
        "qwen3-coder-480b-a35b-instruct": {
            "rating": 1348.047831408831,
            "rating_q975": 1376.3067947046013,
            "rating_q025": 1319.7888681130605
        },
        "minimax-m1": {
            "rating": 1347.9345731379342,
            "rating_q975": 1368.981963800005,
            "rating_q025": 1326.8871824758635
        },
        "gpt-5-nano-high": {
            "rating": 1347.2613680109976,
            "rating_q975": 1388.5708470558623,
            "rating_q025": 1305.9518889661329
        },
        "glm-4-plus-0111": {
            "rating": 1345.5195844850382,
            "rating_q975": 1383.6224826245307,
            "rating_q025": 1307.4166863455457
        },
        "step-3": {
            "rating": 1344.043976587561,
            "rating_q975": 1391.1631565249088,
            "rating_q025": 1296.9247966502132
        },
        "deepseek-v3": {
            "rating": 1343.734212158323,
            "rating_q975": 1368.1813633233946,
            "rating_q025": 1319.2870609932515
        },
        "qwen2.5-max": {
            "rating": 1342.7623080356655,
            "rating_q975": 1363.6991981638564,
            "rating_q025": 1321.8254179074745
        },
        "glm-4.5-air": {
            "rating": 1338.4618199203135,
            "rating_q975": 1363.6491362552956,
            "rating_q025": 1313.2745035853313
        },
        "hunyuan-turbos-20250416": {
            "rating": 1334.244935455361,
            "rating_q975": 1366.6430716029852,
            "rating_q025": 1301.8467993077368
        },
        "grok-3-mini-high": {
            "rating": 1333.2084488004343,
            "rating_q975": 1362.382493364491,
            "rating_q025": 1304.0344042363777
        },
        "llama-4-maverick-17b-128e-instruct": {
            "rating": 1329.9861477100415,
            "rating_q975": 1349.449171551469,
            "rating_q025": 1310.523123868614
        },
        "claude-3-5-sonnet-20240620": {
            "rating": 1328.581403654563,
            "rating_q975": 1342.0783606149034,
            "rating_q025": 1315.0844466942226
        },
        "qwen3-32b": {
            "rating": 1323.6779344398296,
            "rating_q975": 1364.869681372751,
            "rating_q025": 1282.4861875069082
        },
        "gemini-2.0-flash-lite-preview-02-05": {
            "rating": 1323.5367470213216,
            "rating_q975": 1345.4286029798168,
            "rating_q025": 1301.6448910628264
        },
        "gpt-4o-2024-05-13": {
            "rating": 1323.1243653386034,
            "rating_q975": 1334.8805798322499,
            "rating_q025": 1311.368150844957
        },
        "o3-mini": {
            "rating": 1322.6697432644146,
            "rating_q975": 1339.3529416861516,
            "rating_q025": 1305.9865448426776
        },
        "gemini-advanced-0514": {
            "rating": 1320.8515427525517,
            "rating_q975": 1337.0272062327938,
            "rating_q025": 1304.6758792723097
        },
        "o3-mini-high": {
            "rating": 1320.6244364177269,
            "rating_q975": 1349.991641555047,
            "rating_q025": 1291.2572312804068
        },
        "gpt-oss-120b": {
            "rating": 1316.2556038497555,
            "rating_q975": 1342.8863240921467,
            "rating_q025": 1289.6248836073644
        },
        "grok-3-mini-beta": {
            "rating": 1315.2386700441425,
            "rating_q975": 1340.20841906389,
            "rating_q025": 1290.268921024395
        },
        "gemma-3n-e4b-it": {
            "rating": 1314.8988717346417,
            "rating_q975": 1337.3774662027733,
            "rating_q025": 1292.42027726651
        },
        "claude-3-opus-20240229": {
            "rating": 1313.7437657229916,
            "rating_q975": 1324.735244554999,
            "rating_q025": 1302.7522868909841
        },
        "gpt-4.1-nano-2025-04-14": {
            "rating": 1313.330067390653,
            "rating_q975": 1350.635580722148,
            "rating_q025": 1276.0245540591582
        },
        "gemini-1.5-pro-002": {
            "rating": 1309.8962294789471,
            "rating_q975": 1325.7703475009928,
            "rating_q025": 1294.0221114569015
        },
        "gpt-4o-2024-08-06": {
            "rating": 1307.5042590146993,
            "rating_q975": 1323.8028087371333,
            "rating_q025": 1291.2057092922653
        },
        "claude-3-5-haiku-20241022": {
            "rating": 1307.2104853665387,
            "rating_q975": 1322.518455195562,
            "rating_q025": 1291.9025155375155
        },
        "gpt-4-turbo-2024-04-09": {
            "rating": 1306.546099709899,
            "rating_q975": 1319.1480127577458,
            "rating_q025": 1293.944186662052
        },
        "grok-2-2024-08-13": {
            "rating": 1306.2318579839425,
            "rating_q975": 1321.0155807418246,
            "rating_q025": 1291.4481352260605
        },
        "llama-4-scout-17b-16e-instruct": {
            "rating": 1301.9886751928502,
            "rating_q975": 1324.151003124174,
            "rating_q025": 1279.8263472615265
        },
        "llama-3.1-405b-instruct-bf16": {
            "rating": 1300.0077784687924,
            "rating_q975": 1318.8418221136615,
            "rating_q025": 1281.1737348239233
        },
        "llama-3.1-405b-instruct-fp8": {
            "rating": 1297.8635156067226,
            "rating_q975": 1312.7346203619586,
            "rating_q025": 1282.9924108514865
        },
        "glm-4-plus": {
            "rating": 1297.0473264573907,
            "rating_q975": 1319.1492716504333,
            "rating_q025": 1274.945381264348
        },
        "mistral-large-2407": {
            "rating": 1295.3936634399386,
            "rating_q975": 1311.8758290573794,
            "rating_q025": 1278.9114978224977
        },
        "qwen3-30b-a3b": {
            "rating": 1294.7488278853325,
            "rating_q975": 1316.854183441311,
            "rating_q025": 1272.643472329354
        },
        "gpt-4-1106-preview": {
            "rating": 1294.636579415293,
            "rating_q975": 1308.5369161102328,
            "rating_q025": 1280.7362427203532
        },
        "gemini-1.5-pro-001": {
            "rating": 1294.5187399298877,
            "rating_q975": 1307.9643512878297,
            "rating_q025": 1281.0731285719457
        },
        "qwq-32b": {
            "rating": 1293.8105822886932,
            "rating_q975": 1316.783717050958,
            "rating_q025": 1270.8374475264284
        },
        "o1-mini": {
            "rating": 1293.7215819525977,
            "rating_q975": 1310.7408743180738,
            "rating_q025": 1276.7022895871216
        },
        "magistral-medium-2506": {
            "rating": 1292.7175149902996,
            "rating_q975": 1326.0770542779692,
            "rating_q025": 1259.35797570263
        },
        "gpt-4o-mini-2024-07-18": {
            "rating": 1291.9428027277845,
            "rating_q975": 1306.082083855811,
            "rating_q025": 1277.803521599758
        },
        "gpt-4-0125-preview": {
            "rating": 1289.6362957695928,
            "rating_q975": 1303.1608514160482,
            "rating_q025": 1276.1117401231375
        },
        "llama-3.3-70b-instruct": {
            "rating": 1287.8541080530679,
            "rating_q975": 1304.7008968627022,
            "rating_q025": 1271.0073192434336
        },
        "mistral-small-3.1-24b-instruct-2503": {
            "rating": 1286.8890614822021,
            "rating_q975": 1308.8360736212576,
            "rating_q025": 1264.9420493431467
        },
        "grok-2-mini-2024-08-13": {
            "rating": 1286.1912524154566,
            "rating_q975": 1302.3391769437835,
            "rating_q025": 1270.0433278871296
        },
        "yi-lightning": {
            "rating": 1285.6414174040856,
            "rating_q975": 1306.4497174730554,
            "rating_q025": 1264.8331173351157
        },
        "gemma-3-4b-it": {
            "rating": 1283.9420061459227,
            "rating_q975": 1325.4861364191868,
            "rating_q025": 1242.3978758726587
        },
        "step-1o-turbo-202506": {
            "rating": 1282.4504159530297,
            "rating_q975": 1314.3541128283769,
            "rating_q025": 1250.5467190776826
        },
        "mistral-large-2411": {
            "rating": 1280.915264061218,
            "rating_q975": 1303.0461088243244,
            "rating_q025": 1258.7844192981117
        },
        "deepseek-v2.5-1210": {
            "rating": 1280.522504313027,
            "rating_q975": 1327.6828266539699,
            "rating_q025": 1233.362181972084
        },
        "athene-70b-0725": {
            "rating": 1279.3062579887583,
            "rating_q975": 1302.3170738034837,
            "rating_q025": 1256.2954421740328
        },
        "qwen-max-0919": {
            "rating": 1276.9034191951473,
            "rating_q975": 1302.0700659410825,
            "rating_q025": 1251.7367724492121
        },
        "gemini-1.5-flash-002": {
            "rating": 1276.813017636365,
            "rating_q975": 1297.6942679098674,
            "rating_q025": 1255.9317673628625
        },
        "reka-core-20240904": {
            "rating": 1276.7779935472606,
            "rating_q975": 1317.7662293521944,
            "rating_q025": 1235.7897577423269
        },
        "athene-v2-chat": {
            "rating": 1271.7550203700266,
            "rating_q975": 1293.7837352686404,
            "rating_q025": 1249.7263054714128
        },
        "gpt-4-0314": {
            "rating": 1271.6191017057886,
            "rating_q975": 1289.5539172161657,
            "rating_q025": 1253.6842861954115
        },
        "amazon-nova-pro-v1.0": {
            "rating": 1269.130377740907,
            "rating_q975": 1291.9440617786304,
            "rating_q025": 1246.3166937031838
        },
        "claude-3-sonnet-20240229": {
            "rating": 1268.918362798841,
            "rating_q975": 1282.5654799606482,
            "rating_q025": 1255.2712456370336
        },
        "gpt-oss-20b": {
            "rating": 1265.2516489539848,
            "rating_q975": 1306.2785484472506,
            "rating_q025": 1224.224749460719
        },
        "gemma-2-9b-it-simpo": {
            "rating": 1264.5895992746669,
            "rating_q975": 1295.424878827888,
            "rating_q025": 1233.7543197214457
        },
        "gemma-2-27b-it": {
            "rating": 1262.2924731936384,
            "rating_q975": 1275.42072135854,
            "rating_q025": 1249.1642250287368
        },
        "gemini-1.5-flash-001": {
            "rating": 1259.5830389197777,
            "rating_q975": 1273.5760294456884,
            "rating_q025": 1245.590048393867
        },
        "qwen2.5-72b-instruct": {
            "rating": 1258.5219443340102,
            "rating_q975": 1276.834362592893,
            "rating_q025": 1240.2095260751273
        },
        "command-r-plus-08-2024": {
            "rating": 1257.177468146889,
            "rating_q975": 1290.2164613255004,
            "rating_q025": 1224.1384749682775
        },
        "deepseek-v2.5": {
            "rating": 1253.2643960946348,
            "rating_q975": 1276.9509527267685,
            "rating_q025": 1229.577839462501
        },
        "amazon-nova-lite-v1.0": {
            "rating": 1252.750971443859,
            "rating_q975": 1278.7077904887844,
            "rating_q025": 1226.7941523989336
        },
        "llama-3.1-70b-instruct": {
            "rating": 1251.897444086805,
            "rating_q975": 1267.7163112299418,
            "rating_q025": 1236.0785769436684
        },
        "phi-4": {
            "rating": 1250.6564039648965,
            "rating_q975": 1276.0966930517848,
            "rating_q025": 1225.2161148780083
        },
        "mistral-small-24b-instruct-2501": {
            "rating": 1250.24575794326,
            "rating_q975": 1283.2237445667802,
            "rating_q025": 1217.26777131974
        },
        "command-r-plus": {
            "rating": 1248.040655902072,
            "rating_q975": 1261.8882355684948,
            "rating_q025": 1234.1930762356494
        },
        "gpt-4-0613": {
            "rating": 1247.760694273249,
            "rating_q975": 1262.4890391867368,
            "rating_q025": 1233.0323493597614
        },
        "jamba-1.5-large": {
            "rating": 1243.864535563588,
            "rating_q975": 1279.8876936265037,
            "rating_q025": 1207.8413775006725
        },
        "qwen2.5-plus-1127": {
            "rating": 1242.194716109653,
            "rating_q975": 1277.085001867238,
            "rating_q025": 1207.304430352068
        },
        "mistral-large-2402": {
            "rating": 1241.9639446091676,
            "rating_q975": 1257.8078584993145,
            "rating_q025": 1226.1200307190206
        },
        "nemotron-4-340b-instruct": {
            "rating": 1241.33959906187,
            "rating_q975": 1263.6656299467807,
            "rating_q025": 1219.0135681769596
        },
        "claude-3-haiku-20240307": {
            "rating": 1241.0722228889445,
            "rating_q975": 1253.6112114214181,
            "rating_q025": 1228.5332343564708
        },
        "command-r-08-2024": {
            "rating": 1240.038530224533,
            "rating_q975": 1272.8887755978262,
            "rating_q025": 1207.1882848512396
        },
        "gemma-2-9b-it": {
            "rating": 1238.0152044147142,
            "rating_q975": 1252.9368471742314,
            "rating_q025": 1223.093561655197
        },
        "c4ai-aya-expanse-32b": {
            "rating": 1232.4361499455138,
            "rating_q975": 1255.5781505757516,
            "rating_q025": 1209.294149315276
        },
        "deepseek-coder-v2": {
            "rating": 1228.7180520377585,
            "rating_q975": 1254.1560859983315,
            "rating_q025": 1203.2800180771856
        },
        "gemini-1.5-flash-8b-001": {
            "rating": 1224.3308653433417,
            "rating_q975": 1244.5701413711502,
            "rating_q025": 1204.0915893155332
        },
        "reka-flash-20240904": {
            "rating": 1223.5608590225684,
            "rating_q975": 1262.532535493755,
            "rating_q025": 1184.5891825513818
        },
        "llama-3-70b-instruct": {
            "rating": 1222.340974416321,
            "rating_q975": 1234.2235771162555,
            "rating_q025": 1210.4583717163864
        },
        "glm-4-0520": {
            "rating": 1221.6869678813014,
            "rating_q975": 1250.8685061656802,
            "rating_q025": 1192.5054295969226
        },
        "amazon-nova-micro-v1.0": {
            "rating": 1220.6332762160418,
            "rating_q975": 1247.5096294950222,
            "rating_q025": 1193.7569229370615
        },
        "qwen2-72b-instruct": {
            "rating": 1217.100008072728,
            "rating_q975": 1233.7302193515027,
            "rating_q025": 1200.4697967939535
        },
        "c4ai-aya-expanse-8b": {
            "rating": 1215.778631175179,
            "rating_q975": 1252.2258528044345,
            "rating_q025": 1179.3314095459236
        },
        "reka-flash-21b-20240226-online": {
            "rating": 1212.7212669296002,
            "rating_q975": 1238.8829473810738,
            "rating_q025": 1186.5595864781267
        },
        "reka-flash-21b-20240226": {
            "rating": 1212.6887217994472,
            "rating_q975": 1233.5383162462945,
            "rating_q025": 1191.8391273526
        },
        "mistral-medium": {
            "rating": 1212.3624678263639,
            "rating_q975": 1233.8761751293061,
            "rating_q025": 1190.8487605234216
        },
        "mixtral-8x22b-instruct-v0.1": {
            "rating": 1211.8808489391934,
            "rating_q975": 1227.9112878596336,
            "rating_q025": 1195.850410018753
        },
        "jamba-1.5-mini": {
            "rating": 1208.1675810884956,
            "rating_q975": 1245.3549277242923,
            "rating_q025": 1170.9802344526988
        },
        "gemini-pro-dev-api": {
            "rating": 1206.5998506549038,
            "rating_q975": 1235.5172333134587,
            "rating_q025": 1177.6824679963488
        },
        "gpt-3.5-turbo-0125": {
            "rating": 1191.2851647828152,
            "rating_q975": 1207.14206189833,
            "rating_q025": 1175.4282676673004
        },
        "command-r": {
            "rating": 1187.7356718558804,
            "rating_q975": 1205.094071368079,
            "rating_q025": 1170.3772723436816
        },
        "qwen1.5-110b-chat": {
            "rating": 1184.8970394689027,
            "rating_q975": 1204.7427218909058,
            "rating_q025": 1165.0513570468995
        },
        "mixtral-8x7b-instruct-v0.1": {
            "rating": 1181.4547408113851,
            "rating_q975": 1196.49104567469,
            "rating_q025": 1166.4184359480803
        },
        "gpt-3.5-turbo-1106": {
            "rating": 1169.1807915752765,
            "rating_q975": 1203.191541878195,
            "rating_q025": 1135.170041272358
        },
        "phi-3-medium-4k-instruct": {
            "rating": 1166.3055398813317,
            "rating_q975": 1186.4811042952915,
            "rating_q025": 1146.1299754673719
        },
        "llama-3.1-8b-instruct": {
            "rating": 1162.3751347414345,
            "rating_q975": 1179.1476012070514,
            "rating_q025": 1145.6026682758177
        },
        "llama-3-8b-instruct": {
            "rating": 1156.6590341880988,
            "rating_q975": 1169.6959635148023,
            "rating_q025": 1143.6221048613952
        },
        "yi-1.5-34b-chat": {
            "rating": 1151.9279529504302,
            "rating_q975": 1171.7314900970935,
            "rating_q025": 1132.1244158037669
        },
        "qwen1.5-72b-chat": {
            "rating": 1150.8222713341047,
            "rating_q975": 1169.6777757088907,
            "rating_q025": 1131.9667669593186
        },
        "gemma-2-2b-it": {
            "rating": 1150.0146532331125,
            "rating_q975": 1168.0639759113105,
            "rating_q025": 1131.9653305549145
        },
        "gemma-1.1-7b-it": {
            "rating": 1147.7251920072758,
            "rating_q975": 1168.7376807447865,
            "rating_q025": 1126.7127032697651
        },
        "wizardlm-70b": {
            "rating": 1145.0905727394136,
            "rating_q975": 1187.9711824327806,
            "rating_q025": 1102.2099630460466
        },
        "snowflake-arctic-instruct": {
            "rating": 1141.7523331923503,
            "rating_q975": 1163.5210590034812,
            "rating_q025": 1119.9836073812194
        },
        "phi-3-small-8k-instruct": {
            "rating": 1141.6070518478477,
            "rating_q975": 1165.0835107094642,
            "rating_q025": 1118.1305929862312
        },
        "dbrx-instruct-preview": {
            "rating": 1134.3026944308212,
            "rating_q975": 1156.654143706729,
            "rating_q025": 1111.9512451549135
        },
        "openchat-3.5-0106": {
            "rating": 1131.8129079328473,
            "rating_q975": 1164.8816223373217,
            "rating_q025": 1098.744193528373
        },
        "vicuna-33b": {
            "rating": 1128.0493962504156,
            "rating_q975": 1156.788820311235,
            "rating_q025": 1099.3099721895962
        },
        "qwen1.5-32b-chat": {
            "rating": 1125.2615353330539,
            "rating_q975": 1146.9180804207351,
            "rating_q025": 1103.6049902453726
        },
        "starling-lm-7b-beta": {
            "rating": 1106.9529490265518,
            "rating_q975": 1137.222275426558,
            "rating_q025": 1076.6836226265455
        },
        "llama-3.2-3b-instruct": {
            "rating": 1106.3674430765377,
            "rating_q975": 1146.9460183344124,
            "rating_q025": 1065.788867818663
        },
        "qwen1.5-14b-chat": {
            "rating": 1104.4719827088625,
            "rating_q975": 1129.6263142738856,
            "rating_q025": 1079.3176511438394
        },
        "phi-3-mini-4k-instruct": {
            "rating": 1103.73930827279,
            "rating_q975": 1126.9112897063226,
            "rating_q025": 1080.5673268392572
        },
        "phi-3-mini-4k-instruct-june-2024": {
            "rating": 1101.2749292399321,
            "rating_q975": 1132.905256888385,
            "rating_q025": 1069.6446015914792
        },
        "yi-34b-chat": {
            "rating": 1098.1818848060743,
            "rating_q975": 1129.090363799033,
            "rating_q025": 1067.2734058131157
        },
        "llama-2-70b-chat": {
            "rating": 1095.5239811702986,
            "rating_q975": 1116.761174575661,
            "rating_q025": 1074.2867877649362
        },
        "phi-3-mini-128k-instruct": {
            "rating": 1086.5589014354696,
            "rating_q975": 1110.3176465328052,
            "rating_q025": 1062.800156338134
        },
        "internlm2_5-20b-chat": {
            "rating": 1081.1428251925872,
            "rating_q975": 1118.487000968809,
            "rating_q025": 1043.7986494163654
        },
        "starling-lm-7b-alpha": {
            "rating": 1080.7200232701607,
            "rating_q975": 1121.8272448890684,
            "rating_q025": 1039.612801651253
        },
        "vicuna-13b": {
            "rating": 1073.9604751974964,
            "rating_q975": 1109.3387694444216,
            "rating_q025": 1038.5821809505712
        },
        "gemma-7b-it": {
            "rating": 1068.244947599538,
            "rating_q975": 1111.353616516108,
            "rating_q025": 1025.1362786829677
        },
        "llama-2-13b-chat": {
            "rating": 1064.4609792486456,
            "rating_q975": 1093.4896890187042,
            "rating_q025": 1035.432269478587
        },
        "llama-3.2-1b-instruct": {
            "rating": 1062.2759526835534,
            "rating_q975": 1101.8645246743458,
            "rating_q025": 1022.687380692761
        },
        "zephyr-7b-beta": {
            "rating": 1055.1102086631186,
            "rating_q975": 1101.9864347692153,
            "rating_q025": 1008.2339825570218
        },
        "mistral-7b-instruct-v0.2": {
            "rating": 1043.406627259959,
            "rating_q975": 1070.0304668558056,
            "rating_q025": 1016.7827876641121
        },
        "gemma-1.1-2b-it": {
            "rating": 1041.2233567022108,
            "rating_q975": 1075.3951441127506,
            "rating_q025": 1007.0515692916711
        },
        "llama-2-7b-chat": {
            "rating": 1034.255971066763,
            "rating_q975": 1068.0833021894593,
            "rating_q025": 1000.4286399440668
        },
        "mistral-7b-instruct": {
            "rating": 1017.2513624514988,
            "rating_q975": 1062.3352358015409,
            "rating_q025": 972.1674891014567
        },
        "qwen1.5-4b-chat": {
            "rating": 993.8777174332752,
            "rating_q975": 1032.8011331265643,
            "rating_q025": 954.954301739986
        }
    },
    "hard_6": {
        "claude-sonnet-4-5-20250929-thinking-32k": {
            "rating": 1482.2373802766842,
            "rating_q975": 1490.0839551965512,
            "rating_q025": 1474.3908053568173
        },
        "claude-opus-4-1-20250805-thinking-16k": {
            "rating": 1480.9735771618296,
            "rating_q975": 1487.1456502732221,
            "rating_q025": 1474.801504050437
        },
        "deepseek-v3.2-exp": {
            "rating": 1478.2143483573134,
            "rating_q975": 1515.051685994736,
            "rating_q025": 1441.3770107198907
        },
        "claude-opus-4-1-20250805": {
            "rating": 1468.260323834785,
            "rating_q975": 1473.997476463255,
            "rating_q025": 1462.5231712063148
        },
        "claude-sonnet-4-5-20250929": {
            "rating": 1465.2013706817256,
            "rating_q975": 1475.2720978045168,
            "rating_q025": 1455.1306435589345
        },
        "gemini-2.5-pro": {
            "rating": 1463.5592685688416,
            "rating_q975": 1468.7608129953144,
            "rating_q025": 1458.3577241423689
        },
        "qwen3-max-preview": {
            "rating": 1455.1034906772327,
            "rating_q975": 1461.4829044518908,
            "rating_q025": 1448.7240769025746
        },
        "claude-opus-4-20250514-thinking-16k": {
            "rating": 1451.4739634976595,
            "rating_q975": 1457.2099432143325,
            "rating_q025": 1445.7379837809865
        },
        "glm-4.6": {
            "rating": 1449.4292361250648,
            "rating_q975": 1457.8353627088616,
            "rating_q025": 1441.023109541268
        },
        "chatgpt-4o-latest-20250326": {
            "rating": 1448.176563103953,
            "rating_q975": 1453.4340307462803,
            "rating_q025": 1442.9190954616256
        },
        "gpt-5-high": {
            "rating": 1447.5803091359687,
            "rating_q975": 1453.9802855914293,
            "rating_q025": 1441.1803326805082
        },
        "gpt-5-chat": {
            "rating": 1445.1224103274901,
            "rating_q975": 1451.184743712981,
            "rating_q025": 1439.0600769419993
        },
        "qwen3-235b-a22b-instruct-2507": {
            "rating": 1444.677492949357,
            "rating_q975": 1450.4265813768598,
            "rating_q025": 1438.9284045218542
        },
        "qwen3-max-2025-09-23": {
            "rating": 1444.6128186489939,
            "rating_q975": 1453.1685853131112,
            "rating_q025": 1436.0570519848766
        },
        "deepseek-v3.2-exp-thinking": {
            "rating": 1440.3007208183928,
            "rating_q975": 1449.0256928173624,
            "rating_q025": 1431.5757488194233
        },
        "o3-2025-04-16": {
            "rating": 1439.9725319207105,
            "rating_q975": 1445.1213864834538,
            "rating_q025": 1434.8236773579672
        },
        "deepseek-v3.1-terminus-thinking": {
            "rating": 1439.66071451476,
            "rating_q975": 1454.0292265733497,
            "rating_q025": 1425.2922024561703
        },
        "qwen3-vl-235b-a22b-instruct": {
            "rating": 1437.124972191243,
            "rating_q975": 1446.1010935345878,
            "rating_q025": 1428.148850847898
        },
        "claude-haiku-4-5-20251001": {
            "rating": 1436.0813481403961,
            "rating_q975": 1444.370108752563,
            "rating_q025": 1427.7925875282292
        },
        "gpt-4.5-preview-2025-02-27": {
            "rating": 1435.259824282456,
            "rating_q975": 1445.2235689252727,
            "rating_q025": 1425.2960796396394
        },
        "deepseek-v3.1-thinking": {
            "rating": 1435.0794411472853,
            "rating_q975": 1443.807640083358,
            "rating_q025": 1426.3512422112126
        },
        "kimi-k2-0905-preview": {
            "rating": 1434.845855229589,
            "rating_q975": 1443.7062156207921,
            "rating_q025": 1425.9854948383859
        },
        "claude-opus-4-20250514": {
            "rating": 1431.1034790587946,
            "rating_q975": 1436.6507652999621,
            "rating_q025": 1425.556192817627
        },
        "deepseek-r1-0528": {
            "rating": 1430.5802905171265,
            "rating_q975": 1438.306462719937,
            "rating_q025": 1422.854118314316
        },
        "glm-4.5": {
            "rating": 1430.4486333431255,
            "rating_q975": 1436.9526201076505,
            "rating_q025": 1423.9446465786004
        },
        "deepseek-v3.1": {
            "rating": 1429.6102403891848,
            "rating_q975": 1437.5116557083074,
            "rating_q025": 1421.7088250700622
        },
        "mistral-medium-2508": {
            "rating": 1429.5472136155668,
            "rating_q975": 1435.6786563466244,
            "rating_q025": 1423.4157708845091
        },
        "grok-4-fast": {
            "rating": 1428.8176727465454,
            "rating_q975": 1439.4296951489075,
            "rating_q025": 1418.2056503441834
        },
        "kimi-k2-0711-preview": {
            "rating": 1428.1227820072068,
            "rating_q975": 1434.549090879939,
            "rating_q025": 1421.6964731344744
        },
        "claude-sonnet-4-20250514-thinking-32k": {
            "rating": 1428.052467485503,
            "rating_q975": 1433.7877152153947,
            "rating_q025": 1422.3172197556114
        },
        "gpt-4.1-2025-04-14": {
            "rating": 1428.0173118896828,
            "rating_q975": 1433.2850653214236,
            "rating_q025": 1422.749558457942
        },
        "longcat-flash-chat": {
            "rating": 1423.32904725872,
            "rating_q975": 1431.6648109376297,
            "rating_q025": 1414.9932835798104
        },
        "grok-3-preview-02-24": {
            "rating": 1421.4589227276156,
            "rating_q975": 1427.874131484436,
            "rating_q025": 1415.0437139707951
        },
        "deepseek-v3.1-terminus": {
            "rating": 1421.1874257648137,
            "rating_q975": 1434.4716538502287,
            "rating_q025": 1407.9031976793988
        },
        "qwen3-next-80b-a3b-instruct": {
            "rating": 1419.156881979777,
            "rating_q975": 1425.9023598996941,
            "rating_q025": 1412.4114040598597
        },
        "gemini-2.5-flash-preview-09-2025": {
            "rating": 1417.5843402388598,
            "rating_q975": 1425.0236954056677,
            "rating_q025": 1410.144985072052
        },
        "grok-4-0709": {
            "rating": 1417.1630327002083,
            "rating_q975": 1422.7606680915094,
            "rating_q025": 1411.5653973089072
        },
        "qwen3-235b-a22b-thinking-2507": {
            "rating": 1416.2342195467943,
            "rating_q975": 1425.734383324547,
            "rating_q025": 1406.7340557690416
        },
        "qwen3-235b-a22b-no-thinking": {
            "rating": 1415.1911273061717,
            "rating_q975": 1420.9691254589416,
            "rating_q025": 1409.4131291534018
        },
        "qwen3-vl-235b-a22b-thinking": {
            "rating": 1414.6516083724593,
            "rating_q975": 1423.9289208302646,
            "rating_q025": 1405.374295914654
        },
        "deepseek-r1": {
            "rating": 1413.9674050251697,
            "rating_q975": 1422.8862806912252,
            "rating_q025": 1405.0485293591141
        },
        "o1-2024-12-17": {
            "rating": 1413.8667745481935,
            "rating_q975": 1421.434777421544,
            "rating_q025": 1406.298771674843
        },
        "claude-sonnet-4-20250514": {
            "rating": 1413.5545804474853,
            "rating_q975": 1419.2002837991822,
            "rating_q025": 1407.9088770957883
        },
        "claude-3-7-sonnet-20250219-thinking-32k": {
            "rating": 1412.9901192015416,
            "rating_q975": 1418.9186147523121,
            "rating_q025": 1407.061623650771
        },
        "gemini-2.5-flash": {
            "rating": 1412.1807856043993,
            "rating_q975": 1417.3242975206765,
            "rating_q025": 1407.037273688122
        },
        "qwen3-coder-480b-a35b-instruct": {
            "rating": 1408.94088573832,
            "rating_q975": 1415.5565433964182,
            "rating_q025": 1402.325228080222
        },
        "qwen3-30b-a3b-instruct-2507": {
            "rating": 1404.3081233683376,
            "rating_q975": 1410.7854691490809,
            "rating_q025": 1397.8307775875944
        },
        "gpt-5-mini-high": {
            "rating": 1403.8561122334017,
            "rating_q975": 1410.5472119566807,
            "rating_q025": 1397.1650125101228
        },
        "o4-mini-2025-04-16": {
            "rating": 1402.9028289836583,
            "rating_q975": 1408.2039570415695,
            "rating_q025": 1397.601700925747
        },
        "deepseek-v3-0324": {
            "rating": 1402.7355205600986,
            "rating_q975": 1408.0603218303565,
            "rating_q025": 1397.4107192898407
        },
        "mai-1-preview": {
            "rating": 1400.923628383434,
            "rating_q975": 1408.1636277208993,
            "rating_q025": 1393.683629045969
        },
        "gpt-4.1-mini-2025-04-14": {
            "rating": 1397.3076100819644,
            "rating_q975": 1403.09011020043,
            "rating_q025": 1391.5251099634988
        },
        "o3-mini-high": {
            "rating": 1397.1169357465756,
            "rating_q975": 1406.124935069063,
            "rating_q025": 1388.1089364240881
        },
        "hunyuan-t1-20250711": {
            "rating": 1395.7504417688026,
            "rating_q975": 1408.8990501591163,
            "rating_q025": 1382.601833378489
        },
        "mistral-medium-2505": {
            "rating": 1395.331906672323,
            "rating_q975": 1401.379031890968,
            "rating_q025": 1389.2847814536779
        },
        "claude-3-5-sonnet-20241022": {
            "rating": 1394.8029125583353,
            "rating_q975": 1399.055078362282,
            "rating_q025": 1390.5507467543885
        },
        "o1-preview": {
            "rating": 1393.0475468921243,
            "rating_q975": 1400.5951804469987,
            "rating_q025": 1385.4999133372498
        },
        "gemini-2.5-flash-lite-preview-09-2025-no-thinking": {
            "rating": 1389.7662670548948,
            "rating_q975": 1397.1916198958543,
            "rating_q025": 1382.3409142139353
        },
        "qwen3-235b-a22b": {
            "rating": 1388.412387814933,
            "rating_q975": 1394.791286504891,
            "rating_q025": 1382.033489124975
        },
        "hunyuan-turbos-20250416": {
            "rating": 1387.1286342652463,
            "rating_q975": 1396.645585250276,
            "rating_q025": 1377.6116832802165
        },
        "glm-4.5-air": {
            "rating": 1386.372153893951,
            "rating_q975": 1392.3327220662866,
            "rating_q025": 1380.4115857216154
        },
        "qwen3-next-80b-a3b-thinking": {
            "rating": 1381.3286861974582,
            "rating_q975": 1388.9977508498391,
            "rating_q025": 1373.6596215450772
        },
        "gemini-2.5-flash-lite-preview-06-17-thinking": {
            "rating": 1381.3168517675838,
            "rating_q975": 1387.28422000658,
            "rating_q025": 1375.3494835285876
        },
        "minimax-m1": {
            "rating": 1380.3973578241425,
            "rating_q975": 1386.0000677415285,
            "rating_q025": 1374.7946479067566
        },
        "qwen2.5-max": {
            "rating": 1380.2987318174914,
            "rating_q975": 1386.4951533863639,
            "rating_q025": 1374.102310248619
        },
        "grok-3-mini-high": {
            "rating": 1374.53109339502,
            "rating_q975": 1381.7477283074277,
            "rating_q025": 1367.3144584826123
        },
        "step-3": {
            "rating": 1372.9636054467328,
            "rating_q975": 1383.733740642453,
            "rating_q025": 1362.1934702510125
        },
        "mistral-small-2506": {
            "rating": 1369.4329355667758,
            "rating_q975": 1376.4205999469136,
            "rating_q025": 1362.445271186638
        },
        "llama-3.1-nemotron-ultra-253b-v1": {
            "rating": 1369.3314859649229,
            "rating_q975": 1390.7532950336179,
            "rating_q025": 1347.909676896228
        },
        "grok-3-mini-beta": {
            "rating": 1367.8557944099305,
            "rating_q975": 1374.5247440564033,
            "rating_q025": 1361.1868447634577
        },
        "glm-4.5v": {
            "rating": 1367.7782937884888,
            "rating_q975": 1379.9082443608763,
            "rating_q025": 1355.6483432161012
        },
        "o3-mini": {
            "rating": 1367.1751672288453,
            "rating_q975": 1372.0870646895712,
            "rating_q025": 1362.2632697681195
        },
        "ling-flash-2.0": {
            "rating": 1363.5118093175668,
            "rating_q975": 1373.4888504085948,
            "rating_q025": 1353.5347682265387
        },
        "gemma-3-27b-it": {
            "rating": 1363.5094127838222,
            "rating_q975": 1368.7943520309825,
            "rating_q025": 1358.224473536662
        },
        "command-a-03-2025": {
            "rating": 1362.9989576143726,
            "rating_q975": 1367.962236681168,
            "rating_q025": 1358.0356785475772
        },
        "amazon-nova-experimental-chat-10-09": {
            "rating": 1362.3508532845651,
            "rating_q975": 1372.5618874699003,
            "rating_q025": 1352.13981909923
        },
        "qwen3-32b": {
            "rating": 1361.712069042393,
            "rating_q975": 1377.9455117399445,
            "rating_q025": 1345.4786263448416
        },
        "hunyuan-turbos-20250226": {
            "rating": 1361.427719046972,
            "rating_q975": 1384.0629093870655,
            "rating_q025": 1338.7925287068786
        },
        "claude-3-5-sonnet-20240620": {
            "rating": 1357.4960704403873,
            "rating_q975": 1362.949802729679,
            "rating_q025": 1352.0423381510955
        },
        "o1-mini": {
            "rating": 1355.8790280130743,
            "rating_q975": 1361.7180280879998,
            "rating_q025": 1350.0400279381488
        },
        "nvidia-llama-3.3-nemotron-super-49b-v1.5": {
            "rating": 1355.8646868331903,
            "rating_q975": 1370.6698721832945,
            "rating_q025": 1341.059501483086
        },
        "llama-3.3-nemotron-49b-super-v1": {
            "rating": 1355.7856879073156,
            "rating_q975": 1380.209369620093,
            "rating_q025": 1331.3620061945383
        },
        "gpt-oss-120b": {
            "rating": 1355.0583717512186,
            "rating_q975": 1361.199283661784,
            "rating_q025": 1348.9174598406532
        },
        "gpt-5-nano-high": {
            "rating": 1353.1009246401607,
            "rating_q975": 1363.0246581456288,
            "rating_q025": 1343.1771911346925
        },
        "qwq-32b": {
            "rating": 1352.8772733399442,
            "rating_q975": 1359.4096741320654,
            "rating_q025": 1346.344872547823
        },
        "ring-flash-2.0": {
            "rating": 1348.9652765905528,
            "rating_q975": 1358.8109105177398,
            "rating_q025": 1339.1196426633658
        },
        "gemini-1.5-pro-002": {
            "rating": 1348.2642929723788,
            "rating_q975": 1353.6621582498217,
            "rating_q025": 1342.866427694936
        },
        "qwen-plus-0125": {
            "rating": 1348.0625633131722,
            "rating_q975": 1362.3650159221806,
            "rating_q025": 1333.7601107041637
        },
        "gemini-2.0-flash-lite-preview-02-05": {
            "rating": 1346.388784375981,
            "rating_q975": 1353.73495985799,
            "rating_q025": 1339.042608893972
        },
        "deepseek-v3": {
            "rating": 1345.8871847469877,
            "rating_q975": 1353.8899175105091,
            "rating_q025": 1337.8844519834663
        },
        "hunyuan-turbo-0110": {
            "rating": 1342.5344134966804,
            "rating_q975": 1365.9872349266993,
            "rating_q025": 1319.0815920666614
        },
        "qwen3-30b-a3b": {
            "rating": 1341.5179355441771,
            "rating_q975": 1347.9472296829433,
            "rating_q025": 1335.088641405411
        },
        "claude-3-5-haiku-20241022": {
            "rating": 1339.799414950015,
            "rating_q975": 1344.441539618943,
            "rating_q025": 1335.1572902810872
        },
        "llama-3.1-405b-instruct-bf16": {
            "rating": 1338.2745057737395,
            "rating_q975": 1344.09113773554,
            "rating_q025": 1332.457873811939
        },
        "yi-lightning": {
            "rating": 1336.9316114209441,
            "rating_q975": 1344.7781085911308,
            "rating_q025": 1329.0851142507574
        },
        "llama-4-maverick-17b-128e-instruct": {
            "rating": 1336.4909129507516,
            "rating_q975": 1342.2973042368596,
            "rating_q025": 1330.6845216646436
        },
        "gpt-4o-2024-05-13": {
            "rating": 1333.6876881045619,
            "rating_q975": 1338.8550032382566,
            "rating_q025": 1328.5203729708671
        },
        "llama-3.1-405b-instruct-fp8": {
            "rating": 1333.3217692064181,
            "rating_q975": 1338.9901743953558,
            "rating_q025": 1327.6533640174805
        },
        "step-2-16k-exp-202412": {
            "rating": 1333.1157587734601,
            "rating_q975": 1348.427630229605,
            "rating_q025": 1317.8038873173152
        },
        "magistral-medium-2506": {
            "rating": 1330.0815674797318,
            "rating_q975": 1338.4057516986732,
            "rating_q025": 1321.7573832607904
        },
        "gemma-3-12b-it": {
            "rating": 1329.556256950914,
            "rating_q975": 1347.5023764285686,
            "rating_q025": 1311.6101374732596
        },
        "step-1o-turbo-202506": {
            "rating": 1329.1854401597902,
            "rating_q975": 1338.9403384726475,
            "rating_q025": 1319.430541846933
        },
        "athene-v2-chat": {
            "rating": 1328.9091934878838,
            "rating_q975": 1336.1724229173246,
            "rating_q025": 1321.645964058443
        },
        "gpt-4.1-nano-2025-04-14": {
            "rating": 1327.834803793431,
            "rating_q975": 1341.5015680980803,
            "rating_q025": 1314.168039488782
        },
        "llama-4-scout-17b-16e-instruct": {
            "rating": 1326.2123516950383,
            "rating_q975": 1332.4655911958594,
            "rating_q025": 1319.9591121942171
        },
        "hunyuan-large-2025-02-10": {
            "rating": 1325.5870966267232,
            "rating_q975": 1344.6073019819637,
            "rating_q025": 1306.5668912714827
        },
        "claude-3-opus-20240229": {
            "rating": 1325.5850340782436,
            "rating_q975": 1330.2442768674262,
            "rating_q025": 1320.925791289061
        },
        "deepseek-v2.5-1210": {
            "rating": 1324.9594218238683,
            "rating_q975": 1338.2545250558162,
            "rating_q025": 1311.6643185919204
        },
        "glm-4-plus-0111": {
            "rating": 1323.7788789285232,
            "rating_q975": 1338.1644534112252,
            "rating_q025": 1309.3933044458213
        },
        "gemini-1.5-pro-001": {
            "rating": 1323.3538387697415,
            "rating_q975": 1329.34040744101,
            "rating_q025": 1317.367270098473
        },
        "gpt-4o-2024-08-06": {
            "rating": 1322.8299890127164,
            "rating_q975": 1329.0949840186338,
            "rating_q025": 1316.564994006799
        },
        "qwen2.5-plus-1127": {
            "rating": 1322.7225226184814,
            "rating_q975": 1333.3414930291601,
            "rating_q025": 1312.1035522078027
        },
        "gemini-advanced-0514": {
            "rating": 1322.109228113319,
            "rating_q975": 1329.2833246221035,
            "rating_q025": 1314.9351316045345
        },
        "grok-2-2024-08-13": {
            "rating": 1322.092305387137,
            "rating_q975": 1327.4760417178918,
            "rating_q025": 1316.7085690563822
        },
        "gpt-oss-20b": {
            "rating": 1320.2117163985672,
            "rating_q975": 1329.181715896892,
            "rating_q025": 1311.2417169002424
        },
        "llama-3.3-70b-instruct": {
            "rating": 1318.3025386619584,
            "rating_q975": 1323.180664197782,
            "rating_q025": 1313.4244131261346
        },
        "deepseek-v2.5": {
            "rating": 1317.5530797463944,
            "rating_q975": 1325.0021697146979,
            "rating_q025": 1310.1039897780909
        },
        "mistral-small-3.1-24b-instruct-2503": {
            "rating": 1316.9205765003153,
            "rating_q975": 1322.8688595246206,
            "rating_q025": 1310.97229347601
        },
        "mistral-large-2407": {
            "rating": 1316.2517489890133,
            "rating_q975": 1322.394348401979,
            "rating_q025": 1310.1091495760477
        },
        "glm-4-plus": {
            "rating": 1314.9332596711458,
            "rating_q975": 1322.5385613427,
            "rating_q025": 1307.3279579995917
        },
        "qwen-max-0919": {
            "rating": 1314.6389218025743,
            "rating_q975": 1323.7856579973736,
            "rating_q025": 1305.492185607775
        },
        "qwen2.5-72b-instruct": {
            "rating": 1313.2847601789924,
            "rating_q975": 1319.4788526104091,
            "rating_q025": 1307.0906677475757
        },
        "gemma-3n-e4b-it": {
            "rating": 1312.314953022816,
            "rating_q975": 1319.4887816454323,
            "rating_q025": 1305.1411244002
        },
        "gpt-4-turbo-2024-04-09": {
            "rating": 1312.1193040134413,
            "rating_q975": 1317.8447825896499,
            "rating_q025": 1306.3938254372326
        },
        "gpt-4-1106-preview": {
            "rating": 1309.4853219620868,
            "rating_q975": 1315.3610513850988,
            "rating_q025": 1303.6095925390748
        },
        "mistral-large-2411": {
            "rating": 1309.2476649197285,
            "rating_q975": 1316.1328539913447,
            "rating_q025": 1302.3624758481124
        },
        "athene-70b-0725": {
            "rating": 1308.523369308476,
            "rating_q975": 1317.0082009164707,
            "rating_q025": 1300.0385377004814
        },
        "gpt-4o-mini-2024-07-18": {
            "rating": 1306.7618186099414,
            "rating_q975": 1311.8590371645846,
            "rating_q025": 1301.6646000552983
        },
        "hunyuan-standard-2025-02-10": {
            "rating": 1306.7344351786778,
            "rating_q975": 1325.6102399914523,
            "rating_q025": 1287.8586303659033
        },
        "llama-3.1-nemotron-70b-instruct": {
            "rating": 1306.3730005518737,
            "rating_q975": 1319.209965317428,
            "rating_q025": 1293.5360357863194
        },
        "gpt-4-0125-preview": {
            "rating": 1303.2634045752875,
            "rating_q975": 1309.259665767386,
            "rating_q025": 1297.267143383189
        },
        "gpt-4-0314": {
            "rating": 1301.1244973831995,
            "rating_q975": 1308.8209296261425,
            "rating_q025": 1293.4280651402564
        },
        "gemini-1.5-flash-002": {
            "rating": 1300.351808760919,
            "rating_q975": 1306.9225604133549,
            "rating_q025": 1293.7810571084833
        },
        "hunyuan-large-vision": {
            "rating": 1300.0201837991794,
            "rating_q975": 1313.053928652434,
            "rating_q025": 1286.9864389459249
        },
        "grok-2-mini-2024-08-13": {
            "rating": 1299.8486089244107,
            "rating_q975": 1305.5362398812827,
            "rating_q025": 1294.1609779675387
        },
        "qwen2.5-coder-32b-instruct": {
            "rating": 1299.56114887098,
            "rating_q975": 1314.1074941736504,
            "rating_q025": 1285.0148035683098
        },
        "amazon-nova-pro-v1.0": {
            "rating": 1297.693946863572,
            "rating_q975": 1304.855725472139,
            "rating_q025": 1290.5321682550048
        },
        "llama-3.1-70b-instruct": {
            "rating": 1295.1041920144332,
            "rating_q975": 1300.763877453943,
            "rating_q025": 1289.4445065749235
        },
        "gpt-4-0613": {
            "rating": 1284.454839470348,
            "rating_q975": 1290.8487723762921,
            "rating_q025": 1278.0609065644037
        },
        "gemini-1.5-flash-001": {
            "rating": 1284.315013700193,
            "rating_q975": 1290.4218923932078,
            "rating_q025": 1278.2081350071783
        },
        "deepseek-coder-v2": {
            "rating": 1283.9037855943375,
            "rating_q975": 1293.5689595034798,
            "rating_q025": 1274.238611685195
        },
        "gemma-3-4b-it": {
            "rating": 1281.3040733562345,
            "rating_q975": 1298.7312927644666,
            "rating_q025": 1263.8768539480025
        },
        "mistral-small-24b-instruct-2501": {
            "rating": 1280.1368057858128,
            "rating_q975": 1289.723117428237,
            "rating_q025": 1270.5504941433887
        },
        "jamba-1.5-large": {
            "rating": 1280.0611837015344,
            "rating_q975": 1291.6331432256038,
            "rating_q025": 1268.489224177465
        },
        "claude-3-sonnet-20240229": {
            "rating": 1278.9050160630668,
            "rating_q975": 1284.7287694206557,
            "rating_q025": 1273.081262705478
        },
        "llama-3.1-nemotron-51b-instruct": {
            "rating": 1278.0691373225645,
            "rating_q975": 1295.4968482488741,
            "rating_q025": 1260.641426396255
        },
        "nemotron-4-340b-instruct": {
            "rating": 1277.7994744453936,
            "rating_q975": 1286.653956581906,
            "rating_q025": 1268.9449923088812
        },
        "gemma-2-27b-it": {
            "rating": 1277.7201554818103,
            "rating_q975": 1282.7333237566181,
            "rating_q025": 1272.7069872070024
        },
        "reka-core-20240904": {
            "rating": 1276.8216323970828,
            "rating_q975": 1288.2898411611895,
            "rating_q025": 1265.353423632976
        },
        "llama-3-70b-instruct": {
            "rating": 1276.1514767172566,
            "rating_q975": 1281.595552895541,
            "rating_q025": 1270.7074005389723
        },
        "glm-4-0520": {
            "rating": 1274.248063857776,
            "rating_q975": 1285.2997226769307,
            "rating_q025": 1263.1964050386214
        },
        "phi-4": {
            "rating": 1273.6874807154409,
            "rating_q975": 1281.3612123309276,
            "rating_q025": 1266.013749099954
        },
        "llama-3.1-tulu-3-70b": {
            "rating": 1270.186441842639,
            "rating_q975": 1288.8381964864698,
            "rating_q025": 1251.5346871988081
        },
        "qwen2-72b-instruct": {
            "rating": 1269.4806205588181,
            "rating_q975": 1276.6618516494364,
            "rating_q025": 1262.2993894682
        },
        "gemma-2-9b-it-simpo": {
            "rating": 1268.7705576038018,
            "rating_q975": 1280.119753724584,
            "rating_q025": 1257.4213614830196
        },
        "amazon-nova-lite-v1.0": {
            "rating": 1267.92188462851,
            "rating_q975": 1276.1462922150156,
            "rating_q025": 1259.6974770420045
        },
        "c4ai-aya-expanse-32b": {
            "rating": 1267.3084048010855,
            "rating_q975": 1274.7276526441076,
            "rating_q025": 1259.8891569580635
        },
        "hunyuan-standard-256k": {
            "rating": 1266.1138567582511,
            "rating_q975": 1286.690656362187,
            "rating_q025": 1245.5370571543153
        },
        "reka-flash-20240904": {
            "rating": 1264.1062897296094,
            "rating_q975": 1275.2723213387903,
            "rating_q025": 1252.9402581204286
        },
        "claude-3-haiku-20240307": {
            "rating": 1261.6251149009424,
            "rating_q975": 1267.1770634143193,
            "rating_q025": 1256.0731663875656
        },
        "olmo-2-0325-32b-instruct": {
            "rating": 1259.4636770961647,
            "rating_q975": 1279.2456659037496,
            "rating_q025": 1239.6816882885798
        },
        "mistral-large-2402": {
            "rating": 1258.3985717197452,
            "rating_q975": 1265.2567371553564,
            "rating_q025": 1251.540406284134
        },
        "command-r-plus-08-2024": {
            "rating": 1257.9296118606069,
            "rating_q975": 1268.4506489947976,
            "rating_q025": 1247.4085747264162
        },
        "gemini-1.5-flash-8b-001": {
            "rating": 1255.9231127955172,
            "rating_q975": 1262.4832371058267,
            "rating_q025": 1249.3629884852078
        },
        "command-r-08-2024": {
            "rating": 1253.193288924298,
            "rating_q975": 1263.4677188584888,
            "rating_q025": 1242.9188589901073
        },
        "gemma-2-9b-it": {
            "rating": 1252.8641215822845,
            "rating_q975": 1258.6045888412896,
            "rating_q025": 1247.1236543232794
        },
        "command-r-plus": {
            "rating": 1248.4965717819518,
            "rating_q975": 1254.7801174511362,
            "rating_q025": 1242.2130261127675
        },
        "ministral-8b-2410": {
            "rating": 1246.9726220017667,
            "rating_q975": 1262.2052915691977,
            "rating_q025": 1231.7399524343357
        },
        "qwen1.5-110b-chat": {
            "rating": 1242.7992058742752,
            "rating_q975": 1251.456563109948,
            "rating_q025": 1234.1418486386024
        },
        "amazon-nova-micro-v1.0": {
            "rating": 1241.1250298454029,
            "rating_q975": 1249.247940539201,
            "rating_q025": 1233.0021191516048
        },
        "mixtral-8x22b-instruct-v0.1": {
            "rating": 1239.9323474999435,
            "rating_q975": 1246.795339186595,
            "rating_q025": 1233.069355813292
        },
        "qwen1.5-72b-chat": {
            "rating": 1235.8868879589543,
            "rating_q975": 1243.6806099759394,
            "rating_q025": 1228.0931659419691
        },
        "jamba-1.5-mini": {
            "rating": 1232.9008644251248,
            "rating_q975": 1244.7386497804644,
            "rating_q025": 1221.0630790697853
        },
        "mistral-medium": {
            "rating": 1232.3138834190731,
            "rating_q975": 1240.9461304926403,
            "rating_q025": 1223.681636345506
        },
        "reka-flash-21b-20240226-online": {
            "rating": 1232.1823789595232,
            "rating_q975": 1242.9021961166175,
            "rating_q025": 1221.462561802429
        },
        "reka-flash-21b-20240226": {
            "rating": 1230.4025259069572,
            "rating_q975": 1239.2172577104145,
            "rating_q025": 1221.5877941034998
        },
        "granite-3.1-8b-instruct": {
            "rating": 1228.5090056293752,
            "rating_q975": 1248.3610086294705,
            "rating_q025": 1208.65700262928
        },
        "gemini-pro-dev-api": {
            "rating": 1227.0648040135854,
            "rating_q975": 1238.4022698317372,
            "rating_q025": 1215.7273381954337
        },
        "c4ai-aya-expanse-8b": {
            "rating": 1226.6501705635733,
            "rating_q975": 1237.89156791557,
            "rating_q025": 1215.4087732115765
        },
        "gemini-pro": {
            "rating": 1224.282486492469,
            "rating_q975": 1242.4774918743742,
            "rating_q025": 1206.0874811105637
        },
        "gpt-3.5-turbo-0125": {
            "rating": 1224.2690700649182,
            "rating_q975": 1230.8360571337203,
            "rating_q025": 1217.7020829961161
        },
        "gpt-3.5-turbo-1106": {
            "rating": 1222.7999212451787,
            "rating_q975": 1235.5542480552954,
            "rating_q025": 1210.045594435062
        },
        "internlm2_5-20b-chat": {
            "rating": 1222.7824469516527,
            "rating_q975": 1234.17531540361,
            "rating_q025": 1211.3895784996953
        },
        "yi-1.5-34b-chat": {
            "rating": 1222.0159458869239,
            "rating_q975": 1230.249344007072,
            "rating_q025": 1213.7825477667757
        },
        "llama-3.1-tulu-3-8b": {
            "rating": 1219.9169816124647,
            "rating_q975": 1239.778961079805,
            "rating_q025": 1200.0550021451245
        },
        "llama-3.1-8b-instruct": {
            "rating": 1219.4197413468462,
            "rating_q975": 1225.4047459272508,
            "rating_q025": 1213.4347367664416
        },
        "qwen1.5-32b-chat": {
            "rating": 1217.766615806687,
            "rating_q975": 1227.0006546587108,
            "rating_q025": 1208.5325769546632
        },
        "llama-3-8b-instruct": {
            "rating": 1216.1939838972103,
            "rating_q975": 1222.1826432564694,
            "rating_q025": 1210.2053245379511
        },
        "granite-3.1-2b-instruct": {
            "rating": 1215.644043308227,
            "rating_q975": 1234.7372704002776,
            "rating_q025": 1196.5508162161766
        },
        "dbrx-instruct-preview": {
            "rating": 1213.4830434768296,
            "rating_q975": 1222.480073624865,
            "rating_q025": 1204.4860133287941
        },
        "zephyr-orpo-141b-A35b-v0.1": {
            "rating": 1212.8134869508626,
            "rating_q975": 1229.7469561087778,
            "rating_q025": 1195.8800177929475
        },
        "command-r": {
            "rating": 1211.2959522312335,
            "rating_q975": 1218.3957659267703,
            "rating_q025": 1204.1961385356967
        },
        "phi-3-medium-4k-instruct": {
            "rating": 1209.1158656955408,
            "rating_q975": 1217.158897414294,
            "rating_q025": 1201.0728339767877
        },
        "mixtral-8x7b-instruct-v0.1": {
            "rating": 1207.4551230580503,
            "rating_q975": 1214.0644945683705,
            "rating_q025": 1200.84575154773
        },
        "granite-3.0-8b-instruct": {
            "rating": 1199.3553507045528,
            "rating_q975": 1214.1824500569373,
            "rating_q025": 1184.5282513521684
        },
        "qwen1.5-14b-chat": {
            "rating": 1197.2543225182221,
            "rating_q975": 1207.9007144748766,
            "rating_q025": 1186.6079305615676
        },
        "starling-lm-7b-beta": {
            "rating": 1192.196200937045,
            "rating_q975": 1202.9306721512485,
            "rating_q025": 1181.4617297228415
        },
        "gemma-1.1-7b-it": {
            "rating": 1187.6254456182953,
            "rating_q975": 1196.1363083279089,
            "rating_q025": 1179.1145829086818
        },
        "phi-3-small-8k-instruct": {
            "rating": 1184.751610748278,
            "rating_q975": 1194.2327213095714,
            "rating_q025": 1175.2705001869845
        },
        "tulu-2-dpo-70b": {
            "rating": 1184.7115242975012,
            "rating_q975": 1201.1635217513451,
            "rating_q025": 1168.2595268436573
        },
        "snowflake-arctic-instruct": {
            "rating": 1183.3315119513936,
            "rating_q975": 1192.3991312166147,
            "rating_q025": 1174.2638926861725
        },
        "openchat-3.5-0106": {
            "rating": 1183.3312439420397,
            "rating_q975": 1194.5251000967075,
            "rating_q025": 1172.1373877873718
        },
        "gemma-2-2b-it": {
            "rating": 1181.5576859163393,
            "rating_q975": 1187.832503993683,
            "rating_q025": 1175.2828678389956
        },
        "yi-34b-chat": {
            "rating": 1180.780560858219,
            "rating_q975": 1191.302135447542,
            "rating_q025": 1170.2589862688958
        },
        "openhermes-2.5-mistral-7b": {
            "rating": 1176.6089346794847,
            "rating_q975": 1193.5717558678596,
            "rating_q025": 1159.6461134911099
        },
        "granite-3.0-2b-instruct": {
            "rating": 1173.1388186253205,
            "rating_q975": 1187.819966049842,
            "rating_q025": 1158.457671200799
        },
        "phi-3-mini-4k-instruct-june-2024": {
            "rating": 1171.8967634550118,
            "rating_q975": 1182.6834794860997,
            "rating_q025": 1161.1100474239238
        },
        "deepseek-llm-67b-chat": {
            "rating": 1171.8571476045252,
            "rating_q975": 1190.4487568466432,
            "rating_q025": 1153.2655383624071
        },
        "openchat-3.5": {
            "rating": 1171.5765829540119,
            "rating_q975": 1187.36609087686,
            "rating_q025": 1155.7870750311638
        },
        "wizardlm-70b": {
            "rating": 1169.3936093760185,
            "rating_q975": 1184.6847166939915,
            "rating_q025": 1154.1025020580455
        },
        "qwq-32b-preview": {
            "rating": 1167.5666778713048,
            "rating_q975": 1187.0213040137662,
            "rating_q025": 1148.1120517288434
        },
        "llama-3.2-3b-instruct": {
            "rating": 1165.9076853990668,
            "rating_q975": 1178.398373931553,
            "rating_q025": 1153.4169968665808
        },
        "starling-lm-7b-alpha": {
            "rating": 1165.0950975698383,
            "rating_q975": 1177.7775440135772,
            "rating_q025": 1152.4126511260995
        },
        "vicuna-33b": {
            "rating": 1160.2698163315329,
            "rating_q975": 1170.3001540294592,
            "rating_q025": 1150.2394786336065
        },
        "llama-2-70b-chat": {
            "rating": 1156.8456605052816,
            "rating_q975": 1164.961279320134,
            "rating_q025": 1148.730041690429
        },
        "solar-10.7b-instruct-v1.0": {
            "rating": 1155.2581033214615,
            "rating_q975": 1175.0275553694003,
            "rating_q025": 1135.4886512735227
        },
        "codellama-70b-instruct": {
            "rating": 1154.7120244583389,
            "rating_q975": 1186.0287184428864,
            "rating_q025": 1123.3953304737913
        },
        "mistral-7b-instruct-v0.2": {
            "rating": 1153.724810221177,
            "rating_q975": 1163.372033183307,
            "rating_q025": 1144.077587259047
        },
        "mpt-30b-chat": {
            "rating": 1152.2849716389685,
            "rating_q975": 1179.3542859983884,
            "rating_q025": 1125.2156572795486
        },
        "dolphin-2.2.1-mistral-7b": {
            "rating": 1152.0803340247346,
            "rating_q975": 1179.9718670336124,
            "rating_q025": 1124.1888010158568
        },
        "smollm2-1.7b-instruct": {
            "rating": 1150.0348508616428,
            "rating_q975": 1174.7114674395975,
            "rating_q025": 1125.358234283688
        },
        "gemma-7b-it": {
            "rating": 1148.825857304379,
            "rating_q975": 1162.3704993919341,
            "rating_q025": 1135.281215216824
        },
        "phi-3-mini-4k-instruct": {
            "rating": 1148.3259998843869,
            "rating_q975": 1157.8526961379944,
            "rating_q025": 1138.7993036307794
        },
        "qwen1.5-7b-chat": {
            "rating": 1147.187755102194,
            "rating_q975": 1162.8377393353337,
            "rating_q025": 1131.5377708690542
        },
        "llama2-70b-steerlm-chat": {
            "rating": 1142.6490009537724,
            "rating_q975": 1163.2816008613793,
            "rating_q025": 1122.0164010461656
        },
        "palm-2": {
            "rating": 1140.209783418973,
            "rating_q975": 1155.778505103873,
            "rating_q025": 1124.6410617340732
        },
        "qwen-14b-chat": {
            "rating": 1137.4500371324466,
            "rating_q975": 1156.5156859882184,
            "rating_q025": 1118.3843882766748
        },
        "llama-2-13b-chat": {
            "rating": 1135.5928561834326,
            "rating_q975": 1145.863794348339,
            "rating_q025": 1125.321918018526
        },
        "gemma-1.1-2b-it": {
            "rating": 1132.0032309447597,
            "rating_q975": 1143.8172615938468,
            "rating_q025": 1120.1892002956727
        },
        "codellama-34b-instruct": {
            "rating": 1129.101521605835,
            "rating_q975": 1143.8822061336105,
            "rating_q025": 1114.3208370780594
        },
        "vicuna-13b": {
            "rating": 1127.1815847948787,
            "rating_q975": 1137.8716538099188,
            "rating_q025": 1116.4915157798387
        },
        "phi-3-mini-128k-instruct": {
            "rating": 1127.0096367556823,
            "rating_q975": 1137.8568767416944,
            "rating_q025": 1116.1623967696703
        },
        "nous-hermes-2-mixtral-8x7b-dpo": {
            "rating": 1126.6830580452715,
            "rating_q975": 1144.4499424364146,
            "rating_q025": 1108.9161736541284
        },
        "falcon-180b-chat": {
            "rating": 1121.6909235499575,
            "rating_q975": 1157.5001488601097,
            "rating_q025": 1085.8816982398052
        },
        "zephyr-7b-alpha": {
            "rating": 1120.0800907863495,
            "rating_q975": 1149.943051180021,
            "rating_q025": 1090.217130392678
        },
        "zephyr-7b-beta": {
            "rating": 1112.9276634738567,
            "rating_q975": 1127.3445926088755,
            "rating_q025": 1098.510734338838
        },
        "llama-3.2-1b-instruct": {
            "rating": 1111.6984104120158,
            "rating_q975": 1124.5563797306027,
            "rating_q025": 1098.840441093429
        },
        "mistral-7b-instruct": {
            "rating": 1110.407019528407,
            "rating_q975": 1125.7619040869365,
            "rating_q025": 1095.0521349698777
        },
        "wizardlm-13b": {
            "rating": 1110.0534918203998,
            "rating_q975": 1126.6946851441808,
            "rating_q025": 1093.4122984966189
        },
        "gemma-2b-it": {
            "rating": 1106.6573452706232,
            "rating_q975": 1124.3043541781017,
            "rating_q025": 1089.0103363631447
        },
        "stripedhyena-nous-7b": {
            "rating": 1103.8188669728515,
            "rating_q975": 1120.8445268691953,
            "rating_q025": 1086.7932070765078
        },
        "vicuna-7b": {
            "rating": 1099.9779359614795,
            "rating_q975": 1117.0511281776178,
            "rating_q025": 1082.9047437453412
        },
        "guanaco-33b": {
            "rating": 1099.2636031638135,
            "rating_q975": 1125.0802231128862,
            "rating_q025": 1073.4469832147408
        },
        "llama-2-7b-chat": {
            "rating": 1093.4145381411831,
            "rating_q975": 1104.2828455464194,
            "rating_q025": 1082.546230735947
        },
        "qwen1.5-4b-chat": {
            "rating": 1090.206086071765,
            "rating_q975": 1104.3923392729785,
            "rating_q025": 1076.0198328705515
        },
        "olmo-7b-instruct": {
            "rating": 1066.907030287374,
            "rating_q975": 1083.816650750082,
            "rating_q025": 1049.997409824666
        },
        "chatglm3-6b": {
            "rating": 1056.262597753466,
            "rating_q975": 1076.335820431965,
            "rating_q025": 1036.189375074967
        },
        "gpt4all-13b-snoozy": {
            "rating": 1055.8701166184205,
            "rating_q975": 1086.6720166521372,
            "rating_q025": 1025.0682165847038
        },
        "koala-13b": {
            "rating": 1027.593297519051,
            "rating_q975": 1046.212267994367,
            "rating_q025": 1008.9743270437351
        },
        "mpt-7b-chat": {
            "rating": 1025.6004810718737,
            "rating_q975": 1047.9051248367682,
            "rating_q025": 1003.2958373069791
        },
        "chatglm2-6b": {
            "rating": 1023.3473060813569,
            "rating_q975": 1050.3996169273585,
            "rating_q025": 996.2949952353555
        },
        "oasst-pythia-12b": {
            "rating": 1015.205127669444,
            "rating_q975": 1034.4418066295457,
            "rating_q025": 995.9684487093423
        },
        "RWKV-4-Raven-14B": {
            "rating": 1009.9212709766111,
            "rating_q975": 1030.994764696856,
            "rating_q025": 988.8477772563664
        },
        "alpaca-13b": {
            "rating": 999.5602498323266,
            "rating_q975": 1019.7046597254327,
            "rating_q025": 979.4158399392204
        },
        "chatglm-6b": {
            "rating": 994.5315216350004,
            "rating_q975": 1016.5204785819549,
            "rating_q025": 972.542564688046
        },
        "dolly-v2-12b": {
            "rating": 963.354849633173,
            "rating_q975": 988.2000821383958,
            "rating_q025": 938.5096171279502
        },
        "stablelm-tuned-alpha-7b": {
            "rating": 936.1761709500306,
            "rating_q975": 961.0420187376468,
            "rating_q025": 911.3103231624144
        },
        "fastchat-t5-3b": {
            "rating": 931.4537270692647,
            "rating_q975": 953.261233231799,
            "rating_q025": 909.6462209067304
        },
        "llama-13b": {
            "rating": 907.5511344378345,
            "rating_q975": 938.8229257984173,
            "rating_q025": 876.2793430772518
        }
    },
    "hard_english_6": {
        "claude-sonnet-4-5-20250929-thinking-32k": {
            "rating": 1494.910380911077,
            "rating_q975": 1505.4657010006592,
            "rating_q025": 1484.3550608214948
        },
        "claude-opus-4-1-20250805-thinking-16k": {
            "rating": 1490.983502207679,
            "rating_q975": 1498.9023454199596,
            "rating_q025": 1483.0646589953985
        },
        "claude-opus-4-1-20250805": {
            "rating": 1477.5226283313839,
            "rating_q975": 1484.6661154903159,
            "rating_q025": 1470.379141172452
        },
        "claude-sonnet-4-5-20250929": {
            "rating": 1470.164779771691,
            "rating_q975": 1484.3072219340631,
            "rating_q025": 1456.0223376093188
        },
        "gemini-2.5-pro": {
            "rating": 1462.3319706747861,
            "rating_q975": 1468.6950048045182,
            "rating_q025": 1455.968936545054
        },
        "glm-4.6": {
            "rating": 1460.6088061988362,
            "rating_q975": 1472.1310841708214,
            "rating_q025": 1449.086528226851
        },
        "claude-opus-4-20250514-thinking-16k": {
            "rating": 1459.92769460641,
            "rating_q975": 1467.1633222080343,
            "rating_q025": 1452.6920670047855
        },
        "claude-haiku-4-5-20251001": {
            "rating": 1457.4200756927266,
            "rating_q975": 1468.6497364642944,
            "rating_q025": 1446.190414921159
        },
        "deepseek-v3.2-exp-thinking": {
            "rating": 1457.3075543359907,
            "rating_q975": 1469.5396996210634,
            "rating_q025": 1445.075409050918
        },
        "qwen3-max-preview": {
            "rating": 1456.0098307181697,
            "rating_q975": 1464.2846354573621,
            "rating_q025": 1447.7350259789773
        },
        "gpt-5-high": {
            "rating": 1453.894165211784,
            "rating_q975": 1462.0108259120498,
            "rating_q025": 1445.7775045115181
        },
        "qwen3-max-2025-09-23": {
            "rating": 1452.6056639642813,
            "rating_q975": 1464.3951769303192,
            "rating_q025": 1440.8161509982435
        },
        "chatgpt-4o-latest-20250326": {
            "rating": 1450.6913576205939,
            "rating_q975": 1457.230756299103,
            "rating_q025": 1444.1519589420848
        },
        "qwen3-vl-235b-a22b-instruct": {
            "rating": 1450.2199182278248,
            "rating_q975": 1462.6919778222286,
            "rating_q025": 1437.747858633421
        },
        "deepseek-v3.1-thinking": {
            "rating": 1448.5021250844238,
            "rating_q975": 1460.5676714996664,
            "rating_q025": 1436.4365786691812
        },
        "qwen3-235b-a22b-instruct-2507": {
            "rating": 1447.5460541443651,
            "rating_q975": 1454.8188412909888,
            "rating_q025": 1440.2732669977415
        },
        "o3-2025-04-16": {
            "rating": 1447.1562812615084,
            "rating_q975": 1453.433423981064,
            "rating_q025": 1440.879138541953
        },
        "gpt-5-chat": {
            "rating": 1446.5872078600871,
            "rating_q975": 1454.3593478173846,
            "rating_q025": 1438.8150679027897
        },
        "claude-sonnet-4-20250514-thinking-32k": {
            "rating": 1444.6652551269476,
            "rating_q975": 1451.912390063488,
            "rating_q025": 1437.4181201904073
        },
        "deepseek-v3.1-terminus-thinking": {
            "rating": 1442.2401487250993,
            "rating_q975": 1462.4072278003487,
            "rating_q025": 1422.07306964985
        },
        "grok-4-fast": {
            "rating": 1440.9489891897063,
            "rating_q975": 1456.0328293195223,
            "rating_q025": 1425.8651490598902
        },
        "gpt-4.5-preview-2025-02-27": {
            "rating": 1440.86956724035,
            "rating_q975": 1453.0711588902434,
            "rating_q025": 1428.6679755904568
        },
        "deepseek-r1-0528": {
            "rating": 1438.7126707675156,
            "rating_q975": 1448.9499997478504,
            "rating_q025": 1428.475341787181
        },
        "longcat-flash-chat": {
            "rating": 1437.1439676639443,
            "rating_q975": 1448.3778568733042,
            "rating_q025": 1425.9100784545844
        },
        "claude-opus-4-20250514": {
            "rating": 1437.1016985268025,
            "rating_q975": 1443.9431165798387,
            "rating_q025": 1430.2602804737662
        },
        "kimi-k2-0905-preview": {
            "rating": 1436.9804801309258,
            "rating_q975": 1449.0074097640204,
            "rating_q025": 1424.9535504978312
        },
        "gpt-4.1-2025-04-14": {
            "rating": 1436.8160134040368,
            "rating_q975": 1443.3105405070157,
            "rating_q025": 1430.3214863010578
        },
        "mistral-medium-2508": {
            "rating": 1436.0675992822662,
            "rating_q975": 1443.7225528433723,
            "rating_q025": 1428.41264572116
        },
        "grok-3-preview-02-24": {
            "rating": 1433.0497143154446,
            "rating_q975": 1441.0097790536524,
            "rating_q025": 1425.0896495772367
        },
        "deepseek-v3.1": {
            "rating": 1433.0479360653599,
            "rating_q975": 1443.5338649652797,
            "rating_q025": 1422.56200716544
        },
        "glm-4.5": {
            "rating": 1432.5205836329221,
            "rating_q975": 1440.9107324335312,
            "rating_q025": 1424.130434832313
        },
        "qwen3-next-80b-a3b-instruct": {
            "rating": 1431.5792690960056,
            "rating_q975": 1440.4104471419894,
            "rating_q025": 1422.748091050022
        },
        "deepseek-r1": {
            "rating": 1429.7352602264707,
            "rating_q975": 1440.8135698635751,
            "rating_q025": 1418.6569505893663
        },
        "kimi-k2-0711-preview": {
            "rating": 1428.7078100981819,
            "rating_q975": 1436.8127450282925,
            "rating_q025": 1420.6028751680713
        },
        "deepseek-v3.1-terminus": {
            "rating": 1427.555221402092,
            "rating_q975": 1445.8805734881134,
            "rating_q025": 1409.2298693160706
        },
        "qwen3-235b-a22b-thinking-2507": {
            "rating": 1427.478624965625,
            "rating_q975": 1440.6248205179688,
            "rating_q025": 1414.332429413281
        },
        "claude-3-7-sonnet-20250219-thinking-32k": {
            "rating": 1426.1741754124025,
            "rating_q975": 1433.4912231552353,
            "rating_q025": 1418.8571276695698
        },
        "qwen3-coder-480b-a35b-instruct": {
            "rating": 1423.5044317511645,
            "rating_q975": 1431.9704957284396,
            "rating_q025": 1415.0383677738894
        },
        "grok-4-0709": {
            "rating": 1422.8423097006973,
            "rating_q975": 1429.938517672557,
            "rating_q025": 1415.7461017288376
        },
        "claude-sonnet-4-20250514": {
            "rating": 1421.491068402954,
            "rating_q975": 1428.4723271955127,
            "rating_q025": 1414.5098096103952
        },
        "gemini-2.5-flash-preview-09-2025": {
            "rating": 1420.4420466976674,
            "rating_q975": 1430.5238257288463,
            "rating_q025": 1410.3602676664884
        },
        "o1-2024-12-17": {
            "rating": 1419.2521283003698,
            "rating_q975": 1428.4629895938,
            "rating_q025": 1410.0412670069395
        },
        "o4-mini-2025-04-16": {
            "rating": 1417.035523495995,
            "rating_q975": 1423.5642586088989,
            "rating_q025": 1410.5067883830911
        },
        "qwen3-vl-235b-a22b-thinking": {
            "rating": 1416.9322028606205,
            "rating_q975": 1429.7611904769178,
            "rating_q025": 1404.103215244323
        },
        "qwen3-235b-a22b-no-thinking": {
            "rating": 1415.9046080586545,
            "rating_q975": 1423.0812680575098,
            "rating_q025": 1408.7279480597992
        },
        "deepseek-v3-0324": {
            "rating": 1415.619041721875,
            "rating_q975": 1422.1511160826115,
            "rating_q025": 1409.0869673611385
        },
        "gemini-2.5-flash": {
            "rating": 1415.4683730136803,
            "rating_q975": 1421.7547447590873,
            "rating_q025": 1409.1820012682733
        },
        "qwen3-30b-a3b-instruct-2507": {
            "rating": 1415.07347641168,
            "rating_q975": 1423.4766460659773,
            "rating_q025": 1406.6703067573828
        },
        "mai-1-preview": {
            "rating": 1414.016687290836,
            "rating_q975": 1423.604305595049,
            "rating_q025": 1404.429068986623
        },
        "gpt-5-mini-high": {
            "rating": 1410.902087258474,
            "rating_q975": 1419.614071985837,
            "rating_q025": 1402.190102531111
        },
        "gpt-4.1-mini-2025-04-14": {
            "rating": 1410.4239505192543,
            "rating_q975": 1417.4897961819722,
            "rating_q025": 1403.3581048565363
        },
        "o3-mini-high": {
            "rating": 1410.340060177908,
            "rating_q975": 1421.1080948297079,
            "rating_q025": 1399.5720255261083
        },
        "o1-preview": {
            "rating": 1409.6221295692235,
            "rating_q975": 1418.8543200233019,
            "rating_q025": 1400.3899391151451
        },
        "mistral-medium-2505": {
            "rating": 1405.9176964638461,
            "rating_q975": 1413.4152937780748,
            "rating_q025": 1398.4200991496175
        },
        "qwen3-235b-a22b": {
            "rating": 1401.0117515037223,
            "rating_q975": 1409.0706303870468,
            "rating_q025": 1392.9528726203978
        },
        "glm-4.5-air": {
            "rating": 1400.8987006054776,
            "rating_q975": 1408.5604939963605,
            "rating_q025": 1393.2369072145948
        },
        "claude-3-5-sonnet-20241022": {
            "rating": 1400.6406159361995,
            "rating_q975": 1405.797662555387,
            "rating_q025": 1395.483569317012
        },
        "step-3": {
            "rating": 1398.8038410127228,
            "rating_q975": 1413.8490366806504,
            "rating_q025": 1383.7586453447952
        },
        "minimax-m1": {
            "rating": 1397.3788656151187,
            "rating_q975": 1404.4462574659512,
            "rating_q025": 1390.3114737642861
        },
        "hunyuan-t1-20250711": {
            "rating": 1396.0306249216815,
            "rating_q975": 1415.154862505336,
            "rating_q025": 1376.906387338027
        },
        "gemini-2.5-flash-lite-preview-09-2025-no-thinking": {
            "rating": 1394.9108274610483,
            "rating_q975": 1404.6481866407223,
            "rating_q025": 1385.1734682813742
        },
        "qwen3-next-80b-a3b-thinking": {
            "rating": 1394.149385431192,
            "rating_q975": 1404.3822767996107,
            "rating_q025": 1383.9164940627734
        },
        "llama-3.1-nemotron-ultra-253b-v1": {
            "rating": 1393.43791963071,
            "rating_q975": 1420.3527769053305,
            "rating_q025": 1366.5230623560894
        },
        "mistral-small-2506": {
            "rating": 1393.0178971094736,
            "rating_q975": 1402.2356429883391,
            "rating_q025": 1383.800151230608
        },
        "ling-flash-2.0": {
            "rating": 1392.7321806512218,
            "rating_q975": 1406.2938130698894,
            "rating_q025": 1379.1705482325542
        },
        "glm-4.5v": {
            "rating": 1390.6096876670344,
            "rating_q975": 1407.4985988638218,
            "rating_q025": 1373.720776470247
        },
        "amazon-nova-experimental-chat-10-09": {
            "rating": 1389.7167726989521,
            "rating_q975": 1403.9402957728298,
            "rating_q025": 1375.4932496250744
        },
        "hunyuan-turbos-20250416": {
            "rating": 1389.2645515196677,
            "rating_q975": 1401.7989029369314,
            "rating_q025": 1376.730200102404
        },
        "qwen2.5-max": {
            "rating": 1385.6987091548901,
            "rating_q975": 1393.298261082485,
            "rating_q025": 1378.0991572272953
        },
        "llama-3.3-nemotron-49b-super-v1": {
            "rating": 1383.4769926388155,
            "rating_q975": 1412.7839567802573,
            "rating_q025": 1354.1700284973738
        },
        "gemini-2.5-flash-lite-preview-06-17-thinking": {
            "rating": 1383.339560140674,
            "rating_q975": 1390.8327086523927,
            "rating_q025": 1375.8464116289551
        },
        "grok-3-mini-high": {
            "rating": 1380.9874118968914,
            "rating_q975": 1390.517563966169,
            "rating_q025": 1371.4572598276138
        },
        "grok-3-mini-beta": {
            "rating": 1380.6465275858282,
            "rating_q975": 1389.0485839481835,
            "rating_q025": 1372.2444712234728
        },
        "o3-mini": {
            "rating": 1380.3348796356108,
            "rating_q975": 1386.3481957677361,
            "rating_q025": 1374.3215635034855
        },
        "qwen3-32b": {
            "rating": 1379.1012578755315,
            "rating_q975": 1400.0219566565727,
            "rating_q025": 1358.1805590944903
        },
        "ring-flash-2.0": {
            "rating": 1377.6275080671105,
            "rating_q975": 1391.197963827771,
            "rating_q025": 1364.05705230645
        },
        "hunyuan-turbos-20250226": {
            "rating": 1377.0917646484484,
            "rating_q975": 1404.6064596901076,
            "rating_q025": 1349.577069606789
        },
        "command-a-03-2025": {
            "rating": 1372.539877065619,
            "rating_q975": 1378.6880056748046,
            "rating_q025": 1366.3917484564336
        },
        "nvidia-llama-3.3-nemotron-super-49b-v1.5": {
            "rating": 1372.0871963467205,
            "rating_q975": 1392.7728428699872,
            "rating_q025": 1351.4015498234537
        },
        "qwq-32b": {
            "rating": 1371.3956545607089,
            "rating_q975": 1379.5953099332708,
            "rating_q025": 1363.195999188147
        },
        "o1-mini": {
            "rating": 1371.35458513207,
            "rating_q975": 1378.481826704813,
            "rating_q025": 1364.227343559327
        },
        "gemma-3-27b-it": {
            "rating": 1366.8242951705558,
            "rating_q975": 1373.3239948045189,
            "rating_q025": 1360.3245955365928
        },
        "gpt-5-nano-high": {
            "rating": 1366.6809277100122,
            "rating_q975": 1380.3141762296584,
            "rating_q025": 1353.047679190366
        },
        "hunyuan-turbo-0110": {
            "rating": 1364.2666458924361,
            "rating_q975": 1391.747101729234,
            "rating_q025": 1336.7861900556384
        },
        "qwen-plus-0125": {
            "rating": 1364.1467552207646,
            "rating_q975": 1381.5391211853741,
            "rating_q025": 1346.754389256155
        },
        "gpt-oss-120b": {
            "rating": 1362.8033591076237,
            "rating_q975": 1370.648399141583,
            "rating_q025": 1354.9583190736644
        },
        "claude-3-5-sonnet-20240620": {
            "rating": 1362.6935804036925,
            "rating_q975": 1369.2549434792566,
            "rating_q025": 1356.1322173281285
        },
        "qwen3-30b-a3b": {
            "rating": 1359.9766931882018,
            "rating_q975": 1368.1530454146935,
            "rating_q025": 1351.8003409617102
        },
        "deepseek-v3": {
            "rating": 1358.5131041014897,
            "rating_q975": 1368.0165849759273,
            "rating_q025": 1349.009623227052
        },
        "llama-3.1-405b-instruct-bf16": {
            "rating": 1357.7006587629498,
            "rating_q975": 1364.744768588944,
            "rating_q025": 1350.6565489369557
        },
        "yi-lightning": {
            "rating": 1357.0970297609256,
            "rating_q975": 1366.6953429739772,
            "rating_q025": 1347.498716547874
        },
        "claude-3-5-haiku-20241022": {
            "rating": 1352.2837436856512,
            "rating_q975": 1357.9857878923303,
            "rating_q025": 1346.581699478972
        },
        "gemini-2.0-flash-lite-preview-02-05": {
            "rating": 1351.8506851157053,
            "rating_q975": 1360.6937467338341,
            "rating_q025": 1343.0076234975766
        },
        "gemini-1.5-pro-002": {
            "rating": 1351.1659339086043,
            "rating_q975": 1357.6285678641134,
            "rating_q025": 1344.7032999530952
        },
        "llama-4-maverick-17b-128e-instruct": {
            "rating": 1350.4004751025166,
            "rating_q975": 1357.4742503347948,
            "rating_q025": 1343.3266998702384
        },
        "magistral-medium-2506": {
            "rating": 1350.2625306691937,
            "rating_q975": 1361.8690636681697,
            "rating_q025": 1338.6559976702176
        },
        "llama-3.1-405b-instruct-fp8": {
            "rating": 1349.478725412139,
            "rating_q975": 1356.2557324534598,
            "rating_q025": 1342.7017183708183
        },
        "llama-4-scout-17b-16e-instruct": {
            "rating": 1347.0806765696125,
            "rating_q975": 1354.9086483200845,
            "rating_q025": 1339.2527048191405
        },
        "step-1o-turbo-202506": {
            "rating": 1346.2663832611147,
            "rating_q975": 1359.4758407873385,
            "rating_q025": 1333.056925734891
        },
        "gpt-4o-2024-05-13": {
            "rating": 1344.7925689097833,
            "rating_q975": 1350.8296208716145,
            "rating_q025": 1338.7555169479522
        },
        "athene-v2-chat": {
            "rating": 1343.1240242340234,
            "rating_q975": 1352.0302472082783,
            "rating_q025": 1334.2178012597685
        },
        "step-2-16k-exp-202412": {
            "rating": 1342.8111578689777,
            "rating_q975": 1361.3259138536466,
            "rating_q025": 1324.2964018843088
        },
        "qwen2.5-plus-1127": {
            "rating": 1341.6940130985372,
            "rating_q975": 1354.6463134005628,
            "rating_q025": 1328.7417127965116
        },
        "gpt-oss-20b": {
            "rating": 1338.9718856590357,
            "rating_q975": 1351.416928159037,
            "rating_q025": 1326.5268431590343
        },
        "hunyuan-large-2025-02-10": {
            "rating": 1336.4041152067084,
            "rating_q975": 1359.188337003164,
            "rating_q025": 1313.6198934102529
        },
        "gpt-4.1-nano-2025-04-14": {
            "rating": 1335.9117540644072,
            "rating_q975": 1353.1392021460142,
            "rating_q025": 1318.6843059828002
        },
        "gemma-3-12b-it": {
            "rating": 1335.4941157937196,
            "rating_q975": 1356.3716562502166,
            "rating_q025": 1314.6165753372227
        },
        "gpt-4o-2024-08-06": {
            "rating": 1334.97668839778,
            "rating_q975": 1342.395508767509,
            "rating_q025": 1327.557868028051
        },
        "llama-3.3-70b-instruct": {
            "rating": 1334.69488751966,
            "rating_q975": 1340.664681139343,
            "rating_q025": 1328.7250938999769
        },
        "deepseek-v2.5-1210": {
            "rating": 1334.6815610244487,
            "rating_q975": 1350.8895201016787,
            "rating_q025": 1318.4736019472186
        },
        "mistral-small-3.1-24b-instruct-2503": {
            "rating": 1333.5010389061354,
            "rating_q975": 1340.9145103445799,
            "rating_q025": 1326.0875674676909
        },
        "mistral-large-2407": {
            "rating": 1330.3930255714822,
            "rating_q975": 1337.774849240572,
            "rating_q025": 1323.0112019023925
        },
        "grok-2-2024-08-13": {
            "rating": 1327.3286208823642,
            "rating_q975": 1333.7969501810746,
            "rating_q025": 1320.8602915836539
        },
        "deepseek-v2.5": {
            "rating": 1327.0613516792464,
            "rating_q975": 1336.1544583027596,
            "rating_q025": 1317.9682450557332
        },
        "gemini-1.5-pro-001": {
            "rating": 1326.5503205833902,
            "rating_q975": 1333.5029075193993,
            "rating_q025": 1319.5977336473811
        },
        "qwen-max-0919": {
            "rating": 1326.2793911546796,
            "rating_q975": 1337.4143399927584,
            "rating_q025": 1315.1444423166008
        },
        "gpt-4-turbo-2024-04-09": {
            "rating": 1325.5202054861204,
            "rating_q975": 1332.1731420760393,
            "rating_q025": 1318.8672688962015
        },
        "gemini-advanced-0514": {
            "rating": 1324.5513258522199,
            "rating_q975": 1333.0996905340005,
            "rating_q025": 1316.0029611704392
        },
        "qwen2.5-72b-instruct": {
            "rating": 1324.0776035595259,
            "rating_q975": 1331.59150716816,
            "rating_q025": 1316.5636999508918
        },
        "glm-4-plus": {
            "rating": 1323.2573115230591,
            "rating_q975": 1332.6561478004587,
            "rating_q025": 1313.8584752456595
        },
        "llama-3.1-nemotron-70b-instruct": {
            "rating": 1323.1862176859704,
            "rating_q975": 1339.8686009763626,
            "rating_q025": 1306.5038343955782
        },
        "claude-3-opus-20240229": {
            "rating": 1322.1244772406762,
            "rating_q975": 1327.609920322764,
            "rating_q025": 1316.6390341585884
        },
        "glm-4-plus-0111": {
            "rating": 1321.881351162739,
            "rating_q975": 1339.5047853203087,
            "rating_q025": 1304.2579170051695
        },
        "hunyuan-large-vision": {
            "rating": 1321.6977113463886,
            "rating_q975": 1338.3941947583598,
            "rating_q025": 1305.0012279344173
        },
        "gpt-4-1106-preview": {
            "rating": 1320.8643474687728,
            "rating_q975": 1327.6654784764028,
            "rating_q025": 1314.063216461143
        },
        "hunyuan-standard-2025-02-10": {
            "rating": 1320.7980249939078,
            "rating_q975": 1344.2868738504014,
            "rating_q025": 1297.3091761374142
        },
        "mistral-large-2411": {
            "rating": 1320.5859324459564,
            "rating_q975": 1328.9706089975994,
            "rating_q025": 1312.2012558943134
        },
        "athene-70b-0725": {
            "rating": 1320.4131816596214,
            "rating_q975": 1330.3301575840212,
            "rating_q025": 1310.4962057352216
        },
        "gemma-3n-e4b-it": {
            "rating": 1317.7435242760594,
            "rating_q975": 1326.9099407130043,
            "rating_q025": 1308.5771078391144
        },
        "gpt-4o-mini-2024-07-18": {
            "rating": 1317.6289237338046,
            "rating_q975": 1323.6871449954133,
            "rating_q025": 1311.570702472196
        },
        "qwen2.5-coder-32b-instruct": {
            "rating": 1315.5758038748113,
            "rating_q975": 1335.2406497373079,
            "rating_q025": 1295.9109580123147
        },
        "gpt-4-0125-preview": {
            "rating": 1315.1188975541227,
            "rating_q975": 1322.0761231609606,
            "rating_q025": 1308.1616719472847
        },
        "grok-2-mini-2024-08-13": {
            "rating": 1311.3249306048378,
            "rating_q975": 1318.1370879095998,
            "rating_q025": 1304.5127733000759
        },
        "llama-3.1-70b-instruct": {
            "rating": 1311.200367689004,
            "rating_q975": 1318.0214988075325,
            "rating_q025": 1304.3792365704755
        },
        "amazon-nova-pro-v1.0": {
            "rating": 1310.710534271302,
            "rating_q975": 1319.3383443378993,
            "rating_q025": 1302.0827242047048
        },
        "gemini-1.5-flash-002": {
            "rating": 1310.3136430625923,
            "rating_q975": 1318.2874648200443,
            "rating_q025": 1302.3398213051403
        },
        "gpt-4-0314": {
            "rating": 1308.6827670469802,
            "rating_q975": 1317.4016657874188,
            "rating_q025": 1299.9638683065416
        },
        "llama-3-70b-instruct": {
            "rating": 1306.0514852799004,
            "rating_q975": 1312.4769179272632,
            "rating_q025": 1299.6260526325375
        },
        "gpt-4-0613": {
            "rating": 1295.7090733383948,
            "rating_q975": 1303.100251886479,
            "rating_q025": 1288.3178947903104
        },
        "olmo-2-0325-32b-instruct": {
            "rating": 1294.9748988193041,
            "rating_q975": 1318.6670599468066,
            "rating_q025": 1271.2827376918017
        },
        "deepseek-coder-v2": {
            "rating": 1293.4094592266647,
            "rating_q975": 1305.0270478921873,
            "rating_q025": 1281.791870561142
        },
        "jamba-1.5-large": {
            "rating": 1291.4561298530539,
            "rating_q975": 1305.2545437953847,
            "rating_q025": 1277.657715910723
        },
        "mistral-small-24b-instruct-2501": {
            "rating": 1290.963210210315,
            "rating_q975": 1302.6495598861616,
            "rating_q025": 1279.2768605344686
        },
        "gemini-1.5-flash-001": {
            "rating": 1288.7935248925571,
            "rating_q975": 1295.9191727545933,
            "rating_q025": 1281.667877030521
        },
        "llama-3.1-tulu-3-70b": {
            "rating": 1287.4951626488314,
            "rating_q975": 1310.8574515742641,
            "rating_q025": 1264.1328737233987
        },
        "phi-4": {
            "rating": 1286.7769521341256,
            "rating_q975": 1295.9693165402311,
            "rating_q025": 1277.58458772802
        },
        "gemma-2-27b-it": {
            "rating": 1284.085408819971,
            "rating_q975": 1290.0736956184348,
            "rating_q025": 1278.0971220215072
        },
        "claude-3-sonnet-20240229": {
            "rating": 1281.2068432060544,
            "rating_q975": 1288.1769934837423,
            "rating_q025": 1274.2366929283664
        },
        "gemma-3-4b-it": {
            "rating": 1280.8384526046543,
            "rating_q975": 1301.495564075017,
            "rating_q025": 1260.1813411342916
        },
        "glm-4-0520": {
            "rating": 1280.4210534781696,
            "rating_q975": 1293.8556586599523,
            "rating_q025": 1266.986448296387
        },
        "qwen2-72b-instruct": {
            "rating": 1279.8220645097538,
            "rating_q975": 1288.3042152105118,
            "rating_q025": 1271.3399138089958
        },
        "reka-core-20240904": {
            "rating": 1277.9042138514192,
            "rating_q975": 1292.0191857114519,
            "rating_q025": 1263.7892419913865
        },
        "nemotron-4-340b-instruct": {
            "rating": 1276.6288973307157,
            "rating_q975": 1287.5167097706171,
            "rating_q025": 1265.7410848908144
        },
        "gemma-2-9b-it-simpo": {
            "rating": 1274.815447861657,
            "rating_q975": 1288.5593377579144,
            "rating_q025": 1261.0715579653997
        },
        "amazon-nova-lite-v1.0": {
            "rating": 1274.6041605118216,
            "rating_q975": 1284.645493524403,
            "rating_q025": 1264.5628274992403
        },
        "hunyuan-standard-256k": {
            "rating": 1273.914045821029,
            "rating_q975": 1302.3046879152473,
            "rating_q025": 1245.5234037268108
        },
        "llama-3.1-nemotron-51b-instruct": {
            "rating": 1273.8809377354905,
            "rating_q975": 1296.2618483549186,
            "rating_q025": 1251.5000271160625
        },
        "c4ai-aya-expanse-32b": {
            "rating": 1272.1531123661816,
            "rating_q975": 1281.1993921545632,
            "rating_q025": 1263.1068325778
        },
        "mistral-large-2402": {
            "rating": 1268.493711350909,
            "rating_q975": 1276.5739650240687,
            "rating_q025": 1260.4134576777494
        },
        "command-r-plus-08-2024": {
            "rating": 1266.6279356503032,
            "rating_q975": 1279.7650878748993,
            "rating_q025": 1253.4907834257071
        },
        "reka-flash-20240904": {
            "rating": 1266.3934873071767,
            "rating_q975": 1280.2171027410639,
            "rating_q025": 1252.5698718732895
        },
        "claude-3-haiku-20240307": {
            "rating": 1264.957626959296,
            "rating_q975": 1271.3769704866543,
            "rating_q025": 1258.5382834319378
        },
        "ministral-8b-2410": {
            "rating": 1262.8657455246434,
            "rating_q975": 1283.0180420522202,
            "rating_q025": 1242.7134489970667
        },
        "gemini-1.5-flash-8b-001": {
            "rating": 1262.799685010491,
            "rating_q975": 1270.8149964151683,
            "rating_q025": 1254.7843736058137
        },
        "qwen1.5-110b-chat": {
            "rating": 1259.5867858006368,
            "rating_q975": 1269.770207731044,
            "rating_q025": 1249.4033638702297
        },
        "command-r-08-2024": {
            "rating": 1259.1767646322323,
            "rating_q975": 1271.9570867476675,
            "rating_q025": 1246.3964425167972
        },
        "gemma-2-9b-it": {
            "rating": 1257.2068065564458,
            "rating_q975": 1264.1015537338913,
            "rating_q025": 1250.3120593790004
        },
        "internlm2_5-20b-chat": {
            "rating": 1253.511476506862,
            "rating_q975": 1267.9233567066565,
            "rating_q025": 1239.0995963070675
        },
        "amazon-nova-micro-v1.0": {
            "rating": 1253.2884682724634,
            "rating_q975": 1263.179596047743,
            "rating_q025": 1243.397340497184
        },
        "command-r-plus": {
            "rating": 1253.0653863330147,
            "rating_q975": 1260.4653473176515,
            "rating_q025": 1245.6654253483778
        },
        "mixtral-8x22b-instruct-v0.1": {
            "rating": 1250.7793325847183,
            "rating_q975": 1258.8462894596803,
            "rating_q025": 1242.7123757097563
        },
        "qwen1.5-72b-chat": {
            "rating": 1247.3988172482093,
            "rating_q975": 1256.1844764867353,
            "rating_q025": 1238.6131580096833
        },
        "granite-3.1-8b-instruct": {
            "rating": 1247.2047833076758,
            "rating_q975": 1271.2994039646208,
            "rating_q025": 1223.110162650731
        },
        "jamba-1.5-mini": {
            "rating": 1243.4395588017824,
            "rating_q975": 1257.6888276500526,
            "rating_q025": 1229.190289953512
        },
        "llama-3-8b-instruct": {
            "rating": 1240.8649357532277,
            "rating_q975": 1247.8132752285474,
            "rating_q025": 1233.916596277908
        },
        "mistral-medium": {
            "rating": 1238.8226554690073,
            "rating_q975": 1248.48327820613,
            "rating_q025": 1229.1620327318844
        },
        "reka-flash-21b-20240226-online": {
            "rating": 1238.6763137801115,
            "rating_q975": 1251.105474853866,
            "rating_q025": 1226.247152706357
        },
        "llama-3.1-8b-instruct": {
            "rating": 1237.061122804087,
            "rating_q975": 1244.3169155110995,
            "rating_q025": 1229.8053300970746
        },
        "yi-1.5-34b-chat": {
            "rating": 1236.9704626059424,
            "rating_q975": 1246.874563383649,
            "rating_q025": 1227.0663618282358
        },
        "reka-flash-21b-20240226": {
            "rating": 1235.2807363168704,
            "rating_q975": 1245.5909599532358,
            "rating_q025": 1224.970512680505
        },
        "gemini-pro": {
            "rating": 1234.532370073357,
            "rating_q975": 1253.963605598177,
            "rating_q025": 1215.101134548537
        },
        "gpt-3.5-turbo-0125": {
            "rating": 1234.2749774257486,
            "rating_q975": 1241.7669276921047,
            "rating_q025": 1226.7830271593925
        },
        "gpt-3.5-turbo-1106": {
            "rating": 1233.9664720367655,
            "rating_q975": 1247.6780740358217,
            "rating_q025": 1220.2548700377092
        },
        "granite-3.1-2b-instruct": {
            "rating": 1233.2156296174694,
            "rating_q975": 1257.703923703521,
            "rating_q025": 1208.7273355314178
        },
        "dbrx-instruct-preview": {
            "rating": 1232.3460007319695,
            "rating_q975": 1242.991736978373,
            "rating_q025": 1221.700264485566
        },
        "qwen1.5-32b-chat": {
            "rating": 1231.4064645405306,
            "rating_q975": 1242.3283121298782,
            "rating_q025": 1220.484616951183
        },
        "granite-3.0-8b-instruct": {
            "rating": 1231.1634103075194,
            "rating_q975": 1250.7331649111336,
            "rating_q025": 1211.5936557039051
        },
        "gemini-pro-dev-api": {
            "rating": 1230.34049076835,
            "rating_q975": 1243.0165566978471,
            "rating_q025": 1217.664424838853
        },
        "c4ai-aya-expanse-8b": {
            "rating": 1227.236388736399,
            "rating_q975": 1241.4510478463549,
            "rating_q025": 1213.0217296264432
        },
        "zephyr-orpo-141b-A35b-v0.1": {
            "rating": 1225.6545863474494,
            "rating_q975": 1246.165464171204,
            "rating_q025": 1205.1437085236948
        },
        "phi-3-medium-4k-instruct": {
            "rating": 1224.3678373826249,
            "rating_q975": 1234.0477647030543,
            "rating_q025": 1214.6879100621954
        },
        "mixtral-8x7b-instruct-v0.1": {
            "rating": 1223.995368662453,
            "rating_q975": 1231.5258596419048,
            "rating_q025": 1216.4648776830013
        },
        "llama-3.1-tulu-3-8b": {
            "rating": 1222.556549182491,
            "rating_q975": 1248.200079768008,
            "rating_q025": 1196.9130185969739
        },
        "command-r": {
            "rating": 1218.1731730898257,
            "rating_q975": 1226.6127927582622,
            "rating_q025": 1209.7335534213892
        },
        "phi-3-small-8k-instruct": {
            "rating": 1208.4768415332737,
            "rating_q975": 1219.9558741002204,
            "rating_q025": 1196.997808966327
        },
        "llama-3.2-3b-instruct": {
            "rating": 1205.7884891300123,
            "rating_q975": 1220.8788071058564,
            "rating_q025": 1190.6981711541682
        },
        "qwen1.5-14b-chat": {
            "rating": 1204.4297214526857,
            "rating_q975": 1217.0368222785703,
            "rating_q025": 1191.8226206268012
        },
        "starling-lm-7b-beta": {
            "rating": 1203.2614501852445,
            "rating_q975": 1215.8713606328515,
            "rating_q025": 1190.6515397376374
        },
        "tulu-2-dpo-70b": {
            "rating": 1201.51509002811,
            "rating_q975": 1219.1439669760284,
            "rating_q025": 1183.8862130801917
        },
        "gemma-1.1-7b-it": {
            "rating": 1201.4461285600514,
            "rating_q975": 1211.6133751713305,
            "rating_q025": 1191.2788819487723
        },
        "snowflake-arctic-instruct": {
            "rating": 1197.7096696980616,
            "rating_q975": 1208.3613315051396,
            "rating_q025": 1187.0580078909836
        },
        "phi-3-mini-4k-instruct-june-2024": {
            "rating": 1197.1776890979368,
            "rating_q975": 1210.0401641204667,
            "rating_q025": 1184.3152140754069
        },
        "yi-34b-chat": {
            "rating": 1192.7471806172039,
            "rating_q975": 1204.6399338844788,
            "rating_q025": 1180.854427349929
        },
        "openchat-3.5-0106": {
            "rating": 1191.9441243200285,
            "rating_q975": 1204.340919547078,
            "rating_q025": 1179.547329092979
        },
        "gemma-2-2b-it": {
            "rating": 1191.725306226301,
            "rating_q975": 1199.300213801402,
            "rating_q025": 1184.1503986512
        },
        "openhermes-2.5-mistral-7b": {
            "rating": 1190.0286943574874,
            "rating_q975": 1208.671783006216,
            "rating_q025": 1171.385605708759
        },
        "granite-3.0-2b-instruct": {
            "rating": 1187.769375644441,
            "rating_q975": 1207.0917392354759,
            "rating_q025": 1168.447012053406
        },
        "deepseek-llm-67b-chat": {
            "rating": 1184.8959425584014,
            "rating_q975": 1204.8216954276522,
            "rating_q025": 1164.9701896891506
        },
        "wizardlm-70b": {
            "rating": 1181.8393581412997,
            "rating_q975": 1198.2096506369721,
            "rating_q025": 1165.4690656456273
        },
        "starling-lm-7b-alpha": {
            "rating": 1181.3960097524564,
            "rating_q975": 1195.5611747698454,
            "rating_q025": 1167.2308447350674
        },
        "mpt-30b-chat": {
            "rating": 1181.1625609450546,
            "rating_q975": 1211.1771854813837,
            "rating_q025": 1151.1479364087254
        },
        "qwq-32b-preview": {
            "rating": 1176.159133071616,
            "rating_q975": 1201.0764199096993,
            "rating_q025": 1151.2418462335327
        },
        "codellama-70b-instruct": {
            "rating": 1174.9959828367123,
            "rating_q975": 1211.9151456074856,
            "rating_q025": 1138.076820065939
        },
        "openchat-3.5": {
            "rating": 1173.642453247671,
            "rating_q975": 1190.551049132357,
            "rating_q025": 1156.733857362985
        },
        "llama-2-70b-chat": {
            "rating": 1171.3038303782469,
            "rating_q975": 1180.3421839916361,
            "rating_q025": 1162.2654767648576
        },
        "mistral-7b-instruct-v0.2": {
            "rating": 1171.0963796194178,
            "rating_q975": 1182.077309262945,
            "rating_q025": 1160.1154499758907
        },
        "vicuna-33b": {
            "rating": 1170.228902568564,
            "rating_q975": 1181.4627387913645,
            "rating_q025": 1158.9950663457637
        },
        "phi-3-mini-4k-instruct": {
            "rating": 1170.1923445869675,
            "rating_q975": 1181.6685318062841,
            "rating_q025": 1158.7161573676508
        },
        "solar-10.7b-instruct-v1.0": {
            "rating": 1164.8142530597963,
            "rating_q975": 1186.5154401955647,
            "rating_q025": 1143.113065924028
        },
        "gemma-7b-it": {
            "rating": 1162.9500819573316,
            "rating_q975": 1178.2484483692795,
            "rating_q025": 1147.6517155453837
        },
        "dolphin-2.2.1-mistral-7b": {
            "rating": 1162.152585995247,
            "rating_q975": 1193.7399246350042,
            "rating_q025": 1130.5652473554896
        },
        "palm-2": {
            "rating": 1161.1496094739468,
            "rating_q975": 1177.8093355913268,
            "rating_q025": 1144.489883356567
        },
        "smollm2-1.7b-instruct": {
            "rating": 1159.2490874949945,
            "rating_q975": 1191.25045573763,
            "rating_q025": 1127.2477192523588
        },
        "qwen1.5-7b-chat": {
            "rating": 1154.0556549066214,
            "rating_q975": 1171.6306875437729,
            "rating_q025": 1136.48062226947
        },
        "llama-2-13b-chat": {
            "rating": 1152.7975145562225,
            "rating_q975": 1164.5766065472865,
            "rating_q025": 1141.0184225651585
        },
        "llama-3.2-1b-instruct": {
            "rating": 1151.1355184980916,
            "rating_q975": 1166.1852668453273,
            "rating_q025": 1136.085770150856
        },
        "llama2-70b-steerlm-chat": {
            "rating": 1150.7262882891746,
            "rating_q975": 1173.502503052132,
            "rating_q025": 1127.9500735262172
        },
        "phi-3-mini-128k-instruct": {
            "rating": 1148.0018777870464,
            "rating_q975": 1160.382304962351,
            "rating_q025": 1135.6214506117417
        },
        "qwen-14b-chat": {
            "rating": 1147.2956444432693,
            "rating_q975": 1167.7898819867405,
            "rating_q025": 1126.8014068997982
        },
        "gemma-1.1-2b-it": {
            "rating": 1143.1483263374107,
            "rating_q975": 1157.4417036169366,
            "rating_q025": 1128.8549490578848
        },
        "codellama-34b-instruct": {
            "rating": 1140.04881672986,
            "rating_q975": 1156.1280373135207,
            "rating_q025": 1123.9695961461991
        },
        "nous-hermes-2-mixtral-8x7b-dpo": {
            "rating": 1138.100302222911,
            "rating_q975": 1156.8725691460056,
            "rating_q025": 1119.3280352998165
        },
        "vicuna-13b": {
            "rating": 1136.7006633241658,
            "rating_q975": 1148.6265088942757,
            "rating_q025": 1124.774817754056
        },
        "zephyr-7b-alpha": {
            "rating": 1133.3275973340988,
            "rating_q975": 1166.5086388789666,
            "rating_q025": 1100.146555789231
        },
        "zephyr-7b-beta": {
            "rating": 1130.4807103895082,
            "rating_q975": 1145.9626413499218,
            "rating_q025": 1114.9987794290946
        },
        "mistral-7b-instruct": {
            "rating": 1126.9428096135287,
            "rating_q975": 1143.4676381992163,
            "rating_q025": 1110.417981027841
        },
        "wizardlm-13b": {
            "rating": 1123.5643191044962,
            "rating_q975": 1141.9031731140535,
            "rating_q025": 1105.225465094939
        },
        "stripedhyena-nous-7b": {
            "rating": 1117.7029724865465,
            "rating_q975": 1135.9348756883915,
            "rating_q025": 1099.4710692847016
        },
        "guanaco-33b": {
            "rating": 1111.9074559225155,
            "rating_q975": 1140.3514223267127,
            "rating_q025": 1083.4634895183183
        },
        "llama-2-7b-chat": {
            "rating": 1111.2830309930403,
            "rating_q975": 1123.6264771334545,
            "rating_q025": 1098.939584852626
        },
        "gemma-2b-it": {
            "rating": 1109.063971157998,
            "rating_q975": 1129.295402390535,
            "rating_q025": 1088.8325399254609
        },
        "vicuna-7b": {
            "rating": 1106.2962015527796,
            "rating_q975": 1124.9800049924077,
            "rating_q025": 1087.6123981131516
        },
        "qwen1.5-4b-chat": {
            "rating": 1093.4243465134196,
            "rating_q975": 1109.5851727277795,
            "rating_q025": 1077.2635202990596
        },
        "olmo-7b-instruct": {
            "rating": 1083.059006159947,
            "rating_q975": 1101.8199946257193,
            "rating_q025": 1064.2980176941749
        },
        "chatglm3-6b": {
            "rating": 1077.4341915283462,
            "rating_q975": 1098.7662415270759,
            "rating_q025": 1056.1021415296166
        },
        "gpt4all-13b-snoozy": {
            "rating": 1074.4129732173487,
            "rating_q975": 1108.470226306426,
            "rating_q025": 1040.3557201282715
        },
        "chatglm2-6b": {
            "rating": 1041.2260385577613,
            "rating_q975": 1070.6815340065,
            "rating_q025": 1011.7705431090226
        },
        "koala-13b": {
            "rating": 1037.285840620339,
            "rating_q975": 1057.2445882440352,
            "rating_q025": 1017.3270929966428
        },
        "mpt-7b-chat": {
            "rating": 1036.1253989928682,
            "rating_q975": 1060.371688154332,
            "rating_q025": 1011.8791098314042
        },
        "oasst-pythia-12b": {
            "rating": 1025.252835485081,
            "rating_q975": 1045.967531491238,
            "rating_q025": 1004.5381394789241
        },
        "RWKV-4-Raven-14B": {
            "rating": 1013.8258460773927,
            "rating_q975": 1036.5117719611455,
            "rating_q025": 991.13992019364
        },
        "alpaca-13b": {
            "rating": 1010.7994045304399,
            "rating_q975": 1032.6262046441673,
            "rating_q025": 988.9726044167127
        },
        "chatglm-6b": {
            "rating": 990.8119267700255,
            "rating_q975": 1014.6925126829937,
            "rating_q025": 966.9313408570573
        },
        "dolly-v2-12b": {
            "rating": 962.9206503183486,
            "rating_q975": 990.066441791001,
            "rating_q025": 935.7748588456963
        },
        "stablelm-tuned-alpha-7b": {
            "rating": 949.3014513529977,
            "rating_q975": 976.4887551420758,
            "rating_q025": 922.1141475639196
        },
        "fastchat-t5-3b": {
            "rating": 938.8405113804577,
            "rating_q975": 962.1924430875974,
            "rating_q025": 915.4885796733179
        },
        "llama-13b": {
            "rating": 906.9686399068569,
            "rating_q975": 941.5832041171748,
            "rating_q025": 872.354075696539
        }
    },
    "if": {
        "claude-opus-4-1-20250805-thinking-16k": {
            "rating": 1458.7922715221664,
            "rating_q975": 1466.4242882713356,
            "rating_q025": 1451.1602547729972
        },
        "claude-sonnet-4-5-20250929-thinking-32k": {
            "rating": 1457.1690074266003,
            "rating_q975": 1467.5130455620667,
            "rating_q025": 1446.8249692911338
        },
        "claude-opus-4-1-20250805": {
            "rating": 1447.3321545731008,
            "rating_q975": 1454.2264704340807,
            "rating_q025": 1440.4378387121208
        },
        "gemini-2.5-pro": {
            "rating": 1442.1695402803387,
            "rating_q975": 1448.2340344263628,
            "rating_q025": 1436.1050461343145
        },
        "claude-sonnet-4-5-20250929": {
            "rating": 1440.3546944555676,
            "rating_q975": 1454.185797851022,
            "rating_q025": 1426.5235910601132
        },
        "claude-opus-4-20250514-thinking-16k": {
            "rating": 1437.881964340413,
            "rating_q975": 1444.7409817301145,
            "rating_q025": 1431.0229469507117
        },
        "gpt-4.5-preview-2025-02-27": {
            "rating": 1430.4424459737209,
            "rating_q975": 1438.6183463173834,
            "rating_q025": 1422.2665456300583
        },
        "glm-4.6": {
            "rating": 1425.0554298609238,
            "rating_q975": 1436.1164179179625,
            "rating_q025": 1413.9944418038851
        },
        "qwen3-max-preview": {
            "rating": 1424.6512438043835,
            "rating_q975": 1432.5014977861001,
            "rating_q025": 1416.800989822667
        },
        "claude-haiku-4-5-20251001": {
            "rating": 1416.2065940822981,
            "rating_q975": 1427.1176343121322,
            "rating_q025": 1405.295553852464
        },
        "chatgpt-4o-latest-20250326": {
            "rating": 1415.6278999695555,
            "rating_q975": 1421.424456884982,
            "rating_q025": 1409.831343054129
        },
        "deepseek-v3.1-thinking": {
            "rating": 1415.052300989797,
            "rating_q975": 1426.11308152065,
            "rating_q025": 1403.991520458944
        },
        "qwen3-235b-a22b-instruct-2507": {
            "rating": 1412.379029840646,
            "rating_q975": 1419.2901129955192,
            "rating_q025": 1405.4679466857726
        },
        "qwen3-max-2025-09-23": {
            "rating": 1411.6189139198855,
            "rating_q975": 1422.9502523057777,
            "rating_q025": 1400.2875755339933
        },
        "deepseek-v3.2-exp-thinking": {
            "rating": 1411.3248181064712,
            "rating_q975": 1422.844549630558,
            "rating_q025": 1399.8050865823843
        },
        "gpt-5-high": {
            "rating": 1411.2195396830784,
            "rating_q975": 1418.8383131232695,
            "rating_q025": 1403.6007662428874
        },
        "deepseek-v3.1-terminus-thinking": {
            "rating": 1410.9444182376112,
            "rating_q975": 1430.884647036837,
            "rating_q025": 1391.0041894383855
        },
        "gpt-5-chat": {
            "rating": 1410.7447113374892,
            "rating_q975": 1418.1441063360403,
            "rating_q025": 1403.3453163389381
        },
        "claude-sonnet-4-20250514-thinking-32k": {
            "rating": 1409.1576338290736,
            "rating_q975": 1416.0779543985013,
            "rating_q025": 1402.2373132596458
        },
        "qwen3-vl-235b-a22b-instruct": {
            "rating": 1408.4433869332279,
            "rating_q975": 1420.1634507769904,
            "rating_q025": 1396.7233230894653
        },
        "claude-opus-4-20250514": {
            "rating": 1407.201498251252,
            "rating_q975": 1413.6795365874943,
            "rating_q025": 1400.7234599150095
        },
        "glm-4.5": {
            "rating": 1404.146243722776,
            "rating_q975": 1412.0679480200554,
            "rating_q025": 1396.2245394254967
        },
        "gemini-2.5-flash-preview-09-2025": {
            "rating": 1402.8909813874664,
            "rating_q975": 1412.4606664931378,
            "rating_q025": 1393.321296281795
        },
        "grok-3-preview-02-24": {
            "rating": 1402.2630436533186,
            "rating_q975": 1408.7327283874904,
            "rating_q025": 1395.7933589191468
        },
        "claude-3-7-sonnet-20250219-thinking-32k": {
            "rating": 1401.6980369663722,
            "rating_q975": 1408.0033738804873,
            "rating_q025": 1395.3927000522572
        },
        "deepseek-v3.1": {
            "rating": 1400.277972937509,
            "rating_q975": 1410.11323273578,
            "rating_q025": 1390.442713139238
        },
        "o3-2025-04-16": {
            "rating": 1400.087895549323,
            "rating_q975": 1405.8651360460044,
            "rating_q025": 1394.3106550526418
        },
        "o1-2024-12-17": {
            "rating": 1399.2962711593034,
            "rating_q975": 1405.5733571280562,
            "rating_q025": 1393.0191851905506
        },
        "grok-4-fast": {
            "rating": 1399.0302845993963,
            "rating_q975": 1413.4270483043529,
            "rating_q025": 1384.6335208944397
        },
        "gemini-2.5-flash": {
            "rating": 1398.6638491349534,
            "rating_q975": 1404.567925284972,
            "rating_q025": 1392.7597729849347
        },
        "mistral-medium-2508": {
            "rating": 1395.8724528507178,
            "rating_q975": 1403.2239665933653,
            "rating_q025": 1388.5209391080703
        },
        "gpt-4.1-2025-04-14": {
            "rating": 1395.8343802885677,
            "rating_q975": 1401.8029369552955,
            "rating_q025": 1389.8658236218398
        },
        "grok-4-0709": {
            "rating": 1394.6778902764152,
            "rating_q975": 1401.4162943109304,
            "rating_q025": 1387.9394862418999
        },
        "deepseek-v3.1-terminus": {
            "rating": 1390.3403199035363,
            "rating_q975": 1408.2554469999325,
            "rating_q025": 1372.42519280714
        },
        "deepseek-r1": {
            "rating": 1389.451501219082,
            "rating_q975": 1396.7608200086624,
            "rating_q025": 1382.1421824295016
        },
        "qwen3-235b-a22b-thinking-2507": {
            "rating": 1387.5190377909269,
            "rating_q975": 1399.923610185383,
            "rating_q025": 1375.1144653964707
        },
        "longcat-flash-chat": {
            "rating": 1387.0731580310132,
            "rating_q975": 1397.8139704317798,
            "rating_q025": 1376.3323456302467
        },
        "deepseek-r1-0528": {
            "rating": 1386.964751281057,
            "rating_q975": 1396.37815097372,
            "rating_q025": 1377.551351588394
        },
        "claude-sonnet-4-20250514": {
            "rating": 1385.5089521400666,
            "rating_q975": 1392.0828995792253,
            "rating_q025": 1378.935004700908
        },
        "kimi-k2-0905-preview": {
            "rating": 1382.9532516882439,
            "rating_q975": 1394.581823118761,
            "rating_q025": 1371.3246802577269
        },
        "qwen3-vl-235b-a22b-thinking": {
            "rating": 1378.4276025902434,
            "rating_q975": 1390.7608306507439,
            "rating_q025": 1366.094374529743
        },
        "qwen3-coder-480b-a35b-instruct": {
            "rating": 1378.2432861423247,
            "rating_q975": 1386.239766591932,
            "rating_q025": 1370.2468056927173
        },
        "qwen3-next-80b-a3b-instruct": {
            "rating": 1377.21719859418,
            "rating_q975": 1385.5750545112028,
            "rating_q025": 1368.8593426771572
        },
        "qwen3-235b-a22b-no-thinking": {
            "rating": 1375.0333663743274,
            "rating_q975": 1381.824029991153,
            "rating_q025": 1368.2427027575018
        },
        "o1-preview": {
            "rating": 1373.719529404017,
            "rating_q975": 1380.3436771016072,
            "rating_q025": 1367.095381706427
        },
        "hunyuan-t1-20250711": {
            "rating": 1373.5596042742247,
            "rating_q975": 1391.0322586346701,
            "rating_q025": 1356.0869499137793
        },
        "gpt-5-mini-high": {
            "rating": 1373.4889295243192,
            "rating_q975": 1381.6586626763908,
            "rating_q025": 1365.3191963722477
        },
        "deepseek-v3-0324": {
            "rating": 1371.588421167274,
            "rating_q975": 1377.4594996479054,
            "rating_q025": 1365.7173426866425
        },
        "kimi-k2-0711-preview": {
            "rating": 1370.3496788441867,
            "rating_q975": 1378.0061652014151,
            "rating_q025": 1362.6931924869582
        },
        "mai-1-preview": {
            "rating": 1368.4426115308968,
            "rating_q975": 1377.6525117444962,
            "rating_q025": 1359.2327113172973
        },
        "gemini-2.5-flash-lite-preview-06-17-thinking": {
            "rating": 1367.8798967664288,
            "rating_q975": 1374.8927308763339,
            "rating_q025": 1360.8670626565238
        },
        "gemini-2.5-flash-lite-preview-09-2025-no-thinking": {
            "rating": 1365.6601844227735,
            "rating_q975": 1375.0580367158423,
            "rating_q025": 1356.2623321297046
        },
        "gpt-4.1-mini-2025-04-14": {
            "rating": 1365.3148259065047,
            "rating_q975": 1371.7867765066105,
            "rating_q025": 1358.8428753063988
        },
        "claude-3-5-sonnet-20241022": {
            "rating": 1364.20481805394,
            "rating_q975": 1368.3745169928422,
            "rating_q025": 1360.0351191150378
        },
        "o4-mini-2025-04-16": {
            "rating": 1363.8975875715512,
            "rating_q975": 1369.9358670842619,
            "rating_q025": 1357.8593080588405
        },
        "qwen3-30b-a3b-instruct-2507": {
            "rating": 1363.6593503197064,
            "rating_q975": 1371.6157263370205,
            "rating_q025": 1355.7029743023922
        },
        "o3-mini-high": {
            "rating": 1359.9631892026666,
            "rating_q975": 1367.4309007609725,
            "rating_q025": 1352.4954776443608
        },
        "glm-4.5-air": {
            "rating": 1358.580229753584,
            "rating_q975": 1365.8962085962507,
            "rating_q025": 1351.2642509109173
        },
        "mistral-medium-2505": {
            "rating": 1358.400147506779,
            "rating_q975": 1365.4879051617813,
            "rating_q025": 1351.3123898517765
        },
        "grok-3-mini-high": {
            "rating": 1357.9432066264526,
            "rating_q975": 1366.972150595361,
            "rating_q025": 1348.9142626575442
        },
        "qwen3-next-80b-a3b-thinking": {
            "rating": 1354.3820191167313,
            "rating_q975": 1364.2953636114157,
            "rating_q025": 1344.4686746220468
        },
        "qwen3-235b-a22b": {
            "rating": 1353.3240412690423,
            "rating_q975": 1361.0039267570933,
            "rating_q025": 1345.6441557809912
        },
        "grok-3-mini-beta": {
            "rating": 1351.5409560321182,
            "rating_q975": 1359.5052849570282,
            "rating_q025": 1343.5766271072082
        },
        "qwen2.5-max": {
            "rating": 1351.3036330597702,
            "rating_q975": 1357.142769278694,
            "rating_q025": 1345.4644968408463
        },
        "hunyuan-turbos-20250416": {
            "rating": 1347.7265937224652,
            "rating_q975": 1359.2488208739144,
            "rating_q025": 1336.204366571016
        },
        "minimax-m1": {
            "rating": 1344.8211844445423,
            "rating_q975": 1351.4790661233794,
            "rating_q025": 1338.163302765705
        },
        "llama-3.1-nemotron-ultra-253b-v1": {
            "rating": 1344.2046508353735,
            "rating_q975": 1365.6574508084627,
            "rating_q025": 1322.7518508622843
        },
        "hunyuan-turbos-20250226": {
            "rating": 1342.3492042648145,
            "rating_q975": 1360.0640990756742,
            "rating_q025": 1324.6343094539548
        },
        "gemma-3-27b-it": {
            "rating": 1339.1512254470274,
            "rating_q975": 1344.7778331011195,
            "rating_q025": 1333.5246177929353
        },
        "o3-mini": {
            "rating": 1338.4297429238309,
            "rating_q975": 1343.407098857707,
            "rating_q025": 1333.4523869899547
        },
        "step-3": {
            "rating": 1338.3938805729833,
            "rating_q975": 1352.7575833397761,
            "rating_q025": 1324.0301778061905
        },
        "deepseek-v3": {
            "rating": 1337.3918758990867,
            "rating_q975": 1344.0528505926043,
            "rating_q025": 1330.7309012055691
        },
        "command-a-03-2025": {
            "rating": 1336.0379373343078,
            "rating_q975": 1341.4857501531876,
            "rating_q025": 1330.590124515428
        },
        "glm-4.5v": {
            "rating": 1334.6705763838645,
            "rating_q975": 1350.6957161896496,
            "rating_q025": 1318.6454365780794
        },
        "amazon-nova-experimental-chat-10-09": {
            "rating": 1333.69522058528,
            "rating_q975": 1347.6943742109243,
            "rating_q025": 1319.6960669596356
        },
        "gemini-1.5-pro-002": {
            "rating": 1332.8442785867096,
            "rating_q975": 1337.519662868425,
            "rating_q025": 1328.1688943049942
        },
        "mistral-small-2506": {
            "rating": 1332.682581813923,
            "rating_q975": 1341.4941537367642,
            "rating_q025": 1323.8710098910817
        },
        "claude-3-5-sonnet-20240620": {
            "rating": 1328.8246679056954,
            "rating_q975": 1333.6630937404693,
            "rating_q025": 1323.9862420709214
        },
        "qwen-plus-0125": {
            "rating": 1326.3975949797414,
            "rating_q975": 1338.4023061258056,
            "rating_q025": 1314.3928838336772
        },
        "gemini-2.0-flash-lite-preview-02-05": {
            "rating": 1326.382809110936,
            "rating_q975": 1332.5359489325733,
            "rating_q025": 1320.2296692892987
        },
        "o1-mini": {
            "rating": 1326.0175725232232,
            "rating_q975": 1330.991636897747,
            "rating_q025": 1321.0435081486994
        },
        "qwen3-32b": {
            "rating": 1325.2298406963205,
            "rating_q975": 1344.147302782466,
            "rating_q025": 1306.3123786101748
        },
        "gpt-5-nano-high": {
            "rating": 1320.8992897175165,
            "rating_q975": 1334.1053471319788,
            "rating_q025": 1307.6932323030542
        },
        "qwq-32b": {
            "rating": 1320.0113163230337,
            "rating_q975": 1326.9592213473004,
            "rating_q025": 1313.063411298767
        },
        "llama-3.3-nemotron-49b-super-v1": {
            "rating": 1319.5302309976119,
            "rating_q975": 1338.834147208659,
            "rating_q025": 1300.2263147865647
        },
        "gpt-4o-2024-05-13": {
            "rating": 1318.113439598434,
            "rating_q975": 1322.7931572357916,
            "rating_q025": 1313.4337219610766
        },
        "nvidia-llama-3.3-nemotron-super-49b-v1.5": {
            "rating": 1317.1616278021077,
            "rating_q975": 1336.6068182103122,
            "rating_q025": 1297.716437393903
        },
        "gpt-oss-120b": {
            "rating": 1317.0164902411875,
            "rating_q975": 1324.547739152939,
            "rating_q025": 1309.4852413294361
        },
        "gemma-3-12b-it": {
            "rating": 1316.609196243929,
            "rating_q975": 1332.8202764451094,
            "rating_q025": 1300.3981160427488
        },
        "ling-flash-2.0": {
            "rating": 1314.1069044328635,
            "rating_q975": 1327.6401563469967,
            "rating_q025": 1300.5736525187303
        },
        "ring-flash-2.0": {
            "rating": 1313.4494479922782,
            "rating_q975": 1326.9271821549496,
            "rating_q025": 1299.9717138296069
        },
        "glm-4-plus-0111": {
            "rating": 1311.0414290054036,
            "rating_q975": 1323.3861400138544,
            "rating_q025": 1298.6967179969529
        },
        "gpt-4o-2024-08-06": {
            "rating": 1310.9111457570316,
            "rating_q975": 1316.4260818856808,
            "rating_q025": 1305.3962096283824
        },
        "step-2-16k-exp-202412": {
            "rating": 1309.455386641644,
            "rating_q975": 1321.7876744828138,
            "rating_q025": 1297.1230988004743
        },
        "hunyuan-large-2025-02-10": {
            "rating": 1309.2338312793272,
            "rating_q975": 1324.7304678428488,
            "rating_q025": 1293.7371947158056
        },
        "llama-4-maverick-17b-128e-instruct": {
            "rating": 1308.6865807620256,
            "rating_q975": 1315.1061093680812,
            "rating_q025": 1302.26705215597
        },
        "deepseek-v2.5-1210": {
            "rating": 1308.3872814810056,
            "rating_q975": 1319.4903381361185,
            "rating_q025": 1297.2842248258928
        },
        "hunyuan-turbo-0110": {
            "rating": 1307.7424242323987,
            "rating_q975": 1325.7025923547108,
            "rating_q025": 1289.7822561100866
        },
        "gemini-advanced-0514": {
            "rating": 1307.3494015187846,
            "rating_q975": 1313.8863319548243,
            "rating_q025": 1300.8124710827449
        },
        "llama-3.1-405b-instruct-bf16": {
            "rating": 1306.9985989137497,
            "rating_q975": 1311.9836809932287,
            "rating_q025": 1302.0135168342706
        },
        "qwen3-30b-a3b": {
            "rating": 1306.9829550915865,
            "rating_q975": 1314.7390937674631,
            "rating_q025": 1299.22681641571
        },
        "llama-3.1-405b-instruct-fp8": {
            "rating": 1306.9298756528356,
            "rating_q975": 1311.9257696110656,
            "rating_q025": 1301.9339816946056
        },
        "step-1o-turbo-202506": {
            "rating": 1306.0810084049733,
            "rating_q975": 1318.4246853590344,
            "rating_q025": 1293.7373314509123
        },
        "claude-3-opus-20240229": {
            "rating": 1305.3641624685781,
            "rating_q975": 1309.5358356278975,
            "rating_q025": 1301.1924893092587
        },
        "grok-2-2024-08-13": {
            "rating": 1305.2776644567027,
            "rating_q975": 1309.9678740296918,
            "rating_q025": 1300.5874548837137
        },
        "claude-3-5-haiku-20241022": {
            "rating": 1304.8183455525614,
            "rating_q975": 1309.3388645946295,
            "rating_q025": 1300.2978265104932
        },
        "yi-lightning": {
            "rating": 1303.4358216990613,
            "rating_q975": 1310.1299922280118,
            "rating_q025": 1296.7416511701108
        },
        "gemini-1.5-pro-001": {
            "rating": 1302.2128808235898,
            "rating_q975": 1307.733866377198,
            "rating_q025": 1296.6918952699816
        },
        "magistral-medium-2506": {
            "rating": 1299.8513749188735,
            "rating_q975": 1310.5360569813981,
            "rating_q025": 1289.1666928563488
        },
        "athene-v2-chat": {
            "rating": 1296.4465471208914,
            "rating_q975": 1302.5395180650462,
            "rating_q025": 1290.3535761767366
        },
        "qwen-max-0919": {
            "rating": 1295.434595152481,
            "rating_q975": 1303.186772841322,
            "rating_q025": 1287.6824174636401
        },
        "gpt-4-turbo-2024-04-09": {
            "rating": 1295.1466226738685,
            "rating_q975": 1300.3754919294906,
            "rating_q025": 1289.9177534182463
        },
        "gpt-4.1-nano-2025-04-14": {
            "rating": 1294.9964793403137,
            "rating_q975": 1307.4207233779384,
            "rating_q025": 1282.572235302689
        },
        "llama-4-scout-17b-16e-instruct": {
            "rating": 1294.3191285146816,
            "rating_q975": 1301.5963265467412,
            "rating_q025": 1287.0419304826219
        },
        "glm-4-plus": {
            "rating": 1294.2863500479964,
            "rating_q975": 1300.960058169303,
            "rating_q025": 1287.6126419266898
        },
        "mistral-large-2407": {
            "rating": 1291.7856726266382,
            "rating_q975": 1297.167903642853,
            "rating_q025": 1286.4034416104234
        },
        "mistral-small-3.1-24b-instruct-2503": {
            "rating": 1291.1296176932622,
            "rating_q975": 1298.221569899986,
            "rating_q025": 1284.0376654865383
        },
        "qwen2.5-plus-1127": {
            "rating": 1290.410850576825,
            "rating_q975": 1299.2956831226743,
            "rating_q025": 1281.5260180309756
        },
        "gpt-4-1106-preview": {
            "rating": 1288.2220464181828,
            "rating_q975": 1293.566714224233,
            "rating_q025": 1282.8773786121326
        },
        "mistral-large-2411": {
            "rating": 1287.8062015626151,
            "rating_q975": 1293.6197858191554,
            "rating_q025": 1281.9926173060749
        },
        "gpt-4o-mini-2024-07-18": {
            "rating": 1286.9783036049403,
            "rating_q975": 1291.4782234001063,
            "rating_q025": 1282.4783838097742
        },
        "llama-3.3-70b-instruct": {
            "rating": 1285.8644661410817,
            "rating_q975": 1290.6492552247907,
            "rating_q025": 1281.0796770573727
        },
        "qwen2.5-72b-instruct": {
            "rating": 1285.7860413449403,
            "rating_q975": 1291.1523603530065,
            "rating_q025": 1280.419722336874
        },
        "deepseek-v2.5": {
            "rating": 1284.8487546363272,
            "rating_q975": 1291.3426732179657,
            "rating_q025": 1278.3548360546886
        },
        "gemini-1.5-flash-002": {
            "rating": 1284.8394272628632,
            "rating_q975": 1290.4642636649266,
            "rating_q025": 1279.2145908607997
        },
        "hunyuan-large-vision": {
            "rating": 1283.118455369845,
            "rating_q975": 1299.5639458779358,
            "rating_q025": 1266.672964861754
        },
        "gpt-4-0125-preview": {
            "rating": 1282.0799037527277,
            "rating_q975": 1287.5601036426287,
            "rating_q025": 1276.5997038628266
        },
        "gemma-3n-e4b-it": {
            "rating": 1279.0938312909461,
            "rating_q975": 1287.5364124628204,
            "rating_q025": 1270.6512501190718
        },
        "grok-2-mini-2024-08-13": {
            "rating": 1277.0265141324776,
            "rating_q975": 1282.003979103736,
            "rating_q025": 1272.0490491612193
        },
        "hunyuan-standard-2025-02-10": {
            "rating": 1275.8992845242171,
            "rating_q975": 1291.0960599919765,
            "rating_q025": 1260.7025090564578
        },
        "gpt-oss-20b": {
            "rating": 1275.8551606558117,
            "rating_q975": 1287.9440587674699,
            "rating_q025": 1263.7662625441535
        },
        "llama-3.1-nemotron-70b-instruct": {
            "rating": 1274.7429161446594,
            "rating_q975": 1285.4627372352575,
            "rating_q025": 1264.0230950540613
        },
        "gpt-4-0314": {
            "rating": 1272.904283865254,
            "rating_q975": 1279.9727743644935,
            "rating_q025": 1265.8357933660145
        },
        "amazon-nova-pro-v1.0": {
            "rating": 1269.6176317617048,
            "rating_q975": 1275.6788321971026,
            "rating_q025": 1263.5564313263071
        },
        "athene-70b-0725": {
            "rating": 1269.5447455936753,
            "rating_q975": 1277.066194555292,
            "rating_q025": 1262.0232966320586
        },
        "llama-3.1-tulu-3-70b": {
            "rating": 1266.4010217236282,
            "rating_q975": 1281.7492163671284,
            "rating_q025": 1251.052827080128
        },
        "llama-3.1-70b-instruct": {
            "rating": 1266.3238492101923,
            "rating_q975": 1271.3180529386675,
            "rating_q025": 1261.329645481717
        },
        "gpt-4-0613": {
            "rating": 1264.7698322330666,
            "rating_q975": 1270.5806681000693,
            "rating_q025": 1258.958996366064
        },
        "gemma-3-4b-it": {
            "rating": 1262.9850159986227,
            "rating_q975": 1279.2602076168912,
            "rating_q025": 1246.7098243803541
        },
        "gemma-2-27b-it": {
            "rating": 1261.6082713223204,
            "rating_q975": 1266.0219752697974,
            "rating_q025": 1257.1945673748435
        },
        "jamba-1.5-large": {
            "rating": 1259.0003136098544,
            "rating_q975": 1269.5370039585166,
            "rating_q025": 1248.4636232611922
        },
        "claude-3-sonnet-20240229": {
            "rating": 1258.6109868675903,
            "rating_q975": 1263.9922678859002,
            "rating_q025": 1253.2297058492804
        },
        "qwen2.5-coder-32b-instruct": {
            "rating": 1256.8663087187547,
            "rating_q975": 1268.6358703958015,
            "rating_q025": 1245.0967470417079
        },
        "gemini-1.5-flash-001": {
            "rating": 1256.4892768009474,
            "rating_q975": 1262.197177058813,
            "rating_q025": 1250.781376543082
        },
        "reka-core-20240904": {
            "rating": 1254.1964327526662,
            "rating_q975": 1264.1600178526473,
            "rating_q025": 1244.232847652685
        },
        "llama-3.1-nemotron-51b-instruct": {
            "rating": 1253.3904348204564,
            "rating_q975": 1267.8794643223177,
            "rating_q025": 1238.9014053185952
        },
        "nemotron-4-340b-instruct": {
            "rating": 1251.3218011721967,
            "rating_q975": 1259.2994951291312,
            "rating_q025": 1243.3441072152623
        },
        "llama-3-70b-instruct": {
            "rating": 1249.6333342926669,
            "rating_q975": 1254.6600484798698,
            "rating_q025": 1244.606620105464
        },
        "mistral-small-24b-instruct-2501": {
            "rating": 1248.6655864709019,
            "rating_q975": 1256.7098360390323,
            "rating_q025": 1240.6213369027714
        },
        "glm-4-0520": {
            "rating": 1248.0740597583267,
            "rating_q975": 1258.1977726359653,
            "rating_q025": 1237.9503468806881
        },
        "command-r-plus-08-2024": {
            "rating": 1245.8922699978311,
            "rating_q975": 1255.0254914814511,
            "rating_q025": 1236.7590485142111
        },
        "gemma-2-9b-it-simpo": {
            "rating": 1242.6586854063407,
            "rating_q975": 1252.5376955551947,
            "rating_q025": 1232.7796752574868
        },
        "deepseek-coder-v2": {
            "rating": 1242.256323568921,
            "rating_q975": 1251.1036566662833,
            "rating_q025": 1233.4089904715588
        },
        "c4ai-aya-expanse-32b": {
            "rating": 1241.5042311209047,
            "rating_q975": 1247.9463251835227,
            "rating_q025": 1235.0621370582867
        },
        "reka-flash-20240904": {
            "rating": 1240.4486600609353,
            "rating_q975": 1250.3484395761704,
            "rating_q025": 1230.5488805457
        },
        "phi-4": {
            "rating": 1238.645708629857,
            "rating_q975": 1245.0417716776176,
            "rating_q025": 1232.2496455820963
        },
        "amazon-nova-lite-v1.0": {
            "rating": 1237.79460795218,
            "rating_q975": 1244.644560431239,
            "rating_q025": 1230.9446554731212
        },
        "claude-3-haiku-20240307": {
            "rating": 1235.9517820286294,
            "rating_q975": 1240.9863971209686,
            "rating_q025": 1230.9171669362902
        },
        "hunyuan-standard-256k": {
            "rating": 1235.700285374462,
            "rating_q975": 1252.4048311868996,
            "rating_q025": 1218.9957395620245
        },
        "gemma-2-9b-it": {
            "rating": 1235.4164276637332,
            "rating_q975": 1240.3749108101995,
            "rating_q025": 1230.457944517267
        },
        "qwen2-72b-instruct": {
            "rating": 1233.7099918973936,
            "rating_q975": 1240.2828727733208,
            "rating_q025": 1227.1371110214664
        },
        "command-r-plus": {
            "rating": 1232.5794607177434,
            "rating_q975": 1238.4110556736407,
            "rating_q025": 1226.747865761846
        },
        "gemini-1.5-flash-8b-001": {
            "rating": 1231.9451509148564,
            "rating_q975": 1237.6185285247566,
            "rating_q025": 1226.2717733049562
        },
        "mistral-large-2402": {
            "rating": 1228.3180000085954,
            "rating_q975": 1234.7272647042469,
            "rating_q025": 1221.908735312944
        },
        "command-r-08-2024": {
            "rating": 1227.2097162475998,
            "rating_q975": 1236.253670807855,
            "rating_q025": 1218.1657616873445
        },
        "olmo-2-0325-32b-instruct": {
            "rating": 1223.7808158902121,
            "rating_q975": 1240.8693937026064,
            "rating_q025": 1206.6922380778178
        },
        "amazon-nova-micro-v1.0": {
            "rating": 1209.9418231988086,
            "rating_q975": 1216.7630959654982,
            "rating_q025": 1203.120550432119
        },
        "qwen1.5-110b-chat": {
            "rating": 1209.4004649224285,
            "rating_q975": 1217.2886536021292,
            "rating_q025": 1201.5122762427277
        },
        "mixtral-8x22b-instruct-v0.1": {
            "rating": 1205.892579420954,
            "rating_q975": 1212.1937645986745,
            "rating_q025": 1199.5913942432335
        },
        "gemini-pro": {
            "rating": 1205.3829567829741,
            "rating_q975": 1221.910067346647,
            "rating_q025": 1188.8558462193012
        },
        "ministral-8b-2410": {
            "rating": 1204.0762730598103,
            "rating_q975": 1216.6853947271868,
            "rating_q025": 1191.4671513924338
        },
        "llama-3.1-tulu-3-8b": {
            "rating": 1203.8078190101332,
            "rating_q975": 1219.241215172889,
            "rating_q025": 1188.3744228473774
        },
        "gpt-3.5-turbo-0125": {
            "rating": 1202.5588994009256,
            "rating_q975": 1208.7076112812774,
            "rating_q025": 1196.4101875205738
        },
        "mistral-medium": {
            "rating": 1202.4002514902868,
            "rating_q975": 1210.4282679374094,
            "rating_q025": 1194.3722350431642
        },
        "qwen1.5-72b-chat": {
            "rating": 1202.3210895854295,
            "rating_q975": 1209.5138019023348,
            "rating_q025": 1195.1283772685242
        },
        "c4ai-aya-expanse-8b": {
            "rating": 1197.3679344351244,
            "rating_q975": 1206.7415099130149,
            "rating_q025": 1187.994358957234
        },
        "jamba-1.5-mini": {
            "rating": 1196.992006611704,
            "rating_q975": 1207.4649683079185,
            "rating_q025": 1186.5190449154895
        },
        "gemini-pro-dev-api": {
            "rating": 1196.6196441196694,
            "rating_q975": 1207.0454307464183,
            "rating_q025": 1186.1938574929204
        },
        "reka-flash-21b-20240226-online": {
            "rating": 1191.9788709571503,
            "rating_q975": 1202.103845847023,
            "rating_q025": 1181.8538960672777
        },
        "command-r": {
            "rating": 1189.9718890644792,
            "rating_q975": 1196.516670593835,
            "rating_q025": 1183.4271075351235
        },
        "granite-3.1-8b-instruct": {
            "rating": 1186.9721102808526,
            "rating_q975": 1203.3246478803662,
            "rating_q025": 1170.619572681339
        },
        "llama-3.1-8b-instruct": {
            "rating": 1186.205571582418,
            "rating_q975": 1191.467020278033,
            "rating_q025": 1180.9441228868031
        },
        "llama-3-8b-instruct": {
            "rating": 1183.7045916917016,
            "rating_q975": 1189.1123346837064,
            "rating_q025": 1178.2968486996967
        },
        "zephyr-orpo-141b-A35b-v0.1": {
            "rating": 1183.321650803989,
            "rating_q975": 1198.7558944173425,
            "rating_q025": 1167.8874071906357
        },
        "gpt-3.5-turbo-1106": {
            "rating": 1183.121182628186,
            "rating_q975": 1195.1223999844642,
            "rating_q025": 1171.1199652719079
        },
        "reka-flash-21b-20240226": {
            "rating": 1182.9281566683283,
            "rating_q975": 1191.213546918681,
            "rating_q025": 1174.6427664179755
        },
        "yi-1.5-34b-chat": {
            "rating": 1180.6775718860501,
            "rating_q975": 1188.1924291813878,
            "rating_q025": 1173.1627145907125
        },
        "dbrx-instruct-preview": {
            "rating": 1177.2733099412037,
            "rating_q975": 1185.6179336904183,
            "rating_q025": 1168.928686191989
        },
        "qwen1.5-32b-chat": {
            "rating": 1175.87283218707,
            "rating_q975": 1184.2828922346569,
            "rating_q025": 1167.462772139483
        },
        "internlm2_5-20b-chat": {
            "rating": 1172.745721216245,
            "rating_q975": 1182.698876321886,
            "rating_q025": 1162.7925661106042
        },
        "mixtral-8x7b-instruct-v0.1": {
            "rating": 1170.738152805247,
            "rating_q975": 1176.799373694242,
            "rating_q025": 1164.676931916252
        },
        "phi-3-medium-4k-instruct": {
            "rating": 1169.1754597226904,
            "rating_q975": 1176.3680684397577,
            "rating_q025": 1161.9828510056232
        },
        "granite-3.1-2b-instruct": {
            "rating": 1165.4057845796315,
            "rating_q975": 1181.5464809100238,
            "rating_q025": 1149.2650882492392
        },
        "gemma-2-2b-it": {
            "rating": 1163.1654124022286,
            "rating_q975": 1168.5271131051431,
            "rating_q025": 1157.8037116993141
        },
        "tulu-2-dpo-70b": {
            "rating": 1162.2175850707797,
            "rating_q975": 1176.8441916396177,
            "rating_q025": 1147.5909785019417
        },
        "granite-3.0-8b-instruct": {
            "rating": 1161.7417832229235,
            "rating_q975": 1173.9152082237092,
            "rating_q025": 1149.5683582221377
        },
        "qwen1.5-14b-chat": {
            "rating": 1159.3628457775658,
            "rating_q975": 1169.2128878888611,
            "rating_q025": 1149.5128036662704
        },
        "wizardlm-70b": {
            "rating": 1153.7275291929489,
            "rating_q975": 1167.071266160358,
            "rating_q025": 1140.3837922255398
        },
        "qwq-32b-preview": {
            "rating": 1148.4395400948356,
            "rating_q975": 1164.3288500270833,
            "rating_q025": 1132.550230162588
        },
        "deepseek-llm-67b-chat": {
            "rating": 1146.7517730406666,
            "rating_q975": 1163.586209234874,
            "rating_q025": 1129.9173368464592
        },
        "phi-3-small-8k-instruct": {
            "rating": 1145.2232976127732,
            "rating_q975": 1153.775076488194,
            "rating_q025": 1136.6715187373525
        },
        "openchat-3.5-0106": {
            "rating": 1144.8634290934501,
            "rating_q975": 1155.2740737776955,
            "rating_q025": 1134.4527844092047
        },
        "yi-34b-chat": {
            "rating": 1143.634491653625,
            "rating_q975": 1153.2090150794597,
            "rating_q025": 1134.0599682277903
        },
        "gemma-1.1-7b-it": {
            "rating": 1143.0434510355167,
            "rating_q975": 1150.8419656774195,
            "rating_q025": 1135.244936393614
        },
        "openchat-3.5": {
            "rating": 1142.5480968203913,
            "rating_q975": 1156.6456378183102,
            "rating_q025": 1128.4505558224723
        },
        "snowflake-arctic-instruct": {
            "rating": 1142.456013682614,
            "rating_q975": 1150.78140233794,
            "rating_q025": 1134.1306250272878
        },
        "openhermes-2.5-mistral-7b": {
            "rating": 1142.1312861946365,
            "rating_q975": 1157.42542294631,
            "rating_q025": 1126.837149442963
        },
        "starling-lm-7b-beta": {
            "rating": 1139.6537849682431,
            "rating_q975": 1149.5990578558994,
            "rating_q025": 1129.7085120805868
        },
        "llama-3.2-3b-instruct": {
            "rating": 1138.8557730681573,
            "rating_q975": 1149.6688889564864,
            "rating_q025": 1128.0426571798282
        },
        "vicuna-33b": {
            "rating": 1129.3317074881925,
            "rating_q975": 1138.202907484297,
            "rating_q025": 1120.460507492088
        },
        "starling-lm-7b-alpha": {
            "rating": 1127.7109171097925,
            "rating_q975": 1139.079247107508,
            "rating_q025": 1116.342587112077
        },
        "llama-2-70b-chat": {
            "rating": 1126.6637065462482,
            "rating_q975": 1134.152297260003,
            "rating_q025": 1119.1751158324935
        },
        "mpt-30b-chat": {
            "rating": 1123.6915473085505,
            "rating_q975": 1144.7669039230786,
            "rating_q025": 1102.6161906940224
        },
        "falcon-180b-chat": {
            "rating": 1122.5997616970576,
            "rating_q975": 1151.3131720982594,
            "rating_q025": 1093.8863512958558
        },
        "granite-3.0-2b-instruct": {
            "rating": 1122.5550734995754,
            "rating_q975": 1134.8297952771777,
            "rating_q025": 1110.2803517219731
        },
        "dolphin-2.2.1-mistral-7b": {
            "rating": 1118.3955828237833,
            "rating_q975": 1142.897013391271,
            "rating_q025": 1093.8941522562957
        },
        "llama2-70b-steerlm-chat": {
            "rating": 1116.5116754704231,
            "rating_q975": 1134.8060211317122,
            "rating_q025": 1098.217329809134
        },
        "phi-3-mini-4k-instruct-june-2024": {
            "rating": 1115.697183320803,
            "rating_q975": 1125.232947977205,
            "rating_q025": 1106.1614186644013
        },
        "qwen1.5-7b-chat": {
            "rating": 1114.941693614886,
            "rating_q975": 1128.9494650353095,
            "rating_q025": 1100.9339221944624
        },
        "mistral-7b-instruct-v0.2": {
            "rating": 1114.6312816750042,
            "rating_q975": 1123.480195284411,
            "rating_q025": 1105.7823680655974
        },
        "wizardlm-13b": {
            "rating": 1113.2066980641607,
            "rating_q975": 1127.0642485934459,
            "rating_q025": 1099.3491475348756
        },
        "solar-10.7b-instruct-v1.0": {
            "rating": 1107.3887585357256,
            "rating_q975": 1125.8641625618416,
            "rating_q025": 1088.9133545096097
        },
        "qwen-14b-chat": {
            "rating": 1106.6701918914396,
            "rating_q975": 1123.0382885867962,
            "rating_q025": 1090.302095196083
        },
        "vicuna-13b": {
            "rating": 1105.8297593454292,
            "rating_q975": 1115.3004099990092,
            "rating_q025": 1096.3591086918493
        },
        "phi-3-mini-4k-instruct": {
            "rating": 1103.837261425606,
            "rating_q975": 1112.5331454273742,
            "rating_q025": 1095.1413774238376
        },
        "palm-2": {
            "rating": 1101.708504703835,
            "rating_q975": 1115.0589430231466,
            "rating_q025": 1088.3580663845232
        },
        "llama-2-13b-chat": {
            "rating": 1101.491783191962,
            "rating_q975": 1110.7418354411116,
            "rating_q025": 1092.2417309428124
        },
        "nous-hermes-2-mixtral-8x7b-dpo": {
            "rating": 1101.2897466856398,
            "rating_q975": 1117.5679412013753,
            "rating_q025": 1085.0115521699042
        },
        "smollm2-1.7b-instruct": {
            "rating": 1097.5279817620758,
            "rating_q975": 1118.5289924372269,
            "rating_q025": 1076.5269710869247
        },
        "codellama-34b-instruct": {
            "rating": 1094.032493880326,
            "rating_q975": 1106.9292910103015,
            "rating_q025": 1081.1356967503505
        },
        "gemma-7b-it": {
            "rating": 1091.9996195555227,
            "rating_q975": 1104.6842043844256,
            "rating_q025": 1079.3150347266198
        },
        "zephyr-7b-alpha": {
            "rating": 1090.873615766609,
            "rating_q975": 1115.3248284247131,
            "rating_q025": 1066.4224031085048
        },
        "phi-3-mini-128k-instruct": {
            "rating": 1090.7039253439993,
            "rating_q975": 1100.83552392396,
            "rating_q025": 1080.5723267640387
        },
        "codellama-70b-instruct": {
            "rating": 1087.4575567035226,
            "rating_q975": 1117.521304454198,
            "rating_q025": 1057.3938089528474
        },
        "gemma-1.1-2b-it": {
            "rating": 1085.9384240337272,
            "rating_q975": 1096.7560229263836,
            "rating_q025": 1075.1208251410708
        },
        "zephyr-7b-beta": {
            "rating": 1080.4068220810545,
            "rating_q975": 1093.0877501903517,
            "rating_q025": 1067.7258939717574
        },
        "stripedhyena-nous-7b": {
            "rating": 1079.9141632810263,
            "rating_q975": 1095.0840461610103,
            "rating_q025": 1064.7442804010423
        },
        "llama-3.2-1b-instruct": {
            "rating": 1079.4774874989512,
            "rating_q975": 1090.6679460280827,
            "rating_q025": 1068.2870289698196
        },
        "mistral-7b-instruct": {
            "rating": 1076.0065203268118,
            "rating_q975": 1089.5376064098255,
            "rating_q025": 1062.4754342437982
        },
        "vicuna-7b": {
            "rating": 1065.9620608005946,
            "rating_q975": 1080.0999966144257,
            "rating_q025": 1051.8241249867635
        },
        "llama-2-7b-chat": {
            "rating": 1060.7573326808165,
            "rating_q975": 1070.5018505424903,
            "rating_q025": 1051.0128148191427
        },
        "qwen1.5-4b-chat": {
            "rating": 1057.9683194299519,
            "rating_q975": 1070.8453968195754,
            "rating_q025": 1045.0912420403283
        },
        "gemma-2b-it": {
            "rating": 1057.0552044517103,
            "rating_q975": 1073.101746469637,
            "rating_q025": 1041.0086624337837
        },
        "guanaco-33b": {
            "rating": 1055.087533819606,
            "rating_q975": 1076.1917730002967,
            "rating_q025": 1033.9832946389154
        },
        "chatglm3-6b": {
            "rating": 1026.6075501574812,
            "rating_q975": 1044.220712191349,
            "rating_q025": 1008.9943881236134
        },
        "gpt4all-13b-snoozy": {
            "rating": 1026.035761196458,
            "rating_q975": 1050.9092076040652,
            "rating_q025": 1001.1623147888507
        },
        "olmo-7b-instruct": {
            "rating": 1023.9966108690037,
            "rating_q975": 1039.8683302733966,
            "rating_q025": 1008.1248914646108
        },
        "koala-13b": {
            "rating": 1015.0352400979962,
            "rating_q975": 1030.3481086527104,
            "rating_q025": 999.722371543282
        },
        "alpaca-13b": {
            "rating": 1007.12082548755,
            "rating_q975": 1023.354990635019,
            "rating_q025": 990.8866603400809
        },
        "mpt-7b-chat": {
            "rating": 996.9618285769536,
            "rating_q975": 1015.3492443339478,
            "rating_q025": 978.5744128199594
        },
        "oasst-pythia-12b": {
            "rating": 973.2412620305679,
            "rating_q975": 989.3265072690178,
            "rating_q025": 957.156016792118
        },
        "chatglm2-6b": {
            "rating": 971.6770383380565,
            "rating_q975": 994.3191549995634,
            "rating_q025": 949.0349216765496
        },
        "chatglm-6b": {
            "rating": 967.1836661513946,
            "rating_q975": 985.1491069055752,
            "rating_q025": 949.218225397214
        },
        "RWKV-4-Raven-14B": {
            "rating": 957.735103129643,
            "rating_q975": 974.6583264815512,
            "rating_q025": 940.8118797777348
        },
        "fastchat-t5-3b": {
            "rating": 944.0365196388177,
            "rating_q975": 962.6885497794638,
            "rating_q025": 925.3844894981717
        },
        "dolly-v2-12b": {
            "rating": 922.2344133110023,
            "rating_q975": 943.4145785361452,
            "rating_q025": 901.0542480858594
        },
        "stablelm-tuned-alpha-7b": {
            "rating": 899.2066382167715,
            "rating_q975": 919.5623719213177,
            "rating_q025": 878.8509045122253
        },
        "llama-13b": {
            "rating": 897.8860914219866,
            "rating_q975": 923.3001218827612,
            "rating_q025": 872.472060961212
        }
    },
    "industry_business_and_management_and_financial_operations": {
        "claude-opus-4-1-20250805-thinking-16k": {
            "rating": 1450.8565340287064,
            "rating_q975": 1459.9002105885531,
            "rating_q025": 1441.8128574688596
        },
        "chatgpt-4o-latest-20250326": {
            "rating": 1446.5287500465083,
            "rating_q975": 1454.505880927557,
            "rating_q025": 1438.5516191654597
        },
        "claude-sonnet-4-5-20250929": {
            "rating": 1445.2340612530543,
            "rating_q975": 1461.3115759495267,
            "rating_q025": 1429.1565465565818
        },
        "qwen3-max-preview": {
            "rating": 1443.3632325409897,
            "rating_q975": 1452.8685503969168,
            "rating_q025": 1433.8579146850625
        },
        "claude-opus-4-1-20250805": {
            "rating": 1440.064576542649,
            "rating_q975": 1448.2016999146033,
            "rating_q025": 1431.927453170695
        },
        "gpt-5-chat": {
            "rating": 1438.7657524235904,
            "rating_q975": 1447.8785079035347,
            "rating_q025": 1429.652996943646
        },
        "claude-sonnet-4-5-20250929-thinking-32k": {
            "rating": 1438.4434124803943,
            "rating_q975": 1451.21343475495,
            "rating_q025": 1425.6733902058386
        },
        "qwen3-vl-235b-a22b-instruct": {
            "rating": 1437.038985019001,
            "rating_q975": 1451.7005973004475,
            "rating_q025": 1422.3773727375547
        },
        "gemini-2.5-pro": {
            "rating": 1431.2641298784988,
            "rating_q975": 1438.6032211018312,
            "rating_q025": 1423.9250386551664
        },
        "qwen3-235b-a22b-instruct-2507": {
            "rating": 1430.6495516596858,
            "rating_q975": 1438.943807963141,
            "rating_q025": 1422.3552953562307
        },
        "o3-2025-04-16": {
            "rating": 1428.4367951348445,
            "rating_q975": 1435.8750180712686,
            "rating_q025": 1420.9985721984203
        },
        "gpt-4.5-preview-2025-02-27": {
            "rating": 1424.3111410704262,
            "rating_q975": 1439.8060925827633,
            "rating_q025": 1408.816189558089
        },
        "qwen3-max-2025-09-23": {
            "rating": 1420.1731881350654,
            "rating_q975": 1434.1559806606485,
            "rating_q025": 1406.1903956094823
        },
        "deepseek-v3.1-terminus-thinking": {
            "rating": 1416.5025448656918,
            "rating_q975": 1438.903360692729,
            "rating_q025": 1394.1017290386546
        },
        "gpt-5-high": {
            "rating": 1414.7921555697342,
            "rating_q975": 1424.320356255104,
            "rating_q025": 1405.2639548843645
        },
        "gpt-4.1-2025-04-14": {
            "rating": 1414.0812014310395,
            "rating_q975": 1421.7019736756702,
            "rating_q025": 1406.4604291864089
        },
        "deepseek-v3.1-thinking": {
            "rating": 1413.4582273893673,
            "rating_q975": 1427.0292998564073,
            "rating_q025": 1399.8871549223272
        },
        "deepseek-v3.1": {
            "rating": 1412.5803178275137,
            "rating_q975": 1424.7735057234331,
            "rating_q025": 1400.3871299315942
        },
        "claude-opus-4-20250514-thinking-16k": {
            "rating": 1412.0436580799478,
            "rating_q975": 1420.3983937143898,
            "rating_q025": 1403.6889224455058
        },
        "kimi-k2-0711-preview": {
            "rating": 1412.0178846971141,
            "rating_q975": 1421.4076704639988,
            "rating_q025": 1402.6280989302295
        },
        "claude-haiku-4-5-20251001": {
            "rating": 1410.9545170193785,
            "rating_q975": 1425.0721157501305,
            "rating_q025": 1396.8369182886265
        },
        "mistral-medium-2508": {
            "rating": 1410.6007054837335,
            "rating_q975": 1419.655009029548,
            "rating_q025": 1401.546401937919
        },
        "longcat-flash-chat": {
            "rating": 1410.5158827657249,
            "rating_q975": 1423.4947964095481,
            "rating_q025": 1397.5369691219016
        },
        "qwen3-235b-a22b-no-thinking": {
            "rating": 1409.7040925319334,
            "rating_q975": 1418.0409743873975,
            "rating_q025": 1401.3672106764693
        },
        "qwen3-next-80b-a3b-instruct": {
            "rating": 1408.4830846344707,
            "rating_q975": 1418.9538069380649,
            "rating_q025": 1398.0123623308766
        },
        "glm-4.5": {
            "rating": 1407.8322396516114,
            "rating_q975": 1417.467225590606,
            "rating_q025": 1398.1972537126169
        },
        "gemini-2.5-flash-preview-09-2025": {
            "rating": 1407.7295543720634,
            "rating_q975": 1419.9450922857113,
            "rating_q025": 1395.5140164584154
        },
        "claude-opus-4-20250514": {
            "rating": 1406.8246069256659,
            "rating_q975": 1414.7425477228878,
            "rating_q025": 1398.906666128444
        },
        "glm-4.6": {
            "rating": 1406.559126134595,
            "rating_q975": 1420.4393813918412,
            "rating_q025": 1392.678870877349
        },
        "hunyuan-turbos-20250416": {
            "rating": 1402.727232436629,
            "rating_q975": 1418.6331652240845,
            "rating_q025": 1386.8212996491736
        },
        "kimi-k2-0905-preview": {
            "rating": 1402.4855394749586,
            "rating_q975": 1416.680945477547,
            "rating_q025": 1388.2901334723701
        },
        "grok-4-fast": {
            "rating": 1402.4849746259806,
            "rating_q975": 1419.610481866819,
            "rating_q025": 1385.3594673851421
        },
        "deepseek-v3.2-exp-thinking": {
            "rating": 1402.27619531575,
            "rating_q975": 1416.308602849437,
            "rating_q025": 1388.2437877820632
        },
        "deepseek-r1-0528": {
            "rating": 1400.0000402735939,
            "rating_q975": 1411.3782303778473,
            "rating_q025": 1388.6218501693404
        },
        "qwen3-235b-a22b-thinking-2507": {
            "rating": 1399.6620067419947,
            "rating_q975": 1414.7526222649606,
            "rating_q025": 1384.5713912190288
        },
        "qwen3-30b-a3b-instruct-2507": {
            "rating": 1395.5676209834924,
            "rating_q975": 1405.2545657746507,
            "rating_q025": 1385.880676192334
        },
        "gemini-2.5-flash": {
            "rating": 1395.4650186784268,
            "rating_q975": 1402.7661720591796,
            "rating_q025": 1388.163865297674
        },
        "deepseek-v3.1-terminus": {
            "rating": 1393.2571641557115,
            "rating_q975": 1414.8122970441127,
            "rating_q025": 1371.7020312673103
        },
        "grok-3-preview-02-24": {
            "rating": 1392.561346357844,
            "rating_q975": 1402.3340349016964,
            "rating_q025": 1382.7886578139917
        },
        "grok-4-0709": {
            "rating": 1391.5667159836141,
            "rating_q975": 1399.9538711827327,
            "rating_q025": 1383.1795607844956
        },
        "qwen3-coder-480b-a35b-instruct": {
            "rating": 1391.3784731743817,
            "rating_q975": 1401.3307963798416,
            "rating_q025": 1381.426149968922
        },
        "claude-sonnet-4-20250514": {
            "rating": 1390.9279901858647,
            "rating_q975": 1399.0954847167127,
            "rating_q025": 1382.7604956550167
        },
        "deepseek-v3-0324": {
            "rating": 1388.6988973775062,
            "rating_q975": 1396.5094404533254,
            "rating_q025": 1380.888354301687
        },
        "deepseek-r1": {
            "rating": 1387.6845050723807,
            "rating_q975": 1401.4912238106826,
            "rating_q025": 1373.8777863340788
        },
        "claude-sonnet-4-20250514-thinking-32k": {
            "rating": 1386.4545707990271,
            "rating_q975": 1394.926345712745,
            "rating_q025": 1377.9827958853093
        },
        "mistral-medium-2505": {
            "rating": 1385.9071234151752,
            "rating_q975": 1394.8546568146708,
            "rating_q025": 1376.9595900156796
        },
        "qwen3-vl-235b-a22b-thinking": {
            "rating": 1385.8286764887694,
            "rating_q975": 1400.6622946610064,
            "rating_q025": 1370.9950583165323
        },
        "gpt-5-mini-high": {
            "rating": 1384.3052473241914,
            "rating_q975": 1394.3888815136636,
            "rating_q025": 1374.2216131347193
        },
        "gemma-3-12b-it": {
            "rating": 1383.8113693915734,
            "rating_q975": 1414.1985430445147,
            "rating_q025": 1353.424195738632
        },
        "gpt-4.1-mini-2025-04-14": {
            "rating": 1382.1628494176302,
            "rating_q975": 1390.4982526506174,
            "rating_q025": 1373.8274461846431
        },
        "o4-mini-2025-04-16": {
            "rating": 1381.7894093336913,
            "rating_q975": 1389.57397151379,
            "rating_q025": 1374.0048471535927
        },
        "mai-1-preview": {
            "rating": 1378.6716789171776,
            "rating_q975": 1389.2008685957487,
            "rating_q025": 1368.1424892386065
        },
        "gemma-3-27b-it": {
            "rating": 1377.8170625803166,
            "rating_q975": 1385.6548990577253,
            "rating_q025": 1369.979226102908
        },
        "o1-2024-12-17": {
            "rating": 1370.3873910524462,
            "rating_q975": 1381.8607376601503,
            "rating_q025": 1358.914044444742
        },
        "claude-3-7-sonnet-20250219-thinking-32k": {
            "rating": 1370.254484494133,
            "rating_q975": 1378.8939098419858,
            "rating_q025": 1361.6150591462804
        },
        "gemini-2.5-flash-lite-preview-09-2025-no-thinking": {
            "rating": 1368.8000720067464,
            "rating_q975": 1380.466690792887,
            "rating_q025": 1357.1334532206058
        },
        "hunyuan-turbos-20250226": {
            "rating": 1367.993650218377,
            "rating_q975": 1400.4153581601186,
            "rating_q025": 1335.5719422766356
        },
        "glm-4.5-air": {
            "rating": 1367.0574680579655,
            "rating_q975": 1376.0392137856572,
            "rating_q025": 1358.0757223302737
        },
        "qwen3-235b-a22b": {
            "rating": 1366.7363027350154,
            "rating_q975": 1376.414933048242,
            "rating_q025": 1357.057672421789
        },
        "qwen2.5-max": {
            "rating": 1365.8117353583464,
            "rating_q975": 1375.6879117619417,
            "rating_q025": 1355.935558954751
        },
        "gemini-2.5-flash-lite-preview-06-17-thinking": {
            "rating": 1363.358170072314,
            "rating_q975": 1372.0768773113307,
            "rating_q025": 1354.639462833297
        },
        "mistral-small-2506": {
            "rating": 1363.1197838377204,
            "rating_q975": 1374.3012100806218,
            "rating_q025": 1351.938357594819
        },
        "qwen3-next-80b-a3b-thinking": {
            "rating": 1362.807080586849,
            "rating_q975": 1374.9322370354655,
            "rating_q025": 1350.6819241382325
        },
        "hunyuan-t1-20250711": {
            "rating": 1360.487048772904,
            "rating_q975": 1382.0539153442735,
            "rating_q025": 1338.9201822015345
        },
        "claude-3-5-sonnet-20241022": {
            "rating": 1360.4104502532314,
            "rating_q975": 1366.650041967764,
            "rating_q025": 1354.1708585386987
        },
        "gemini-2.0-flash-lite-preview-02-05": {
            "rating": 1357.7253706941287,
            "rating_q975": 1369.3533830465483,
            "rating_q025": 1346.0973583417092
        },
        "o1-preview": {
            "rating": 1355.4539733344775,
            "rating_q975": 1365.7146664803445,
            "rating_q025": 1345.1932801886105
        },
        "step-3": {
            "rating": 1353.706283976966,
            "rating_q975": 1370.6716261513498,
            "rating_q025": 1336.7409418025823
        },
        "minimax-m1": {
            "rating": 1352.015770703925,
            "rating_q975": 1360.2142065672076,
            "rating_q025": 1343.8173348406424
        },
        "deepseek-v3": {
            "rating": 1349.6695620264218,
            "rating_q975": 1361.8779174575077,
            "rating_q025": 1337.4612065953359
        },
        "o3-mini-high": {
            "rating": 1348.9143537210662,
            "rating_q975": 1362.4641122905239,
            "rating_q025": 1335.3645951516085
        },
        "command-a-03-2025": {
            "rating": 1348.8717838030568,
            "rating_q975": 1356.1690823894603,
            "rating_q025": 1341.5744852166533
        },
        "hunyuan-turbo-0110": {
            "rating": 1347.4056629536597,
            "rating_q975": 1381.4757448629257,
            "rating_q025": 1313.3355810443936
        },
        "glm-4-plus-0111": {
            "rating": 1345.051995336873,
            "rating_q975": 1369.0651796007714,
            "rating_q025": 1321.0388110729746
        },
        "gpt-oss-120b": {
            "rating": 1343.674419647943,
            "rating_q975": 1352.9427182689676,
            "rating_q025": 1334.4061210269185
        },
        "llama-3.1-nemotron-ultra-253b-v1": {
            "rating": 1343.0169169348926,
            "rating_q975": 1377.646071020919,
            "rating_q025": 1308.3877628488663
        },
        "amazon-nova-experimental-chat-10-09": {
            "rating": 1342.94667845242,
            "rating_q975": 1361.0707796059767,
            "rating_q025": 1324.8225772988633
        },
        "ling-flash-2.0": {
            "rating": 1341.218765470436,
            "rating_q975": 1357.4565375854652,
            "rating_q025": 1324.9809933554068
        },
        "qwen-plus-0125": {
            "rating": 1340.9930933260566,
            "rating_q975": 1364.6558040627804,
            "rating_q025": 1317.3303825893329
        },
        "grok-3-mini-beta": {
            "rating": 1340.3600867524256,
            "rating_q975": 1350.585676260901,
            "rating_q025": 1330.1344972439501
        },
        "qwen3-32b": {
            "rating": 1337.237790042418,
            "rating_q975": 1364.0073766788037,
            "rating_q025": 1310.4682034060324
        },
        "grok-3-mini-high": {
            "rating": 1337.0300235365994,
            "rating_q975": 1348.5616333824032,
            "rating_q025": 1325.4984136907956
        },
        "glm-4.5v": {
            "rating": 1336.7718666780945,
            "rating_q975": 1356.4578904480218,
            "rating_q025": 1317.0858429081673
        },
        "gpt-5-nano-high": {
            "rating": 1334.787110894013,
            "rating_q975": 1350.6516016535895,
            "rating_q025": 1318.9226201344366
        },
        "qwq-32b": {
            "rating": 1334.3173109996198,
            "rating_q975": 1344.3297541289871,
            "rating_q025": 1324.3048678702526
        },
        "gemini-1.5-pro-002": {
            "rating": 1333.644438904924,
            "rating_q975": 1341.5289928106038,
            "rating_q025": 1325.7598849992444
        },
        "gemma-3-4b-it": {
            "rating": 1329.498078961767,
            "rating_q975": 1359.9600636463763,
            "rating_q025": 1299.0360942771579
        },
        "qwen3-30b-a3b": {
            "rating": 1327.5406183306263,
            "rating_q975": 1337.2238944106446,
            "rating_q025": 1317.857342250608
        },
        "o3-mini": {
            "rating": 1327.1905256536497,
            "rating_q975": 1334.4124193918049,
            "rating_q025": 1319.9686319154946
        },
        "claude-3-5-sonnet-20240620": {
            "rating": 1326.9929413312648,
            "rating_q975": 1334.990367049243,
            "rating_q025": 1318.9955156132864
        },
        "gpt-4o-2024-05-13": {
            "rating": 1324.088535970748,
            "rating_q975": 1331.2584321048857,
            "rating_q025": 1316.91863983661
        },
        "llama-4-scout-17b-16e-instruct": {
            "rating": 1322.7366475672839,
            "rating_q975": 1331.8779687996378,
            "rating_q025": 1313.59532633493
        },
        "nvidia-llama-3.3-nemotron-super-49b-v1.5": {
            "rating": 1322.526446111559,
            "rating_q975": 1345.5753624235795,
            "rating_q025": 1299.4775297995384
        },
        "gpt-4.1-nano-2025-04-14": {
            "rating": 1322.5159311524703,
            "rating_q975": 1344.7127187389676,
            "rating_q025": 1300.319143565973
        },
        "gpt-oss-20b": {
            "rating": 1321.516357035263,
            "rating_q975": 1335.754195787081,
            "rating_q025": 1307.2785182834448
        },
        "llama-4-maverick-17b-128e-instruct": {
            "rating": 1321.448129774071,
            "rating_q975": 1329.7455643635508,
            "rating_q025": 1313.1506951845913
        },
        "ring-flash-2.0": {
            "rating": 1319.4404330559973,
            "rating_q975": 1335.8055248002977,
            "rating_q025": 1303.075341311697
        },
        "claude-3-5-haiku-20241022": {
            "rating": 1319.3658995616952,
            "rating_q975": 1326.360226711947,
            "rating_q025": 1312.3715724114434
        },
        "yi-lightning": {
            "rating": 1319.2669840284736,
            "rating_q975": 1330.1191916847663,
            "rating_q025": 1308.414776372181
        },
        "llama-3.1-405b-instruct-fp8": {
            "rating": 1318.9937848126915,
            "rating_q975": 1327.1666236703384,
            "rating_q025": 1310.8209459550446
        },
        "gemini-advanced-0514": {
            "rating": 1318.774622421024,
            "rating_q975": 1329.0228523340727,
            "rating_q025": 1308.5263925079755
        },
        "gemma-3n-e4b-it": {
            "rating": 1318.7623044363395,
            "rating_q975": 1329.4179243501762,
            "rating_q025": 1308.1066845225027
        },
        "glm-4-plus": {
            "rating": 1318.701909758522,
            "rating_q975": 1329.7128978284877,
            "rating_q025": 1307.6909216885565
        },
        "llama-3.1-405b-instruct-bf16": {
            "rating": 1317.8061111013362,
            "rating_q975": 1326.6941951125318,
            "rating_q025": 1308.9180270901406
        },
        "llama-3.3-nemotron-49b-super-v1": {
            "rating": 1317.2546218414332,
            "rating_q975": 1352.5732402315198,
            "rating_q025": 1281.9360034513466
        },
        "o1-mini": {
            "rating": 1316.945019340285,
            "rating_q975": 1325.1764972511348,
            "rating_q025": 1308.713541429435
        },
        "grok-2-2024-08-13": {
            "rating": 1316.0825262900544,
            "rating_q975": 1323.8559657259686,
            "rating_q025": 1308.30908685414
        },
        "gemini-1.5-pro-001": {
            "rating": 1314.482486313092,
            "rating_q975": 1323.0216097739892,
            "rating_q025": 1305.943362852195
        },
        "step-1o-turbo-202506": {
            "rating": 1313.5224745487235,
            "rating_q975": 1329.22028160805,
            "rating_q025": 1297.824667489397
        },
        "qwen2.5-plus-1127": {
            "rating": 1312.5112523032835,
            "rating_q975": 1329.913624510927,
            "rating_q025": 1295.10888009564
        },
        "claude-3-opus-20240229": {
            "rating": 1311.6417701309,
            "rating_q975": 1318.2914838824613,
            "rating_q025": 1304.992056379339
        },
        "gpt-4o-mini-2024-07-18": {
            "rating": 1310.1847128041713,
            "rating_q975": 1317.584546506401,
            "rating_q025": 1302.7848791019417
        },
        "step-2-16k-exp-202412": {
            "rating": 1309.335865741944,
            "rating_q975": 1333.938843246284,
            "rating_q025": 1284.732888237604
        },
        "athene-v2-chat": {
            "rating": 1308.4567731399006,
            "rating_q975": 1319.4820055957036,
            "rating_q025": 1297.4315406840976
        },
        "llama-3.3-70b-instruct": {
            "rating": 1307.7355700766511,
            "rating_q975": 1315.1553103801753,
            "rating_q025": 1300.315829773127
        },
        "qwen-max-0919": {
            "rating": 1306.7511213004734,
            "rating_q975": 1319.4556869894227,
            "rating_q025": 1294.0465556115241
        },
        "gpt-4o-2024-08-06": {
            "rating": 1306.1540650898648,
            "rating_q975": 1314.957232720177,
            "rating_q025": 1297.3508974595527
        },
        "deepseek-v2.5-1210": {
            "rating": 1305.7155010761617,
            "rating_q975": 1327.2470555664652,
            "rating_q025": 1284.1839465858582
        },
        "grok-2-mini-2024-08-13": {
            "rating": 1301.7477134721303,
            "rating_q975": 1309.8940553854586,
            "rating_q025": 1293.601371558802
        },
        "athene-70b-0725": {
            "rating": 1301.6236751231295,
            "rating_q975": 1314.8442579572425,
            "rating_q025": 1288.4030922890165
        },
        "deepseek-v2.5": {
            "rating": 1300.9766647537617,
            "rating_q975": 1312.3126942681533,
            "rating_q025": 1289.64063523937
        },
        "gemini-1.5-flash-002": {
            "rating": 1299.5118999333386,
            "rating_q975": 1308.949456908803,
            "rating_q025": 1290.074342957874
        },
        "hunyuan-standard-2025-02-10": {
            "rating": 1299.4818351459608,
            "rating_q975": 1328.246593625417,
            "rating_q025": 1270.7170766665045
        },
        "qwen2.5-72b-instruct": {
            "rating": 1299.3375607003704,
            "rating_q975": 1308.4142983972297,
            "rating_q025": 1290.2608230035112
        },
        "mistral-small-3.1-24b-instruct-2503": {
            "rating": 1297.0312260307028,
            "rating_q975": 1305.8973644951805,
            "rating_q025": 1288.165087566225
        },
        "llama-3.1-nemotron-51b-instruct": {
            "rating": 1296.823537830783,
            "rating_q975": 1324.2261595638129,
            "rating_q025": 1269.420916097753
        },
        "gpt-4-turbo-2024-04-09": {
            "rating": 1296.6788377362573,
            "rating_q975": 1304.8393551761717,
            "rating_q025": 1288.5183202963428
        },
        "magistral-medium-2506": {
            "rating": 1296.4798990969416,
            "rating_q975": 1310.106006226354,
            "rating_q025": 1282.853791967529
        },
        "mistral-large-2411": {
            "rating": 1295.9829613786733,
            "rating_q975": 1306.5014143198966,
            "rating_q025": 1285.46450843745
        },
        "llama-3.1-nemotron-70b-instruct": {
            "rating": 1294.950567007037,
            "rating_q975": 1314.15778181454,
            "rating_q025": 1275.7433521995342
        },
        "mistral-large-2407": {
            "rating": 1293.1676923701125,
            "rating_q975": 1302.2435142939792,
            "rating_q025": 1284.0918704462458
        },
        "hunyuan-large-2025-02-10": {
            "rating": 1290.1462683236614,
            "rating_q975": 1320.9452429640353,
            "rating_q025": 1259.3472936832875
        },
        "llama-3.1-70b-instruct": {
            "rating": 1290.030126982477,
            "rating_q975": 1298.2275874266118,
            "rating_q025": 1281.8326665383422
        },
        "gemma-2-9b-it-simpo": {
            "rating": 1288.2967646124393,
            "rating_q975": 1305.5236601907136,
            "rating_q025": 1271.069869034165
        },
        "gpt-4-0125-preview": {
            "rating": 1287.9065501840992,
            "rating_q975": 1296.4656656716656,
            "rating_q025": 1279.3474346965327
        },
        "gemini-1.5-flash-001": {
            "rating": 1287.0385163322105,
            "rating_q975": 1296.0578522538342,
            "rating_q025": 1278.0191804105868
        },
        "qwen2.5-coder-32b-instruct": {
            "rating": 1284.9778036115472,
            "rating_q975": 1307.3820111464288,
            "rating_q025": 1262.5735960766656
        },
        "reka-core-20240904": {
            "rating": 1284.3638368726151,
            "rating_q975": 1303.9427932686885,
            "rating_q025": 1264.7848804765417
        },
        "gpt-4-1106-preview": {
            "rating": 1284.1261184554296,
            "rating_q975": 1292.6068229644045,
            "rating_q025": 1275.6454139464547
        },
        "gemma-2-27b-it": {
            "rating": 1282.5667203594157,
            "rating_q975": 1289.8026332282004,
            "rating_q025": 1275.330807490631
        },
        "hunyuan-large-vision": {
            "rating": 1282.018426106545,
            "rating_q975": 1303.5448055680247,
            "rating_q025": 1260.492046645065
        },
        "llama-3.1-tulu-3-70b": {
            "rating": 1278.7665844532366,
            "rating_q975": 1311.4906022418224,
            "rating_q025": 1246.0425666646508
        },
        "amazon-nova-pro-v1.0": {
            "rating": 1278.6484322227375,
            "rating_q975": 1289.8129813023581,
            "rating_q025": 1267.4838831431168
        },
        "command-r-plus-08-2024": {
            "rating": 1273.9264074165194,
            "rating_q975": 1291.0273571971325,
            "rating_q025": 1256.8254576359063
        },
        "reka-flash-20240904": {
            "rating": 1271.9175964064689,
            "rating_q975": 1290.6436392007402,
            "rating_q025": 1253.1915536121976
        },
        "c4ai-aya-expanse-32b": {
            "rating": 1270.6057025576806,
            "rating_q975": 1281.4153917264298,
            "rating_q025": 1259.7960133889314
        },
        "amazon-nova-lite-v1.0": {
            "rating": 1269.94740888054,
            "rating_q975": 1282.7004266816211,
            "rating_q025": 1257.194391079459
        },
        "claude-3-sonnet-20240229": {
            "rating": 1267.9931803810136,
            "rating_q975": 1276.7675191812973,
            "rating_q025": 1259.21884158073
        },
        "jamba-1.5-large": {
            "rating": 1267.5419029476557,
            "rating_q975": 1286.0190328441097,
            "rating_q025": 1249.0647730512017
        },
        "gemma-2-9b-it": {
            "rating": 1264.8598280633398,
            "rating_q975": 1273.0975625441386,
            "rating_q025": 1256.622093582541
        },
        "command-r-plus": {
            "rating": 1264.1889297415023,
            "rating_q975": 1273.433767140587,
            "rating_q025": 1254.9440923424177
        },
        "nemotron-4-340b-instruct": {
            "rating": 1264.145978790225,
            "rating_q975": 1277.2378424142164,
            "rating_q025": 1251.0541151662335
        },
        "mistral-small-24b-instruct-2501": {
            "rating": 1261.7567309796796,
            "rating_q975": 1277.26171431825,
            "rating_q025": 1246.2517476411092
        },
        "phi-4": {
            "rating": 1258.1232950024892,
            "rating_q975": 1270.072470485907,
            "rating_q025": 1246.1741195190714
        },
        "gemini-1.5-flash-8b-001": {
            "rating": 1257.3485506381917,
            "rating_q975": 1266.812429355584,
            "rating_q025": 1247.8846719207993
        },
        "deepseek-coder-v2": {
            "rating": 1257.275991709342,
            "rating_q975": 1271.543753804265,
            "rating_q025": 1243.008229614419
        },
        "claude-3-haiku-20240307": {
            "rating": 1255.0230728535666,
            "rating_q975": 1262.9442178466045,
            "rating_q025": 1247.1019278605288
        },
        "llama-3-70b-instruct": {
            "rating": 1254.9288705372173,
            "rating_q975": 1262.6561284002732,
            "rating_q025": 1247.2016126741614
        },
        "gpt-4-0314": {
            "rating": 1253.3814321613313,
            "rating_q975": 1264.396536998099,
            "rating_q025": 1242.3663273245636
        },
        "glm-4-0520": {
            "rating": 1247.8084086630038,
            "rating_q975": 1265.1007860593604,
            "rating_q025": 1230.5160312666471
        },
        "llama-3.1-tulu-3-8b": {
            "rating": 1245.7733095007704,
            "rating_q975": 1277.9204602264588,
            "rating_q025": 1213.626158775082
        },
        "gpt-4-0613": {
            "rating": 1241.4226230385223,
            "rating_q975": 1250.5654315062714,
            "rating_q025": 1232.2798145707732
        },
        "olmo-2-0325-32b-instruct": {
            "rating": 1237.4540070916978,
            "rating_q975": 1269.656174245343,
            "rating_q025": 1205.2518399380526
        },
        "ministral-8b-2410": {
            "rating": 1237.1420543086156,
            "rating_q975": 1260.8704281976638,
            "rating_q025": 1213.4136804195673
        },
        "gemini-pro-dev-api": {
            "rating": 1235.1679954528872,
            "rating_q975": 1252.2769180045211,
            "rating_q025": 1218.0590729012533
        },
        "amazon-nova-micro-v1.0": {
            "rating": 1234.6278498945055,
            "rating_q975": 1247.6570265075452,
            "rating_q025": 1221.5986732814658
        },
        "qwen2-72b-instruct": {
            "rating": 1233.8567476917256,
            "rating_q975": 1244.331042315516,
            "rating_q025": 1223.382453067935
        },
        "command-r-08-2024": {
            "rating": 1233.2680372782374,
            "rating_q975": 1250.7594415442181,
            "rating_q025": 1215.7766330122568
        },
        "granite-3.1-8b-instruct": {
            "rating": 1232.631860381848,
            "rating_q975": 1266.1225733931476,
            "rating_q025": 1199.1411473705482
        },
        "reka-flash-21b-20240226-online": {
            "rating": 1231.5031583073594,
            "rating_q975": 1247.0819954208519,
            "rating_q025": 1215.924321193867
        },
        "command-r": {
            "rating": 1229.9765323668685,
            "rating_q975": 1240.3210418009044,
            "rating_q025": 1219.6320229328326
        },
        "c4ai-aya-expanse-8b": {
            "rating": 1229.516438379598,
            "rating_q975": 1247.3932708381553,
            "rating_q025": 1211.6396059210406
        },
        "mistral-large-2402": {
            "rating": 1227.8690582959916,
            "rating_q975": 1237.8726425988284,
            "rating_q025": 1217.8654739931549
        },
        "jamba-1.5-mini": {
            "rating": 1225.8379636686745,
            "rating_q975": 1244.2973009630912,
            "rating_q025": 1207.378626374258
        },
        "qwen1.5-110b-chat": {
            "rating": 1225.6488478905358,
            "rating_q975": 1237.9060668910877,
            "rating_q025": 1213.3916288899838
        },
        "hunyuan-standard-256k": {
            "rating": 1223.392966084838,
            "rating_q975": 1255.072893424763,
            "rating_q025": 1191.713038744913
        },
        "reka-flash-21b-20240226": {
            "rating": 1219.584174326647,
            "rating_q975": 1232.7046286276545,
            "rating_q025": 1206.4637200256393
        },
        "mixtral-8x22b-instruct-v0.1": {
            "rating": 1218.8214816505943,
            "rating_q975": 1228.7546156222402,
            "rating_q025": 1208.8883476789483
        },
        "granite-3.1-2b-instruct": {
            "rating": 1218.616906098367,
            "rating_q975": 1248.5665301910356,
            "rating_q025": 1188.6672820056986
        },
        "mistral-medium": {
            "rating": 1213.7331176190103,
            "rating_q975": 1226.2051775883128,
            "rating_q025": 1201.2610576497077
        },
        "qwen1.5-72b-chat": {
            "rating": 1213.0447772488183,
            "rating_q975": 1224.5085107526452,
            "rating_q025": 1201.5810437449913
        },
        "llama-3-8b-instruct": {
            "rating": 1211.2963379761577,
            "rating_q975": 1219.9762647190198,
            "rating_q025": 1202.6164112332956
        },
        "llama-3.1-8b-instruct": {
            "rating": 1210.4688280690045,
            "rating_q975": 1219.2144261116814,
            "rating_q025": 1201.7232300263277
        },
        "gpt-3.5-turbo-0125": {
            "rating": 1209.4881846361027,
            "rating_q975": 1218.949102445153,
            "rating_q025": 1200.0272668270525
        },
        "yi-1.5-34b-chat": {
            "rating": 1198.9077462081423,
            "rating_q975": 1210.9841699221504,
            "rating_q025": 1186.8313224941342
        },
        "zephyr-orpo-141b-A35b-v0.1": {
            "rating": 1189.8196890483948,
            "rating_q975": 1217.6614335048835,
            "rating_q025": 1161.9779445919062
        },
        "qwen1.5-32b-chat": {
            "rating": 1189.4273977648866,
            "rating_q975": 1202.9916211631028,
            "rating_q025": 1175.8631743666704
        },
        "mixtral-8x7b-instruct-v0.1": {
            "rating": 1185.4898044675392,
            "rating_q975": 1195.1682295191627,
            "rating_q025": 1175.8113794159158
        },
        "phi-3-medium-4k-instruct": {
            "rating": 1185.2844271794772,
            "rating_q975": 1197.3886446431727,
            "rating_q025": 1173.1802097157818
        },
        "gemini-pro": {
            "rating": 1184.0276220275387,
            "rating_q975": 1214.2606161174635,
            "rating_q025": 1153.7946279376138
        },
        "gemma-2-2b-it": {
            "rating": 1183.1781917530302,
            "rating_q975": 1192.306327761367,
            "rating_q025": 1174.0500557446935
        },
        "dbrx-instruct-preview": {
            "rating": 1182.9111975194814,
            "rating_q975": 1196.115541213483,
            "rating_q025": 1169.7068538254798
        },
        "llama2-70b-steerlm-chat": {
            "rating": 1180.758927728377,
            "rating_q975": 1216.8002053670748,
            "rating_q025": 1144.7176500896794
        },
        "openchat-3.5-0106": {
            "rating": 1179.573603433064,
            "rating_q975": 1197.676279177688,
            "rating_q025": 1161.4709276884398
        },
        "gemma-1.1-7b-it": {
            "rating": 1178.6150907565757,
            "rating_q975": 1191.4518565668604,
            "rating_q025": 1165.778324946291
        },
        "wizardlm-70b": {
            "rating": 1178.4809351976044,
            "rating_q975": 1202.5072329993718,
            "rating_q025": 1154.454637395837
        },
        "qwen1.5-14b-chat": {
            "rating": 1177.5510433611585,
            "rating_q975": 1193.1026711407562,
            "rating_q025": 1161.9994155815607
        },
        "yi-34b-chat": {
            "rating": 1175.7535837637602,
            "rating_q975": 1192.284657908493,
            "rating_q025": 1159.2225096190273
        },
        "starling-lm-7b-beta": {
            "rating": 1173.8382164422317,
            "rating_q975": 1190.2570760222225,
            "rating_q025": 1157.4193568622409
        },
        "tulu-2-dpo-70b": {
            "rating": 1173.1358544875777,
            "rating_q975": 1198.6438454933636,
            "rating_q025": 1147.6278634817918
        },
        "deepseek-llm-67b-chat": {
            "rating": 1170.1350245042559,
            "rating_q975": 1198.4128362150107,
            "rating_q025": 1141.857212793501
        },
        "internlm2_5-20b-chat": {
            "rating": 1169.0996316381527,
            "rating_q975": 1186.1727463535872,
            "rating_q025": 1152.0265169227182
        },
        "llama-2-70b-chat": {
            "rating": 1166.0384058215152,
            "rating_q975": 1177.9377776954652,
            "rating_q025": 1154.1390339475652
        },
        "starling-lm-7b-alpha": {
            "rating": 1165.5121782228957,
            "rating_q975": 1186.0665936151945,
            "rating_q025": 1144.957762830597
        },
        "phi-3-small-8k-instruct": {
            "rating": 1164.8984326854916,
            "rating_q975": 1178.6174827797488,
            "rating_q025": 1151.1793825912343
        },
        "gpt-3.5-turbo-1106": {
            "rating": 1162.8620398237315,
            "rating_q975": 1182.0086691967035,
            "rating_q025": 1143.7154104507595
        },
        "granite-3.0-8b-instruct": {
            "rating": 1158.4285332904838,
            "rating_q975": 1181.3785753660438,
            "rating_q025": 1135.4784912149237
        },
        "vicuna-33b": {
            "rating": 1158.0254304857283,
            "rating_q975": 1173.460268862075,
            "rating_q025": 1142.5905921093815
        },
        "nous-hermes-2-mixtral-8x7b-dpo": {
            "rating": 1157.6959586749172,
            "rating_q975": 1192.9718057957402,
            "rating_q025": 1122.420111554094
        },
        "openchat-3.5": {
            "rating": 1155.5167982901771,
            "rating_q975": 1179.451101263599,
            "rating_q025": 1131.5824953167553
        },
        "qwen1.5-7b-chat": {
            "rating": 1155.3678017165985,
            "rating_q975": 1183.3402781537732,
            "rating_q025": 1127.3953252794238
        },
        "llama-3.2-3b-instruct": {
            "rating": 1150.4709609511478,
            "rating_q975": 1170.5326723966032,
            "rating_q025": 1130.4092495056925
        },
        "snowflake-arctic-instruct": {
            "rating": 1148.4792017499421,
            "rating_q975": 1161.7708350023402,
            "rating_q025": 1135.1875684975441
        },
        "granite-3.0-2b-instruct": {
            "rating": 1144.39534442618,
            "rating_q975": 1166.3571842512422,
            "rating_q025": 1122.4335046011176
        },
        "openhermes-2.5-mistral-7b": {
            "rating": 1140.0680554538694,
            "rating_q975": 1169.9869637800791,
            "rating_q025": 1110.1491471276597
        },
        "llama-2-13b-chat": {
            "rating": 1139.9854067924612,
            "rating_q975": 1155.936554947156,
            "rating_q025": 1124.0342586377662
        },
        "mistral-7b-instruct-v0.2": {
            "rating": 1136.861058097093,
            "rating_q975": 1152.4468455969727,
            "rating_q025": 1121.2752705972134
        },
        "solar-10.7b-instruct-v1.0": {
            "rating": 1135.7338459742236,
            "rating_q975": 1170.223962992901,
            "rating_q025": 1101.2437289555462
        },
        "codellama-34b-instruct": {
            "rating": 1135.5092762703503,
            "rating_q975": 1160.288423448928,
            "rating_q025": 1110.7301290917726
        },
        "mpt-30b-chat": {
            "rating": 1131.220946560923,
            "rating_q975": 1169.7182599509035,
            "rating_q025": 1092.7236331709425
        },
        "gemma-7b-it": {
            "rating": 1131.2152165141938,
            "rating_q975": 1152.9317712749707,
            "rating_q025": 1109.4986617534169
        },
        "qwen-14b-chat": {
            "rating": 1127.8381631171837,
            "rating_q975": 1156.4749320061014,
            "rating_q025": 1099.201394228266
        },
        "vicuna-13b": {
            "rating": 1127.431786466167,
            "rating_q975": 1144.6235994226356,
            "rating_q025": 1110.2399735096985
        },
        "phi-3-mini-4k-instruct": {
            "rating": 1117.9258182039857,
            "rating_q975": 1131.5127719081654,
            "rating_q025": 1104.338864499806
        },
        "wizardlm-13b": {
            "rating": 1115.2371863939593,
            "rating_q975": 1139.870191864942,
            "rating_q025": 1090.6041809229766
        },
        "llama-2-7b-chat": {
            "rating": 1109.8872062156604,
            "rating_q975": 1127.8535698482856,
            "rating_q025": 1091.9208425830352
        },
        "gemma-2b-it": {
            "rating": 1109.2618481721004,
            "rating_q975": 1137.5624306792663,
            "rating_q025": 1080.9612656649344
        },
        "phi-3-mini-4k-instruct-june-2024": {
            "rating": 1109.199319375981,
            "rating_q975": 1126.1304848540044,
            "rating_q025": 1092.2681538979577
        },
        "gemma-1.1-2b-it": {
            "rating": 1108.6323581340116,
            "rating_q975": 1127.96445151499,
            "rating_q025": 1089.3002647530332
        },
        "phi-3-mini-128k-instruct": {
            "rating": 1107.6208718961714,
            "rating_q975": 1123.7101521034756,
            "rating_q025": 1091.5315916888671
        },
        "qwq-32b-preview": {
            "rating": 1105.3424793830368,
            "rating_q975": 1138.0172793043437,
            "rating_q025": 1072.66767946173
        },
        "palm-2": {
            "rating": 1104.1188242104542,
            "rating_q975": 1128.8072391174044,
            "rating_q025": 1079.4304093035041
        },
        "zephyr-7b-beta": {
            "rating": 1101.5425847157007,
            "rating_q975": 1122.1115428035018,
            "rating_q025": 1080.9736266278996
        },
        "qwen1.5-4b-chat": {
            "rating": 1095.1766685875928,
            "rating_q975": 1119.0464360992985,
            "rating_q025": 1071.306901075887
        },
        "vicuna-7b": {
            "rating": 1093.689288326447,
            "rating_q975": 1121.1135750572844,
            "rating_q025": 1066.2650015956096
        },
        "stripedhyena-nous-7b": {
            "rating": 1090.4932522482582,
            "rating_q975": 1120.6400975916263,
            "rating_q025": 1060.34640690489
        },
        "olmo-7b-instruct": {
            "rating": 1089.7963238129996,
            "rating_q975": 1116.30456089102,
            "rating_q025": 1063.2880867349793
        },
        "guanaco-33b": {
            "rating": 1088.3514256429626,
            "rating_q975": 1127.35482912845,
            "rating_q025": 1049.348022157475
        },
        "mistral-7b-instruct": {
            "rating": 1080.7916115164298,
            "rating_q975": 1104.7094008379283,
            "rating_q025": 1056.8738221949313
        },
        "smollm2-1.7b-instruct": {
            "rating": 1080.2723946483845,
            "rating_q975": 1124.5756194717856,
            "rating_q025": 1035.9691698249835
        },
        "llama-3.2-1b-instruct": {
            "rating": 1074.937240650705,
            "rating_q975": 1095.8927091063117,
            "rating_q025": 1053.9817721950983
        },
        "koala-13b": {
            "rating": 1057.7561741477712,
            "rating_q975": 1087.4064044847664,
            "rating_q025": 1028.105943810776
        },
        "chatglm3-6b": {
            "rating": 1054.2790726703556,
            "rating_q975": 1086.0550009664962,
            "rating_q025": 1022.5031443742151
        },
        "mpt-7b-chat": {
            "rating": 1019.4050924350022,
            "rating_q975": 1056.9384021377302,
            "rating_q025": 981.871782732274
        },
        "RWKV-4-Raven-14B": {
            "rating": 1018.7879422019038,
            "rating_q975": 1053.2391580421483,
            "rating_q025": 984.3367263616592
        },
        "chatglm2-6b": {
            "rating": 1016.5838861781765,
            "rating_q975": 1058.6276569415377,
            "rating_q025": 974.5401154148154
        },
        "fastchat-t5-3b": {
            "rating": 1010.6114363693406,
            "rating_q975": 1049.339996726288,
            "rating_q025": 971.882876012393
        },
        "alpaca-13b": {
            "rating": 995.8724742953843,
            "rating_q975": 1030.0883673890712,
            "rating_q025": 961.6565812016975
        },
        "oasst-pythia-12b": {
            "rating": 972.3621431283725,
            "rating_q975": 1003.7731342130212,
            "rating_q025": 940.9511520437238
        },
        "chatglm-6b": {
            "rating": 959.931658268026,
            "rating_q975": 998.739759117002,
            "rating_q025": 921.12355741905
        },
        "stablelm-tuned-alpha-7b": {
            "rating": 915.2453453654553,
            "rating_q975": 956.9874709555879,
            "rating_q025": 873.5032197753226
        },
        "dolly-v2-12b": {
            "rating": 911.527972979906,
            "rating_q975": 956.3699232592019,
            "rating_q025": 866.6860227006102
        }
    },
    "industry_entertainment_and_sports_and_media": {
        "gemini-2.5-pro": {
            "rating": 1439.5789161642276,
            "rating_q975": 1446.599514653171,
            "rating_q025": 1432.5583176752843
        },
        "claude-sonnet-4-5-20250929-thinking-32k": {
            "rating": 1434.527946452936,
            "rating_q975": 1447.1093286529704,
            "rating_q025": 1421.9465642529017
        },
        "gpt-4.5-preview-2025-02-27": {
            "rating": 1431.6695206036445,
            "rating_q975": 1443.275197001433,
            "rating_q025": 1420.063844205856
        },
        "claude-sonnet-4-5-20250929": {
            "rating": 1430.2514394478906,
            "rating_q975": 1447.3452287046885,
            "rating_q025": 1413.1576501910927
        },
        "claude-opus-4-1-20250805-thinking-16k": {
            "rating": 1428.8664153799998,
            "rating_q975": 1437.6282774840604,
            "rating_q025": 1420.1045532759392
        },
        "chatgpt-4o-latest-20250326": {
            "rating": 1424.9278621259316,
            "rating_q975": 1432.0116628318385,
            "rating_q025": 1417.8440614200247
        },
        "claude-opus-4-1-20250805": {
            "rating": 1421.5696977853513,
            "rating_q975": 1429.3316899042145,
            "rating_q025": 1413.8077056664881
        },
        "claude-opus-4-20250514-thinking-16k": {
            "rating": 1415.0542831796458,
            "rating_q975": 1422.9301120321104,
            "rating_q025": 1407.1784543271813
        },
        "gpt-5-high": {
            "rating": 1402.767407056536,
            "rating_q975": 1411.5673864962648,
            "rating_q025": 1393.9674276168073
        },
        "claude-opus-4-20250514": {
            "rating": 1396.8349768187559,
            "rating_q975": 1404.2244482278868,
            "rating_q025": 1389.445505409625
        },
        "gpt-4.1-2025-04-14": {
            "rating": 1396.7932298400767,
            "rating_q975": 1403.7982653179724,
            "rating_q025": 1389.788194362181
        },
        "o3-2025-04-16": {
            "rating": 1396.3862022134263,
            "rating_q975": 1403.1462624336411,
            "rating_q025": 1389.6261419932114
        },
        "grok-3-preview-02-24": {
            "rating": 1394.7681483760043,
            "rating_q975": 1402.9724893912494,
            "rating_q025": 1386.5638073607593
        },
        "qwen3-max-preview": {
            "rating": 1393.9738649977937,
            "rating_q975": 1403.2694148704215,
            "rating_q025": 1384.678315125166
        },
        "deepseek-v3.1-thinking": {
            "rating": 1393.2409872680842,
            "rating_q975": 1405.712386839442,
            "rating_q025": 1380.7695876967264
        },
        "glm-4.6": {
            "rating": 1393.2205627541573,
            "rating_q975": 1407.0363561105366,
            "rating_q025": 1379.404769397778
        },
        "qwen3-max-2025-09-23": {
            "rating": 1390.6773386906905,
            "rating_q975": 1404.8189427076966,
            "rating_q025": 1376.5357346736844
        },
        "gemini-2.5-flash": {
            "rating": 1390.3625483959909,
            "rating_q975": 1397.1090481883655,
            "rating_q025": 1383.6160486036163
        },
        "gpt-5-chat": {
            "rating": 1390.0765756876328,
            "rating_q975": 1398.7500489681279,
            "rating_q025": 1381.4031024071378
        },
        "deepseek-v3.2-exp-thinking": {
            "rating": 1388.9315202244302,
            "rating_q975": 1403.2166087000435,
            "rating_q025": 1374.646431748817
        },
        "o1-2024-12-17": {
            "rating": 1387.3563218979036,
            "rating_q975": 1395.6080081883813,
            "rating_q025": 1379.104635607426
        },
        "grok-4-0709": {
            "rating": 1387.3210852174013,
            "rating_q975": 1395.2069505003217,
            "rating_q025": 1379.435219934481
        },
        "gemini-2.5-flash-preview-09-2025": {
            "rating": 1386.7490013788154,
            "rating_q975": 1398.7457798652163,
            "rating_q025": 1374.7522228924145
        },
        "deepseek-r1-0528": {
            "rating": 1385.5077451369962,
            "rating_q975": 1396.0017435846607,
            "rating_q025": 1375.0137466893316
        },
        "claude-sonnet-4-20250514-thinking-32k": {
            "rating": 1384.7386061557968,
            "rating_q975": 1392.678122569498,
            "rating_q025": 1376.7990897420955
        },
        "claude-haiku-4-5-20251001": {
            "rating": 1382.1162637632308,
            "rating_q975": 1395.9115273085454,
            "rating_q025": 1368.3210002179162
        },
        "grok-4-fast": {
            "rating": 1381.9237720952783,
            "rating_q975": 1398.0002541073693,
            "rating_q025": 1365.8472900831873
        },
        "glm-4.5": {
            "rating": 1381.8255269645176,
            "rating_q975": 1391.0742549127408,
            "rating_q025": 1372.5767990162944
        },
        "kimi-k2-0711-preview": {
            "rating": 1380.2213866607453,
            "rating_q975": 1388.8806905309898,
            "rating_q025": 1371.5620827905009
        },
        "claude-3-7-sonnet-20250219-thinking-32k": {
            "rating": 1379.4806881312509,
            "rating_q975": 1387.1075209290207,
            "rating_q025": 1371.853855333481
        },
        "kimi-k2-0905-preview": {
            "rating": 1379.381044484965,
            "rating_q975": 1392.8463341998802,
            "rating_q025": 1365.91575477005
        },
        "deepseek-v3-0324": {
            "rating": 1378.6678256402574,
            "rating_q975": 1385.6598856953606,
            "rating_q025": 1371.6757655851543
        },
        "deepseek-v3.1": {
            "rating": 1378.6583050675288,
            "rating_q975": 1389.9590188772372,
            "rating_q025": 1367.3575912578203
        },
        "deepseek-v3.1-terminus-thinking": {
            "rating": 1377.277451791562,
            "rating_q975": 1401.2333506198722,
            "rating_q025": 1353.3215529632519
        },
        "deepseek-v3.1-terminus": {
            "rating": 1375.195119627244,
            "rating_q975": 1398.2957728333195,
            "rating_q025": 1352.0944664211684
        },
        "claude-sonnet-4-20250514": {
            "rating": 1371.2154410824792,
            "rating_q975": 1378.9297036114156,
            "rating_q025": 1363.5011785535428
        },
        "deepseek-r1": {
            "rating": 1369.7482387825673,
            "rating_q975": 1379.45919387467,
            "rating_q025": 1360.0372836904646
        },
        "o1-preview": {
            "rating": 1369.3721322606489,
            "rating_q975": 1378.667711621836,
            "rating_q025": 1360.0765528994618
        },
        "qwen3-235b-a22b-instruct-2507": {
            "rating": 1365.9877615644577,
            "rating_q975": 1373.838812004507,
            "rating_q025": 1358.1367111244085
        },
        "mistral-medium-2508": {
            "rating": 1363.9831887769344,
            "rating_q975": 1372.6017051590047,
            "rating_q025": 1355.364672394864
        },
        "qwen3-vl-235b-a22b-thinking": {
            "rating": 1361.0313383394853,
            "rating_q975": 1376.361455029166,
            "rating_q025": 1345.7012216498044
        },
        "claude-3-5-sonnet-20241022": {
            "rating": 1360.908037123784,
            "rating_q975": 1366.2988580976312,
            "rating_q025": 1355.5172161499368
        },
        "gemini-2.5-flash-lite-preview-06-17-thinking": {
            "rating": 1360.451684324889,
            "rating_q975": 1368.521021665732,
            "rating_q025": 1352.3823469840459
        },
        "qwen3-vl-235b-a22b-instruct": {
            "rating": 1356.5789263610247,
            "rating_q975": 1371.683438400396,
            "rating_q025": 1341.4744143216535
        },
        "qwen3-235b-a22b-no-thinking": {
            "rating": 1355.852567516323,
            "rating_q975": 1363.5661955082137,
            "rating_q025": 1348.1389395244323
        },
        "mai-1-preview": {
            "rating": 1353.6509882792448,
            "rating_q975": 1364.2944053649996,
            "rating_q025": 1343.0075711934899
        },
        "gemini-2.5-flash-lite-preview-09-2025-no-thinking": {
            "rating": 1351.5905909744372,
            "rating_q975": 1363.374913310811,
            "rating_q025": 1339.8062686380633
        },
        "o4-mini-2025-04-16": {
            "rating": 1350.707044466016,
            "rating_q975": 1357.7753109095402,
            "rating_q025": 1343.6387780224918
        },
        "mistral-medium-2505": {
            "rating": 1350.3487859684885,
            "rating_q975": 1358.4859699063807,
            "rating_q025": 1342.2116020305964
        },
        "qwen3-coder-480b-a35b-instruct": {
            "rating": 1348.7926488779985,
            "rating_q975": 1357.9521506790504,
            "rating_q025": 1339.6331470769467
        },
        "gpt-5-mini-high": {
            "rating": 1347.3011643499171,
            "rating_q975": 1356.9296944930477,
            "rating_q025": 1337.6726342067866
        },
        "deepseek-v3": {
            "rating": 1346.260704357438,
            "rating_q975": 1355.3542117104732,
            "rating_q025": 1337.1671970044029
        },
        "gpt-4.1-mini-2025-04-14": {
            "rating": 1343.980964075774,
            "rating_q975": 1351.5836524595577,
            "rating_q025": 1336.3782756919902
        },
        "qwen3-235b-a22b-thinking-2507": {
            "rating": 1342.7195574127873,
            "rating_q975": 1357.2068224908285,
            "rating_q025": 1328.232292334746
        },
        "longcat-flash-chat": {
            "rating": 1339.2420996923086,
            "rating_q975": 1352.4126106977858,
            "rating_q025": 1326.0715886868313
        },
        "hunyuan-t1-20250711": {
            "rating": 1338.356628636902,
            "rating_q975": 1357.6631797974974,
            "rating_q025": 1319.0500774763068
        },
        "qwen2.5-max": {
            "rating": 1337.0450462836689,
            "rating_q975": 1344.5548698452142,
            "rating_q025": 1329.5352227221235
        },
        "gemini-1.5-pro-002": {
            "rating": 1335.2143509926277,
            "rating_q975": 1341.6629581410305,
            "rating_q025": 1328.765743844225
        },
        "hunyuan-turbos-20250416": {
            "rating": 1334.5775000167816,
            "rating_q975": 1347.7908743444507,
            "rating_q025": 1321.3641256891126
        },
        "gpt-4o-2024-05-13": {
            "rating": 1334.5454493221835,
            "rating_q975": 1341.006729037397,
            "rating_q025": 1328.08416960697
        },
        "gemini-advanced-0514": {
            "rating": 1333.091530850436,
            "rating_q975": 1342.3508394220105,
            "rating_q025": 1323.8322222788613
        },
        "qwen3-30b-a3b-instruct-2507": {
            "rating": 1330.7009649747265,
            "rating_q975": 1340.0141707368473,
            "rating_q025": 1321.3877592126057
        },
        "command-a-03-2025": {
            "rating": 1327.710649925408,
            "rating_q975": 1334.209909390289,
            "rating_q025": 1321.211390460527
        },
        "minimax-m1": {
            "rating": 1327.552773436075,
            "rating_q975": 1335.1956122537626,
            "rating_q025": 1319.9099346183875
        },
        "gemma-3-27b-it": {
            "rating": 1326.5402269235558,
            "rating_q975": 1333.3484376103247,
            "rating_q025": 1319.7320162367869
        },
        "qwen3-next-80b-a3b-instruct": {
            "rating": 1326.4803085062065,
            "rating_q975": 1336.6400167265306,
            "rating_q025": 1316.3206002858824
        },
        "glm-4.5-air": {
            "rating": 1324.771509141819,
            "rating_q975": 1333.2490277536826,
            "rating_q025": 1316.2939905299554
        },
        "gemini-2.0-flash-lite-preview-02-05": {
            "rating": 1324.6972080947319,
            "rating_q975": 1333.2026111633795,
            "rating_q025": 1316.1918050260842
        },
        "grok-3-mini-high": {
            "rating": 1323.0632454052247,
            "rating_q975": 1333.7238729250766,
            "rating_q025": 1312.4026178853728
        },
        "qwen3-235b-a22b": {
            "rating": 1322.560851184974,
            "rating_q975": 1331.1233659654802,
            "rating_q025": 1313.9983364044676
        },
        "mistral-small-2506": {
            "rating": 1321.9955549598474,
            "rating_q975": 1332.0977019374823,
            "rating_q025": 1311.8934079822125
        },
        "gpt-4o-2024-08-06": {
            "rating": 1321.7343994781013,
            "rating_q975": 1329.6890096244645,
            "rating_q025": 1313.7797893317381
        },
        "grok-3-mini-beta": {
            "rating": 1318.9969483320856,
            "rating_q975": 1328.4594530510547,
            "rating_q025": 1309.5344436131165
        },
        "step-3": {
            "rating": 1318.168145612434,
            "rating_q975": 1335.269225413936,
            "rating_q025": 1301.067065810932
        },
        "glm-4.5v": {
            "rating": 1317.0544030347035,
            "rating_q975": 1335.897989077147,
            "rating_q025": 1298.2108169922599
        },
        "amazon-nova-experimental-chat-10-09": {
            "rating": 1314.708895749643,
            "rating_q975": 1331.8076923597948,
            "rating_q025": 1297.6100991394912
        },
        "grok-2-2024-08-13": {
            "rating": 1311.9703387649747,
            "rating_q975": 1318.6350530837813,
            "rating_q025": 1305.3056244461682
        },
        "gpt-4-turbo-2024-04-09": {
            "rating": 1310.8166373026438,
            "rating_q975": 1317.9448907874894,
            "rating_q025": 1303.6883838177982
        },
        "qwen3-next-80b-a3b-thinking": {
            "rating": 1308.422126433552,
            "rating_q975": 1320.5010901894989,
            "rating_q025": 1296.343162677605
        },
        "o3-mini-high": {
            "rating": 1308.0335347975697,
            "rating_q975": 1318.2091529724785,
            "rating_q025": 1297.857916622661
        },
        "claude-3-5-sonnet-20240620": {
            "rating": 1307.379915970247,
            "rating_q975": 1314.3055225608293,
            "rating_q025": 1300.454309379665
        },
        "gemini-1.5-pro-001": {
            "rating": 1305.5778053725944,
            "rating_q975": 1312.98413370834,
            "rating_q025": 1298.1714770368487
        },
        "gemma-3-12b-it": {
            "rating": 1305.0036531955943,
            "rating_q975": 1326.3353295731652,
            "rating_q025": 1283.6719768180235
        },
        "llama-3.1-405b-instruct-fp8": {
            "rating": 1301.423359232325,
            "rating_q975": 1308.4466172262014,
            "rating_q025": 1294.4001012384488
        },
        "llama-3.3-nemotron-49b-super-v1": {
            "rating": 1301.2392640021076,
            "rating_q975": 1328.1572888009214,
            "rating_q025": 1274.3212392032938
        },
        "llama-3.1-nemotron-ultra-253b-v1": {
            "rating": 1301.0410961374116,
            "rating_q975": 1324.8935179717614,
            "rating_q025": 1277.1886743030618
        },
        "o3-mini": {
            "rating": 1300.0916024108287,
            "rating_q975": 1306.2260047738982,
            "rating_q025": 1293.9572000477592
        },
        "deepseek-v2.5-1210": {
            "rating": 1299.8060036498446,
            "rating_q975": 1315.6897100839421,
            "rating_q025": 1283.922297215747
        },
        "step-2-16k-exp-202412": {
            "rating": 1299.2647305856162,
            "rating_q975": 1317.5800689787095,
            "rating_q025": 1280.949392192523
        },
        "glm-4-plus-0111": {
            "rating": 1298.9457141323724,
            "rating_q975": 1316.2792207590664,
            "rating_q025": 1281.6122075056783
        },
        "hunyuan-large-2025-02-10": {
            "rating": 1298.8883474095442,
            "rating_q975": 1321.0080234059715,
            "rating_q025": 1276.7686714131169
        },
        "hunyuan-turbo-0110": {
            "rating": 1298.7330199593778,
            "rating_q975": 1324.0193480359314,
            "rating_q025": 1273.446691882824
        },
        "claude-3-5-haiku-20241022": {
            "rating": 1297.6796224327986,
            "rating_q975": 1303.384140787688,
            "rating_q025": 1291.9751040779092
        },
        "llama-4-maverick-17b-128e-instruct": {
            "rating": 1295.4116666281116,
            "rating_q975": 1302.9414326139915,
            "rating_q025": 1287.8819006422316
        },
        "llama-3.1-405b-instruct-bf16": {
            "rating": 1293.3319571121765,
            "rating_q975": 1300.3888484455383,
            "rating_q025": 1286.2750657788147
        },
        "yi-lightning": {
            "rating": 1292.4459166656143,
            "rating_q975": 1302.3820687890186,
            "rating_q025": 1282.50976454221
        },
        "qwen-plus-0125": {
            "rating": 1291.4658093857038,
            "rating_q975": 1308.049398946483,
            "rating_q025": 1274.8822198249245
        },
        "llama-4-scout-17b-16e-instruct": {
            "rating": 1289.6196782890602,
            "rating_q975": 1298.1225650195277,
            "rating_q025": 1281.1167915585927
        },
        "magistral-medium-2506": {
            "rating": 1288.4751040502933,
            "rating_q975": 1301.8197266669201,
            "rating_q025": 1275.1304814336665
        },
        "gpt-4-1106-preview": {
            "rating": 1287.7599915619649,
            "rating_q975": 1295.1492332892135,
            "rating_q025": 1280.3707498347162
        },
        "mistral-large-2407": {
            "rating": 1287.5823905248749,
            "rating_q975": 1295.5484965273859,
            "rating_q025": 1279.616284522364
        },
        "nvidia-llama-3.3-nemotron-super-49b-v1.5": {
            "rating": 1286.7197563652362,
            "rating_q975": 1309.2736074115883,
            "rating_q025": 1264.1659053188841
        },
        "gpt-4.1-nano-2025-04-14": {
            "rating": 1285.5868098714664,
            "rating_q975": 1302.9071517388136,
            "rating_q025": 1268.2664680041191
        },
        "qwen3-32b": {
            "rating": 1284.9564054250234,
            "rating_q975": 1305.7538336733892,
            "rating_q025": 1264.1589771766576
        },
        "gpt-4-0125-preview": {
            "rating": 1284.9488187188372,
            "rating_q975": 1292.522943993581,
            "rating_q025": 1277.3746934440933
        },
        "hunyuan-turbos-20250226": {
            "rating": 1284.178658497056,
            "rating_q975": 1309.8063892352625,
            "rating_q025": 1258.5509277588494
        },
        "llama-3.3-70b-instruct": {
            "rating": 1283.7613899340784,
            "rating_q975": 1289.8294092528488,
            "rating_q025": 1277.693370615308
        },
        "qwq-32b": {
            "rating": 1283.7093245108172,
            "rating_q975": 1292.3582427214976,
            "rating_q025": 1275.0604063001367
        },
        "gpt-oss-120b": {
            "rating": 1282.7538402556427,
            "rating_q975": 1291.4659847818145,
            "rating_q025": 1274.0416957294708
        },
        "gpt-4o-mini-2024-07-18": {
            "rating": 1281.380149522021,
            "rating_q975": 1287.5474881425062,
            "rating_q025": 1275.2128109015357
        },
        "claude-3-opus-20240229": {
            "rating": 1280.8083343481258,
            "rating_q975": 1286.5102021550613,
            "rating_q025": 1275.1064665411902
        },
        "gpt-5-nano-high": {
            "rating": 1280.5065570277825,
            "rating_q975": 1296.8341945487505,
            "rating_q025": 1264.1789195068145
        },
        "gemma-3n-e4b-it": {
            "rating": 1279.4142274687242,
            "rating_q975": 1288.8483639679307,
            "rating_q025": 1269.9800909695177
        },
        "o1-mini": {
            "rating": 1278.8139698035102,
            "rating_q975": 1285.692628432682,
            "rating_q025": 1271.9353111743383
        },
        "glm-4-plus": {
            "rating": 1277.5937580150294,
            "rating_q975": 1287.3778123132495,
            "rating_q025": 1267.8097037168093
        },
        "qwen-max-0919": {
            "rating": 1276.007135218409,
            "rating_q975": 1287.623169676037,
            "rating_q025": 1264.3911007607812
        },
        "ling-flash-2.0": {
            "rating": 1275.891716162485,
            "rating_q975": 1292.7597830211148,
            "rating_q025": 1259.023649303855
        },
        "mistral-small-3.1-24b-instruct-2503": {
            "rating": 1275.8528195301983,
            "rating_q975": 1283.9469792742243,
            "rating_q025": 1267.7586597861723
        },
        "step-1o-turbo-202506": {
            "rating": 1275.626706838852,
            "rating_q975": 1290.2696688965798,
            "rating_q025": 1260.9837447811242
        },
        "gemini-1.5-flash-002": {
            "rating": 1271.826053334819,
            "rating_q975": 1279.7809012004225,
            "rating_q025": 1263.8712054692157
        },
        "ring-flash-2.0": {
            "rating": 1271.2609980934053,
            "rating_q975": 1287.6283402957201,
            "rating_q025": 1254.8936558910905
        },
        "gemma-2-27b-it": {
            "rating": 1269.6262605847517,
            "rating_q975": 1275.6870977451472,
            "rating_q025": 1263.5654234243561
        },
        "qwen3-30b-a3b": {
            "rating": 1269.57479345014,
            "rating_q975": 1278.381306140625,
            "rating_q025": 1260.7682807596552
        },
        "mistral-large-2411": {
            "rating": 1268.670904098432,
            "rating_q975": 1276.7838877168517,
            "rating_q025": 1260.5579204800122
        },
        "athene-70b-0725": {
            "rating": 1268.4867509042951,
            "rating_q975": 1278.8608085261505,
            "rating_q025": 1258.1126932824397
        },
        "jamba-1.5-large": {
            "rating": 1266.8938397997656,
            "rating_q975": 1282.157269987151,
            "rating_q025": 1251.6304096123802
        },
        "llama-3.1-nemotron-70b-instruct": {
            "rating": 1265.9777346652666,
            "rating_q975": 1284.9247578916204,
            "rating_q025": 1247.0307114389127
        },
        "gemma-2-9b-it-simpo": {
            "rating": 1265.5502272189108,
            "rating_q975": 1279.6200497835769,
            "rating_q025": 1251.4804046542447
        },
        "gpt-4-0613": {
            "rating": 1264.7901720043633,
            "rating_q975": 1272.653528393794,
            "rating_q025": 1256.9268156149326
        },
        "llama-3.1-70b-instruct": {
            "rating": 1262.0374539618906,
            "rating_q975": 1269.082773752207,
            "rating_q025": 1254.9921341715742
        },
        "deepseek-v2.5": {
            "rating": 1261.223788504195,
            "rating_q975": 1271.1652648782103,
            "rating_q025": 1251.2823121301797
        },
        "grok-2-mini-2024-08-13": {
            "rating": 1260.789702185814,
            "rating_q975": 1267.778468164398,
            "rating_q025": 1253.8009362072298
        },
        "gpt-4-0314": {
            "rating": 1260.0290021426576,
            "rating_q975": 1269.502159153678,
            "rating_q025": 1250.5558451316374
        },
        "llama-3.1-tulu-3-70b": {
            "rating": 1258.8285991015532,
            "rating_q975": 1281.2725884525305,
            "rating_q025": 1236.384609750576
        },
        "gpt-oss-20b": {
            "rating": 1257.2122943551617,
            "rating_q975": 1272.023923968373,
            "rating_q025": 1242.4006647419503
        },
        "hunyuan-standard-2025-02-10": {
            "rating": 1255.9155141996323,
            "rating_q975": 1277.9532993187904,
            "rating_q025": 1233.8777290804742
        },
        "command-r-plus-08-2024": {
            "rating": 1255.48074908315,
            "rating_q975": 1270.1207291301625,
            "rating_q025": 1240.8407690361373
        },
        "hunyuan-large-vision": {
            "rating": 1253.1701801983377,
            "rating_q975": 1272.7773103980287,
            "rating_q025": 1233.5630499986466
        },
        "gemini-1.5-flash-001": {
            "rating": 1252.8442294337042,
            "rating_q975": 1260.5160889997992,
            "rating_q025": 1245.1723698676092
        },
        "qwen2.5-plus-1127": {
            "rating": 1252.5455259455537,
            "rating_q975": 1265.3851619017548,
            "rating_q025": 1239.7058899893525
        },
        "olmo-2-0325-32b-instruct": {
            "rating": 1251.1332966858922,
            "rating_q975": 1274.2001550530592,
            "rating_q025": 1228.0664383187252
        },
        "nemotron-4-340b-instruct": {
            "rating": 1250.9349669387316,
            "rating_q975": 1262.220271666602,
            "rating_q025": 1239.6496622108612
        },
        "gemma-3-4b-it": {
            "rating": 1247.8977249455713,
            "rating_q975": 1268.6042482565524,
            "rating_q025": 1227.1912016345902
        },
        "llama-3.1-nemotron-51b-instruct": {
            "rating": 1247.8771686511059,
            "rating_q975": 1271.6478511697733,
            "rating_q025": 1224.1064861324385
        },
        "llama-3-70b-instruct": {
            "rating": 1247.2920276555874,
            "rating_q975": 1254.1692672230822,
            "rating_q025": 1240.4147880880926
        },
        "athene-v2-chat": {
            "rating": 1246.3122055292451,
            "rating_q975": 1255.078885425127,
            "rating_q025": 1237.5455256333632
        },
        "gemma-2-9b-it": {
            "rating": 1244.5752546560923,
            "rating_q975": 1251.2753468208277,
            "rating_q025": 1237.8751624913568
        },
        "reka-core-20240904": {
            "rating": 1244.0612007243062,
            "rating_q975": 1261.145687019827,
            "rating_q025": 1226.9767144287855
        },
        "qwen2.5-72b-instruct": {
            "rating": 1241.9145020278875,
            "rating_q975": 1249.651792890243,
            "rating_q025": 1234.1772111655318
        },
        "amazon-nova-pro-v1.0": {
            "rating": 1237.073768443554,
            "rating_q975": 1245.5223614775387,
            "rating_q025": 1228.6251754095692
        },
        "claude-3-sonnet-20240229": {
            "rating": 1235.4244849212218,
            "rating_q975": 1242.9749651368531,
            "rating_q025": 1227.8740047055906
        },
        "command-r-plus": {
            "rating": 1235.0674457684026,
            "rating_q975": 1243.1643334631722,
            "rating_q025": 1226.9705580736331
        },
        "glm-4-0520": {
            "rating": 1231.131860722639,
            "rating_q975": 1245.5057756893218,
            "rating_q025": 1216.7579457559561
        },
        "reka-flash-20240904": {
            "rating": 1225.3595481866723,
            "rating_q975": 1242.0135468702306,
            "rating_q025": 1208.705549503114
        },
        "mistral-small-24b-instruct-2501": {
            "rating": 1222.7862146885664,
            "rating_q975": 1234.2176446992514,
            "rating_q025": 1211.3547846778813
        },
        "c4ai-aya-expanse-32b": {
            "rating": 1219.057522261503,
            "rating_q975": 1228.038441875829,
            "rating_q025": 1210.076602647177
        },
        "qwen2-72b-instruct": {
            "rating": 1218.970307365566,
            "rating_q975": 1227.898040641683,
            "rating_q025": 1210.0425740894489
        },
        "claude-3-haiku-20240307": {
            "rating": 1216.9202812983276,
            "rating_q975": 1223.8842185073765,
            "rating_q025": 1209.9563440892787
        },
        "gemini-1.5-flash-8b-001": {
            "rating": 1215.6349210151163,
            "rating_q975": 1223.8152876114336,
            "rating_q025": 1207.454554418799
        },
        "command-r-08-2024": {
            "rating": 1213.1576638594286,
            "rating_q975": 1227.3332839249626,
            "rating_q025": 1198.9820437938945
        },
        "mistral-large-2402": {
            "rating": 1209.8826370318263,
            "rating_q975": 1218.6163389806438,
            "rating_q025": 1201.1489350830088
        },
        "deepseek-coder-v2": {
            "rating": 1208.5799757179798,
            "rating_q975": 1220.7617617210024,
            "rating_q025": 1196.3981897149572
        },
        "jamba-1.5-mini": {
            "rating": 1206.8822895431908,
            "rating_q975": 1222.0508128823485,
            "rating_q025": 1191.7137662040332
        },
        "amazon-nova-lite-v1.0": {
            "rating": 1204.800764780718,
            "rating_q975": 1214.6083304201024,
            "rating_q025": 1194.9931991413337
        },
        "phi-4": {
            "rating": 1199.9813181504596,
            "rating_q975": 1208.8534827218996,
            "rating_q025": 1191.1091535790197
        },
        "mixtral-8x22b-instruct-v0.1": {
            "rating": 1199.4557024878586,
            "rating_q975": 1208.162882459211,
            "rating_q025": 1190.7485225165062
        },
        "reka-flash-21b-20240226-online": {
            "rating": 1194.5814081081712,
            "rating_q975": 1208.6666822073842,
            "rating_q025": 1180.4961340089583
        },
        "gpt-3.5-turbo-0125": {
            "rating": 1192.014508084494,
            "rating_q975": 1200.2850024383522,
            "rating_q025": 1183.744013730636
        },
        "command-r": {
            "rating": 1191.6665264091582,
            "rating_q975": 1200.743865488205,
            "rating_q025": 1182.5891873301114
        },
        "amazon-nova-micro-v1.0": {
            "rating": 1191.1966309658178,
            "rating_q975": 1201.073734343163,
            "rating_q025": 1181.3195275884725
        },
        "qwen1.5-110b-chat": {
            "rating": 1189.638221269146,
            "rating_q975": 1200.5078283974808,
            "rating_q025": 1178.7686141408112
        },
        "ministral-8b-2410": {
            "rating": 1187.252578487712,
            "rating_q975": 1207.501763195054,
            "rating_q025": 1167.00339378037
        },
        "zephyr-orpo-141b-A35b-v0.1": {
            "rating": 1186.7557639687175,
            "rating_q975": 1209.9238859740167,
            "rating_q025": 1163.5876419634183
        },
        "mistral-medium": {
            "rating": 1186.555488694078,
            "rating_q975": 1197.0466709996815,
            "rating_q025": 1176.0643063884743
        },
        "llama-3-8b-instruct": {
            "rating": 1184.3447533509989,
            "rating_q975": 1191.839717474211,
            "rating_q025": 1176.8497892277867
        },
        "qwen2.5-coder-32b-instruct": {
            "rating": 1184.240135142626,
            "rating_q975": 1202.7722676005874,
            "rating_q025": 1165.7080026846647
        },
        "qwen1.5-72b-chat": {
            "rating": 1183.9153849516529,
            "rating_q975": 1193.7733282379832,
            "rating_q025": 1174.0574416653226
        },
        "gemini-pro-dev-api": {
            "rating": 1183.0520186006652,
            "rating_q975": 1197.0553937620948,
            "rating_q025": 1169.0486434392355
        },
        "hunyuan-standard-256k": {
            "rating": 1182.8221738761235,
            "rating_q975": 1212.07565114558,
            "rating_q025": 1153.5686966066671
        },
        "c4ai-aya-expanse-8b": {
            "rating": 1179.064201150583,
            "rating_q975": 1192.6187737410064,
            "rating_q025": 1165.5096285601594
        },
        "llama-3.1-tulu-3-8b": {
            "rating": 1177.6118006408499,
            "rating_q975": 1200.5802971863739,
            "rating_q025": 1154.643304095326
        },
        "gemini-pro": {
            "rating": 1172.591188366297,
            "rating_q975": 1193.46162901908,
            "rating_q025": 1151.7207477135141
        },
        "wizardlm-70b": {
            "rating": 1172.277408779121,
            "rating_q975": 1189.718064126086,
            "rating_q025": 1154.8367534321562
        },
        "llama-3.1-8b-instruct": {
            "rating": 1171.8550007153672,
            "rating_q975": 1179.5077383341547,
            "rating_q025": 1164.2022630965796
        },
        "gemma-2-2b-it": {
            "rating": 1169.1478651250588,
            "rating_q975": 1176.7010937342486,
            "rating_q025": 1161.594636515869
        },
        "tulu-2-dpo-70b": {
            "rating": 1168.581986443743,
            "rating_q975": 1188.6213858612923,
            "rating_q025": 1148.5425870261938
        },
        "openchat-3.5": {
            "rating": 1168.3213856007774,
            "rating_q975": 1185.5223033104485,
            "rating_q025": 1151.1204678911063
        },
        "dbrx-instruct-preview": {
            "rating": 1167.165489744307,
            "rating_q975": 1178.4804740010593,
            "rating_q025": 1155.8505054875548
        },
        "granite-3.1-8b-instruct": {
            "rating": 1163.7520913250792,
            "rating_q975": 1188.7603950779296,
            "rating_q025": 1138.7437875722287
        },
        "mixtral-8x7b-instruct-v0.1": {
            "rating": 1163.6776310049422,
            "rating_q975": 1171.8284517628638,
            "rating_q025": 1155.5268102470206
        },
        "vicuna-33b": {
            "rating": 1162.3402794241813,
            "rating_q975": 1174.207158708115,
            "rating_q025": 1150.4734001402476
        },
        "reka-flash-21b-20240226": {
            "rating": 1159.9189782427065,
            "rating_q975": 1171.5625557856813,
            "rating_q025": 1148.2754006997318
        },
        "gpt-3.5-turbo-1106": {
            "rating": 1157.4534588598935,
            "rating_q975": 1172.4223387755706,
            "rating_q025": 1142.4845789442165
        },
        "yi-34b-chat": {
            "rating": 1156.7277804254995,
            "rating_q975": 1169.9063379154545,
            "rating_q025": 1143.5492229355445
        },
        "yi-1.5-34b-chat": {
            "rating": 1150.2984028926458,
            "rating_q975": 1160.7727601154115,
            "rating_q025": 1139.82404566988
        },
        "openhermes-2.5-mistral-7b": {
            "rating": 1147.103795730601,
            "rating_q975": 1168.1607305377447,
            "rating_q025": 1126.0468609234572
        },
        "gemma-1.1-7b-it": {
            "rating": 1146.7880711113444,
            "rating_q975": 1158.062006640721,
            "rating_q025": 1135.5141355819678
        },
        "granite-3.1-2b-instruct": {
            "rating": 1145.8009301620323,
            "rating_q975": 1169.6188728448424,
            "rating_q025": 1121.9829874792222
        },
        "snowflake-arctic-instruct": {
            "rating": 1142.5320478146436,
            "rating_q975": 1154.2314634047207,
            "rating_q025": 1130.8326322245666
        },
        "llama-3.2-3b-instruct": {
            "rating": 1139.8101423103008,
            "rating_q975": 1157.933082924803,
            "rating_q025": 1121.6872016957984
        },
        "granite-3.0-8b-instruct": {
            "rating": 1138.826897788796,
            "rating_q975": 1159.35449364484,
            "rating_q025": 1118.299301932752
        },
        "qwen1.5-32b-chat": {
            "rating": 1138.134009753206,
            "rating_q975": 1150.1425428863395,
            "rating_q025": 1126.1254766200727
        },
        "openchat-3.5-0106": {
            "rating": 1137.7556758845164,
            "rating_q975": 1152.2349916324104,
            "rating_q025": 1123.2763601366225
        },
        "guanaco-33b": {
            "rating": 1137.5838430094095,
            "rating_q975": 1167.1653378718966,
            "rating_q025": 1108.0023481469225
        },
        "deepseek-llm-67b-chat": {
            "rating": 1137.2984636275921,
            "rating_q975": 1158.540866337587,
            "rating_q025": 1116.0560609175973
        },
        "wizardlm-13b": {
            "rating": 1137.2250578964085,
            "rating_q975": 1155.434452385513,
            "rating_q025": 1119.0156634073041
        },
        "falcon-180b-chat": {
            "rating": 1137.0198653372672,
            "rating_q975": 1174.6014632580245,
            "rating_q025": 1099.43826741651
        },
        "phi-3-medium-4k-instruct": {
            "rating": 1133.9230359271169,
            "rating_q975": 1144.2374196031105,
            "rating_q025": 1123.6086522511232
        },
        "starling-lm-7b-alpha": {
            "rating": 1131.0237382179375,
            "rating_q975": 1146.299098706036,
            "rating_q025": 1115.7483777298391
        },
        "mpt-30b-chat": {
            "rating": 1126.9119317224697,
            "rating_q975": 1156.0875174991456,
            "rating_q025": 1097.7363459457938
        },
        "qwen1.5-14b-chat": {
            "rating": 1122.814728473957,
            "rating_q975": 1136.4615626328357,
            "rating_q025": 1109.1678943150785
        },
        "internlm2_5-20b-chat": {
            "rating": 1121.1703390498246,
            "rating_q975": 1137.012408893508,
            "rating_q025": 1105.3282692061412
        },
        "solar-10.7b-instruct-v1.0": {
            "rating": 1120.2107390813337,
            "rating_q975": 1144.2640624115875,
            "rating_q025": 1096.15741575108
        },
        "dolphin-2.2.1-mistral-7b": {
            "rating": 1115.6743073726875,
            "rating_q975": 1149.109603613628,
            "rating_q025": 1082.239011131747
        },
        "zephyr-7b-beta": {
            "rating": 1112.8814814377445,
            "rating_q975": 1128.6663600960276,
            "rating_q025": 1097.0966027794614
        },
        "phi-3-small-8k-instruct": {
            "rating": 1111.6370882468354,
            "rating_q975": 1124.01876485416,
            "rating_q025": 1099.2554116395108
        },
        "starling-lm-7b-beta": {
            "rating": 1111.5524684634765,
            "rating_q975": 1126.3234330882688,
            "rating_q025": 1096.7815038386843
        },
        "nous-hermes-2-mixtral-8x7b-dpo": {
            "rating": 1110.5910367755841,
            "rating_q975": 1134.3040233455622,
            "rating_q025": 1086.878050205606
        },
        "llama-2-70b-chat": {
            "rating": 1109.6029473306105,
            "rating_q975": 1119.3717794021434,
            "rating_q025": 1099.8341152590776
        },
        "llama2-70b-steerlm-chat": {
            "rating": 1108.1663366789153,
            "rating_q975": 1132.8405063010146,
            "rating_q025": 1083.492167056816
        },
        "vicuna-13b": {
            "rating": 1107.4080878217364,
            "rating_q975": 1119.8251308454187,
            "rating_q025": 1094.9910447980542
        },
        "mistral-7b-instruct-v0.2": {
            "rating": 1106.7166002075855,
            "rating_q975": 1118.814151647304,
            "rating_q025": 1094.619048767867
        },
        "granite-3.0-2b-instruct": {
            "rating": 1103.5661721461493,
            "rating_q975": 1124.3803278407113,
            "rating_q025": 1082.7520164515872
        },
        "qwq-32b-preview": {
            "rating": 1103.1339478102946,
            "rating_q975": 1130.0271328614042,
            "rating_q025": 1076.240762759185
        },
        "llama-2-13b-chat": {
            "rating": 1100.3451901506858,
            "rating_q975": 1112.6781040732803,
            "rating_q025": 1088.0122762280912
        },
        "zephyr-7b-alpha": {
            "rating": 1096.918093121559,
            "rating_q975": 1128.8201755057178,
            "rating_q025": 1065.0160107374002
        },
        "vicuna-7b": {
            "rating": 1093.8099994291779,
            "rating_q975": 1111.4368473868637,
            "rating_q025": 1076.183151471492
        },
        "palm-2": {
            "rating": 1092.7819791743234,
            "rating_q975": 1110.4958556984352,
            "rating_q025": 1075.0681026502116
        },
        "phi-3-mini-4k-instruct-june-2024": {
            "rating": 1088.521246414299,
            "rating_q975": 1102.3087560719703,
            "rating_q025": 1074.7337367566276
        },
        "gemma-7b-it": {
            "rating": 1085.6623272474596,
            "rating_q975": 1103.2551379038412,
            "rating_q025": 1068.0695165910781
        },
        "stripedhyena-nous-7b": {
            "rating": 1084.9042569838375,
            "rating_q975": 1106.1056294336458,
            "rating_q025": 1063.7028845340292
        },
        "phi-3-mini-128k-instruct": {
            "rating": 1083.1269320910442,
            "rating_q975": 1097.2168229042127,
            "rating_q025": 1069.0370412778757
        },
        "qwen1.5-7b-chat": {
            "rating": 1082.711439692636,
            "rating_q975": 1105.3059654450278,
            "rating_q025": 1060.1169139402443
        },
        "gemma-1.1-2b-it": {
            "rating": 1082.3045513252841,
            "rating_q975": 1098.973868981788,
            "rating_q025": 1065.6352336687803
        },
        "qwen-14b-chat": {
            "rating": 1081.439707794894,
            "rating_q975": 1102.723778214723,
            "rating_q025": 1060.155637375065
        },
        "llama-3.2-1b-instruct": {
            "rating": 1078.4397018043285,
            "rating_q975": 1097.374852458474,
            "rating_q025": 1059.504551150183
        },
        "codellama-34b-instruct": {
            "rating": 1077.1672896009136,
            "rating_q975": 1093.9332406364374,
            "rating_q025": 1060.4013385653898
        },
        "mistral-7b-instruct": {
            "rating": 1075.998193466523,
            "rating_q975": 1093.3523845108398,
            "rating_q025": 1058.644002422206
        },
        "smollm2-1.7b-instruct": {
            "rating": 1074.2464822811812,
            "rating_q975": 1107.8219428258524,
            "rating_q025": 1040.67102173651
        },
        "alpaca-13b": {
            "rating": 1067.1321265422634,
            "rating_q975": 1088.8004468287015,
            "rating_q025": 1045.4638062558254
        },
        "phi-3-mini-4k-instruct": {
            "rating": 1066.790600020066,
            "rating_q975": 1078.9413915001005,
            "rating_q025": 1054.6398085400315
        },
        "llama-2-7b-chat": {
            "rating": 1065.5669184399378,
            "rating_q975": 1079.0652843423954,
            "rating_q025": 1052.0685525374802
        },
        "gemma-2b-it": {
            "rating": 1063.418372785036,
            "rating_q975": 1086.4850121989878,
            "rating_q025": 1040.351733371084
        },
        "gpt4all-13b-snoozy": {
            "rating": 1045.084974260582,
            "rating_q975": 1082.6637207964059,
            "rating_q025": 1007.506227724758
        },
        "qwen1.5-4b-chat": {
            "rating": 1043.8139195327992,
            "rating_q975": 1062.0375922511607,
            "rating_q025": 1025.5902468144377
        },
        "mpt-7b-chat": {
            "rating": 1030.9901575473423,
            "rating_q975": 1055.3817145890569,
            "rating_q025": 1006.5986005056277
        },
        "koala-13b": {
            "rating": 1025.6407203325607,
            "rating_q975": 1046.0491874459829,
            "rating_q025": 1005.2322532191384
        },
        "olmo-7b-instruct": {
            "rating": 1022.9404975415436,
            "rating_q975": 1043.9113326082297,
            "rating_q025": 1001.9696624748574
        },
        "chatglm3-6b": {
            "rating": 1013.3053483975648,
            "rating_q975": 1036.9594090696853,
            "rating_q025": 989.6512877254441
        },
        "chatglm2-6b": {
            "rating": 991.1285609155029,
            "rating_q975": 1019.0995896863781,
            "rating_q025": 963.1575321446278
        },
        "RWKV-4-Raven-14B": {
            "rating": 986.6007988122395,
            "rating_q975": 1008.7551879380215,
            "rating_q025": 964.4464096864575
        },
        "oasst-pythia-12b": {
            "rating": 982.6357207583937,
            "rating_q975": 1003.9957830369719,
            "rating_q025": 961.2756584798155
        },
        "fastchat-t5-3b": {
            "rating": 953.9494921325763,
            "rating_q975": 978.7828186779888,
            "rating_q025": 929.1161655871639
        },
        "llama-13b": {
            "rating": 931.5097875496381,
            "rating_q975": 963.6758970308074,
            "rating_q025": 899.3436780684688
        },
        "dolly-v2-12b": {
            "rating": 931.459135970999,
            "rating_q975": 959.424585372074,
            "rating_q025": 903.493686569924
        },
        "chatglm-6b": {
            "rating": 909.298096528459,
            "rating_q975": 934.1254831548839,
            "rating_q025": 884.4707099020342
        },
        "stablelm-tuned-alpha-7b": {
            "rating": 901.8811444053756,
            "rating_q975": 930.8242723157641,
            "rating_q025": 872.9380164949871
        }
    },
    "industry_legal_and_government": {
        "gemini-2.5-pro": {
            "rating": 1469.591813262499,
            "rating_q975": 1480.4524043985389,
            "rating_q025": 1458.7312221264592
        },
        "gpt-4.5-preview-2025-02-27": {
            "rating": 1468.7692407952807,
            "rating_q975": 1491.2538829584284,
            "rating_q025": 1446.2845986321329
        },
        "claude-opus-4-1-20250805-thinking-16k": {
            "rating": 1467.2071083865114,
            "rating_q975": 1482.4352554017605,
            "rating_q025": 1451.9789613712624
        },
        "deepseek-v3.1-terminus-thinking": {
            "rating": 1459.8223925091404,
            "rating_q975": 1495.3251915116944,
            "rating_q025": 1424.3195935065864
        },
        "gpt-5-chat": {
            "rating": 1458.9453288958414,
            "rating_q975": 1474.1796977791057,
            "rating_q025": 1443.710960012577
        },
        "claude-opus-4-1-20250805": {
            "rating": 1458.6645195517394,
            "rating_q975": 1471.3569623692788,
            "rating_q025": 1445.9720767342
        },
        "chatgpt-4o-latest-20250326": {
            "rating": 1457.7550151372002,
            "rating_q975": 1469.8507559429852,
            "rating_q025": 1445.6592743314152
        },
        "gpt-5-high": {
            "rating": 1457.6802841051085,
            "rating_q975": 1473.3036482681418,
            "rating_q025": 1442.0569199420752
        },
        "kimi-k2-0905-preview": {
            "rating": 1456.9496473863408,
            "rating_q975": 1479.5622185120956,
            "rating_q025": 1434.337076260586
        },
        "o3-2025-04-16": {
            "rating": 1456.7390716822456,
            "rating_q975": 1467.626462049228,
            "rating_q025": 1445.8516813152632
        },
        "claude-sonnet-4-5-20250929-thinking-32k": {
            "rating": 1445.8576476942312,
            "rating_q975": 1469.1684350005773,
            "rating_q025": 1422.546860387885
        },
        "claude-sonnet-4-5-20250929": {
            "rating": 1444.7537885486513,
            "rating_q975": 1474.10846383545,
            "rating_q025": 1415.3991132618526
        },
        "claude-opus-4-20250514": {
            "rating": 1441.6580172317056,
            "rating_q975": 1453.23780485111,
            "rating_q025": 1430.0782296123011
        },
        "gpt-4.1-2025-04-14": {
            "rating": 1439.5875052634776,
            "rating_q975": 1451.0418084194598,
            "rating_q025": 1428.1332021074954
        },
        "claude-opus-4-20250514-thinking-16k": {
            "rating": 1435.5009109091018,
            "rating_q975": 1448.23077707555,
            "rating_q025": 1422.7710447426537
        },
        "glm-4.6": {
            "rating": 1433.614318961805,
            "rating_q975": 1459.6180833777455,
            "rating_q025": 1407.6105545458647
        },
        "qwen3-vl-235b-a22b-instruct": {
            "rating": 1431.2858319332804,
            "rating_q975": 1456.5655583501657,
            "rating_q025": 1406.006105516395
        },
        "grok-4-fast": {
            "rating": 1430.0059752719635,
            "rating_q975": 1457.7731758427087,
            "rating_q025": 1402.2387747012183
        },
        "gemini-2.5-flash": {
            "rating": 1428.2065018098222,
            "rating_q975": 1438.7639673760825,
            "rating_q025": 1417.6490362435618
        },
        "qwen3-235b-a22b-instruct-2507": {
            "rating": 1424.778361387366,
            "rating_q975": 1438.2156744938345,
            "rating_q025": 1411.3410482808974
        },
        "kimi-k2-0711-preview": {
            "rating": 1424.4856202114554,
            "rating_q975": 1439.3426602699556,
            "rating_q025": 1409.6285801529552
        },
        "grok-4-0709": {
            "rating": 1423.9337626817878,
            "rating_q975": 1437.1678821066787,
            "rating_q025": 1410.699643256897
        },
        "qwen3-max-preview": {
            "rating": 1423.018549630591,
            "rating_q975": 1438.7395908163446,
            "rating_q025": 1407.2975084448374
        },
        "deepseek-v3.2-exp-thinking": {
            "rating": 1422.4604249291344,
            "rating_q975": 1448.5250183834203,
            "rating_q025": 1396.3958314748486
        },
        "deepseek-v3.1": {
            "rating": 1422.1139334799734,
            "rating_q975": 1440.5306263420675,
            "rating_q025": 1403.6972406178793
        },
        "gemini-2.5-flash-preview-09-2025": {
            "rating": 1421.6367568900644,
            "rating_q975": 1443.155633539896,
            "rating_q025": 1400.1178802402328
        },
        "deepseek-v3.1-terminus": {
            "rating": 1419.6603427098867,
            "rating_q975": 1454.6666140680704,
            "rating_q025": 1384.654071351703
        },
        "deepseek-v3.1-thinking": {
            "rating": 1417.23450259978,
            "rating_q975": 1438.0759817619453,
            "rating_q025": 1396.3930234376146
        },
        "mistral-medium-2508": {
            "rating": 1417.2184208702035,
            "rating_q975": 1431.6747399338935,
            "rating_q025": 1402.7621018065136
        },
        "qwen3-max-2025-09-23": {
            "rating": 1416.0398176657197,
            "rating_q975": 1440.6954151164448,
            "rating_q025": 1391.3842202149947
        },
        "claude-sonnet-4-20250514": {
            "rating": 1415.6439475503564,
            "rating_q975": 1427.9251180700296,
            "rating_q025": 1403.3627770306832
        },
        "grok-3-preview-02-24": {
            "rating": 1413.930621168347,
            "rating_q975": 1428.1383266794105,
            "rating_q025": 1399.7229156572835
        },
        "glm-4.5": {
            "rating": 1413.132561951745,
            "rating_q975": 1429.0712150548732,
            "rating_q025": 1397.1939088486167
        },
        "claude-sonnet-4-20250514-thinking-32k": {
            "rating": 1412.6493659650093,
            "rating_q975": 1425.831206392868,
            "rating_q025": 1399.4675255371508
        },
        "qwen3-next-80b-a3b-instruct": {
            "rating": 1410.676021922645,
            "rating_q975": 1428.1887741070277,
            "rating_q025": 1393.1632697382624
        },
        "mistral-medium-2505": {
            "rating": 1410.0985079603452,
            "rating_q975": 1423.1775350347748,
            "rating_q025": 1397.0194808859155
        },
        "deepseek-r1-0528": {
            "rating": 1409.4178370874815,
            "rating_q975": 1425.8456265081138,
            "rating_q025": 1392.9900476668493
        },
        "o1-2024-12-17": {
            "rating": 1408.4445202706934,
            "rating_q975": 1423.7877111661735,
            "rating_q025": 1393.1013293752133
        },
        "deepseek-v3-0324": {
            "rating": 1407.7666687646913,
            "rating_q975": 1419.2599868368325,
            "rating_q025": 1396.2733506925501
        },
        "claude-3-7-sonnet-20250219-thinking-32k": {
            "rating": 1406.6273850825644,
            "rating_q975": 1418.994793492758,
            "rating_q025": 1394.2599766723708
        },
        "gpt-4.1-mini-2025-04-14": {
            "rating": 1402.564689541913,
            "rating_q975": 1414.8570605426662,
            "rating_q025": 1390.2723185411596
        },
        "o4-mini-2025-04-16": {
            "rating": 1401.9564375179211,
            "rating_q975": 1413.8642007502265,
            "rating_q025": 1390.0486742856158
        },
        "qwen3-235b-a22b-no-thinking": {
            "rating": 1400.8370230483158,
            "rating_q975": 1413.16703586627,
            "rating_q025": 1388.5070102303616
        },
        "mai-1-preview": {
            "rating": 1399.1072074872254,
            "rating_q975": 1416.9313034021757,
            "rating_q025": 1381.2831115722752
        },
        "deepseek-r1": {
            "rating": 1398.6131210056874,
            "rating_q975": 1416.2043113413904,
            "rating_q025": 1381.0219306699844
        },
        "qwen3-coder-480b-a35b-instruct": {
            "rating": 1398.0377269088394,
            "rating_q975": 1414.0300666120042,
            "rating_q025": 1382.0453872056746
        },
        "qwen3-vl-235b-a22b-thinking": {
            "rating": 1397.063445408364,
            "rating_q975": 1422.8078404130872,
            "rating_q025": 1371.3190504036409
        },
        "gemini-2.5-flash-lite-preview-09-2025-no-thinking": {
            "rating": 1394.780864128268,
            "rating_q975": 1416.3166459050585,
            "rating_q025": 1373.2450823514773
        },
        "o1-preview": {
            "rating": 1394.7738345180087,
            "rating_q975": 1408.5330958744087,
            "rating_q025": 1381.0145731616087
        },
        "gpt-5-mini-high": {
            "rating": 1390.9813776955907,
            "rating_q975": 1407.6080336407417,
            "rating_q025": 1374.3547217504397
        },
        "claude-3-5-sonnet-20241022": {
            "rating": 1390.2777691724725,
            "rating_q975": 1398.773711376815,
            "rating_q025": 1381.78182696813
        },
        "claude-haiku-4-5-20251001": {
            "rating": 1389.9782615129504,
            "rating_q975": 1417.3995828134416,
            "rating_q025": 1362.5569402124593
        },
        "qwen3-235b-a22b-thinking-2507": {
            "rating": 1387.4582477315266,
            "rating_q975": 1411.8670123972688,
            "rating_q025": 1363.0494830657844
        },
        "deepseek-v3": {
            "rating": 1386.5137440779465,
            "rating_q975": 1402.58022036439,
            "rating_q025": 1370.447267791503
        },
        "hunyuan-t1-20250711": {
            "rating": 1386.006243733584,
            "rating_q975": 1420.0422972886163,
            "rating_q025": 1351.9701901785515
        },
        "longcat-flash-chat": {
            "rating": 1384.6994756788083,
            "rating_q975": 1406.1758817975906,
            "rating_q025": 1363.223069560026
        },
        "qwen2.5-max": {
            "rating": 1384.6994398305555,
            "rating_q975": 1398.4909604830893,
            "rating_q025": 1370.9079191780218
        },
        "gemini-2.5-flash-lite-preview-06-17-thinking": {
            "rating": 1383.8937332189655,
            "rating_q975": 1397.2370008028386,
            "rating_q025": 1370.5504656350925
        },
        "gemma-3-27b-it": {
            "rating": 1382.482480462597,
            "rating_q975": 1394.2282041790936,
            "rating_q025": 1370.7367567461006
        },
        "glm-4-plus-0111": {
            "rating": 1382.0731747207485,
            "rating_q975": 1411.7924365766362,
            "rating_q025": 1352.3539128648608
        },
        "gemini-2.0-flash-lite-preview-02-05": {
            "rating": 1381.9340913917242,
            "rating_q975": 1397.2015247536713,
            "rating_q025": 1366.6666580297772
        },
        "gemini-advanced-0514": {
            "rating": 1381.4271031364115,
            "rating_q975": 1394.8687874243635,
            "rating_q025": 1367.9854188484594
        },
        "gemma-3-12b-it": {
            "rating": 1380.305453896557,
            "rating_q975": 1419.5228765341183,
            "rating_q025": 1341.088031258996
        },
        "qwen3-30b-a3b-instruct-2507": {
            "rating": 1379.9870585648252,
            "rating_q975": 1395.672176841989,
            "rating_q025": 1364.3019402876614
        },
        "grok-3-mini-high": {
            "rating": 1379.398106776752,
            "rating_q975": 1396.8754793494052,
            "rating_q025": 1361.9207342040988
        },
        "hunyuan-turbos-20250416": {
            "rating": 1378.7575836524766,
            "rating_q975": 1399.9740546673643,
            "rating_q025": 1357.5411126375889
        },
        "qwen-plus-0125": {
            "rating": 1378.4798181266162,
            "rating_q975": 1406.832944885656,
            "rating_q025": 1350.1266913675765
        },
        "gpt-4o-2024-05-13": {
            "rating": 1375.718875894821,
            "rating_q975": 1384.7610763647406,
            "rating_q025": 1366.6766754249013
        },
        "command-a-03-2025": {
            "rating": 1374.9872388429737,
            "rating_q975": 1386.0244699886389,
            "rating_q025": 1363.9500076973086
        },
        "llama-3.1-405b-instruct-bf16": {
            "rating": 1374.909664174892,
            "rating_q975": 1387.215390199246,
            "rating_q025": 1362.603938150538
        },
        "llama-3.1-405b-instruct-fp8": {
            "rating": 1374.8591606722998,
            "rating_q975": 1385.6165529525683,
            "rating_q025": 1364.1017683920313
        },
        "mistral-small-2506": {
            "rating": 1371.2250084638326,
            "rating_q975": 1388.5040115611937,
            "rating_q025": 1353.9460053664716
        },
        "gemini-1.5-pro-002": {
            "rating": 1370.711770576641,
            "rating_q975": 1381.1357927653153,
            "rating_q025": 1360.2877483879665
        },
        "glm-4.5v": {
            "rating": 1369.336639933366,
            "rating_q975": 1404.2307215648427,
            "rating_q025": 1334.4425583018894
        },
        "yi-lightning": {
            "rating": 1367.952653576989,
            "rating_q975": 1382.3243183162579,
            "rating_q025": 1353.58098883772
        },
        "glm-4.5-air": {
            "rating": 1366.6611033611161,
            "rating_q975": 1381.639341066247,
            "rating_q025": 1351.6828656559853
        },
        "minimax-m1": {
            "rating": 1366.4684365924277,
            "rating_q975": 1379.1335840696902,
            "rating_q025": 1353.8032891151652
        },
        "grok-2-2024-08-13": {
            "rating": 1366.0116214981085,
            "rating_q975": 1376.2568928576297,
            "rating_q025": 1355.7663501385873
        },
        "qwen3-235b-a22b": {
            "rating": 1364.2745368317048,
            "rating_q975": 1378.4594040047891,
            "rating_q025": 1350.0896696586206
        },
        "o3-mini-high": {
            "rating": 1361.3404519101446,
            "rating_q975": 1379.423364954618,
            "rating_q025": 1343.2575388656712
        },
        "amazon-nova-experimental-chat-10-09": {
            "rating": 1361.1063767956657,
            "rating_q975": 1396.7038095452267,
            "rating_q025": 1325.5089440461047
        },
        "claude-3-5-sonnet-20240620": {
            "rating": 1359.069746290042,
            "rating_q975": 1369.1978576781469,
            "rating_q025": 1348.9416349019373
        },
        "grok-3-mini-beta": {
            "rating": 1355.7719753252372,
            "rating_q975": 1371.3215078099806,
            "rating_q025": 1340.2224428404938
        },
        "qwen3-next-80b-a3b-thinking": {
            "rating": 1355.4297159508167,
            "rating_q975": 1376.2534840866274,
            "rating_q025": 1334.605947815006
        },
        "claude-3-opus-20240229": {
            "rating": 1355.2947960173856,
            "rating_q975": 1363.738324210933,
            "rating_q025": 1346.8512678238383
        },
        "gpt-4o-2024-08-06": {
            "rating": 1353.422507766508,
            "rating_q975": 1365.120833476876,
            "rating_q025": 1341.72418205614
        },
        "gpt-4.1-nano-2025-04-14": {
            "rating": 1352.5486868148319,
            "rating_q975": 1381.385892973832,
            "rating_q025": 1323.7114806558318
        },
        "claude-3-5-haiku-20241022": {
            "rating": 1352.523288991944,
            "rating_q975": 1362.3247049674512,
            "rating_q025": 1342.7218730164366
        },
        "glm-4-plus": {
            "rating": 1351.3165460809962,
            "rating_q975": 1365.8628557118025,
            "rating_q025": 1336.77023645019
        },
        "llama-3.3-70b-instruct": {
            "rating": 1348.3604739818074,
            "rating_q975": 1358.7998179612355,
            "rating_q025": 1337.9211300023794
        },
        "gpt-4o-mini-2024-07-18": {
            "rating": 1347.9826852872359,
            "rating_q975": 1358.0173111393303,
            "rating_q025": 1337.9480594351414
        },
        "nvidia-llama-3.3-nemotron-super-49b-v1.5": {
            "rating": 1347.685100885634,
            "rating_q975": 1383.351477166038,
            "rating_q025": 1312.01872460523
        },
        "step-2-16k-exp-202412": {
            "rating": 1346.3053095736786,
            "rating_q975": 1379.680752712664,
            "rating_q025": 1312.9298664346934
        },
        "llama-4-scout-17b-16e-instruct": {
            "rating": 1346.1634861441144,
            "rating_q975": 1360.1534859336577,
            "rating_q025": 1332.173486354571
        },
        "ling-flash-2.0": {
            "rating": 1345.76389656358,
            "rating_q975": 1373.8160581485563,
            "rating_q025": 1317.7117349786035
        },
        "llama-4-maverick-17b-128e-instruct": {
            "rating": 1344.7529198195052,
            "rating_q975": 1357.0212044291097,
            "rating_q025": 1332.4846352099007
        },
        "o1-mini": {
            "rating": 1343.5214349325597,
            "rating_q975": 1354.509747568952,
            "rating_q025": 1332.5331222961674
        },
        "mistral-large-2407": {
            "rating": 1343.324564325772,
            "rating_q975": 1354.8269305630065,
            "rating_q025": 1331.8221980885373
        },
        "gpt-4-turbo-2024-04-09": {
            "rating": 1342.6674170732638,
            "rating_q975": 1352.8860481272172,
            "rating_q025": 1332.4487860193103
        },
        "step-3": {
            "rating": 1342.2496521688659,
            "rating_q975": 1370.9152576626843,
            "rating_q025": 1313.5840466750474
        },
        "hunyuan-standard-2025-02-10": {
            "rating": 1341.6366976557797,
            "rating_q975": 1375.417550585339,
            "rating_q025": 1307.8558447262203
        },
        "o3-mini": {
            "rating": 1340.5931074638709,
            "rating_q975": 1350.7445349538245,
            "rating_q025": 1330.4416799739172
        },
        "gemma-3-4b-it": {
            "rating": 1339.9289707893806,
            "rating_q975": 1376.3740809276317,
            "rating_q025": 1303.4838606511296
        },
        "llama-3.1-nemotron-51b-instruct": {
            "rating": 1339.4970733055125,
            "rating_q975": 1374.9965941643054,
            "rating_q025": 1303.9975524467195
        },
        "qwq-32b": {
            "rating": 1337.622711773254,
            "rating_q975": 1352.258092338199,
            "rating_q025": 1322.987331208309
        },
        "hunyuan-large-2025-02-10": {
            "rating": 1337.5328329891931,
            "rating_q975": 1373.6012400424902,
            "rating_q025": 1301.464425935896
        },
        "gemini-1.5-pro-001": {
            "rating": 1336.195583369444,
            "rating_q975": 1347.021973073369,
            "rating_q025": 1325.3691936655189
        },
        "gpt-oss-120b": {
            "rating": 1335.859712724035,
            "rating_q975": 1351.2929656995502,
            "rating_q025": 1320.4264597485198
        },
        "deepseek-v2.5": {
            "rating": 1334.7513971313665,
            "rating_q975": 1349.5746005828196,
            "rating_q025": 1319.9281936799134
        },
        "athene-70b-0725": {
            "rating": 1334.248831913431,
            "rating_q975": 1352.980139301748,
            "rating_q025": 1315.5175245251141
        },
        "gpt-4-0125-preview": {
            "rating": 1333.3101079627227,
            "rating_q975": 1344.0910743919867,
            "rating_q025": 1322.5291415334586
        },
        "reka-core-20240904": {
            "rating": 1333.0864370731467,
            "rating_q975": 1361.8390238842596,
            "rating_q025": 1304.3338502620338
        },
        "llama-3.1-70b-instruct": {
            "rating": 1332.5429294200953,
            "rating_q975": 1343.548722249763,
            "rating_q025": 1321.5371365904277
        },
        "qwen2.5-72b-instruct": {
            "rating": 1332.0274468167868,
            "rating_q975": 1344.1357946786493,
            "rating_q025": 1319.9190989549243
        },
        "gpt-5-nano-high": {
            "rating": 1331.8964116504737,
            "rating_q975": 1359.9882749164822,
            "rating_q025": 1303.8045483844653
        },
        "gemini-1.5-flash-002": {
            "rating": 1331.3088972455284,
            "rating_q975": 1344.1477486716208,
            "rating_q025": 1318.470045819436
        },
        "gemma-2-9b-it-simpo": {
            "rating": 1331.1258134290222,
            "rating_q975": 1355.5228559836487,
            "rating_q025": 1306.7287708743957
        },
        "gpt-oss-20b": {
            "rating": 1329.5969220274676,
            "rating_q975": 1353.416676806718,
            "rating_q025": 1305.7771672482172
        },
        "grok-2-mini-2024-08-13": {
            "rating": 1329.4895554831724,
            "rating_q975": 1340.6711686337037,
            "rating_q025": 1318.307942332641
        },
        "jamba-1.5-large": {
            "rating": 1329.368740089483,
            "rating_q975": 1356.399754119107,
            "rating_q025": 1302.337726059859
        },
        "qwen-max-0919": {
            "rating": 1328.556456098374,
            "rating_q975": 1346.0579911190864,
            "rating_q025": 1311.0549210776614
        },
        "mistral-large-2411": {
            "rating": 1328.4772936722943,
            "rating_q975": 1343.006425124892,
            "rating_q025": 1313.9481622196965
        },
        "deepseek-v2.5-1210": {
            "rating": 1328.3661861594542,
            "rating_q975": 1357.7980351627868,
            "rating_q025": 1298.9343371561215
        },
        "athene-v2-chat": {
            "rating": 1327.4275453524347,
            "rating_q975": 1342.6139021491617,
            "rating_q025": 1312.2411885557076
        },
        "amazon-nova-pro-v1.0": {
            "rating": 1327.001114416235,
            "rating_q975": 1342.7588885309558,
            "rating_q025": 1311.243340301514
        },
        "llama-3.1-nemotron-70b-instruct": {
            "rating": 1326.1051247729858,
            "rating_q975": 1352.5377343480388,
            "rating_q025": 1299.6725151979329
        },
        "qwen2.5-plus-1127": {
            "rating": 1325.8045327452417,
            "rating_q975": 1349.4927465853864,
            "rating_q025": 1302.116318905097
        },
        "command-r-plus-08-2024": {
            "rating": 1324.6328001901152,
            "rating_q975": 1347.732303449287,
            "rating_q025": 1301.5332969309434
        },
        "qwen3-30b-a3b": {
            "rating": 1324.075539561403,
            "rating_q975": 1338.134259877128,
            "rating_q025": 1310.016819245678
        },
        "gemma-3n-e4b-it": {
            "rating": 1324.0379772643312,
            "rating_q975": 1339.8720121700317,
            "rating_q025": 1308.2039423586307
        },
        "qwen3-32b": {
            "rating": 1323.9988514357055,
            "rating_q975": 1356.9275313014873,
            "rating_q025": 1291.0701715699238
        },
        "nemotron-4-340b-instruct": {
            "rating": 1322.3347021099767,
            "rating_q975": 1339.991970610293,
            "rating_q025": 1304.6774336096603
        },
        "step-1o-turbo-202506": {
            "rating": 1322.011079211235,
            "rating_q975": 1345.3430302026673,
            "rating_q025": 1298.6791282198028
        },
        "gpt-4-1106-preview": {
            "rating": 1320.5172922851837,
            "rating_q975": 1331.044999503036,
            "rating_q025": 1309.9895850673313
        },
        "command-r-plus": {
            "rating": 1319.7639755208638,
            "rating_q975": 1331.3708252534243,
            "rating_q025": 1308.1571257883033
        },
        "glm-4-0520": {
            "rating": 1317.730334987774,
            "rating_q975": 1342.1104455342966,
            "rating_q025": 1293.3502244412516
        },
        "gemma-2-27b-it": {
            "rating": 1316.089493686654,
            "rating_q975": 1325.5806423334973,
            "rating_q025": 1306.5983450398105
        },
        "qwen2.5-coder-32b-instruct": {
            "rating": 1312.2193547449544,
            "rating_q975": 1346.3965957248718,
            "rating_q025": 1278.0421137650371
        },
        "claude-3-sonnet-20240229": {
            "rating": 1311.1687695124033,
            "rating_q975": 1322.2100214706018,
            "rating_q025": 1300.1275175542048
        },
        "mistral-small-3.1-24b-instruct-2503": {
            "rating": 1310.2244605905507,
            "rating_q975": 1323.5652214649363,
            "rating_q025": 1296.8836997161652
        },
        "gemini-1.5-flash-001": {
            "rating": 1309.5979189123627,
            "rating_q975": 1321.0258588157105,
            "rating_q025": 1298.169979009015
        },
        "command-r-08-2024": {
            "rating": 1307.8661446605493,
            "rating_q975": 1331.9660330096665,
            "rating_q025": 1283.766256311432
        },
        "llama-3-70b-instruct": {
            "rating": 1306.964936033942,
            "rating_q975": 1316.6114741098193,
            "rating_q025": 1297.3183979580647
        },
        "magistral-medium-2506": {
            "rating": 1304.4130107809874,
            "rating_q975": 1326.9836095764376,
            "rating_q025": 1281.8424119855372
        },
        "gpt-4-0314": {
            "rating": 1304.1525940298045,
            "rating_q975": 1317.7623583106808,
            "rating_q025": 1290.5428297489282
        },
        "c4ai-aya-expanse-32b": {
            "rating": 1303.191039715984,
            "rating_q975": 1317.2325348706756,
            "rating_q025": 1289.1495445612925
        },
        "phi-4": {
            "rating": 1302.2432841569764,
            "rating_q975": 1318.6416625675076,
            "rating_q025": 1285.8449057464452
        },
        "gemini-1.5-flash-8b-001": {
            "rating": 1298.7116508240356,
            "rating_q975": 1311.5735618168871,
            "rating_q025": 1285.849739831184
        },
        "hunyuan-large-vision": {
            "rating": 1292.8481478994968,
            "rating_q975": 1324.585894973913,
            "rating_q025": 1261.1104008250807
        },
        "claude-3-haiku-20240307": {
            "rating": 1292.7918033655433,
            "rating_q975": 1302.774425061321,
            "rating_q025": 1282.8091816697656
        },
        "reka-flash-20240904": {
            "rating": 1291.301631835243,
            "rating_q975": 1320.8770065777196,
            "rating_q025": 1261.7262570927662
        },
        "ring-flash-2.0": {
            "rating": 1290.5364019278713,
            "rating_q975": 1319.6484034623477,
            "rating_q025": 1261.424400393395
        },
        "jamba-1.5-mini": {
            "rating": 1289.9348726398887,
            "rating_q975": 1315.2020030537844,
            "rating_q025": 1264.667742225993
        },
        "command-r": {
            "rating": 1289.2547445199543,
            "rating_q975": 1302.404797955146,
            "rating_q025": 1276.1046910847626
        },
        "gemma-2-9b-it": {
            "rating": 1288.9015363810631,
            "rating_q975": 1299.7046739593022,
            "rating_q025": 1278.098398802824
        },
        "reka-flash-21b-20240226-online": {
            "rating": 1288.3605140463155,
            "rating_q975": 1308.877188827358,
            "rating_q025": 1267.8438392652731
        },
        "amazon-nova-lite-v1.0": {
            "rating": 1285.1070107317641,
            "rating_q975": 1302.926132229115,
            "rating_q025": 1267.2878892344133
        },
        "gpt-4-0613": {
            "rating": 1284.0048004760329,
            "rating_q975": 1295.553773496451,
            "rating_q025": 1272.4558274556148
        },
        "deepseek-coder-v2": {
            "rating": 1283.4137133416818,
            "rating_q975": 1303.332597898392,
            "rating_q025": 1263.4948287849718
        },
        "qwen2-72b-instruct": {
            "rating": 1282.1585448586397,
            "rating_q975": 1295.4312293394394,
            "rating_q025": 1268.8858603778401
        },
        "mistral-small-24b-instruct-2501": {
            "rating": 1278.6304716718746,
            "rating_q975": 1299.1022523455522,
            "rating_q025": 1258.158690998197
        },
        "olmo-2-0325-32b-instruct": {
            "rating": 1277.6197198056009,
            "rating_q975": 1318.38375126306,
            "rating_q025": 1236.8556883481417
        },
        "mistral-large-2402": {
            "rating": 1277.5140240080236,
            "rating_q975": 1290.2980920684358,
            "rating_q025": 1264.7299559476114
        },
        "qwen1.5-110b-chat": {
            "rating": 1276.2606181537535,
            "rating_q975": 1292.8797200317813,
            "rating_q025": 1259.6415162757257
        },
        "ministral-8b-2410": {
            "rating": 1273.2584278840352,
            "rating_q975": 1307.0656555752603,
            "rating_q025": 1239.4512001928101
        },
        "gemini-pro-dev-api": {
            "rating": 1273.0009303807583,
            "rating_q975": 1293.9945264833245,
            "rating_q025": 1252.007334278192
        },
        "reka-flash-21b-20240226": {
            "rating": 1269.4340500573262,
            "rating_q975": 1287.0030898138575,
            "rating_q025": 1251.865010300795
        },
        "c4ai-aya-expanse-8b": {
            "rating": 1269.0365409224346,
            "rating_q975": 1294.2589183350242,
            "rating_q025": 1243.814163509845
        },
        "amazon-nova-micro-v1.0": {
            "rating": 1268.6043634151797,
            "rating_q975": 1286.9386590963716,
            "rating_q025": 1250.2700677339878
        },
        "qwen1.5-72b-chat": {
            "rating": 1268.406383540325,
            "rating_q975": 1282.8551826092503,
            "rating_q025": 1253.9575844713995
        },
        "mixtral-8x22b-instruct-v0.1": {
            "rating": 1264.5348063286162,
            "rating_q975": 1277.4158111847923,
            "rating_q025": 1251.6538014724401
        },
        "mistral-medium": {
            "rating": 1261.3309483268654,
            "rating_q975": 1277.0936026478798,
            "rating_q025": 1245.568294005851
        },
        "gpt-3.5-turbo-0125": {
            "rating": 1261.220353582762,
            "rating_q975": 1273.1150405302108,
            "rating_q025": 1249.3256666353134
        },
        "granite-3.1-8b-instruct": {
            "rating": 1258.1222378806972,
            "rating_q975": 1300.0819054181284,
            "rating_q025": 1216.162570343266
        },
        "yi-1.5-34b-chat": {
            "rating": 1257.136102330594,
            "rating_q975": 1273.070344999576,
            "rating_q025": 1241.201859661612
        },
        "llama-3-8b-instruct": {
            "rating": 1252.011036755006,
            "rating_q975": 1262.7149661102023,
            "rating_q025": 1241.3071073998096
        },
        "llama-3.1-8b-instruct": {
            "rating": 1247.7538979064757,
            "rating_q975": 1259.3888302624662,
            "rating_q025": 1236.1189655504852
        },
        "openchat-3.5": {
            "rating": 1239.7548904671708,
            "rating_q975": 1267.9407793187345,
            "rating_q025": 1211.569001615607
        },
        "qwen1.5-32b-chat": {
            "rating": 1237.2267869119732,
            "rating_q975": 1254.5790135321467,
            "rating_q025": 1219.8745602917998
        },
        "mixtral-8x7b-instruct-v0.1": {
            "rating": 1233.790043801994,
            "rating_q975": 1245.6947296737126,
            "rating_q025": 1221.8853579302754
        },
        "zephyr-orpo-141b-A35b-v0.1": {
            "rating": 1230.372204512808,
            "rating_q975": 1268.4172688763085,
            "rating_q025": 1192.3271401493073
        },
        "gemini-pro": {
            "rating": 1230.3619807572736,
            "rating_q975": 1264.421600684906,
            "rating_q025": 1196.3023608296412
        },
        "yi-34b-chat": {
            "rating": 1228.2605375419898,
            "rating_q975": 1249.64358507089,
            "rating_q025": 1206.8774900130898
        },
        "wizardlm-70b": {
            "rating": 1227.198265585157,
            "rating_q975": 1256.0256127953007,
            "rating_q025": 1198.3709183750134
        },
        "tulu-2-dpo-70b": {
            "rating": 1225.2993970186635,
            "rating_q975": 1255.640990182423,
            "rating_q025": 1194.9578038549041
        },
        "gemma-2-2b-it": {
            "rating": 1223.3735306260219,
            "rating_q975": 1235.5882464591114,
            "rating_q025": 1211.1588147929324
        },
        "openhermes-2.5-mistral-7b": {
            "rating": 1221.1586727895256,
            "rating_q975": 1257.3117866053647,
            "rating_q025": 1185.0055589736864
        },
        "phi-3-medium-4k-instruct": {
            "rating": 1219.92788853188,
            "rating_q975": 1235.92284879348,
            "rating_q025": 1203.93292827028
        },
        "dbrx-instruct-preview": {
            "rating": 1218.5155075377847,
            "rating_q975": 1234.8025387376222,
            "rating_q025": 1202.2284763379473
        },
        "gpt-3.5-turbo-1106": {
            "rating": 1217.0774417315454,
            "rating_q975": 1239.3809576001922,
            "rating_q025": 1194.7739258628985
        },
        "gemma-1.1-7b-it": {
            "rating": 1217.0541587368912,
            "rating_q975": 1234.037788864362,
            "rating_q025": 1200.0705286094203
        },
        "openchat-3.5-0106": {
            "rating": 1214.3970114612812,
            "rating_q975": 1238.556380755623,
            "rating_q025": 1190.2376421669394
        },
        "qwen1.5-14b-chat": {
            "rating": 1213.7093959000626,
            "rating_q975": 1232.811930817655,
            "rating_q025": 1194.6068609824704
        },
        "starling-lm-7b-beta": {
            "rating": 1212.9276119679694,
            "rating_q975": 1233.8757079137179,
            "rating_q025": 1191.9795160222209
        },
        "deepseek-llm-67b-chat": {
            "rating": 1211.430594649372,
            "rating_q975": 1246.2360297403693,
            "rating_q025": 1176.625159558375
        },
        "starling-lm-7b-alpha": {
            "rating": 1210.6481195117901,
            "rating_q975": 1237.3078309583832,
            "rating_q025": 1183.988408065197
        },
        "snowflake-arctic-instruct": {
            "rating": 1207.8223157033747,
            "rating_q975": 1225.6825028444628,
            "rating_q025": 1189.9621285622866
        },
        "hunyuan-standard-256k": {
            "rating": 1203.5336211055776,
            "rating_q975": 1247.1174900062065,
            "rating_q025": 1159.9497522049487
        },
        "phi-3-small-8k-instruct": {
            "rating": 1202.6313569488343,
            "rating_q975": 1220.5118110188048,
            "rating_q025": 1184.7509028788638
        },
        "wizardlm-13b": {
            "rating": 1202.5060020110116,
            "rating_q975": 1234.5465393471557,
            "rating_q025": 1170.4654646748675
        },
        "granite-3.0-8b-instruct": {
            "rating": 1200.9627891498985,
            "rating_q975": 1235.043241324113,
            "rating_q025": 1166.882336975684
        },
        "vicuna-33b": {
            "rating": 1198.0836025734736,
            "rating_q975": 1216.8409644569715,
            "rating_q025": 1179.3262406899757
        },
        "internlm2_5-20b-chat": {
            "rating": 1197.7264634378314,
            "rating_q975": 1221.049513398917,
            "rating_q025": 1174.4034134767458
        },
        "llama-2-70b-chat": {
            "rating": 1196.5998724939654,
            "rating_q975": 1211.5761525837224,
            "rating_q025": 1181.6235924042085
        },
        "zephyr-7b-beta": {
            "rating": 1194.5591842327663,
            "rating_q975": 1220.2793532523488,
            "rating_q025": 1168.8390152131838
        },
        "llama-3.2-3b-instruct": {
            "rating": 1194.362382944138,
            "rating_q975": 1222.478659715748,
            "rating_q025": 1166.246106172528
        },
        "mistral-7b-instruct-v0.2": {
            "rating": 1192.6951889772963,
            "rating_q975": 1212.781983413899,
            "rating_q025": 1172.6083945406936
        },
        "solar-10.7b-instruct-v1.0": {
            "rating": 1191.1517817214592,
            "rating_q975": 1230.732098420573,
            "rating_q025": 1151.5714650223454
        },
        "granite-3.0-2b-instruct": {
            "rating": 1190.2978373329033,
            "rating_q975": 1222.2376256902558,
            "rating_q025": 1158.358048975551
        },
        "qwen1.5-7b-chat": {
            "rating": 1186.6231850267134,
            "rating_q975": 1227.2328185153494,
            "rating_q025": 1146.0135515380773
        },
        "qwen-14b-chat": {
            "rating": 1182.765805204599,
            "rating_q975": 1220.2979239824917,
            "rating_q025": 1145.2336864267063
        },
        "vicuna-13b": {
            "rating": 1180.4422362088353,
            "rating_q975": 1201.9988269824853,
            "rating_q025": 1158.8856454351853
        },
        "palm-2": {
            "rating": 1168.4255415958978,
            "rating_q975": 1200.7978557330712,
            "rating_q025": 1136.0532274587245
        },
        "codellama-34b-instruct": {
            "rating": 1166.4054918123452,
            "rating_q975": 1198.3911996168226,
            "rating_q025": 1134.4197840078677
        },
        "gemma-7b-it": {
            "rating": 1165.0320590452616,
            "rating_q975": 1193.705949330112,
            "rating_q025": 1136.3581687604112
        },
        "llama-2-13b-chat": {
            "rating": 1162.072708442999,
            "rating_q975": 1182.6179045383235,
            "rating_q025": 1141.5275123476747
        },
        "phi-3-mini-4k-instruct": {
            "rating": 1161.6889147838824,
            "rating_q975": 1180.6268877875577,
            "rating_q025": 1142.750941780207
        },
        "phi-3-mini-4k-instruct-june-2024": {
            "rating": 1161.1897932268128,
            "rating_q975": 1185.7799405225126,
            "rating_q025": 1136.599645931113
        },
        "mistral-7b-instruct": {
            "rating": 1160.387524730745,
            "rating_q975": 1189.5784389040346,
            "rating_q025": 1131.1966105574556
        },
        "qwq-32b-preview": {
            "rating": 1157.0283909630898,
            "rating_q975": 1199.713467668747,
            "rating_q025": 1114.3433142574327
        },
        "vicuna-7b": {
            "rating": 1155.4266246843636,
            "rating_q975": 1190.3957081607552,
            "rating_q025": 1120.4575412079719
        },
        "llama-3.2-1b-instruct": {
            "rating": 1155.3306997708821,
            "rating_q975": 1185.2572763608594,
            "rating_q025": 1125.404123180905
        },
        "qwen1.5-4b-chat": {
            "rating": 1150.8066465050333,
            "rating_q975": 1182.9628962574363,
            "rating_q025": 1118.6503967526303
        },
        "gemma-2b-it": {
            "rating": 1147.5041198993677,
            "rating_q975": 1185.6869286974859,
            "rating_q025": 1109.3213111012494
        },
        "llama-2-7b-chat": {
            "rating": 1143.7342057518408,
            "rating_q975": 1165.9863799585717,
            "rating_q025": 1121.48203154511
        },
        "phi-3-mini-128k-instruct": {
            "rating": 1126.5062247456867,
            "rating_q975": 1148.6694558961888,
            "rating_q025": 1104.3429935951847
        },
        "gemma-1.1-2b-it": {
            "rating": 1125.64709238013,
            "rating_q975": 1153.260771415,
            "rating_q025": 1098.0334133452602
        },
        "stripedhyena-nous-7b": {
            "rating": 1122.4714467797098,
            "rating_q975": 1158.032469517109,
            "rating_q025": 1086.9104240423108
        },
        "RWKV-4-Raven-14B": {
            "rating": 1119.6757725998805,
            "rating_q975": 1167.474585756163,
            "rating_q025": 1071.876959443598
        },
        "olmo-7b-instruct": {
            "rating": 1111.1652959122998,
            "rating_q975": 1146.5454503045048,
            "rating_q025": 1075.7851415200948
        },
        "alpaca-13b": {
            "rating": 1106.0258015602778,
            "rating_q975": 1149.6357305982372,
            "rating_q025": 1062.4158725223185
        },
        "chatglm3-6b": {
            "rating": 1102.5383103278741,
            "rating_q975": 1143.2871262151316,
            "rating_q025": 1061.7894944406166
        },
        "koala-13b": {
            "rating": 1089.6326966873082,
            "rating_q975": 1130.0774239894183,
            "rating_q025": 1049.1879693851981
        },
        "oasst-pythia-12b": {
            "rating": 1075.829906602868,
            "rating_q975": 1117.1592087022036,
            "rating_q025": 1034.5006045035325
        },
        "fastchat-t5-3b": {
            "rating": 1039.6253415177832,
            "rating_q975": 1086.197147053497,
            "rating_q025": 993.0535359820695
        },
        "chatglm-6b": {
            "rating": 1001.4791339345545,
            "rating_q975": 1049.3336207554278,
            "rating_q025": 953.6246471136812
        }
    },
    "industry_life_and_physical_and_social_science": {
        "gemini-2.5-pro": {
            "rating": 1478.3046748034549,
            "rating_q975": 1485.4372346804803,
            "rating_q025": 1471.1721149264295
        },
        "claude-sonnet-4-5-20250929-thinking-32k": {
            "rating": 1470.6017819842461,
            "rating_q975": 1484.406346459208,
            "rating_q025": 1456.7972175092843
        },
        "claude-opus-4-1-20250805-thinking-16k": {
            "rating": 1469.2465612254668,
            "rating_q975": 1478.66550458707,
            "rating_q025": 1459.8276178638637
        },
        "claude-sonnet-4-5-20250929": {
            "rating": 1464.57032213117,
            "rating_q975": 1483.1841934868844,
            "rating_q025": 1445.9564507754558
        },
        "o3-2025-04-16": {
            "rating": 1463.7810463898738,
            "rating_q975": 1470.8721648735354,
            "rating_q025": 1456.6899279062122
        },
        "claude-opus-4-1-20250805": {
            "rating": 1463.0085349128456,
            "rating_q975": 1471.3362281469335,
            "rating_q025": 1454.6808416787576
        },
        "chatgpt-4o-latest-20250326": {
            "rating": 1460.2991306297315,
            "rating_q975": 1467.6540564565667,
            "rating_q025": 1452.9442048028964
        },
        "qwen3-max-preview": {
            "rating": 1456.8088300364923,
            "rating_q975": 1467.009096336036,
            "rating_q025": 1446.6085637369486
        },
        "deepseek-v3.1-terminus": {
            "rating": 1454.769057184555,
            "rating_q975": 1479.366049518741,
            "rating_q025": 1430.1720648503692
        },
        "gpt-4.5-preview-2025-02-27": {
            "rating": 1450.7566371554767,
            "rating_q975": 1462.5134953894726,
            "rating_q025": 1438.9997789214808
        },
        "glm-4.6": {
            "rating": 1450.4540941836315,
            "rating_q975": 1465.0199373612738,
            "rating_q025": 1435.888251005989
        },
        "gpt-5-high": {
            "rating": 1449.3041295422968,
            "rating_q975": 1458.7901202511807,
            "rating_q025": 1439.8181388334128
        },
        "gpt-5-chat": {
            "rating": 1447.139116290068,
            "rating_q975": 1456.432689020106,
            "rating_q025": 1437.84554356003
        },
        "deepseek-v3.1-terminus-thinking": {
            "rating": 1446.9981955980663,
            "rating_q975": 1472.1721024824465,
            "rating_q025": 1421.8242887136862
        },
        "qwen3-vl-235b-a22b-instruct": {
            "rating": 1445.5148444629906,
            "rating_q975": 1461.8746925923836,
            "rating_q025": 1429.1549963335976
        },
        "deepseek-v3.2-exp-thinking": {
            "rating": 1445.3433336494732,
            "rating_q975": 1460.4546888705179,
            "rating_q025": 1430.2319784284284
        },
        "grok-4-fast": {
            "rating": 1443.2612382236794,
            "rating_q975": 1462.1767988050096,
            "rating_q025": 1424.345677642349
        },
        "claude-opus-4-20250514-thinking-16k": {
            "rating": 1442.8883802368314,
            "rating_q975": 1451.137666988247,
            "rating_q025": 1434.6390934854157
        },
        "qwen3-235b-a22b-instruct-2507": {
            "rating": 1442.4440597970201,
            "rating_q975": 1450.9251261682557,
            "rating_q025": 1433.9629934257846
        },
        "gemini-2.5-flash-preview-09-2025": {
            "rating": 1441.2399160336784,
            "rating_q975": 1454.4821055730124,
            "rating_q025": 1427.9977264943443
        },
        "kimi-k2-0905-preview": {
            "rating": 1440.7157677873256,
            "rating_q975": 1456.1077627360496,
            "rating_q025": 1425.3237728386016
        },
        "deepseek-v3.1": {
            "rating": 1439.6204158660662,
            "rating_q975": 1452.0566481512446,
            "rating_q025": 1427.1841835808877
        },
        "grok-4-0709": {
            "rating": 1438.2593730832798,
            "rating_q975": 1446.5424678197585,
            "rating_q025": 1429.976278346801
        },
        "qwen3-max-2025-09-23": {
            "rating": 1437.2619212554162,
            "rating_q975": 1452.8110995402385,
            "rating_q025": 1421.7127429705938
        },
        "kimi-k2-0711-preview": {
            "rating": 1436.6380100290844,
            "rating_q975": 1446.0026479479643,
            "rating_q025": 1427.2733721102045
        },
        "claude-opus-4-20250514": {
            "rating": 1433.5657924059021,
            "rating_q975": 1441.32789274881,
            "rating_q025": 1425.8036920629943
        },
        "deepseek-v3.1-thinking": {
            "rating": 1431.8036607625788,
            "rating_q975": 1445.381314989993,
            "rating_q025": 1418.2260065351647
        },
        "mistral-medium-2508": {
            "rating": 1431.2787123543076,
            "rating_q975": 1440.698086839808,
            "rating_q025": 1421.8593378688072
        },
        "gemini-2.5-flash": {
            "rating": 1427.6054552913845,
            "rating_q975": 1434.6192786159268,
            "rating_q025": 1420.5916319668422
        },
        "gpt-4.1-2025-04-14": {
            "rating": 1426.1234723655195,
            "rating_q975": 1433.334615915409,
            "rating_q025": 1418.9123288156302
        },
        "glm-4.5": {
            "rating": 1423.5292136848857,
            "rating_q975": 1433.3633709531905,
            "rating_q025": 1413.6950564165809
        },
        "claude-sonnet-4-20250514-thinking-32k": {
            "rating": 1422.2012442301207,
            "rating_q975": 1430.4743554365716,
            "rating_q025": 1413.9281330236697
        },
        "deepseek-r1-0528": {
            "rating": 1420.0215392165358,
            "rating_q975": 1430.4495366818678,
            "rating_q025": 1409.5935417512037
        },
        "claude-haiku-4-5-20251001": {
            "rating": 1419.5920831347657,
            "rating_q975": 1435.0112853669582,
            "rating_q025": 1404.1728809025733
        },
        "qwen3-next-80b-a3b-instruct": {
            "rating": 1419.3918232178733,
            "rating_q975": 1430.6766606339404,
            "rating_q025": 1408.106985801806
        },
        "hunyuan-t1-20250711": {
            "rating": 1418.7183440386723,
            "rating_q975": 1440.5953414335293,
            "rating_q025": 1396.8413466438153
        },
        "claude-sonnet-4-20250514": {
            "rating": 1417.1943002640937,
            "rating_q975": 1425.2664225488722,
            "rating_q025": 1409.1221779793152
        },
        "grok-3-preview-02-24": {
            "rating": 1416.0904789914186,
            "rating_q975": 1424.2301155432936,
            "rating_q025": 1407.9508424395437
        },
        "qwen3-235b-a22b-no-thinking": {
            "rating": 1415.188527960179,
            "rating_q975": 1423.4324758247492,
            "rating_q025": 1406.944580095609
        },
        "o1-2024-12-17": {
            "rating": 1414.743933899081,
            "rating_q975": 1423.4546751352907,
            "rating_q025": 1406.0331926628712
        },
        "deepseek-v3-0324": {
            "rating": 1414.2833867068548,
            "rating_q975": 1421.5248889253678,
            "rating_q025": 1407.0418844883418
        },
        "deepseek-r1": {
            "rating": 1412.4700342752878,
            "rating_q975": 1422.627172867326,
            "rating_q025": 1402.3128956832497
        },
        "qwen3-235b-a22b-thinking-2507": {
            "rating": 1411.4652520495788,
            "rating_q975": 1426.5484150088037,
            "rating_q025": 1396.382089090354
        },
        "hunyuan-turbos-20250416": {
            "rating": 1411.278982785835,
            "rating_q975": 1424.5581982254316,
            "rating_q025": 1397.9997673462385
        },
        "claude-3-7-sonnet-20250219-thinking-32k": {
            "rating": 1411.040227107488,
            "rating_q975": 1418.9834316385613,
            "rating_q025": 1403.0970225764145
        },
        "o4-mini-2025-04-16": {
            "rating": 1409.2444488662663,
            "rating_q975": 1416.7052514298653,
            "rating_q025": 1401.7836463026674
        },
        "qwen3-vl-235b-a22b-thinking": {
            "rating": 1407.7265058943049,
            "rating_q975": 1424.4543968764085,
            "rating_q025": 1390.9986149122012
        },
        "mai-1-preview": {
            "rating": 1407.6886164372931,
            "rating_q975": 1418.6458760778264,
            "rating_q025": 1396.7313567967599
        },
        "mistral-medium-2505": {
            "rating": 1406.2469747246653,
            "rating_q975": 1414.6509136207203,
            "rating_q025": 1397.8430358286103
        },
        "gpt-5-mini-high": {
            "rating": 1404.7177665777203,
            "rating_q975": 1415.1236349398366,
            "rating_q025": 1394.311898215604
        },
        "gemini-2.5-flash-lite-preview-09-2025-no-thinking": {
            "rating": 1402.4556493455832,
            "rating_q975": 1415.7962853128965,
            "rating_q025": 1389.1150133782699
        },
        "longcat-flash-chat": {
            "rating": 1400.6400222064276,
            "rating_q975": 1414.86104439059,
            "rating_q025": 1386.4190000222652
        },
        "qwen3-coder-480b-a35b-instruct": {
            "rating": 1397.1660831140418,
            "rating_q975": 1407.1067599224596,
            "rating_q025": 1387.2254063056241
        },
        "glm-4.5-air": {
            "rating": 1395.6660970634057,
            "rating_q975": 1404.8443887443752,
            "rating_q025": 1386.4878053824361
        },
        "qwen3-30b-a3b-instruct-2507": {
            "rating": 1395.0920369637347,
            "rating_q975": 1404.9906414579827,
            "rating_q025": 1385.1934324694867
        },
        "minimax-m1": {
            "rating": 1394.8213152780645,
            "rating_q975": 1402.8828841521863,
            "rating_q025": 1386.7597464039427
        },
        "o1-preview": {
            "rating": 1393.8525360817569,
            "rating_q975": 1402.683319265658,
            "rating_q025": 1385.0217528978558
        },
        "gemma-3-27b-it": {
            "rating": 1392.531680102253,
            "rating_q975": 1399.6637474305162,
            "rating_q025": 1385.3996127739897
        },
        "qwen2.5-max": {
            "rating": 1391.5638475479627,
            "rating_q975": 1399.493777230236,
            "rating_q025": 1383.6339178656895
        },
        "gemini-2.5-flash-lite-preview-06-17-thinking": {
            "rating": 1388.2317694900935,
            "rating_q975": 1396.8094716680475,
            "rating_q025": 1379.6540673121394
        },
        "gpt-4.1-mini-2025-04-14": {
            "rating": 1387.8210533522793,
            "rating_q975": 1395.7372155866526,
            "rating_q025": 1379.904891117906
        },
        "qwen3-235b-a22b": {
            "rating": 1386.2587423912028,
            "rating_q975": 1395.2197097171652,
            "rating_q025": 1377.2977750652403
        },
        "grok-3-mini-high": {
            "rating": 1384.0349600193463,
            "rating_q975": 1395.3067376870658,
            "rating_q025": 1372.7631823516267
        },
        "qwen-plus-0125": {
            "rating": 1383.2286510470428,
            "rating_q975": 1401.6641539569932,
            "rating_q025": 1364.7931481370924
        },
        "claude-3-5-sonnet-20241022": {
            "rating": 1381.404034785123,
            "rating_q975": 1386.9623372027102,
            "rating_q025": 1375.845732367536
        },
        "qwen3-next-80b-a3b-thinking": {
            "rating": 1378.8928758265295,
            "rating_q975": 1391.7616355561506,
            "rating_q025": 1366.0241160969083
        },
        "qwen3-32b": {
            "rating": 1378.639585674069,
            "rating_q975": 1399.202336635142,
            "rating_q025": 1358.0768347129958
        },
        "o3-mini-high": {
            "rating": 1376.1675744079578,
            "rating_q975": 1386.4976300001222,
            "rating_q025": 1365.8375188157934
        },
        "deepseek-v3": {
            "rating": 1375.7557066172412,
            "rating_q975": 1385.2157686229336,
            "rating_q025": 1366.2956446115488
        },
        "grok-3-mini-beta": {
            "rating": 1373.9592766434967,
            "rating_q975": 1383.617886611374,
            "rating_q025": 1364.3006666756194
        },
        "mistral-small-2506": {
            "rating": 1369.8674373299962,
            "rating_q975": 1380.9106082990338,
            "rating_q025": 1358.8242663609585
        },
        "command-a-03-2025": {
            "rating": 1369.5276739279311,
            "rating_q975": 1376.3662952395202,
            "rating_q025": 1362.689052616342
        },
        "nvidia-llama-3.3-nemotron-super-49b-v1.5": {
            "rating": 1369.3401500446323,
            "rating_q975": 1391.9758139229555,
            "rating_q025": 1346.7044861663092
        },
        "llama-3.1-405b-instruct-bf16": {
            "rating": 1368.8320504393994,
            "rating_q975": 1375.9291477364377,
            "rating_q025": 1361.734953142361
        },
        "gemma-3-12b-it": {
            "rating": 1368.4301845915918,
            "rating_q975": 1389.2754858539845,
            "rating_q025": 1347.584883329199
        },
        "glm-4-plus-0111": {
            "rating": 1368.0790602022812,
            "rating_q975": 1386.5182206378852,
            "rating_q025": 1349.6398997666772
        },
        "ling-flash-2.0": {
            "rating": 1367.8859778853373,
            "rating_q975": 1386.047707761842,
            "rating_q025": 1349.7242480088325
        },
        "hunyuan-turbo-0110": {
            "rating": 1366.8941413340835,
            "rating_q975": 1394.119964878132,
            "rating_q025": 1339.6683177900352
        },
        "gemini-2.0-flash-lite-preview-02-05": {
            "rating": 1365.9084799008815,
            "rating_q975": 1374.8549846782819,
            "rating_q025": 1356.9619751234811
        },
        "gemini-1.5-pro-002": {
            "rating": 1365.2447706464995,
            "rating_q975": 1371.8466500166141,
            "rating_q025": 1358.642891276385
        },
        "llama-3.1-nemotron-ultra-253b-v1": {
            "rating": 1362.8639019054249,
            "rating_q975": 1388.8895712145336,
            "rating_q025": 1336.8382325963162
        },
        "claude-3-5-sonnet-20240620": {
            "rating": 1362.0329468847472,
            "rating_q975": 1368.9690918462713,
            "rating_q025": 1355.096801923223
        },
        "glm-4.5v": {
            "rating": 1361.6373547855592,
            "rating_q975": 1383.8594122320324,
            "rating_q025": 1339.415297339086
        },
        "llama-3.3-nemotron-49b-super-v1": {
            "rating": 1361.352792066401,
            "rating_q975": 1389.7937283893689,
            "rating_q025": 1332.911855743433
        },
        "gpt-oss-120b": {
            "rating": 1360.9267775306002,
            "rating_q975": 1370.564730000054,
            "rating_q025": 1351.2888250611466
        },
        "hunyuan-turbos-20250226": {
            "rating": 1360.8364069298132,
            "rating_q975": 1388.0750784559411,
            "rating_q025": 1333.5977354036852
        },
        "gpt-4o-2024-05-13": {
            "rating": 1358.8456888883084,
            "rating_q975": 1365.1611608627181,
            "rating_q025": 1352.5302169138986
        },
        "yi-lightning": {
            "rating": 1357.9070925483288,
            "rating_q975": 1367.295265371874,
            "rating_q025": 1348.5189197247837
        },
        "llama-3.1-405b-instruct-fp8": {
            "rating": 1356.1816866676404,
            "rating_q975": 1363.1629271119432,
            "rating_q025": 1349.2004462233376
        },
        "o3-mini": {
            "rating": 1355.2135718428058,
            "rating_q975": 1361.6561721389353,
            "rating_q025": 1348.7709715466763
        },
        "gpt-4o-2024-08-06": {
            "rating": 1353.8122949733092,
            "rating_q975": 1361.5305821203315,
            "rating_q025": 1346.094007826287
        },
        "grok-2-2024-08-13": {
            "rating": 1353.3594498563266,
            "rating_q975": 1360.1171821725682,
            "rating_q025": 1346.601717540085
        },
        "step-3": {
            "rating": 1353.1521736066259,
            "rating_q975": 1371.4233543435425,
            "rating_q025": 1334.8809928697092
        },
        "amazon-nova-experimental-chat-10-09": {
            "rating": 1353.0548578558642,
            "rating_q975": 1371.802632164693,
            "rating_q025": 1334.3070835470353
        },
        "qwq-32b": {
            "rating": 1352.2717877381922,
            "rating_q975": 1361.154217990669,
            "rating_q025": 1343.3893574857154
        },
        "gpt-4.1-nano-2025-04-14": {
            "rating": 1352.1833310193379,
            "rating_q975": 1368.799085904688,
            "rating_q025": 1335.5675761339878
        },
        "gpt-5-nano-high": {
            "rating": 1349.9479981418674,
            "rating_q975": 1366.6245199190769,
            "rating_q025": 1333.271476364658
        },
        "gemini-advanced-0514": {
            "rating": 1348.7085977390207,
            "rating_q975": 1357.6857080108189,
            "rating_q025": 1339.7314874672225
        },
        "step-2-16k-exp-202412": {
            "rating": 1347.5115449825435,
            "rating_q975": 1366.915087717269,
            "rating_q025": 1328.108002247818
        },
        "llama-4-maverick-17b-128e-instruct": {
            "rating": 1347.466235725683,
            "rating_q975": 1355.3656276180825,
            "rating_q025": 1339.5668438332834
        },
        "llama-3.3-70b-instruct": {
            "rating": 1347.3434150769708,
            "rating_q975": 1353.627230744047,
            "rating_q025": 1341.0595994098946
        },
        "claude-3-opus-20240229": {
            "rating": 1346.904869916244,
            "rating_q975": 1352.6647130110248,
            "rating_q025": 1341.1450268214633
        },
        "hunyuan-large-2025-02-10": {
            "rating": 1346.368046689377,
            "rating_q975": 1367.392039958367,
            "rating_q025": 1325.3440534203871
        },
        "claude-3-5-haiku-20241022": {
            "rating": 1344.6936116963188,
            "rating_q975": 1350.8405742998136,
            "rating_q025": 1338.546649092824
        },
        "gemma-3n-e4b-it": {
            "rating": 1342.1073590680357,
            "rating_q975": 1352.0686622955145,
            "rating_q025": 1332.146055840557
        },
        "o1-mini": {
            "rating": 1342.0917499000461,
            "rating_q975": 1349.0829832420757,
            "rating_q025": 1335.1005165580166
        },
        "athene-70b-0725": {
            "rating": 1341.6232621601025,
            "rating_q975": 1352.909367989167,
            "rating_q025": 1330.337156331038
        },
        "qwen2.5-plus-1127": {
            "rating": 1340.078243381594,
            "rating_q975": 1353.536333061957,
            "rating_q025": 1326.6201537012307
        },
        "step-1o-turbo-202506": {
            "rating": 1339.6233951207935,
            "rating_q975": 1354.2404158434047,
            "rating_q025": 1325.0063743981823
        },
        "llama-4-scout-17b-16e-instruct": {
            "rating": 1339.085652253415,
            "rating_q975": 1348.0314325588442,
            "rating_q025": 1330.1398719479857
        },
        "athene-v2-chat": {
            "rating": 1338.4600384940622,
            "rating_q975": 1347.3903224563057,
            "rating_q025": 1329.5297545318188
        },
        "glm-4-plus": {
            "rating": 1337.066564082997,
            "rating_q975": 1346.4575341498396,
            "rating_q025": 1327.6755940161545
        },
        "gemini-1.5-pro-001": {
            "rating": 1336.9704183351007,
            "rating_q975": 1344.45655764021,
            "rating_q025": 1329.4842790299915
        },
        "hunyuan-standard-2025-02-10": {
            "rating": 1336.4347800154044,
            "rating_q975": 1357.8398046158075,
            "rating_q025": 1315.0297554150013
        },
        "mistral-large-2407": {
            "rating": 1335.6694593180023,
            "rating_q975": 1343.5734731049868,
            "rating_q025": 1327.7654455310178
        },
        "qwen3-30b-a3b": {
            "rating": 1335.1507073702992,
            "rating_q975": 1344.2419554712726,
            "rating_q025": 1326.0594592693258
        },
        "grok-2-mini-2024-08-13": {
            "rating": 1334.5727718690277,
            "rating_q975": 1341.6937347991764,
            "rating_q025": 1327.4518089388791
        },
        "deepseek-v2.5-1210": {
            "rating": 1334.4643358754715,
            "rating_q975": 1351.07254218876,
            "rating_q025": 1317.856129562183
        },
        "gpt-oss-20b": {
            "rating": 1334.0143154470347,
            "rating_q975": 1349.1735764995378,
            "rating_q025": 1318.8550543945316
        },
        "gpt-4-turbo-2024-04-09": {
            "rating": 1333.6636304104297,
            "rating_q975": 1340.683844539915,
            "rating_q025": 1326.6434162809444
        },
        "gemini-1.5-flash-002": {
            "rating": 1333.0343117119833,
            "rating_q975": 1341.0932466887384,
            "rating_q025": 1324.975376735228
        },
        "gpt-4o-mini-2024-07-18": {
            "rating": 1329.3565912896206,
            "rating_q975": 1335.6286395538266,
            "rating_q025": 1323.0845430254146
        },
        "qwen-max-0919": {
            "rating": 1328.473165932829,
            "rating_q975": 1339.361355780788,
            "rating_q025": 1317.58497608487
        },
        "gpt-4-1106-preview": {
            "rating": 1326.8296209090088,
            "rating_q975": 1334.112423824088,
            "rating_q025": 1319.5468179939296
        },
        "reka-core-20240904": {
            "rating": 1326.6967175730088,
            "rating_q975": 1342.9114399564128,
            "rating_q025": 1310.4819951896047
        },
        "ring-flash-2.0": {
            "rating": 1324.7138383126635,
            "rating_q975": 1342.8664135223048,
            "rating_q025": 1306.5612631030222
        },
        "deepseek-v2.5": {
            "rating": 1324.7065813207134,
            "rating_q975": 1333.992112091733,
            "rating_q025": 1315.421050549694
        },
        "gpt-4-0125-preview": {
            "rating": 1324.2957409765895,
            "rating_q975": 1331.6789939898765,
            "rating_q025": 1316.9124879633025
        },
        "llama-3.1-70b-instruct": {
            "rating": 1323.4253378356052,
            "rating_q975": 1330.4932157574126,
            "rating_q025": 1316.3574599137978
        },
        "qwen2.5-72b-instruct": {
            "rating": 1321.1131459394192,
            "rating_q975": 1328.6844576040617,
            "rating_q025": 1313.5418342747766
        },
        "magistral-medium-2506": {
            "rating": 1318.7800320343526,
            "rating_q975": 1333.4073392353,
            "rating_q025": 1304.1527248334053
        },
        "llama-3.1-nemotron-70b-instruct": {
            "rating": 1318.6911771866576,
            "rating_q975": 1334.9451608120437,
            "rating_q025": 1302.4371935612714
        },
        "mistral-large-2411": {
            "rating": 1318.5830241862802,
            "rating_q975": 1327.0711224089953,
            "rating_q025": 1310.0949259635652
        },
        "jamba-1.5-large": {
            "rating": 1317.8502940562469,
            "rating_q975": 1333.63232796568,
            "rating_q025": 1302.0682601468138
        },
        "gemma-3-4b-it": {
            "rating": 1315.8456379122604,
            "rating_q975": 1336.7819160300944,
            "rating_q025": 1294.9093597944263
        },
        "hunyuan-large-vision": {
            "rating": 1315.2229328000667,
            "rating_q975": 1334.9581414693114,
            "rating_q025": 1295.487724130822
        },
        "llama-3.1-tulu-3-70b": {
            "rating": 1312.8241636425792,
            "rating_q975": 1337.4456235086739,
            "rating_q025": 1288.2027037764844
        },
        "mistral-small-3.1-24b-instruct-2503": {
            "rating": 1312.2415159243274,
            "rating_q975": 1321.0093524717745,
            "rating_q025": 1303.4736793768802
        },
        "nemotron-4-340b-instruct": {
            "rating": 1310.4803410907775,
            "rating_q975": 1321.970281528958,
            "rating_q025": 1298.9904006525971
        },
        "command-r-plus-08-2024": {
            "rating": 1309.4590745165078,
            "rating_q975": 1323.8259984929086,
            "rating_q025": 1295.092150540107
        },
        "llama-3.1-nemotron-51b-instruct": {
            "rating": 1309.3873837927758,
            "rating_q975": 1330.9673114117306,
            "rating_q025": 1287.807456173821
        },
        "gemma-2-27b-it": {
            "rating": 1307.6693873402548,
            "rating_q975": 1313.8496398933796,
            "rating_q025": 1301.48913478713
        },
        "claude-3-sonnet-20240229": {
            "rating": 1306.7568329008775,
            "rating_q975": 1314.1309063818417,
            "rating_q025": 1299.3827594199133
        },
        "amazon-nova-pro-v1.0": {
            "rating": 1306.6407305720422,
            "rating_q975": 1315.6873989374085,
            "rating_q025": 1297.594062206676
        },
        "reka-flash-20240904": {
            "rating": 1302.253463456671,
            "rating_q975": 1318.1270059046558,
            "rating_q025": 1286.379921008686
        },
        "llama-3-70b-instruct": {
            "rating": 1301.0015025966404,
            "rating_q975": 1307.8999406252374,
            "rating_q025": 1294.1030645680435
        },
        "gemma-2-9b-it-simpo": {
            "rating": 1299.8779637189139,
            "rating_q975": 1314.6925569920115,
            "rating_q025": 1285.0633704458162
        },
        "command-r-08-2024": {
            "rating": 1298.1036727002015,
            "rating_q975": 1312.4106156890693,
            "rating_q025": 1283.7967297113337
        },
        "mistral-small-24b-instruct-2501": {
            "rating": 1298.0756683783025,
            "rating_q975": 1309.6575599802757,
            "rating_q025": 1286.4937767763292
        },
        "gemini-1.5-flash-001": {
            "rating": 1297.990794866747,
            "rating_q975": 1305.7374840012449,
            "rating_q025": 1290.244105732249
        },
        "command-r-plus": {
            "rating": 1296.3735847328844,
            "rating_q975": 1304.448730481075,
            "rating_q025": 1288.2984389846938
        },
        "gpt-4-0314": {
            "rating": 1295.2802061014936,
            "rating_q975": 1304.3233388988308,
            "rating_q025": 1286.2370733041564
        },
        "glm-4-0520": {
            "rating": 1295.1570478443748,
            "rating_q975": 1310.115065570733,
            "rating_q025": 1280.1990301180167
        },
        "olmo-2-0325-32b-instruct": {
            "rating": 1293.355296018934,
            "rating_q975": 1317.3351473612984,
            "rating_q025": 1269.3754446765697
        },
        "c4ai-aya-expanse-32b": {
            "rating": 1291.469103450731,
            "rating_q975": 1300.5041841308962,
            "rating_q025": 1282.4340227705657
        },
        "qwen2-72b-instruct": {
            "rating": 1287.8116933088793,
            "rating_q975": 1296.920478823594,
            "rating_q025": 1278.7029077941645
        },
        "gpt-4-0613": {
            "rating": 1285.8800364208948,
            "rating_q975": 1293.7690021886178,
            "rating_q025": 1277.9910706531718
        },
        "amazon-nova-lite-v1.0": {
            "rating": 1284.3003373200536,
            "rating_q975": 1294.5042390896606,
            "rating_q025": 1274.0964355504466
        },
        "gemma-2-9b-it": {
            "rating": 1283.490098226144,
            "rating_q975": 1290.5075047409318,
            "rating_q025": 1276.4726917113562
        },
        "gemini-1.5-flash-8b-001": {
            "rating": 1282.3212209349847,
            "rating_q975": 1290.3818532024577,
            "rating_q025": 1274.2605886675117
        },
        "qwen2.5-coder-32b-instruct": {
            "rating": 1281.9583409951301,
            "rating_q975": 1299.9277328388966,
            "rating_q025": 1263.9889491513636
        },
        "claude-3-haiku-20240307": {
            "rating": 1279.874496862199,
            "rating_q975": 1286.7995930923455,
            "rating_q025": 1272.9494006320526
        },
        "deepseek-coder-v2": {
            "rating": 1276.8175362498127,
            "rating_q975": 1289.3827075343136,
            "rating_q025": 1264.252364965312
        },
        "phi-4": {
            "rating": 1269.4899485144156,
            "rating_q975": 1279.0113412447606,
            "rating_q025": 1259.9685557840705
        },
        "reka-flash-21b-20240226-online": {
            "rating": 1267.3942367445966,
            "rating_q975": 1280.7974624727676,
            "rating_q025": 1253.9910110164255
        },
        "amazon-nova-micro-v1.0": {
            "rating": 1261.0112555614014,
            "rating_q975": 1271.369370473327,
            "rating_q025": 1250.6531406494757
        },
        "mistral-medium": {
            "rating": 1260.966762899602,
            "rating_q975": 1271.2511841418132,
            "rating_q025": 1250.6823416573907
        },
        "gemini-pro-dev-api": {
            "rating": 1260.475513605525,
            "rating_q975": 1274.2276243004542,
            "rating_q025": 1246.723402910596
        },
        "mistral-large-2402": {
            "rating": 1260.3131343353307,
            "rating_q975": 1269.0507565919352,
            "rating_q025": 1251.5755120787262
        },
        "mixtral-8x22b-instruct-v0.1": {
            "rating": 1259.2958483922293,
            "rating_q975": 1268.1007361524275,
            "rating_q025": 1250.4909606320311
        },
        "jamba-1.5-mini": {
            "rating": 1258.37688562606,
            "rating_q975": 1274.0581464418383,
            "rating_q025": 1242.6956248102815
        },
        "command-r": {
            "rating": 1258.2382853836702,
            "rating_q975": 1267.294866612419,
            "rating_q025": 1249.1817041549216
        },
        "qwen1.5-72b-chat": {
            "rating": 1256.054369494118,
            "rating_q975": 1265.7203486030398,
            "rating_q025": 1246.388390385196
        },
        "qwen1.5-110b-chat": {
            "rating": 1255.3986088923293,
            "rating_q975": 1266.204175529645,
            "rating_q025": 1244.5930422550136
        },
        "c4ai-aya-expanse-8b": {
            "rating": 1255.26590698856,
            "rating_q975": 1269.5235807116944,
            "rating_q025": 1241.0082332654254
        },
        "reka-flash-21b-20240226": {
            "rating": 1254.0450083848991,
            "rating_q975": 1265.358474430673,
            "rating_q025": 1242.7315423391253
        },
        "ministral-8b-2410": {
            "rating": 1253.2161533361214,
            "rating_q975": 1273.4386232779946,
            "rating_q025": 1232.9936833942481
        },
        "llama-3-8b-instruct": {
            "rating": 1250.9682549258732,
            "rating_q975": 1258.5116499166716,
            "rating_q025": 1243.424859935075
        },
        "zephyr-orpo-141b-A35b-v0.1": {
            "rating": 1248.759504858946,
            "rating_q975": 1269.641828828543,
            "rating_q025": 1227.877180889349
        },
        "hunyuan-standard-256k": {
            "rating": 1247.0111026051682,
            "rating_q975": 1272.190405921419,
            "rating_q025": 1221.8317992889174
        },
        "gemini-pro": {
            "rating": 1246.3992694272697,
            "rating_q975": 1266.8790793427008,
            "rating_q025": 1225.9194595118386
        },
        "llama-3.1-tulu-3-8b": {
            "rating": 1240.732188392058,
            "rating_q975": 1265.4284939146062,
            "rating_q025": 1216.03588286951
        },
        "yi-1.5-34b-chat": {
            "rating": 1236.6209962402413,
            "rating_q975": 1247.1603273586131,
            "rating_q025": 1226.0816651218695
        },
        "gpt-3.5-turbo-0125": {
            "rating": 1233.5613135252493,
            "rating_q975": 1241.7844167510953,
            "rating_q025": 1225.3382102994033
        },
        "llama-3.1-8b-instruct": {
            "rating": 1232.4141760127623,
            "rating_q975": 1240.0133090576683,
            "rating_q025": 1224.8150429678562
        },
        "phi-3-medium-4k-instruct": {
            "rating": 1232.2088398553951,
            "rating_q975": 1242.6422077902316,
            "rating_q025": 1221.7754719205586
        },
        "qwen1.5-32b-chat": {
            "rating": 1230.0423115812625,
            "rating_q975": 1241.411428112282,
            "rating_q025": 1218.673195050243
        },
        "granite-3.0-8b-instruct": {
            "rating": 1225.936525722887,
            "rating_q975": 1245.6275005358061,
            "rating_q025": 1206.2455509099677
        },
        "granite-3.1-8b-instruct": {
            "rating": 1225.140410097532,
            "rating_q975": 1250.3417811941758,
            "rating_q025": 1199.939039000888
        },
        "mixtral-8x7b-instruct-v0.1": {
            "rating": 1223.7604091097037,
            "rating_q975": 1231.8875145031207,
            "rating_q025": 1215.6333037162867
        },
        "dbrx-instruct-preview": {
            "rating": 1221.6653230803954,
            "rating_q975": 1233.087247502366,
            "rating_q025": 1210.243398658425
        },
        "yi-34b-chat": {
            "rating": 1220.869945798121,
            "rating_q975": 1233.9121304563334,
            "rating_q025": 1207.8277611399087
        },
        "gemma-2-2b-it": {
            "rating": 1216.6825167358588,
            "rating_q975": 1224.394964397121,
            "rating_q025": 1208.9700690745967
        },
        "internlm2_5-20b-chat": {
            "rating": 1215.7312430369539,
            "rating_q975": 1230.5291166737895,
            "rating_q025": 1200.9333694001182
        },
        "starling-lm-7b-beta": {
            "rating": 1212.1776781113354,
            "rating_q975": 1225.8582291384441,
            "rating_q025": 1198.4971270842266
        },
        "gpt-3.5-turbo-1106": {
            "rating": 1210.6488288714045,
            "rating_q975": 1225.5513349260507,
            "rating_q025": 1195.7463228167583
        },
        "wizardlm-70b": {
            "rating": 1208.9900380731553,
            "rating_q975": 1226.7333357114683,
            "rating_q025": 1191.2467404348424
        },
        "starling-lm-7b-alpha": {
            "rating": 1204.221995162456,
            "rating_q975": 1219.390837743613,
            "rating_q025": 1189.0531525812992
        },
        "snowflake-arctic-instruct": {
            "rating": 1203.404085209741,
            "rating_q975": 1214.8493139000127,
            "rating_q025": 1191.9588565194692
        },
        "llama-2-70b-chat": {
            "rating": 1203.1780155451643,
            "rating_q975": 1212.9460771454658,
            "rating_q025": 1193.4099539448628
        },
        "phi-3-small-8k-instruct": {
            "rating": 1201.0094449308326,
            "rating_q975": 1213.0704527949931,
            "rating_q025": 1188.948437066672
        },
        "vicuna-33b": {
            "rating": 1200.6686043339687,
            "rating_q975": 1212.0561176812105,
            "rating_q025": 1189.281090986727
        },
        "qwen1.5-14b-chat": {
            "rating": 1200.2818458876673,
            "rating_q975": 1213.5143400963193,
            "rating_q025": 1187.0493516790152
        },
        "gemma-1.1-7b-it": {
            "rating": 1200.0483510319095,
            "rating_q975": 1211.0728543318164,
            "rating_q025": 1189.0238477320027
        },
        "tulu-2-dpo-70b": {
            "rating": 1198.879276719579,
            "rating_q975": 1217.6386699008772,
            "rating_q025": 1180.1198835382806
        },
        "openchat-3.5": {
            "rating": 1197.0597388030317,
            "rating_q975": 1214.6214458895556,
            "rating_q025": 1179.4980317165077
        },
        "nous-hermes-2-mixtral-8x7b-dpo": {
            "rating": 1196.0536893431813,
            "rating_q975": 1218.8807064511527,
            "rating_q025": 1173.22667223521
        },
        "llama-3.2-3b-instruct": {
            "rating": 1192.7989894804607,
            "rating_q975": 1210.2277737354907,
            "rating_q025": 1175.3702052254307
        },
        "openhermes-2.5-mistral-7b": {
            "rating": 1192.0363683823346,
            "rating_q975": 1212.3441099878162,
            "rating_q025": 1171.728626776853
        },
        "openchat-3.5-0106": {
            "rating": 1191.238752416149,
            "rating_q975": 1205.3561314525637,
            "rating_q025": 1177.1213733797345
        },
        "deepseek-llm-67b-chat": {
            "rating": 1191.1516460565772,
            "rating_q975": 1212.774080627623,
            "rating_q025": 1169.5292114855313
        },
        "granite-3.0-2b-instruct": {
            "rating": 1190.9937015616688,
            "rating_q975": 1209.9330427822679,
            "rating_q025": 1172.0543603410697
        },
        "llama2-70b-steerlm-chat": {
            "rating": 1190.0601721851274,
            "rating_q975": 1214.191884523854,
            "rating_q025": 1165.9284598464008
        },
        "solar-10.7b-instruct-v1.0": {
            "rating": 1187.8973773800851,
            "rating_q975": 1211.3008533196366,
            "rating_q025": 1164.4939014405336
        },
        "granite-3.1-2b-instruct": {
            "rating": 1184.3261304791827,
            "rating_q975": 1211.8630045443565,
            "rating_q025": 1156.7892564140088
        },
        "mistral-7b-instruct-v0.2": {
            "rating": 1181.373053564224,
            "rating_q975": 1193.7726892757628,
            "rating_q025": 1168.973417852685
        },
        "dolphin-2.2.1-mistral-7b": {
            "rating": 1181.076727155641,
            "rating_q975": 1214.7401620065712,
            "rating_q025": 1147.413292304711
        },
        "wizardlm-13b": {
            "rating": 1179.7639473513937,
            "rating_q975": 1197.6736502348572,
            "rating_q025": 1161.8542444679301
        },
        "codellama-34b-instruct": {
            "rating": 1171.7986386986795,
            "rating_q975": 1189.377406357783,
            "rating_q025": 1154.219871039576
        },
        "guanaco-33b": {
            "rating": 1170.8875505797623,
            "rating_q975": 1197.2610406219192,
            "rating_q025": 1144.5140605376055
        },
        "falcon-180b-chat": {
            "rating": 1170.7717853180216,
            "rating_q975": 1212.5043364943435,
            "rating_q025": 1129.0392341416996
        },
        "palm-2": {
            "rating": 1170.4707488253928,
            "rating_q975": 1188.8035051949685,
            "rating_q025": 1152.137992455817
        },
        "qwen1.5-7b-chat": {
            "rating": 1168.505792191886,
            "rating_q975": 1189.700863276304,
            "rating_q025": 1147.310721107468
        },
        "phi-3-mini-4k-instruct-june-2024": {
            "rating": 1168.422614159304,
            "rating_q975": 1182.9298098015872,
            "rating_q025": 1153.9154185170207
        },
        "qwq-32b-preview": {
            "rating": 1166.8418470657307,
            "rating_q975": 1192.5022587511255,
            "rating_q025": 1141.1814353803359
        },
        "zephyr-7b-beta": {
            "rating": 1166.75847367311,
            "rating_q975": 1182.491992708437,
            "rating_q025": 1151.0249546377831
        },
        "llama-2-13b-chat": {
            "rating": 1166.605383482112,
            "rating_q975": 1179.2719405147602,
            "rating_q025": 1153.938826449464
        },
        "smollm2-1.7b-instruct": {
            "rating": 1163.2554592734898,
            "rating_q975": 1198.7313855625546,
            "rating_q025": 1127.779532984425
        },
        "vicuna-13b": {
            "rating": 1162.606023771103,
            "rating_q975": 1175.456269205141,
            "rating_q025": 1149.755778337065
        },
        "mpt-30b-chat": {
            "rating": 1161.8459594438855,
            "rating_q975": 1188.1155031813469,
            "rating_q025": 1135.576415706424
        },
        "phi-3-mini-4k-instruct": {
            "rating": 1153.9648000364998,
            "rating_q975": 1166.4703171418535,
            "rating_q025": 1141.4592829311462
        },
        "zephyr-7b-alpha": {
            "rating": 1152.1431456515534,
            "rating_q975": 1185.9037058028039,
            "rating_q025": 1118.3825855003029
        },
        "phi-3-mini-128k-instruct": {
            "rating": 1147.6367487714012,
            "rating_q975": 1161.317788485927,
            "rating_q025": 1133.9557090568755
        },
        "gemma-7b-it": {
            "rating": 1144.213719956775,
            "rating_q975": 1161.2945130761766,
            "rating_q025": 1127.1329268373736
        },
        "qwen-14b-chat": {
            "rating": 1144.1129799906944,
            "rating_q975": 1165.425628613111,
            "rating_q025": 1122.8003313682777
        },
        "stripedhyena-nous-7b": {
            "rating": 1141.4926309458413,
            "rating_q975": 1162.4142885449946,
            "rating_q025": 1120.5709733466879
        },
        "llama-3.2-1b-instruct": {
            "rating": 1138.9470904813304,
            "rating_q975": 1157.232883762452,
            "rating_q025": 1120.6612972002088
        },
        "mistral-7b-instruct": {
            "rating": 1137.1060946748512,
            "rating_q975": 1154.9018517206798,
            "rating_q025": 1119.3103376290226
        },
        "gemma-1.1-2b-it": {
            "rating": 1132.1882977742598,
            "rating_q975": 1148.333288392485,
            "rating_q025": 1116.0433071560346
        },
        "llama-2-7b-chat": {
            "rating": 1129.8874505022509,
            "rating_q975": 1143.1373029642648,
            "rating_q025": 1116.637598040237
        },
        "vicuna-7b": {
            "rating": 1126.3807243682786,
            "rating_q975": 1145.3036724756325,
            "rating_q025": 1107.4577762609247
        },
        "qwen1.5-4b-chat": {
            "rating": 1118.8222432615335,
            "rating_q975": 1137.3242606895499,
            "rating_q025": 1100.320225833517
        },
        "koala-13b": {
            "rating": 1112.051323330641,
            "rating_q975": 1132.7588788208889,
            "rating_q025": 1091.3437678403932
        },
        "alpaca-13b": {
            "rating": 1086.2356648034856,
            "rating_q975": 1108.1504986710852,
            "rating_q025": 1064.320830935886
        },
        "olmo-7b-instruct": {
            "rating": 1083.7083185796023,
            "rating_q975": 1103.685798560994,
            "rating_q025": 1063.7308385982105
        },
        "gemma-2b-it": {
            "rating": 1082.5777402148096,
            "rating_q975": 1105.5075007825594,
            "rating_q025": 1059.6479796470599
        },
        "mpt-7b-chat": {
            "rating": 1074.5345187778344,
            "rating_q975": 1099.3243978783921,
            "rating_q025": 1049.7446396772766
        },
        "RWKV-4-Raven-14B": {
            "rating": 1071.631973592957,
            "rating_q975": 1095.183608937706,
            "rating_q025": 1048.080338248208
        },
        "gpt4all-13b-snoozy": {
            "rating": 1068.763726359688,
            "rating_q975": 1105.3321574201855,
            "rating_q025": 1032.1952952991905
        },
        "chatglm3-6b": {
            "rating": 1058.6958476759187,
            "rating_q975": 1081.9154937022042,
            "rating_q025": 1035.4762016496331
        },
        "oasst-pythia-12b": {
            "rating": 1055.4295698037472,
            "rating_q975": 1076.7134403836378,
            "rating_q025": 1034.1456992238566
        },
        "chatglm2-6b": {
            "rating": 1050.77254255251,
            "rating_q975": 1081.1242706200658,
            "rating_q025": 1020.4208144849542
        },
        "fastchat-t5-3b": {
            "rating": 1002.5304130597567,
            "rating_q975": 1027.9263679534008,
            "rating_q025": 977.1344581661126
        },
        "llama-13b": {
            "rating": 1002.0385728251977,
            "rating_q975": 1034.8655677275824,
            "rating_q025": 969.2115779228129
        },
        "dolly-v2-12b": {
            "rating": 993.0780313736652,
            "rating_q975": 1022.4661303517847,
            "rating_q025": 963.6899323955457
        },
        "chatglm-6b": {
            "rating": 964.6614350330269,
            "rating_q975": 990.1916888926793,
            "rating_q025": 939.1311811733746
        },
        "stablelm-tuned-alpha-7b": {
            "rating": 944.5771762474658,
            "rating_q975": 972.015457284988,
            "rating_q025": 917.1388952099436
        }
    },
    "industry_mathematical": {
        "claude-sonnet-4-5-20250929-thinking-32k": {
            "rating": 1478.7264173764306,
            "rating_q975": 1502.5504179181657,
            "rating_q025": 1454.9024168346955
        },
        "o3-2025-04-16": {
            "rating": 1460.5729882729015,
            "rating_q975": 1470.8991015488593,
            "rating_q025": 1450.2468749969437
        },
        "gemini-2.5-pro": {
            "rating": 1458.097886735786,
            "rating_q975": 1468.6083876031826,
            "rating_q025": 1447.5873858683894
        },
        "deepseek-v3.1-thinking": {
            "rating": 1454.9207755836724,
            "rating_q975": 1478.7347891123713,
            "rating_q025": 1431.1067620549734
        },
        "claude-opus-4-1-20250805-thinking-16k": {
            "rating": 1453.9620779171917,
            "rating_q975": 1469.3101723024145,
            "rating_q025": 1438.6139835319689
        },
        "claude-opus-4-1-20250805": {
            "rating": 1453.699037611572,
            "rating_q975": 1466.5114817256897,
            "rating_q025": 1440.8865934974544
        },
        "glm-4.6": {
            "rating": 1450.2951125608479,
            "rating_q975": 1476.5566429672117,
            "rating_q025": 1424.033582154484
        },
        "qwen3-max-preview": {
            "rating": 1449.2897132907333,
            "rating_q975": 1466.2246745069285,
            "rating_q025": 1432.354752074538
        },
        "grok-4-0709": {
            "rating": 1447.4709689697177,
            "rating_q975": 1461.3496681199738,
            "rating_q025": 1433.5922698194615
        },
        "gpt-5-high": {
            "rating": 1447.4309357419559,
            "rating_q975": 1462.0191374531541,
            "rating_q025": 1432.8427340307576
        },
        "grok-4-fast": {
            "rating": 1444.2604730081491,
            "rating_q975": 1475.6667025250244,
            "rating_q025": 1412.8542434912738
        },
        "qwen3-vl-235b-a22b-thinking": {
            "rating": 1440.183796092622,
            "rating_q975": 1469.5508337192664,
            "rating_q025": 1410.8167584659777
        },
        "qwen3-235b-a22b-instruct-2507": {
            "rating": 1436.2487730591004,
            "rating_q975": 1449.7977635550435,
            "rating_q025": 1422.6997825631572
        },
        "qwen3-235b-a22b-thinking-2507": {
            "rating": 1435.7271407530634,
            "rating_q975": 1459.7322191669543,
            "rating_q025": 1411.7220623391725
        },
        "deepseek-v3.2-exp-thinking": {
            "rating": 1435.5063726541027,
            "rating_q975": 1465.9410625230842,
            "rating_q025": 1405.0716827851213
        },
        "gemini-2.5-flash-preview-09-2025": {
            "rating": 1434.5460556833384,
            "rating_q975": 1457.954969691461,
            "rating_q025": 1411.1371416752158
        },
        "glm-4.5": {
            "rating": 1431.307075557541,
            "rating_q975": 1447.9522059974383,
            "rating_q025": 1414.6619451176439
        },
        "qwen3-32b": {
            "rating": 1430.5805426512054,
            "rating_q975": 1462.519491629147,
            "rating_q025": 1398.6415936732637
        },
        "longcat-flash-chat": {
            "rating": 1428.919969952766,
            "rating_q975": 1453.6585331464591,
            "rating_q025": 1404.1814067590728
        },
        "qwen3-max-2025-09-23": {
            "rating": 1426.4302674737241,
            "rating_q975": 1451.848604259272,
            "rating_q025": 1401.0119306881763
        },
        "kimi-k2-0905-preview": {
            "rating": 1426.3380011920033,
            "rating_q975": 1450.1010242380057,
            "rating_q025": 1402.5749781460008
        },
        "qwen3-next-80b-a3b-instruct": {
            "rating": 1426.138298778634,
            "rating_q975": 1445.9363574554868,
            "rating_q025": 1406.340240101781
        },
        "claude-opus-4-20250514-thinking-16k": {
            "rating": 1426.1291417662117,
            "rating_q975": 1438.5847599335807,
            "rating_q025": 1413.6735235988426
        },
        "minimax-m1": {
            "rating": 1425.8860160158351,
            "rating_q975": 1438.8834031131182,
            "rating_q025": 1412.888628918552
        },
        "gemini-2.5-flash": {
            "rating": 1424.4147370273251,
            "rating_q975": 1434.2807132862495,
            "rating_q025": 1414.5487607684008
        },
        "deepseek-v3.1": {
            "rating": 1421.8140507137086,
            "rating_q975": 1441.3048398948674,
            "rating_q025": 1402.3232615325499
        },
        "claude-haiku-4-5-20251001": {
            "rating": 1419.7798613253929,
            "rating_q975": 1445.0545019091426,
            "rating_q025": 1394.5052207416431
        },
        "gpt-4.5-preview-2025-02-27": {
            "rating": 1419.0398807323184,
            "rating_q975": 1434.4414334362566,
            "rating_q025": 1403.63832802838
        },
        "o1-2024-12-17": {
            "rating": 1418.1160398455138,
            "rating_q975": 1429.190470121967,
            "rating_q025": 1407.0416095690605
        },
        "claude-sonnet-4-20250514-thinking-32k": {
            "rating": 1417.7689568500675,
            "rating_q975": 1430.6679838436664,
            "rating_q025": 1404.8699298564686
        },
        "o3-mini-high": {
            "rating": 1417.340093780545,
            "rating_q975": 1430.8871962244511,
            "rating_q025": 1403.7929913366388
        },
        "o4-mini-2025-04-16": {
            "rating": 1417.2556103854963,
            "rating_q975": 1428.056626943143,
            "rating_q025": 1406.4545938278495
        },
        "gpt-5-mini-high": {
            "rating": 1416.9898813853154,
            "rating_q975": 1434.4320887589308,
            "rating_q025": 1399.5476740116999
        },
        "deepseek-r1": {
            "rating": 1414.9097223770332,
            "rating_q975": 1429.3570346162512,
            "rating_q025": 1400.4624101378151
        },
        "claude-sonnet-4-5-20250929": {
            "rating": 1413.8862099754451,
            "rating_q975": 1445.2148076985495,
            "rating_q025": 1382.5576122523407
        },
        "qwen3-vl-235b-a22b-instruct": {
            "rating": 1413.2856079979977,
            "rating_q975": 1439.4137343097595,
            "rating_q025": 1387.1574816862358
        },
        "deepseek-r1-0528": {
            "rating": 1413.1950583162275,
            "rating_q975": 1431.4792565331811,
            "rating_q025": 1394.9108600992738
        },
        "mistral-medium-2508": {
            "rating": 1412.6930468342425,
            "rating_q975": 1427.357026108839,
            "rating_q025": 1398.0290675596461
        },
        "gpt-5-chat": {
            "rating": 1411.4067891017578,
            "rating_q975": 1426.9498140609105,
            "rating_q025": 1395.863764142605
        },
        "claude-opus-4-20250514": {
            "rating": 1409.1688994541964,
            "rating_q975": 1420.228778746037,
            "rating_q025": 1398.1090201623558
        },
        "qwen3-30b-a3b-instruct-2507": {
            "rating": 1408.9059525031237,
            "rating_q975": 1425.2756939817655,
            "rating_q025": 1392.5362110244819
        },
        "qwen3-235b-a22b-no-thinking": {
            "rating": 1408.582569180188,
            "rating_q975": 1420.5507985376362,
            "rating_q025": 1396.61433982274
        },
        "chatgpt-4o-latest-20250326": {
            "rating": 1408.5516714312055,
            "rating_q975": 1418.675520571349,
            "rating_q025": 1398.427822291062
        },
        "nvidia-llama-3.3-nemotron-super-49b-v1.5": {
            "rating": 1408.2852976677361,
            "rating_q975": 1446.3769464035886,
            "rating_q025": 1370.1936489318837
        },
        "qwen3-235b-a22b": {
            "rating": 1408.225274170208,
            "rating_q975": 1422.7264381867285,
            "rating_q025": 1393.7241101536874
        },
        "mai-1-preview": {
            "rating": 1406.1805907613154,
            "rating_q975": 1426.388879211223,
            "rating_q025": 1385.972302311408
        },
        "o1-preview": {
            "rating": 1400.8497939551644,
            "rating_q975": 1410.7328140757384,
            "rating_q025": 1390.9667738345904
        },
        "grok-3-preview-02-24": {
            "rating": 1399.9131731235855,
            "rating_q975": 1411.2613890590933,
            "rating_q025": 1388.5649571880776
        },
        "o3-mini": {
            "rating": 1398.307638026133,
            "rating_q975": 1406.8513266911007,
            "rating_q025": 1389.7639493611653
        },
        "glm-4.5-air": {
            "rating": 1397.2075961607409,
            "rating_q975": 1413.3122924938798,
            "rating_q025": 1381.102899827602
        },
        "qwen3-next-80b-a3b-thinking": {
            "rating": 1396.8846716376631,
            "rating_q975": 1419.0917440456988,
            "rating_q025": 1374.6775992296275
        },
        "amazon-nova-experimental-chat-10-09": {
            "rating": 1395.366732746122,
            "rating_q975": 1431.6514315467323,
            "rating_q025": 1359.0820339455115
        },
        "claude-sonnet-4-20250514": {
            "rating": 1394.2682821116318,
            "rating_q975": 1406.0926614359532,
            "rating_q025": 1382.4439027873104
        },
        "claude-3-7-sonnet-20250219-thinking-32k": {
            "rating": 1393.9796532742173,
            "rating_q975": 1405.1185630593313,
            "rating_q025": 1382.8407434891033
        },
        "gpt-oss-120b": {
            "rating": 1390.3369720157827,
            "rating_q975": 1405.9403390117625,
            "rating_q025": 1374.733605019803
        },
        "qwen3-coder-480b-a35b-instruct": {
            "rating": 1389.8519329742014,
            "rating_q975": 1405.3523356877195,
            "rating_q025": 1374.3515302606834
        },
        "kimi-k2-0711-preview": {
            "rating": 1389.61750663565,
            "rating_q975": 1404.0588287892242,
            "rating_q025": 1375.1761844820758
        },
        "hunyuan-t1-20250711": {
            "rating": 1387.2152216579273,
            "rating_q975": 1425.037896457892,
            "rating_q025": 1349.3925468579625
        },
        "step-3": {
            "rating": 1385.5661512454817,
            "rating_q975": 1418.4963406117852,
            "rating_q025": 1352.6359618791782
        },
        "grok-3-mini-high": {
            "rating": 1385.3061284923688,
            "rating_q975": 1403.0009085967558,
            "rating_q025": 1367.6113483879817
        },
        "o1-mini": {
            "rating": 1379.8588185465073,
            "rating_q975": 1387.6191939417145,
            "rating_q025": 1372.0984431513002
        },
        "qwen3-30b-a3b": {
            "rating": 1377.8319049916474,
            "rating_q975": 1391.8627571020136,
            "rating_q025": 1363.8010528812813
        },
        "qwen2.5-max": {
            "rating": 1375.6274055393828,
            "rating_q975": 1385.7292675151714,
            "rating_q025": 1365.5255435635943
        },
        "gemini-2.5-flash-lite-preview-06-17-thinking": {
            "rating": 1375.6227300231524,
            "rating_q975": 1388.203790635532,
            "rating_q025": 1363.0416694107728
        },
        "gpt-4.1-2025-04-14": {
            "rating": 1373.9729732949966,
            "rating_q975": 1384.5276784161301,
            "rating_q025": 1363.418268173863
        },
        "gemini-2.5-flash-lite-preview-09-2025-no-thinking": {
            "rating": 1372.659221283369,
            "rating_q975": 1395.885307811561,
            "rating_q025": 1349.4331347551772
        },
        "ring-flash-2.0": {
            "rating": 1371.1406936234384,
            "rating_q975": 1401.5346016154474,
            "rating_q025": 1340.7467856314295
        },
        "deepseek-v3-0324": {
            "rating": 1371.0056818294875,
            "rating_q975": 1381.5575341216027,
            "rating_q025": 1360.4538295373723
        },
        "llama-3.3-nemotron-49b-super-v1": {
            "rating": 1370.0608758215149,
            "rating_q975": 1407.0689542221235,
            "rating_q025": 1333.0527974209062
        },
        "gpt-4.1-mini-2025-04-14": {
            "rating": 1368.8292202582786,
            "rating_q975": 1380.1528438754553,
            "rating_q025": 1357.5055966411019
        },
        "grok-3-mini-beta": {
            "rating": 1368.7854502957236,
            "rating_q975": 1382.8026084497221,
            "rating_q025": 1354.7682921417252
        },
        "ling-flash-2.0": {
            "rating": 1368.121819576298,
            "rating_q975": 1396.6816774558802,
            "rating_q025": 1339.561961696716
        },
        "qwq-32b": {
            "rating": 1367.404784003433,
            "rating_q975": 1381.2388307218762,
            "rating_q025": 1353.5707372849897
        },
        "gpt-5-nano-high": {
            "rating": 1365.469665940848,
            "rating_q975": 1393.2759703599377,
            "rating_q025": 1337.6633615217584
        },
        "hunyuan-turbos-20250416": {
            "rating": 1364.877830927137,
            "rating_q975": 1384.5683854990189,
            "rating_q025": 1345.187276355255
        },
        "mistral-small-2506": {
            "rating": 1362.197676942795,
            "rating_q975": 1379.8911287554545,
            "rating_q025": 1344.5042251301354
        },
        "claude-3-5-sonnet-20241022": {
            "rating": 1359.1871144533552,
            "rating_q975": 1365.501010886847,
            "rating_q025": 1352.8732180198633
        },
        "mistral-medium-2505": {
            "rating": 1356.8855378702208,
            "rating_q975": 1368.7356562051564,
            "rating_q025": 1345.0354195352852
        },
        "gemini-1.5-pro-002": {
            "rating": 1356.1574450070937,
            "rating_q975": 1363.2458362222085,
            "rating_q025": 1349.0690537919788
        },
        "gemma-3-12b-it": {
            "rating": 1353.6331672503154,
            "rating_q975": 1383.890705166525,
            "rating_q025": 1323.3756293341057
        },
        "glm-4.5v": {
            "rating": 1351.02475253067,
            "rating_q975": 1388.0275401176818,
            "rating_q025": 1314.021964943658
        },
        "gemma-3-27b-it": {
            "rating": 1343.7110916926547,
            "rating_q975": 1353.528692347924,
            "rating_q025": 1333.8934910373853
        },
        "claude-3-5-sonnet-20240620": {
            "rating": 1341.822181170104,
            "rating_q975": 1348.89165012558,
            "rating_q025": 1334.7527122146278
        },
        "step-1o-turbo-202506": {
            "rating": 1341.4265670247382,
            "rating_q975": 1363.2871551335186,
            "rating_q025": 1319.5659789159579
        },
        "gemini-2.0-flash-lite-preview-02-05": {
            "rating": 1340.899478589605,
            "rating_q975": 1351.7359583953937,
            "rating_q025": 1330.0629987838163
        },
        "qwen-plus-0125": {
            "rating": 1340.8533960947502,
            "rating_q975": 1362.1391844645796,
            "rating_q025": 1319.567607724921
        },
        "gpt-oss-20b": {
            "rating": 1334.2365984061407,
            "rating_q975": 1357.3688650394024,
            "rating_q025": 1311.104331772879
        },
        "command-a-03-2025": {
            "rating": 1329.9994703642706,
            "rating_q975": 1339.6087395042523,
            "rating_q025": 1320.3902012242888
        },
        "hunyuan-large-2025-02-10": {
            "rating": 1329.387154701266,
            "rating_q975": 1355.296090771952,
            "rating_q025": 1303.4782186305797
        },
        "step-2-16k-exp-202412": {
            "rating": 1328.490681025457,
            "rating_q975": 1350.517166577008,
            "rating_q025": 1306.4641954739059
        },
        "athene-v2-chat": {
            "rating": 1326.9249644067672,
            "rating_q975": 1336.7274861440194,
            "rating_q025": 1317.122442669515
        },
        "llama-4-maverick-17b-128e-instruct": {
            "rating": 1326.286826268038,
            "rating_q975": 1337.4347517842955,
            "rating_q025": 1315.1389007517807
        },
        "hunyuan-large-vision": {
            "rating": 1325.1945262386025,
            "rating_q975": 1352.23628703468,
            "rating_q025": 1298.1527654425252
        },
        "deepseek-v3": {
            "rating": 1323.550447541203,
            "rating_q975": 1334.9001432110147,
            "rating_q025": 1312.2007518713915
        },
        "yi-lightning": {
            "rating": 1323.3075124029092,
            "rating_q975": 1333.307532285817,
            "rating_q025": 1313.3074925200015
        },
        "qwen2.5-plus-1127": {
            "rating": 1323.294868039699,
            "rating_q975": 1337.666692032605,
            "rating_q025": 1308.923044046793
        },
        "llama-3.1-405b-instruct-fp8": {
            "rating": 1322.6705446835292,
            "rating_q975": 1329.90480929244,
            "rating_q025": 1315.4362800746185
        },
        "llama-3.1-405b-instruct-bf16": {
            "rating": 1321.7542666697218,
            "rating_q975": 1329.8463067952237,
            "rating_q025": 1313.66222654422
        },
        "llama-4-scout-17b-16e-instruct": {
            "rating": 1319.427193213755,
            "rating_q975": 1332.6599957771207,
            "rating_q025": 1306.194390650389
        },
        "gemini-advanced-0514": {
            "rating": 1317.6416242432495,
            "rating_q975": 1327.0466343736327,
            "rating_q025": 1308.2366141128662
        },
        "gpt-4o-2024-08-06": {
            "rating": 1316.2094740256643,
            "rating_q975": 1323.9787438822823,
            "rating_q025": 1308.4402041690464
        },
        "hunyuan-turbo-0110": {
            "rating": 1315.6057969513226,
            "rating_q975": 1349.5498300901543,
            "rating_q025": 1281.661763812491
        },
        "gpt-4o-2024-05-13": {
            "rating": 1314.4603124005894,
            "rating_q975": 1320.7971187646235,
            "rating_q025": 1308.1235060365552
        },
        "qwen2.5-72b-instruct": {
            "rating": 1314.418236717172,
            "rating_q975": 1322.5365058820616,
            "rating_q025": 1306.2999675522824
        },
        "hunyuan-standard-2025-02-10": {
            "rating": 1314.0502979688404,
            "rating_q975": 1339.5287083778137,
            "rating_q025": 1288.571887559867
        },
        "gpt-4-1106-preview": {
            "rating": 1313.3519164982213,
            "rating_q975": 1320.7584770036149,
            "rating_q025": 1305.9453559928277
        },
        "claude-3-opus-20240229": {
            "rating": 1312.862754360665,
            "rating_q975": 1318.7279931398612,
            "rating_q025": 1306.9975155814686
        },
        "gemini-1.5-pro-001": {
            "rating": 1312.3477901121532,
            "rating_q975": 1319.837214330425,
            "rating_q025": 1304.8583658938815
        },
        "glm-4-plus-0111": {
            "rating": 1308.3194331105133,
            "rating_q975": 1328.9461292512053,
            "rating_q025": 1287.6927369698212
        },
        "hunyuan-turbos-20250226": {
            "rating": 1306.7283468460578,
            "rating_q975": 1338.5123497251932,
            "rating_q025": 1274.9443439669224
        },
        "gemini-1.5-flash-002": {
            "rating": 1305.7971894982834,
            "rating_q975": 1314.4272996427517,
            "rating_q025": 1297.167079353815
        },
        "qwen-max-0919": {
            "rating": 1305.7254172986372,
            "rating_q975": 1318.2959878580623,
            "rating_q025": 1293.1548467392122
        },
        "magistral-medium-2506": {
            "rating": 1305.3268252182584,
            "rating_q975": 1330.1980629886618,
            "rating_q025": 1280.455587447855
        },
        "llama-3.3-70b-instruct": {
            "rating": 1305.1669203384463,
            "rating_q975": 1312.7247595754309,
            "rating_q025": 1297.6090811014617
        },
        "glm-4-plus": {
            "rating": 1305.144609421056,
            "rating_q975": 1315.2031851777992,
            "rating_q025": 1295.0860336643127
        },
        "llama-3.1-nemotron-70b-instruct": {
            "rating": 1304.2888302925244,
            "rating_q975": 1322.3458500436377,
            "rating_q025": 1286.231810541411
        },
        "grok-2-2024-08-13": {
            "rating": 1303.2681847635545,
            "rating_q975": 1310.1552069514887,
            "rating_q025": 1296.3811625756202
        },
        "gpt-4-turbo-2024-04-09": {
            "rating": 1303.253405201392,
            "rating_q975": 1310.398008656508,
            "rating_q025": 1296.1088017462762
        },
        "gpt-4-0125-preview": {
            "rating": 1302.4323424616637,
            "rating_q975": 1309.925613163752,
            "rating_q025": 1294.9390717595754
        },
        "mistral-large-2407": {
            "rating": 1302.2661470743394,
            "rating_q975": 1310.0738819656515,
            "rating_q025": 1294.4584121830273
        },
        "deepseek-v2.5": {
            "rating": 1300.7924952296748,
            "rating_q975": 1310.6530127291,
            "rating_q025": 1290.9319777302496
        },
        "claude-3-5-haiku-20241022": {
            "rating": 1300.6317040398028,
            "rating_q975": 1308.1956810667243,
            "rating_q025": 1293.0677270128813
        },
        "mistral-small-3.1-24b-instruct-2503": {
            "rating": 1297.4040504436698,
            "rating_q975": 1310.3080957201796,
            "rating_q025": 1284.50000516716
        },
        "gemma-3n-e4b-it": {
            "rating": 1295.8347881550912,
            "rating_q975": 1310.7287278381402,
            "rating_q025": 1280.9408484720423
        },
        "deepseek-v2.5-1210": {
            "rating": 1292.4067372764111,
            "rating_q975": 1309.8824426882788,
            "rating_q025": 1274.9310318645435
        },
        "gpt-4o-mini-2024-07-18": {
            "rating": 1290.6695806816206,
            "rating_q975": 1297.224096522814,
            "rating_q025": 1284.115064840427
        },
        "gpt-4-0314": {
            "rating": 1290.1864865305633,
            "rating_q975": 1299.7074443520885,
            "rating_q025": 1280.6655287090382
        },
        "grok-2-mini-2024-08-13": {
            "rating": 1289.4394793719412,
            "rating_q975": 1296.7989065748666,
            "rating_q025": 1282.0800521690157
        },
        "amazon-nova-pro-v1.0": {
            "rating": 1288.7880306614531,
            "rating_q975": 1298.7911991118974,
            "rating_q025": 1278.7848622110089
        },
        "mistral-large-2411": {
            "rating": 1287.6894045468814,
            "rating_q975": 1297.276166663868,
            "rating_q025": 1278.1026424298948
        },
        "gpt-4.1-nano-2025-04-14": {
            "rating": 1285.4568475141905,
            "rating_q975": 1309.492001130486,
            "rating_q025": 1261.421693897895
        },
        "phi-4": {
            "rating": 1282.4133110450903,
            "rating_q975": 1293.6199684786245,
            "rating_q025": 1271.206653611556
        },
        "llama-3.1-70b-instruct": {
            "rating": 1279.7149890478152,
            "rating_q975": 1287.073652034229,
            "rating_q025": 1272.3563260614012
        },
        "llama-3.1-nemotron-51b-instruct": {
            "rating": 1278.3720848985408,
            "rating_q975": 1303.6204113928438,
            "rating_q025": 1253.1237584042378
        },
        "qwen2-72b-instruct": {
            "rating": 1278.337478363274,
            "rating_q975": 1287.6532317356111,
            "rating_q025": 1269.0217249909367
        },
        "gemma-3-4b-it": {
            "rating": 1277.645256026412,
            "rating_q975": 1307.850051530315,
            "rating_q025": 1247.4404605225088
        },
        "llama-3.1-tulu-3-70b": {
            "rating": 1277.5607700076507,
            "rating_q975": 1304.9961473697806,
            "rating_q025": 1250.1253926455208
        },
        "mistral-small-24b-instruct-2501": {
            "rating": 1274.384762212171,
            "rating_q975": 1288.4832377342088,
            "rating_q025": 1260.286286690133
        },
        "qwen2.5-coder-32b-instruct": {
            "rating": 1273.928289657439,
            "rating_q975": 1294.489037170515,
            "rating_q025": 1253.3675421443631
        },
        "gemini-1.5-flash-001": {
            "rating": 1273.5485750608545,
            "rating_q975": 1281.2862022401994,
            "rating_q025": 1265.8109478815097
        },
        "deepseek-coder-v2": {
            "rating": 1273.0241148634645,
            "rating_q975": 1286.5492268253954,
            "rating_q025": 1259.4990029015337
        },
        "reka-core-20240904": {
            "rating": 1272.909987205778,
            "rating_q975": 1288.117099953102,
            "rating_q025": 1257.7028744584538
        },
        "hunyuan-standard-256k": {
            "rating": 1271.4877495730548,
            "rating_q975": 1302.6288003519594,
            "rating_q025": 1240.3466987941501
        },
        "athene-70b-0725": {
            "rating": 1270.1755281709748,
            "rating_q975": 1280.7053686823322,
            "rating_q025": 1259.6456876596174
        },
        "gpt-4-0613": {
            "rating": 1269.8296957330956,
            "rating_q975": 1277.972730157433,
            "rating_q025": 1261.6866613087582
        },
        "glm-4-0520": {
            "rating": 1268.6156854755857,
            "rating_q975": 1284.7116703461418,
            "rating_q025": 1252.5197006050296
        },
        "claude-3-sonnet-20240229": {
            "rating": 1263.871061538779,
            "rating_q975": 1271.5269761384266,
            "rating_q025": 1256.2151469391315
        },
        "amazon-nova-lite-v1.0": {
            "rating": 1262.4844055231492,
            "rating_q975": 1273.661401319512,
            "rating_q025": 1251.3074097267865
        },
        "gemma-2-27b-it": {
            "rating": 1262.3347050692416,
            "rating_q975": 1268.741443643171,
            "rating_q025": 1255.9279664953124
        },
        "llama-3-70b-instruct": {
            "rating": 1262.3051539036383,
            "rating_q975": 1269.221301203321,
            "rating_q025": 1255.3890066039555
        },
        "nemotron-4-340b-instruct": {
            "rating": 1261.7508176347678,
            "rating_q975": 1273.9363854447508,
            "rating_q025": 1249.5652498247848
        },
        "jamba-1.5-large": {
            "rating": 1260.8103663882748,
            "rating_q975": 1277.298190530442,
            "rating_q025": 1244.3225422461076
        },
        "gemini-1.5-flash-8b-001": {
            "rating": 1255.688831667368,
            "rating_q975": 1264.1150418720426,
            "rating_q025": 1247.2626214626935
        },
        "command-r-plus-08-2024": {
            "rating": 1248.8735555295807,
            "rating_q975": 1263.43714583961,
            "rating_q025": 1234.3099652195515
        },
        "c4ai-aya-expanse-32b": {
            "rating": 1248.4843496630042,
            "rating_q975": 1258.30187274474,
            "rating_q025": 1238.6668265812684
        },
        "reka-flash-20240904": {
            "rating": 1247.710669169876,
            "rating_q975": 1262.6098289965657,
            "rating_q025": 1232.8115093431861
        },
        "mistral-large-2402": {
            "rating": 1244.2896665948178,
            "rating_q975": 1253.1248689101797,
            "rating_q025": 1235.454464279456
        },
        "amazon-nova-micro-v1.0": {
            "rating": 1240.0204426230919,
            "rating_q975": 1251.532441246828,
            "rating_q025": 1228.5084439993557
        },
        "claude-3-haiku-20240307": {
            "rating": 1240.0037896849728,
            "rating_q975": 1247.0158058925244,
            "rating_q025": 1232.9917734774212
        },
        "gemma-2-9b-it-simpo": {
            "rating": 1236.0889498138372,
            "rating_q975": 1251.5603320088521,
            "rating_q025": 1220.6175676188222
        },
        "gemma-2-9b-it": {
            "rating": 1235.7577365137195,
            "rating_q975": 1243.1748175911166,
            "rating_q025": 1228.3406554363223
        },
        "qwen1.5-110b-chat": {
            "rating": 1235.4372800652613,
            "rating_q975": 1246.6234201049572,
            "rating_q025": 1224.2511400255655
        },
        "mixtral-8x22b-instruct-v0.1": {
            "rating": 1233.1420967288964,
            "rating_q975": 1241.9811874242016,
            "rating_q025": 1224.3030060335911
        },
        "granite-3.1-2b-instruct": {
            "rating": 1232.536256959364,
            "rating_q975": 1260.967778081646,
            "rating_q025": 1204.104735837082
        },
        "qwq-32b-preview": {
            "rating": 1230.9649936728497,
            "rating_q975": 1257.2220302205026,
            "rating_q025": 1204.7079571251968
        },
        "granite-3.1-8b-instruct": {
            "rating": 1230.3928317275604,
            "rating_q975": 1260.7823597371246,
            "rating_q025": 1200.0033037179962
        },
        "mistral-medium": {
            "rating": 1230.198143418673,
            "rating_q975": 1240.9945972133876,
            "rating_q025": 1219.4016896239584
        },
        "phi-3-medium-4k-instruct": {
            "rating": 1227.9979837032704,
            "rating_q975": 1238.6548269414766,
            "rating_q025": 1217.3411404650642
        },
        "yi-1.5-34b-chat": {
            "rating": 1226.8247648010306,
            "rating_q975": 1237.9594325831208,
            "rating_q025": 1215.6900970189404
        },
        "command-r-08-2024": {
            "rating": 1225.5509979589785,
            "rating_q975": 1239.624929040792,
            "rating_q025": 1211.477066877165
        },
        "qwen1.5-72b-chat": {
            "rating": 1225.278485763412,
            "rating_q975": 1234.9677946763707,
            "rating_q025": 1215.5891768504532
        },
        "olmo-2-0325-32b-instruct": {
            "rating": 1224.7897682739751,
            "rating_q975": 1254.4593778616245,
            "rating_q025": 1195.1201586863258
        },
        "command-r-plus": {
            "rating": 1222.2873701719145,
            "rating_q975": 1230.5265532365665,
            "rating_q025": 1214.0481871072625
        },
        "ministral-8b-2410": {
            "rating": 1220.488588665192,
            "rating_q975": 1242.1781659487779,
            "rating_q025": 1198.7990113816063
        },
        "reka-flash-21b-20240226-online": {
            "rating": 1219.9620756265924,
            "rating_q975": 1234.1147612401398,
            "rating_q025": 1205.809390013045
        },
        "internlm2_5-20b-chat": {
            "rating": 1217.6118621424107,
            "rating_q975": 1233.552246705368,
            "rating_q025": 1201.6714775794535
        },
        "qwen1.5-32b-chat": {
            "rating": 1216.9859089641495,
            "rating_q975": 1228.9657982022622,
            "rating_q025": 1205.0060197260368
        },
        "c4ai-aya-expanse-8b": {
            "rating": 1216.8051728066794,
            "rating_q975": 1232.5071215563792,
            "rating_q025": 1201.1032240569796
        },
        "granite-3.0-8b-instruct": {
            "rating": 1214.904148432366,
            "rating_q975": 1235.786023997073,
            "rating_q025": 1194.0222728676588
        },
        "llama-3.1-tulu-3-8b": {
            "rating": 1213.842235628042,
            "rating_q975": 1243.1027971899446,
            "rating_q025": 1184.5816740661396
        },
        "gemini-pro": {
            "rating": 1212.0237798943963,
            "rating_q975": 1232.495579298478,
            "rating_q025": 1191.5519804903145
        },
        "reka-flash-21b-20240226": {
            "rating": 1211.9237174185969,
            "rating_q975": 1223.4614269810454,
            "rating_q025": 1200.3860078561484
        },
        "phi-3-small-8k-instruct": {
            "rating": 1205.9444493348815,
            "rating_q975": 1219.0166277687335,
            "rating_q025": 1192.8722709010294
        },
        "zephyr-orpo-141b-A35b-v0.1": {
            "rating": 1204.2438204771788,
            "rating_q975": 1227.849749321144,
            "rating_q025": 1180.6378916332137
        },
        "llama-3-8b-instruct": {
            "rating": 1203.379240544046,
            "rating_q975": 1210.8187964206475,
            "rating_q025": 1195.9396846674447
        },
        "gpt-3.5-turbo-1106": {
            "rating": 1202.6403435883367,
            "rating_q975": 1218.7593032551156,
            "rating_q025": 1186.5213839215578
        },
        "llama-3.1-8b-instruct": {
            "rating": 1200.0481108092836,
            "rating_q975": 1207.7773543744825,
            "rating_q025": 1192.3188672440847
        },
        "phi-3-mini-4k-instruct-june-2024": {
            "rating": 1199.4324820095399,
            "rating_q975": 1213.552201518514,
            "rating_q025": 1185.3127625005657
        },
        "mixtral-8x7b-instruct-v0.1": {
            "rating": 1197.7267830486621,
            "rating_q975": 1205.9817512083287,
            "rating_q025": 1189.4718148889956
        },
        "gpt-3.5-turbo-0125": {
            "rating": 1196.1889335840578,
            "rating_q975": 1204.5365695907549,
            "rating_q025": 1187.8412975773608
        },
        "jamba-1.5-mini": {
            "rating": 1196.0219990579565,
            "rating_q975": 1212.8751005788201,
            "rating_q025": 1179.1688975370928
        },
        "gemini-pro-dev-api": {
            "rating": 1194.4146014319124,
            "rating_q975": 1208.95039136403,
            "rating_q025": 1179.8788114997947
        },
        "dbrx-instruct-preview": {
            "rating": 1191.864752116918,
            "rating_q975": 1203.4276948773665,
            "rating_q025": 1180.3018093564694
        },
        "granite-3.0-2b-instruct": {
            "rating": 1190.617099782191,
            "rating_q975": 1211.1264383669645,
            "rating_q025": 1170.1077611974174
        },
        "command-r": {
            "rating": 1189.5628486796006,
            "rating_q975": 1199.07099225226,
            "rating_q025": 1180.0547051069411
        },
        "qwen1.5-14b-chat": {
            "rating": 1187.13633164337,
            "rating_q975": 1200.4997534845802,
            "rating_q025": 1173.77290980216
        },
        "gemma-2-2b-it": {
            "rating": 1180.9437820432145,
            "rating_q975": 1188.8886829911744,
            "rating_q025": 1172.9988810952545
        },
        "smollm2-1.7b-instruct": {
            "rating": 1180.332848531885,
            "rating_q975": 1213.876876784933,
            "rating_q025": 1146.788820278837
        },
        "llama-3.2-3b-instruct": {
            "rating": 1176.6986234473386,
            "rating_q975": 1193.3353028032009,
            "rating_q025": 1160.0619440914763
        },
        "starling-lm-7b-beta": {
            "rating": 1174.2725723866263,
            "rating_q975": 1188.4868936889138,
            "rating_q025": 1160.0582510843387
        },
        "yi-34b-chat": {
            "rating": 1163.4808879634893,
            "rating_q975": 1177.223543954748,
            "rating_q025": 1149.7382319722306
        },
        "snowflake-arctic-instruct": {
            "rating": 1162.5177470229457,
            "rating_q975": 1173.9613053119015,
            "rating_q025": 1151.07418873399
        },
        "openhermes-2.5-mistral-7b": {
            "rating": 1160.8204948615203,
            "rating_q975": 1182.6336961700026,
            "rating_q025": 1139.007293553038
        },
        "wizardlm-70b": {
            "rating": 1159.5294779674368,
            "rating_q975": 1179.8864980510102,
            "rating_q025": 1139.1724578838634
        },
        "phi-3-mini-4k-instruct": {
            "rating": 1159.0092780970308,
            "rating_q975": 1171.5499198906855,
            "rating_q025": 1146.4686363033761
        },
        "gemma-1.1-7b-it": {
            "rating": 1158.5194423861408,
            "rating_q975": 1170.0518985153535,
            "rating_q025": 1146.986986256928
        },
        "qwen1.5-7b-chat": {
            "rating": 1158.2474878925973,
            "rating_q975": 1181.0440753909397,
            "rating_q025": 1135.4509003942549
        },
        "openchat-3.5-0106": {
            "rating": 1156.1739564304448,
            "rating_q975": 1170.821048134509,
            "rating_q025": 1141.5268647263806
        },
        "deepseek-llm-67b-chat": {
            "rating": 1151.972934577922,
            "rating_q975": 1178.233085080657,
            "rating_q025": 1125.7127840751868
        },
        "tulu-2-dpo-70b": {
            "rating": 1147.0801606276273,
            "rating_q975": 1167.3308871986262,
            "rating_q025": 1126.8294340566283
        },
        "phi-3-mini-128k-instruct": {
            "rating": 1144.9844162627746,
            "rating_q975": 1158.2880898540259,
            "rating_q025": 1131.6807426715234
        },
        "llama-3.2-1b-instruct": {
            "rating": 1144.8960253791745,
            "rating_q975": 1162.662188079392,
            "rating_q025": 1127.129862678957
        },
        "llama-2-70b-chat": {
            "rating": 1143.6718702417356,
            "rating_q975": 1154.0812179027455,
            "rating_q025": 1133.2625225807258
        },
        "qwen-14b-chat": {
            "rating": 1141.6303570761438,
            "rating_q975": 1167.1322195517723,
            "rating_q025": 1116.1284946005153
        },
        "mistral-7b-instruct-v0.2": {
            "rating": 1139.0929848152477,
            "rating_q975": 1151.5786024308748,
            "rating_q025": 1126.6073671996207
        },
        "starling-lm-7b-alpha": {
            "rating": 1137.7431621004182,
            "rating_q975": 1154.6257756579635,
            "rating_q025": 1120.860548542873
        },
        "openchat-3.5": {
            "rating": 1133.3725962405504,
            "rating_q975": 1153.1087865382865,
            "rating_q025": 1113.6364059428142
        },
        "vicuna-33b": {
            "rating": 1132.0058478370051,
            "rating_q975": 1145.0719265224473,
            "rating_q025": 1118.939769151563
        },
        "llama-2-13b-chat": {
            "rating": 1123.7068629500068,
            "rating_q975": 1137.3285545219678,
            "rating_q025": 1110.0851713780457
        },
        "gemma-7b-it": {
            "rating": 1121.957553547684,
            "rating_q975": 1139.1780770122607,
            "rating_q025": 1104.7370300831074
        },
        "palm-2": {
            "rating": 1121.703953920502,
            "rating_q975": 1142.3848051035377,
            "rating_q025": 1101.0231027374664
        },
        "llama2-70b-steerlm-chat": {
            "rating": 1118.9541484032015,
            "rating_q975": 1148.5769728326602,
            "rating_q025": 1089.3313239737429
        },
        "codellama-34b-instruct": {
            "rating": 1117.508316453885,
            "rating_q975": 1138.6352189824356,
            "rating_q025": 1096.3814139253345
        },
        "mpt-30b-chat": {
            "rating": 1115.3628069821852,
            "rating_q975": 1152.0846620039458,
            "rating_q025": 1078.6409519604247
        },
        "dolphin-2.2.1-mistral-7b": {
            "rating": 1114.7142202215505,
            "rating_q975": 1148.8098569309282,
            "rating_q025": 1080.6185835121728
        },
        "solar-10.7b-instruct-v1.0": {
            "rating": 1113.2828645777045,
            "rating_q975": 1136.688965618477,
            "rating_q025": 1089.876763536932
        },
        "gemma-1.1-2b-it": {
            "rating": 1111.6582699431792,
            "rating_q975": 1128.4581935145345,
            "rating_q025": 1094.858346371824
        },
        "zephyr-7b-beta": {
            "rating": 1097.645393509824,
            "rating_q975": 1115.5609127060118,
            "rating_q025": 1079.7298743136364
        },
        "nous-hermes-2-mixtral-8x7b-dpo": {
            "rating": 1093.2774207867144,
            "rating_q975": 1118.9552635621353,
            "rating_q025": 1067.5995780112935
        },
        "llama-2-7b-chat": {
            "rating": 1093.201892840411,
            "rating_q975": 1108.139687129874,
            "rating_q025": 1078.264098550948
        },
        "vicuna-13b": {
            "rating": 1085.790477886987,
            "rating_q975": 1100.4167930648146,
            "rating_q025": 1071.1641627091594
        },
        "stripedhyena-nous-7b": {
            "rating": 1084.6370171239887,
            "rating_q975": 1107.6508522007302,
            "rating_q025": 1061.6231820472472
        },
        "guanaco-33b": {
            "rating": 1078.5485079984503,
            "rating_q975": 1113.6684356508686,
            "rating_q025": 1043.428580346032
        },
        "mistral-7b-instruct": {
            "rating": 1074.5538579460765,
            "rating_q975": 1095.3216180539785,
            "rating_q025": 1053.7860978381746
        },
        "gemma-2b-it": {
            "rating": 1073.9577751041477,
            "rating_q975": 1098.150175174277,
            "rating_q025": 1049.7653750340185
        },
        "wizardlm-13b": {
            "rating": 1072.9363938151314,
            "rating_q975": 1095.8433847909814,
            "rating_q025": 1050.0294028392814
        },
        "qwen1.5-4b-chat": {
            "rating": 1068.1536589930838,
            "rating_q975": 1087.7316578271564,
            "rating_q025": 1048.5756601590112
        },
        "olmo-7b-instruct": {
            "rating": 1064.3959126752322,
            "rating_q975": 1084.6184651352273,
            "rating_q025": 1044.1733602152372
        },
        "vicuna-7b": {
            "rating": 1045.6849578694523,
            "rating_q975": 1069.2735658233444,
            "rating_q025": 1022.0963499155602
        },
        "chatglm3-6b": {
            "rating": 1030.7945385236285,
            "rating_q975": 1057.1711638070226,
            "rating_q025": 1004.4179132402345
        },
        "RWKV-4-Raven-14B": {
            "rating": 992.3187353719422,
            "rating_q975": 1018.1700538664347,
            "rating_q025": 966.4674168774498
        },
        "koala-13b": {
            "rating": 988.150995994487,
            "rating_q975": 1010.850974844908,
            "rating_q025": 965.4510171440659
        },
        "mpt-7b-chat": {
            "rating": 984.2535700717308,
            "rating_q975": 1012.5274036520568,
            "rating_q025": 955.9797364914048
        },
        "alpaca-13b": {
            "rating": 974.886588484823,
            "rating_q975": 1000.128556085909,
            "rating_q025": 949.644620883737
        },
        "chatglm-6b": {
            "rating": 974.2609100817701,
            "rating_q975": 1001.8432436364259,
            "rating_q025": 946.6785765271144
        },
        "oasst-pythia-12b": {
            "rating": 970.0980023491206,
            "rating_q975": 994.9240165389751,
            "rating_q025": 945.2719881592661
        },
        "dolly-v2-12b": {
            "rating": 930.6239058862175,
            "rating_q975": 961.1189369344102,
            "rating_q025": 900.1288748380248
        },
        "llama-13b": {
            "rating": 926.0507526231647,
            "rating_q975": 963.2932332977067,
            "rating_q025": 888.8082719486227
        },
        "fastchat-t5-3b": {
            "rating": 921.760188896527,
            "rating_q975": 950.0856380265004,
            "rating_q025": 893.4347397665535
        },
        "stablelm-tuned-alpha-7b": {
            "rating": 896.4337671314933,
            "rating_q975": 927.7679292732082,
            "rating_q025": 865.0996049897783
        }
    },
    "industry_medicine_and_healthcare": {
        "o3-2025-04-16": {
            "rating": 1488.2746596264194,
            "rating_q975": 1500.2657465242141,
            "rating_q025": 1476.2835727286247
        },
        "chatgpt-4o-latest-20250326": {
            "rating": 1485.5267459851834,
            "rating_q975": 1498.5846530743504,
            "rating_q025": 1472.4688388960165
        },
        "claude-opus-4-1-20250805-thinking-16k": {
            "rating": 1479.3622570920427,
            "rating_q975": 1495.6547595248055,
            "rating_q025": 1463.0697546592799
        },
        "deepseek-v3.2-exp-thinking": {
            "rating": 1478.0971255785528,
            "rating_q975": 1507.6465500729776,
            "rating_q025": 1448.547701084128
        },
        "qwen3-max-preview": {
            "rating": 1476.6575318431517,
            "rating_q975": 1494.243752572371,
            "rating_q025": 1459.0713111139323
        },
        "claude-sonnet-4-5-20250929": {
            "rating": 1470.9519335849557,
            "rating_q975": 1503.0105693073976,
            "rating_q025": 1438.8932978625137
        },
        "gemini-2.5-pro": {
            "rating": 1470.9299286384587,
            "rating_q975": 1482.476547732784,
            "rating_q025": 1459.3833095441335
        },
        "gpt-5-high": {
            "rating": 1467.0375199360155,
            "rating_q975": 1483.2131785576369,
            "rating_q025": 1450.8618613143942
        },
        "claude-opus-4-1-20250805": {
            "rating": 1465.2877691351166,
            "rating_q975": 1479.2852602414248,
            "rating_q025": 1451.2902780288084
        },
        "gpt-5-chat": {
            "rating": 1461.9855007088506,
            "rating_q975": 1478.190155570945,
            "rating_q025": 1445.7808458467562
        },
        "qwen3-235b-a22b-instruct-2507": {
            "rating": 1461.3717154056874,
            "rating_q975": 1476.1540773441823,
            "rating_q025": 1446.5893534671925
        },
        "deepseek-v3.1-terminus-thinking": {
            "rating": 1460.9596538672047,
            "rating_q975": 1498.8991330906194,
            "rating_q025": 1423.02017464379
        },
        "kimi-k2-0711-preview": {
            "rating": 1457.4536274971726,
            "rating_q975": 1472.6116412638276,
            "rating_q025": 1442.2956137305177
        },
        "claude-opus-4-20250514": {
            "rating": 1455.3405100958935,
            "rating_q975": 1467.7711549604976,
            "rating_q025": 1442.9098652312894
        },
        "grok-4-fast": {
            "rating": 1454.9876009682075,
            "rating_q975": 1485.2152234079924,
            "rating_q025": 1424.7599785284226
        },
        "claude-opus-4-20250514-thinking-16k": {
            "rating": 1454.655289448435,
            "rating_q975": 1467.9925103218218,
            "rating_q025": 1441.3180685750483
        },
        "gpt-4.5-preview-2025-02-27": {
            "rating": 1454.5912239863962,
            "rating_q975": 1479.1497710015149,
            "rating_q025": 1430.0326769712776
        },
        "kimi-k2-0905-preview": {
            "rating": 1452.205699532081,
            "rating_q975": 1475.983857054648,
            "rating_q025": 1428.4275420095141
        },
        "deepseek-v3.1-terminus": {
            "rating": 1452.150730315298,
            "rating_q975": 1490.9657312879483,
            "rating_q025": 1413.3357293426477
        },
        "claude-sonnet-4-5-20250929-thinking-32k": {
            "rating": 1450.4941853432153,
            "rating_q975": 1477.0921637247604,
            "rating_q025": 1423.8962069616703
        },
        "grok-4-0709": {
            "rating": 1450.023258105852,
            "rating_q975": 1464.5458544297123,
            "rating_q025": 1435.5006617819915
        },
        "deepseek-v3.1-thinking": {
            "rating": 1449.5340279929237,
            "rating_q975": 1472.1497050665268,
            "rating_q025": 1426.9183509193206
        },
        "glm-4.6": {
            "rating": 1446.9214345067671,
            "rating_q975": 1476.892881988602,
            "rating_q025": 1416.9499870249322
        },
        "hunyuan-t1-20250711": {
            "rating": 1445.3791730213193,
            "rating_q975": 1484.2170462441538,
            "rating_q025": 1406.5412997984847
        },
        "qwen3-max-2025-09-23": {
            "rating": 1443.8291127301293,
            "rating_q975": 1472.0303456503584,
            "rating_q025": 1415.6278798099002
        },
        "grok-3-preview-02-24": {
            "rating": 1442.081106149096,
            "rating_q975": 1457.290713316038,
            "rating_q025": 1426.8714989821542
        },
        "mistral-medium-2508": {
            "rating": 1441.5685842248406,
            "rating_q975": 1457.6346427347808,
            "rating_q025": 1425.5025257149005
        },
        "deepseek-v3.1": {
            "rating": 1440.2502578699587,
            "rating_q975": 1460.0965317297712,
            "rating_q025": 1420.4039840101461
        },
        "gpt-4.1-2025-04-14": {
            "rating": 1439.2214540531938,
            "rating_q975": 1451.8266474388001,
            "rating_q025": 1426.6162606675875
        },
        "qwen3-next-80b-a3b-instruct": {
            "rating": 1439.1075807246634,
            "rating_q975": 1458.7662734773533,
            "rating_q025": 1419.4488879719736
        },
        "deepseek-r1-0528": {
            "rating": 1438.341757702236,
            "rating_q975": 1456.0129386240399,
            "rating_q025": 1420.6705767804322
        },
        "qwen3-vl-235b-a22b-instruct": {
            "rating": 1437.3432070862857,
            "rating_q975": 1465.874000324357,
            "rating_q025": 1408.8124138482144
        },
        "longcat-flash-chat": {
            "rating": 1436.5232306535097,
            "rating_q975": 1460.7328473426253,
            "rating_q025": 1412.313613964394
        },
        "qwen3-235b-a22b-thinking-2507": {
            "rating": 1435.490885800746,
            "rating_q975": 1461.5429105936912,
            "rating_q025": 1409.4388610078006
        },
        "claude-sonnet-4-20250514": {
            "rating": 1435.28464265332,
            "rating_q975": 1448.5908223622746,
            "rating_q025": 1421.9784629443652
        },
        "hunyuan-turbos-20250416": {
            "rating": 1431.9286953043963,
            "rating_q975": 1456.4008826340998,
            "rating_q025": 1407.4565079746928
        },
        "glm-4.5": {
            "rating": 1431.7406475328307,
            "rating_q975": 1448.7014375203714,
            "rating_q025": 1414.77985754529
        },
        "claude-haiku-4-5-20251001": {
            "rating": 1430.0047515348458,
            "rating_q975": 1460.3398816920321,
            "rating_q025": 1399.6696213776595
        },
        "deepseek-v3-0324": {
            "rating": 1429.8731064158128,
            "rating_q975": 1442.0339572896287,
            "rating_q025": 1417.712255541997
        },
        "claude-3-7-sonnet-20250219-thinking-32k": {
            "rating": 1428.8963405284353,
            "rating_q975": 1442.3128026825266,
            "rating_q025": 1415.479878374344
        },
        "o4-mini-2025-04-16": {
            "rating": 1427.4862606347945,
            "rating_q975": 1440.3075268512735,
            "rating_q025": 1414.6649944183155
        },
        "claude-sonnet-4-20250514-thinking-32k": {
            "rating": 1427.4482725881658,
            "rating_q975": 1441.0226697044432,
            "rating_q025": 1413.8738754718884
        },
        "qwen3-235b-a22b-no-thinking": {
            "rating": 1427.1195354735246,
            "rating_q975": 1440.3005317773182,
            "rating_q025": 1413.938539169731
        },
        "mai-1-preview": {
            "rating": 1426.3120950252612,
            "rating_q975": 1444.975461676009,
            "rating_q025": 1407.6487283745134
        },
        "gemini-2.5-flash": {
            "rating": 1425.4042112564107,
            "rating_q975": 1436.7649159614687,
            "rating_q025": 1414.0435065513527
        },
        "gemini-2.5-flash-preview-09-2025": {
            "rating": 1421.6670143716726,
            "rating_q975": 1445.730562230363,
            "rating_q025": 1397.6034665129823
        },
        "mistral-medium-2505": {
            "rating": 1420.2872899649567,
            "rating_q975": 1434.298089159648,
            "rating_q025": 1406.2764907702654
        },
        "glm-4-plus-0111": {
            "rating": 1418.0185952043123,
            "rating_q975": 1451.7363498320578,
            "rating_q025": 1384.3008405765668
        },
        "deepseek-r1": {
            "rating": 1415.5605586743377,
            "rating_q975": 1436.0266562910308,
            "rating_q025": 1395.0944610576446
        },
        "minimax-m1": {
            "rating": 1413.378336042198,
            "rating_q975": 1427.011154811273,
            "rating_q025": 1399.7455172731231
        },
        "qwen3-vl-235b-a22b-thinking": {
            "rating": 1411.190253913226,
            "rating_q975": 1440.0253359508167,
            "rating_q025": 1382.355171875635
        },
        "qwen3-coder-480b-a35b-instruct": {
            "rating": 1410.4042529195951,
            "rating_q975": 1427.4628803805338,
            "rating_q025": 1393.3456254586565
        },
        "gemini-2.5-flash-lite-preview-06-17-thinking": {
            "rating": 1408.3886651759406,
            "rating_q975": 1422.7545489805846,
            "rating_q025": 1394.0227813712966
        },
        "gpt-5-mini-high": {
            "rating": 1407.2802515937715,
            "rating_q975": 1425.4050749648454,
            "rating_q025": 1389.1554282226975
        },
        "o1-2024-12-17": {
            "rating": 1406.4556483462295,
            "rating_q975": 1423.6293809661827,
            "rating_q025": 1389.2819157262763
        },
        "gemma-3-27b-it": {
            "rating": 1405.2009655248653,
            "rating_q975": 1418.1637501949783,
            "rating_q025": 1392.2381808547523
        },
        "gpt-4.1-mini-2025-04-14": {
            "rating": 1403.8992308886338,
            "rating_q975": 1416.9797252330138,
            "rating_q025": 1390.8187365442539
        },
        "qwen3-30b-a3b-instruct-2507": {
            "rating": 1400.4418498778505,
            "rating_q975": 1417.4712222193327,
            "rating_q025": 1383.4124775363682
        },
        "deepseek-v3": {
            "rating": 1399.1689770279984,
            "rating_q975": 1416.990648334667,
            "rating_q025": 1381.3473057213298
        },
        "glm-4.5v": {
            "rating": 1397.7826010269407,
            "rating_q975": 1437.218065253308,
            "rating_q025": 1358.3471368005735
        },
        "gemini-2.5-flash-lite-preview-09-2025-no-thinking": {
            "rating": 1397.57105449927,
            "rating_q975": 1422.9190556585293,
            "rating_q025": 1372.223053340011
        },
        "hunyuan-large-2025-02-10": {
            "rating": 1396.0829586144564,
            "rating_q975": 1434.7778683702893,
            "rating_q025": 1357.3880488586235
        },
        "claude-3-5-sonnet-20241022": {
            "rating": 1395.92632910678,
            "rating_q975": 1405.452116403684,
            "rating_q025": 1386.4005418098761
        },
        "glm-4.5-air": {
            "rating": 1395.659073148049,
            "rating_q975": 1411.678228115969,
            "rating_q025": 1379.639918180129
        },
        "qwen2.5-max": {
            "rating": 1395.5787838953515,
            "rating_q975": 1410.2702683248135,
            "rating_q025": 1380.8872994658896
        },
        "qwen3-next-80b-a3b-thinking": {
            "rating": 1392.8787878517935,
            "rating_q975": 1415.6597770488274,
            "rating_q025": 1370.0977986547596
        },
        "mistral-small-2506": {
            "rating": 1391.278675302817,
            "rating_q975": 1409.392025288552,
            "rating_q025": 1373.1653253170819
        },
        "qwen-plus-0125": {
            "rating": 1391.1944471767492,
            "rating_q975": 1423.0213727681837,
            "rating_q025": 1359.3675215853148
        },
        "grok-3-mini-high": {
            "rating": 1388.8067144688766,
            "rating_q975": 1407.9158449799954,
            "rating_q025": 1369.6975839577578
        },
        "nvidia-llama-3.3-nemotron-super-49b-v1.5": {
            "rating": 1385.7533250171068,
            "rating_q975": 1425.5227627955287,
            "rating_q025": 1345.983887238685
        },
        "qwen3-235b-a22b": {
            "rating": 1383.9637494168956,
            "rating_q975": 1399.3727595575754,
            "rating_q025": 1368.5547392762157
        },
        "command-a-03-2025": {
            "rating": 1380.704542061729,
            "rating_q975": 1392.5636934993643,
            "rating_q025": 1368.8453906240936
        },
        "step-2-16k-exp-202412": {
            "rating": 1379.313927907249,
            "rating_q975": 1415.9674581086513,
            "rating_q025": 1342.660397705847
        },
        "qwen3-32b": {
            "rating": 1379.0315834704436,
            "rating_q975": 1418.5968601753414,
            "rating_q025": 1339.4663067655458
        },
        "llama-3.1-405b-instruct-bf16": {
            "rating": 1377.0119792598603,
            "rating_q975": 1390.5127910169695,
            "rating_q025": 1363.511167502751
        },
        "gemini-2.0-flash-lite-preview-02-05": {
            "rating": 1376.9519472792922,
            "rating_q975": 1395.638770244458,
            "rating_q025": 1358.2651243141263
        },
        "o1-preview": {
            "rating": 1375.669651192642,
            "rating_q975": 1390.2510277710855,
            "rating_q025": 1361.0882746141986
        },
        "o3-mini-high": {
            "rating": 1375.2208950019774,
            "rating_q975": 1396.118878857337,
            "rating_q025": 1354.3229111466178
        },
        "gpt-5-nano-high": {
            "rating": 1374.7844870065044,
            "rating_q975": 1403.185993446392,
            "rating_q025": 1346.3829805666167
        },
        "hunyuan-standard-2025-02-10": {
            "rating": 1368.7637349823328,
            "rating_q975": 1406.311726664445,
            "rating_q025": 1331.2157433002208
        },
        "step-3": {
            "rating": 1367.2475179253966,
            "rating_q975": 1399.1168911428406,
            "rating_q025": 1335.3781447079525
        },
        "gpt-oss-120b": {
            "rating": 1367.1003533037685,
            "rating_q975": 1383.680222761145,
            "rating_q025": 1350.5204838463922
        },
        "gpt-oss-20b": {
            "rating": 1365.2130056763517,
            "rating_q975": 1391.6870039288738,
            "rating_q025": 1338.7390074238297
        },
        "gemini-1.5-pro-002": {
            "rating": 1364.771257421462,
            "rating_q975": 1376.4919686970939,
            "rating_q025": 1353.0505461458301
        },
        "gpt-4o-2024-05-13": {
            "rating": 1363.137304673111,
            "rating_q975": 1372.640283364204,
            "rating_q025": 1353.634325982018
        },
        "yi-lightning": {
            "rating": 1362.7503519323618,
            "rating_q975": 1378.346697261702,
            "rating_q025": 1347.1540066030216
        },
        "grok-3-mini-beta": {
            "rating": 1362.5622587640264,
            "rating_q975": 1378.6781758397228,
            "rating_q025": 1346.44634168833
        },
        "grok-2-2024-08-13": {
            "rating": 1361.7606901158533,
            "rating_q975": 1372.6594946208838,
            "rating_q025": 1350.8618856108228
        },
        "claude-3-5-sonnet-20240620": {
            "rating": 1361.611262757205,
            "rating_q975": 1372.1866288556585,
            "rating_q025": 1351.0358966587514
        },
        "llama-4-maverick-17b-128e-instruct": {
            "rating": 1359.0437280041415,
            "rating_q975": 1372.5147605395634,
            "rating_q025": 1345.5726954687195
        },
        "llama-3.1-405b-instruct-fp8": {
            "rating": 1357.8093694276577,
            "rating_q975": 1369.1301969918472,
            "rating_q025": 1346.488541863468
        },
        "qwq-32b": {
            "rating": 1356.6332718356232,
            "rating_q975": 1372.7274543155554,
            "rating_q025": 1340.539089355691
        },
        "ling-flash-2.0": {
            "rating": 1356.2739190962025,
            "rating_q975": 1387.3680944353748,
            "rating_q025": 1325.17974375703
        },
        "amazon-nova-experimental-chat-10-09": {
            "rating": 1354.5300658282436,
            "rating_q975": 1398.5101281453,
            "rating_q025": 1310.550003511187
        },
        "gpt-4o-2024-08-06": {
            "rating": 1354.4516567362612,
            "rating_q975": 1367.4279581308306,
            "rating_q025": 1341.4753553416917
        },
        "gemini-advanced-0514": {
            "rating": 1353.8030323913795,
            "rating_q975": 1367.251122627056,
            "rating_q025": 1340.354942155703
        },
        "claude-3-5-haiku-20241022": {
            "rating": 1353.5782888988947,
            "rating_q975": 1364.582662564136,
            "rating_q025": 1342.5739152336535
        },
        "llama-3.3-70b-instruct": {
            "rating": 1352.6125047951466,
            "rating_q975": 1364.1270261505563,
            "rating_q025": 1341.097983439737
        },
        "gemma-3-4b-it": {
            "rating": 1352.110963782878,
            "rating_q975": 1391.382911104828,
            "rating_q025": 1312.8390164609277
        },
        "o3-mini": {
            "rating": 1351.191814141776,
            "rating_q975": 1362.4569887794016,
            "rating_q025": 1339.9266395041502
        },
        "gpt-4.1-nano-2025-04-14": {
            "rating": 1350.579322526815,
            "rating_q975": 1382.9694904960422,
            "rating_q025": 1318.189154557588
        },
        "reka-core-20240904": {
            "rating": 1350.5274851867525,
            "rating_q975": 1378.725362213304,
            "rating_q025": 1322.3296081602011
        },
        "magistral-medium-2506": {
            "rating": 1350.119145369334,
            "rating_q975": 1373.675520881702,
            "rating_q025": 1326.5627698569663
        },
        "llama-4-scout-17b-16e-instruct": {
            "rating": 1349.5544256090766,
            "rating_q975": 1364.5976462791002,
            "rating_q025": 1334.511204939053
        },
        "grok-2-mini-2024-08-13": {
            "rating": 1348.9014887664614,
            "rating_q975": 1360.889159462307,
            "rating_q025": 1336.913818070616
        },
        "claude-3-opus-20240229": {
            "rating": 1348.8808128290193,
            "rating_q975": 1357.6184650252785,
            "rating_q025": 1340.14316063276
        },
        "gemma-3n-e4b-it": {
            "rating": 1347.1510965728935,
            "rating_q975": 1363.9694445884065,
            "rating_q025": 1330.3327485573805
        },
        "glm-4-plus": {
            "rating": 1344.6572211329644,
            "rating_q975": 1359.5001084912367,
            "rating_q025": 1329.8143337746922
        },
        "o1-mini": {
            "rating": 1342.0057008481194,
            "rating_q975": 1353.8265130224574,
            "rating_q025": 1330.1848886737814
        },
        "deepseek-v2.5-1210": {
            "rating": 1341.5086905110602,
            "rating_q975": 1373.83985487319,
            "rating_q025": 1309.1775261489304
        },
        "gpt-4-turbo-2024-04-09": {
            "rating": 1340.1454088632663,
            "rating_q975": 1350.682366224394,
            "rating_q025": 1329.6084515021387
        },
        "gpt-4o-mini-2024-07-18": {
            "rating": 1340.127509008483,
            "rating_q975": 1350.5117335760897,
            "rating_q025": 1329.7432844408763
        },
        "llama-3.1-nemotron-70b-instruct": {
            "rating": 1338.9960876514715,
            "rating_q975": 1369.5505492538405,
            "rating_q025": 1308.4416260491025
        },
        "qwen3-30b-a3b": {
            "rating": 1338.8434620735306,
            "rating_q975": 1354.014044415336,
            "rating_q025": 1323.6728797317253
        },
        "athene-v2-chat": {
            "rating": 1337.211959759431,
            "rating_q975": 1353.8345135592142,
            "rating_q025": 1320.5894059596478
        },
        "gemini-1.5-flash-002": {
            "rating": 1335.3783388018471,
            "rating_q975": 1349.807110784128,
            "rating_q025": 1320.9495668195661
        },
        "athene-70b-0725": {
            "rating": 1335.0358220066232,
            "rating_q975": 1353.271554143435,
            "rating_q025": 1316.8000898698115
        },
        "step-1o-turbo-202506": {
            "rating": 1334.3355527343456,
            "rating_q975": 1357.319608484027,
            "rating_q025": 1311.3514969846642
        },
        "ring-flash-2.0": {
            "rating": 1334.2156767848494,
            "rating_q975": 1365.2302100402646,
            "rating_q025": 1303.2011435294341
        },
        "qwen2.5-plus-1127": {
            "rating": 1333.2928534399944,
            "rating_q975": 1359.5151532813452,
            "rating_q025": 1307.0705535986435
        },
        "mistral-large-2407": {
            "rating": 1333.141503792858,
            "rating_q975": 1345.6183395531048,
            "rating_q025": 1320.6646680326112
        },
        "amazon-nova-pro-v1.0": {
            "rating": 1329.0739214193263,
            "rating_q975": 1346.3428372420915,
            "rating_q025": 1311.8050055965612
        },
        "gpt-4-0125-preview": {
            "rating": 1327.075175426825,
            "rating_q975": 1337.9238219733675,
            "rating_q025": 1316.2265288802823
        },
        "mistral-large-2411": {
            "rating": 1325.3028284040402,
            "rating_q975": 1341.6980799343964,
            "rating_q025": 1308.9075768736839
        },
        "mistral-small-3.1-24b-instruct-2503": {
            "rating": 1324.2201650131688,
            "rating_q975": 1338.7278261296378,
            "rating_q025": 1309.7125038966997
        },
        "qwen-max-0919": {
            "rating": 1324.1523621391698,
            "rating_q975": 1342.2725728247137,
            "rating_q025": 1306.0321514536258
        },
        "gemma-3-12b-it": {
            "rating": 1323.889211167696,
            "rating_q975": 1370.8388919485685,
            "rating_q025": 1276.9395303868234
        },
        "llama-3.1-70b-instruct": {
            "rating": 1320.4352660239354,
            "rating_q975": 1332.1059402830601,
            "rating_q025": 1308.7645917648106
        },
        "deepseek-v2.5": {
            "rating": 1319.8772116067314,
            "rating_q975": 1336.6585656306193,
            "rating_q025": 1303.0958575828436
        },
        "qwen2.5-72b-instruct": {
            "rating": 1319.8054240599145,
            "rating_q975": 1333.1035207584075,
            "rating_q025": 1306.5073273614214
        },
        "gpt-4-1106-preview": {
            "rating": 1315.8965525437548,
            "rating_q975": 1326.7003795114642,
            "rating_q025": 1305.0927255760453
        },
        "claude-3-sonnet-20240229": {
            "rating": 1314.1705430365082,
            "rating_q975": 1325.3747017674661,
            "rating_q025": 1302.9663843055503
        },
        "command-r-plus-08-2024": {
            "rating": 1310.8037723556718,
            "rating_q975": 1334.8628604507883,
            "rating_q025": 1286.7446842605552
        },
        "llama-3-70b-instruct": {
            "rating": 1310.233162995831,
            "rating_q975": 1320.1321895655863,
            "rating_q025": 1300.3341364260757
        },
        "gemini-1.5-pro-001": {
            "rating": 1309.1899883942397,
            "rating_q975": 1320.448409610429,
            "rating_q025": 1297.9315671780503
        },
        "gemma-2-9b-it-simpo": {
            "rating": 1309.1228202485543,
            "rating_q975": 1335.1538639214893,
            "rating_q025": 1283.0917765756192
        },
        "gemma-2-27b-it": {
            "rating": 1301.1265184271756,
            "rating_q975": 1311.3794785305327,
            "rating_q025": 1290.8735583238185
        },
        "nemotron-4-340b-instruct": {
            "rating": 1300.444752163867,
            "rating_q975": 1318.5546784913995,
            "rating_q025": 1282.3348258363344
        },
        "command-r-plus": {
            "rating": 1300.3561610104548,
            "rating_q975": 1312.2609186488576,
            "rating_q025": 1288.451403372052
        },
        "c4ai-aya-expanse-32b": {
            "rating": 1299.8539650794428,
            "rating_q975": 1315.6310543896157,
            "rating_q025": 1284.07687576927
        },
        "command-r-08-2024": {
            "rating": 1299.3909106454407,
            "rating_q975": 1325.0053398082061,
            "rating_q025": 1273.7764814826753
        },
        "reka-flash-20240904": {
            "rating": 1295.798466438941,
            "rating_q975": 1323.1884099738154,
            "rating_q025": 1268.4085229040666
        },
        "mistral-small-24b-instruct-2501": {
            "rating": 1294.5737150064083,
            "rating_q975": 1318.3873032497352,
            "rating_q025": 1270.7601267630814
        },
        "claude-3-haiku-20240307": {
            "rating": 1294.5113759245464,
            "rating_q975": 1304.683466671331,
            "rating_q025": 1284.339285177762
        },
        "jamba-1.5-large": {
            "rating": 1292.5485865759656,
            "rating_q975": 1319.8284795983009,
            "rating_q025": 1265.2686935536303
        },
        "glm-4-0520": {
            "rating": 1291.7026651118017,
            "rating_q975": 1315.579440132646,
            "rating_q025": 1267.8258900909575
        },
        "llama-3.1-nemotron-51b-instruct": {
            "rating": 1290.8205523691886,
            "rating_q975": 1330.143014284618,
            "rating_q025": 1251.4980904537592
        },
        "qwen2-72b-instruct": {
            "rating": 1290.596952862474,
            "rating_q975": 1304.3131700515046,
            "rating_q025": 1276.8807356734433
        },
        "hunyuan-large-vision": {
            "rating": 1290.444802939484,
            "rating_q975": 1321.9610588259893,
            "rating_q025": 1258.9285470529785
        },
        "gpt-4-0314": {
            "rating": 1289.9531188348606,
            "rating_q975": 1303.7606306509274,
            "rating_q025": 1276.1456070187937
        },
        "gpt-4-0613": {
            "rating": 1284.9423287690734,
            "rating_q975": 1296.5329736653914,
            "rating_q025": 1273.3516838727553
        },
        "phi-4": {
            "rating": 1282.6688350275163,
            "rating_q975": 1301.875593230586,
            "rating_q025": 1263.4620768244465
        },
        "amazon-nova-lite-v1.0": {
            "rating": 1280.7973477968746,
            "rating_q975": 1300.3671718201945,
            "rating_q025": 1261.2275237735548
        },
        "gemini-1.5-flash-001": {
            "rating": 1280.59731619762,
            "rating_q975": 1292.47098732976,
            "rating_q025": 1268.7236450654802
        },
        "gemini-1.5-flash-8b-001": {
            "rating": 1276.527650750786,
            "rating_q975": 1290.8119328700998,
            "rating_q025": 1262.2433686314723
        },
        "amazon-nova-micro-v1.0": {
            "rating": 1276.0945749016737,
            "rating_q975": 1294.8928387192368,
            "rating_q025": 1257.2963110841106
        },
        "jamba-1.5-mini": {
            "rating": 1274.668774873288,
            "rating_q975": 1301.2542767107057,
            "rating_q025": 1248.0832730358702
        },
        "gemini-pro-dev-api": {
            "rating": 1274.4408530360165,
            "rating_q975": 1294.9209077850858,
            "rating_q025": 1253.9607982869472
        },
        "deepseek-coder-v2": {
            "rating": 1270.9465371808062,
            "rating_q975": 1290.9355052822414,
            "rating_q025": 1250.957569079371
        },
        "gemma-2-9b-it": {
            "rating": 1270.0049206989065,
            "rating_q975": 1281.7745973369679,
            "rating_q025": 1258.2352440608452
        },
        "c4ai-aya-expanse-8b": {
            "rating": 1268.3431759082177,
            "rating_q975": 1295.423043308685,
            "rating_q025": 1241.2633085077505
        },
        "mistral-large-2402": {
            "rating": 1266.146035248373,
            "rating_q975": 1278.9316524045566,
            "rating_q025": 1253.3604180921893
        },
        "reka-flash-21b-20240226-online": {
            "rating": 1264.4843319538736,
            "rating_q975": 1285.4733717314466,
            "rating_q025": 1243.4952921763006
        },
        "qwen2.5-coder-32b-instruct": {
            "rating": 1263.3213442671477,
            "rating_q975": 1299.5752589129395,
            "rating_q025": 1227.0674296213558
        },
        "ministral-8b-2410": {
            "rating": 1263.2763577642668,
            "rating_q975": 1297.8793585917638,
            "rating_q025": 1228.6733569367698
        },
        "command-r": {
            "rating": 1262.7619886714383,
            "rating_q975": 1276.183249587265,
            "rating_q025": 1249.3407277556116
        },
        "reka-flash-21b-20240226": {
            "rating": 1262.2250488122938,
            "rating_q975": 1280.0950734654612,
            "rating_q025": 1244.3550241591265
        },
        "qwen1.5-110b-chat": {
            "rating": 1260.897254690512,
            "rating_q975": 1277.4901916754395,
            "rating_q025": 1244.3043177055845
        },
        "qwen1.5-72b-chat": {
            "rating": 1259.5628298416354,
            "rating_q975": 1273.4581821487948,
            "rating_q025": 1245.6674775344761
        },
        "mistral-medium": {
            "rating": 1257.8769716335707,
            "rating_q975": 1273.2764452516287,
            "rating_q025": 1242.4774980155128
        },
        "olmo-2-0325-32b-instruct": {
            "rating": 1256.3454057546219,
            "rating_q975": 1302.0664414536216,
            "rating_q025": 1210.6243700556222
        },
        "mixtral-8x22b-instruct-v0.1": {
            "rating": 1255.042652162321,
            "rating_q975": 1268.071877654604,
            "rating_q025": 1242.0134266700381
        },
        "gemini-pro": {
            "rating": 1251.9516338554022,
            "rating_q975": 1291.2091514561353,
            "rating_q025": 1212.694116254669
        },
        "gpt-3.5-turbo-0125": {
            "rating": 1249.3345877306945,
            "rating_q975": 1261.158224832666,
            "rating_q025": 1237.5109506287229
        },
        "llama-3-8b-instruct": {
            "rating": 1248.968022328992,
            "rating_q975": 1259.9845138140256,
            "rating_q025": 1237.9515308439584
        },
        "zephyr-orpo-141b-A35b-v0.1": {
            "rating": 1245.5041903812662,
            "rating_q975": 1280.6949963127242,
            "rating_q025": 1210.3133844498082
        },
        "yi-1.5-34b-chat": {
            "rating": 1237.4223485960906,
            "rating_q975": 1254.344838323572,
            "rating_q025": 1220.4998588686092
        },
        "llama-3.1-8b-instruct": {
            "rating": 1236.2267418998513,
            "rating_q975": 1248.569604101981,
            "rating_q025": 1223.8838796977216
        },
        "phi-3-medium-4k-instruct": {
            "rating": 1233.7707977696018,
            "rating_q975": 1250.4847100401755,
            "rating_q025": 1217.056885499028
        },
        "qwen1.5-32b-chat": {
            "rating": 1229.304835332527,
            "rating_q975": 1247.1168502231462,
            "rating_q025": 1211.492820441908
        },
        "deepseek-llm-67b-chat": {
            "rating": 1227.5914501905504,
            "rating_q975": 1256.203307328993,
            "rating_q025": 1198.9795930521077
        },
        "starling-lm-7b-alpha": {
            "rating": 1227.5170925761097,
            "rating_q975": 1252.6816822488381,
            "rating_q025": 1202.3525029033813
        },
        "mixtral-8x7b-instruct-v0.1": {
            "rating": 1226.2477286731341,
            "rating_q975": 1238.04502261348,
            "rating_q025": 1214.4504347327884
        },
        "gemma-1.1-7b-it": {
            "rating": 1225.8660079941023,
            "rating_q975": 1244.0140561380545,
            "rating_q025": 1207.7179598501502
        },
        "qwen1.5-14b-chat": {
            "rating": 1224.1593359034714,
            "rating_q975": 1244.103290918609,
            "rating_q025": 1204.2153808883338
        },
        "openchat-3.5": {
            "rating": 1222.791433093175,
            "rating_q975": 1252.7651012098843,
            "rating_q025": 1192.817764976466
        },
        "gemma-2-2b-it": {
            "rating": 1220.8851577909545,
            "rating_q975": 1234.0824283791794,
            "rating_q025": 1207.6878872027296
        },
        "dbrx-instruct-preview": {
            "rating": 1220.3501272300075,
            "rating_q975": 1237.5666768420017,
            "rating_q025": 1203.1335776180133
        },
        "internlm2_5-20b-chat": {
            "rating": 1218.041725227505,
            "rating_q975": 1243.469278981114,
            "rating_q025": 1192.6141714738958
        },
        "llama-3.2-3b-instruct": {
            "rating": 1217.3662878922314,
            "rating_q975": 1247.939549304991,
            "rating_q025": 1186.7930264794718
        },
        "phi-3-small-8k-instruct": {
            "rating": 1216.0983706314528,
            "rating_q975": 1235.1224364601012,
            "rating_q025": 1197.0743048028044
        },
        "starling-lm-7b-beta": {
            "rating": 1215.7675146724832,
            "rating_q975": 1237.2265662259458,
            "rating_q025": 1194.3084631190206
        },
        "yi-34b-chat": {
            "rating": 1214.0518790037413,
            "rating_q975": 1235.4778032286895,
            "rating_q025": 1192.6259547787931
        },
        "wizardlm-70b": {
            "rating": 1214.03867833585,
            "rating_q975": 1244.1366187148735,
            "rating_q025": 1183.9407379568263
        },
        "granite-3.0-8b-instruct": {
            "rating": 1213.331221112548,
            "rating_q975": 1248.9953399956394,
            "rating_q025": 1177.6671022294568
        },
        "snowflake-arctic-instruct": {
            "rating": 1212.113080136915,
            "rating_q975": 1230.4572734829276,
            "rating_q025": 1193.7688867909023
        },
        "openchat-3.5-0106": {
            "rating": 1211.5339662987235,
            "rating_q975": 1232.5852106084449,
            "rating_q025": 1190.4827219890021
        },
        "openhermes-2.5-mistral-7b": {
            "rating": 1209.6691578589543,
            "rating_q975": 1244.5790133898388,
            "rating_q025": 1174.75930232807
        },
        "gpt-3.5-turbo-1106": {
            "rating": 1202.477258515853,
            "rating_q975": 1223.9662815108277,
            "rating_q025": 1180.9882355208783
        },
        "solar-10.7b-instruct-v1.0": {
            "rating": 1198.2543325185911,
            "rating_q975": 1238.9257505659311,
            "rating_q025": 1157.5829144712511
        },
        "llama-2-70b-chat": {
            "rating": 1194.8906011291087,
            "rating_q975": 1209.599913999595,
            "rating_q025": 1180.1812882586225
        },
        "mistral-7b-instruct-v0.2": {
            "rating": 1193.8490908882068,
            "rating_q975": 1211.9751072951312,
            "rating_q025": 1175.7230744812823
        },
        "vicuna-33b": {
            "rating": 1191.2194392449233,
            "rating_q975": 1209.8996081856426,
            "rating_q025": 1172.539270304204
        },
        "wizardlm-13b": {
            "rating": 1189.4163446728103,
            "rating_q975": 1224.2724138508358,
            "rating_q025": 1154.5602754947847
        },
        "tulu-2-dpo-70b": {
            "rating": 1186.86083652681,
            "rating_q975": 1217.8944706283578,
            "rating_q025": 1155.8272024252624
        },
        "qwen1.5-7b-chat": {
            "rating": 1180.3055209173644,
            "rating_q975": 1216.1323807800943,
            "rating_q025": 1144.4786610546346
        },
        "llama-2-13b-chat": {
            "rating": 1179.7502616702761,
            "rating_q975": 1200.1088224691212,
            "rating_q025": 1159.391700871431
        },
        "qwen-14b-chat": {
            "rating": 1178.3661005294334,
            "rating_q975": 1215.499361806921,
            "rating_q025": 1141.232839251946
        },
        "vicuna-13b": {
            "rating": 1176.9752475213702,
            "rating_q975": 1198.7886546577165,
            "rating_q025": 1155.1618403850239
        },
        "gemma-7b-it": {
            "rating": 1171.6794688492582,
            "rating_q975": 1197.255362485332,
            "rating_q025": 1146.1035752131845
        },
        "palm-2": {
            "rating": 1170.642372719009,
            "rating_q975": 1207.9346358874554,
            "rating_q025": 1133.3501095505626
        },
        "zephyr-7b-beta": {
            "rating": 1166.4379852149852,
            "rating_q975": 1192.2721847926725,
            "rating_q025": 1140.603785637298
        },
        "nous-hermes-2-mixtral-8x7b-dpo": {
            "rating": 1164.7816149494577,
            "rating_q975": 1196.753882150223,
            "rating_q025": 1132.8093477486923
        },
        "phi-3-mini-4k-instruct-june-2024": {
            "rating": 1162.801462354566,
            "rating_q975": 1188.2345719887176,
            "rating_q025": 1137.3683527204144
        },
        "mistral-7b-instruct": {
            "rating": 1159.8370060190027,
            "rating_q975": 1187.291933522705,
            "rating_q025": 1132.3820785153005
        },
        "codellama-34b-instruct": {
            "rating": 1157.0698680274104,
            "rating_q975": 1188.2002697170087,
            "rating_q025": 1125.939466337812
        },
        "gemma-1.1-2b-it": {
            "rating": 1156.1947623105675,
            "rating_q975": 1182.7039056623316,
            "rating_q025": 1129.6856189588034
        },
        "vicuna-7b": {
            "rating": 1153.3240060316073,
            "rating_q975": 1188.4094727799172,
            "rating_q025": 1118.2385392832973
        },
        "granite-3.0-2b-instruct": {
            "rating": 1148.6525231175326,
            "rating_q975": 1185.9133318273255,
            "rating_q025": 1111.3917144077398
        },
        "phi-3-mini-128k-instruct": {
            "rating": 1147.0595216724246,
            "rating_q975": 1168.6772404757867,
            "rating_q025": 1125.4418028690625
        },
        "phi-3-mini-4k-instruct": {
            "rating": 1146.0088799700773,
            "rating_q975": 1166.1033875109715,
            "rating_q025": 1125.914372429183
        },
        "stripedhyena-nous-7b": {
            "rating": 1144.7365212429934,
            "rating_q975": 1175.6119092986075,
            "rating_q025": 1113.8611331873792
        },
        "llama-2-7b-chat": {
            "rating": 1139.6569197036276,
            "rating_q975": 1162.201236134491,
            "rating_q025": 1117.1126032727643
        },
        "olmo-7b-instruct": {
            "rating": 1135.73579957261,
            "rating_q975": 1167.716890762031,
            "rating_q025": 1103.754708383189
        },
        "qwen1.5-4b-chat": {
            "rating": 1127.2988813686839,
            "rating_q975": 1157.6458707565002,
            "rating_q025": 1096.9518919808675
        },
        "RWKV-4-Raven-14B": {
            "rating": 1118.3739245370984,
            "rating_q975": 1167.7682477736137,
            "rating_q025": 1068.9796013005832
        },
        "llama-3.2-1b-instruct": {
            "rating": 1111.8470460572717,
            "rating_q975": 1144.1004575949205,
            "rating_q025": 1079.5936345196228
        },
        "koala-13b": {
            "rating": 1108.435330546712,
            "rating_q975": 1150.7987696864643,
            "rating_q025": 1066.0718914069598
        },
        "gemma-2b-it": {
            "rating": 1105.979462000534,
            "rating_q975": 1144.7149162009716,
            "rating_q025": 1067.2440078000966
        },
        "alpaca-13b": {
            "rating": 1062.8746203166888,
            "rating_q975": 1112.7153524898447,
            "rating_q025": 1013.033888143533
        },
        "chatglm3-6b": {
            "rating": 1054.5657936154312,
            "rating_q975": 1096.5003902783753,
            "rating_q025": 1012.6311969524871
        },
        "oasst-pythia-12b": {
            "rating": 1003.2601773935316,
            "rating_q975": 1052.6936063850032,
            "rating_q025": 953.82674840206
        },
        "chatglm-6b": {
            "rating": 960.5061661402417,
            "rating_q975": 1013.7210367197522,
            "rating_q025": 907.2912955607312
        }
    },
    "industry_software_and_it_services": {
        "claude-sonnet-4-5-20250929-thinking-32k": {
            "rating": 1497.8949542034904,
            "rating_q975": 1507.073761723708,
            "rating_q025": 1488.7161466832729
        },
        "claude-opus-4-1-20250805-thinking-16k": {
            "rating": 1492.646980285424,
            "rating_q975": 1499.5516658658466,
            "rating_q025": 1485.7422947050013
        },
        "claude-sonnet-4-5-20250929": {
            "rating": 1482.4594911857366,
            "rating_q975": 1494.8424434052902,
            "rating_q025": 1470.076538966183
        },
        "claude-opus-4-1-20250805": {
            "rating": 1479.7236641836641,
            "rating_q975": 1486.0940309056245,
            "rating_q025": 1473.3532974617037
        },
        "qwen3-max-preview": {
            "rating": 1469.8361324524703,
            "rating_q975": 1477.0851646943077,
            "rating_q025": 1462.587100210633
        },
        "claude-opus-4-20250514-thinking-16k": {
            "rating": 1465.2358393642417,
            "rating_q975": 1471.5548536628799,
            "rating_q025": 1458.9168250656035
        },
        "gemini-2.5-pro": {
            "rating": 1464.359136912604,
            "rating_q975": 1470.05221450089,
            "rating_q025": 1458.6660593243182
        },
        "glm-4.6": {
            "rating": 1462.7738038326854,
            "rating_q975": 1472.7796500761558,
            "rating_q025": 1452.767957589215
        },
        "qwen3-max-2025-09-23": {
            "rating": 1462.1742273574253,
            "rating_q975": 1472.2761697815292,
            "rating_q025": 1452.0722849333213
        },
        "chatgpt-4o-latest-20250326": {
            "rating": 1460.544908834684,
            "rating_q975": 1466.3275874449287,
            "rating_q025": 1454.7622302244395
        },
        "qwen3-235b-a22b-instruct-2507": {
            "rating": 1460.255942113924,
            "rating_q975": 1466.6172752125174,
            "rating_q025": 1453.8946090153306
        },
        "deepseek-v3.2-exp-thinking": {
            "rating": 1456.7018484119233,
            "rating_q975": 1467.2092471677186,
            "rating_q025": 1446.194449656128
        },
        "grok-4-fast": {
            "rating": 1456.5270635550528,
            "rating_q975": 1469.0173996897424,
            "rating_q025": 1444.0367274203631
        },
        "gpt-4.5-preview-2025-02-27": {
            "rating": 1456.0636141227737,
            "rating_q975": 1466.18094755044,
            "rating_q025": 1445.9462806951076
        },
        "qwen3-vl-235b-a22b-instruct": {
            "rating": 1454.9468141822842,
            "rating_q975": 1465.3884260483142,
            "rating_q025": 1444.5052023162543
        },
        "gpt-5-high": {
            "rating": 1454.5907161890254,
            "rating_q975": 1461.622288789587,
            "rating_q025": 1447.559143588464
        },
        "deepseek-r1-0528": {
            "rating": 1454.479486700313,
            "rating_q975": 1462.833408750993,
            "rating_q025": 1446.125564649633
        },
        "o3-2025-04-16": {
            "rating": 1454.422202433113,
            "rating_q975": 1460.010062993981,
            "rating_q025": 1448.834341872245
        },
        "claude-haiku-4-5-20251001": {
            "rating": 1452.8709740770505,
            "rating_q975": 1462.7852084657495,
            "rating_q025": 1442.9567396883515
        },
        "kimi-k2-0711-preview": {
            "rating": 1452.7570872609622,
            "rating_q975": 1459.7686070961727,
            "rating_q025": 1445.7455674257517
        },
        "kimi-k2-0905-preview": {
            "rating": 1452.0201176651778,
            "rating_q975": 1462.2985506222499,
            "rating_q025": 1441.7416847081058
        },
        "gpt-5-chat": {
            "rating": 1451.8514492830336,
            "rating_q975": 1458.6085397373176,
            "rating_q025": 1445.0943588287496
        },
        "longcat-flash-chat": {
            "rating": 1451.2916335391942,
            "rating_q975": 1460.9936930081972,
            "rating_q025": 1441.5895740701912
        },
        "deepseek-v3.1-thinking": {
            "rating": 1446.593793520192,
            "rating_q975": 1456.6499856389198,
            "rating_q025": 1436.5376014014644
        },
        "qwen3-next-80b-a3b-instruct": {
            "rating": 1444.4700701888141,
            "rating_q975": 1452.1630164714652,
            "rating_q025": 1436.777123906163
        },
        "glm-4.5": {
            "rating": 1443.1357217269524,
            "rating_q975": 1450.3283153671634,
            "rating_q025": 1435.9431280867414
        },
        "mistral-medium-2508": {
            "rating": 1443.1004182144131,
            "rating_q975": 1449.8955314911375,
            "rating_q025": 1436.3053049376888
        },
        "claude-sonnet-4-20250514-thinking-32k": {
            "rating": 1442.7994420181717,
            "rating_q975": 1449.1000092875245,
            "rating_q025": 1436.498874748819
        },
        "deepseek-v3.1": {
            "rating": 1442.3166739385158,
            "rating_q975": 1451.270847209516,
            "rating_q025": 1433.3625006675156
        },
        "deepseek-v3.1-terminus-thinking": {
            "rating": 1442.1141157771963,
            "rating_q975": 1459.368719034652,
            "rating_q025": 1424.8595125197405
        },
        "gpt-4.1-2025-04-14": {
            "rating": 1441.602833804069,
            "rating_q975": 1447.331129703544,
            "rating_q025": 1435.8745379045938
        },
        "claude-opus-4-20250514": {
            "rating": 1440.578765882865,
            "rating_q975": 1446.6119550597332,
            "rating_q025": 1434.5455767059966
        },
        "qwen3-235b-a22b-no-thinking": {
            "rating": 1436.1313282945064,
            "rating_q975": 1442.3952817156792,
            "rating_q025": 1429.8673748733336
        },
        "qwen3-vl-235b-a22b-thinking": {
            "rating": 1435.4920219214362,
            "rating_q975": 1446.4480554851527,
            "rating_q025": 1424.5359883577196
        },
        "qwen3-coder-480b-a35b-instruct": {
            "rating": 1432.4682432352565,
            "rating_q975": 1439.8261486782208,
            "rating_q025": 1425.1103377922923
        },
        "grok-3-preview-02-24": {
            "rating": 1431.4708417595118,
            "rating_q975": 1438.231332266632,
            "rating_q025": 1424.7103512523915
        },
        "qwen3-235b-a22b-thinking-2507": {
            "rating": 1429.9892339214803,
            "rating_q975": 1440.8117531961823,
            "rating_q025": 1419.1667146467782
        },
        "deepseek-v3.1-terminus": {
            "rating": 1429.3166655399682,
            "rating_q975": 1445.4067100382226,
            "rating_q025": 1413.2266210417138
        },
        "deepseek-r1": {
            "rating": 1428.6434890903913,
            "rating_q975": 1437.7870769936048,
            "rating_q025": 1419.4999011871778
        },
        "qwen3-30b-a3b-instruct-2507": {
            "rating": 1427.8855692378934,
            "rating_q975": 1435.1206677456967,
            "rating_q025": 1420.65047073009
        },
        "claude-sonnet-4-20250514": {
            "rating": 1426.8117355469992,
            "rating_q975": 1432.9358748908458,
            "rating_q025": 1420.6875962031527
        },
        "grok-4-0709": {
            "rating": 1423.5015137135854,
            "rating_q975": 1429.6997395756907,
            "rating_q025": 1417.30328785148
        },
        "o1-2024-12-17": {
            "rating": 1421.4830926685838,
            "rating_q975": 1429.021494029782,
            "rating_q025": 1413.9446913073857
        },
        "gemini-2.5-flash-preview-09-2025": {
            "rating": 1420.9584582519697,
            "rating_q975": 1429.6941809599973,
            "rating_q025": 1412.222735543942
        },
        "deepseek-v3-0324": {
            "rating": 1420.8469242736949,
            "rating_q975": 1426.6115995305815,
            "rating_q025": 1415.0822490168082
        },
        "o4-mini-2025-04-16": {
            "rating": 1420.789731638295,
            "rating_q975": 1426.595193212722,
            "rating_q025": 1414.984270063868
        },
        "mai-1-preview": {
            "rating": 1418.9133350217119,
            "rating_q975": 1427.066431872035,
            "rating_q025": 1410.7602381713887
        },
        "mistral-medium-2505": {
            "rating": 1418.3950901933429,
            "rating_q975": 1424.9845926223998,
            "rating_q025": 1411.805587764286
        },
        "gpt-4.1-mini-2025-04-14": {
            "rating": 1417.8405467433383,
            "rating_q975": 1424.0099619838138,
            "rating_q025": 1411.6711315028629
        },
        "claude-3-7-sonnet-20250219-thinking-32k": {
            "rating": 1417.149354254873,
            "rating_q975": 1423.504780625985,
            "rating_q025": 1410.7939278837612
        },
        "gemini-2.5-flash": {
            "rating": 1416.3640401493622,
            "rating_q975": 1421.9481972631584,
            "rating_q025": 1410.779883035566
        },
        "gpt-5-mini-high": {
            "rating": 1414.5362562386981,
            "rating_q975": 1422.1028000846034,
            "rating_q025": 1406.9697123927929
        },
        "qwen3-235b-a22b": {
            "rating": 1414.416820104784,
            "rating_q975": 1421.491351276836,
            "rating_q025": 1407.342288932732
        },
        "glm-4.5-air": {
            "rating": 1412.8406981660353,
            "rating_q975": 1419.5309901820685,
            "rating_q025": 1406.150406150002
        },
        "hunyuan-turbos-20250416": {
            "rating": 1411.5557027228506,
            "rating_q975": 1422.2311700372275,
            "rating_q025": 1400.8802354084737
        },
        "qwen3-next-80b-a3b-thinking": {
            "rating": 1409.9076079235297,
            "rating_q975": 1418.6774334324957,
            "rating_q025": 1401.1377824145636
        },
        "o3-mini-high": {
            "rating": 1408.8561622187513,
            "rating_q975": 1418.0097895269948,
            "rating_q025": 1399.7025349105077
        },
        "claude-3-5-sonnet-20241022": {
            "rating": 1406.795047245309,
            "rating_q975": 1411.2631142686066,
            "rating_q025": 1402.3269802220113
        },
        "hunyuan-t1-20250711": {
            "rating": 1406.1013433835253,
            "rating_q975": 1420.7301377002595,
            "rating_q025": 1391.472549066791
        },
        "o1-preview": {
            "rating": 1405.775185980567,
            "rating_q975": 1413.4644530901683,
            "rating_q025": 1398.0859188709655
        },
        "ling-flash-2.0": {
            "rating": 1404.7838343980156,
            "rating_q975": 1416.3850296668431,
            "rating_q025": 1393.1826391291881
        },
        "minimax-m1": {
            "rating": 1403.2806800568176,
            "rating_q975": 1409.5160569428037,
            "rating_q025": 1397.0453031708314
        },
        "mistral-small-2506": {
            "rating": 1397.9395480272442,
            "rating_q975": 1405.6873827344834,
            "rating_q025": 1390.191713320005
        },
        "qwen3-32b": {
            "rating": 1396.384829994457,
            "rating_q975": 1415.8483118484835,
            "rating_q025": 1376.9213481404306
        },
        "gemini-2.5-flash-lite-preview-09-2025-no-thinking": {
            "rating": 1395.4356181592464,
            "rating_q975": 1404.0523525749625,
            "rating_q025": 1386.8188837435303
        },
        "glm-4.5v": {
            "rating": 1395.2764452801562,
            "rating_q975": 1409.2679567871194,
            "rating_q025": 1381.284933773193
        },
        "qwen2.5-max": {
            "rating": 1394.529022598232,
            "rating_q975": 1401.0959287526703,
            "rating_q025": 1387.9621164437935
        },
        "hunyuan-turbos-20250226": {
            "rating": 1394.2333711900974,
            "rating_q975": 1419.1858941353444,
            "rating_q025": 1369.2808482448504
        },
        "amazon-nova-experimental-chat-10-09": {
            "rating": 1391.897515630029,
            "rating_q975": 1404.3787866318958,
            "rating_q025": 1379.416244628162
        },
        "o3-mini": {
            "rating": 1388.5151088165753,
            "rating_q975": 1393.757035491229,
            "rating_q025": 1383.2731821419216
        },
        "step-3": {
            "rating": 1387.0720711258682,
            "rating_q975": 1399.6845654439626,
            "rating_q025": 1374.4595768077738
        },
        "gemini-2.5-flash-lite-preview-06-17-thinking": {
            "rating": 1386.6774652742174,
            "rating_q975": 1393.2354226061814,
            "rating_q025": 1380.1195079422534
        },
        "llama-3.1-nemotron-ultra-253b-v1": {
            "rating": 1386.0548894965784,
            "rating_q975": 1409.8308148162728,
            "rating_q025": 1362.278964176884
        },
        "deepseek-v3": {
            "rating": 1382.40704094336,
            "rating_q975": 1390.687503439987,
            "rating_q025": 1374.126578446733
        },
        "gpt-oss-120b": {
            "rating": 1380.862175390278,
            "rating_q975": 1387.7864069970947,
            "rating_q025": 1373.9379437834614
        },
        "nvidia-llama-3.3-nemotron-super-49b-v1.5": {
            "rating": 1380.393463777827,
            "rating_q975": 1396.9299044628385,
            "rating_q025": 1363.8570230928156
        },
        "command-a-03-2025": {
            "rating": 1378.3705997126567,
            "rating_q975": 1383.7412726327066,
            "rating_q025": 1372.9999267926069
        },
        "gemma-3-27b-it": {
            "rating": 1377.977778249488,
            "rating_q975": 1383.6278102855704,
            "rating_q025": 1372.3277462134056
        },
        "qwen-plus-0125": {
            "rating": 1377.977680505044,
            "rating_q975": 1393.0595781107475,
            "rating_q025": 1362.8957828993405
        },
        "grok-3-mini-high": {
            "rating": 1377.557727586347,
            "rating_q975": 1385.549408901785,
            "rating_q025": 1369.566046270909
        },
        "grok-3-mini-beta": {
            "rating": 1376.7854521827926,
            "rating_q975": 1384.0887028267725,
            "rating_q025": 1369.4822015388127
        },
        "qwq-32b": {
            "rating": 1375.8551844073233,
            "rating_q975": 1382.910323778231,
            "rating_q025": 1368.8000450364157
        },
        "ring-flash-2.0": {
            "rating": 1373.7708108283155,
            "rating_q975": 1385.3282786191785,
            "rating_q025": 1362.2133430374524
        },
        "claude-3-5-sonnet-20240620": {
            "rating": 1373.1980656362823,
            "rating_q975": 1378.9016525233474,
            "rating_q025": 1367.4944787492173
        },
        "o1-mini": {
            "rating": 1372.9043502230784,
            "rating_q975": 1378.9372178254116,
            "rating_q025": 1366.8714826207452
        },
        "hunyuan-turbo-0110": {
            "rating": 1371.829223320015,
            "rating_q975": 1395.1964716367715,
            "rating_q025": 1348.4619750032584
        },
        "gpt-5-nano-high": {
            "rating": 1371.0839309706196,
            "rating_q975": 1382.372835702451,
            "rating_q025": 1359.795026238788
        },
        "qwen3-30b-a3b": {
            "rating": 1369.8178686826413,
            "rating_q975": 1376.8167374843742,
            "rating_q025": 1362.8189998809084
        },
        "claude-3-5-haiku-20241022": {
            "rating": 1363.9233972008465,
            "rating_q975": 1368.8704284665994,
            "rating_q025": 1358.9763659350936
        },
        "deepseek-v2.5-1210": {
            "rating": 1362.8476414296865,
            "rating_q975": 1376.9801644477736,
            "rating_q025": 1348.7151184115994
        },
        "llama-3.1-405b-instruct-bf16": {
            "rating": 1362.7301923798664,
            "rating_q975": 1368.763846932676,
            "rating_q025": 1356.6965378270568
        },
        "gpt-4.1-nano-2025-04-14": {
            "rating": 1360.2154523667205,
            "rating_q975": 1375.0762452782585,
            "rating_q025": 1345.3546594551824
        },
        "gpt-oss-20b": {
            "rating": 1359.9464197612547,
            "rating_q975": 1369.9862192618252,
            "rating_q025": 1349.9066202606841
        },
        "gpt-4o-2024-05-13": {
            "rating": 1358.6378462119305,
            "rating_q975": 1363.9429539643766,
            "rating_q025": 1353.3327384594845
        },
        "llama-4-maverick-17b-128e-instruct": {
            "rating": 1358.2567067950986,
            "rating_q975": 1364.4680995394478,
            "rating_q025": 1352.0453140507493
        },
        "yi-lightning": {
            "rating": 1357.8971772338589,
            "rating_q975": 1365.9793983259494,
            "rating_q025": 1349.8149561417683
        },
        "hunyuan-large-2025-02-10": {
            "rating": 1355.0774102687428,
            "rating_q975": 1374.8671356124,
            "rating_q025": 1335.2876849250856
        },
        "gemini-1.5-pro-002": {
            "rating": 1354.9427048375803,
            "rating_q975": 1360.5486795754418,
            "rating_q025": 1349.3367300997188
        },
        "llama-3.1-405b-instruct-fp8": {
            "rating": 1354.0615975552896,
            "rating_q975": 1359.9125688170843,
            "rating_q025": 1348.210626293495
        },
        "gemini-2.0-flash-lite-preview-02-05": {
            "rating": 1353.804566840417,
            "rating_q975": 1361.6319573383698,
            "rating_q025": 1345.9771763424642
        },
        "athene-v2-chat": {
            "rating": 1351.4592884752446,
            "rating_q975": 1358.9514315820136,
            "rating_q025": 1343.9671453684757
        },
        "magistral-medium-2506": {
            "rating": 1349.8029282227512,
            "rating_q975": 1359.3988953812166,
            "rating_q025": 1340.206961064286
        },
        "step-1o-turbo-202506": {
            "rating": 1349.787110881573,
            "rating_q975": 1360.8123196972804,
            "rating_q025": 1338.7619020658656
        },
        "llama-4-scout-17b-16e-instruct": {
            "rating": 1349.628790586396,
            "rating_q975": 1356.4904984582213,
            "rating_q025": 1342.7670827145707
        },
        "step-2-16k-exp-202412": {
            "rating": 1349.559647466592,
            "rating_q975": 1365.266702106835,
            "rating_q025": 1333.8525928263489
        },
        "glm-4-plus-0111": {
            "rating": 1349.383238004916,
            "rating_q975": 1364.217368361556,
            "rating_q025": 1334.5491076482758
        },
        "grok-2-2024-08-13": {
            "rating": 1349.0759714396008,
            "rating_q975": 1354.6965185591623,
            "rating_q025": 1343.4554243200394
        },
        "deepseek-v2.5": {
            "rating": 1347.7834428123178,
            "rating_q975": 1355.6359541032923,
            "rating_q025": 1339.9309315213434
        },
        "llama-3.3-nemotron-49b-super-v1": {
            "rating": 1346.2204321118893,
            "rating_q975": 1370.8331851657028,
            "rating_q025": 1321.6076790580757
        },
        "gpt-4o-2024-08-06": {
            "rating": 1345.867300421663,
            "rating_q975": 1352.3659615926738,
            "rating_q025": 1339.3686392506522
        },
        "mistral-small-3.1-24b-instruct-2503": {
            "rating": 1343.4879282335328,
            "rating_q975": 1349.9762050497939,
            "rating_q025": 1336.9996514172717
        },
        "qwen2.5-plus-1127": {
            "rating": 1343.4128752082365,
            "rating_q975": 1354.7369131517567,
            "rating_q025": 1332.0888372647164
        },
        "mistral-large-2407": {
            "rating": 1342.118205980673,
            "rating_q975": 1348.5930992974268,
            "rating_q025": 1335.6433126639195
        },
        "qwen-max-0919": {
            "rating": 1342.0385263967084,
            "rating_q975": 1351.3123397657623,
            "rating_q025": 1332.7647130276546
        },
        "gemini-1.5-pro-001": {
            "rating": 1341.899484174589,
            "rating_q975": 1348.1346811425578,
            "rating_q025": 1335.66428720662
        },
        "qwen2.5-72b-instruct": {
            "rating": 1341.311221145208,
            "rating_q975": 1347.6969370240204,
            "rating_q025": 1334.9255052663957
        },
        "claude-3-opus-20240229": {
            "rating": 1340.2132136510722,
            "rating_q975": 1345.0029651365476,
            "rating_q025": 1335.423462165597
        },
        "gemini-advanced-0514": {
            "rating": 1339.9522925435067,
            "rating_q975": 1347.4010852299223,
            "rating_q025": 1332.5034998570911
        },
        "glm-4-plus": {
            "rating": 1338.8708438914368,
            "rating_q975": 1346.711140232104,
            "rating_q025": 1331.0305475507696
        },
        "llama-3.3-70b-instruct": {
            "rating": 1338.5157879290914,
            "rating_q975": 1343.7372791780604,
            "rating_q025": 1333.2942966801224
        },
        "gpt-4o-mini-2024-07-18": {
            "rating": 1336.3143596364944,
            "rating_q975": 1341.5893802680018,
            "rating_q025": 1331.039339004987
        },
        "gemma-3n-e4b-it": {
            "rating": 1335.618591330008,
            "rating_q975": 1343.419458457539,
            "rating_q025": 1327.8177242024772
        },
        "gpt-4-turbo-2024-04-09": {
            "rating": 1335.3431362556003,
            "rating_q975": 1341.249615580145,
            "rating_q025": 1329.4366569310555
        },
        "gemma-3-12b-it": {
            "rating": 1334.2797960348876,
            "rating_q975": 1353.4288328751961,
            "rating_q025": 1315.130759194579
        },
        "hunyuan-standard-2025-02-10": {
            "rating": 1332.853066685575,
            "rating_q975": 1352.0868798978768,
            "rating_q025": 1313.6192534732731
        },
        "mistral-large-2411": {
            "rating": 1332.1654604240266,
            "rating_q975": 1339.3165138426684,
            "rating_q025": 1325.0144070053848
        },
        "athene-70b-0725": {
            "rating": 1331.6858043875368,
            "rating_q975": 1340.75278761795,
            "rating_q025": 1322.6188211571236
        },
        "grok-2-mini-2024-08-13": {
            "rating": 1328.1088727371352,
            "rating_q975": 1334.0372683883193,
            "rating_q025": 1322.1804770859512
        },
        "amazon-nova-pro-v1.0": {
            "rating": 1327.7921272604847,
            "rating_q975": 1335.206568817282,
            "rating_q025": 1320.3776857036873
        },
        "hunyuan-large-vision": {
            "rating": 1327.0209484776497,
            "rating_q975": 1341.0340752263778,
            "rating_q025": 1313.0078217289215
        },
        "deepseek-coder-v2": {
            "rating": 1324.3221761591717,
            "rating_q975": 1334.2695680395452,
            "rating_q025": 1314.3747842787982
        },
        "gpt-4-1106-preview": {
            "rating": 1323.9074283331352,
            "rating_q975": 1329.9839141240082,
            "rating_q025": 1317.8309425422622
        },
        "llama-3.1-nemotron-70b-instruct": {
            "rating": 1323.3564096431307,
            "rating_q975": 1335.9148875568876,
            "rating_q025": 1310.7979317293739
        },
        "gemini-1.5-flash-002": {
            "rating": 1320.873487181901,
            "rating_q975": 1327.5744684719957,
            "rating_q025": 1314.1725058918064
        },
        "gpt-4-0125-preview": {
            "rating": 1319.2768253144782,
            "rating_q975": 1325.4623557700033,
            "rating_q025": 1313.091294858953
        },
        "qwen2.5-coder-32b-instruct": {
            "rating": 1318.1987763508128,
            "rating_q975": 1333.051287386489,
            "rating_q025": 1303.3462653151364
        },
        "llama-3.1-70b-instruct": {
            "rating": 1317.9524057211129,
            "rating_q975": 1323.820531765954,
            "rating_q025": 1312.0842796762718
        },
        "llama-3.1-nemotron-51b-instruct": {
            "rating": 1309.8168136905483,
            "rating_q975": 1327.5031582920085,
            "rating_q025": 1292.1304690890881
        },
        "gemma-2-27b-it": {
            "rating": 1309.5491026545355,
            "rating_q975": 1314.7587071848468,
            "rating_q025": 1304.3394981242243
        },
        "jamba-1.5-large": {
            "rating": 1308.9417971060188,
            "rating_q975": 1320.9833759106898,
            "rating_q025": 1296.9002183013479
        },
        "claude-3-sonnet-20240229": {
            "rating": 1306.525636517552,
            "rating_q975": 1312.4855520588544,
            "rating_q025": 1300.5657209762494
        },
        "gemini-1.5-flash-001": {
            "rating": 1305.2292829596113,
            "rating_q975": 1311.6751783947618,
            "rating_q025": 1298.7833875244607
        },
        "gpt-4-0314": {
            "rating": 1304.6289651471488,
            "rating_q975": 1312.3510241530682,
            "rating_q025": 1296.9069061412295
        },
        "mistral-small-24b-instruct-2501": {
            "rating": 1304.10116123596,
            "rating_q975": 1313.9796928789763,
            "rating_q025": 1294.2226295929438
        },
        "reka-core-20240904": {
            "rating": 1299.956039443094,
            "rating_q975": 1312.4929209418428,
            "rating_q025": 1287.419157944345
        },
        "gemma-3-4b-it": {
            "rating": 1299.7288993879256,
            "rating_q975": 1318.4352258803644,
            "rating_q025": 1281.0225728954867
        },
        "nemotron-4-340b-instruct": {
            "rating": 1299.344691175532,
            "rating_q975": 1308.4627691156402,
            "rating_q025": 1290.2266132354239
        },
        "llama-3.1-tulu-3-70b": {
            "rating": 1297.6799985503135,
            "rating_q975": 1317.5466009086633,
            "rating_q025": 1277.8133961919636
        },
        "glm-4-0520": {
            "rating": 1295.441917256318,
            "rating_q975": 1306.8969398927609,
            "rating_q025": 1283.986894619875
        },
        "amazon-nova-lite-v1.0": {
            "rating": 1294.2641435045148,
            "rating_q975": 1302.7314879794808,
            "rating_q025": 1285.7967990295488
        },
        "c4ai-aya-expanse-32b": {
            "rating": 1289.5797968163142,
            "rating_q975": 1297.1696725645913,
            "rating_q025": 1281.9899210680371
        },
        "llama-3-70b-instruct": {
            "rating": 1289.4918352539435,
            "rating_q975": 1295.1943100172105,
            "rating_q025": 1283.7893604906765
        },
        "phi-4": {
            "rating": 1288.627016516245,
            "rating_q975": 1296.6182369525466,
            "rating_q025": 1280.6357960799435
        },
        "gpt-4-0613": {
            "rating": 1285.5615608226594,
            "rating_q975": 1292.0997455194747,
            "rating_q025": 1279.0233761258442
        },
        "reka-flash-20240904": {
            "rating": 1285.1583639330875,
            "rating_q975": 1297.6002828196386,
            "rating_q025": 1272.7164450465364
        },
        "claude-3-haiku-20240307": {
            "rating": 1284.80334139559,
            "rating_q975": 1290.5165831935647,
            "rating_q025": 1279.0900995976153
        },
        "gemma-2-9b-it-simpo": {
            "rating": 1281.6912625438667,
            "rating_q975": 1293.5957122166938,
            "rating_q025": 1269.7868128710397
        },
        "qwen2-72b-instruct": {
            "rating": 1280.7699337360496,
            "rating_q975": 1288.1752661211253,
            "rating_q025": 1273.3646013509738
        },
        "gemma-2-9b-it": {
            "rating": 1280.2195782939993,
            "rating_q975": 1286.1030129473286,
            "rating_q025": 1274.3361436406701
        },
        "hunyuan-standard-256k": {
            "rating": 1275.6134640200341,
            "rating_q975": 1296.3992318572712,
            "rating_q025": 1254.8276961827971
        },
        "ministral-8b-2410": {
            "rating": 1275.2786363768041,
            "rating_q975": 1290.924672513155,
            "rating_q025": 1259.6326002404533
        },
        "gemini-1.5-flash-8b-001": {
            "rating": 1273.3873448838795,
            "rating_q975": 1280.1699576557069,
            "rating_q025": 1266.604732112052
        },
        "command-r-plus-08-2024": {
            "rating": 1272.646747906776,
            "rating_q975": 1283.643840342843,
            "rating_q025": 1261.649655470709
        },
        "command-r-plus": {
            "rating": 1270.4205682923916,
            "rating_q975": 1276.8492524455428,
            "rating_q025": 1263.9918841392405
        },
        "mistral-large-2402": {
            "rating": 1270.0853666907499,
            "rating_q975": 1277.2290233274352,
            "rating_q025": 1262.9417100540645
        },
        "amazon-nova-micro-v1.0": {
            "rating": 1269.9551931450774,
            "rating_q975": 1278.5351253492945,
            "rating_q025": 1261.3752609408602
        },
        "olmo-2-0325-32b-instruct": {
            "rating": 1268.6334862704025,
            "rating_q975": 1289.974602867667,
            "rating_q025": 1247.292369673138
        },
        "command-r-08-2024": {
            "rating": 1267.392001261262,
            "rating_q975": 1278.3913966065459,
            "rating_q025": 1256.3926059159783
        },
        "reka-flash-21b-20240226-online": {
            "rating": 1263.56712824316,
            "rating_q975": 1274.3875401048922,
            "rating_q025": 1252.7467163814276
        },
        "jamba-1.5-mini": {
            "rating": 1263.1298557448763,
            "rating_q975": 1275.5486280448424,
            "rating_q025": 1250.7110834449102
        },
        "qwen1.5-110b-chat": {
            "rating": 1259.090584090769,
            "rating_q975": 1267.882083438942,
            "rating_q025": 1250.299084742596
        },
        "qwen1.5-72b-chat": {
            "rating": 1256.776016052272,
            "rating_q975": 1264.9132550545137,
            "rating_q025": 1248.6387770500305
        },
        "mixtral-8x22b-instruct-v0.1": {
            "rating": 1254.2695168946198,
            "rating_q975": 1261.4705435341941,
            "rating_q025": 1247.0684902550454
        },
        "reka-flash-21b-20240226": {
            "rating": 1252.9071263793005,
            "rating_q975": 1261.870153558458,
            "rating_q025": 1243.944099200143
        },
        "granite-3.1-8b-instruct": {
            "rating": 1250.5605514338563,
            "rating_q975": 1271.192824495129,
            "rating_q025": 1229.9282783725837
        },
        "c4ai-aya-expanse-8b": {
            "rating": 1250.1437505120584,
            "rating_q975": 1261.981846908854,
            "rating_q025": 1238.3056541152628
        },
        "gemini-pro-dev-api": {
            "rating": 1247.2504689999676,
            "rating_q975": 1258.7830031837868,
            "rating_q025": 1235.7179348161483
        },
        "gpt-3.5-turbo-0125": {
            "rating": 1245.4493711234027,
            "rating_q975": 1252.3415200938596,
            "rating_q025": 1238.5572221529458
        },
        "llama-3.1-8b-instruct": {
            "rating": 1243.5526760487737,
            "rating_q975": 1249.8943246589743,
            "rating_q025": 1237.2110274385732
        },
        "llama-3-8b-instruct": {
            "rating": 1243.0109367464029,
            "rating_q975": 1249.3178570702858,
            "rating_q025": 1236.70401642252
        },
        "llama-3.1-tulu-3-8b": {
            "rating": 1242.9572478905848,
            "rating_q975": 1263.0063992929001,
            "rating_q025": 1222.9080964882694
        },
        "mistral-medium": {
            "rating": 1242.6975424626805,
            "rating_q975": 1251.5243346711038,
            "rating_q025": 1233.8707502542572
        },
        "qwen1.5-32b-chat": {
            "rating": 1241.8574322253608,
            "rating_q975": 1251.1904550746835,
            "rating_q025": 1232.524409376038
        },
        "command-r": {
            "rating": 1239.6430073127967,
            "rating_q975": 1246.9457040365064,
            "rating_q025": 1232.340310589087
        },
        "yi-1.5-34b-chat": {
            "rating": 1237.2035423655236,
            "rating_q975": 1245.77617216879,
            "rating_q025": 1228.6309125622572
        },
        "zephyr-orpo-141b-A35b-v0.1": {
            "rating": 1234.8118158927064,
            "rating_q975": 1251.5585591675028,
            "rating_q025": 1218.06507261791
        },
        "internlm2_5-20b-chat": {
            "rating": 1233.319992271322,
            "rating_q975": 1245.0995592826937,
            "rating_q025": 1221.5404252599503
        },
        "qwen1.5-14b-chat": {
            "rating": 1230.9965810371832,
            "rating_q975": 1241.7825113071488,
            "rating_q025": 1220.2106507672177
        },
        "gpt-3.5-turbo-1106": {
            "rating": 1228.0991221195843,
            "rating_q975": 1241.2073179910444,
            "rating_q025": 1214.9909262481242
        },
        "gemini-pro": {
            "rating": 1227.494555166754,
            "rating_q975": 1246.5634848250536,
            "rating_q025": 1208.4256255084545
        },
        "mixtral-8x7b-instruct-v0.1": {
            "rating": 1224.9356002971294,
            "rating_q975": 1231.7105826166046,
            "rating_q025": 1218.1606179776543
        },
        "dbrx-instruct-preview": {
            "rating": 1224.5289011408263,
            "rating_q975": 1233.7392799511772,
            "rating_q025": 1215.3185223304754
        },
        "granite-3.1-2b-instruct": {
            "rating": 1223.6428036685766,
            "rating_q975": 1243.9280206443202,
            "rating_q025": 1203.357586692833
        },
        "phi-3-medium-4k-instruct": {
            "rating": 1220.8865611411743,
            "rating_q975": 1229.2601704191522,
            "rating_q025": 1212.5129518631963
        },
        "granite-3.0-8b-instruct": {
            "rating": 1218.740295150645,
            "rating_q975": 1233.5314029153756,
            "rating_q025": 1203.9491873859142
        },
        "starling-lm-7b-beta": {
            "rating": 1217.3171009760347,
            "rating_q975": 1228.2669071088665,
            "rating_q025": 1206.367294843203
        },
        "gemma-1.1-7b-it": {
            "rating": 1213.474513259763,
            "rating_q975": 1222.1350351145888,
            "rating_q025": 1204.813991404937
        },
        "openchat-3.5-0106": {
            "rating": 1210.84494364158,
            "rating_q975": 1222.5579791882099,
            "rating_q025": 1199.13190809495
        },
        "deepseek-llm-67b-chat": {
            "rating": 1205.9051264478303,
            "rating_q975": 1224.525063833673,
            "rating_q025": 1187.2851890619877
        },
        "snowflake-arctic-instruct": {
            "rating": 1205.6981555773996,
            "rating_q975": 1215.3439056217737,
            "rating_q025": 1196.0524055330254
        },
        "yi-34b-chat": {
            "rating": 1204.6080012897535,
            "rating_q975": 1215.2551406387213,
            "rating_q025": 1193.9608619407857
        },
        "openchat-3.5": {
            "rating": 1200.0887457828785,
            "rating_q975": 1215.6299069011707,
            "rating_q025": 1184.5475846645863
        },
        "gemma-2-2b-it": {
            "rating": 1199.032220959981,
            "rating_q975": 1205.5753027686194,
            "rating_q025": 1192.4891391513427
        },
        "phi-3-small-8k-instruct": {
            "rating": 1198.243773252237,
            "rating_q975": 1208.0404811022663,
            "rating_q025": 1188.4470654022075
        },
        "tulu-2-dpo-70b": {
            "rating": 1197.497436748254,
            "rating_q975": 1214.1686423278184,
            "rating_q025": 1180.8262311686894
        },
        "vicuna-33b": {
            "rating": 1188.3071773560787,
            "rating_q975": 1198.3784512355062,
            "rating_q025": 1178.2359034766512
        },
        "openhermes-2.5-mistral-7b": {
            "rating": 1187.6146744158254,
            "rating_q975": 1205.0980398104236,
            "rating_q025": 1170.1313090212273
        },
        "wizardlm-70b": {
            "rating": 1186.6733147745083,
            "rating_q975": 1202.0350069044111,
            "rating_q025": 1171.3116226446054
        },
        "granite-3.0-2b-instruct": {
            "rating": 1185.81696276427,
            "rating_q975": 1200.2317092814671,
            "rating_q025": 1171.402216247073
        },
        "starling-lm-7b-alpha": {
            "rating": 1185.5712387092772,
            "rating_q975": 1198.6360387911004,
            "rating_q025": 1172.506438627454
        },
        "llama-2-70b-chat": {
            "rating": 1182.9387822788242,
            "rating_q975": 1191.1684767238473,
            "rating_q025": 1174.709087833801
        },
        "qwen1.5-7b-chat": {
            "rating": 1180.0121048427043,
            "rating_q975": 1196.5715481230372,
            "rating_q025": 1163.4526615623713
        },
        "phi-3-mini-4k-instruct-june-2024": {
            "rating": 1179.3495047798183,
            "rating_q975": 1190.6708049990866,
            "rating_q025": 1168.02820456055
        },
        "nous-hermes-2-mixtral-8x7b-dpo": {
            "rating": 1179.0633171193003,
            "rating_q975": 1197.7619681818262,
            "rating_q025": 1160.3646660567745
        },
        "mistral-7b-instruct-v0.2": {
            "rating": 1176.543060293791,
            "rating_q975": 1186.5163941301057,
            "rating_q025": 1166.5697264574765
        },
        "llama-3.2-3b-instruct": {
            "rating": 1173.3067744534358,
            "rating_q975": 1186.4923466310308,
            "rating_q025": 1160.1212022758407
        },
        "qwen-14b-chat": {
            "rating": 1171.1189095477816,
            "rating_q975": 1189.4735423452955,
            "rating_q025": 1152.7642767502678
        },
        "solar-10.7b-instruct-v1.0": {
            "rating": 1169.7419765572813,
            "rating_q975": 1190.5514057555251,
            "rating_q025": 1148.9325473590375
        },
        "mpt-30b-chat": {
            "rating": 1168.7409749134601,
            "rating_q975": 1193.5628324577606,
            "rating_q025": 1143.9191173691597
        },
        "gemma-7b-it": {
            "rating": 1165.7524615551279,
            "rating_q975": 1179.626873390421,
            "rating_q025": 1151.8780497198347
        },
        "qwq-32b-preview": {
            "rating": 1165.6612060789644,
            "rating_q975": 1186.4269109922027,
            "rating_q025": 1144.895501165726
        },
        "phi-3-mini-4k-instruct": {
            "rating": 1162.815979112033,
            "rating_q975": 1172.63805652847,
            "rating_q025": 1152.9939016955957
        },
        "codellama-70b-instruct": {
            "rating": 1161.7925161688113,
            "rating_q975": 1193.6382995956033,
            "rating_q025": 1129.9467327420193
        },
        "vicuna-13b": {
            "rating": 1161.7231871223712,
            "rating_q975": 1172.403728043196,
            "rating_q025": 1151.0426462015464
        },
        "codellama-34b-instruct": {
            "rating": 1161.4392571373323,
            "rating_q975": 1176.4256480368535,
            "rating_q025": 1146.4528662378111
        },
        "zephyr-7b-alpha": {
            "rating": 1158.775608041762,
            "rating_q975": 1187.6510378162598,
            "rating_q025": 1129.9001782672644
        },
        "llama2-70b-steerlm-chat": {
            "rating": 1157.4818487351465,
            "rating_q975": 1178.098350940087,
            "rating_q025": 1136.8653465302061
        },
        "wizardlm-13b": {
            "rating": 1157.3509852547195,
            "rating_q975": 1173.303035180164,
            "rating_q025": 1141.398935329275
        },
        "llama-2-13b-chat": {
            "rating": 1156.319785402562,
            "rating_q975": 1166.581130689353,
            "rating_q025": 1146.0584401157712
        },
        "gemma-1.1-2b-it": {
            "rating": 1155.9460100720087,
            "rating_q975": 1167.8026015782725,
            "rating_q025": 1144.0894185657448
        },
        "dolphin-2.2.1-mistral-7b": {
            "rating": 1154.3040574524846,
            "rating_q975": 1182.7802014067136,
            "rating_q025": 1125.8279134982556
        },
        "falcon-180b-chat": {
            "rating": 1149.2692504435418,
            "rating_q975": 1182.3393907250456,
            "rating_q025": 1116.1991101620379
        },
        "smollm2-1.7b-instruct": {
            "rating": 1145.8759701360982,
            "rating_q975": 1172.5298616742648,
            "rating_q025": 1119.2220785979316
        },
        "zephyr-7b-beta": {
            "rating": 1143.9980547829887,
            "rating_q975": 1158.208863495988,
            "rating_q025": 1129.7872460699894
        },
        "palm-2": {
            "rating": 1142.4572132261137,
            "rating_q975": 1157.6646513806045,
            "rating_q025": 1127.249775071623
        },
        "phi-3-mini-128k-instruct": {
            "rating": 1141.2365663419596,
            "rating_q975": 1152.561865084261,
            "rating_q025": 1129.9112675996582
        },
        "stripedhyena-nous-7b": {
            "rating": 1137.1904975075236,
            "rating_q975": 1154.9626066324909,
            "rating_q025": 1119.4183883825563
        },
        "vicuna-7b": {
            "rating": 1130.8758423372524,
            "rating_q975": 1147.2794604180306,
            "rating_q025": 1114.4722242564742
        },
        "mistral-7b-instruct": {
            "rating": 1130.7569827934071,
            "rating_q975": 1146.6752784147268,
            "rating_q025": 1114.8386871720875
        },
        "gemma-2b-it": {
            "rating": 1130.0934483221517,
            "rating_q975": 1147.8980721016487,
            "rating_q025": 1112.2888245426548
        },
        "llama-3.2-1b-instruct": {
            "rating": 1126.06326114796,
            "rating_q975": 1139.6681345153954,
            "rating_q025": 1112.4583877805246
        },
        "qwen1.5-4b-chat": {
            "rating": 1118.2918599800698,
            "rating_q975": 1132.848837076147,
            "rating_q025": 1103.7348828839927
        },
        "guanaco-33b": {
            "rating": 1116.5866335484443,
            "rating_q975": 1140.5505920862022,
            "rating_q025": 1092.6226750106864
        },
        "olmo-7b-instruct": {
            "rating": 1115.8658672826264,
            "rating_q975": 1133.3844781901328,
            "rating_q025": 1098.34725637512
        },
        "llama-2-7b-chat": {
            "rating": 1111.8841161519435,
            "rating_q975": 1122.8308098374132,
            "rating_q025": 1100.937422466474
        },
        "chatglm3-6b": {
            "rating": 1086.1053867727942,
            "rating_q975": 1106.5168039045573,
            "rating_q025": 1065.6939696410311
        },
        "gpt4all-13b-snoozy": {
            "rating": 1074.8340181516764,
            "rating_q975": 1104.495815669103,
            "rating_q025": 1045.17222063425
        },
        "koala-13b": {
            "rating": 1072.993070426167,
            "rating_q975": 1091.2220692405883,
            "rating_q025": 1054.7640716117455
        },
        "mpt-7b-chat": {
            "rating": 1055.8807467135075,
            "rating_q975": 1077.829505446682,
            "rating_q025": 1033.931987980333
        },
        "RWKV-4-Raven-14B": {
            "rating": 1039.478033854868,
            "rating_q975": 1059.4758742790648,
            "rating_q025": 1019.4801934306713
        },
        "chatglm2-6b": {
            "rating": 1032.895672239656,
            "rating_q975": 1057.7653026327748,
            "rating_q025": 1008.0260418465373
        },
        "oasst-pythia-12b": {
            "rating": 1019.0596050918816,
            "rating_q975": 1038.193375080586,
            "rating_q025": 999.9258351031773
        },
        "alpaca-13b": {
            "rating": 1007.9903839072643,
            "rating_q975": 1027.979360384293,
            "rating_q025": 988.0014074302359
        },
        "chatglm-6b": {
            "rating": 996.6356757145405,
            "rating_q975": 1016.9214923265291,
            "rating_q025": 976.3498591025519
        },
        "stablelm-tuned-alpha-7b": {
            "rating": 968.9263215032041,
            "rating_q975": 993.1204745849946,
            "rating_q025": 944.7321684214137
        },
        "fastchat-t5-3b": {
            "rating": 967.9224016185883,
            "rating_q975": 988.8206141924346,
            "rating_q025": 947.024189044742
        },
        "dolly-v2-12b": {
            "rating": 963.012847478489,
            "rating_q975": 987.1047271815935,
            "rating_q025": 938.9209677753845
        },
        "llama-13b": {
            "rating": 902.1147351167954,
            "rating_q975": 931.7858193825406,
            "rating_q025": 872.4436508510502
        }
    },
    "industry_writing_and_literature_and_language": {
        "gemini-2.5-pro": {
            "rating": 1454.1234901954458,
            "rating_q975": 1460.7072174392931,
            "rating_q025": 1447.5397629515985
        },
        "gpt-4.5-preview-2025-02-27": {
            "rating": 1442.9242340654775,
            "rating_q975": 1452.4361777955369,
            "rating_q025": 1433.4122903354182
        },
        "claude-opus-4-1-20250805-thinking-16k": {
            "rating": 1440.0827862409842,
            "rating_q975": 1448.2730128180212,
            "rating_q025": 1431.8925596639472
        },
        "claude-sonnet-4-5-20250929-thinking-32k": {
            "rating": 1438.0121491913876,
            "rating_q975": 1449.590464420127,
            "rating_q025": 1426.4338339626481
        },
        "claude-sonnet-4-5-20250929": {
            "rating": 1437.440039515593,
            "rating_q975": 1452.9847691740297,
            "rating_q025": 1421.8953098571565
        },
        "claude-opus-4-1-20250805": {
            "rating": 1434.5018999253728,
            "rating_q975": 1441.7418160736015,
            "rating_q025": 1427.261983777144
        },
        "chatgpt-4o-latest-20250326": {
            "rating": 1425.3433430250557,
            "rating_q975": 1431.7918034879006,
            "rating_q025": 1418.8948825622108
        },
        "claude-opus-4-20250514-thinking-16k": {
            "rating": 1423.0449424524,
            "rating_q975": 1430.310923911308,
            "rating_q025": 1415.7789609934919
        },
        "claude-opus-4-20250514": {
            "rating": 1413.9876640836583,
            "rating_q975": 1420.8584450140327,
            "rating_q025": 1407.1168831532839
        },
        "glm-4.6": {
            "rating": 1409.6909835406598,
            "rating_q975": 1422.3816214572757,
            "rating_q025": 1397.0003456240438
        },
        "deepseek-v3.1-thinking": {
            "rating": 1407.4554712002623,
            "rating_q975": 1418.7348093717108,
            "rating_q025": 1396.1761330288139
        },
        "qwen3-max-2025-09-23": {
            "rating": 1406.2398281127548,
            "rating_q975": 1419.2624897550515,
            "rating_q025": 1393.217166470458
        },
        "qwen3-max-preview": {
            "rating": 1406.0835174576277,
            "rating_q975": 1414.5227311585115,
            "rating_q025": 1397.644303756744
        },
        "deepseek-v3.1-terminus": {
            "rating": 1404.784578948699,
            "rating_q975": 1425.4830208434075,
            "rating_q025": 1384.0861370539903
        },
        "gemini-2.5-flash": {
            "rating": 1404.142007070052,
            "rating_q975": 1410.4021517530753,
            "rating_q025": 1397.8818623870286
        },
        "grok-3-preview-02-24": {
            "rating": 1403.4978973961433,
            "rating_q975": 1410.562185617681,
            "rating_q025": 1396.4336091746056
        },
        "gpt-5-chat": {
            "rating": 1403.1559049920875,
            "rating_q975": 1411.2314613796962,
            "rating_q025": 1395.0803486044788
        },
        "gpt-5-high": {
            "rating": 1401.638491634414,
            "rating_q975": 1409.707868446424,
            "rating_q025": 1393.5691148224041
        },
        "deepseek-v3.1-terminus-thinking": {
            "rating": 1400.6356189632131,
            "rating_q975": 1421.7631289746084,
            "rating_q025": 1379.5081089518178
        },
        "gpt-4.1-2025-04-14": {
            "rating": 1398.7259595021173,
            "rating_q975": 1405.1416495859464,
            "rating_q025": 1392.3102694182883
        },
        "grok-4-0709": {
            "rating": 1398.4605416240227,
            "rating_q975": 1405.779715853847,
            "rating_q025": 1391.1413673941984
        },
        "deepseek-v3.1": {
            "rating": 1396.6102256154602,
            "rating_q975": 1406.7985964244065,
            "rating_q025": 1386.421854806514
        },
        "o3-2025-04-16": {
            "rating": 1396.184750214217,
            "rating_q975": 1402.361266009695,
            "rating_q025": 1390.008234418739
        },
        "gemini-2.5-flash-preview-09-2025": {
            "rating": 1396.003877110135,
            "rating_q975": 1407.1597963460777,
            "rating_q025": 1384.8479578741922
        },
        "claude-sonnet-4-20250514-thinking-32k": {
            "rating": 1394.5072553859786,
            "rating_q975": 1401.7961259397678,
            "rating_q025": 1387.2183848321895
        },
        "o1-2024-12-17": {
            "rating": 1394.3826636860795,
            "rating_q975": 1401.4120655995537,
            "rating_q025": 1387.3532617726053
        },
        "deepseek-v3.2-exp-thinking": {
            "rating": 1394.2234439700494,
            "rating_q975": 1407.2277894646606,
            "rating_q025": 1381.2190984754382
        },
        "grok-4-fast": {
            "rating": 1393.5666379054471,
            "rating_q975": 1408.281175987989,
            "rating_q025": 1378.8520998229053
        },
        "claude-haiku-4-5-20251001": {
            "rating": 1392.6815665785398,
            "rating_q975": 1405.6002546025748,
            "rating_q025": 1379.7628785545048
        },
        "qwen3-235b-a22b-instruct-2507": {
            "rating": 1390.4012371342426,
            "rating_q975": 1397.717658563661,
            "rating_q025": 1383.0848157048242
        },
        "deepseek-r1-0528": {
            "rating": 1388.7476707550636,
            "rating_q975": 1398.1786435061217,
            "rating_q025": 1379.3166980040055
        },
        "claude-3-7-sonnet-20250219-thinking-32k": {
            "rating": 1387.5842264118924,
            "rating_q975": 1394.2899597618105,
            "rating_q025": 1380.8784930619743
        },
        "qwen3-vl-235b-a22b-instruct": {
            "rating": 1385.617755399612,
            "rating_q975": 1399.2067163227266,
            "rating_q025": 1372.0287944764973
        },
        "claude-sonnet-4-20250514": {
            "rating": 1383.4762266604666,
            "rating_q975": 1390.4753841330564,
            "rating_q025": 1376.4770691878769
        },
        "deepseek-v3-0324": {
            "rating": 1382.6170148937285,
            "rating_q975": 1389.0402124585778,
            "rating_q025": 1376.1938173288793
        },
        "glm-4.5": {
            "rating": 1381.2528706372245,
            "rating_q975": 1389.7265471859628,
            "rating_q025": 1372.7791940884863
        },
        "deepseek-r1": {
            "rating": 1379.1186007694125,
            "rating_q975": 1387.1697888199737,
            "rating_q025": 1371.0674127188513
        },
        "mistral-medium-2508": {
            "rating": 1378.276926533801,
            "rating_q975": 1386.2232172513618,
            "rating_q025": 1370.3306358162404
        },
        "o1-preview": {
            "rating": 1377.9254588560689,
            "rating_q975": 1385.635926234291,
            "rating_q025": 1370.2149914778468
        },
        "kimi-k2-0905-preview": {
            "rating": 1376.7133352278354,
            "rating_q975": 1388.8821963754926,
            "rating_q025": 1364.5444740801781
        },
        "gemini-2.5-flash-lite-preview-09-2025-no-thinking": {
            "rating": 1376.2096046024326,
            "rating_q975": 1387.1486009834741,
            "rating_q025": 1365.270608221391
        },
        "qwen3-235b-a22b-thinking-2507": {
            "rating": 1376.0104921546465,
            "rating_q975": 1389.3287362284711,
            "rating_q025": 1362.6922480808219
        },
        "gemini-2.5-flash-lite-preview-06-17-thinking": {
            "rating": 1375.8593371210093,
            "rating_q975": 1383.32864852751,
            "rating_q025": 1368.3900257145085
        },
        "qwen3-235b-a22b-no-thinking": {
            "rating": 1373.7944260018112,
            "rating_q975": 1380.924219895034,
            "rating_q025": 1366.6646321085884
        },
        "claude-3-5-sonnet-20241022": {
            "rating": 1372.3622248348736,
            "rating_q975": 1377.0259374429324,
            "rating_q025": 1367.6985122268147
        },
        "kimi-k2-0711-preview": {
            "rating": 1371.771769035024,
            "rating_q975": 1379.7595279238815,
            "rating_q025": 1363.7840101461663
        },
        "hunyuan-t1-20250711": {
            "rating": 1368.6350113224346,
            "rating_q975": 1386.8226915952769,
            "rating_q025": 1350.4473310495923
        },
        "mistral-medium-2505": {
            "rating": 1365.8076382821182,
            "rating_q975": 1373.2874205985067,
            "rating_q025": 1358.3278559657297
        },
        "qwen3-coder-480b-a35b-instruct": {
            "rating": 1363.1743663246962,
            "rating_q975": 1371.7022473720306,
            "rating_q025": 1354.6464852773618
        },
        "qwen3-vl-235b-a22b-thinking": {
            "rating": 1362.7136213140031,
            "rating_q975": 1376.8517404972283,
            "rating_q025": 1348.575502130778
        },
        "mai-1-preview": {
            "rating": 1359.8717572320106,
            "rating_q975": 1369.4833749556522,
            "rating_q025": 1350.260139508369
        },
        "qwen2.5-max": {
            "rating": 1359.689284456512,
            "rating_q975": 1366.289971265642,
            "rating_q025": 1353.0885976473821
        },
        "gpt-4.1-mini-2025-04-14": {
            "rating": 1356.1918342043487,
            "rating_q975": 1363.1233813298204,
            "rating_q025": 1349.260287078877
        },
        "gpt-5-mini-high": {
            "rating": 1355.4895373464092,
            "rating_q975": 1364.080742824609,
            "rating_q025": 1346.8983318682094
        },
        "hunyuan-turbos-20250416": {
            "rating": 1354.867681999382,
            "rating_q975": 1366.2936866302368,
            "rating_q025": 1343.4416773685273
        },
        "o4-mini-2025-04-16": {
            "rating": 1353.236304395776,
            "rating_q975": 1359.7273576975626,
            "rating_q025": 1346.7452510939893
        },
        "deepseek-v3": {
            "rating": 1353.0846830508833,
            "rating_q975": 1361.017631761894,
            "rating_q025": 1345.1517343398725
        },
        "longcat-flash-chat": {
            "rating": 1352.523583137965,
            "rating_q975": 1364.2847498646358,
            "rating_q025": 1340.7624164112942
        },
        "gemma-3-27b-it": {
            "rating": 1351.7526219759325,
            "rating_q975": 1357.8387103616678,
            "rating_q025": 1345.666533590197
        },
        "gemini-1.5-pro-002": {
            "rating": 1351.7161390233277,
            "rating_q975": 1357.2983828669342,
            "rating_q025": 1346.1338951797213
        },
        "qwen3-235b-a22b": {
            "rating": 1345.6680337342043,
            "rating_q975": 1353.4744744283216,
            "rating_q025": 1337.861593040087
        },
        "grok-3-mini-high": {
            "rating": 1344.774103311406,
            "rating_q975": 1354.5536052250163,
            "rating_q025": 1334.9946013977956
        },
        "gemini-2.0-flash-lite-preview-02-05": {
            "rating": 1344.3544378338493,
            "rating_q975": 1351.5363009944974,
            "rating_q025": 1337.172574673201
        },
        "command-a-03-2025": {
            "rating": 1343.5051144735528,
            "rating_q975": 1349.465652079576,
            "rating_q025": 1337.5445768675295
        },
        "qwen3-next-80b-a3b-instruct": {
            "rating": 1341.3090614580763,
            "rating_q975": 1350.6090214441606,
            "rating_q025": 1332.009101471992
        },
        "qwen3-30b-a3b-instruct-2507": {
            "rating": 1341.2668898251331,
            "rating_q975": 1349.8161514140972,
            "rating_q025": 1332.717628236169
        },
        "gpt-4o-2024-05-13": {
            "rating": 1341.0524073183497,
            "rating_q975": 1346.5659043583214,
            "rating_q025": 1335.538910278378
        },
        "grok-3-mini-beta": {
            "rating": 1340.6171196379944,
            "rating_q975": 1349.1952984867921,
            "rating_q025": 1332.0389407891967
        },
        "glm-4.5-air": {
            "rating": 1338.4989130512172,
            "rating_q975": 1346.3853717313946,
            "rating_q025": 1330.6124543710398
        },
        "o3-mini-high": {
            "rating": 1338.0860596879443,
            "rating_q975": 1346.7298073856743,
            "rating_q025": 1329.4423119902142
        },
        "gpt-4o-2024-08-06": {
            "rating": 1337.1556647768905,
            "rating_q975": 1343.737573022523,
            "rating_q025": 1330.573756531258
        },
        "gemini-advanced-0514": {
            "rating": 1335.5126976623578,
            "rating_q975": 1343.132765493484,
            "rating_q025": 1327.8926298312317
        },
        "qwen3-next-80b-a3b-thinking": {
            "rating": 1332.6807416611787,
            "rating_q975": 1343.486975629332,
            "rating_q025": 1321.8745076930254
        },
        "minimax-m1": {
            "rating": 1332.3141163730418,
            "rating_q975": 1339.398100312966,
            "rating_q025": 1325.2301324331174
        },
        "glm-4-plus-0111": {
            "rating": 1330.8054805741938,
            "rating_q975": 1345.8664915604325,
            "rating_q025": 1315.744469587955
        },
        "gemini-1.5-pro-001": {
            "rating": 1329.9825340037223,
            "rating_q975": 1336.4317175579124,
            "rating_q025": 1323.5333504495322
        },
        "hunyuan-turbos-20250226": {
            "rating": 1328.351630020276,
            "rating_q975": 1349.304534231658,
            "rating_q025": 1307.398725808894
        },
        "claude-3-5-sonnet-20240620": {
            "rating": 1327.5274654729258,
            "rating_q975": 1333.3180511361431,
            "rating_q025": 1321.7368798097084
        },
        "gpt-4-turbo-2024-04-09": {
            "rating": 1326.4225811404754,
            "rating_q975": 1332.5517437018873,
            "rating_q025": 1320.2934185790634
        },
        "mistral-small-2506": {
            "rating": 1326.1056426781274,
            "rating_q975": 1335.5779971191957,
            "rating_q025": 1316.633288237059
        },
        "grok-2-2024-08-13": {
            "rating": 1323.6279968480203,
            "rating_q975": 1329.2204072170148,
            "rating_q025": 1318.0355864790258
        },
        "o3-mini": {
            "rating": 1322.1436494889483,
            "rating_q975": 1327.6457232125358,
            "rating_q025": 1316.6415757653608
        },
        "hunyuan-turbo-0110": {
            "rating": 1319.598993702924,
            "rating_q975": 1339.5388361955504,
            "rating_q025": 1299.6591512102975
        },
        "qwen-plus-0125": {
            "rating": 1318.219329385261,
            "rating_q975": 1332.8511023714518,
            "rating_q025": 1303.5875563990703
        },
        "llama-3.1-nemotron-ultra-253b-v1": {
            "rating": 1317.9184978677854,
            "rating_q975": 1338.9103945298489,
            "rating_q025": 1296.926601205722
        },
        "step-2-16k-exp-202412": {
            "rating": 1316.6883103385048,
            "rating_q975": 1332.137890139303,
            "rating_q025": 1301.2387305377067
        },
        "amazon-nova-experimental-chat-10-09": {
            "rating": 1316.013463400187,
            "rating_q975": 1331.9382637981716,
            "rating_q025": 1300.0886630022023
        },
        "glm-4.5v": {
            "rating": 1315.2569651085873,
            "rating_q975": 1332.9849402716213,
            "rating_q025": 1297.5289899455533
        },
        "claude-3-opus-20240229": {
            "rating": 1312.9313332387082,
            "rating_q975": 1317.8240457546603,
            "rating_q025": 1308.0386207227561
        },
        "llama-3.1-405b-instruct-fp8": {
            "rating": 1312.4853046610372,
            "rating_q975": 1318.3675792894635,
            "rating_q025": 1306.6030300326108
        },
        "step-3": {
            "rating": 1311.9084766886851,
            "rating_q975": 1327.0277215332326,
            "rating_q025": 1296.7892318441377
        },
        "gemma-3-12b-it": {
            "rating": 1311.8283392628168,
            "rating_q975": 1329.5975206283115,
            "rating_q025": 1294.0591578973222
        },
        "deepseek-v2.5-1210": {
            "rating": 1311.5576037831224,
            "rating_q975": 1324.8822731856787,
            "rating_q025": 1298.2329343805661
        },
        "llama-4-maverick-17b-128e-instruct": {
            "rating": 1310.89735436093,
            "rating_q975": 1317.7516854798246,
            "rating_q025": 1304.0430232420354
        },
        "gpt-4o-mini-2024-07-18": {
            "rating": 1310.216689839398,
            "rating_q975": 1315.4584374032324,
            "rating_q025": 1304.9749422755635
        },
        "llama-3.1-405b-instruct-bf16": {
            "rating": 1309.0859060999085,
            "rating_q975": 1314.986037492363,
            "rating_q025": 1303.185774707454
        },
        "claude-3-5-haiku-20241022": {
            "rating": 1308.0633339878514,
            "rating_q975": 1313.0759892734354,
            "rating_q025": 1303.0506787022673
        },
        "gemini-1.5-flash-002": {
            "rating": 1307.1882336995923,
            "rating_q975": 1313.9045689547854,
            "rating_q025": 1300.4718984443991
        },
        "llama-3.3-nemotron-49b-super-v1": {
            "rating": 1306.9869044728775,
            "rating_q975": 1329.58803539488,
            "rating_q025": 1284.385773550875
        },
        "o1-mini": {
            "rating": 1306.786865173191,
            "rating_q975": 1312.5514720590359,
            "rating_q025": 1301.0222582873462
        },
        "llama-4-scout-17b-16e-instruct": {
            "rating": 1306.3058789171416,
            "rating_q975": 1313.9667444947554,
            "rating_q025": 1298.6450133395278
        },
        "qwen3-32b": {
            "rating": 1306.1447718185852,
            "rating_q975": 1323.1835299828451,
            "rating_q025": 1289.1060136543254
        },
        "hunyuan-large-2025-02-10": {
            "rating": 1306.1365211846137,
            "rating_q975": 1324.8445466896146,
            "rating_q025": 1287.4284956796128
        },
        "qwq-32b": {
            "rating": 1305.9488337377438,
            "rating_q975": 1313.4845858457422,
            "rating_q025": 1298.4130816297454
        },
        "gpt-oss-120b": {
            "rating": 1305.7971614296084,
            "rating_q975": 1313.9202900524722,
            "rating_q025": 1297.6740328067447
        },
        "glm-4-plus": {
            "rating": 1305.7820060538684,
            "rating_q975": 1313.8394771915628,
            "rating_q025": 1297.724534916174
        },
        "gpt-4-1106-preview": {
            "rating": 1304.7119481743998,
            "rating_q975": 1310.916471265704,
            "rating_q025": 1298.5074250830955
        },
        "qwen-max-0919": {
            "rating": 1303.7796622073688,
            "rating_q975": 1313.0280099192141,
            "rating_q025": 1294.5313144955235
        },
        "qwen3-30b-a3b": {
            "rating": 1303.3181203816432,
            "rating_q975": 1311.2087425499924,
            "rating_q025": 1295.427498213294
        },
        "gpt-4-0125-preview": {
            "rating": 1302.1021446106283,
            "rating_q975": 1308.483036946994,
            "rating_q025": 1295.7212522742627
        },
        "yi-lightning": {
            "rating": 1300.3111166443432,
            "rating_q975": 1308.3332840993432,
            "rating_q025": 1292.2889491893432
        },
        "step-1o-turbo-202506": {
            "rating": 1300.0930529889101,
            "rating_q975": 1313.4085722126722,
            "rating_q025": 1286.777533765148
        },
        "mistral-large-2407": {
            "rating": 1299.1986442408584,
            "rating_q975": 1305.774600888292,
            "rating_q025": 1292.6226875934246
        },
        "gemma-3n-e4b-it": {
            "rating": 1298.0236997191628,
            "rating_q975": 1306.6628938194988,
            "rating_q025": 1289.3845056188268
        },
        "gemma-3-4b-it": {
            "rating": 1296.059566929944,
            "rating_q975": 1313.2242197948133,
            "rating_q025": 1278.8949140650745
        },
        "gpt-4.1-nano-2025-04-14": {
            "rating": 1295.8378751805242,
            "rating_q975": 1310.1594405302096,
            "rating_q025": 1281.5163098308387
        },
        "nvidia-llama-3.3-nemotron-super-49b-v1.5": {
            "rating": 1295.413539058126,
            "rating_q975": 1316.8100323050603,
            "rating_q025": 1274.0170458111916
        },
        "mistral-large-2411": {
            "rating": 1294.6198631010143,
            "rating_q975": 1301.5659901697347,
            "rating_q025": 1287.6737360322938
        },
        "gemma-2-27b-it": {
            "rating": 1292.883065557363,
            "rating_q975": 1298.031174344758,
            "rating_q025": 1287.7349567699678
        },
        "gpt-5-nano-high": {
            "rating": 1291.0162775966637,
            "rating_q975": 1305.2761765899272,
            "rating_q025": 1276.7563786034002
        },
        "grok-2-mini-2024-08-13": {
            "rating": 1290.9325086566055,
            "rating_q975": 1296.8520750401408,
            "rating_q025": 1285.0129422730702
        },
        "magistral-medium-2506": {
            "rating": 1290.2721557565092,
            "rating_q975": 1302.4253088205917,
            "rating_q025": 1278.1190026924266
        },
        "hunyuan-standard-2025-02-10": {
            "rating": 1289.5786084451572,
            "rating_q975": 1307.7799155002597,
            "rating_q025": 1271.3773013900548
        },
        "llama-3.3-70b-instruct": {
            "rating": 1289.3862683213374,
            "rating_q975": 1294.766375936943,
            "rating_q025": 1284.0061607057319
        },
        "mistral-small-3.1-24b-instruct-2503": {
            "rating": 1287.9696752106347,
            "rating_q975": 1295.4683876700897,
            "rating_q025": 1280.4709627511797
        },
        "gemini-1.5-flash-001": {
            "rating": 1287.7513393296858,
            "rating_q975": 1294.3758161296614,
            "rating_q025": 1281.1268625297103
        },
        "qwen2.5-plus-1127": {
            "rating": 1286.5754886353852,
            "rating_q975": 1297.374497974185,
            "rating_q025": 1275.7764792965854
        },
        "hunyuan-large-vision": {
            "rating": 1284.2961531469848,
            "rating_q975": 1301.977285766286,
            "rating_q025": 1266.6150205276836
        },
        "ring-flash-2.0": {
            "rating": 1283.7305639526485,
            "rating_q975": 1299.085255914339,
            "rating_q025": 1268.3758719909579
        },
        "gpt-4-0613": {
            "rating": 1280.7387988574962,
            "rating_q975": 1287.3485840018795,
            "rating_q025": 1274.129013713113
        },
        "deepseek-v2.5": {
            "rating": 1280.28946881289,
            "rating_q975": 1288.339677480636,
            "rating_q025": 1272.2392601451438
        },
        "gpt-4-0314": {
            "rating": 1279.557390312186,
            "rating_q975": 1287.6966629870885,
            "rating_q025": 1271.4181176372836
        },
        "qwen2.5-72b-instruct": {
            "rating": 1278.881039972901,
            "rating_q975": 1285.3604033895815,
            "rating_q025": 1272.4016765562203
        },
        "ling-flash-2.0": {
            "rating": 1276.246358240015,
            "rating_q975": 1291.6692399577864,
            "rating_q025": 1260.8234765222437
        },
        "llama-3.1-tulu-3-70b": {
            "rating": 1275.8175471664972,
            "rating_q975": 1295.3690817006927,
            "rating_q025": 1256.2660126323017
        },
        "athene-v2-chat": {
            "rating": 1275.7119962806294,
            "rating_q975": 1283.1053325469206,
            "rating_q025": 1268.318660014338
        },
        "athene-70b-0725": {
            "rating": 1274.9351279063603,
            "rating_q975": 1283.6334969751279,
            "rating_q025": 1266.2367588375928
        },
        "command-r-plus-08-2024": {
            "rating": 1274.4491344978846,
            "rating_q975": 1285.5930041946838,
            "rating_q025": 1263.3052648010855
        },
        "jamba-1.5-large": {
            "rating": 1272.586385363086,
            "rating_q975": 1285.1257293971503,
            "rating_q025": 1260.0470413290218
        },
        "gpt-oss-20b": {
            "rating": 1271.6498098889485,
            "rating_q975": 1284.6081151573574,
            "rating_q025": 1258.6915046205397
        },
        "amazon-nova-pro-v1.0": {
            "rating": 1270.9744324437363,
            "rating_q975": 1278.185462728107,
            "rating_q025": 1263.7634021593656
        },
        "gemma-2-9b-it-simpo": {
            "rating": 1270.0311923370055,
            "rating_q975": 1281.6291373180543,
            "rating_q025": 1258.4332473559566
        },
        "reka-core-20240904": {
            "rating": 1269.0533971423267,
            "rating_q975": 1282.434615232159,
            "rating_q025": 1255.6721790524944
        },
        "claude-3-sonnet-20240229": {
            "rating": 1266.083629870183,
            "rating_q975": 1272.400732587922,
            "rating_q025": 1259.7665271524438
        },
        "llama-3.1-nemotron-51b-instruct": {
            "rating": 1265.539758927603,
            "rating_q975": 1283.5635074892023,
            "rating_q025": 1247.516010366004
        },
        "gemma-2-9b-it": {
            "rating": 1263.898810414575,
            "rating_q975": 1269.5949368803952,
            "rating_q025": 1258.202683948755
        },
        "llama-3.1-nemotron-70b-instruct": {
            "rating": 1262.7416220287384,
            "rating_q975": 1276.5010892186438,
            "rating_q025": 1248.9821548388331
        },
        "llama-3.1-70b-instruct": {
            "rating": 1261.231200044474,
            "rating_q975": 1267.1896805173221,
            "rating_q025": 1255.2727195716259
        },
        "command-r-plus": {
            "rating": 1257.0357008854578,
            "rating_q975": 1263.9267935080888,
            "rating_q025": 1250.1446082628268
        },
        "nemotron-4-340b-instruct": {
            "rating": 1256.461405618201,
            "rating_q975": 1265.665244802064,
            "rating_q025": 1247.257566434338
        },
        "reka-flash-20240904": {
            "rating": 1255.3153008023307,
            "rating_q975": 1268.240082893305,
            "rating_q025": 1242.3905187113564
        },
        "gemini-1.5-flash-8b-001": {
            "rating": 1252.012871193304,
            "rating_q975": 1258.8170709223264,
            "rating_q025": 1245.2086714642815
        },
        "c4ai-aya-expanse-32b": {
            "rating": 1251.0624131700329,
            "rating_q975": 1258.6358263259792,
            "rating_q025": 1243.4890000140865
        },
        "glm-4-0520": {
            "rating": 1250.7399122217316,
            "rating_q975": 1262.6230567779544,
            "rating_q025": 1238.8567676655089
        },
        "llama-3-70b-instruct": {
            "rating": 1246.562334205497,
            "rating_q975": 1252.572584313629,
            "rating_q025": 1240.5520840973652
        },
        "mistral-small-24b-instruct-2501": {
            "rating": 1244.6680247380414,
            "rating_q975": 1254.050689165703,
            "rating_q025": 1235.2853603103797
        },
        "claude-3-haiku-20240307": {
            "rating": 1243.262504578624,
            "rating_q975": 1249.2367607541203,
            "rating_q025": 1237.2882484031277
        },
        "qwen2-72b-instruct": {
            "rating": 1239.5361564194654,
            "rating_q975": 1247.170505977815,
            "rating_q025": 1231.9018068611158
        },
        "deepseek-coder-v2": {
            "rating": 1237.0625624948443,
            "rating_q975": 1247.561330869959,
            "rating_q025": 1226.5637941197297
        },
        "amazon-nova-lite-v1.0": {
            "rating": 1236.529274527858,
            "rating_q975": 1244.696510621557,
            "rating_q025": 1228.3620384341589
        },
        "command-r-08-2024": {
            "rating": 1235.3610634397094,
            "rating_q975": 1246.9446420901245,
            "rating_q025": 1223.7774847892942
        },
        "olmo-2-0325-32b-instruct": {
            "rating": 1231.78701629114,
            "rating_q975": 1251.0475658168748,
            "rating_q025": 1212.526466765405
        },
        "phi-4": {
            "rating": 1226.5908807797732,
            "rating_q975": 1234.1519204709107,
            "rating_q025": 1219.0298410886357
        },
        "qwen2.5-coder-32b-instruct": {
            "rating": 1223.771050394258,
            "rating_q975": 1238.4313739230015,
            "rating_q025": 1209.1107268655146
        },
        "mistral-large-2402": {
            "rating": 1223.0275409908138,
            "rating_q975": 1230.5023156004547,
            "rating_q025": 1215.552766381173
        },
        "ministral-8b-2410": {
            "rating": 1221.8466597415768,
            "rating_q975": 1237.3597003490574,
            "rating_q025": 1206.3336191340961
        },
        "gpt-3.5-turbo-0125": {
            "rating": 1220.0649606916863,
            "rating_q975": 1227.1845574152649,
            "rating_q025": 1212.9453639681078
        },
        "amazon-nova-micro-v1.0": {
            "rating": 1219.9363369086382,
            "rating_q975": 1228.163954349583,
            "rating_q025": 1211.7087194676933
        },
        "qwen1.5-110b-chat": {
            "rating": 1215.656459457627,
            "rating_q975": 1224.9497208770892,
            "rating_q025": 1206.363198038165
        },
        "gemini-pro-dev-api": {
            "rating": 1211.4738317375275,
            "rating_q975": 1223.2047481058403,
            "rating_q025": 1199.7429153692146
        },
        "qwen1.5-72b-chat": {
            "rating": 1211.2132051092176,
            "rating_q975": 1219.5460162190698,
            "rating_q025": 1202.8803939993654
        },
        "c4ai-aya-expanse-8b": {
            "rating": 1209.8423377643592,
            "rating_q975": 1220.9439379384266,
            "rating_q025": 1198.7407375902917
        },
        "jamba-1.5-mini": {
            "rating": 1209.68079058664,
            "rating_q975": 1222.1192846845115,
            "rating_q025": 1197.2422964887683
        },
        "mixtral-8x22b-instruct-v0.1": {
            "rating": 1206.4914905213614,
            "rating_q975": 1213.8694171158347,
            "rating_q025": 1199.113563926888
        },
        "mistral-medium": {
            "rating": 1206.002869557547,
            "rating_q975": 1215.259512837675,
            "rating_q025": 1196.746226277419
        },
        "command-r": {
            "rating": 1205.6594523223541,
            "rating_q975": 1213.3173662575052,
            "rating_q025": 1198.001538387203
        },
        "hunyuan-standard-256k": {
            "rating": 1204.9314700685613,
            "rating_q975": 1225.712300344584,
            "rating_q025": 1184.1506397925386
        },
        "gemini-pro": {
            "rating": 1202.0756535257729,
            "rating_q975": 1220.849830528084,
            "rating_q025": 1183.3014765234616
        },
        "reka-flash-21b-20240226-online": {
            "rating": 1201.2997097134753,
            "rating_q975": 1213.36715593103,
            "rating_q025": 1189.2322634959205
        },
        "llama-3.1-tulu-3-8b": {
            "rating": 1198.5815376403664,
            "rating_q975": 1218.0920595483906,
            "rating_q025": 1179.0710157323422
        },
        "reka-flash-21b-20240226": {
            "rating": 1194.9861893309217,
            "rating_q975": 1204.7566423251676,
            "rating_q025": 1185.2157363366757
        },
        "zephyr-orpo-141b-A35b-v0.1": {
            "rating": 1192.8179956030472,
            "rating_q975": 1210.713078384161,
            "rating_q025": 1174.9229128219333
        },
        "wizardlm-70b": {
            "rating": 1192.2482631140363,
            "rating_q975": 1206.938060963932,
            "rating_q025": 1177.5584652641405
        },
        "gemma-2-2b-it": {
            "rating": 1189.2054060155347,
            "rating_q975": 1195.4683231937386,
            "rating_q025": 1182.9424888373308
        },
        "llama-3-8b-instruct": {
            "rating": 1188.9634053738987,
            "rating_q975": 1195.3401737663353,
            "rating_q025": 1182.586636981462
        },
        "gpt-3.5-turbo-1106": {
            "rating": 1185.585094491823,
            "rating_q975": 1198.794128834908,
            "rating_q025": 1172.376060148738
        },
        "llama-3.1-8b-instruct": {
            "rating": 1179.7415590510427,
            "rating_q975": 1186.1346119862699,
            "rating_q025": 1173.3485061158156
        },
        "granite-3.1-8b-instruct": {
            "rating": 1176.1617789376137,
            "rating_q975": 1196.788283435947,
            "rating_q025": 1155.5352744392803
        },
        "dbrx-instruct-preview": {
            "rating": 1173.284932623428,
            "rating_q975": 1182.9593304429993,
            "rating_q025": 1163.6105348038566
        },
        "yi-1.5-34b-chat": {
            "rating": 1172.9481232169996,
            "rating_q975": 1181.641613953614,
            "rating_q025": 1164.2546324803852
        },
        "openchat-3.5": {
            "rating": 1172.483179645139,
            "rating_q975": 1187.8420609347809,
            "rating_q025": 1157.124298355497
        },
        "phi-3-medium-4k-instruct": {
            "rating": 1170.509400929679,
            "rating_q975": 1178.9925420865918,
            "rating_q025": 1162.0262597727663
        },
        "qwen1.5-32b-chat": {
            "rating": 1169.6043099314645,
            "rating_q975": 1179.7577352225464,
            "rating_q025": 1159.4508846403826
        },
        "vicuna-33b": {
            "rating": 1168.6208881553855,
            "rating_q975": 1178.632919577675,
            "rating_q025": 1158.608856733096
        },
        "mixtral-8x7b-instruct-v0.1": {
            "rating": 1167.9943539538222,
            "rating_q975": 1175.0456400218532,
            "rating_q025": 1160.9430678857912
        },
        "falcon-180b-chat": {
            "rating": 1167.7769295651135,
            "rating_q975": 1199.9283206862528,
            "rating_q025": 1135.6255384439742
        },
        "deepseek-llm-67b-chat": {
            "rating": 1166.2779750791806,
            "rating_q975": 1185.01895514774,
            "rating_q025": 1147.5369950106212
        },
        "tulu-2-dpo-70b": {
            "rating": 1163.5250915723973,
            "rating_q975": 1180.3052540505073,
            "rating_q025": 1146.7449290942873
        },
        "qwen1.5-14b-chat": {
            "rating": 1162.1316020656905,
            "rating_q975": 1173.432563750455,
            "rating_q025": 1150.8306403809258
        },
        "yi-34b-chat": {
            "rating": 1161.365471399638,
            "rating_q975": 1172.5887673820891,
            "rating_q025": 1150.1421754171868
        },
        "openchat-3.5-0106": {
            "rating": 1159.8365064350446,
            "rating_q975": 1172.0828735553519,
            "rating_q025": 1147.5901393147374
        },
        "snowflake-arctic-instruct": {
            "rating": 1156.8740457558956,
            "rating_q975": 1166.7289626101394,
            "rating_q025": 1147.0191289016518
        },
        "openhermes-2.5-mistral-7b": {
            "rating": 1155.3509334228347,
            "rating_q975": 1173.6895548017276,
            "rating_q025": 1137.0123120439418
        },
        "wizardlm-13b": {
            "rating": 1150.7626863385378,
            "rating_q975": 1165.9867992471547,
            "rating_q025": 1135.538573429921
        },
        "internlm2_5-20b-chat": {
            "rating": 1150.2480360812656,
            "rating_q975": 1162.368579025784,
            "rating_q025": 1138.1274931367473
        },
        "gemma-1.1-7b-it": {
            "rating": 1147.2552391583158,
            "rating_q975": 1156.3672243921603,
            "rating_q025": 1138.1432539244713
        },
        "vicuna-13b": {
            "rating": 1142.0668190812135,
            "rating_q975": 1152.641679379792,
            "rating_q025": 1131.4919587826348
        },
        "granite-3.0-8b-instruct": {
            "rating": 1140.2007353330102,
            "rating_q975": 1155.6283350178646,
            "rating_q025": 1124.7731356481559
        },
        "llama-3.2-3b-instruct": {
            "rating": 1139.1148402986628,
            "rating_q975": 1153.055522295089,
            "rating_q025": 1125.1741583022365
        },
        "nous-hermes-2-mixtral-8x7b-dpo": {
            "rating": 1138.8249328174613,
            "rating_q975": 1158.7748988748567,
            "rating_q025": 1118.874966760066
        },
        "phi-3-small-8k-instruct": {
            "rating": 1138.1538965038803,
            "rating_q975": 1148.140312890247,
            "rating_q025": 1128.1674801175136
        },
        "starling-lm-7b-alpha": {
            "rating": 1137.5268765717906,
            "rating_q975": 1150.5945763192005,
            "rating_q025": 1124.4591768243806
        },
        "mpt-30b-chat": {
            "rating": 1136.7353246148507,
            "rating_q975": 1159.3914334392825,
            "rating_q025": 1114.0792157904189
        },
        "solar-10.7b-instruct-v1.0": {
            "rating": 1136.60180450048,
            "rating_q975": 1157.5274549749706,
            "rating_q025": 1115.6761540259895
        },
        "dolphin-2.2.1-mistral-7b": {
            "rating": 1129.406674082422,
            "rating_q975": 1158.2302317083133,
            "rating_q025": 1100.5831164565304
        },
        "llama-2-70b-chat": {
            "rating": 1128.7126116710883,
            "rating_q975": 1137.1624276747264,
            "rating_q025": 1120.2627956674503
        },
        "starling-lm-7b-beta": {
            "rating": 1127.146813535522,
            "rating_q975": 1139.254606845392,
            "rating_q025": 1115.039020225652
        },
        "llama2-70b-steerlm-chat": {
            "rating": 1126.3272919447313,
            "rating_q975": 1148.1454367009162,
            "rating_q025": 1104.5091471885464
        },
        "granite-3.1-2b-instruct": {
            "rating": 1125.2140496887787,
            "rating_q975": 1146.319716642524,
            "rating_q025": 1104.1083827350333
        },
        "zephyr-7b-alpha": {
            "rating": 1121.317259086728,
            "rating_q975": 1146.6639920825107,
            "rating_q025": 1095.9705260909452
        },
        "guanaco-33b": {
            "rating": 1121.0325114216764,
            "rating_q975": 1144.0362665714676,
            "rating_q025": 1098.0287562718852
        },
        "zephyr-7b-beta": {
            "rating": 1119.5186766810596,
            "rating_q975": 1133.3882480029158,
            "rating_q025": 1105.6491053592033
        },
        "qwen-14b-chat": {
            "rating": 1117.0512651529784,
            "rating_q975": 1135.150739317439,
            "rating_q025": 1098.9517909885178
        },
        "qwq-32b-preview": {
            "rating": 1115.9112730707825,
            "rating_q975": 1136.9409405150213,
            "rating_q025": 1094.8816056265437
        },
        "vicuna-7b": {
            "rating": 1112.9947492209712,
            "rating_q975": 1128.071422868344,
            "rating_q025": 1097.9180755735986
        },
        "mistral-7b-instruct-v0.2": {
            "rating": 1111.393562388035,
            "rating_q975": 1121.8070551351427,
            "rating_q025": 1100.9800696409272
        },
        "qwen1.5-7b-chat": {
            "rating": 1110.3471111550766,
            "rating_q975": 1128.4468085458327,
            "rating_q025": 1092.2474137643205
        },
        "granite-3.0-2b-instruct": {
            "rating": 1102.5384384901213,
            "rating_q975": 1118.0389902885104,
            "rating_q025": 1087.0378866917322
        },
        "llama-2-13b-chat": {
            "rating": 1102.3411507617648,
            "rating_q975": 1112.9165052463677,
            "rating_q025": 1091.7657962771618
        },
        "codellama-34b-instruct": {
            "rating": 1101.2866613330566,
            "rating_q975": 1115.7861091271918,
            "rating_q025": 1086.7872135389214
        },
        "phi-3-mini-4k-instruct-june-2024": {
            "rating": 1100.2438083882,
            "rating_q975": 1111.4430034101104,
            "rating_q025": 1089.0446133662897
        },
        "gemma-7b-it": {
            "rating": 1099.6677537595938,
            "rating_q975": 1114.2963780970263,
            "rating_q025": 1085.0391294221613
        },
        "phi-3-mini-128k-instruct": {
            "rating": 1095.693052585215,
            "rating_q975": 1107.5224947704705,
            "rating_q025": 1083.8636103999593
        },
        "mistral-7b-instruct": {
            "rating": 1091.8591823653337,
            "rating_q975": 1106.8648550617709,
            "rating_q025": 1076.8535096688965
        },
        "palm-2": {
            "rating": 1091.7007987712332,
            "rating_q975": 1106.7053784438003,
            "rating_q025": 1076.696219098666
        },
        "phi-3-mini-4k-instruct": {
            "rating": 1091.0094599348918,
            "rating_q975": 1101.3321331126144,
            "rating_q025": 1080.686786757169
        },
        "stripedhyena-nous-7b": {
            "rating": 1089.55675561728,
            "rating_q975": 1107.5006161202568,
            "rating_q025": 1071.6128951143032
        },
        "gemma-1.1-2b-it": {
            "rating": 1085.2054212166152,
            "rating_q975": 1098.2801977027812,
            "rating_q025": 1072.1306447304491
        },
        "smollm2-1.7b-instruct": {
            "rating": 1076.6328744029397,
            "rating_q975": 1103.293343064388,
            "rating_q025": 1049.9724057414915
        },
        "alpaca-13b": {
            "rating": 1074.3315549518102,
            "rating_q975": 1093.5712007458983,
            "rating_q025": 1055.091909157722
        },
        "llama-2-7b-chat": {
            "rating": 1074.1797516552074,
            "rating_q975": 1085.502752665734,
            "rating_q025": 1062.8567506446807
        },
        "llama-3.2-1b-instruct": {
            "rating": 1072.875706642683,
            "rating_q975": 1087.8890262647644,
            "rating_q025": 1057.8623870206018
        },
        "qwen1.5-4b-chat": {
            "rating": 1072.2963467618356,
            "rating_q975": 1087.1647346130565,
            "rating_q025": 1057.4279589106147
        },
        "gpt4all-13b-snoozy": {
            "rating": 1058.6009071218477,
            "rating_q975": 1090.2005767584812,
            "rating_q025": 1027.0012374852142
        },
        "codellama-70b-instruct": {
            "rating": 1054.7111340475476,
            "rating_q975": 1091.9316652369478,
            "rating_q025": 1017.4906028581474
        },
        "mpt-7b-chat": {
            "rating": 1053.1678165605344,
            "rating_q975": 1073.971650401309,
            "rating_q025": 1032.3639827197599
        },
        "gemma-2b-it": {
            "rating": 1051.883131347026,
            "rating_q975": 1070.6032886482142,
            "rating_q025": 1033.1629740458377
        },
        "koala-13b": {
            "rating": 1046.1774173984081,
            "rating_q975": 1063.9864850829076,
            "rating_q025": 1028.3683497139086
        },
        "chatglm3-6b": {
            "rating": 1038.204778345777,
            "rating_q975": 1058.3672798103305,
            "rating_q025": 1018.0422768812234
        },
        "olmo-7b-instruct": {
            "rating": 1022.4287507055078,
            "rating_q975": 1040.5417713133727,
            "rating_q025": 1004.315730097643
        },
        "chatglm2-6b": {
            "rating": 1012.8999436898806,
            "rating_q975": 1035.3225702267355,
            "rating_q025": 990.4773171530259
        },
        "oasst-pythia-12b": {
            "rating": 1008.6733330995777,
            "rating_q975": 1026.4504230421728,
            "rating_q025": 990.8962431569826
        },
        "RWKV-4-Raven-14B": {
            "rating": 1000.6882053935765,
            "rating_q975": 1020.106773068173,
            "rating_q025": 981.26963771898
        },
        "fastchat-t5-3b": {
            "rating": 993.6789550957536,
            "rating_q975": 1014.7553326517004,
            "rating_q025": 972.6025775398068
        },
        "chatglm-6b": {
            "rating": 980.2298047103652,
            "rating_q975": 1000.7030900188253,
            "rating_q025": 959.7565194019052
        },
        "dolly-v2-12b": {
            "rating": 970.2732857546571,
            "rating_q975": 993.5574927655604,
            "rating_q025": 946.9890787437538
        },
        "stablelm-tuned-alpha-7b": {
            "rating": 929.2928386168398,
            "rating_q975": 953.5651850668378,
            "rating_q025": 905.0204921668419
        },
        "llama-13b": {
            "rating": 922.8772712989951,
            "rating_q975": 951.6329170622325,
            "rating_q025": 894.1216255357576
        }
    },
    "japanese": {
        "gemini-2.5-pro": {
            "rating": 1455.349254578891,
            "rating_q975": 1474.0165735274568,
            "rating_q025": 1436.6819356303254
        },
        "gpt-5-high": {
            "rating": 1442.9869324891747,
            "rating_q975": 1465.8683669416728,
            "rating_q025": 1420.1054980366766
        },
        "gpt-4.5-preview-2025-02-27": {
            "rating": 1440.5684834093595,
            "rating_q975": 1478.1049029554704,
            "rating_q025": 1403.0320638632486
        },
        "o3-2025-04-16": {
            "rating": 1436.9523266386866,
            "rating_q975": 1455.2356412715155,
            "rating_q025": 1418.6690120058577
        },
        "gpt-5-chat": {
            "rating": 1427.3404077731316,
            "rating_q975": 1459.0944411256544,
            "rating_q025": 1395.5863744206088
        },
        "gemini-2.5-flash-preview-09-2025": {
            "rating": 1415.056083626152,
            "rating_q975": 1469.9126334211091,
            "rating_q025": 1360.199533831195
        },
        "claude-opus-4-1-20250805-thinking-16k": {
            "rating": 1409.9783790850984,
            "rating_q975": 1438.9814449603746,
            "rating_q025": 1380.9753132098222
        },
        "chatgpt-4o-latest-20250326": {
            "rating": 1408.6469774128605,
            "rating_q975": 1429.9836634038397,
            "rating_q025": 1387.3102914218812
        },
        "gemini-2.5-flash-lite-preview-09-2025-no-thinking": {
            "rating": 1406.1870313944116,
            "rating_q975": 1464.7243048489258,
            "rating_q025": 1347.6497579398974
        },
        "claude-opus-4-1-20250805": {
            "rating": 1396.7275483827632,
            "rating_q975": 1419.7095531725906,
            "rating_q025": 1373.7455435929357
        },
        "grok-4-0709": {
            "rating": 1392.0994666259617,
            "rating_q975": 1413.2408529241768,
            "rating_q025": 1370.9580803277465
        },
        "gemini-2.5-flash": {
            "rating": 1390.447443712572,
            "rating_q975": 1407.9257183559168,
            "rating_q025": 1372.9691690692273
        },
        "glm-4.5": {
            "rating": 1386.2807384072316,
            "rating_q975": 1409.878748731908,
            "rating_q025": 1362.6827280825553
        },
        "claude-opus-4-20250514-thinking-16k": {
            "rating": 1383.7136704602412,
            "rating_q975": 1405.418793072105,
            "rating_q025": 1362.0085478483775
        },
        "o1-2024-12-17": {
            "rating": 1379.723421938582,
            "rating_q975": 1404.8355827107237,
            "rating_q025": 1354.6112611664405
        },
        "qwen3-235b-a22b-instruct-2507": {
            "rating": 1379.426042786923,
            "rating_q975": 1400.752375896301,
            "rating_q025": 1358.0997096775452
        },
        "gpt-5-mini-high": {
            "rating": 1379.2330597744196,
            "rating_q975": 1411.9328965197715,
            "rating_q025": 1346.5332230290678
        },
        "claude-opus-4-20250514": {
            "rating": 1377.0631683299187,
            "rating_q975": 1396.2616624790544,
            "rating_q025": 1357.864674180783
        },
        "grok-3-preview-02-24": {
            "rating": 1376.1913156099547,
            "rating_q975": 1397.1164239204315,
            "rating_q025": 1355.2662072994779
        },
        "deepseek-r1-0528": {
            "rating": 1375.7614819212008,
            "rating_q975": 1401.0358198199692,
            "rating_q025": 1350.4871440224324
        },
        "kimi-k2-0711-preview": {
            "rating": 1375.2081174793232,
            "rating_q975": 1395.3008306907427,
            "rating_q025": 1355.1154042679036
        },
        "qwen3-max-preview": {
            "rating": 1374.8114356364893,
            "rating_q975": 1408.1019728042086,
            "rating_q025": 1341.52089846877
        },
        "deepseek-v3.1": {
            "rating": 1373.6609404467315,
            "rating_q975": 1406.072401758484,
            "rating_q025": 1341.249479134979
        },
        "deepseek-v3.1-thinking": {
            "rating": 1373.6472936951934,
            "rating_q975": 1410.6211388394079,
            "rating_q025": 1336.673448550979
        },
        "qwen3-235b-a22b-no-thinking": {
            "rating": 1367.3071110010512,
            "rating_q975": 1388.3271031694926,
            "rating_q025": 1346.2871188326098
        },
        "qwen3-next-80b-a3b-instruct": {
            "rating": 1365.9224509549938,
            "rating_q975": 1404.268651724368,
            "rating_q025": 1327.5762501856195
        },
        "qwen3-235b-a22b-thinking-2507": {
            "rating": 1363.6910722163075,
            "rating_q975": 1392.7111433605608,
            "rating_q025": 1334.6710010720542
        },
        "kimi-k2-0905-preview": {
            "rating": 1361.3486282626247,
            "rating_q975": 1407.9519167562207,
            "rating_q025": 1314.7453397690288
        },
        "gemini-2.5-flash-lite-preview-06-17-thinking": {
            "rating": 1359.9932676979897,
            "rating_q975": 1381.6094692612905,
            "rating_q025": 1338.377066134689
        },
        "mistral-medium-2508": {
            "rating": 1358.484201241281,
            "rating_q975": 1386.7410469832237,
            "rating_q025": 1330.2273554993383
        },
        "claude-sonnet-4-5-20250929-thinking-32k": {
            "rating": 1357.2770428224094,
            "rating_q975": 1409.0430776743804,
            "rating_q025": 1305.5110079704384
        },
        "o1-preview": {
            "rating": 1355.9554992280837,
            "rating_q975": 1378.7863550353215,
            "rating_q025": 1333.1246434208458
        },
        "gpt-4.1-2025-04-14": {
            "rating": 1350.7319012627877,
            "rating_q975": 1370.062466405482,
            "rating_q025": 1331.4013361200934
        },
        "o4-mini-2025-04-16": {
            "rating": 1347.010521275404,
            "rating_q975": 1366.440398020552,
            "rating_q025": 1327.580644530256
        },
        "mai-1-preview": {
            "rating": 1345.7844106022148,
            "rating_q975": 1381.0718906518487,
            "rating_q025": 1310.496930552581
        },
        "claude-3-7-sonnet-20250219-thinking-32k": {
            "rating": 1343.0268926797069,
            "rating_q975": 1362.4494497664666,
            "rating_q025": 1323.604335592947
        },
        "hunyuan-turbos-20250416": {
            "rating": 1343.013293437939,
            "rating_q975": 1374.947631562598,
            "rating_q025": 1311.07895531328
        },
        "deepseek-r1": {
            "rating": 1340.8924817617246,
            "rating_q975": 1366.34749044924,
            "rating_q025": 1315.4374730742093
        },
        "claude-sonnet-4-20250514": {
            "rating": 1340.5776125599966,
            "rating_q975": 1360.70117867449,
            "rating_q025": 1320.4540464455033
        },
        "deepseek-v3-0324": {
            "rating": 1338.5361831353237,
            "rating_q975": 1357.9312856084866,
            "rating_q025": 1319.1410806621607
        },
        "claude-sonnet-4-20250514-thinking-32k": {
            "rating": 1337.789518830297,
            "rating_q975": 1359.7696355748599,
            "rating_q025": 1315.8094020857343
        },
        "grok-3-mini-beta": {
            "rating": 1331.382175339224,
            "rating_q975": 1355.4492716095278,
            "rating_q025": 1307.31507906892
        },
        "qwen3-30b-a3b-instruct-2507": {
            "rating": 1330.7017897776018,
            "rating_q975": 1354.446587088338,
            "rating_q025": 1306.9569924668656
        },
        "glm-4.5-air": {
            "rating": 1330.0831745613998,
            "rating_q975": 1352.1862913962045,
            "rating_q025": 1307.980057726595
        },
        "qwen3-coder-480b-a35b-instruct": {
            "rating": 1327.1080026672314,
            "rating_q975": 1347.560801180693,
            "rating_q025": 1306.6552041537698
        },
        "gemini-2.0-flash-lite-preview-02-05": {
            "rating": 1324.6445121517527,
            "rating_q975": 1349.18912279395,
            "rating_q025": 1300.0999015095554
        },
        "gpt-4.1-mini-2025-04-14": {
            "rating": 1324.6141335364052,
            "rating_q975": 1344.4366340388033,
            "rating_q025": 1304.7916330340072
        },
        "gemini-1.5-pro-002": {
            "rating": 1322.3537348929642,
            "rating_q975": 1338.8499909682157,
            "rating_q025": 1305.8574788177127
        },
        "mistral-medium-2505": {
            "rating": 1317.1948069730345,
            "rating_q975": 1337.5612857619437,
            "rating_q025": 1296.8283281841252
        },
        "qwen2.5-max": {
            "rating": 1317.0126717404705,
            "rating_q975": 1338.2449790214303,
            "rating_q025": 1295.7803644595108
        },
        "o3-mini-high": {
            "rating": 1316.586581821739,
            "rating_q975": 1346.5147900980737,
            "rating_q025": 1286.6583735454042
        },
        "grok-3-mini-high": {
            "rating": 1314.664535929134,
            "rating_q975": 1341.9558776301242,
            "rating_q025": 1287.3731942281438
        },
        "gemma-3-27b-it": {
            "rating": 1313.7858253797456,
            "rating_q975": 1332.9871153602314,
            "rating_q025": 1294.5845353992597
        },
        "claude-3-5-sonnet-20241022": {
            "rating": 1313.0433008485206,
            "rating_q975": 1326.2565941869943,
            "rating_q025": 1299.830007510047
        },
        "command-a-03-2025": {
            "rating": 1312.1621475942213,
            "rating_q975": 1330.7702621833184,
            "rating_q025": 1293.5540330051242
        },
        "gpt-oss-120b": {
            "rating": 1311.6540222648855,
            "rating_q975": 1340.064169660253,
            "rating_q025": 1283.243874869518
        },
        "gpt-4o-2024-05-13": {
            "rating": 1310.5729949559284,
            "rating_q975": 1323.9241570743025,
            "rating_q025": 1297.2218328375543
        },
        "qwen3-235b-a22b": {
            "rating": 1308.2719197081472,
            "rating_q975": 1331.2029446748647,
            "rating_q025": 1285.3408947414296
        },
        "o3-mini": {
            "rating": 1301.8410209163208,
            "rating_q975": 1318.0552516310277,
            "rating_q025": 1285.6267902016139
        },
        "gpt-4o-2024-08-06": {
            "rating": 1297.3912154801656,
            "rating_q975": 1314.8000361215873,
            "rating_q025": 1279.9823948387439
        },
        "gemma-3n-e4b-it": {
            "rating": 1296.5854946846316,
            "rating_q975": 1319.3211439047234,
            "rating_q025": 1273.8498454645398
        },
        "mistral-small-2506": {
            "rating": 1295.8933755290007,
            "rating_q975": 1321.270152852766,
            "rating_q025": 1270.5165982052354
        },
        "gemini-advanced-0514": {
            "rating": 1295.1867052744124,
            "rating_q975": 1314.4874493632792,
            "rating_q025": 1275.8859611855455
        },
        "deepseek-v3": {
            "rating": 1294.4687993046448,
            "rating_q975": 1317.4455220867767,
            "rating_q025": 1271.492076522513
        },
        "claude-3-5-sonnet-20240620": {
            "rating": 1292.1472983150354,
            "rating_q975": 1306.680739012179,
            "rating_q025": 1277.6138576178919
        },
        "gemini-1.5-pro-001": {
            "rating": 1290.8885874521673,
            "rating_q975": 1306.1512413248379,
            "rating_q025": 1275.6259335794966
        },
        "qwen3-next-80b-a3b-thinking": {
            "rating": 1290.3163971940835,
            "rating_q975": 1334.8407971734368,
            "rating_q025": 1245.7919972147301
        },
        "o1-mini": {
            "rating": 1282.4062630970352,
            "rating_q975": 1299.5292145330864,
            "rating_q025": 1265.283311660984
        },
        "nvidia-llama-3.3-nemotron-super-49b-v1.5": {
            "rating": 1282.2038437308188,
            "rating_q975": 1311.9582156646072,
            "rating_q025": 1252.4494717970304
        },
        "qwen-plus-0125": {
            "rating": 1280.9149134302384,
            "rating_q975": 1318.6380772804575,
            "rating_q025": 1243.1917495800192
        },
        "llama-3.1-405b-instruct-bf16": {
            "rating": 1278.3195787129514,
            "rating_q975": 1297.8145814428126,
            "rating_q025": 1258.8245759830902
        },
        "grok-2-2024-08-13": {
            "rating": 1276.0123966720116,
            "rating_q975": 1291.1583256881584,
            "rating_q025": 1260.8664676558649
        },
        "gpt-4-1106-preview": {
            "rating": 1269.5068264949762,
            "rating_q975": 1286.3512475430691,
            "rating_q025": 1252.6624054468832
        },
        "claude-3-opus-20240229": {
            "rating": 1268.1221633504842,
            "rating_q975": 1280.3952231510395,
            "rating_q025": 1255.849103549929
        },
        "gemini-1.5-flash-002": {
            "rating": 1267.278503167633,
            "rating_q975": 1288.1176699675939,
            "rating_q025": 1246.4393363676722
        },
        "gpt-oss-20b": {
            "rating": 1264.8796031302645,
            "rating_q975": 1305.5375068846793,
            "rating_q025": 1224.2216993758498
        },
        "longcat-flash-chat": {
            "rating": 1264.3503772836634,
            "rating_q975": 1309.2861229172754,
            "rating_q025": 1219.4146316500514
        },
        "yi-lightning": {
            "rating": 1262.719722909427,
            "rating_q975": 1285.8038285432217,
            "rating_q025": 1239.6356172756323
        },
        "llama-4-maverick-17b-128e-instruct": {
            "rating": 1260.6793988629881,
            "rating_q975": 1281.9250437085443,
            "rating_q025": 1239.433754017432
        },
        "llama-4-scout-17b-16e-instruct": {
            "rating": 1260.1969260410347,
            "rating_q975": 1282.458966500218,
            "rating_q025": 1237.9348855818514
        },
        "gpt-4-0125-preview": {
            "rating": 1258.1783771034702,
            "rating_q975": 1275.0619771063618,
            "rating_q025": 1241.2947771005786
        },
        "gpt-4-turbo-2024-04-09": {
            "rating": 1257.4706184438508,
            "rating_q975": 1272.0998115814646,
            "rating_q025": 1242.841425306237
        },
        "step-1o-turbo-202506": {
            "rating": 1255.9373648938224,
            "rating_q975": 1297.513939765128,
            "rating_q025": 1214.3607900225168
        },
        "gpt-4o-mini-2024-07-18": {
            "rating": 1255.8579192193993,
            "rating_q975": 1269.4419308509164,
            "rating_q025": 1242.2739075878821
        },
        "deepseek-v2.5-1210": {
            "rating": 1255.319848862,
            "rating_q975": 1296.2506340310981,
            "rating_q025": 1214.389063692902
        },
        "qwen3-30b-a3b": {
            "rating": 1254.2363225219572,
            "rating_q975": 1276.7534043053342,
            "rating_q025": 1231.71924073858
        },
        "claude-3-5-haiku-20241022": {
            "rating": 1251.7027202701317,
            "rating_q975": 1267.6613033954009,
            "rating_q025": 1235.7441371448626
        },
        "qwen-max-0919": {
            "rating": 1248.373058582571,
            "rating_q975": 1279.9317742249978,
            "rating_q025": 1216.8143429401443
        },
        "qwq-32b": {
            "rating": 1244.1553082436615,
            "rating_q975": 1269.3271722385875,
            "rating_q025": 1218.9834442487354
        },
        "llama-3.1-405b-instruct-fp8": {
            "rating": 1243.5776891089154,
            "rating_q975": 1258.535728308121,
            "rating_q025": 1228.6196499097098
        },
        "mistral-small-3.1-24b-instruct-2503": {
            "rating": 1243.1253738310993,
            "rating_q975": 1265.2131323793922,
            "rating_q025": 1221.0376152828064
        },
        "grok-2-mini-2024-08-13": {
            "rating": 1241.147379786368,
            "rating_q975": 1257.6331113517035,
            "rating_q025": 1224.6616482210325
        },
        "glm-4-plus": {
            "rating": 1240.6173688705785,
            "rating_q975": 1266.2218087061328,
            "rating_q025": 1215.0129290350242
        },
        "magistral-medium-2506": {
            "rating": 1238.3958726570186,
            "rating_q975": 1271.8509848989295,
            "rating_q025": 1204.9407604151077
        },
        "qwen2.5-plus-1127": {
            "rating": 1237.7416714132771,
            "rating_q975": 1269.559356376963,
            "rating_q025": 1205.9239864495912
        },
        "athene-v2-chat": {
            "rating": 1237.5718347368697,
            "rating_q975": 1259.9050761267615,
            "rating_q025": 1215.238593346978
        },
        "mistral-large-2407": {
            "rating": 1237.2589332024254,
            "rating_q975": 1253.3506679766904,
            "rating_q025": 1221.1671984281604
        },
        "gpt-4.1-nano-2025-04-14": {
            "rating": 1235.6139760043507,
            "rating_q975": 1280.5537763406749,
            "rating_q025": 1190.6741756680265
        },
        "deepseek-v2.5": {
            "rating": 1234.7567015970594,
            "rating_q975": 1260.3025883963103,
            "rating_q025": 1209.2108147978086
        },
        "minimax-m1": {
            "rating": 1234.6246272820777,
            "rating_q975": 1256.6166729172553,
            "rating_q025": 1212.6325816469
        },
        "gemma-2-27b-it": {
            "rating": 1233.3573079130429,
            "rating_q975": 1247.3846676145931,
            "rating_q025": 1219.3299482114926
        },
        "amazon-nova-pro-v1.0": {
            "rating": 1232.267892277793,
            "rating_q975": 1257.5957506796294,
            "rating_q025": 1206.9400338759565
        },
        "glm-4-plus-0111": {
            "rating": 1229.791980255456,
            "rating_q975": 1267.672435202518,
            "rating_q025": 1191.9115253083942
        },
        "gemini-1.5-flash-001": {
            "rating": 1228.0790175962275,
            "rating_q975": 1244.429530332419,
            "rating_q025": 1211.7285048600359
        },
        "command-r-plus": {
            "rating": 1225.591284274029,
            "rating_q975": 1243.2076356883515,
            "rating_q025": 1207.9749328597065
        },
        "gpt-4-0314": {
            "rating": 1223.5513235735652,
            "rating_q975": 1248.1493639469572,
            "rating_q025": 1198.9532832001732
        },
        "command-r-plus-08-2024": {
            "rating": 1222.0969521042616,
            "rating_q975": 1259.345394461927,
            "rating_q025": 1184.8485097465962
        },
        "llama-3.3-70b-instruct": {
            "rating": 1221.826047276951,
            "rating_q975": 1239.441364993758,
            "rating_q025": 1204.2107295601438
        },
        "command-r-08-2024": {
            "rating": 1218.5303906097654,
            "rating_q975": 1251.5575546552209,
            "rating_q025": 1185.50322656431
        },
        "mistral-large-2411": {
            "rating": 1218.1943554223735,
            "rating_q975": 1240.0291788430368,
            "rating_q025": 1196.3595320017102
        },
        "qwen2.5-72b-instruct": {
            "rating": 1216.0153157100835,
            "rating_q975": 1235.8676393293742,
            "rating_q025": 1196.1629920907928
        },
        "c4ai-aya-expanse-32b": {
            "rating": 1212.5005933589564,
            "rating_q975": 1234.2402399099096,
            "rating_q025": 1190.7609468080032
        },
        "gpt-4-0613": {
            "rating": 1207.0230132616375,
            "rating_q975": 1225.3612032565647,
            "rating_q025": 1188.6848232667103
        },
        "claude-3-sonnet-20240229": {
            "rating": 1203.485497184175,
            "rating_q975": 1220.0072539948114,
            "rating_q025": 1186.9637403735387
        },
        "deepseek-coder-v2": {
            "rating": 1201.0316069727432,
            "rating_q975": 1231.386531441479,
            "rating_q025": 1170.6766825040074
        },
        "gemma-2-9b-it": {
            "rating": 1199.2859278758488,
            "rating_q975": 1215.228569733079,
            "rating_q025": 1183.3432860186185
        },
        "phi-4": {
            "rating": 1198.7405698064983,
            "rating_q975": 1224.8409898306193,
            "rating_q025": 1172.6401497823774
        },
        "gemma-2-9b-it-simpo": {
            "rating": 1193.223552999668,
            "rating_q975": 1225.300764892623,
            "rating_q025": 1161.1463411067132
        },
        "athene-70b-0725": {
            "rating": 1189.8911297816653,
            "rating_q975": 1211.7197604220119,
            "rating_q025": 1168.0624991413188
        },
        "amazon-nova-lite-v1.0": {
            "rating": 1188.670441942353,
            "rating_q975": 1215.6994451873252,
            "rating_q025": 1161.6414386973806
        },
        "amazon-nova-micro-v1.0": {
            "rating": 1187.1698553297688,
            "rating_q975": 1213.647507340351,
            "rating_q025": 1160.6922033191865
        },
        "nemotron-4-340b-instruct": {
            "rating": 1186.787960542637,
            "rating_q975": 1214.823336810655,
            "rating_q025": 1158.7525842746188
        },
        "qwen2-72b-instruct": {
            "rating": 1182.4859191690139,
            "rating_q975": 1202.2479817191393,
            "rating_q025": 1162.7238566188885
        },
        "jamba-1.5-large": {
            "rating": 1182.4287481172614,
            "rating_q975": 1218.7217529855043,
            "rating_q025": 1146.1357432490186
        },
        "llama-3.1-70b-instruct": {
            "rating": 1181.2137208355166,
            "rating_q975": 1196.547879712467,
            "rating_q025": 1165.8795619585662
        },
        "claude-3-haiku-20240307": {
            "rating": 1178.9231779416132,
            "rating_q975": 1193.9954821207507,
            "rating_q025": 1163.8508737624757
        },
        "gemini-1.5-flash-8b-001": {
            "rating": 1177.6006620509456,
            "rating_q975": 1199.0238119600604,
            "rating_q025": 1156.177512141831
        },
        "command-r": {
            "rating": 1169.3826857079227,
            "rating_q975": 1190.7689119899019,
            "rating_q025": 1147.9964594259436
        },
        "c4ai-aya-expanse-8b": {
            "rating": 1160.7939329156966,
            "rating_q975": 1195.1093627073499,
            "rating_q025": 1126.4785031240433
        },
        "mistral-small-24b-instruct-2501": {
            "rating": 1154.7559112425138,
            "rating_q975": 1191.1511103094888,
            "rating_q025": 1118.3607121755388
        },
        "gpt-3.5-turbo-0125": {
            "rating": 1148.0590417120056,
            "rating_q975": 1168.7067329887936,
            "rating_q025": 1127.4113504352176
        },
        "reka-flash-21b-20240226-online": {
            "rating": 1144.836327847969,
            "rating_q975": 1179.569053608703,
            "rating_q025": 1110.103602087235
        },
        "qwen1.5-110b-chat": {
            "rating": 1142.7039178679086,
            "rating_q975": 1168.5916875095506,
            "rating_q025": 1116.8161482262665
        },
        "qwen1.5-72b-chat": {
            "rating": 1137.0066848150916,
            "rating_q975": 1163.9776654577233,
            "rating_q025": 1110.0357041724599
        },
        "gemma-2-2b-it": {
            "rating": 1125.4440017369175,
            "rating_q975": 1142.6634902516548,
            "rating_q025": 1108.2245132221801
        },
        "reka-flash-21b-20240226": {
            "rating": 1124.302868470905,
            "rating_q975": 1152.849627707796,
            "rating_q025": 1095.756109234014
        },
        "phi-3-medium-4k-instruct": {
            "rating": 1121.8670825422882,
            "rating_q975": 1145.025168237216,
            "rating_q025": 1098.7089968473606
        },
        "mixtral-8x22b-instruct-v0.1": {
            "rating": 1115.2349206782194,
            "rating_q975": 1135.2387723121005,
            "rating_q025": 1095.2310690443383
        },
        "gemini-pro-dev-api": {
            "rating": 1110.6258250082437,
            "rating_q975": 1155.490201130199,
            "rating_q025": 1065.7614488862885
        },
        "qwen1.5-32b-chat": {
            "rating": 1107.0444764065257,
            "rating_q975": 1140.0331680046015,
            "rating_q025": 1074.05578480845
        },
        "llama-3.1-8b-instruct": {
            "rating": 1093.539792047829,
            "rating_q975": 1111.2890002754561,
            "rating_q025": 1075.7905838202018
        },
        "qwen1.5-14b-chat": {
            "rating": 1091.6476973273197,
            "rating_q975": 1131.4459199396777,
            "rating_q025": 1051.8494747149618
        },
        "llama-3-70b-instruct": {
            "rating": 1088.4347564075647,
            "rating_q975": 1102.3449966954474,
            "rating_q025": 1074.524516119682
        },
        "mistral-large-2402": {
            "rating": 1087.0470082120546,
            "rating_q975": 1108.3859991839397,
            "rating_q025": 1065.7080172401695
        },
        "dbrx-instruct-preview": {
            "rating": 1084.8320786858676,
            "rating_q975": 1114.4371508007637,
            "rating_q025": 1055.2270065709715
        },
        "jamba-1.5-mini": {
            "rating": 1083.3759133352078,
            "rating_q975": 1118.3232883027065,
            "rating_q025": 1048.428538367709
        },
        "yi-1.5-34b-chat": {
            "rating": 1083.35495823453,
            "rating_q975": 1110.0230539700735,
            "rating_q025": 1056.6868624989863
        },
        "mistral-medium": {
            "rating": 1078.4303589480223,
            "rating_q975": 1111.6079506084993,
            "rating_q025": 1045.2527672875453
        },
        "yi-34b-chat": {
            "rating": 1063.557126177919,
            "rating_q975": 1106.3127808669192,
            "rating_q025": 1020.8014714889188
        },
        "gemma-1.1-7b-it": {
            "rating": 1054.8273532585638,
            "rating_q975": 1083.7863716757813,
            "rating_q025": 1025.8683348413463
        },
        "snowflake-arctic-instruct": {
            "rating": 1049.8497863544274,
            "rating_q975": 1073.9048511876026,
            "rating_q025": 1025.794721521252
        },
        "starling-lm-7b-beta": {
            "rating": 1047.8380786648784,
            "rating_q975": 1091.45422218208,
            "rating_q025": 1004.2219351476767
        },
        "llama-3-8b-instruct": {
            "rating": 1041.5762496510206,
            "rating_q975": 1057.9566547925494,
            "rating_q025": 1025.1958445094917
        },
        "phi-3-small-8k-instruct": {
            "rating": 1040.4135856411174,
            "rating_q975": 1071.150183481868,
            "rating_q025": 1009.6769878003669
        },
        "phi-3-mini-4k-instruct-june-2024": {
            "rating": 1033.221414190652,
            "rating_q975": 1065.7951411707475,
            "rating_q025": 1000.6476872105567
        },
        "vicuna-33b": {
            "rating": 1030.911464118001,
            "rating_q975": 1071.8365722465085,
            "rating_q025": 989.9863559894936
        },
        "mixtral-8x7b-instruct-v0.1": {
            "rating": 1009.7717325267297,
            "rating_q975": 1031.123589652246,
            "rating_q025": 988.4198754012134
        },
        "vicuna-13b": {
            "rating": 1008.0642667604637,
            "rating_q975": 1060.8100378248203,
            "rating_q025": 955.3184956961072
        },
        "phi-3-mini-4k-instruct": {
            "rating": 1006.4976203901259,
            "rating_q975": 1039.8741809904432,
            "rating_q025": 973.1210597898086
        },
        "llama-2-70b-chat": {
            "rating": 997.0992234344722,
            "rating_q975": 1029.7224441467692,
            "rating_q025": 964.4760027221749
        },
        "phi-3-mini-128k-instruct": {
            "rating": 987.4425839624025,
            "rating_q975": 1018.7046976491476,
            "rating_q025": 956.1804702756574
        },
        "llama-2-13b-chat": {
            "rating": 967.903305517062,
            "rating_q975": 1016.9241355442547,
            "rating_q025": 918.8824754898693
        },
        "mistral-7b-instruct-v0.2": {
            "rating": 950.9698266385838,
            "rating_q975": 997.2381056109122,
            "rating_q025": 904.7015476662554
        }
    },
    "korean": {
        "gemini-2.5-pro": {
            "rating": 1425.7597880808003,
            "rating_q975": 1444.6277581782185,
            "rating_q025": 1406.891817983382
        },
        "claude-opus-4-1-20250805-thinking-16k": {
            "rating": 1408.106999998163,
            "rating_q975": 1432.0035669840693,
            "rating_q025": 1384.2104330122568
        },
        "gpt-4.5-preview-2025-02-27": {
            "rating": 1405.897153413819,
            "rating_q975": 1448.439428904845,
            "rating_q025": 1363.354877922793
        },
        "o1-2024-12-17": {
            "rating": 1403.175142872765,
            "rating_q975": 1433.1027799537987,
            "rating_q025": 1373.2475057917313
        },
        "claude-sonnet-4-5-20250929-thinking-32k": {
            "rating": 1398.5408921879523,
            "rating_q975": 1437.1258930722922,
            "rating_q025": 1359.9558913036124
        },
        "chatgpt-4o-latest-20250326": {
            "rating": 1398.4745340290576,
            "rating_q975": 1420.4549022543513,
            "rating_q025": 1376.494165803764
        },
        "gpt-5-high": {
            "rating": 1397.4091494204501,
            "rating_q975": 1421.6937211140032,
            "rating_q025": 1373.124577726897
        },
        "claude-opus-4-1-20250805": {
            "rating": 1388.3427037167703,
            "rating_q975": 1409.1952698472176,
            "rating_q025": 1367.490137586323
        },
        "o3-2025-04-16": {
            "rating": 1383.7852339293693,
            "rating_q975": 1403.194836460608,
            "rating_q025": 1364.3756313981305
        },
        "glm-4.6": {
            "rating": 1378.1750463167082,
            "rating_q975": 1421.1469425446287,
            "rating_q025": 1335.2031500887877
        },
        "gemini-2.5-flash-preview-09-2025": {
            "rating": 1377.7724909005206,
            "rating_q975": 1412.0985589860584,
            "rating_q025": 1343.4464228149827
        },
        "hunyuan-t1-20250711": {
            "rating": 1374.7779028702473,
            "rating_q975": 1418.9923906778831,
            "rating_q025": 1330.5634150626115
        },
        "qwen3-max-preview": {
            "rating": 1373.1979347656757,
            "rating_q975": 1398.5009388108374,
            "rating_q025": 1347.894930720514
        },
        "grok-4-0709": {
            "rating": 1370.9716004825427,
            "rating_q975": 1394.5934701663184,
            "rating_q025": 1347.349730798767
        },
        "gpt-5-chat": {
            "rating": 1370.1755473063795,
            "rating_q975": 1393.8984128673706,
            "rating_q025": 1346.4526817453884
        },
        "claude-opus-4-20250514-thinking-16k": {
            "rating": 1369.7581972655414,
            "rating_q975": 1393.1178936204387,
            "rating_q025": 1346.398500910644
        },
        "qwen3-vl-235b-a22b-instruct": {
            "rating": 1369.6306707999386,
            "rating_q975": 1407.3263723674272,
            "rating_q025": 1331.93496923245
        },
        "gpt-4.1-2025-04-14": {
            "rating": 1369.012599031628,
            "rating_q975": 1389.3949875500487,
            "rating_q025": 1348.6302105132074
        },
        "gemini-2.5-flash": {
            "rating": 1365.9039352853667,
            "rating_q975": 1384.881790984121,
            "rating_q025": 1346.9260795866126
        },
        "qwen3-235b-a22b-instruct-2507": {
            "rating": 1365.4937987998567,
            "rating_q975": 1388.1168840903053,
            "rating_q025": 1342.870713509408
        },
        "qwen3-max-2025-09-23": {
            "rating": 1363.5228276909756,
            "rating_q975": 1401.144538101484,
            "rating_q025": 1325.9011172804674
        },
        "claude-opus-4-20250514": {
            "rating": 1358.7276955767265,
            "rating_q975": 1378.7071007209258,
            "rating_q025": 1338.7482904325273
        },
        "qwen3-235b-a22b-no-thinking": {
            "rating": 1358.040908461595,
            "rating_q975": 1382.0274132739964,
            "rating_q025": 1334.0544036491938
        },
        "gemini-2.5-flash-lite-preview-06-17-thinking": {
            "rating": 1357.9809061168405,
            "rating_q975": 1381.6853924153409,
            "rating_q025": 1334.2764198183402
        },
        "gemini-2.5-flash-lite-preview-09-2025-no-thinking": {
            "rating": 1355.5215859462708,
            "rating_q975": 1391.3880254199535,
            "rating_q025": 1319.655146472588
        },
        "qwen3-vl-235b-a22b-thinking": {
            "rating": 1352.775355998185,
            "rating_q975": 1393.8833310996863,
            "rating_q025": 1311.6673808966837
        },
        "o4-mini-2025-04-16": {
            "rating": 1349.8866075539318,
            "rating_q975": 1370.547388953725,
            "rating_q025": 1329.2258261541385
        },
        "glm-4.5": {
            "rating": 1348.7604771152567,
            "rating_q975": 1374.0425865154377,
            "rating_q025": 1323.4783677150756
        },
        "deepseek-r1": {
            "rating": 1346.1435341242159,
            "rating_q975": 1385.3419558248186,
            "rating_q025": 1306.9451124236132
        },
        "claude-sonnet-4-20250514": {
            "rating": 1345.1645971549779,
            "rating_q975": 1366.2087980813096,
            "rating_q025": 1324.120396228646
        },
        "hunyuan-turbos-20250416": {
            "rating": 1344.3306807951158,
            "rating_q975": 1395.4801428517308,
            "rating_q025": 1293.1812187385008
        },
        "grok-3-preview-02-24": {
            "rating": 1343.5990537772045,
            "rating_q975": 1371.1674618130753,
            "rating_q025": 1316.0306457413337
        },
        "mistral-medium-2508": {
            "rating": 1342.6186126869325,
            "rating_q975": 1363.9879254521893,
            "rating_q025": 1321.2492999216756
        },
        "qwen3-235b-a22b-thinking-2507": {
            "rating": 1340.7300579981359,
            "rating_q975": 1383.0966395388114,
            "rating_q025": 1298.3634764574604
        },
        "o1-preview": {
            "rating": 1340.1285494308647,
            "rating_q975": 1367.2846558545862,
            "rating_q025": 1312.9724430071433
        },
        "deepseek-v3.2-exp-thinking": {
            "rating": 1338.707497680554,
            "rating_q975": 1383.1458722835819,
            "rating_q025": 1294.2691230775263
        },
        "gpt-4.1-mini-2025-04-14": {
            "rating": 1338.5004838008126,
            "rating_q975": 1360.9536251850288,
            "rating_q025": 1316.0473424165964
        },
        "gemini-2.0-flash-lite-preview-02-05": {
            "rating": 1337.2439626177372,
            "rating_q975": 1367.9839078811672,
            "rating_q025": 1306.5040173543073
        },
        "kimi-k2-0905-preview": {
            "rating": 1336.2801720835726,
            "rating_q975": 1373.6585826978499,
            "rating_q025": 1298.9017614692953
        },
        "deepseek-v3.1-thinking": {
            "rating": 1336.1731091654535,
            "rating_q975": 1368.8110772995344,
            "rating_q025": 1303.5351410313726
        },
        "grok-4-fast": {
            "rating": 1334.8320916005755,
            "rating_q975": 1375.6771885545902,
            "rating_q025": 1293.9869946465608
        },
        "deepseek-v3.1": {
            "rating": 1333.6662706096524,
            "rating_q975": 1361.2098577649706,
            "rating_q025": 1306.1226834543343
        },
        "amazon-nova-experimental-chat-10-09": {
            "rating": 1331.9125965539567,
            "rating_q975": 1388.3757620447204,
            "rating_q025": 1275.449431063193
        },
        "claude-sonnet-4-20250514-thinking-32k": {
            "rating": 1331.072964348267,
            "rating_q975": 1354.6920261746768,
            "rating_q025": 1307.4539025218573
        },
        "claude-haiku-4-5-20251001": {
            "rating": 1329.3701065785037,
            "rating_q975": 1375.6340465971448,
            "rating_q025": 1283.1061665598627
        },
        "deepseek-r1-0528": {
            "rating": 1329.0210693156544,
            "rating_q975": 1364.4002153451104,
            "rating_q025": 1293.6419232861983
        },
        "kimi-k2-0711-preview": {
            "rating": 1328.6447509610289,
            "rating_q975": 1353.8910775919462,
            "rating_q025": 1303.3984243301115
        },
        "mai-1-preview": {
            "rating": 1328.3334462974005,
            "rating_q975": 1356.328113856668,
            "rating_q025": 1300.338778738133
        },
        "grok-3-mini-high": {
            "rating": 1327.2490845210443,
            "rating_q975": 1361.510212324962,
            "rating_q025": 1292.9879567171267
        },
        "gpt-5-mini-high": {
            "rating": 1326.4402842282964,
            "rating_q975": 1352.8508569794767,
            "rating_q025": 1300.029711477116
        },
        "o3-mini-high": {
            "rating": 1323.7466039799926,
            "rating_q975": 1363.1371593107938,
            "rating_q025": 1284.3560486491915
        },
        "claude-3-7-sonnet-20250219-thinking-32k": {
            "rating": 1323.0889548300067,
            "rating_q975": 1345.7642016694995,
            "rating_q025": 1300.413707990514
        },
        "gemini-1.5-pro-002": {
            "rating": 1320.8528870751393,
            "rating_q975": 1342.604646888764,
            "rating_q025": 1299.1011272615146
        },
        "qwen3-235b-a22b": {
            "rating": 1319.1458363713234,
            "rating_q975": 1346.2125475606942,
            "rating_q025": 1292.0791251819526
        },
        "deepseek-v3-0324": {
            "rating": 1316.867891728814,
            "rating_q975": 1337.3749054501902,
            "rating_q025": 1296.3608780074376
        },
        "gemma-3-27b-it": {
            "rating": 1315.116596579097,
            "rating_q975": 1336.2993422160416,
            "rating_q025": 1293.9338509421523
        },
        "longcat-flash-chat": {
            "rating": 1314.9676447365923,
            "rating_q975": 1350.6725635815897,
            "rating_q025": 1279.262725891595
        },
        "qwen3-next-80b-a3b-instruct": {
            "rating": 1312.724962700624,
            "rating_q975": 1343.6294771432817,
            "rating_q025": 1281.8204482579663
        },
        "qwen3-30b-a3b-instruct-2507": {
            "rating": 1310.6396915319615,
            "rating_q975": 1337.0822959197787,
            "rating_q025": 1284.1970871441442
        },
        "qwen2.5-max": {
            "rating": 1309.7471015303058,
            "rating_q975": 1336.6104359199915,
            "rating_q025": 1282.8837671406202
        },
        "command-a-03-2025": {
            "rating": 1307.7010407631308,
            "rating_q975": 1327.141718656772,
            "rating_q025": 1288.2603628694897
        },
        "qwen3-coder-480b-a35b-instruct": {
            "rating": 1307.300838227727,
            "rating_q975": 1334.9678138099946,
            "rating_q025": 1279.6338626454592
        },
        "mistral-medium-2505": {
            "rating": 1301.4360777749628,
            "rating_q975": 1325.43551683563,
            "rating_q025": 1277.4366387142954
        },
        "claude-3-5-sonnet-20241022": {
            "rating": 1296.498082646017,
            "rating_q975": 1314.0217418879693,
            "rating_q025": 1278.974423404065
        },
        "qwen3-next-80b-a3b-thinking": {
            "rating": 1290.3625392898107,
            "rating_q975": 1325.64225178692,
            "rating_q025": 1255.0828267927013
        },
        "gpt-4o-2024-05-13": {
            "rating": 1290.163980793597,
            "rating_q975": 1304.792946766039,
            "rating_q025": 1275.5350148211548
        },
        "ling-flash-2.0": {
            "rating": 1289.0105110565821,
            "rating_q975": 1329.7892149232514,
            "rating_q025": 1248.2318071899128
        },
        "o3-mini": {
            "rating": 1288.211035491575,
            "rating_q975": 1306.9536887967674,
            "rating_q025": 1269.4683821863828
        },
        "gpt-4o-2024-08-06": {
            "rating": 1285.206252926394,
            "rating_q975": 1307.9226356569577,
            "rating_q025": 1262.4898701958302
        },
        "grok-3-mini-beta": {
            "rating": 1283.6664264955084,
            "rating_q975": 1313.1126252396732,
            "rating_q025": 1254.2202277513436
        },
        "claude-3-5-sonnet-20240620": {
            "rating": 1281.823537043459,
            "rating_q975": 1298.9997955046613,
            "rating_q025": 1264.6472785822568
        },
        "glm-4.5-air": {
            "rating": 1280.9803422152972,
            "rating_q975": 1307.372329353479,
            "rating_q025": 1254.5883550771155
        },
        "gpt-oss-20b": {
            "rating": 1280.190235761629,
            "rating_q975": 1321.0113446662765,
            "rating_q025": 1239.3691268569817
        },
        "gemini-advanced-0514": {
            "rating": 1278.720617766257,
            "rating_q975": 1297.0615896918641,
            "rating_q025": 1260.3796458406498
        },
        "glm-4-plus": {
            "rating": 1276.1208616147644,
            "rating_q975": 1306.1650960243048,
            "rating_q025": 1246.076627205224
        },
        "deepseek-v3": {
            "rating": 1274.8956865222221,
            "rating_q975": 1308.6351397520996,
            "rating_q025": 1241.1562332923447
        },
        "grok-2-2024-08-13": {
            "rating": 1271.3054199499318,
            "rating_q975": 1291.2113973365595,
            "rating_q025": 1251.399442563304
        },
        "mistral-small-2506": {
            "rating": 1270.8271832732992,
            "rating_q975": 1303.2077399213672,
            "rating_q025": 1238.4466266252311
        },
        "gemma-3n-e4b-it": {
            "rating": 1269.9643097589055,
            "rating_q975": 1297.4035937713609,
            "rating_q025": 1242.5250257464502
        },
        "llama-4-scout-17b-16e-instruct": {
            "rating": 1268.3385860417275,
            "rating_q975": 1293.9503494677956,
            "rating_q025": 1242.7268226156593
        },
        "claude-3-opus-20240229": {
            "rating": 1266.164408574226,
            "rating_q975": 1280.4401346891225,
            "rating_q025": 1251.8886824593294
        },
        "gemini-1.5-pro-001": {
            "rating": 1266.0279535986483,
            "rating_q975": 1282.2437083062,
            "rating_q025": 1249.8121988910966
        },
        "gpt-5-nano-high": {
            "rating": 1260.4595258358327,
            "rating_q975": 1303.6769030808532,
            "rating_q025": 1217.2421485908121
        },
        "llama-4-maverick-17b-128e-instruct": {
            "rating": 1259.9502658892789,
            "rating_q975": 1281.8651908207637,
            "rating_q025": 1238.035340957794
        },
        "qwen3-30b-a3b": {
            "rating": 1257.9319077031535,
            "rating_q975": 1285.8080238998627,
            "rating_q025": 1230.0557915064442
        },
        "gpt-oss-120b": {
            "rating": 1257.809483652924,
            "rating_q975": 1283.9753382354288,
            "rating_q025": 1231.6436290704191
        },
        "qwq-32b": {
            "rating": 1257.2344459453784,
            "rating_q975": 1287.1234373461941,
            "rating_q025": 1227.3454545445627
        },
        "gpt-4-turbo-2024-04-09": {
            "rating": 1256.9369099283028,
            "rating_q975": 1272.8338380213554,
            "rating_q025": 1241.0399818352503
        },
        "claude-3-5-haiku-20241022": {
            "rating": 1256.6161373121045,
            "rating_q975": 1275.2636156014341,
            "rating_q025": 1237.9686590227748
        },
        "minimax-m1": {
            "rating": 1255.4486381432584,
            "rating_q975": 1280.8612736513023,
            "rating_q025": 1230.0360026352146
        },
        "mistral-large-2411": {
            "rating": 1254.6406628917366,
            "rating_q975": 1282.430334890669,
            "rating_q025": 1226.8509908928042
        },
        "llama-3.1-405b-instruct-fp8": {
            "rating": 1252.699286551253,
            "rating_q975": 1272.4931989904458,
            "rating_q025": 1232.9053741120601
        },
        "o1-mini": {
            "rating": 1248.8860260250644,
            "rating_q975": 1270.7938099156718,
            "rating_q025": 1226.978242134457
        },
        "gpt-4-1106-preview": {
            "rating": 1247.9578505337543,
            "rating_q975": 1266.7092352684542,
            "rating_q025": 1229.2064657990543
        },
        "deepseek-v2.5": {
            "rating": 1246.9022846902826,
            "rating_q975": 1277.7664286835784,
            "rating_q025": 1216.0381406969868
        },
        "command-r-08-2024": {
            "rating": 1246.2768863670658,
            "rating_q975": 1295.2627883551115,
            "rating_q025": 1197.29098437902
        },
        "gemini-1.5-flash-001": {
            "rating": 1241.8428892483441,
            "rating_q975": 1258.4337598156303,
            "rating_q025": 1225.252018681058
        },
        "step-3": {
            "rating": 1241.6293656001524,
            "rating_q975": 1286.9697240290825,
            "rating_q025": 1196.2890071712222
        },
        "gpt-4-0125-preview": {
            "rating": 1241.2259299899652,
            "rating_q975": 1259.7263672629567,
            "rating_q025": 1222.7254927169736
        },
        "llama-3.1-405b-instruct-bf16": {
            "rating": 1236.4524292384158,
            "rating_q975": 1260.3024256525105,
            "rating_q025": 1212.602432824321
        },
        "mistral-small-24b-instruct-2501": {
            "rating": 1236.4443466477503,
            "rating_q975": 1274.9841706817501,
            "rating_q025": 1197.9045226137505
        },
        "gpt-4o-mini-2024-07-18": {
            "rating": 1234.9720315749946,
            "rating_q975": 1253.5456291517696,
            "rating_q025": 1216.3984339982196
        },
        "gemini-1.5-flash-002": {
            "rating": 1234.7049622236505,
            "rating_q975": 1260.7880013845142,
            "rating_q025": 1208.6219230627867
        },
        "ring-flash-2.0": {
            "rating": 1234.085255559708,
            "rating_q975": 1276.3935697047348,
            "rating_q025": 1191.7769414146812
        },
        "mistral-small-3.1-24b-instruct-2503": {
            "rating": 1231.9600134133702,
            "rating_q975": 1257.1786851521663,
            "rating_q025": 1206.7413416745742
        },
        "gemma-2-27b-it": {
            "rating": 1229.3703711781595,
            "rating_q975": 1246.1016462247924,
            "rating_q025": 1212.6390961315267
        },
        "yi-lightning": {
            "rating": 1228.522162300514,
            "rating_q975": 1257.2239921479165,
            "rating_q025": 1199.8203324531116
        },
        "amazon-nova-pro-v1.0": {
            "rating": 1226.2228212400305,
            "rating_q975": 1257.2688506548197,
            "rating_q025": 1195.1767918252413
        },
        "qwen2.5-72b-instruct": {
            "rating": 1225.320357756445,
            "rating_q975": 1251.1141947105718,
            "rating_q025": 1199.5265208023181
        },
        "mistral-large-2407": {
            "rating": 1225.3103072255703,
            "rating_q975": 1247.0707178130763,
            "rating_q025": 1203.5498966380644
        },
        "athene-v2-chat": {
            "rating": 1225.0087687941555,
            "rating_q975": 1256.6790810639195,
            "rating_q025": 1193.3384565243914
        },
        "grok-2-mini-2024-08-13": {
            "rating": 1224.6758714160014,
            "rating_q975": 1245.975395022497,
            "rating_q025": 1203.376347809506
        },
        "claude-3-sonnet-20240229": {
            "rating": 1219.4872535235932,
            "rating_q975": 1236.4847894708664,
            "rating_q025": 1202.48971757632
        },
        "nemotron-4-340b-instruct": {
            "rating": 1217.2559112200313,
            "rating_q975": 1241.9852354497232,
            "rating_q025": 1192.5265869903394
        },
        "command-r-plus": {
            "rating": 1211.580350429762,
            "rating_q975": 1229.1886794936854,
            "rating_q025": 1193.9720213658384
        },
        "llama-3.3-70b-instruct": {
            "rating": 1206.9780107460942,
            "rating_q975": 1227.3674790949526,
            "rating_q025": 1186.5885423972359
        },
        "athene-70b-0725": {
            "rating": 1206.5154086070452,
            "rating_q975": 1236.3697218357368,
            "rating_q025": 1176.6610953783536
        },
        "claude-3-haiku-20240307": {
            "rating": 1205.3841743567168,
            "rating_q975": 1221.5962501778106,
            "rating_q025": 1189.172098535623
        },
        "c4ai-aya-expanse-32b": {
            "rating": 1204.3569277775719,
            "rating_q975": 1233.1878482394682,
            "rating_q025": 1175.5260073156755
        },
        "magistral-medium-2506": {
            "rating": 1203.3900444374,
            "rating_q975": 1251.6982415518132,
            "rating_q025": 1155.081847322987
        },
        "deepseek-coder-v2": {
            "rating": 1197.3580535652086,
            "rating_q975": 1227.225667419531,
            "rating_q025": 1167.4904397108862
        },
        "gemma-2-9b-it": {
            "rating": 1195.716167582293,
            "rating_q975": 1214.4880568213352,
            "rating_q025": 1176.944278343251
        },
        "gpt-4-0314": {
            "rating": 1192.1146392598007,
            "rating_q975": 1221.577929007903,
            "rating_q025": 1162.6513495116983
        },
        "phi-4": {
            "rating": 1190.4868431616758,
            "rating_q975": 1223.137196070699,
            "rating_q025": 1157.8364902526525
        },
        "reka-flash-21b-20240226-online": {
            "rating": 1186.6396322077012,
            "rating_q975": 1220.1563565007164,
            "rating_q025": 1153.122907914686
        },
        "amazon-nova-micro-v1.0": {
            "rating": 1186.5555004313899,
            "rating_q975": 1221.2659105874322,
            "rating_q025": 1151.8450902753475
        },
        "llama-3.1-70b-instruct": {
            "rating": 1185.7854641437925,
            "rating_q975": 1206.4627779596979,
            "rating_q025": 1165.1081503278872
        },
        "qwen-max-0919": {
            "rating": 1185.5254455987715,
            "rating_q975": 1219.8656793590555,
            "rating_q025": 1151.1852118384875
        },
        "command-r": {
            "rating": 1182.2741129092426,
            "rating_q975": 1201.883949205957,
            "rating_q025": 1162.6642766125283
        },
        "gemini-1.5-flash-8b-001": {
            "rating": 1181.534692047447,
            "rating_q975": 1207.743661685175,
            "rating_q025": 1155.3257224097188
        },
        "amazon-nova-lite-v1.0": {
            "rating": 1179.64698562858,
            "rating_q975": 1213.0842954542072,
            "rating_q025": 1146.209675802953
        },
        "gpt-4-0613": {
            "rating": 1172.308322833707,
            "rating_q975": 1192.3408093291953,
            "rating_q025": 1152.2758363382188
        },
        "qwen2-72b-instruct": {
            "rating": 1169.5036028436555,
            "rating_q975": 1188.7404732473813,
            "rating_q025": 1150.2667324399297
        },
        "reka-flash-21b-20240226": {
            "rating": 1155.7502128253304,
            "rating_q975": 1180.5715106649027,
            "rating_q025": 1130.9289149857582
        },
        "gpt-3.5-turbo-0125": {
            "rating": 1150.3255645957092,
            "rating_q975": 1170.2323107177158,
            "rating_q025": 1130.4188184737027
        },
        "mixtral-8x22b-instruct-v0.1": {
            "rating": 1140.8433772202459,
            "rating_q975": 1160.4815140502762,
            "rating_q025": 1121.2052403902155
        },
        "qwen1.5-72b-chat": {
            "rating": 1134.0542850853465,
            "rating_q975": 1160.4407932492845,
            "rating_q025": 1107.6677769214084
        },
        "qwen1.5-110b-chat": {
            "rating": 1122.299559100768,
            "rating_q975": 1141.1757850658555,
            "rating_q025": 1103.4233331356804
        },
        "mistral-large-2402": {
            "rating": 1107.7075850115025,
            "rating_q975": 1128.600348637931,
            "rating_q025": 1086.814821385074
        },
        "dbrx-instruct-preview": {
            "rating": 1107.202094216961,
            "rating_q975": 1136.1250710892077,
            "rating_q025": 1078.2791173447145
        },
        "llama-3-70b-instruct": {
            "rating": 1106.5098240633474,
            "rating_q975": 1120.8340180036337,
            "rating_q025": 1092.1856301230612
        },
        "mistral-medium": {
            "rating": 1102.244377205545,
            "rating_q975": 1137.0884800297522,
            "rating_q025": 1067.400274381338
        },
        "glm-4-0520": {
            "rating": 1100.138374699519,
            "rating_q975": 1134.7855083529053,
            "rating_q025": 1065.491241046133
        },
        "qwen1.5-32b-chat": {
            "rating": 1095.9955737082846,
            "rating_q975": 1126.0458168418618,
            "rating_q025": 1065.9453305747074
        },
        "gemma-1.1-7b-it": {
            "rating": 1094.7158153748514,
            "rating_q975": 1117.2301891125335,
            "rating_q025": 1072.2014416371694
        },
        "llama-3-8b-instruct": {
            "rating": 1093.251459627022,
            "rating_q975": 1109.8379972625667,
            "rating_q025": 1076.6649219914775
        },
        "gemma-2-2b-it": {
            "rating": 1087.9131315007246,
            "rating_q975": 1111.9019560315637,
            "rating_q025": 1063.9243069698855
        },
        "llama-3.1-8b-instruct": {
            "rating": 1086.2165982826878,
            "rating_q975": 1108.1766723119706,
            "rating_q025": 1064.256524253405
        },
        "yi-1.5-34b-chat": {
            "rating": 1078.6351496065663,
            "rating_q975": 1101.3223527191649,
            "rating_q025": 1055.9479464939677
        },
        "mixtral-8x7b-instruct-v0.1": {
            "rating": 1067.6388762098363,
            "rating_q975": 1090.965147268112,
            "rating_q025": 1044.3126051515605
        },
        "snowflake-arctic-instruct": {
            "rating": 1066.22577398461,
            "rating_q975": 1093.420437473684,
            "rating_q025": 1039.031110495536
        },
        "llama-2-70b-chat": {
            "rating": 1060.0491970858134,
            "rating_q975": 1097.706589613715,
            "rating_q025": 1022.3918045579117
        },
        "llama-2-13b-chat": {
            "rating": 1050.924379351633,
            "rating_q975": 1097.6215411442147,
            "rating_q025": 1004.2272175590513
        },
        "yi-34b-chat": {
            "rating": 1040.1120816049824,
            "rating_q975": 1079.5021705077747,
            "rating_q025": 1000.7219927021902
        },
        "phi-3-medium-4k-instruct": {
            "rating": 1034.4952479527192,
            "rating_q975": 1057.683953095115,
            "rating_q025": 1011.3065428103233
        },
        "gemma-1.1-2b-it": {
            "rating": 1004.5224008411358,
            "rating_q975": 1035.550353647465,
            "rating_q025": 973.4944480348064
        },
        "phi-3-small-8k-instruct": {
            "rating": 989.6878465025354,
            "rating_q975": 1012.6566495888782,
            "rating_q025": 966.7190434161927
        },
        "phi-3-mini-4k-instruct": {
            "rating": 978.2126801235621,
            "rating_q975": 1000.4671651283071,
            "rating_q025": 955.9581951188171
        },
        "phi-3-mini-4k-instruct-june-2024": {
            "rating": 962.5431307579445,
            "rating_q975": 1000.4732074333864,
            "rating_q025": 924.6130540825026
        },
        "phi-3-mini-128k-instruct": {
            "rating": 959.7953027942967,
            "rating_q975": 996.310324364115,
            "rating_q025": 923.2802812244785
        }
    },
    "long_user": {
        "claude-opus-4-1-20250805-thinking-16k": {
            "rating": 1483.0322622833214,
            "rating_q975": 1491.5476159414716,
            "rating_q025": 1474.5169086251713
        },
        "claude-sonnet-4-5-20250929-thinking-32k": {
            "rating": 1480.4068767607441,
            "rating_q975": 1492.4455599707833,
            "rating_q025": 1468.368193550705
        },
        "claude-opus-4-1-20250805": {
            "rating": 1465.5739644894804,
            "rating_q975": 1473.1953769442027,
            "rating_q025": 1457.9525520347581
        },
        "claude-sonnet-4-5-20250929": {
            "rating": 1461.7816776538257,
            "rating_q975": 1477.4602839196666,
            "rating_q025": 1446.1030713879848
        },
        "gemini-2.5-pro": {
            "rating": 1459.1945954918046,
            "rating_q975": 1465.9195133898183,
            "rating_q025": 1452.469677593791
        },
        "claude-opus-4-20250514-thinking-16k": {
            "rating": 1459.0676276401687,
            "rating_q975": 1466.9413034488705,
            "rating_q025": 1451.1939518314668
        },
        "deepseek-v3.1-thinking": {
            "rating": 1445.5167111881508,
            "rating_q975": 1457.5801844040789,
            "rating_q025": 1433.4532379722227
        },
        "qwen3-max-preview": {
            "rating": 1445.4187550620832,
            "rating_q975": 1454.3114518843543,
            "rating_q025": 1436.526058239812
        },
        "claude-opus-4-20250514": {
            "rating": 1441.4781562670219,
            "rating_q975": 1448.794845170667,
            "rating_q025": 1434.1614673633767
        },
        "gpt-4.5-preview-2025-02-27": {
            "rating": 1441.2123347775332,
            "rating_q975": 1454.7268597040402,
            "rating_q025": 1427.6978098510262
        },
        "chatgpt-4o-latest-20250326": {
            "rating": 1438.1277518661161,
            "rating_q975": 1445.2257389983217,
            "rating_q025": 1431.0297647339105
        },
        "deepseek-v3.1-terminus-thinking": {
            "rating": 1438.1183751899302,
            "rating_q975": 1460.7280940268136,
            "rating_q025": 1415.508656353047
        },
        "claude-sonnet-4-20250514-thinking-32k": {
            "rating": 1437.369968976514,
            "rating_q975": 1445.16089397143,
            "rating_q025": 1429.579043981598
        },
        "claude-haiku-4-5-20251001": {
            "rating": 1437.3477920780078,
            "rating_q975": 1449.9052428007499,
            "rating_q025": 1424.7903413552658
        },
        "glm-4.6": {
            "rating": 1436.2161913400723,
            "rating_q975": 1448.7866916075095,
            "rating_q025": 1423.6456910726351
        },
        "gpt-5-chat": {
            "rating": 1434.8947822231667,
            "rating_q975": 1443.218800260902,
            "rating_q025": 1426.5707641854312
        },
        "qwen3-max-2025-09-23": {
            "rating": 1433.8791599932974,
            "rating_q975": 1446.8840923767677,
            "rating_q025": 1420.8742276098271
        },
        "deepseek-v3.2-exp-thinking": {
            "rating": 1431.2023957720266,
            "rating_q975": 1444.3761513490608,
            "rating_q025": 1418.0286401949925
        },
        "qwen3-235b-a22b-instruct-2507": {
            "rating": 1431.0753057008496,
            "rating_q975": 1438.7713500174814,
            "rating_q025": 1423.379261384218
        },
        "grok-3-preview-02-24": {
            "rating": 1427.9826056248896,
            "rating_q975": 1436.6654824566467,
            "rating_q025": 1419.2997287931325
        },
        "claude-3-7-sonnet-20250219-thinking-32k": {
            "rating": 1423.8054720093853,
            "rating_q975": 1431.734881631172,
            "rating_q025": 1415.8760623875987
        },
        "deepseek-v3.1": {
            "rating": 1423.4853460210518,
            "rating_q975": 1434.17148803229,
            "rating_q025": 1412.7992040098136
        },
        "grok-4-fast": {
            "rating": 1423.0653414591516,
            "rating_q975": 1438.4490314446814,
            "rating_q025": 1407.6816514736217
        },
        "gpt-4.1-2025-04-14": {
            "rating": 1422.7234081580777,
            "rating_q975": 1429.6373589651228,
            "rating_q025": 1415.8094573510327
        },
        "qwen3-vl-235b-a22b-instruct": {
            "rating": 1421.9595550746033,
            "rating_q975": 1435.5666520438447,
            "rating_q025": 1408.3524581053618
        },
        "glm-4.5": {
            "rating": 1421.613327445411,
            "rating_q975": 1430.52988691826,
            "rating_q025": 1412.696767972562
        },
        "gemini-2.5-flash": {
            "rating": 1421.45900971604,
            "rating_q975": 1428.138305988928,
            "rating_q025": 1414.779713443152
        },
        "claude-sonnet-4-20250514": {
            "rating": 1421.3848816830964,
            "rating_q975": 1428.8371057305358,
            "rating_q025": 1413.932657635657
        },
        "gemini-2.5-flash-preview-09-2025": {
            "rating": 1420.3482003430454,
            "rating_q975": 1431.140229753618,
            "rating_q025": 1409.5561709324727
        },
        "grok-4-0709": {
            "rating": 1418.7617921244644,
            "rating_q975": 1426.3871594361672,
            "rating_q025": 1411.1364248127616
        },
        "deepseek-v3.1-terminus": {
            "rating": 1416.4000467504088,
            "rating_q975": 1436.47440461556,
            "rating_q025": 1396.3256888852577
        },
        "gpt-5-high": {
            "rating": 1414.0459498418795,
            "rating_q975": 1422.643627643851,
            "rating_q025": 1405.448272039908
        },
        "o3-2025-04-16": {
            "rating": 1409.2757767474284,
            "rating_q975": 1415.944467983313,
            "rating_q025": 1402.6070855115438
        },
        "mistral-medium-2508": {
            "rating": 1409.0278154839643,
            "rating_q975": 1417.1292729445945,
            "rating_q025": 1400.9263580233342
        },
        "o1-2024-12-17": {
            "rating": 1409.011310211387,
            "rating_q975": 1418.6156181541173,
            "rating_q025": 1399.4070022686565
        },
        "deepseek-r1-0528": {
            "rating": 1407.0826544495123,
            "rating_q975": 1417.7732307822812,
            "rating_q025": 1396.3920781167435
        },
        "qwen3-235b-a22b-no-thinking": {
            "rating": 1406.0230522093789,
            "rating_q975": 1413.7273990328645,
            "rating_q025": 1398.3187053858933
        },
        "qwen3-coder-480b-a35b-instruct": {
            "rating": 1404.7915078204605,
            "rating_q975": 1413.8410038810484,
            "rating_q025": 1395.7420117598726
        },
        "qwen3-vl-235b-a22b-thinking": {
            "rating": 1404.5971405545174,
            "rating_q975": 1418.626221252936,
            "rating_q025": 1390.568059856099
        },
        "kimi-k2-0905-preview": {
            "rating": 1403.6043735259843,
            "rating_q975": 1416.1573101916217,
            "rating_q025": 1391.051436860347
        },
        "qwen3-235b-a22b-thinking-2507": {
            "rating": 1402.9073800174351,
            "rating_q975": 1417.2640277637297,
            "rating_q025": 1388.5507322711405
        },
        "deepseek-r1": {
            "rating": 1396.0884945657453,
            "rating_q975": 1407.904602518754,
            "rating_q025": 1384.2723866127367
        },
        "qwen3-next-80b-a3b-instruct": {
            "rating": 1394.1076964222748,
            "rating_q975": 1403.630132731285,
            "rating_q025": 1384.5852601132647
        },
        "gemini-2.5-flash-lite-preview-09-2025-no-thinking": {
            "rating": 1393.8780246558558,
            "rating_q975": 1404.6991516594783,
            "rating_q025": 1383.0568976522334
        },
        "mai-1-preview": {
            "rating": 1392.4757748116388,
            "rating_q975": 1402.650006672897,
            "rating_q025": 1382.3015429503805
        },
        "claude-3-5-sonnet-20241022": {
            "rating": 1390.9081255993128,
            "rating_q975": 1396.412033726703,
            "rating_q025": 1385.4042174719227
        },
        "kimi-k2-0711-preview": {
            "rating": 1390.8426410495292,
            "rating_q975": 1399.3443577500025,
            "rating_q025": 1382.340924349056
        },
        "deepseek-v3-0324": {
            "rating": 1390.6919217023992,
            "rating_q975": 1397.624379082637,
            "rating_q025": 1383.7594643221614
        },
        "mistral-medium-2505": {
            "rating": 1389.6210436309304,
            "rating_q975": 1397.7567133669952,
            "rating_q025": 1381.4853738948657
        },
        "longcat-flash-chat": {
            "rating": 1386.456289312192,
            "rating_q975": 1398.7705361060491,
            "rating_q025": 1374.1420425183348
        },
        "gpt-4.1-mini-2025-04-14": {
            "rating": 1386.1885246007696,
            "rating_q975": 1393.8487579520208,
            "rating_q025": 1378.5282912495184
        },
        "hunyuan-t1-20250711": {
            "rating": 1386.0750540787633,
            "rating_q975": 1405.9266011543589,
            "rating_q025": 1366.2235070031677
        },
        "gemini-2.5-flash-lite-preview-06-17-thinking": {
            "rating": 1382.5370830918564,
            "rating_q975": 1390.6463486105397,
            "rating_q025": 1374.4278175731731
        },
        "qwen2.5-max": {
            "rating": 1381.8776257952381,
            "rating_q975": 1390.379174521405,
            "rating_q025": 1373.3760770690712
        },
        "qwen3-30b-a3b-instruct-2507": {
            "rating": 1381.6408210714142,
            "rating_q975": 1390.516138821509,
            "rating_q025": 1372.7655033213193
        },
        "o1-preview": {
            "rating": 1378.8831013684228,
            "rating_q975": 1388.267292664839,
            "rating_q025": 1369.4989100720065
        },
        "qwen3-235b-a22b": {
            "rating": 1378.8705048173465,
            "rating_q975": 1387.7173610646946,
            "rating_q025": 1370.0236485699984
        },
        "glm-4.5-air": {
            "rating": 1378.1952624289213,
            "rating_q975": 1386.4675204380412,
            "rating_q025": 1369.9230044198014
        },
        "hunyuan-turbos-20250416": {
            "rating": 1377.9027042678624,
            "rating_q975": 1392.5071217912337,
            "rating_q025": 1363.2982867444912
        },
        "grok-3-mini-high": {
            "rating": 1377.8081681344547,
            "rating_q975": 1388.1758230171044,
            "rating_q025": 1367.440513251805
        },
        "gpt-5-mini-high": {
            "rating": 1374.653616276514,
            "rating_q975": 1383.9136552228356,
            "rating_q025": 1365.3935773301923
        },
        "hunyuan-large-2025-02-10": {
            "rating": 1373.3123780424394,
            "rating_q975": 1401.7330318068211,
            "rating_q025": 1344.8917242780576
        },
        "deepseek-v3": {
            "rating": 1371.6265882641737,
            "rating_q975": 1381.9432249969109,
            "rating_q025": 1361.3099515314366
        },
        "o3-mini-high": {
            "rating": 1369.647136221005,
            "rating_q975": 1381.6980808202595,
            "rating_q025": 1357.5961916217504
        },
        "qwen3-next-80b-a3b-thinking": {
            "rating": 1368.6683354040747,
            "rating_q975": 1380.0129686654057,
            "rating_q025": 1357.3237021427437
        },
        "minimax-m1": {
            "rating": 1368.1989697856668,
            "rating_q975": 1375.768990443627,
            "rating_q025": 1360.6289491277066
        },
        "command-a-03-2025": {
            "rating": 1367.4192024152758,
            "rating_q975": 1374.0071772516974,
            "rating_q025": 1360.8312275788542
        },
        "grok-3-mini-beta": {
            "rating": 1367.1432998306566,
            "rating_q975": 1376.502514015545,
            "rating_q025": 1357.784085645768
        },
        "o4-mini-2025-04-16": {
            "rating": 1366.6979153647126,
            "rating_q975": 1373.8184748655574,
            "rating_q025": 1359.5773558638678
        },
        "gemma-3-27b-it": {
            "rating": 1363.7183034214656,
            "rating_q975": 1371.2269900720928,
            "rating_q025": 1356.2096167708385
        },
        "qwen-plus-0125": {
            "rating": 1359.3801856722255,
            "rating_q975": 1380.2734346690274,
            "rating_q025": 1338.4869366754235
        },
        "mistral-small-2506": {
            "rating": 1358.451580099819,
            "rating_q975": 1368.6638842741568,
            "rating_q025": 1348.2392759254813
        },
        "o3-mini": {
            "rating": 1357.271752791368,
            "rating_q975": 1363.7470926540386,
            "rating_q025": 1350.7964129286975
        },
        "qwen3-32b": {
            "rating": 1354.13447883111,
            "rating_q975": 1378.925389166047,
            "rating_q025": 1329.3435684961732
        },
        "gemini-1.5-pro-002": {
            "rating": 1354.0529813654764,
            "rating_q975": 1360.9186292482761,
            "rating_q025": 1347.1873334826766
        },
        "hunyuan-turbos-20250226": {
            "rating": 1351.6304020021728,
            "rating_q975": 1383.5942016961405,
            "rating_q025": 1319.666602308205
        },
        "claude-3-5-sonnet-20240620": {
            "rating": 1349.145545404574,
            "rating_q975": 1356.6364576274748,
            "rating_q025": 1341.6546331816733
        },
        "step-3": {
            "rating": 1347.2904209153544,
            "rating_q975": 1363.705866678115,
            "rating_q025": 1330.8749751525938
        },
        "gemma-3-12b-it": {
            "rating": 1346.7832737313834,
            "rating_q975": 1375.3505030662682,
            "rating_q025": 1318.2160443964985
        },
        "gemini-1.5-pro-001": {
            "rating": 1346.4213089415107,
            "rating_q975": 1354.5311288356106,
            "rating_q025": 1338.3114890474108
        },
        "gemini-2.0-flash-lite-preview-02-05": {
            "rating": 1346.2592669756204,
            "rating_q975": 1356.549890697014,
            "rating_q025": 1335.968643254227
        },
        "step-1o-turbo-202506": {
            "rating": 1346.0624079028883,
            "rating_q975": 1362.0761503672263,
            "rating_q025": 1330.0486654385502
        },
        "amazon-nova-experimental-chat-10-09": {
            "rating": 1344.0517646806748,
            "rating_q975": 1360.6461311887417,
            "rating_q025": 1327.4573981726078
        },
        "o1-mini": {
            "rating": 1341.6507576685167,
            "rating_q975": 1348.972680132236,
            "rating_q025": 1334.3288352047973
        },
        "llama-3.1-nemotron-ultra-253b-v1": {
            "rating": 1341.1703600772144,
            "rating_q975": 1371.1945981996223,
            "rating_q025": 1311.1461219548064
        },
        "hunyuan-turbo-0110": {
            "rating": 1340.626847370655,
            "rating_q975": 1370.594493170222,
            "rating_q025": 1310.659201571088
        },
        "nvidia-llama-3.3-nemotron-super-49b-v1.5": {
            "rating": 1339.618319665692,
            "rating_q975": 1361.16152869349,
            "rating_q025": 1318.075110637894
        },
        "step-2-16k-exp-202412": {
            "rating": 1338.523358252352,
            "rating_q975": 1359.6012836739847,
            "rating_q025": 1317.4454328307193
        },
        "claude-3-5-haiku-20241022": {
            "rating": 1338.4610997553177,
            "rating_q975": 1344.5955270029642,
            "rating_q025": 1332.3266725076712
        },
        "qwen3-30b-a3b": {
            "rating": 1338.3860233462487,
            "rating_q975": 1347.3583110030402,
            "rating_q025": 1329.4137356894573
        },
        "glm-4-plus-0111": {
            "rating": 1337.8898732661703,
            "rating_q975": 1358.3037022596066,
            "rating_q025": 1317.476044272734
        },
        "glm-4.5v": {
            "rating": 1337.4867635652604,
            "rating_q975": 1356.1492665074354,
            "rating_q025": 1318.8242606230854
        },
        "qwq-32b": {
            "rating": 1334.8279629824672,
            "rating_q975": 1344.1113815967562,
            "rating_q025": 1325.544544368178
        },
        "gpt-4o-2024-08-06": {
            "rating": 1334.217511768777,
            "rating_q975": 1342.3682116279358,
            "rating_q025": 1326.0668119096183
        },
        "magistral-medium-2506": {
            "rating": 1333.859775026991,
            "rating_q975": 1346.3075075740414,
            "rating_q025": 1321.4120424799405
        },
        "llama-3.3-nemotron-49b-super-v1": {
            "rating": 1333.7726145038343,
            "rating_q975": 1364.1535234787955,
            "rating_q025": 1303.3917055288732
        },
        "deepseek-v2.5-1210": {
            "rating": 1333.5189801747847,
            "rating_q975": 1350.8090321681889,
            "rating_q025": 1316.2289281813805
        },
        "llama-4-maverick-17b-128e-instruct": {
            "rating": 1333.4912045983947,
            "rating_q975": 1341.0951942047689,
            "rating_q025": 1325.8872149920205
        },
        "grok-2-2024-08-13": {
            "rating": 1331.1617036955147,
            "rating_q975": 1338.0898260747226,
            "rating_q025": 1324.2335813163068
        },
        "ring-flash-2.0": {
            "rating": 1331.1534514639677,
            "rating_q975": 1347.414079831067,
            "rating_q025": 1314.8928230968684
        },
        "gpt-5-nano-high": {
            "rating": 1329.5524411823221,
            "rating_q975": 1344.6325024758446,
            "rating_q025": 1314.4723798887997
        },
        "hunyuan-standard-2025-02-10": {
            "rating": 1329.3782110555094,
            "rating_q975": 1356.0291335423108,
            "rating_q025": 1302.727288568708
        },
        "ling-flash-2.0": {
            "rating": 1328.142943433457,
            "rating_q975": 1344.5437174798749,
            "rating_q025": 1311.7421693870392
        },
        "gpt-4o-2024-05-13": {
            "rating": 1328.0659426772954,
            "rating_q975": 1334.6928672971148,
            "rating_q025": 1321.439018057476
        },
        "llama-4-scout-17b-16e-instruct": {
            "rating": 1326.7511197628137,
            "rating_q975": 1335.2560372433759,
            "rating_q025": 1318.2462022822515
        },
        "gpt-4.1-nano-2025-04-14": {
            "rating": 1324.3193109425897,
            "rating_q975": 1344.4084594941717,
            "rating_q025": 1304.2301623910078
        },
        "claude-3-opus-20240229": {
            "rating": 1324.2305741253867,
            "rating_q975": 1330.3738474097859,
            "rating_q025": 1318.0873008409876
        },
        "mistral-small-3.1-24b-instruct-2503": {
            "rating": 1324.1312413605117,
            "rating_q975": 1332.112929552312,
            "rating_q025": 1316.1495531687115
        },
        "llama-3.1-405b-instruct-bf16": {
            "rating": 1323.3302877369574,
            "rating_q975": 1331.1421405199123,
            "rating_q025": 1315.5184349540025
        },
        "qwen-max-0919": {
            "rating": 1322.5920616262404,
            "rating_q975": 1334.2893935085895,
            "rating_q025": 1310.8947297438913
        },
        "yi-lightning": {
            "rating": 1322.4705422656102,
            "rating_q975": 1332.8641468852306,
            "rating_q025": 1312.0769376459898
        },
        "glm-4-plus": {
            "rating": 1322.1730708308032,
            "rating_q975": 1332.0561813468664,
            "rating_q025": 1312.28996031474
        },
        "gpt-4o-mini-2024-07-18": {
            "rating": 1321.7272790170034,
            "rating_q975": 1328.4993679384663,
            "rating_q025": 1314.9551900955405
        },
        "gemini-advanced-0514": {
            "rating": 1320.0270779989833,
            "rating_q975": 1330.2575110209684,
            "rating_q025": 1309.796644976998
        },
        "gemini-1.5-flash-002": {
            "rating": 1319.7515252360797,
            "rating_q975": 1327.9450046421653,
            "rating_q025": 1311.5580458299942
        },
        "gpt-oss-120b": {
            "rating": 1319.4482993642143,
            "rating_q975": 1328.0385427820208,
            "rating_q025": 1310.8580559464078
        },
        "athene-v2-chat": {
            "rating": 1317.5661983583245,
            "rating_q975": 1326.991274115342,
            "rating_q025": 1308.141122601307
        },
        "hunyuan-large-vision": {
            "rating": 1316.8107930865037,
            "rating_q975": 1336.5332976081465,
            "rating_q025": 1297.088288564861
        },
        "llama-3.1-405b-instruct-fp8": {
            "rating": 1315.3978957835159,
            "rating_q975": 1322.7400793137047,
            "rating_q025": 1308.055712253327
        },
        "qwen2.5-72b-instruct": {
            "rating": 1313.7406529833424,
            "rating_q975": 1321.5594032549284,
            "rating_q025": 1305.9219027117565
        },
        "grok-2-mini-2024-08-13": {
            "rating": 1313.5029706046744,
            "rating_q975": 1320.9478572174796,
            "rating_q025": 1306.0580839918691
        },
        "gemma-3n-e4b-it": {
            "rating": 1312.1972684341931,
            "rating_q975": 1323.1125808815164,
            "rating_q025": 1301.28195598687
        },
        "gemma-3-4b-it": {
            "rating": 1311.7358770296587,
            "rating_q975": 1339.2482913442977,
            "rating_q025": 1284.2234627150197
        },
        "gpt-4-turbo-2024-04-09": {
            "rating": 1311.635968886084,
            "rating_q975": 1319.2913606275001,
            "rating_q025": 1303.9805771446677
        },
        "deepseek-v2.5": {
            "rating": 1310.52407915451,
            "rating_q975": 1320.500813381241,
            "rating_q025": 1300.547344927779
        },
        "llama-3.3-70b-instruct": {
            "rating": 1309.052534310774,
            "rating_q975": 1315.5562664752674,
            "rating_q025": 1302.5488021462807
        },
        "qwen2.5-plus-1127": {
            "rating": 1304.439368884634,
            "rating_q975": 1318.5870866535276,
            "rating_q025": 1290.2916511157403
        },
        "gpt-4-0125-preview": {
            "rating": 1302.824775094705,
            "rating_q975": 1311.1391136814086,
            "rating_q025": 1294.5104365080015
        },
        "gpt-oss-20b": {
            "rating": 1302.2983574151185,
            "rating_q975": 1315.8482687364124,
            "rating_q025": 1288.7484460938247
        },
        "mistral-large-2411": {
            "rating": 1301.4442858643965,
            "rating_q975": 1310.8235388462033,
            "rating_q025": 1292.0650328825898
        },
        "mistral-large-2407": {
            "rating": 1300.475561641501,
            "rating_q975": 1308.932658430601,
            "rating_q025": 1292.018464852401
        },
        "gemini-1.5-flash-001": {
            "rating": 1296.8916686205616,
            "rating_q975": 1305.3911484663963,
            "rating_q025": 1288.392188774727
        },
        "amazon-nova-pro-v1.0": {
            "rating": 1296.7919340202448,
            "rating_q975": 1306.4463842519606,
            "rating_q025": 1287.137483788529
        },
        "gpt-4-1106-preview": {
            "rating": 1296.6446459730394,
            "rating_q975": 1304.8686178069663,
            "rating_q025": 1288.4206741391124
        },
        "gemma-2-27b-it": {
            "rating": 1295.6663092436079,
            "rating_q975": 1302.267962696027,
            "rating_q025": 1289.0646557911887
        },
        "llama-3.1-70b-instruct": {
            "rating": 1290.2651050202558,
            "rating_q975": 1297.6372540145367,
            "rating_q025": 1282.8929560259749
        },
        "athene-70b-0725": {
            "rating": 1288.3259897127152,
            "rating_q975": 1300.6156022558534,
            "rating_q025": 1276.036377169577
        },
        "c4ai-aya-expanse-32b": {
            "rating": 1285.6351554175435,
            "rating_q975": 1294.7945274356541,
            "rating_q025": 1276.4757833994329
        },
        "gemma-2-9b-it-simpo": {
            "rating": 1284.1316866731397,
            "rating_q975": 1303.3120031461465,
            "rating_q025": 1264.951370200133
        },
        "nemotron-4-340b-instruct": {
            "rating": 1283.2515901424658,
            "rating_q975": 1296.4861740694564,
            "rating_q025": 1270.0170062154752
        },
        "qwen2.5-coder-32b-instruct": {
            "rating": 1282.3761565295476,
            "rating_q975": 1301.2216056368695,
            "rating_q025": 1263.5307074222258
        },
        "deepseek-coder-v2": {
            "rating": 1282.221292009336,
            "rating_q975": 1296.0284645422155,
            "rating_q025": 1268.4141194764563
        },
        "claude-3-sonnet-20240229": {
            "rating": 1280.9652764027396,
            "rating_q975": 1289.4640710133451,
            "rating_q025": 1272.4664817921341
        },
        "llama-3.1-nemotron-70b-instruct": {
            "rating": 1277.5766093958985,
            "rating_q975": 1295.1767123015618,
            "rating_q025": 1259.9765064902351
        },
        "command-r-plus-08-2024": {
            "rating": 1277.007418166751,
            "rating_q975": 1292.331990636699,
            "rating_q025": 1261.682845696803
        },
        "mistral-small-24b-instruct-2501": {
            "rating": 1276.8241040082316,
            "rating_q975": 1290.3301732356088,
            "rating_q025": 1263.3180347808545
        },
        "reka-core-20240904": {
            "rating": 1275.8677936210574,
            "rating_q975": 1293.9366810593187,
            "rating_q025": 1257.7989061827961
        },
        "gpt-4-0613": {
            "rating": 1272.433780339214,
            "rating_q975": 1281.611568994243,
            "rating_q025": 1263.2559916841851
        },
        "gpt-4-0314": {
            "rating": 1272.033668073245,
            "rating_q975": 1283.4780568856204,
            "rating_q025": 1260.5892792608697
        },
        "amazon-nova-lite-v1.0": {
            "rating": 1271.06710671833,
            "rating_q975": 1281.6913107095486,
            "rating_q025": 1260.4429027271115
        },
        "llama-3.1-tulu-3-70b": {
            "rating": 1269.3668064327062,
            "rating_q975": 1294.4108335594765,
            "rating_q025": 1244.322779305936
        },
        "hunyuan-standard-256k": {
            "rating": 1266.8218052018772,
            "rating_q975": 1293.4671925764665,
            "rating_q025": 1240.1764178272879
        },
        "llama-3.1-nemotron-51b-instruct": {
            "rating": 1265.4843620198656,
            "rating_q975": 1288.4699030317372,
            "rating_q025": 1242.498821007994
        },
        "gemini-1.5-flash-8b-001": {
            "rating": 1263.0641124548135,
            "rating_q975": 1271.283479136809,
            "rating_q025": 1254.844745772818
        },
        "phi-4": {
            "rating": 1262.9038398389812,
            "rating_q975": 1273.579420616741,
            "rating_q025": 1252.2282590612215
        },
        "glm-4-0520": {
            "rating": 1261.9015919703966,
            "rating_q975": 1278.5002634349714,
            "rating_q025": 1245.3029205058217
        },
        "claude-3-haiku-20240307": {
            "rating": 1261.1423293118733,
            "rating_q975": 1268.6180277391886,
            "rating_q025": 1253.666630884558
        },
        "gemma-2-9b-it": {
            "rating": 1261.0570317785664,
            "rating_q975": 1268.6633341392,
            "rating_q025": 1253.4507294179327
        },
        "reka-flash-20240904": {
            "rating": 1259.224592060405,
            "rating_q975": 1276.9618687236507,
            "rating_q025": 1241.4873153971594
        },
        "command-r-08-2024": {
            "rating": 1258.4785432103963,
            "rating_q975": 1273.3984000022915,
            "rating_q025": 1243.558686418501
        },
        "command-r-plus": {
            "rating": 1257.5561104844373,
            "rating_q975": 1266.3989253727082,
            "rating_q025": 1248.7132955961665
        },
        "jamba-1.5-large": {
            "rating": 1257.2881172137472,
            "rating_q975": 1274.7092556701173,
            "rating_q025": 1239.8669787573772
        },
        "qwen2-72b-instruct": {
            "rating": 1256.0810563424018,
            "rating_q975": 1266.1075723019767,
            "rating_q025": 1246.0545403828269
        },
        "ministral-8b-2410": {
            "rating": 1254.8289414574328,
            "rating_q975": 1275.1914551459256,
            "rating_q025": 1234.46642776894
        },
        "llama-3-70b-instruct": {
            "rating": 1247.7961226223638,
            "rating_q975": 1255.1989151401922,
            "rating_q025": 1240.3933301045354
        },
        "c4ai-aya-expanse-8b": {
            "rating": 1245.4028404953242,
            "rating_q975": 1260.0729432638961,
            "rating_q025": 1230.7327377267522
        },
        "amazon-nova-micro-v1.0": {
            "rating": 1244.7987426833104,
            "rating_q975": 1255.9039336028707,
            "rating_q025": 1233.69355176375
        },
        "olmo-2-0325-32b-instruct": {
            "rating": 1242.6149255425212,
            "rating_q975": 1276.7361506907723,
            "rating_q025": 1208.49370039427
        },
        "mistral-large-2402": {
            "rating": 1241.0035434886004,
            "rating_q975": 1250.7895168995435,
            "rating_q025": 1231.2175700776572
        },
        "qwen1.5-72b-chat": {
            "rating": 1230.7520692379194,
            "rating_q975": 1242.2355708182547,
            "rating_q025": 1219.268567657584
        },
        "command-r": {
            "rating": 1227.7219998904443,
            "rating_q975": 1237.5937582918348,
            "rating_q025": 1217.8502414890538
        },
        "granite-3.1-8b-instruct": {
            "rating": 1227.5738985867538,
            "rating_q975": 1254.7320226148156,
            "rating_q025": 1200.415774558692
        },
        "qwen1.5-110b-chat": {
            "rating": 1223.3803595636332,
            "rating_q975": 1235.0410580668786,
            "rating_q025": 1211.7196610603878
        },
        "llama-3.1-tulu-3-8b": {
            "rating": 1222.8083831545837,
            "rating_q975": 1248.760160766603,
            "rating_q025": 1196.8566055425645
        },
        "llama-3.1-8b-instruct": {
            "rating": 1220.0785399941778,
            "rating_q975": 1227.8845812114673,
            "rating_q025": 1212.2724987768884
        },
        "qwen1.5-32b-chat": {
            "rating": 1218.775974857721,
            "rating_q975": 1231.3049750608895,
            "rating_q025": 1206.2469746545523
        },
        "granite-3.1-2b-instruct": {
            "rating": 1218.6570088671351,
            "rating_q975": 1244.9780641193972,
            "rating_q025": 1192.335953614873
        },
        "gemini-pro-dev-api": {
            "rating": 1218.4365365010208,
            "rating_q975": 1236.2263119703696,
            "rating_q025": 1200.646761031672
        },
        "mistral-medium": {
            "rating": 1215.9452437210675,
            "rating_q975": 1228.7539015846626,
            "rating_q025": 1203.1365858574725
        },
        "gpt-3.5-turbo-0125": {
            "rating": 1214.8609242897865,
            "rating_q975": 1223.8615531809346,
            "rating_q025": 1205.8602953986383
        },
        "jamba-1.5-mini": {
            "rating": 1213.3317706863813,
            "rating_q975": 1230.8819139551438,
            "rating_q025": 1195.781627417619
        },
        "mixtral-8x22b-instruct-v0.1": {
            "rating": 1212.405709572146,
            "rating_q975": 1222.0813810076538,
            "rating_q025": 1202.730038136638
        },
        "reka-flash-21b-20240226": {
            "rating": 1212.3136340610736,
            "rating_q975": 1225.0460100657479,
            "rating_q025": 1199.5812580563993
        },
        "reka-flash-21b-20240226-online": {
            "rating": 1211.874670667264,
            "rating_q975": 1227.4257783319672,
            "rating_q025": 1196.3235630025606
        },
        "llama-3-8b-instruct": {
            "rating": 1203.282484026528,
            "rating_q975": 1211.6435124968468,
            "rating_q025": 1194.9214555562091
        },
        "yi-1.5-34b-chat": {
            "rating": 1199.7934625607822,
            "rating_q975": 1213.0228169918712,
            "rating_q025": 1186.5641081296933
        },
        "internlm2_5-20b-chat": {
            "rating": 1197.236990609464,
            "rating_q975": 1213.4858093657608,
            "rating_q025": 1180.9881718531674
        },
        "granite-3.0-8b-instruct": {
            "rating": 1197.2020467109662,
            "rating_q975": 1221.2692711086274,
            "rating_q025": 1173.134822313305
        },
        "qwen1.5-14b-chat": {
            "rating": 1187.63976842385,
            "rating_q975": 1202.4168556556324,
            "rating_q025": 1172.8626811920676
        },
        "phi-3-medium-4k-instruct": {
            "rating": 1186.5636908222377,
            "rating_q975": 1199.4645493549465,
            "rating_q025": 1173.662832289529
        },
        "dbrx-instruct-preview": {
            "rating": 1183.208213326794,
            "rating_q975": 1195.6918070410657,
            "rating_q025": 1170.7246196125225
        },
        "gemma-2-2b-it": {
            "rating": 1182.890439719234,
            "rating_q975": 1191.365192886227,
            "rating_q025": 1174.4156865522411
        },
        "openchat-3.5": {
            "rating": 1178.968434342291,
            "rating_q975": 1207.3286176468007,
            "rating_q025": 1150.6082510377812
        },
        "gpt-3.5-turbo-1106": {
            "rating": 1178.8895986839784,
            "rating_q975": 1199.3656565244378,
            "rating_q025": 1158.413540843519
        },
        "zephyr-orpo-141b-A35b-v0.1": {
            "rating": 1178.3361704805166,
            "rating_q975": 1206.5782542025731,
            "rating_q025": 1150.09408675846
        },
        "mixtral-8x7b-instruct-v0.1": {
            "rating": 1178.0837144622947,
            "rating_q975": 1187.4873082001209,
            "rating_q025": 1168.6801207244685
        },
        "wizardlm-70b": {
            "rating": 1177.9514945005358,
            "rating_q975": 1209.6758384050877,
            "rating_q025": 1146.2271505959839
        },
        "deepseek-llm-67b-chat": {
            "rating": 1177.3078528954288,
            "rating_q975": 1214.3438861242385,
            "rating_q025": 1140.2718196666192
        },
        "qwq-32b-preview": {
            "rating": 1176.7709285245817,
            "rating_q975": 1203.1378717030439,
            "rating_q025": 1150.4039853461195
        },
        "tulu-2-dpo-70b": {
            "rating": 1172.6937814491184,
            "rating_q975": 1206.3022412702303,
            "rating_q025": 1139.0853216280066
        },
        "yi-34b-chat": {
            "rating": 1166.8598447185127,
            "rating_q975": 1184.7873826487116,
            "rating_q025": 1148.9323067883138
        },
        "openchat-3.5-0106": {
            "rating": 1164.0182745189445,
            "rating_q975": 1182.5288462339402,
            "rating_q025": 1145.5077028039489
        },
        "starling-lm-7b-beta": {
            "rating": 1162.570145815102,
            "rating_q975": 1178.271673476247,
            "rating_q025": 1146.868618153957
        },
        "gemma-1.1-7b-it": {
            "rating": 1160.338308458269,
            "rating_q975": 1172.8198114480558,
            "rating_q025": 1147.8568054684822
        },
        "qwen1.5-7b-chat": {
            "rating": 1159.1028222260356,
            "rating_q975": 1189.2646733004565,
            "rating_q025": 1128.9409711516148
        },
        "phi-3-small-8k-instruct": {
            "rating": 1156.9996873636824,
            "rating_q975": 1170.1684673702712,
            "rating_q025": 1143.8309073570936
        },
        "llama-3.2-3b-instruct": {
            "rating": 1154.9709988056975,
            "rating_q975": 1173.2977128667164,
            "rating_q025": 1136.6442847446785
        },
        "starling-lm-7b-alpha": {
            "rating": 1145.6129965991706,
            "rating_q975": 1168.7438992523014,
            "rating_q025": 1122.4820939460399
        },
        "granite-3.0-2b-instruct": {
            "rating": 1143.718875029118,
            "rating_q975": 1168.4942807234283,
            "rating_q025": 1118.9434693348076
        },
        "wizardlm-13b": {
            "rating": 1141.7406257708687,
            "rating_q975": 1182.7183460732247,
            "rating_q025": 1100.7629054685128
        },
        "vicuna-13b": {
            "rating": 1138.7807705446126,
            "rating_q975": 1160.2953399774954,
            "rating_q025": 1117.2662011117297
        },
        "vicuna-7b": {
            "rating": 1137.407320433892,
            "rating_q975": 1182.582008725705,
            "rating_q025": 1092.232632142079
        },
        "llama-2-13b-chat": {
            "rating": 1135.5005116254633,
            "rating_q975": 1153.0091192955958,
            "rating_q025": 1117.9919039553308
        },
        "openhermes-2.5-mistral-7b": {
            "rating": 1135.3360931138252,
            "rating_q975": 1168.9210054575028,
            "rating_q025": 1101.7511807701476
        },
        "llama-2-70b-chat": {
            "rating": 1133.8564346534686,
            "rating_q975": 1146.6088693581385,
            "rating_q025": 1121.1039999487987
        },
        "smollm2-1.7b-instruct": {
            "rating": 1130.0494512254957,
            "rating_q975": 1163.2637201893888,
            "rating_q025": 1096.8351822616025
        },
        "palm-2": {
            "rating": 1129.990923812982,
            "rating_q975": 1167.8658411360825,
            "rating_q025": 1092.1160064898813
        },
        "mistral-7b-instruct-v0.2": {
            "rating": 1129.2470713892637,
            "rating_q975": 1144.5324585599226,
            "rating_q025": 1113.961684218605
        },
        "vicuna-33b": {
            "rating": 1128.4192308119286,
            "rating_q975": 1147.5738588697066,
            "rating_q025": 1109.2646027541507
        },
        "snowflake-arctic-instruct": {
            "rating": 1124.716005961699,
            "rating_q975": 1138.8559958823453,
            "rating_q025": 1110.5760160410528
        },
        "qwen-14b-chat": {
            "rating": 1119.5970612308256,
            "rating_q975": 1157.9991462534201,
            "rating_q025": 1081.194976208231
        },
        "nous-hermes-2-mixtral-8x7b-dpo": {
            "rating": 1110.2364100435366,
            "rating_q975": 1146.027845705647,
            "rating_q025": 1074.4449743814262
        },
        "gemma-1.1-2b-it": {
            "rating": 1109.7663503779281,
            "rating_q975": 1127.6031879106429,
            "rating_q025": 1091.9295128452134
        },
        "gemma-7b-it": {
            "rating": 1106.7084548210037,
            "rating_q975": 1129.5546148136436,
            "rating_q025": 1083.8622948283637
        },
        "zephyr-7b-beta": {
            "rating": 1100.3329863468725,
            "rating_q975": 1128.1745683884683,
            "rating_q025": 1072.4914043052768
        },
        "phi-3-mini-4k-instruct-june-2024": {
            "rating": 1099.914985773396,
            "rating_q975": 1118.960645176886,
            "rating_q025": 1080.869326369906
        },
        "phi-3-mini-4k-instruct": {
            "rating": 1097.6763771902392,
            "rating_q975": 1112.9639067514809,
            "rating_q025": 1082.3888476289976
        },
        "llama-3.2-1b-instruct": {
            "rating": 1097.477883369821,
            "rating_q975": 1116.5791969841641,
            "rating_q025": 1078.376569755478
        },
        "codellama-34b-instruct": {
            "rating": 1093.3506928735424,
            "rating_q975": 1126.483057795496,
            "rating_q025": 1060.2183279515887
        },
        "mistral-7b-instruct": {
            "rating": 1091.3797845589584,
            "rating_q975": 1118.4426677885872,
            "rating_q025": 1064.3169013293295
        },
        "gemma-2b-it": {
            "rating": 1079.182012107936,
            "rating_q975": 1110.5354273771245,
            "rating_q025": 1047.8285968387477
        },
        "qwen1.5-4b-chat": {
            "rating": 1072.6793776428271,
            "rating_q975": 1096.614777465354,
            "rating_q025": 1048.7439778203002
        },
        "llama-2-7b-chat": {
            "rating": 1071.3612299229922,
            "rating_q975": 1091.5316813588524,
            "rating_q025": 1051.1907784871319
        },
        "phi-3-mini-128k-instruct": {
            "rating": 1067.6078784674107,
            "rating_q975": 1083.6782059953491,
            "rating_q025": 1051.5375509394723
        },
        "stripedhyena-nous-7b": {
            "rating": 1066.349573004014,
            "rating_q975": 1098.879456702826,
            "rating_q025": 1033.819689305202
        },
        "llama2-70b-steerlm-chat": {
            "rating": 1053.7445676248526,
            "rating_q975": 1097.621021176854,
            "rating_q025": 1009.8681140728513
        },
        "chatglm3-6b": {
            "rating": 1036.202284216371,
            "rating_q975": 1076.9442575778974,
            "rating_q025": 995.4603108548448
        }
    },
    "math": {
        "claude-sonnet-4-5-20250929-thinking-32k": {
            "rating": 1461.873508392198,
            "rating_q975": 1483.8542180333332,
            "rating_q025": 1439.8927987510626
        },
        "gemini-2.5-pro": {
            "rating": 1457.0083336193868,
            "rating_q975": 1467.1568920126974,
            "rating_q025": 1446.8597752260762
        },
        "o3-2025-04-16": {
            "rating": 1454.9959361210347,
            "rating_q975": 1465.0390470548423,
            "rating_q025": 1444.952825187227
        },
        "claude-opus-4-1-20250805-thinking-16k": {
            "rating": 1446.1996101384132,
            "rating_q975": 1460.4604865104443,
            "rating_q025": 1431.938733766382
        },
        "qwen3-max-preview": {
            "rating": 1445.0418782341621,
            "rating_q975": 1460.913905741351,
            "rating_q025": 1429.1698507269732
        },
        "grok-4-0709": {
            "rating": 1442.1346816544983,
            "rating_q975": 1455.8235697107168,
            "rating_q025": 1428.4457935982798
        },
        "claude-opus-4-1-20250805": {
            "rating": 1441.6095237543652,
            "rating_q975": 1453.7099180175187,
            "rating_q025": 1429.5091294912118
        },
        "gpt-5-high": {
            "rating": 1439.4603928209244,
            "rating_q975": 1453.4830145498884,
            "rating_q025": 1425.4377710919605
        },
        "qwen3-max-2025-09-23": {
            "rating": 1436.0276348710813,
            "rating_q975": 1459.38851624294,
            "rating_q025": 1412.6667534992225
        },
        "gemini-2.5-flash-preview-09-2025": {
            "rating": 1430.7306812903391,
            "rating_q975": 1452.013391585603,
            "rating_q025": 1409.4479709950754
        },
        "longcat-flash-chat": {
            "rating": 1430.1437926923222,
            "rating_q975": 1452.091596029731,
            "rating_q025": 1408.1959893549135
        },
        "grok-4-fast": {
            "rating": 1426.7844599818618,
            "rating_q975": 1455.3534578922684,
            "rating_q025": 1398.2154620714552
        },
        "qwen3-235b-a22b-instruct-2507": {
            "rating": 1426.6266840532771,
            "rating_q975": 1439.537056381681,
            "rating_q025": 1413.7163117248733
        },
        "deepseek-v3.2-exp-thinking": {
            "rating": 1426.6038261990727,
            "rating_q975": 1453.104438258202,
            "rating_q025": 1400.1032141399435
        },
        "qwen3-next-80b-a3b-instruct": {
            "rating": 1425.930144543902,
            "rating_q975": 1443.8745527277465,
            "rating_q025": 1407.9857363600577
        },
        "glm-4.6": {
            "rating": 1425.4266236558165,
            "rating_q975": 1450.6086638958027,
            "rating_q025": 1400.2445834158302
        },
        "deepseek-v3.1-thinking": {
            "rating": 1423.5467585857286,
            "rating_q975": 1445.5632350301555,
            "rating_q025": 1401.5302821413018
        },
        "claude-opus-4-20250514-thinking-16k": {
            "rating": 1421.6451338072586,
            "rating_q975": 1433.6357811843807,
            "rating_q025": 1409.6544864301366
        },
        "glm-4.5": {
            "rating": 1420.8824160218173,
            "rating_q975": 1436.2572968215043,
            "rating_q025": 1405.5075352221304
        },
        "deepseek-v3.1": {
            "rating": 1419.0558845173512,
            "rating_q975": 1437.263439315835,
            "rating_q025": 1400.8483297188673
        },
        "o4-mini-2025-04-16": {
            "rating": 1418.6759532187775,
            "rating_q975": 1429.236301179719,
            "rating_q025": 1408.115605257836
        },
        "deepseek-v3.1-terminus-thinking": {
            "rating": 1417.7947355944564,
            "rating_q975": 1457.907170309064,
            "rating_q025": 1377.6823008798488
        },
        "claude-sonnet-4-5-20250929": {
            "rating": 1415.8910733671908,
            "rating_q975": 1445.0071011434438,
            "rating_q025": 1386.7750455909377
        },
        "gpt-5-chat": {
            "rating": 1415.1543454005969,
            "rating_q975": 1429.4847798340825,
            "rating_q025": 1400.8239109671113
        },
        "kimi-k2-0905-preview": {
            "rating": 1414.844859940876,
            "rating_q975": 1436.6103312926161,
            "rating_q025": 1393.0793885891358
        },
        "gpt-5-mini-high": {
            "rating": 1414.4740425004127,
            "rating_q975": 1430.7707224692106,
            "rating_q025": 1398.1773625316148
        },
        "qwen3-vl-235b-a22b-thinking": {
            "rating": 1414.0126449766044,
            "rating_q975": 1442.3166356849572,
            "rating_q025": 1385.7086542682516
        },
        "qwen3-vl-235b-a22b-instruct": {
            "rating": 1413.6993012698797,
            "rating_q975": 1438.362316017962,
            "rating_q025": 1389.0362865217974
        },
        "gpt-4.5-preview-2025-02-27": {
            "rating": 1413.61525346191,
            "rating_q975": 1428.613452306211,
            "rating_q025": 1398.617054617609
        },
        "gemini-2.5-flash": {
            "rating": 1413.0549577546133,
            "rating_q975": 1422.6893801399945,
            "rating_q025": 1403.420535369232
        },
        "deepseek-r1": {
            "rating": 1412.6853584227006,
            "rating_q975": 1426.3688409571562,
            "rating_q025": 1399.001875888245
        },
        "o1-2024-12-17": {
            "rating": 1410.3967631685252,
            "rating_q975": 1420.7730871341798,
            "rating_q025": 1400.0204392028706
        },
        "o3-mini-high": {
            "rating": 1409.246917864475,
            "rating_q975": 1422.073143558871,
            "rating_q025": 1396.4206921700793
        },
        "mistral-medium-2508": {
            "rating": 1408.4098066265346,
            "rating_q975": 1422.194381587364,
            "rating_q025": 1394.6252316657053
        },
        "claude-sonnet-4-20250514-thinking-32k": {
            "rating": 1406.2361348351096,
            "rating_q975": 1418.7641021637255,
            "rating_q025": 1393.7081675064937
        },
        "hunyuan-t1-20250711": {
            "rating": 1404.4278492278486,
            "rating_q975": 1442.296124469147,
            "rating_q025": 1366.5595739865503
        },
        "amazon-nova-experimental-chat-10-09": {
            "rating": 1403.8068366166187,
            "rating_q975": 1437.6971758702928,
            "rating_q025": 1369.9164973629447
        },
        "qwen3-235b-a22b-thinking-2507": {
            "rating": 1403.4346719369603,
            "rating_q975": 1427.551377842466,
            "rating_q025": 1379.3179660314545
        },
        "qwen3-32b": {
            "rating": 1403.3657985280577,
            "rating_q975": 1433.4819148184106,
            "rating_q025": 1373.2496822377047
        },
        "minimax-m1": {
            "rating": 1403.3373226877766,
            "rating_q975": 1416.4007550033336,
            "rating_q025": 1390.2738903722195
        },
        "claude-opus-4-20250514": {
            "rating": 1402.5597253616525,
            "rating_q975": 1413.311919163634,
            "rating_q025": 1391.807531559671
        },
        "qwen3-235b-a22b": {
            "rating": 1401.0222806337745,
            "rating_q975": 1414.8590118533361,
            "rating_q025": 1387.1855494142128
        },
        "qwen3-next-80b-a3b-thinking": {
            "rating": 1400.475832339792,
            "rating_q975": 1419.9205228583307,
            "rating_q025": 1381.0311418212534
        },
        "mai-1-preview": {
            "rating": 1399.9900999996678,
            "rating_q975": 1419.1399965956589,
            "rating_q025": 1380.8402034036767
        },
        "chatgpt-4o-latest-20250326": {
            "rating": 1398.5471592015006,
            "rating_q975": 1408.3107678733454,
            "rating_q025": 1388.7835505296557
        },
        "claude-haiku-4-5-20251001": {
            "rating": 1398.2812798334014,
            "rating_q975": 1421.780852605508,
            "rating_q025": 1374.7817070612948
        },
        "qwen3-235b-a22b-no-thinking": {
            "rating": 1397.9511685283937,
            "rating_q975": 1409.74654960952,
            "rating_q025": 1386.1557874472676
        },
        "glm-4.5-air": {
            "rating": 1397.9165062123764,
            "rating_q975": 1413.4123523799528,
            "rating_q025": 1382.4206600448
        },
        "deepseek-r1-0528": {
            "rating": 1397.5606805056773,
            "rating_q975": 1416.756851597008,
            "rating_q025": 1378.3645094143465
        },
        "deepseek-v3.1-terminus": {
            "rating": 1396.6334824487901,
            "rating_q975": 1435.1789119142002,
            "rating_q025": 1358.08805298338
        },
        "grok-3-mini-high": {
            "rating": 1395.2976494900256,
            "rating_q975": 1413.0977402678923,
            "rating_q025": 1377.497558712159
        },
        "nvidia-llama-3.3-nemotron-super-49b-v1.5": {
            "rating": 1394.3743877151092,
            "rating_q975": 1431.6469188238855,
            "rating_q025": 1357.1018566063328
        },
        "kimi-k2-0711-preview": {
            "rating": 1390.3437672124148,
            "rating_q975": 1404.214645304176,
            "rating_q025": 1376.4728891206537
        },
        "claude-sonnet-4-20250514": {
            "rating": 1389.5736625708525,
            "rating_q975": 1400.8641125673319,
            "rating_q025": 1378.2832125743732
        },
        "qwen3-30b-a3b-instruct-2507": {
            "rating": 1387.8514470667708,
            "rating_q975": 1402.8281575301876,
            "rating_q025": 1372.874736603354
        },
        "o1-preview": {
            "rating": 1387.637089237786,
            "rating_q975": 1396.7615854821627,
            "rating_q025": 1378.5125929934095
        },
        "gpt-oss-120b": {
            "rating": 1387.4583934207362,
            "rating_q975": 1401.9358362715184,
            "rating_q025": 1372.980950569954
        },
        "o3-mini": {
            "rating": 1387.161575784209,
            "rating_q975": 1395.3480460596677,
            "rating_q025": 1378.9751055087502
        },
        "claude-3-7-sonnet-20250219-thinking-32k": {
            "rating": 1386.2600165282172,
            "rating_q975": 1397.0264688573836,
            "rating_q025": 1375.4935641990508
        },
        "llama-3.1-nemotron-ultra-253b-v1": {
            "rating": 1382.152862499856,
            "rating_q975": 1419.815494579136,
            "rating_q025": 1344.490230420576
        },
        "grok-3-preview-02-24": {
            "rating": 1381.465359074242,
            "rating_q975": 1392.2576608892437,
            "rating_q025": 1370.6730572592405
        },
        "qwen3-coder-480b-a35b-instruct": {
            "rating": 1381.230138260465,
            "rating_q975": 1396.1430361374573,
            "rating_q025": 1366.3172403834728
        },
        "deepseek-v3-0324": {
            "rating": 1375.4451896579485,
            "rating_q975": 1385.6028319876186,
            "rating_q025": 1365.2875473282784
        },
        "gpt-4.1-2025-04-14": {
            "rating": 1375.17856977323,
            "rating_q975": 1385.471970906283,
            "rating_q025": 1364.885168640177
        },
        "grok-3-mini-beta": {
            "rating": 1373.1793438921516,
            "rating_q975": 1386.9860675378727,
            "rating_q025": 1359.3726202464304
        },
        "gemini-2.5-flash-lite-preview-06-17-thinking": {
            "rating": 1372.8164534653524,
            "rating_q975": 1385.0631666168106,
            "rating_q025": 1360.5697403138943
        },
        "step-3": {
            "rating": 1370.2398091491177,
            "rating_q975": 1401.8496593462075,
            "rating_q025": 1338.629958952028
        },
        "gemini-2.5-flash-lite-preview-09-2025-no-thinking": {
            "rating": 1369.9375081056542,
            "rating_q975": 1390.5218393251712,
            "rating_q025": 1349.3531768861371
        },
        "qwen2.5-max": {
            "rating": 1369.0130444153701,
            "rating_q975": 1378.5423888582113,
            "rating_q025": 1359.483699972529
        },
        "glm-4.5v": {
            "rating": 1365.716499023011,
            "rating_q975": 1399.6893769647081,
            "rating_q025": 1331.743621081314
        },
        "qwq-32b": {
            "rating": 1365.7025467701826,
            "rating_q975": 1378.8578510580521,
            "rating_q025": 1352.547242482313
        },
        "o1-mini": {
            "rating": 1364.6203855894955,
            "rating_q975": 1371.832818993019,
            "rating_q025": 1357.4079521859721
        },
        "qwen3-30b-a3b": {
            "rating": 1360.209074040919,
            "rating_q975": 1373.565877453704,
            "rating_q025": 1346.852270628134
        },
        "gpt-4.1-mini-2025-04-14": {
            "rating": 1357.248429380001,
            "rating_q975": 1368.2103892196558,
            "rating_q025": 1346.2864695403462
        },
        "ling-flash-2.0": {
            "rating": 1357.0123332618678,
            "rating_q975": 1383.5285197284807,
            "rating_q025": 1330.4961467952548
        },
        "ring-flash-2.0": {
            "rating": 1354.6668043909992,
            "rating_q975": 1381.3915636327058,
            "rating_q025": 1327.9420451492927
        },
        "gpt-5-nano-high": {
            "rating": 1353.928300046613,
            "rating_q975": 1380.4471705480853,
            "rating_q025": 1327.4094295451407
        },
        "mistral-medium-2505": {
            "rating": 1353.352924060283,
            "rating_q975": 1365.1144067410937,
            "rating_q025": 1341.5914413794721
        },
        "hunyuan-turbos-20250416": {
            "rating": 1352.430527869487,
            "rating_q975": 1371.5672897598674,
            "rating_q025": 1333.2937659791064
        },
        "claude-3-5-sonnet-20241022": {
            "rating": 1349.127612881159,
            "rating_q975": 1355.1579306795293,
            "rating_q025": 1343.0972950827886
        },
        "mistral-small-2506": {
            "rating": 1345.4867001013713,
            "rating_q975": 1362.5632380863708,
            "rating_q025": 1328.4101621163718
        },
        "claude-3-5-sonnet-20240620": {
            "rating": 1342.1884691035468,
            "rating_q975": 1348.9459816092285,
            "rating_q025": 1335.4309565978651
        },
        "gemini-1.5-pro-002": {
            "rating": 1340.1246366611379,
            "rating_q975": 1346.7866022312166,
            "rating_q025": 1333.462671091059
        },
        "gpt-oss-20b": {
            "rating": 1338.040270949451,
            "rating_q975": 1359.722684335072,
            "rating_q025": 1316.35785756383
        },
        "gemini-2.0-flash-lite-preview-02-05": {
            "rating": 1328.530580620774,
            "rating_q975": 1338.4238547845553,
            "rating_q025": 1318.6373064569925
        },
        "qwen-plus-0125": {
            "rating": 1328.2353144083222,
            "rating_q975": 1347.3510060557842,
            "rating_q025": 1309.1196227608602
        },
        "gemma-3-27b-it": {
            "rating": 1325.9534836633738,
            "rating_q975": 1335.208594395791,
            "rating_q025": 1316.6983729309568
        },
        "llama-4-maverick-17b-128e-instruct": {
            "rating": 1324.6635825221574,
            "rating_q975": 1335.1964455085256,
            "rating_q025": 1314.1307195357892
        },
        "gemma-3-12b-it": {
            "rating": 1322.144134533431,
            "rating_q975": 1349.310511353769,
            "rating_q025": 1294.977757713093
        },
        "llama-3.1-405b-instruct-fp8": {
            "rating": 1320.7130542160753,
            "rating_q975": 1327.5450706256659,
            "rating_q025": 1313.8810378064848
        },
        "llama-4-scout-17b-16e-instruct": {
            "rating": 1317.200741293806,
            "rating_q975": 1330.108320047104,
            "rating_q025": 1304.293162540508
        },
        "llama-3.1-405b-instruct-bf16": {
            "rating": 1316.6947619185603,
            "rating_q975": 1324.1434724678486,
            "rating_q025": 1309.246051369272
        },
        "step-2-16k-exp-202412": {
            "rating": 1316.3718450891163,
            "rating_q975": 1335.9733405902166,
            "rating_q025": 1296.770349588016
        },
        "deepseek-v3": {
            "rating": 1315.5674870284533,
            "rating_q975": 1325.8640335556101,
            "rating_q025": 1305.2709405012965
        },
        "athene-v2-chat": {
            "rating": 1315.2309826120663,
            "rating_q975": 1324.2077496742704,
            "rating_q025": 1306.2542155498622
        },
        "command-a-03-2025": {
            "rating": 1313.872022719285,
            "rating_q975": 1323.0859767509503,
            "rating_q025": 1304.6580686876198
        },
        "claude-3-opus-20240229": {
            "rating": 1312.414409198827,
            "rating_q975": 1318.0438447868137,
            "rating_q025": 1306.78497361084
        },
        "gpt-4o-2024-08-06": {
            "rating": 1310.133389846333,
            "rating_q975": 1317.4677747985315,
            "rating_q025": 1302.7990048941347
        },
        "yi-lightning": {
            "rating": 1309.9754013135698,
            "rating_q975": 1319.2613831996275,
            "rating_q025": 1300.6894194275121
        },
        "qwen2.5-plus-1127": {
            "rating": 1309.1044398588892,
            "rating_q975": 1322.4557139668152,
            "rating_q025": 1295.7531657509633
        },
        "step-1o-turbo-202506": {
            "rating": 1308.4129682503676,
            "rating_q975": 1330.5694836781263,
            "rating_q025": 1286.256452822609
        },
        "gpt-4o-2024-05-13": {
            "rating": 1307.2003909581804,
            "rating_q975": 1313.199270086336,
            "rating_q025": 1301.2015118300249
        },
        "gpt-4-1106-preview": {
            "rating": 1305.650367023082,
            "rating_q975": 1312.7337901538715,
            "rating_q025": 1298.5669438922926
        },
        "gemini-advanced-0514": {
            "rating": 1304.0677158264912,
            "rating_q975": 1313.000412245836,
            "rating_q025": 1295.1350194071463
        },
        "hunyuan-turbos-20250226": {
            "rating": 1303.9387827863434,
            "rating_q975": 1334.762274064468,
            "rating_q025": 1273.1152915082187
        },
        "gpt-4-0125-preview": {
            "rating": 1301.3037674561397,
            "rating_q975": 1308.4238994045481,
            "rating_q025": 1294.1836355077312
        },
        "glm-4-plus-0111": {
            "rating": 1300.0574303896924,
            "rating_q975": 1319.054083699952,
            "rating_q025": 1281.060777079433
        },
        "qwen2.5-72b-instruct": {
            "rating": 1299.3463135732957,
            "rating_q975": 1306.9178822751621,
            "rating_q025": 1291.7747448714292
        },
        "llama-3.3-70b-instruct": {
            "rating": 1298.5936546929738,
            "rating_q975": 1305.7967045607943,
            "rating_q025": 1291.3906048251533
        },
        "gpt-4-turbo-2024-04-09": {
            "rating": 1298.5113485728903,
            "rating_q975": 1305.3263548876303,
            "rating_q025": 1291.6963422581503
        },
        "gemini-1.5-pro-001": {
            "rating": 1297.259403937957,
            "rating_q975": 1304.4655911978596,
            "rating_q025": 1290.0532166780542
        },
        "hunyuan-large-2025-02-10": {
            "rating": 1296.0415061362257,
            "rating_q975": 1319.8163904234086,
            "rating_q025": 1272.2666218490428
        },
        "deepseek-v2.5-1210": {
            "rating": 1295.983135143833,
            "rating_q975": 1312.3769702649106,
            "rating_q025": 1279.5893000227552
        },
        "grok-2-2024-08-13": {
            "rating": 1295.6787670596555,
            "rating_q975": 1302.2100647479722,
            "rating_q025": 1289.1474693713387
        },
        "qwen-max-0919": {
            "rating": 1293.9838874856764,
            "rating_q975": 1305.3817959869582,
            "rating_q025": 1282.5859789843946
        },
        "hunyuan-standard-2025-02-10": {
            "rating": 1293.3486659645264,
            "rating_q975": 1317.3035507063287,
            "rating_q025": 1269.393781222724
        },
        "hunyuan-large-vision": {
            "rating": 1291.2921625091421,
            "rating_q975": 1319.650080327198,
            "rating_q025": 1262.9342446910862
        },
        "gemini-1.5-flash-002": {
            "rating": 1291.0635147463024,
            "rating_q975": 1299.0412334853427,
            "rating_q025": 1283.0857960072622
        },
        "deepseek-v2.5": {
            "rating": 1290.5089379446354,
            "rating_q975": 1299.6979681913142,
            "rating_q025": 1281.3199076979565
        },
        "mistral-large-2407": {
            "rating": 1290.4573297189045,
            "rating_q975": 1297.829357006522,
            "rating_q025": 1283.085302431287
        },
        "glm-4-plus": {
            "rating": 1289.9483238232092,
            "rating_q975": 1299.3363635574658,
            "rating_q025": 1280.5602840889526
        },
        "magistral-medium-2506": {
            "rating": 1286.5846542587742,
            "rating_q975": 1311.42090716441,
            "rating_q025": 1261.7484013531384
        },
        "claude-3-5-haiku-20241022": {
            "rating": 1285.257400614885,
            "rating_q975": 1292.3988835668163,
            "rating_q025": 1278.1159176629537
        },
        "mistral-large-2411": {
            "rating": 1283.9790589731563,
            "rating_q975": 1292.8127480869755,
            "rating_q025": 1275.145369859337
        },
        "mistral-small-3.1-24b-instruct-2503": {
            "rating": 1282.3649600562271,
            "rating_q975": 1295.0246345013354,
            "rating_q025": 1269.7052856111188
        },
        "gpt-4-0314": {
            "rating": 1282.2572422937162,
            "rating_q975": 1291.3399474349387,
            "rating_q025": 1273.1745371524937
        },
        "hunyuan-turbo-0110": {
            "rating": 1281.6905028697058,
            "rating_q975": 1312.173694046347,
            "rating_q025": 1251.2073116930646
        },
        "llama-3.1-nemotron-70b-instruct": {
            "rating": 1281.1450916113376,
            "rating_q975": 1297.6829036877198,
            "rating_q025": 1264.6072795349555
        },
        "gpt-4o-mini-2024-07-18": {
            "rating": 1278.7571853650707,
            "rating_q975": 1284.977601824332,
            "rating_q025": 1272.5367689058094
        },
        "gpt-4.1-nano-2025-04-14": {
            "rating": 1278.2817053661574,
            "rating_q975": 1301.3339948372202,
            "rating_q025": 1255.2294158950947
        },
        "qwen2-72b-instruct": {
            "rating": 1274.8581510413019,
            "rating_q975": 1283.6476979508952,
            "rating_q025": 1266.0686041317085
        },
        "grok-2-mini-2024-08-13": {
            "rating": 1274.8006166231655,
            "rating_q975": 1281.752104494274,
            "rating_q025": 1267.8491287520571
        },
        "gpt-4-0613": {
            "rating": 1273.976847862889,
            "rating_q975": 1281.7087872109234,
            "rating_q025": 1266.2449085148544
        },
        "qwen2.5-coder-32b-instruct": {
            "rating": 1272.634096765174,
            "rating_q975": 1291.6279862435654,
            "rating_q025": 1253.6402072867827
        },
        "llama-3.1-nemotron-51b-instruct": {
            "rating": 1272.169712853914,
            "rating_q975": 1294.43838752665,
            "rating_q025": 1249.901038181178
        },
        "amazon-nova-pro-v1.0": {
            "rating": 1271.916281756349,
            "rating_q975": 1281.3183704246323,
            "rating_q025": 1262.5141930880657
        },
        "llama-3.1-70b-instruct": {
            "rating": 1271.657692835384,
            "rating_q975": 1278.5123942144662,
            "rating_q025": 1264.802991456302
        },
        "deepseek-coder-v2": {
            "rating": 1271.2912790558885,
            "rating_q975": 1284.3651265577143,
            "rating_q025": 1258.2174315540626
        },
        "gemma-3n-e4b-it": {
            "rating": 1270.1527985812845,
            "rating_q975": 1284.5599683311489,
            "rating_q025": 1255.7456288314202
        },
        "phi-4": {
            "rating": 1267.126285378426,
            "rating_q975": 1277.2116836569705,
            "rating_q025": 1257.0408870998815
        },
        "llama-3.1-tulu-3-70b": {
            "rating": 1264.2653526137876,
            "rating_q975": 1288.5199043821322,
            "rating_q025": 1240.010800845443
        },
        "mistral-small-24b-instruct-2501": {
            "rating": 1263.6263660543348,
            "rating_q975": 1276.6601148912432,
            "rating_q025": 1250.5926172174263
        },
        "athene-70b-0725": {
            "rating": 1261.0056357342974,
            "rating_q975": 1270.8919673806881,
            "rating_q025": 1251.1193040879066
        },
        "llama-3-70b-instruct": {
            "rating": 1258.2520665943111,
            "rating_q975": 1264.8844601208418,
            "rating_q025": 1251.6196730677805
        },
        "gemma-3-4b-it": {
            "rating": 1257.2126624670232,
            "rating_q975": 1285.361620237479,
            "rating_q025": 1229.0637046965674
        },
        "gemini-1.5-flash-001": {
            "rating": 1256.70120479321,
            "rating_q975": 1264.026712840062,
            "rating_q025": 1249.3756967463582
        },
        "nemotron-4-340b-instruct": {
            "rating": 1254.964170463646,
            "rating_q975": 1266.509440733128,
            "rating_q025": 1243.418900194164
        },
        "claude-3-sonnet-20240229": {
            "rating": 1254.471832541091,
            "rating_q975": 1261.8175263067249,
            "rating_q025": 1247.1261387754573
        },
        "hunyuan-standard-256k": {
            "rating": 1253.9958663889024,
            "rating_q975": 1282.0923622158161,
            "rating_q025": 1225.8993705619887
        },
        "glm-4-0520": {
            "rating": 1248.3580199160037,
            "rating_q975": 1263.4815332254648,
            "rating_q025": 1233.2345066065427
        },
        "reka-core-20240904": {
            "rating": 1247.958612190972,
            "rating_q975": 1261.8442653057716,
            "rating_q025": 1234.0729590761723
        },
        "amazon-nova-lite-v1.0": {
            "rating": 1247.528868799982,
            "rating_q975": 1257.906923952586,
            "rating_q025": 1237.150813647378
        },
        "jamba-1.5-large": {
            "rating": 1247.0637922327742,
            "rating_q975": 1262.082907267788,
            "rating_q025": 1232.0446771977604
        },
        "mistral-large-2402": {
            "rating": 1245.1010553938563,
            "rating_q975": 1253.489898201124,
            "rating_q025": 1236.7122125865885
        },
        "gemma-2-27b-it": {
            "rating": 1243.8494478447828,
            "rating_q975": 1249.9457003294779,
            "rating_q025": 1237.7531953600878
        },
        "reka-flash-20240904": {
            "rating": 1232.8259902020136,
            "rating_q975": 1246.4802007563783,
            "rating_q025": 1219.171779647649
        },
        "c4ai-aya-expanse-32b": {
            "rating": 1231.816794993204,
            "rating_q975": 1240.9187724768965,
            "rating_q025": 1222.7148175095115
        },
        "olmo-2-0325-32b-instruct": {
            "rating": 1231.7869673619218,
            "rating_q975": 1259.8862208357496,
            "rating_q025": 1203.687713888094
        },
        "command-r-plus-08-2024": {
            "rating": 1231.3667879030525,
            "rating_q975": 1244.8577016071656,
            "rating_q025": 1217.8758741989393
        },
        "claude-3-haiku-20240307": {
            "rating": 1231.070529000214,
            "rating_q975": 1237.7549123210697,
            "rating_q025": 1224.3861456793584
        },
        "gemini-1.5-flash-8b-001": {
            "rating": 1230.32776664333,
            "rating_q975": 1238.1812003880013,
            "rating_q025": 1222.4743328986588
        },
        "mixtral-8x22b-instruct-v0.1": {
            "rating": 1229.2672180481513,
            "rating_q975": 1237.5741832219853,
            "rating_q025": 1220.9602528743173
        },
        "amazon-nova-micro-v1.0": {
            "rating": 1227.9901481989984,
            "rating_q975": 1238.2957124618636,
            "rating_q025": 1217.6845839361333
        },
        "qwen1.5-110b-chat": {
            "rating": 1222.7867150736197,
            "rating_q975": 1233.5569381051398,
            "rating_q025": 1212.0164920420996
        },
        "mistral-medium": {
            "rating": 1222.3568808140146,
            "rating_q975": 1232.586110107631,
            "rating_q025": 1212.1276515203983
        },
        "qwq-32b-preview": {
            "rating": 1221.4897078497745,
            "rating_q975": 1245.6178474852852,
            "rating_q025": 1197.3615682142638
        },
        "phi-3-medium-4k-instruct": {
            "rating": 1217.263705415099,
            "rating_q975": 1227.2951586732484,
            "rating_q025": 1207.2322521569495
        },
        "gemma-2-9b-it": {
            "rating": 1216.2910948866063,
            "rating_q975": 1223.2743933788306,
            "rating_q025": 1209.307796394382
        },
        "ministral-8b-2410": {
            "rating": 1215.471864332916,
            "rating_q975": 1234.8089588860641,
            "rating_q025": 1196.134769779768
        },
        "yi-1.5-34b-chat": {
            "rating": 1215.0922991459383,
            "rating_q975": 1225.6075153530403,
            "rating_q025": 1204.5770829388364
        },
        "command-r-plus": {
            "rating": 1213.0099589358356,
            "rating_q975": 1220.7915909616586,
            "rating_q025": 1205.2283269100126
        },
        "reka-flash-21b-20240226-online": {
            "rating": 1212.39477334612,
            "rating_q975": 1225.677061167115,
            "rating_q025": 1199.112485525125
        },
        "llama-3.1-tulu-3-8b": {
            "rating": 1211.27894375957,
            "rating_q975": 1236.288803135021,
            "rating_q025": 1186.269084384119
        },
        "internlm2_5-20b-chat": {
            "rating": 1210.1850987529015,
            "rating_q975": 1224.5876962477669,
            "rating_q025": 1195.782501258036
        },
        "qwen1.5-72b-chat": {
            "rating": 1209.3023800012002,
            "rating_q975": 1218.37296146871,
            "rating_q025": 1200.2317985336904
        },
        "command-r-08-2024": {
            "rating": 1205.603400508422,
            "rating_q975": 1218.7423463980806,
            "rating_q025": 1192.4644546187635
        },
        "gemma-2-9b-it-simpo": {
            "rating": 1204.0759825338646,
            "rating_q975": 1218.8795939275092,
            "rating_q025": 1189.27237114022
        },
        "qwen1.5-32b-chat": {
            "rating": 1201.6278265164715,
            "rating_q975": 1212.7493040534368,
            "rating_q025": 1190.5063489795061
        },
        "gpt-3.5-turbo-1106": {
            "rating": 1201.0634626719843,
            "rating_q975": 1215.7898166173889,
            "rating_q025": 1186.3371087265798
        },
        "c4ai-aya-expanse-8b": {
            "rating": 1200.1912584074018,
            "rating_q975": 1214.872400246073,
            "rating_q025": 1185.5101165687306
        },
        "reka-flash-21b-20240226": {
            "rating": 1199.7078937741267,
            "rating_q975": 1210.5689646162498,
            "rating_q025": 1188.8468229320035
        },
        "gpt-3.5-turbo-0125": {
            "rating": 1198.328011163007,
            "rating_q975": 1206.1369783071495,
            "rating_q025": 1190.5190440188644
        },
        "granite-3.1-2b-instruct": {
            "rating": 1197.8600755586476,
            "rating_q975": 1223.8053536064629,
            "rating_q025": 1171.9147975108324
        },
        "zephyr-orpo-141b-A35b-v0.1": {
            "rating": 1197.2394129543936,
            "rating_q975": 1219.1860391418659,
            "rating_q025": 1175.2927867669214
        },
        "granite-3.0-8b-instruct": {
            "rating": 1195.965662399276,
            "rating_q975": 1214.3452137539907,
            "rating_q025": 1177.5861110445612
        },
        "dbrx-instruct-preview": {
            "rating": 1195.7060570070062,
            "rating_q975": 1206.6435861580667,
            "rating_q025": 1184.7685278559456
        },
        "gemini-pro": {
            "rating": 1195.464109524326,
            "rating_q975": 1214.2118685622324,
            "rating_q025": 1176.7163504864195
        },
        "phi-3-mini-4k-instruct-june-2024": {
            "rating": 1194.7527717343041,
            "rating_q975": 1207.8741282363117,
            "rating_q025": 1181.6314152322966
        },
        "phi-3-small-8k-instruct": {
            "rating": 1194.2457628300351,
            "rating_q975": 1206.4459596003785,
            "rating_q025": 1182.0455660596917
        },
        "granite-3.1-8b-instruct": {
            "rating": 1193.9436793669072,
            "rating_q975": 1221.514418921436,
            "rating_q025": 1166.3729398123785
        },
        "llama-3.1-8b-instruct": {
            "rating": 1193.8764366561704,
            "rating_q975": 1201.1197556435286,
            "rating_q025": 1186.6331176688122
        },
        "llama-3-8b-instruct": {
            "rating": 1193.280591856364,
            "rating_q975": 1200.3907116932296,
            "rating_q025": 1186.1704720194984
        },
        "mixtral-8x7b-instruct-v0.1": {
            "rating": 1192.1987809816424,
            "rating_q975": 1200.0908943660575,
            "rating_q025": 1184.3066675972273
        },
        "gemini-pro-dev-api": {
            "rating": 1191.3321995617007,
            "rating_q975": 1204.7647558102058,
            "rating_q025": 1177.8996433131956
        },
        "jamba-1.5-mini": {
            "rating": 1187.5085747808944,
            "rating_q975": 1203.1068507695215,
            "rating_q025": 1171.9102987922672
        },
        "command-r": {
            "rating": 1175.403876682008,
            "rating_q975": 1184.275402321518,
            "rating_q025": 1166.5323510424982
        },
        "granite-3.0-2b-instruct": {
            "rating": 1168.8894622649884,
            "rating_q975": 1187.362912596059,
            "rating_q025": 1150.4160119339178
        },
        "qwen1.5-14b-chat": {
            "rating": 1167.5529109199806,
            "rating_q975": 1180.6025784570422,
            "rating_q025": 1154.503243382919
        },
        "llama-3.2-3b-instruct": {
            "rating": 1166.5493528933375,
            "rating_q975": 1181.9800846290295,
            "rating_q025": 1151.1186211576455
        },
        "snowflake-arctic-instruct": {
            "rating": 1162.5033624257862,
            "rating_q975": 1173.2468438635126,
            "rating_q025": 1151.7598809880599
        },
        "gemma-2-2b-it": {
            "rating": 1161.3618646456925,
            "rating_q975": 1168.7991640650578,
            "rating_q025": 1153.9245652263273
        },
        "starling-lm-7b-beta": {
            "rating": 1160.2238721507604,
            "rating_q975": 1173.6772889859326,
            "rating_q025": 1146.7704553155882
        },
        "wizardlm-70b": {
            "rating": 1159.3135076399071,
            "rating_q975": 1178.1770801640516,
            "rating_q025": 1140.4499351157626
        },
        "openchat-3.5-0106": {
            "rating": 1157.5299478775307,
            "rating_q975": 1170.679289396399,
            "rating_q025": 1144.3806063586624
        },
        "gemma-1.1-7b-it": {
            "rating": 1156.0484671751594,
            "rating_q975": 1166.9365020887888,
            "rating_q025": 1145.16043226153
        },
        "deepseek-llm-67b-chat": {
            "rating": 1155.848304946192,
            "rating_q975": 1179.0973335522026,
            "rating_q025": 1132.5992763401814
        },
        "phi-3-mini-4k-instruct": {
            "rating": 1153.0677850096588,
            "rating_q975": 1164.8261741412052,
            "rating_q025": 1141.3093958781124
        },
        "yi-34b-chat": {
            "rating": 1152.6760113728246,
            "rating_q975": 1165.4446407253104,
            "rating_q025": 1139.907382020339
        },
        "smollm2-1.7b-instruct": {
            "rating": 1152.4605320798591,
            "rating_q975": 1184.795962240896,
            "rating_q025": 1120.1251019188223
        },
        "openhermes-2.5-mistral-7b": {
            "rating": 1150.7308033615118,
            "rating_q975": 1170.448017846746,
            "rating_q025": 1131.0135888762775
        },
        "tulu-2-dpo-70b": {
            "rating": 1146.7808713408504,
            "rating_q975": 1165.5102723228504,
            "rating_q025": 1128.0514703588503
        },
        "phi-3-mini-128k-instruct": {
            "rating": 1139.7493756701992,
            "rating_q975": 1152.491522876882,
            "rating_q025": 1127.0072284635164
        },
        "llama-2-70b-chat": {
            "rating": 1136.764670229646,
            "rating_q975": 1146.474079756127,
            "rating_q025": 1127.0552607031652
        },
        "mistral-7b-instruct-v0.2": {
            "rating": 1129.5543819171921,
            "rating_q975": 1141.2327736105794,
            "rating_q025": 1117.8759902238048
        },
        "starling-lm-7b-alpha": {
            "rating": 1128.2276773019082,
            "rating_q975": 1143.5215613386767,
            "rating_q025": 1112.9337932651397
        },
        "llama-3.2-1b-instruct": {
            "rating": 1126.0056356520113,
            "rating_q975": 1141.753185654685,
            "rating_q025": 1110.2580856493375
        },
        "dolphin-2.2.1-mistral-7b": {
            "rating": 1125.6060045376576,
            "rating_q975": 1158.0022911710585,
            "rating_q025": 1093.2097179042566
        },
        "qwen-14b-chat": {
            "rating": 1124.7120699341124,
            "rating_q975": 1148.1013222713768,
            "rating_q025": 1101.322817596848
        },
        "openchat-3.5": {
            "rating": 1123.7237582683215,
            "rating_q975": 1141.717504371333,
            "rating_q025": 1105.73001216531
        },
        "qwen1.5-7b-chat": {
            "rating": 1121.349504750367,
            "rating_q975": 1141.518577789301,
            "rating_q025": 1101.1804317114331
        },
        "llama2-70b-steerlm-chat": {
            "rating": 1116.3773392009725,
            "rating_q975": 1142.797765350239,
            "rating_q025": 1089.9569130517061
        },
        "vicuna-33b": {
            "rating": 1116.198581792971,
            "rating_q975": 1128.3202526906773,
            "rating_q025": 1104.0769108952647
        },
        "gemma-7b-it": {
            "rating": 1115.2522307286092,
            "rating_q975": 1131.3316773774923,
            "rating_q025": 1099.1727840797262
        },
        "palm-2": {
            "rating": 1111.6100680229424,
            "rating_q975": 1130.7849646680463,
            "rating_q025": 1092.4351713778385
        },
        "llama-2-13b-chat": {
            "rating": 1111.0265937389086,
            "rating_q975": 1123.9881299667495,
            "rating_q025": 1098.0650575110676
        },
        "solar-10.7b-instruct-v1.0": {
            "rating": 1110.3562921369353,
            "rating_q975": 1131.7694306534484,
            "rating_q025": 1088.9431536204222
        },
        "codellama-34b-instruct": {
            "rating": 1108.1346918046106,
            "rating_q975": 1127.1719195542685,
            "rating_q025": 1089.0974640549528
        },
        "gemma-1.1-2b-it": {
            "rating": 1104.252803347788,
            "rating_q975": 1119.8107698798672,
            "rating_q025": 1088.6948368157086
        },
        "nous-hermes-2-mixtral-8x7b-dpo": {
            "rating": 1095.9027541681246,
            "rating_q975": 1117.110897128551,
            "rating_q025": 1074.6946112076982
        },
        "mpt-30b-chat": {
            "rating": 1094.2026050326986,
            "rating_q975": 1127.9833775288848,
            "rating_q025": 1060.4218325365123
        },
        "llama-2-7b-chat": {
            "rating": 1087.2421796280325,
            "rating_q975": 1100.7476918999034,
            "rating_q025": 1073.7366673561617
        },
        "stripedhyena-nous-7b": {
            "rating": 1084.49602621777,
            "rating_q975": 1104.4780283020332,
            "rating_q025": 1064.5140241335066
        },
        "qwen1.5-4b-chat": {
            "rating": 1084.1088427773343,
            "rating_q975": 1101.42617087453,
            "rating_q025": 1066.7915146801386
        },
        "zephyr-7b-beta": {
            "rating": 1083.4936885327252,
            "rating_q975": 1100.1564717871888,
            "rating_q025": 1066.8309052782615
        },
        "vicuna-13b": {
            "rating": 1082.0181464688392,
            "rating_q975": 1095.284367961081,
            "rating_q025": 1068.7519249765974
        },
        "mistral-7b-instruct": {
            "rating": 1081.6201134054377,
            "rating_q975": 1100.1529962168686,
            "rating_q025": 1063.0872305940068
        },
        "guanaco-33b": {
            "rating": 1080.0763960355262,
            "rating_q975": 1112.3197082076065,
            "rating_q025": 1047.8330838634458
        },
        "gemma-2b-it": {
            "rating": 1066.8485496659166,
            "rating_q975": 1088.574797083019,
            "rating_q025": 1045.1223022488143
        },
        "wizardlm-13b": {
            "rating": 1064.5703421778223,
            "rating_q975": 1084.852290987601,
            "rating_q025": 1044.2883933680437
        },
        "olmo-7b-instruct": {
            "rating": 1056.725213705515,
            "rating_q975": 1075.4471661431403,
            "rating_q025": 1038.0032612678897
        },
        "vicuna-7b": {
            "rating": 1047.5192841382398,
            "rating_q975": 1068.771955553112,
            "rating_q025": 1026.2666127233674
        },
        "chatglm3-6b": {
            "rating": 1041.4121223306931,
            "rating_q975": 1064.5513234402367,
            "rating_q025": 1018.2729212211495
        },
        "gpt4all-13b-snoozy": {
            "rating": 995.3132393457863,
            "rating_q975": 1032.5446320654514,
            "rating_q025": 958.0818466261212
        },
        "alpaca-13b": {
            "rating": 984.2193489209455,
            "rating_q975": 1006.7960318544771,
            "rating_q025": 961.642665987414
        },
        "mpt-7b-chat": {
            "rating": 981.0658766105647,
            "rating_q975": 1006.1285185902258,
            "rating_q025": 956.0032346309036
        },
        "RWKV-4-Raven-14B": {
            "rating": 979.9038605957171,
            "rating_q975": 1004.0583084825965,
            "rating_q025": 955.7494127088377
        },
        "koala-13b": {
            "rating": 979.2349319972798,
            "rating_q975": 1000.3355051429065,
            "rating_q025": 958.134358851653
        },
        "chatglm-6b": {
            "rating": 975.4508107298884,
            "rating_q975": 1000.7581235173262,
            "rating_q025": 950.1434979424506
        },
        "chatglm2-6b": {
            "rating": 970.2614148846258,
            "rating_q975": 1004.9973218185022,
            "rating_q025": 935.5255079507493
        },
        "oasst-pythia-12b": {
            "rating": 955.6289870354046,
            "rating_q975": 977.3963975709974,
            "rating_q025": 933.8615764998119
        },
        "dolly-v2-12b": {
            "rating": 944.1414619193563,
            "rating_q975": 972.6461370072313,
            "rating_q025": 915.6367868314812
        },
        "fastchat-t5-3b": {
            "rating": 916.923462907497,
            "rating_q975": 942.6569585151069,
            "rating_q025": 891.189967299887
        },
        "llama-13b": {
            "rating": 910.1048778823397,
            "rating_q975": 942.9973731478383,
            "rating_q025": 877.2123826168411
        },
        "stablelm-tuned-alpha-7b": {
            "rating": 888.5454720247928,
            "rating_q975": 917.1673470407605,
            "rating_q025": 859.9235970088251
        }
    },
    "multiturn": {
        "claude-opus-4-1-20250805-thinking-16k": {
            "rating": 1470.7169969572783,
            "rating_q975": 1479.8387134029642,
            "rating_q025": 1461.5952805115924
        },
        "claude-sonnet-4-5-20250929": {
            "rating": 1469.868176736378,
            "rating_q975": 1487.4931529857124,
            "rating_q025": 1452.2432004870436
        },
        "chatgpt-4o-latest-20250326": {
            "rating": 1466.5715344616578,
            "rating_q975": 1473.964944667798,
            "rating_q025": 1459.1781242555178
        },
        "claude-sonnet-4-5-20250929-thinking-32k": {
            "rating": 1463.808325708796,
            "rating_q975": 1477.4079253080265,
            "rating_q025": 1450.2087261095655
        },
        "gpt-4.5-preview-2025-02-27": {
            "rating": 1461.463411309117,
            "rating_q975": 1474.763232429435,
            "rating_q025": 1448.163590188799
        },
        "claude-opus-4-1-20250805": {
            "rating": 1458.9471596752935,
            "rating_q975": 1467.1206352593542,
            "rating_q025": 1450.7736840912328
        },
        "gemini-2.5-pro": {
            "rating": 1454.195433095806,
            "rating_q975": 1461.3212406378238,
            "rating_q025": 1447.0696255537882
        },
        "qwen3-max-2025-09-23": {
            "rating": 1444.844128060612,
            "rating_q975": 1459.4560362282227,
            "rating_q025": 1430.2322198930015
        },
        "gpt-5-chat": {
            "rating": 1443.1615438614053,
            "rating_q975": 1452.0442360861518,
            "rating_q025": 1434.2788516366588
        },
        "qwen3-max-preview": {
            "rating": 1443.0211808201416,
            "rating_q975": 1452.7354147701926,
            "rating_q025": 1433.3069468700905
        },
        "claude-opus-4-20250514-thinking-16k": {
            "rating": 1433.7987423068118,
            "rating_q975": 1441.985554529918,
            "rating_q025": 1425.6119300837056
        },
        "qwen3-235b-a22b-instruct-2507": {
            "rating": 1429.4842982494872,
            "rating_q975": 1437.743377756551,
            "rating_q025": 1421.2252187424235
        },
        "grok-4-fast": {
            "rating": 1425.3928147468966,
            "rating_q975": 1442.2281512754114,
            "rating_q025": 1408.557478218382
        },
        "gpt-4.1-2025-04-14": {
            "rating": 1425.3136957815432,
            "rating_q975": 1432.5426497082901,
            "rating_q025": 1418.0847418547962
        },
        "claude-opus-4-20250514": {
            "rating": 1423.9253082093903,
            "rating_q975": 1431.5990504418924,
            "rating_q025": 1416.2515659768883
        },
        "gpt-5-high": {
            "rating": 1422.8890613560025,
            "rating_q975": 1432.4169798555201,
            "rating_q025": 1413.3611428564848
        },
        "qwen3-vl-235b-a22b-instruct": {
            "rating": 1422.1972652042189,
            "rating_q975": 1437.2935732111648,
            "rating_q025": 1407.100957197273
        },
        "o3-2025-04-16": {
            "rating": 1420.5247465745917,
            "rating_q975": 1427.6265979471098,
            "rating_q025": 1413.4228952020737
        },
        "deepseek-v3.2-exp-thinking": {
            "rating": 1418.7798109246864,
            "rating_q975": 1434.2172918406661,
            "rating_q025": 1403.3423300087068
        },
        "glm-4.6": {
            "rating": 1418.5524290567016,
            "rating_q975": 1433.4895661535681,
            "rating_q025": 1403.615291959835
        },
        "claude-haiku-4-5-20251001": {
            "rating": 1417.4949025423405,
            "rating_q975": 1432.1143112896518,
            "rating_q025": 1402.8754937950291
        },
        "kimi-k2-0711-preview": {
            "rating": 1417.3808037097306,
            "rating_q975": 1426.5087979300952,
            "rating_q025": 1408.252809489366
        },
        "deepseek-v3.1-terminus-thinking": {
            "rating": 1415.5455714232846,
            "rating_q975": 1439.2800073580154,
            "rating_q025": 1391.8111354885539
        },
        "claude-sonnet-4-20250514-thinking-32k": {
            "rating": 1414.7253824108445,
            "rating_q975": 1423.0225088602476,
            "rating_q025": 1406.4282559614414
        },
        "grok-4-0709": {
            "rating": 1413.732365480209,
            "rating_q975": 1422.1628367694448,
            "rating_q025": 1405.3018941909731
        },
        "deepseek-v3.1-thinking": {
            "rating": 1413.3316279175056,
            "rating_q975": 1427.0020707827773,
            "rating_q025": 1399.6611850522338
        },
        "mistral-medium-2508": {
            "rating": 1409.390720799936,
            "rating_q975": 1418.467220792957,
            "rating_q025": 1400.3142208069148
        },
        "grok-3-preview-02-24": {
            "rating": 1407.9138225809897,
            "rating_q975": 1416.848513851494,
            "rating_q025": 1398.9791313104854
        },
        "qwen3-235b-a22b-no-thinking": {
            "rating": 1406.2103696308113,
            "rating_q975": 1414.195922941719,
            "rating_q025": 1398.2248163199038
        },
        "deepseek-r1": {
            "rating": 1405.5310103776133,
            "rating_q975": 1417.324028151626,
            "rating_q025": 1393.7379926036006
        },
        "deepseek-v3-0324": {
            "rating": 1405.0555934394506,
            "rating_q975": 1412.3579105968447,
            "rating_q025": 1397.7532762820565
        },
        "glm-4.5": {
            "rating": 1405.0010055230562,
            "rating_q975": 1414.8869035816103,
            "rating_q025": 1395.115107464502
        },
        "deepseek-v3.1": {
            "rating": 1404.28696069433,
            "rating_q975": 1416.0253189016635,
            "rating_q025": 1392.5486024869965
        },
        "deepseek-r1-0528": {
            "rating": 1404.0488925730654,
            "rating_q975": 1414.9281554931288,
            "rating_q025": 1393.169629653002
        },
        "kimi-k2-0905-preview": {
            "rating": 1403.998390693321,
            "rating_q975": 1417.8248600452825,
            "rating_q025": 1390.1719213413594
        },
        "claude-sonnet-4-20250514": {
            "rating": 1403.4002238550927,
            "rating_q975": 1411.2656308282506,
            "rating_q025": 1395.5348168819348
        },
        "qwen3-next-80b-a3b-instruct": {
            "rating": 1402.0648733310534,
            "rating_q975": 1412.4796259554862,
            "rating_q025": 1391.6501207066206
        },
        "gemini-2.5-flash": {
            "rating": 1398.351364370639,
            "rating_q975": 1405.3950138199134,
            "rating_q025": 1391.3077149213645
        },
        "mistral-medium-2505": {
            "rating": 1397.6405409466377,
            "rating_q975": 1405.9751146963222,
            "rating_q025": 1389.3059671969531
        },
        "gemini-2.5-flash-preview-09-2025": {
            "rating": 1396.6592179560844,
            "rating_q975": 1409.0909431575185,
            "rating_q025": 1384.2274927546503
        },
        "claude-3-7-sonnet-20250219-thinking-32k": {
            "rating": 1395.5761865428485,
            "rating_q975": 1403.6194642244427,
            "rating_q025": 1387.5329088612543
        },
        "qwen3-235b-a22b-thinking-2507": {
            "rating": 1392.6396912272442,
            "rating_q975": 1408.1607546114521,
            "rating_q025": 1377.1186278430362
        },
        "deepseek-v3.1-terminus": {
            "rating": 1392.2989976776441,
            "rating_q975": 1414.5991735144696,
            "rating_q025": 1369.9988218408187
        },
        "qwen3-coder-480b-a35b-instruct": {
            "rating": 1391.333768508673,
            "rating_q975": 1401.1268163563668,
            "rating_q025": 1381.5407206609793
        },
        "longcat-flash-chat": {
            "rating": 1388.7784586861328,
            "rating_q975": 1401.846881505109,
            "rating_q025": 1375.7100358671566
        },
        "gpt-4.1-mini-2025-04-14": {
            "rating": 1388.3189818786952,
            "rating_q975": 1396.0150922434125,
            "rating_q025": 1380.622871513978
        },
        "mai-1-preview": {
            "rating": 1388.0835447554173,
            "rating_q975": 1399.5375361358601,
            "rating_q025": 1376.6295533749744
        },
        "o1-preview": {
            "rating": 1386.7359173971718,
            "rating_q975": 1395.697011201306,
            "rating_q025": 1377.7748235930376
        },
        "claude-3-5-sonnet-20241022": {
            "rating": 1386.4725871983637,
            "rating_q975": 1391.9932987527727,
            "rating_q025": 1380.9518756439547
        },
        "hunyuan-turbos-20250416": {
            "rating": 1385.5650848153416,
            "rating_q975": 1399.605946058412,
            "rating_q025": 1371.5242235722712
        },
        "o1-2024-12-17": {
            "rating": 1383.143002565712,
            "rating_q975": 1392.0467548931294,
            "rating_q025": 1374.2392502382947
        },
        "o4-mini-2025-04-16": {
            "rating": 1380.8750570178863,
            "rating_q975": 1388.2139948172096,
            "rating_q025": 1373.536119218563
        },
        "qwen3-30b-a3b-instruct-2507": {
            "rating": 1380.689203922549,
            "rating_q975": 1390.315971711109,
            "rating_q025": 1371.0624361339892
        },
        "hunyuan-t1-20250711": {
            "rating": 1379.5743840689045,
            "rating_q975": 1401.3177854662881,
            "rating_q025": 1357.8309826715208
        },
        "qwen3-vl-235b-a22b-thinking": {
            "rating": 1378.7485425485602,
            "rating_q975": 1395.287190595958,
            "rating_q025": 1362.2098945011624
        },
        "gpt-5-mini-high": {
            "rating": 1373.4520080600837,
            "rating_q975": 1383.561020050004,
            "rating_q025": 1363.3429960701635
        },
        "gemini-2.5-flash-lite-preview-09-2025-no-thinking": {
            "rating": 1372.2162561383545,
            "rating_q975": 1384.7226407529456,
            "rating_q025": 1359.7098715237635
        },
        "deepseek-v3": {
            "rating": 1369.075557975206,
            "rating_q975": 1378.636549976953,
            "rating_q025": 1359.5145659734592
        },
        "glm-4.5-air": {
            "rating": 1368.5508124152154,
            "rating_q975": 1377.6430954939606,
            "rating_q025": 1359.4585293364703
        },
        "qwen2.5-max": {
            "rating": 1368.3553991382382,
            "rating_q975": 1376.7400046523921,
            "rating_q025": 1359.9707936240843
        },
        "qwen3-235b-a22b": {
            "rating": 1367.6375713455825,
            "rating_q975": 1376.8887047135313,
            "rating_q025": 1358.3864379776337
        },
        "gemini-2.5-flash-lite-preview-06-17-thinking": {
            "rating": 1366.8773153214556,
            "rating_q975": 1375.298843171738,
            "rating_q025": 1358.4557874711732
        },
        "mistral-small-2506": {
            "rating": 1362.3496696589027,
            "rating_q975": 1373.0288282320917,
            "rating_q025": 1351.6705110857138
        },
        "command-a-03-2025": {
            "rating": 1358.9042497410078,
            "rating_q975": 1365.809435385836,
            "rating_q025": 1351.9990640961796
        },
        "gemma-3-27b-it": {
            "rating": 1357.7328775192611,
            "rating_q975": 1365.2048817675786,
            "rating_q025": 1350.2608732709436
        },
        "minimax-m1": {
            "rating": 1356.1615770172925,
            "rating_q975": 1364.4117333673926,
            "rating_q025": 1347.9114206671925
        },
        "glm-4.5v": {
            "rating": 1354.6073495913884,
            "rating_q975": 1374.47539134533,
            "rating_q025": 1334.7393078374466
        },
        "qwen-plus-0125": {
            "rating": 1348.7899999254337,
            "rating_q975": 1367.779144630925,
            "rating_q025": 1329.8008552199424
        },
        "grok-3-mini-high": {
            "rating": 1348.0992697588272,
            "rating_q975": 1359.2010722265545,
            "rating_q025": 1336.9974672910998
        },
        "claude-3-5-sonnet-20240620": {
            "rating": 1346.9972555127015,
            "rating_q975": 1353.8949772483272,
            "rating_q025": 1340.0995337770757
        },
        "grok-3-mini-beta": {
            "rating": 1343.9158209425577,
            "rating_q975": 1353.5713315884668,
            "rating_q025": 1334.2603102966486
        },
        "gemma-3-12b-it": {
            "rating": 1343.7820912618815,
            "rating_q975": 1369.6553378853287,
            "rating_q025": 1317.9088446384344
        },
        "qwen3-next-80b-a3b-thinking": {
            "rating": 1342.3785356029216,
            "rating_q975": 1355.1239099598567,
            "rating_q025": 1329.6331612459865
        },
        "o3-mini-high": {
            "rating": 1342.3715260016,
            "rating_q975": 1353.9469924507166,
            "rating_q025": 1330.7960595524833
        },
        "llama-3.1-nemotron-ultra-253b-v1": {
            "rating": 1338.6126231031262,
            "rating_q975": 1369.0145079227498,
            "rating_q025": 1308.2107382835027
        },
        "llama-3.1-405b-instruct-bf16": {
            "rating": 1338.1873580645802,
            "rating_q975": 1345.527359379508,
            "rating_q025": 1330.8473567496524
        },
        "hunyuan-turbos-20250226": {
            "rating": 1337.093918497975,
            "rating_q975": 1369.7820905674664,
            "rating_q025": 1304.4057464284836
        },
        "gpt-4o-2024-05-13": {
            "rating": 1336.4486808391114,
            "rating_q975": 1342.660851203965,
            "rating_q025": 1330.2365104742578
        },
        "o3-mini": {
            "rating": 1336.243789077987,
            "rating_q975": 1342.7694359215145,
            "rating_q025": 1329.7181422344595
        },
        "step-3": {
            "rating": 1336.0522150473164,
            "rating_q975": 1353.8286728389187,
            "rating_q025": 1318.275757255714
        },
        "amazon-nova-experimental-chat-10-09": {
            "rating": 1335.215844591266,
            "rating_q975": 1354.477519737652,
            "rating_q025": 1315.9541694448799
        },
        "qwen3-32b": {
            "rating": 1333.7511891770164,
            "rating_q975": 1357.237572381031,
            "rating_q025": 1310.2648059730018
        },
        "nvidia-llama-3.3-nemotron-super-49b-v1.5": {
            "rating": 1333.2979299040621,
            "rating_q975": 1356.856932440337,
            "rating_q025": 1309.7389273677873
        },
        "glm-4-plus-0111": {
            "rating": 1331.5819405580055,
            "rating_q975": 1350.9581268732052,
            "rating_q025": 1312.2057542428058
        },
        "llama-3.1-405b-instruct-fp8": {
            "rating": 1328.1398640377204,
            "rating_q975": 1334.9578428274247,
            "rating_q025": 1321.321885248016
        },
        "gemini-1.5-pro-002": {
            "rating": 1327.7712681416856,
            "rating_q975": 1334.3149676366736,
            "rating_q025": 1321.2275686466976
        },
        "yi-lightning": {
            "rating": 1326.9436038328759,
            "rating_q975": 1336.5148316385278,
            "rating_q025": 1317.372376027224
        },
        "gpt-5-nano-high": {
            "rating": 1326.4058300474899,
            "rating_q975": 1342.1609737908873,
            "rating_q025": 1310.6506863040925
        },
        "gemini-2.0-flash-lite-preview-02-05": {
            "rating": 1325.6102349275843,
            "rating_q975": 1335.2308504384646,
            "rating_q025": 1315.989619416704
        },
        "llama-3.3-nemotron-49b-super-v1": {
            "rating": 1324.8242527648551,
            "rating_q975": 1356.6223027102892,
            "rating_q025": 1293.026202819421
        },
        "gpt-4o-2024-08-06": {
            "rating": 1323.4277396953603,
            "rating_q975": 1330.9473796626157,
            "rating_q025": 1315.9080997281048
        },
        "claude-3-5-haiku-20241022": {
            "rating": 1323.2134246035343,
            "rating_q975": 1329.4010692277625,
            "rating_q025": 1317.0257799793062
        },
        "llama-4-maverick-17b-128e-instruct": {
            "rating": 1322.9837317579015,
            "rating_q975": 1330.8367516247743,
            "rating_q025": 1315.1307118910288
        },
        "hunyuan-turbo-0110": {
            "rating": 1322.216516242799,
            "rating_q975": 1351.5253292030343,
            "rating_q025": 1292.9077032825635
        },
        "grok-2-2024-08-13": {
            "rating": 1321.059346147379,
            "rating_q975": 1327.7442143216902,
            "rating_q025": 1314.374477973068
        },
        "step-1o-turbo-202506": {
            "rating": 1320.387443775532,
            "rating_q975": 1336.2589200747723,
            "rating_q025": 1304.5159674762915
        },
        "claude-3-opus-20240229": {
            "rating": 1320.0270942474403,
            "rating_q975": 1325.831296770548,
            "rating_q025": 1314.2228917243326
        },
        "llama-4-scout-17b-16e-instruct": {
            "rating": 1319.529315098563,
            "rating_q975": 1328.2658168621285,
            "rating_q025": 1310.7928133349976
        },
        "deepseek-v2.5-1210": {
            "rating": 1318.906373373485,
            "rating_q975": 1335.044985427116,
            "rating_q025": 1302.767761319854
        },
        "gemini-advanced-0514": {
            "rating": 1318.6486639578202,
            "rating_q975": 1327.9237642900791,
            "rating_q025": 1309.3735636255612
        },
        "gpt-oss-120b": {
            "rating": 1318.5806427723041,
            "rating_q975": 1327.925849788823,
            "rating_q025": 1309.2354357557854
        },
        "o1-mini": {
            "rating": 1318.5759931540888,
            "rating_q975": 1325.571881843884,
            "rating_q025": 1311.5801044642935
        },
        "qwen3-30b-a3b": {
            "rating": 1318.2654125403692,
            "rating_q975": 1327.4081174876746,
            "rating_q025": 1309.1227075930638
        },
        "qwq-32b": {
            "rating": 1318.19237769839,
            "rating_q975": 1327.7046845182274,
            "rating_q025": 1308.6800708785524
        },
        "llama-3.3-70b-instruct": {
            "rating": 1316.2332154918367,
            "rating_q975": 1322.6347857867245,
            "rating_q025": 1309.831645196949
        },
        "ling-flash-2.0": {
            "rating": 1315.8422488702654,
            "rating_q975": 1333.1415964224018,
            "rating_q025": 1298.542901318129
        },
        "magistral-medium-2506": {
            "rating": 1312.3574877404203,
            "rating_q975": 1327.3318639462586,
            "rating_q025": 1297.383111534582
        },
        "gemini-1.5-pro-001": {
            "rating": 1312.3173515954654,
            "rating_q975": 1319.7303030773057,
            "rating_q025": 1304.9044001136251
        },
        "gpt-4.1-nano-2025-04-14": {
            "rating": 1310.6997377128637,
            "rating_q975": 1328.8274308334285,
            "rating_q025": 1292.5720445922989
        },
        "glm-4-plus": {
            "rating": 1309.5555119310707,
            "rating_q975": 1318.7075206344377,
            "rating_q025": 1300.4035032277036
        },
        "gpt-4-turbo-2024-04-09": {
            "rating": 1309.1631416331993,
            "rating_q975": 1316.229909277301,
            "rating_q025": 1302.0963739890976
        },
        "hunyuan-large-2025-02-10": {
            "rating": 1307.3628460649124,
            "rating_q975": 1332.4746926675023,
            "rating_q025": 1282.2509994623226
        },
        "gpt-4o-mini-2024-07-18": {
            "rating": 1305.9825890451434,
            "rating_q975": 1312.2713431369227,
            "rating_q025": 1299.693834953364
        },
        "step-2-16k-exp-202412": {
            "rating": 1302.7947447266852,
            "rating_q975": 1322.6853113139011,
            "rating_q025": 1282.9041781394692
        },
        "qwen2.5-plus-1127": {
            "rating": 1302.2360963876677,
            "rating_q975": 1315.3655904586324,
            "rating_q025": 1289.106602316703
        },
        "athene-v2-chat": {
            "rating": 1302.1399398397048,
            "rating_q975": 1311.120262218876,
            "rating_q025": 1293.1596174605336
        },
        "qwen-max-0919": {
            "rating": 1301.534412425368,
            "rating_q975": 1312.2958592770708,
            "rating_q025": 1290.772965573665
        },
        "gpt-4-1106-preview": {
            "rating": 1296.678136100252,
            "rating_q975": 1304.093302215715,
            "rating_q025": 1289.262969984789
        },
        "hunyuan-standard-2025-02-10": {
            "rating": 1296.6472218307108,
            "rating_q975": 1320.4967365466646,
            "rating_q025": 1272.797707114757
        },
        "qwen2.5-72b-instruct": {
            "rating": 1294.9197752470823,
            "rating_q975": 1302.4608283003954,
            "rating_q025": 1287.3787221937691
        },
        "mistral-large-2407": {
            "rating": 1293.313640597175,
            "rating_q975": 1300.8574556095273,
            "rating_q025": 1285.7698255848227
        },
        "grok-2-mini-2024-08-13": {
            "rating": 1292.979338729374,
            "rating_q975": 1299.9897616721628,
            "rating_q025": 1285.968915786585
        },
        "athene-70b-0725": {
            "rating": 1292.0986364238931,
            "rating_q975": 1302.6941171913013,
            "rating_q025": 1281.503155656485
        },
        "gemma-3n-e4b-it": {
            "rating": 1291.4997680136466,
            "rating_q975": 1301.8608650062145,
            "rating_q025": 1281.1386710210788
        },
        "mistral-large-2411": {
            "rating": 1291.0514029350186,
            "rating_q975": 1299.7635230213832,
            "rating_q025": 1282.339282848654
        },
        "llama-3.1-nemotron-70b-instruct": {
            "rating": 1290.1314155488208,
            "rating_q975": 1306.7636080336033,
            "rating_q025": 1273.4992230640382
        },
        "mistral-small-3.1-24b-instruct-2503": {
            "rating": 1290.0900669606003,
            "rating_q975": 1298.7418619930845,
            "rating_q025": 1281.4382719281161
        },
        "gpt-4-0125-preview": {
            "rating": 1289.4779860797141,
            "rating_q975": 1296.9281148179916,
            "rating_q025": 1282.0278573414366
        },
        "deepseek-v2.5": {
            "rating": 1288.5148156741054,
            "rating_q975": 1297.8656409725554,
            "rating_q025": 1279.1639903756554
        },
        "llama-3.1-70b-instruct": {
            "rating": 1286.6742025255421,
            "rating_q975": 1293.4711847323103,
            "rating_q025": 1279.8772203187739
        },
        "gpt-oss-20b": {
            "rating": 1286.6713665693287,
            "rating_q975": 1300.975868762478,
            "rating_q025": 1272.3668643761794
        },
        "ring-flash-2.0": {
            "rating": 1279.9729148753017,
            "rating_q975": 1297.5596064027486,
            "rating_q025": 1262.3862233478549
        },
        "gemma-2-27b-it": {
            "rating": 1276.838690724167,
            "rating_q975": 1282.9595133128976,
            "rating_q025": 1270.7178681354364
        },
        "llama-3.1-tulu-3-70b": {
            "rating": 1276.3783440445527,
            "rating_q975": 1299.461913394566,
            "rating_q025": 1253.2947746945395
        },
        "hunyuan-large-vision": {
            "rating": 1276.175005768886,
            "rating_q975": 1295.6986569775972,
            "rating_q025": 1256.6513545601747
        },
        "claude-3-sonnet-20240229": {
            "rating": 1276.1394042665502,
            "rating_q975": 1283.7968743081497,
            "rating_q025": 1268.4819342249507
        },
        "gemini-1.5-flash-002": {
            "rating": 1275.6467958914245,
            "rating_q975": 1283.6363520247307,
            "rating_q025": 1267.6572397581183
        },
        "llama-3.1-nemotron-51b-instruct": {
            "rating": 1274.7969764880559,
            "rating_q975": 1294.7820349673877,
            "rating_q025": 1254.811918008724
        },
        "amazon-nova-pro-v1.0": {
            "rating": 1273.7489583052798,
            "rating_q975": 1282.8480924084513,
            "rating_q025": 1264.6498242021082
        },
        "llama-3-70b-instruct": {
            "rating": 1270.9335998481076,
            "rating_q975": 1277.917560880436,
            "rating_q025": 1263.9496388157793
        },
        "gemma-3-4b-it": {
            "rating": 1270.8712738774445,
            "rating_q975": 1294.581754015593,
            "rating_q025": 1247.160793739296
        },
        "gpt-4-0314": {
            "rating": 1269.7967288969362,
            "rating_q975": 1279.4068338458392,
            "rating_q025": 1260.1866239480332
        },
        "gemma-2-9b-it-simpo": {
            "rating": 1268.950275738196,
            "rating_q975": 1283.3413778344432,
            "rating_q025": 1254.559173641949
        },
        "gemini-1.5-flash-001": {
            "rating": 1266.8729172396265,
            "rating_q975": 1274.4591858647718,
            "rating_q025": 1259.2866486144812
        },
        "jamba-1.5-large": {
            "rating": 1263.4417090525715,
            "rating_q975": 1277.79354484961,
            "rating_q025": 1249.089873255533
        },
        "reka-core-20240904": {
            "rating": 1261.999622220513,
            "rating_q975": 1278.1219487335352,
            "rating_q025": 1245.8772957074907
        },
        "gpt-4-0613": {
            "rating": 1258.5011048188685,
            "rating_q975": 1266.5728161898805,
            "rating_q025": 1250.4293934478565
        },
        "nemotron-4-340b-instruct": {
            "rating": 1256.4258792851115,
            "rating_q975": 1267.7305810592477,
            "rating_q025": 1245.1211775109753
        },
        "glm-4-0520": {
            "rating": 1255.8108642115803,
            "rating_q975": 1270.2120545057583,
            "rating_q025": 1241.4096739174024
        },
        "command-r-plus-08-2024": {
            "rating": 1248.6756753571622,
            "rating_q975": 1262.0640649400727,
            "rating_q025": 1235.2872857742516
        },
        "gemma-2-9b-it": {
            "rating": 1248.0672798916255,
            "rating_q975": 1254.9919505655123,
            "rating_q025": 1241.1426092177387
        },
        "mistral-small-24b-instruct-2501": {
            "rating": 1247.5096140869941,
            "rating_q975": 1260.2873628843095,
            "rating_q025": 1234.7318652896788
        },
        "qwen2.5-coder-32b-instruct": {
            "rating": 1246.5288976184374,
            "rating_q975": 1264.342771675725,
            "rating_q025": 1228.7150235611498
        },
        "claude-3-haiku-20240307": {
            "rating": 1242.9884042767148,
            "rating_q975": 1249.9257163121417,
            "rating_q025": 1236.051092241288
        },
        "olmo-2-0325-32b-instruct": {
            "rating": 1242.7944044094959,
            "rating_q975": 1272.0708238585266,
            "rating_q025": 1213.5179849604651
        },
        "qwen2-72b-instruct": {
            "rating": 1241.2987751612702,
            "rating_q975": 1250.194755049765,
            "rating_q025": 1232.4027952727754
        },
        "phi-4": {
            "rating": 1238.8433507910452,
            "rating_q975": 1248.890915036686,
            "rating_q025": 1228.7957865454043
        },
        "command-r-plus": {
            "rating": 1235.9540581540898,
            "rating_q975": 1244.099993091179,
            "rating_q025": 1227.8081232170007
        },
        "reka-flash-20240904": {
            "rating": 1235.2184616668947,
            "rating_q975": 1251.0730077905614,
            "rating_q025": 1219.363915543228
        },
        "deepseek-coder-v2": {
            "rating": 1232.9762131821017,
            "rating_q975": 1245.1211622730996,
            "rating_q025": 1220.8312640911038
        },
        "c4ai-aya-expanse-32b": {
            "rating": 1230.2411233383034,
            "rating_q975": 1239.0380599183193,
            "rating_q025": 1221.4441867582875
        },
        "amazon-nova-lite-v1.0": {
            "rating": 1225.6409773246573,
            "rating_q975": 1235.9731778768353,
            "rating_q025": 1215.3087767724794
        },
        "mistral-large-2402": {
            "rating": 1223.9268612915266,
            "rating_q975": 1232.860355808735,
            "rating_q025": 1214.9933667743182
        },
        "gemini-1.5-flash-8b-001": {
            "rating": 1219.923288228318,
            "rating_q975": 1228.017593134354,
            "rating_q025": 1211.8289833222818
        },
        "qwen1.5-72b-chat": {
            "rating": 1215.773890252254,
            "rating_q975": 1225.8416323970102,
            "rating_q025": 1205.7061481074977
        },
        "qwen1.5-110b-chat": {
            "rating": 1211.0503879054331,
            "rating_q975": 1222.2155211590027,
            "rating_q025": 1199.8852546518635
        },
        "command-r-08-2024": {
            "rating": 1210.7518422942467,
            "rating_q975": 1224.282719257529,
            "rating_q025": 1197.2209653309644
        },
        "amazon-nova-micro-v1.0": {
            "rating": 1208.4274194085892,
            "rating_q975": 1219.0137730337267,
            "rating_q025": 1197.8410657834518
        },
        "hunyuan-standard-256k": {
            "rating": 1204.2271889660997,
            "rating_q975": 1229.0159961019058,
            "rating_q025": 1179.4383818302936
        },
        "ministral-8b-2410": {
            "rating": 1204.19330833718,
            "rating_q975": 1223.0594621214873,
            "rating_q025": 1185.3271545528728
        },
        "llama-3-8b-instruct": {
            "rating": 1203.1536545148622,
            "rating_q975": 1210.9026093639875,
            "rating_q025": 1195.4046996657369
        },
        "jamba-1.5-mini": {
            "rating": 1202.87220541034,
            "rating_q975": 1217.353322375994,
            "rating_q025": 1188.3910884446861
        },
        "reka-flash-21b-20240226-online": {
            "rating": 1202.7994401616106,
            "rating_q975": 1217.4815272760347,
            "rating_q025": 1188.1173530471865
        },
        "gpt-3.5-turbo-0125": {
            "rating": 1198.59433130441,
            "rating_q975": 1206.9608779017442,
            "rating_q025": 1190.2277847070757
        },
        "gemini-pro": {
            "rating": 1197.7216478779383,
            "rating_q975": 1222.5654308994951,
            "rating_q025": 1172.8778648563814
        },
        "c4ai-aya-expanse-8b": {
            "rating": 1197.3387722778411,
            "rating_q975": 1211.6345281327356,
            "rating_q025": 1183.0430164229467
        },
        "command-r": {
            "rating": 1196.478603509355,
            "rating_q975": 1205.681734412595,
            "rating_q025": 1187.275472606115
        },
        "llama-3.1-8b-instruct": {
            "rating": 1195.4477122385665,
            "rating_q975": 1202.7888783520748,
            "rating_q025": 1188.1065461250582
        },
        "mistral-medium": {
            "rating": 1194.2071697886759,
            "rating_q975": 1205.3514044422243,
            "rating_q025": 1183.0629351351274
        },
        "reka-flash-21b-20240226": {
            "rating": 1192.1245474097673,
            "rating_q975": 1203.9731187891925,
            "rating_q025": 1180.275976030342
        },
        "qwen1.5-32b-chat": {
            "rating": 1191.6556148313532,
            "rating_q975": 1203.7486551402824,
            "rating_q025": 1179.562574522424
        },
        "yi-1.5-34b-chat": {
            "rating": 1187.0395706355876,
            "rating_q975": 1198.0326465748265,
            "rating_q025": 1176.0464946963486
        },
        "mixtral-8x22b-instruct-v0.1": {
            "rating": 1186.0194527427739,
            "rating_q975": 1194.779961883182,
            "rating_q025": 1177.2589436023657
        },
        "gemini-pro-dev-api": {
            "rating": 1184.2757158593595,
            "rating_q975": 1198.719093372842,
            "rating_q025": 1169.832338345877
        },
        "llama-3.1-tulu-3-8b": {
            "rating": 1175.1713616427537,
            "rating_q975": 1200.5187348178013,
            "rating_q025": 1149.8239884677062
        },
        "dbrx-instruct-preview": {
            "rating": 1172.9816930051807,
            "rating_q975": 1184.465875656928,
            "rating_q025": 1161.4975103534334
        },
        "gpt-3.5-turbo-1106": {
            "rating": 1168.8481126798754,
            "rating_q975": 1184.5385839510411,
            "rating_q025": 1153.1576414087097
        },
        "mixtral-8x7b-instruct-v0.1": {
            "rating": 1166.3321060496692,
            "rating_q975": 1174.6634620360303,
            "rating_q025": 1158.000750063308
        },
        "internlm2_5-20b-chat": {
            "rating": 1165.8904442774951,
            "rating_q975": 1180.3804032367168,
            "rating_q025": 1151.4004853182735
        },
        "wizardlm-70b": {
            "rating": 1164.8046703131267,
            "rating_q975": 1184.0867842192656,
            "rating_q025": 1145.5225564069879
        },
        "qwen1.5-14b-chat": {
            "rating": 1163.9147775147894,
            "rating_q975": 1177.9984027688868,
            "rating_q025": 1149.831152260692
        },
        "gemma-2-2b-it": {
            "rating": 1161.1665954652594,
            "rating_q975": 1169.0109546247581,
            "rating_q025": 1153.3222363057607
        },
        "yi-34b-chat": {
            "rating": 1159.35530387954,
            "rating_q975": 1173.9280522649572,
            "rating_q025": 1144.782555494123
        },
        "zephyr-orpo-141b-A35b-v0.1": {
            "rating": 1158.5513903461492,
            "rating_q975": 1182.4413189815587,
            "rating_q025": 1134.6614617107398
        },
        "granite-3.1-8b-instruct": {
            "rating": 1156.9147615537454,
            "rating_q975": 1182.5847689954776,
            "rating_q025": 1131.2447541120132
        },
        "openchat-3.5": {
            "rating": 1154.1000195945373,
            "rating_q975": 1172.807577402671,
            "rating_q025": 1135.3924617864036
        },
        "openchat-3.5-0106": {
            "rating": 1150.7552534601837,
            "rating_q975": 1165.7019740978844,
            "rating_q025": 1135.808532822483
        },
        "deepseek-llm-67b-chat": {
            "rating": 1150.1046315615874,
            "rating_q975": 1174.4065169991413,
            "rating_q025": 1125.8027461240335
        },
        "llama-3.2-3b-instruct": {
            "rating": 1147.7144054023852,
            "rating_q975": 1164.604824493648,
            "rating_q025": 1130.8239863111223
        },
        "qwq-32b-preview": {
            "rating": 1146.1443631046507,
            "rating_q975": 1173.2383721040294,
            "rating_q025": 1119.050354105272
        },
        "starling-lm-7b-beta": {
            "rating": 1144.1928995783705,
            "rating_q975": 1159.1680709723523,
            "rating_q025": 1129.2177281843888
        },
        "granite-3.1-2b-instruct": {
            "rating": 1142.7075606467315,
            "rating_q975": 1169.8966403595675,
            "rating_q025": 1115.5184809338955
        },
        "snowflake-arctic-instruct": {
            "rating": 1141.18700246024,
            "rating_q975": 1153.5517383794345,
            "rating_q025": 1128.8222665410453
        },
        "vicuna-33b": {
            "rating": 1138.8528249335936,
            "rating_q975": 1151.63595653958,
            "rating_q025": 1126.0696933276072
        },
        "phi-3-medium-4k-instruct": {
            "rating": 1137.9172437710731,
            "rating_q975": 1148.6890670146347,
            "rating_q025": 1127.1454205275115
        },
        "granite-3.0-8b-instruct": {
            "rating": 1135.5525824647343,
            "rating_q975": 1155.228490621702,
            "rating_q025": 1115.8766743077667
        },
        "tulu-2-dpo-70b": {
            "rating": 1134.2818154385286,
            "rating_q975": 1155.3593068371156,
            "rating_q025": 1113.2043240399416
        },
        "openhermes-2.5-mistral-7b": {
            "rating": 1133.258655617075,
            "rating_q975": 1155.680209311874,
            "rating_q025": 1110.837101922276
        },
        "llama-2-70b-chat": {
            "rating": 1133.1575288011736,
            "rating_q975": 1143.4409050846923,
            "rating_q025": 1122.874152517655
        },
        "starling-lm-7b-alpha": {
            "rating": 1132.3369638153054,
            "rating_q975": 1149.7713459869146,
            "rating_q025": 1114.902581643696
        },
        "nous-hermes-2-mixtral-8x7b-dpo": {
            "rating": 1126.9722638794815,
            "rating_q975": 1152.9305470862878,
            "rating_q025": 1101.0139806726752
        },
        "mpt-30b-chat": {
            "rating": 1123.1832845347153,
            "rating_q975": 1154.842465185002,
            "rating_q025": 1091.5241038844285
        },
        "gemma-1.1-7b-it": {
            "rating": 1120.3197041827073,
            "rating_q975": 1131.804782168041,
            "rating_q025": 1108.8346261973736
        },
        "phi-3-small-8k-instruct": {
            "rating": 1116.844977122731,
            "rating_q975": 1128.884259884046,
            "rating_q025": 1104.805694361416
        },
        "granite-3.0-2b-instruct": {
            "rating": 1116.2310735535166,
            "rating_q975": 1135.1133575568751,
            "rating_q025": 1097.348789550158
        },
        "llama2-70b-steerlm-chat": {
            "rating": 1113.3742021621636,
            "rating_q975": 1141.264940588001,
            "rating_q025": 1085.483463736326
        },
        "mistral-7b-instruct-v0.2": {
            "rating": 1112.8979588324546,
            "rating_q975": 1125.865960106168,
            "rating_q025": 1099.9299575587413
        },
        "qwen1.5-7b-chat": {
            "rating": 1111.5470670609773,
            "rating_q975": 1136.5182785331385,
            "rating_q025": 1086.575855588816
        },
        "solar-10.7b-instruct-v1.0": {
            "rating": 1109.9526611568085,
            "rating_q975": 1135.0410154672288,
            "rating_q025": 1084.8643068463882
        },
        "wizardlm-13b": {
            "rating": 1106.3294221878411,
            "rating_q975": 1126.1252824741648,
            "rating_q025": 1086.5335619015175
        },
        "llama-2-13b-chat": {
            "rating": 1099.4804665334823,
            "rating_q975": 1113.2109805159334,
            "rating_q025": 1085.7499525510311
        },
        "vicuna-13b": {
            "rating": 1098.743850118163,
            "rating_q975": 1112.6116137901233,
            "rating_q025": 1084.8760864462026
        },
        "phi-3-mini-4k-instruct-june-2024": {
            "rating": 1096.5207259993927,
            "rating_q975": 1111.1387848527013,
            "rating_q025": 1081.902667146084
        },
        "falcon-180b-chat": {
            "rating": 1094.0458822220685,
            "rating_q975": 1133.9354095385195,
            "rating_q025": 1054.1563549056175
        },
        "qwen-14b-chat": {
            "rating": 1092.014438584341,
            "rating_q975": 1115.371940697696,
            "rating_q025": 1068.656936470986
        },
        "zephyr-7b-beta": {
            "rating": 1088.150098302066,
            "rating_q975": 1105.5939047507513,
            "rating_q025": 1070.7062918533807
        },
        "palm-2": {
            "rating": 1087.7972367289317,
            "rating_q975": 1107.40920567494,
            "rating_q025": 1068.1852677829233
        },
        "dolphin-2.2.1-mistral-7b": {
            "rating": 1083.329509346843,
            "rating_q975": 1124.6109265498317,
            "rating_q025": 1042.0480921438543
        },
        "mistral-7b-instruct": {
            "rating": 1079.587652740301,
            "rating_q975": 1098.7848030227626,
            "rating_q025": 1060.3905024578396
        },
        "llama-3.2-1b-instruct": {
            "rating": 1075.5346385435078,
            "rating_q975": 1094.1081416426055,
            "rating_q025": 1056.96113544441
        },
        "stripedhyena-nous-7b": {
            "rating": 1075.441356088101,
            "rating_q975": 1098.3538668562455,
            "rating_q025": 1052.5288453199564
        },
        "llama-2-7b-chat": {
            "rating": 1075.353976084255,
            "rating_q975": 1090.300113714665,
            "rating_q025": 1060.407838453845
        },
        "codellama-34b-instruct": {
            "rating": 1072.052042695142,
            "rating_q975": 1090.4895612796975,
            "rating_q025": 1053.6145241105867
        },
        "zephyr-7b-alpha": {
            "rating": 1071.4876724092521,
            "rating_q975": 1105.5993244214042,
            "rating_q025": 1037.3760203971
        },
        "guanaco-33b": {
            "rating": 1069.589353859964,
            "rating_q975": 1103.0976866858448,
            "rating_q025": 1036.081021034083
        },
        "phi-3-mini-4k-instruct": {
            "rating": 1063.8705698442081,
            "rating_q975": 1077.1225025880499,
            "rating_q025": 1050.6186371003664
        },
        "vicuna-7b": {
            "rating": 1059.5351667036869,
            "rating_q975": 1080.4199674607416,
            "rating_q025": 1038.650365946632
        },
        "phi-3-mini-128k-instruct": {
            "rating": 1057.1230644758568,
            "rating_q975": 1072.6088183457523,
            "rating_q025": 1041.6373106059614
        },
        "smollm2-1.7b-instruct": {
            "rating": 1053.8337644483036,
            "rating_q975": 1092.285922252792,
            "rating_q025": 1015.381606643815
        },
        "qwen1.5-4b-chat": {
            "rating": 1053.4446278141004,
            "rating_q975": 1072.149000362034,
            "rating_q025": 1034.7402552661667
        },
        "gemma-1.1-2b-it": {
            "rating": 1045.9762682626908,
            "rating_q975": 1063.756272462658,
            "rating_q025": 1028.1962640627237
        },
        "gemma-7b-it": {
            "rating": 1038.5042140834184,
            "rating_q975": 1057.1771282441143,
            "rating_q025": 1019.8312999227226
        },
        "olmo-7b-instruct": {
            "rating": 1037.8198847213562,
            "rating_q975": 1065.5025104627116,
            "rating_q025": 1010.1372589800008
        },
        "chatglm3-6b": {
            "rating": 1032.9079536821093,
            "rating_q975": 1058.52348797315,
            "rating_q025": 1007.2924193910686
        },
        "gemma-2b-it": {
            "rating": 1030.364194294088,
            "rating_q975": 1053.647889823142,
            "rating_q025": 1007.0804987650343
        },
        "gpt4all-13b-snoozy": {
            "rating": 1021.9981890176346,
            "rating_q975": 1059.794414782768,
            "rating_q025": 984.2019632525011
        },
        "alpaca-13b": {
            "rating": 1005.2278972018537,
            "rating_q975": 1030.9620728414766,
            "rating_q025": 979.4937215622307
        },
        "mpt-7b-chat": {
            "rating": 998.8481995032191,
            "rating_q975": 1027.7747934963772,
            "rating_q025": 969.9216055100611
        },
        "koala-13b": {
            "rating": 992.533559347275,
            "rating_q975": 1016.75854659454,
            "rating_q025": 968.3085721000099
        },
        "RWKV-4-Raven-14B": {
            "rating": 976.3794756038621,
            "rating_q975": 1003.6809018740807,
            "rating_q025": 949.0780493336435
        },
        "chatglm2-6b": {
            "rating": 975.8720352619608,
            "rating_q975": 1007.7932712818197,
            "rating_q025": 943.950799242102
        },
        "oasst-pythia-12b": {
            "rating": 956.0595554935029,
            "rating_q975": 981.541798863356,
            "rating_q025": 930.5773121236498
        },
        "fastchat-t5-3b": {
            "rating": 935.1863464700457,
            "rating_q975": 965.6181312612149,
            "rating_q025": 904.7545616788765
        },
        "chatglm-6b": {
            "rating": 920.121857056354,
            "rating_q975": 949.5887500109448,
            "rating_q025": 890.6549641017632
        },
        "stablelm-tuned-alpha-7b": {
            "rating": 895.0051792530362,
            "rating_q975": 929.2046014760768,
            "rating_q025": 860.8057570299956
        },
        "llama-13b": {
            "rating": 882.7833158242734,
            "rating_q975": 925.1615610737372,
            "rating_q025": 840.4050705748095
        },
        "dolly-v2-12b": {
            "rating": 857.8403162132469,
            "rating_q975": 893.1749496993141,
            "rating_q025": 822.5056827271796
        }
    },
    "no_refusal": {
        "gemini-2.5-pro": {
            "rating": 1451.1260202160338,
            "rating_q975": 1455.1334168329995,
            "rating_q025": 1447.118623599068
        },
        "claude-sonnet-4-5-20250929-thinking-32k": {
            "rating": 1446.2508229216837,
            "rating_q975": 1452.1689229507283,
            "rating_q025": 1440.3327228926391
        },
        "claude-opus-4-1-20250805-thinking-16k": {
            "rating": 1445.80530679978,
            "rating_q975": 1450.4240708971358,
            "rating_q025": 1441.1865427024243
        },
        "gpt-4.5-preview-2025-02-27": {
            "rating": 1441.1330677863486,
            "rating_q975": 1446.8246682467422,
            "rating_q025": 1435.441467325955
        },
        "claude-sonnet-4-5-20250929": {
            "rating": 1438.5338467242032,
            "rating_q975": 1446.0784155346407,
            "rating_q025": 1430.9892779137656
        },
        "chatgpt-4o-latest-20250326": {
            "rating": 1436.8606620305104,
            "rating_q975": 1440.7132191694473,
            "rating_q025": 1433.0081048915736
        },
        "claude-opus-4-1-20250805": {
            "rating": 1436.4691892836695,
            "rating_q975": 1440.8737329275243,
            "rating_q025": 1432.0646456398147
        },
        "gpt-5-high": {
            "rating": 1435.2273805844793,
            "rating_q975": 1440.0415129576945,
            "rating_q025": 1430.413248211264
        },
        "o3-2025-04-16": {
            "rating": 1433.1619562327207,
            "rating_q975": 1436.9597788487315,
            "rating_q025": 1429.36413361671
        },
        "qwen3-max-preview": {
            "rating": 1431.4741063640129,
            "rating_q975": 1436.3238419721413,
            "rating_q025": 1426.6243707558845
        },
        "glm-4.6": {
            "rating": 1428.822906876858,
            "rating_q975": 1435.2271192599444,
            "rating_q025": 1422.4186944937717
        },
        "deepseek-v3.2-exp": {
            "rating": 1427.722036279682,
            "rating_q975": 1454.6315730097847,
            "rating_q025": 1400.8124995495793
        },
        "gpt-5-chat": {
            "rating": 1422.5368232929802,
            "rating_q975": 1427.1233337601352,
            "rating_q025": 1417.9503128258252
        },
        "qwen3-max-2025-09-23": {
            "rating": 1421.4198540313578,
            "rating_q975": 1427.884008476721,
            "rating_q025": 1414.9556995859946
        },
        "claude-opus-4-20250514-thinking-16k": {
            "rating": 1420.4599489273808,
            "rating_q975": 1424.8350948097273,
            "rating_q025": 1416.0848030450343
        },
        "qwen3-235b-a22b-instruct-2507": {
            "rating": 1419.1065332617122,
            "rating_q975": 1423.4870714111391,
            "rating_q025": 1414.7259951122853
        },
        "deepseek-v3.2-exp-thinking": {
            "rating": 1418.8538543163618,
            "rating_q975": 1425.4636627665805,
            "rating_q025": 1412.244045866143
        },
        "grok-4-fast": {
            "rating": 1417.9299697256135,
            "rating_q975": 1425.5486054238781,
            "rating_q025": 1410.311334027349
        },
        "deepseek-r1-0528": {
            "rating": 1416.3533072167586,
            "rating_q975": 1421.9878849145857,
            "rating_q025": 1410.7187295189315
        },
        "deepseek-v3.1": {
            "rating": 1415.5762870522026,
            "rating_q975": 1421.635785765328,
            "rating_q025": 1409.5167883390773
        },
        "deepseek-v3.1-thinking": {
            "rating": 1414.6393862341395,
            "rating_q975": 1421.2615392977914,
            "rating_q025": 1408.0172331704875
        },
        "kimi-k2-0905-preview": {
            "rating": 1414.559492030036,
            "rating_q975": 1421.4194980244224,
            "rating_q025": 1407.6994860356494
        },
        "qwen3-vl-235b-a22b-instruct": {
            "rating": 1413.8180053993224,
            "rating_q975": 1420.5247847081666,
            "rating_q025": 1407.111226090478
        },
        "deepseek-v3.1-terminus": {
            "rating": 1413.4930609508092,
            "rating_q975": 1423.1184322982238,
            "rating_q025": 1403.8676896033946
        },
        "kimi-k2-0711-preview": {
            "rating": 1412.5616077277741,
            "rating_q975": 1417.41746353958,
            "rating_q025": 1407.7057519159682
        },
        "deepseek-v3.1-terminus-thinking": {
            "rating": 1411.6940141799928,
            "rating_q975": 1421.6569734449702,
            "rating_q025": 1401.7310549150154
        },
        "gpt-4.1-2025-04-14": {
            "rating": 1410.7108282446652,
            "rating_q975": 1414.619397064553,
            "rating_q025": 1406.8022594247775
        },
        "grok-4-0709": {
            "rating": 1410.575885549431,
            "rating_q975": 1414.8914253577987,
            "rating_q025": 1406.2603457410632
        },
        "mistral-medium-2508": {
            "rating": 1410.0865827127343,
            "rating_q975": 1414.7685073024315,
            "rating_q025": 1405.404658123037
        },
        "claude-opus-4-20250514": {
            "rating": 1408.7779099108475,
            "rating_q975": 1413.0804375988346,
            "rating_q025": 1404.4753822228604
        },
        "grok-3-preview-02-24": {
            "rating": 1408.748382858953,
            "rating_q975": 1413.0178414090005,
            "rating_q025": 1404.4789243089053
        },
        "glm-4.5": {
            "rating": 1407.4889902116745,
            "rating_q975": 1412.4077006767377,
            "rating_q025": 1402.5702797466113
        },
        "gemini-2.5-flash": {
            "rating": 1406.9914469795856,
            "rating_q975": 1410.911577907332,
            "rating_q025": 1403.0713160518392
        },
        "gemini-2.5-flash-preview-09-2025": {
            "rating": 1404.545139151557,
            "rating_q975": 1410.2260755135885,
            "rating_q025": 1398.8642027895253
        },
        "qwen3-next-80b-a3b-instruct": {
            "rating": 1401.3134015098024,
            "rating_q975": 1406.53049710069,
            "rating_q025": 1396.0963059189148
        },
        "claude-haiku-4-5-20251001": {
            "rating": 1400.9991297814709,
            "rating_q975": 1407.3551075258677,
            "rating_q025": 1394.643152037074
        },
        "o1-2024-12-17": {
            "rating": 1398.821908537137,
            "rating_q975": 1403.1908349412922,
            "rating_q025": 1394.4529821329818
        },
        "longcat-flash-chat": {
            "rating": 1398.6317848904791,
            "rating_q975": 1405.0815005443671,
            "rating_q025": 1392.1820692365911
        },
        "qwen3-235b-a22b-no-thinking": {
            "rating": 1397.478620609343,
            "rating_q975": 1402.0104058579761,
            "rating_q025": 1392.9468353607097
        },
        "qwen3-235b-a22b-thinking-2507": {
            "rating": 1396.8124761865467,
            "rating_q975": 1403.2961495865802,
            "rating_q025": 1390.3288027865133
        },
        "claude-sonnet-4-20250514-thinking-32k": {
            "rating": 1396.2907312084315,
            "rating_q975": 1400.7107136541538,
            "rating_q025": 1391.8707487627091
        },
        "deepseek-r1": {
            "rating": 1393.4144443057223,
            "rating_q975": 1398.2240689935488,
            "rating_q025": 1388.6048196178958
        },
        "gpt-5-mini-high": {
            "rating": 1392.3865354081734,
            "rating_q975": 1397.383626191734,
            "rating_q025": 1387.3894446246127
        },
        "qwen3-vl-235b-a22b-thinking": {
            "rating": 1391.7880741473475,
            "rating_q975": 1398.6405311464887,
            "rating_q025": 1384.9356171482063
        },
        "o1-preview": {
            "rating": 1389.6398614983634,
            "rating_q975": 1394.6211309180205,
            "rating_q025": 1384.6585920787063
        },
        "deepseek-v3-0324": {
            "rating": 1389.1526882108415,
            "rating_q975": 1393.0458658494024,
            "rating_q025": 1385.2595105722805
        },
        "o4-mini-2025-04-16": {
            "rating": 1389.132057846337,
            "rating_q975": 1393.1298907584166,
            "rating_q025": 1385.1342249342572
        },
        "mai-1-preview": {
            "rating": 1388.9060182786855,
            "rating_q975": 1394.3922521880208,
            "rating_q025": 1383.41978436935
        },
        "claude-sonnet-4-20250514": {
            "rating": 1386.3482877036251,
            "rating_q975": 1390.721204449906,
            "rating_q025": 1381.9753709573442
        },
        "hunyuan-t1-20250711": {
            "rating": 1385.0287161879824,
            "rating_q975": 1393.6820542771138,
            "rating_q025": 1376.375378098851
        },
        "claude-3-7-sonnet-20250219-thinking-32k": {
            "rating": 1382.8521320003977,
            "rating_q975": 1387.0234980653893,
            "rating_q025": 1378.680765935406
        },
        "qwen3-coder-480b-a35b-instruct": {
            "rating": 1382.7752124316357,
            "rating_q975": 1387.7940118042088,
            "rating_q025": 1377.7564130590627
        },
        "qwen3-30b-a3b-instruct-2507": {
            "rating": 1381.5566410032848,
            "rating_q975": 1386.4911839922593,
            "rating_q025": 1376.6220980143103
        },
        "mistral-medium-2505": {
            "rating": 1380.3893821391136,
            "rating_q975": 1385.093232307027,
            "rating_q025": 1375.6855319712004
        },
        "hunyuan-turbos-20250416": {
            "rating": 1378.7730874058107,
            "rating_q975": 1385.143530360014,
            "rating_q025": 1372.4026444516073
        },
        "gpt-4.1-mini-2025-04-14": {
            "rating": 1377.735859147181,
            "rating_q975": 1382.052798837751,
            "rating_q025": 1373.4189194566109
        },
        "gemini-2.5-flash-lite-preview-09-2025-no-thinking": {
            "rating": 1377.5197720525566,
            "rating_q975": 1383.1857795292754,
            "rating_q025": 1371.8537645758379
        },
        "gemini-2.5-flash-lite-preview-06-17-thinking": {
            "rating": 1374.512661585783,
            "rating_q975": 1379.0371634196122,
            "rating_q025": 1369.9881597519538
        },
        "qwen2.5-max": {
            "rating": 1371.1357456694182,
            "rating_q975": 1375.1505598152198,
            "rating_q025": 1367.1209315236165
        },
        "qwen3-235b-a22b": {
            "rating": 1371.0203182184973,
            "rating_q975": 1375.7359150125267,
            "rating_q025": 1366.304721424468
        },
        "glm-4.5-air": {
            "rating": 1369.4552275554574,
            "rating_q975": 1373.9868867915784,
            "rating_q025": 1364.9235683193365
        },
        "claude-3-5-sonnet-20241022": {
            "rating": 1368.5625101670485,
            "rating_q975": 1371.6431223564143,
            "rating_q025": 1365.4818979776826
        },
        "qwen3-next-80b-a3b-thinking": {
            "rating": 1366.662336170596,
            "rating_q975": 1372.571812867051,
            "rating_q025": 1360.7528594741411
        },
        "minimax-m1": {
            "rating": 1364.0346470999975,
            "rating_q975": 1368.3204736644138,
            "rating_q025": 1359.7488205355812
        },
        "gemma-3-27b-it": {
            "rating": 1363.3762855175194,
            "rating_q975": 1367.0557729603945,
            "rating_q025": 1359.6967980746442
        },
        "grok-3-mini-high": {
            "rating": 1362.1260644666079,
            "rating_q975": 1367.4817929990354,
            "rating_q025": 1356.7703359341804
        },
        "o3-mini-high": {
            "rating": 1361.9342621009243,
            "rating_q975": 1367.1734758976497,
            "rating_q025": 1356.695048304199
        },
        "grok-3-mini-beta": {
            "rating": 1355.9497260520975,
            "rating_q975": 1360.976415735501,
            "rating_q025": 1350.923036368694
        },
        "deepseek-v3": {
            "rating": 1353.6668573472919,
            "rating_q975": 1358.3241075411502,
            "rating_q025": 1349.0096071534335
        },
        "mistral-small-2506": {
            "rating": 1351.900312121699,
            "rating_q975": 1357.1133872005228,
            "rating_q025": 1346.6872370428753
        },
        "gemini-2.0-flash-lite-preview-02-05": {
            "rating": 1350.7204518757565,
            "rating_q975": 1354.9508878152553,
            "rating_q025": 1346.4900159362576
        },
        "gpt-oss-120b": {
            "rating": 1349.8150906977908,
            "rating_q975": 1354.4788775702657,
            "rating_q025": 1345.1513038253158
        },
        "gemini-1.5-pro-002": {
            "rating": 1349.0574234946164,
            "rating_q975": 1352.2911121013167,
            "rating_q025": 1345.823734887916
        },
        "glm-4.5v": {
            "rating": 1348.8491201809059,
            "rating_q975": 1357.279574963585,
            "rating_q025": 1340.4186653982267
        },
        "command-a-03-2025": {
            "rating": 1348.461915727593,
            "rating_q975": 1352.0436253575306,
            "rating_q025": 1344.8802060976552
        },
        "o3-mini": {
            "rating": 1346.9510341275998,
            "rating_q975": 1350.4328792933024,
            "rating_q025": 1343.469188961897
        },
        "hunyuan-turbos-20250226": {
            "rating": 1345.2862892124854,
            "rating_q975": 1357.0649659710814,
            "rating_q025": 1333.5076124538894
        },
        "ling-flash-2.0": {
            "rating": 1344.613545896821,
            "rating_q975": 1351.8767428890624,
            "rating_q025": 1337.3503489045797
        },
        "llama-3.1-nemotron-ultra-253b-v1": {
            "rating": 1343.3725547042195,
            "rating_q975": 1355.1185868508144,
            "rating_q025": 1331.6265225576246
        },
        "step-3": {
            "rating": 1343.1588526532944,
            "rating_q975": 1350.5621594630993,
            "rating_q025": 1335.7555458434895
        },
        "claude-3-5-sonnet-20240620": {
            "rating": 1343.1456380990253,
            "rating_q975": 1346.5429497615398,
            "rating_q025": 1339.7483264365108
        },
        "amazon-nova-experimental-chat-10-09": {
            "rating": 1342.8827357022703,
            "rating_q975": 1350.6008242255828,
            "rating_q025": 1335.164647178958
        },
        "qwen3-32b": {
            "rating": 1342.3531553668404,
            "rating_q975": 1351.8804645248733,
            "rating_q025": 1332.8258462088074
        },
        "qwen-plus-0125": {
            "rating": 1342.2157512595913,
            "rating_q975": 1350.615290407103,
            "rating_q025": 1333.8162121120797
        },
        "gpt-4o-2024-05-13": {
            "rating": 1341.8489239459504,
            "rating_q975": 1345.1551228693393,
            "rating_q025": 1338.5427250225616
        },
        "glm-4-plus-0111": {
            "rating": 1341.225247214176,
            "rating_q975": 1349.6407291477378,
            "rating_q025": 1332.8097652806143
        },
        "gemma-3-12b-it": {
            "rating": 1339.970595799442,
            "rating_q975": 1349.4955809846444,
            "rating_q025": 1330.4456106142395
        },
        "gpt-5-nano-high": {
            "rating": 1338.8187824878414,
            "rating_q975": 1345.7481215353027,
            "rating_q025": 1331.88944344038
        },
        "nvidia-llama-3.3-nemotron-super-49b-v1.5": {
            "rating": 1337.7030348832222,
            "rating_q975": 1347.5515799459558,
            "rating_q025": 1327.8544898204887
        },
        "hunyuan-turbo-0110": {
            "rating": 1335.038638766066,
            "rating_q975": 1346.6599370847402,
            "rating_q025": 1323.4173404473918
        },
        "o1-mini": {
            "rating": 1334.953253560836,
            "rating_q975": 1338.4845320419777,
            "rating_q025": 1331.4219750796942
        },
        "llama-3.1-405b-instruct-bf16": {
            "rating": 1331.9552111383648,
            "rating_q975": 1335.5324497323916,
            "rating_q025": 1328.377972544338
        },
        "qwq-32b": {
            "rating": 1331.431767724564,
            "rating_q975": 1335.844026251607,
            "rating_q025": 1327.019509197521
        },
        "gpt-4o-2024-08-06": {
            "rating": 1331.3408312315169,
            "rating_q975": 1335.4267013231556,
            "rating_q025": 1327.254961139878
        },
        "grok-2-2024-08-13": {
            "rating": 1330.9459369015485,
            "rating_q975": 1334.4847343549602,
            "rating_q025": 1327.4071394481368
        },
        "step-2-16k-exp-202412": {
            "rating": 1330.9003113293159,
            "rating_q975": 1339.4931080684985,
            "rating_q025": 1322.3075145901332
        },
        "llama-3.1-405b-instruct-fp8": {
            "rating": 1330.3344541389242,
            "rating_q975": 1333.7824782487098,
            "rating_q025": 1326.8864300291386
        },
        "gemini-advanced-0514": {
            "rating": 1329.4557383739038,
            "rating_q975": 1334.5579723570354,
            "rating_q025": 1324.3535043907723
        },
        "claude-3-opus-20240229": {
            "rating": 1326.9644364129786,
            "rating_q975": 1329.9560427601666,
            "rating_q025": 1323.9728300657905
        },
        "yi-lightning": {
            "rating": 1325.1110068253204,
            "rating_q975": 1329.9383875566627,
            "rating_q025": 1320.283626093978
        },
        "llama-4-maverick-17b-128e-instruct": {
            "rating": 1324.8949568794887,
            "rating_q975": 1329.1456902330858,
            "rating_q025": 1320.6442235258917
        },
        "llama-3.3-nemotron-49b-super-v1": {
            "rating": 1323.641368303727,
            "rating_q975": 1335.8854627051637,
            "rating_q025": 1311.3972739022902
        },
        "qwen3-30b-a3b": {
            "rating": 1323.6292014525898,
            "rating_q975": 1328.3592169452754,
            "rating_q025": 1318.8991859599041
        },
        "claude-3-5-haiku-20241022": {
            "rating": 1322.794010070239,
            "rating_q975": 1326.0396589406919,
            "rating_q025": 1319.548361199786
        },
        "hunyuan-large-2025-02-10": {
            "rating": 1321.5936183477593,
            "rating_q975": 1331.5290963818256,
            "rating_q025": 1311.658140313693
        },
        "gpt-4-turbo-2024-04-09": {
            "rating": 1320.6752451782745,
            "rating_q975": 1324.4691663191322,
            "rating_q025": 1316.8813240374168
        },
        "gemini-1.5-pro-001": {
            "rating": 1320.3622503466495,
            "rating_q975": 1324.241122279176,
            "rating_q025": 1316.483378414123
        },
        "llama-4-scout-17b-16e-instruct": {
            "rating": 1320.1891697125527,
            "rating_q975": 1324.9004110397789,
            "rating_q025": 1315.4779283853265
        },
        "deepseek-v2.5-1210": {
            "rating": 1319.9341687695078,
            "rating_q975": 1328.2047460052152,
            "rating_q025": 1311.6635915338004
        },
        "ring-flash-2.0": {
            "rating": 1318.4861155042415,
            "rating_q975": 1325.7247634265593,
            "rating_q025": 1311.2474675819237
        },
        "step-1o-turbo-202506": {
            "rating": 1318.2022873820274,
            "rating_q975": 1324.8689908622844,
            "rating_q025": 1311.5355839017705
        },
        "gpt-4.1-nano-2025-04-14": {
            "rating": 1318.1183648192364,
            "rating_q975": 1325.9178370127638,
            "rating_q025": 1310.318892625709
        },
        "gemma-3n-e4b-it": {
            "rating": 1317.1911981130697,
            "rating_q975": 1322.3362820873094,
            "rating_q025": 1312.04611413883
        },
        "llama-3.3-70b-instruct": {
            "rating": 1316.4632197593846,
            "rating_q975": 1319.8301925760686,
            "rating_q025": 1313.0962469427006
        },
        "glm-4-plus": {
            "rating": 1315.9638804079445,
            "rating_q975": 1320.8115634361495,
            "rating_q025": 1311.1161973797396
        },
        "qwen-max-0919": {
            "rating": 1315.3476092506057,
            "rating_q975": 1320.9937931951827,
            "rating_q025": 1309.7014253060288
        },
        "gpt-oss-20b": {
            "rating": 1314.9254124521726,
            "rating_q975": 1321.3016887735769,
            "rating_q025": 1308.5491361307684
        },
        "gpt-4-1106-preview": {
            "rating": 1313.4164269228277,
            "rating_q975": 1317.233393074925,
            "rating_q025": 1309.5994607707303
        },
        "qwen2.5-plus-1127": {
            "rating": 1313.2080008534758,
            "rating_q975": 1319.5261279858878,
            "rating_q025": 1306.8898737210639
        },
        "gpt-4o-mini-2024-07-18": {
            "rating": 1313.1469586670728,
            "rating_q975": 1316.520324078842,
            "rating_q025": 1309.7735932553037
        },
        "gpt-4-0125-preview": {
            "rating": 1312.5043768818632,
            "rating_q975": 1316.5107415606371,
            "rating_q025": 1308.4980122030893
        },
        "athene-v2-chat": {
            "rating": 1310.2424919866849,
            "rating_q975": 1314.703709213622,
            "rating_q025": 1305.7812747597477
        },
        "mistral-large-2407": {
            "rating": 1309.9825484232201,
            "rating_q975": 1313.7833413063383,
            "rating_q025": 1306.181755540102
        },
        "gemini-1.5-flash-002": {
            "rating": 1308.6006694486844,
            "rating_q975": 1312.6997124097802,
            "rating_q025": 1304.5016264875885
        },
        "hunyuan-standard-2025-02-10": {
            "rating": 1307.9894052655327,
            "rating_q975": 1317.8091270651282,
            "rating_q025": 1298.1696834659372
        },
        "grok-2-mini-2024-08-13": {
            "rating": 1304.1840884381204,
            "rating_q975": 1307.7604768212523,
            "rating_q025": 1300.6077000549885
        },
        "deepseek-v2.5": {
            "rating": 1303.240139699602,
            "rating_q975": 1307.8617525828924,
            "rating_q025": 1298.6185268163115
        },
        "magistral-medium-2506": {
            "rating": 1302.1145608952484,
            "rating_q975": 1308.503270095485,
            "rating_q025": 1295.7258516950117
        },
        "mistral-large-2411": {
            "rating": 1301.6011944010174,
            "rating_q975": 1305.9341509846136,
            "rating_q025": 1297.2682378174213
        },
        "athene-70b-0725": {
            "rating": 1301.4414954407785,
            "rating_q975": 1307.0494842415176,
            "rating_q025": 1295.8335066400393
        },
        "gemma-3-4b-it": {
            "rating": 1301.382756367987,
            "rating_q975": 1310.7450946306512,
            "rating_q025": 1292.0204181053227
        },
        "mistral-small-3.1-24b-instruct-2503": {
            "rating": 1300.7913133628613,
            "rating_q975": 1305.3168767872944,
            "rating_q025": 1296.2657499384281
        },
        "qwen2.5-72b-instruct": {
            "rating": 1298.9963396534517,
            "rating_q975": 1302.9427171550947,
            "rating_q025": 1295.0499621518088
        },
        "llama-3.1-nemotron-70b-instruct": {
            "rating": 1294.693468489922,
            "rating_q975": 1302.444149455947,
            "rating_q025": 1286.942787523897
        },
        "hunyuan-large-vision": {
            "rating": 1293.275448938176,
            "rating_q975": 1302.4345491192269,
            "rating_q025": 1284.116348757125
        },
        "llama-3.1-70b-instruct": {
            "rating": 1289.8925761774094,
            "rating_q975": 1293.4678267755373,
            "rating_q025": 1286.3173255792815
        },
        "amazon-nova-pro-v1.0": {
            "rating": 1285.6869423137814,
            "rating_q975": 1290.1385765320756,
            "rating_q025": 1281.2353080954872
        },
        "reka-core-20240904": {
            "rating": 1284.0567791193503,
            "rating_q975": 1291.1937235932037,
            "rating_q025": 1276.9198346454968
        },
        "jamba-1.5-large": {
            "rating": 1284.0428873966578,
            "rating_q975": 1291.3781650614274,
            "rating_q025": 1276.7076097318882
        },
        "gemma-2-27b-it": {
            "rating": 1283.5672811863672,
            "rating_q975": 1286.8071704386628,
            "rating_q025": 1280.3273919340716
        },
        "llama-3.1-nemotron-51b-instruct": {
            "rating": 1282.9241789205385,
            "rating_q975": 1292.9377585464906,
            "rating_q025": 1272.9105992945863
        },
        "llama-3.1-tulu-3-70b": {
            "rating": 1282.812695967948,
            "rating_q975": 1293.3728302965424,
            "rating_q025": 1272.2525616393536
        },
        "gpt-4-0314": {
            "rating": 1282.7526456866158,
            "rating_q975": 1287.5353709045164,
            "rating_q025": 1277.9699204687151
        },
        "gemini-1.5-flash-001": {
            "rating": 1282.0997812857142,
            "rating_q975": 1286.5230971923038,
            "rating_q025": 1277.6764653791247
        },
        "claude-3-sonnet-20240229": {
            "rating": 1282.0043496782716,
            "rating_q975": 1285.9627261428286,
            "rating_q025": 1278.0459732137147
        },
        "command-r-plus-08-2024": {
            "rating": 1277.3199165048322,
            "rating_q975": 1283.9287272338586,
            "rating_q025": 1270.711105775806
        },
        "nemotron-4-340b-instruct": {
            "rating": 1275.578190472536,
            "rating_q975": 1280.9228427588719,
            "rating_q025": 1270.2335381862003
        },
        "gemma-2-9b-it-simpo": {
            "rating": 1273.6074799273247,
            "rating_q975": 1280.5012966163777,
            "rating_q025": 1266.7136632382717
        },
        "deepseek-coder-v2": {
            "rating": 1273.329108508999,
            "rating_q975": 1279.8260933375393,
            "rating_q025": 1266.8321236804588
        },
        "gpt-4-0613": {
            "rating": 1272.6760371893424,
            "rating_q975": 1276.729889642404,
            "rating_q025": 1268.6221847362808
        },
        "llama-3-70b-instruct": {
            "rating": 1271.208270082394,
            "rating_q975": 1274.6939164039993,
            "rating_q025": 1267.7226237607886
        },
        "mistral-small-24b-instruct-2501": {
            "rating": 1271.065537734371,
            "rating_q975": 1276.9354141631272,
            "rating_q025": 1265.1956613056147
        },
        "glm-4-0520": {
            "rating": 1269.4891320567401,
            "rating_q975": 1276.476918002821,
            "rating_q025": 1262.5013461106591
        },
        "reka-flash-20240904": {
            "rating": 1268.8020700847155,
            "rating_q975": 1275.7769134758096,
            "rating_q025": 1261.8272266936215
        },
        "qwen2.5-coder-32b-instruct": {
            "rating": 1266.499660114094,
            "rating_q975": 1274.6208285355872,
            "rating_q025": 1258.3784916926008
        },
        "c4ai-aya-expanse-32b": {
            "rating": 1264.4406457624998,
            "rating_q975": 1269.2509990867961,
            "rating_q025": 1259.6302924382035
        },
        "claude-3-haiku-20240307": {
            "rating": 1262.8926520421496,
            "rating_q975": 1266.5877621201244,
            "rating_q025": 1259.197541964175
        },
        "command-r-plus": {
            "rating": 1261.060007927218,
            "rating_q975": 1265.3374339487436,
            "rating_q025": 1256.7825819056925
        },
        "gemma-2-9b-it": {
            "rating": 1260.486306224582,
            "rating_q975": 1264.1809380048478,
            "rating_q025": 1256.7916744443162
        },
        "qwen2-72b-instruct": {
            "rating": 1260.0310114926428,
            "rating_q975": 1264.913671566019,
            "rating_q025": 1255.1483514192666
        },
        "gemini-1.5-flash-8b-001": {
            "rating": 1257.9165906842527,
            "rating_q975": 1262.0923129349667,
            "rating_q025": 1253.7408684335387
        },
        "amazon-nova-lite-v1.0": {
            "rating": 1257.8413900879036,
            "rating_q975": 1262.89865122758,
            "rating_q025": 1252.7841289482271
        },
        "phi-4": {
            "rating": 1252.7991539763952,
            "rating_q975": 1257.3419419451695,
            "rating_q025": 1248.256366007621
        },
        "olmo-2-0325-32b-instruct": {
            "rating": 1249.9979151828647,
            "rating_q975": 1260.826732047251,
            "rating_q025": 1239.1690983184785
        },
        "command-r-08-2024": {
            "rating": 1249.1312921634235,
            "rating_q975": 1255.7278475568608,
            "rating_q025": 1242.5347367699862
        },
        "mistral-large-2402": {
            "rating": 1238.7306713408288,
            "rating_q975": 1243.442823153327,
            "rating_q025": 1234.0185195283307
        },
        "amazon-nova-micro-v1.0": {
            "rating": 1238.6109664544338,
            "rating_q975": 1243.6363559160018,
            "rating_q025": 1233.5855769928658
        },
        "jamba-1.5-mini": {
            "rating": 1235.3870792964412,
            "rating_q975": 1242.6167138703797,
            "rating_q025": 1228.1574447225028
        },
        "ministral-8b-2410": {
            "rating": 1233.0167320454373,
            "rating_q975": 1242.088080737844,
            "rating_q025": 1223.9453833530306
        },
        "qwen1.5-110b-chat": {
            "rating": 1231.0090891944915,
            "rating_q975": 1236.5253062765628,
            "rating_q025": 1225.4928721124202
        },
        "qwen1.5-72b-chat": {
            "rating": 1230.7366311591422,
            "rating_q975": 1236.028276607001,
            "rating_q025": 1225.4449857112834
        },
        "hunyuan-standard-256k": {
            "rating": 1230.3719689488826,
            "rating_q975": 1242.2219304644027,
            "rating_q025": 1218.5220074333624
        },
        "reka-flash-21b-20240226-online": {
            "rating": 1229.4475439719483,
            "rating_q975": 1236.8661716225477,
            "rating_q025": 1222.028916321349
        },
        "gemini-pro-dev-api": {
            "rating": 1229.3196643611664,
            "rating_q975": 1236.76867536106,
            "rating_q025": 1221.8706533612726
        },
        "mixtral-8x22b-instruct-v0.1": {
            "rating": 1225.6210732624022,
            "rating_q975": 1230.1346837306905,
            "rating_q025": 1221.1074627941139
        },
        "command-r": {
            "rating": 1225.0044461514174,
            "rating_q975": 1229.740749039797,
            "rating_q025": 1220.2681432630377
        },
        "reka-flash-21b-20240226": {
            "rating": 1222.8026538198028,
            "rating_q975": 1228.7566480466812,
            "rating_q025": 1216.8486595929244
        },
        "c4ai-aya-expanse-8b": {
            "rating": 1220.9227074078385,
            "rating_q975": 1227.8395234986924,
            "rating_q025": 1214.0058913169846
        },
        "gpt-3.5-turbo-0125": {
            "rating": 1220.8700743319785,
            "rating_q975": 1225.5805755720587,
            "rating_q025": 1216.1595730918982
        },
        "llama-3.1-tulu-3-8b": {
            "rating": 1220.6122002666284,
            "rating_q975": 1231.3381661900394,
            "rating_q025": 1209.8862343432174
        },
        "mistral-medium": {
            "rating": 1219.8904904981114,
            "rating_q975": 1225.4238878981473,
            "rating_q025": 1214.3570930980754
        },
        "llama-3-8b-instruct": {
            "rating": 1218.5344685830864,
            "rating_q975": 1222.178723692189,
            "rating_q025": 1214.890213473984
        },
        "gemini-pro": {
            "rating": 1218.4309664759571,
            "rating_q975": 1230.428264747129,
            "rating_q025": 1206.4336682047851
        },
        "yi-1.5-34b-chat": {
            "rating": 1210.8243560747305,
            "rating_q975": 1215.8453579762242,
            "rating_q025": 1205.8033541732368
        },
        "zephyr-orpo-141b-A35b-v0.1": {
            "rating": 1208.5822116290842,
            "rating_q975": 1219.4819017977381,
            "rating_q025": 1197.6825214604303
        },
        "llama-3.1-8b-instruct": {
            "rating": 1208.1300961025017,
            "rating_q975": 1212.1354684312269,
            "rating_q025": 1204.1247237737766
        },
        "granite-3.1-8b-instruct": {
            "rating": 1207.5480557317,
            "rating_q975": 1218.738046929273,
            "rating_q025": 1196.3580645341272
        },
        "gpt-3.5-turbo-1106": {
            "rating": 1205.9293447760115,
            "rating_q975": 1215.1133611829443,
            "rating_q025": 1196.7453283690786
        },
        "qwen1.5-32b-chat": {
            "rating": 1201.9747722390243,
            "rating_q975": 1208.1187402677779,
            "rating_q025": 1195.8308042102708
        },
        "phi-3-medium-4k-instruct": {
            "rating": 1195.2707059939305,
            "rating_q975": 1200.3715643738437,
            "rating_q025": 1190.1698476140173
        },
        "gemma-2-2b-it": {
            "rating": 1194.0678123992284,
            "rating_q975": 1198.0537042941296,
            "rating_q025": 1190.0819205043272
        },
        "mixtral-8x7b-instruct-v0.1": {
            "rating": 1192.7156358706611,
            "rating_q975": 1196.9593541444535,
            "rating_q025": 1188.4719175968687
        },
        "dbrx-instruct-preview": {
            "rating": 1190.77485137009,
            "rating_q975": 1196.9352987978812,
            "rating_q025": 1184.6144039422986
        },
        "internlm2_5-20b-chat": {
            "rating": 1190.653265375736,
            "rating_q975": 1197.852427225956,
            "rating_q025": 1183.454103525516
        },
        "qwen1.5-14b-chat": {
            "rating": 1189.2485313233155,
            "rating_q975": 1196.4331742451263,
            "rating_q025": 1182.0638884015048
        },
        "yi-34b-chat": {
            "rating": 1182.4616470358956,
            "rating_q975": 1189.4149733169866,
            "rating_q025": 1175.5083207548046
        },
        "deepseek-llm-67b-chat": {
            "rating": 1179.198518317381,
            "rating_q975": 1190.9930705164477,
            "rating_q025": 1167.4039661183144
        },
        "wizardlm-70b": {
            "rating": 1179.1609832256888,
            "rating_q975": 1188.8271441183267,
            "rating_q025": 1169.494822333051
        },
        "granite-3.0-8b-instruct": {
            "rating": 1178.76221979021,
            "rating_q975": 1187.5352751782134,
            "rating_q025": 1169.9891644022068
        },
        "openchat-3.5-0106": {
            "rating": 1176.966558156677,
            "rating_q975": 1185.0253055485057,
            "rating_q025": 1168.9078107648481
        },
        "granite-3.1-2b-instruct": {
            "rating": 1176.2723574006804,
            "rating_q975": 1187.5320129390732,
            "rating_q025": 1165.0127018622877
        },
        "snowflake-arctic-instruct": {
            "rating": 1175.0653284362245,
            "rating_q975": 1180.9948348386417,
            "rating_q025": 1169.1358220338072
        },
        "tulu-2-dpo-70b": {
            "rating": 1174.5857788856551,
            "rating_q975": 1184.6962733525982,
            "rating_q025": 1164.4752844187121
        },
        "gemma-1.1-7b-it": {
            "rating": 1172.8632347429434,
            "rating_q975": 1178.8901188422165,
            "rating_q025": 1166.8363506436704
        },
        "openchat-3.5": {
            "rating": 1170.5226956965785,
            "rating_q975": 1180.4767001702094,
            "rating_q025": 1160.5686912229476
        },
        "starling-lm-7b-beta": {
            "rating": 1169.4575453606785,
            "rating_q975": 1176.8849595854554,
            "rating_q025": 1162.0301311359017
        },
        "phi-3-small-8k-instruct": {
            "rating": 1168.2862786154578,
            "rating_q975": 1174.257636708186,
            "rating_q025": 1162.3149205227296
        },
        "llama-2-70b-chat": {
            "rating": 1168.2252749807851,
            "rating_q975": 1173.747365267022,
            "rating_q025": 1162.7031846945483
        },
        "openhermes-2.5-mistral-7b": {
            "rating": 1167.297674401721,
            "rating_q975": 1177.9305305280384,
            "rating_q025": 1156.6648182754036
        },
        "vicuna-33b": {
            "rating": 1166.2727009437408,
            "rating_q975": 1172.546497550398,
            "rating_q025": 1159.9989043370836
        },
        "llama-3.2-3b-instruct": {
            "rating": 1163.4737898440399,
            "rating_q975": 1171.1498639887316,
            "rating_q025": 1155.7977156993481
        },
        "nous-hermes-2-mixtral-8x7b-dpo": {
            "rating": 1162.0712151614234,
            "rating_q975": 1174.1847902187722,
            "rating_q025": 1149.9576401040747
        },
        "starling-lm-7b-alpha": {
            "rating": 1161.2034754210183,
            "rating_q975": 1169.4015626322146,
            "rating_q025": 1153.005388209822
        },
        "qwq-32b-preview": {
            "rating": 1159.3108381206519,
            "rating_q975": 1171.0073636299257,
            "rating_q025": 1147.614312611378
        },
        "granite-3.0-2b-instruct": {
            "rating": 1151.8442458534528,
            "rating_q975": 1160.3351509226788,
            "rating_q025": 1143.3533407842267
        },
        "llama2-70b-steerlm-chat": {
            "rating": 1150.1869086370411,
            "rating_q975": 1163.108322783037,
            "rating_q025": 1137.2654944910453
        },
        "solar-10.7b-instruct-v1.0": {
            "rating": 1146.1067946580256,
            "rating_q975": 1159.5693907494012,
            "rating_q025": 1132.64419856665
        },
        "mistral-7b-instruct-v0.2": {
            "rating": 1145.62996324089,
            "rating_q975": 1152.3803210373194,
            "rating_q025": 1138.8796054444606
        },
        "wizardlm-13b": {
            "rating": 1145.4569491650004,
            "rating_q975": 1154.9955385170751,
            "rating_q025": 1135.9183598129257
        },
        "dolphin-2.2.1-mistral-7b": {
            "rating": 1143.5321047198308,
            "rating_q975": 1159.2668013703965,
            "rating_q025": 1127.7974080692652
        },
        "llama-2-13b-chat": {
            "rating": 1142.2082005323405,
            "rating_q975": 1148.978891565478,
            "rating_q025": 1135.4375094992029
        },
        "mpt-30b-chat": {
            "rating": 1141.1597035841896,
            "rating_q975": 1153.8543273135917,
            "rating_q025": 1128.4650798547875
        },
        "qwen1.5-7b-chat": {
            "rating": 1138.4691952129324,
            "rating_q975": 1148.5224546977638,
            "rating_q025": 1128.415935728101
        },
        "falcon-180b-chat": {
            "rating": 1138.2561561863365,
            "rating_q975": 1156.4566569832177,
            "rating_q025": 1120.0556553894553
        },
        "phi-3-mini-4k-instruct-june-2024": {
            "rating": 1138.143695534673,
            "rating_q975": 1144.6367372918683,
            "rating_q025": 1131.6506537774778
        },
        "vicuna-13b": {
            "rating": 1137.0080681343766,
            "rating_q975": 1143.816755187239,
            "rating_q025": 1130.199381081514
        },
        "qwen-14b-chat": {
            "rating": 1133.7337813754764,
            "rating_q975": 1145.1097730003933,
            "rating_q025": 1122.3577897505595
        },
        "codellama-34b-instruct": {
            "rating": 1133.172276368995,
            "rating_q975": 1142.2977961979936,
            "rating_q025": 1124.0467565399963
        },
        "gemma-7b-it": {
            "rating": 1128.5228243148495,
            "rating_q975": 1138.1336149446124,
            "rating_q025": 1118.9120336850865
        },
        "guanaco-33b": {
            "rating": 1126.90937828895,
            "rating_q975": 1139.6184998476053,
            "rating_q025": 1114.2002567302945
        },
        "phi-3-mini-128k-instruct": {
            "rating": 1126.0748383214564,
            "rating_q975": 1133.5184950912544,
            "rating_q025": 1118.6311815516583
        },
        "phi-3-mini-4k-instruct": {
            "rating": 1126.0447412571639,
            "rating_q975": 1132.4641068117471,
            "rating_q025": 1119.6253757025806
        },
        "zephyr-7b-beta": {
            "rating": 1124.194335593668,
            "rating_q975": 1133.2352757273554,
            "rating_q025": 1115.1533954599806
        },
        "codellama-70b-instruct": {
            "rating": 1123.9014703243806,
            "rating_q975": 1143.0789191930894,
            "rating_q025": 1104.7240214556718
        },
        "palm-2": {
            "rating": 1123.5912780959668,
            "rating_q975": 1133.2495781109694,
            "rating_q025": 1113.9329780809642
        },
        "zephyr-7b-alpha": {
            "rating": 1117.0152751190226,
            "rating_q975": 1133.3122047543459,
            "rating_q025": 1100.7183454836993
        },
        "smollm2-1.7b-instruct": {
            "rating": 1116.6900896675681,
            "rating_q975": 1131.1810123378295,
            "rating_q025": 1102.1991669973067
        },
        "stripedhyena-nous-7b": {
            "rating": 1114.7934993453655,
            "rating_q975": 1126.0787045853035,
            "rating_q025": 1103.5082941054275
        },
        "llama-2-7b-chat": {
            "rating": 1110.3285078273511,
            "rating_q975": 1117.5234050817066,
            "rating_q025": 1103.1336105729956
        },
        "llama-3.2-1b-instruct": {
            "rating": 1110.1014541024115,
            "rating_q975": 1117.9161058411564,
            "rating_q025": 1102.2868023636665
        },
        "vicuna-7b": {
            "rating": 1109.5523596202368,
            "rating_q975": 1119.0002204194031,
            "rating_q025": 1100.1044988210704
        },
        "gemma-1.1-2b-it": {
            "rating": 1107.5210863181378,
            "rating_q975": 1115.2535052379994,
            "rating_q025": 1099.7886673982762
        },
        "mistral-7b-instruct": {
            "rating": 1096.795387764399,
            "rating_q975": 1106.337504753579,
            "rating_q025": 1087.253270775219
        },
        "gemma-2b-it": {
            "rating": 1083.5923792687595,
            "rating_q975": 1095.3776090516878,
            "rating_q025": 1071.8071494858311
        },
        "qwen1.5-4b-chat": {
            "rating": 1082.6655100709627,
            "rating_q975": 1092.2333406038788,
            "rating_q025": 1073.0976795380466
        },
        "olmo-7b-instruct": {
            "rating": 1068.7555656874322,
            "rating_q975": 1080.1912582939672,
            "rating_q025": 1057.3198730808972
        },
        "koala-13b": {
            "rating": 1064.527541661542,
            "rating_q975": 1075.0490203893096,
            "rating_q025": 1054.0060629337745
        },
        "gpt4all-13b-snoozy": {
            "rating": 1055.742681644636,
            "rating_q975": 1071.8278666262004,
            "rating_q025": 1039.6574966630715
        },
        "mpt-7b-chat": {
            "rating": 1054.7362461953408,
            "rating_q975": 1067.193200416353,
            "rating_q025": 1042.2792919743285
        },
        "alpaca-13b": {
            "rating": 1047.935818106815,
            "rating_q975": 1059.8048407606032,
            "rating_q025": 1036.066795453027
        },
        "chatglm3-6b": {
            "rating": 1045.1241357969736,
            "rating_q975": 1057.4463086678315,
            "rating_q025": 1032.8019629261157
        },
        "RWKV-4-Raven-14B": {
            "rating": 1028.94579152358,
            "rating_q975": 1040.7465647805543,
            "rating_q025": 1017.1450182666058
        },
        "oasst-pythia-12b": {
            "rating": 1008.7619548479106,
            "rating_q975": 1020.1004514680661,
            "rating_q025": 997.4234582277551
        },
        "chatglm2-6b": {
            "rating": 1007.4050288171505,
            "rating_q975": 1022.0198418729506,
            "rating_q025": 992.7902157613505
        },
        "chatglm-6b": {
            "rating": 979.2104584085962,
            "rating_q975": 992.425949869167,
            "rating_q025": 965.9949669480254
        },
        "fastchat-t5-3b": {
            "rating": 974.6481277324717,
            "rating_q975": 987.6011116084499,
            "rating_q025": 961.6951438564936
        },
        "dolly-v2-12b": {
            "rating": 958.9095847810519,
            "rating_q975": 972.8212566525455,
            "rating_q025": 944.9979129095583
        },
        "llama-13b": {
            "rating": 950.612788344049,
            "rating_q975": 966.89111107084,
            "rating_q025": 934.334465617258
        },
        "stablelm-tuned-alpha-7b": {
            "rating": 939.1272888643439,
            "rating_q975": 952.5979472886316,
            "rating_q025": 925.6566304400561
        }
    },
    "no_short": {
        "gemini-2.5-pro": {
            "rating": 1453.2390935596413,
            "rating_q975": 1457.2641959259279,
            "rating_q025": 1449.2139911933548
        },
        "claude-opus-4-1-20250805-thinking-16k": {
            "rating": 1449.948047061472,
            "rating_q975": 1454.580647372644,
            "rating_q025": 1445.3154467502998
        },
        "claude-sonnet-4-5-20250929-thinking-32k": {
            "rating": 1449.496579451774,
            "rating_q975": 1455.4236016182924,
            "rating_q025": 1443.5695572852558
        },
        "gpt-4.5-preview-2025-02-27": {
            "rating": 1443.5234733607317,
            "rating_q975": 1449.2109748547125,
            "rating_q025": 1437.835971866751
        },
        "claude-sonnet-4-5-20250929": {
            "rating": 1442.6664872412116,
            "rating_q975": 1450.2290370901555,
            "rating_q025": 1435.1039373922677
        },
        "claude-opus-4-1-20250805": {
            "rating": 1440.9561424470394,
            "rating_q975": 1445.3774374381653,
            "rating_q025": 1436.5348474559135
        },
        "chatgpt-4o-latest-20250326": {
            "rating": 1438.7929293389518,
            "rating_q975": 1442.6532554996245,
            "rating_q025": 1434.9326031782791
        },
        "gpt-5-high": {
            "rating": 1436.6465634736205,
            "rating_q975": 1441.4854673070258,
            "rating_q025": 1431.8076596402152
        },
        "deepseek-v3.2-exp": {
            "rating": 1436.5419981072512,
            "rating_q975": 1463.799140422369,
            "rating_q025": 1409.2848557921334
        },
        "o3-2025-04-16": {
            "rating": 1434.2852737041665,
            "rating_q975": 1438.0897469566576,
            "rating_q025": 1430.4808004516753
        },
        "qwen3-max-preview": {
            "rating": 1433.3522248542163,
            "rating_q975": 1438.2142880708545,
            "rating_q025": 1428.490161637578
        },
        "glm-4.6": {
            "rating": 1429.89346776588,
            "rating_q975": 1436.2931287914425,
            "rating_q025": 1423.4938067403173
        },
        "gpt-5-chat": {
            "rating": 1426.7566058455075,
            "rating_q975": 1431.3645500119367,
            "rating_q025": 1422.1486616790783
        },
        "claude-opus-4-20250514-thinking-16k": {
            "rating": 1424.0748447424742,
            "rating_q975": 1428.4658480884998,
            "rating_q025": 1419.6838413964485
        },
        "qwen3-max-2025-09-23": {
            "rating": 1423.821428296639,
            "rating_q975": 1430.3173732487412,
            "rating_q025": 1417.3254833445367
        },
        "deepseek-v3.2-exp-thinking": {
            "rating": 1421.0942867174274,
            "rating_q975": 1427.7185550977597,
            "rating_q025": 1414.470018337095
        },
        "qwen3-235b-a22b-instruct-2507": {
            "rating": 1420.6724972371387,
            "rating_q975": 1425.0555642877296,
            "rating_q025": 1416.2894301865479
        },
        "grok-4-fast": {
            "rating": 1420.560602400824,
            "rating_q975": 1428.2227389911397,
            "rating_q025": 1412.8984658105085
        },
        "kimi-k2-0905-preview": {
            "rating": 1418.1960860856957,
            "rating_q975": 1425.0935241755988,
            "rating_q025": 1411.2986479957926
        },
        "deepseek-v3.1": {
            "rating": 1418.0588893923414,
            "rating_q975": 1424.127102492653,
            "rating_q025": 1411.9906762920298
        },
        "deepseek-r1-0528": {
            "rating": 1417.6410652292288,
            "rating_q975": 1423.2926317267963,
            "rating_q025": 1411.9894987316613
        },
        "deepseek-v3.1-thinking": {
            "rating": 1415.7908130674748,
            "rating_q975": 1422.4550032306563,
            "rating_q025": 1409.1266229042933
        },
        "kimi-k2-0711-preview": {
            "rating": 1415.5924183606314,
            "rating_q975": 1420.466977819441,
            "rating_q025": 1410.717858901822
        },
        "qwen3-vl-235b-a22b-instruct": {
            "rating": 1415.2803881766113,
            "rating_q975": 1422.0052063000555,
            "rating_q025": 1408.555570053167
        },
        "deepseek-v3.1-terminus": {
            "rating": 1414.926744085974,
            "rating_q975": 1424.5741845244418,
            "rating_q025": 1405.2793036475061
        },
        "deepseek-v3.1-terminus-thinking": {
            "rating": 1414.438146241626,
            "rating_q975": 1424.4296021288403,
            "rating_q025": 1404.4466903544119
        },
        "gpt-4.1-2025-04-14": {
            "rating": 1413.279080531449,
            "rating_q975": 1417.1889417389032,
            "rating_q025": 1409.3692193239947
        },
        "claude-opus-4-20250514": {
            "rating": 1413.0816347695697,
            "rating_q975": 1417.392214506153,
            "rating_q025": 1408.7710550329864
        },
        "mistral-medium-2508": {
            "rating": 1411.72142723689,
            "rating_q975": 1416.4158834305597,
            "rating_q025": 1407.02697104322
        },
        "grok-4-0709": {
            "rating": 1409.5946769972447,
            "rating_q975": 1413.8924176445598,
            "rating_q025": 1405.2969363499296
        },
        "grok-3-preview-02-24": {
            "rating": 1409.4770833616903,
            "rating_q975": 1413.758472334236,
            "rating_q025": 1405.1956943891446
        },
        "glm-4.5": {
            "rating": 1409.1305761468454,
            "rating_q975": 1414.0700373752898,
            "rating_q025": 1404.1911149184011
        },
        "gemini-2.5-flash": {
            "rating": 1407.6268642769103,
            "rating_q975": 1411.555981252748,
            "rating_q025": 1403.6977473010725
        },
        "gemini-2.5-flash-preview-09-2025": {
            "rating": 1406.4450847254075,
            "rating_q975": 1412.1433059377869,
            "rating_q025": 1400.746863513028
        },
        "claude-haiku-4-5-20251001": {
            "rating": 1403.6445960398403,
            "rating_q975": 1410.0175617301816,
            "rating_q025": 1397.271630349499
        },
        "o1-2024-12-17": {
            "rating": 1401.9513737926102,
            "rating_q975": 1406.3200350868656,
            "rating_q025": 1397.5827124983548
        },
        "qwen3-next-80b-a3b-instruct": {
            "rating": 1401.2562359192952,
            "rating_q975": 1406.4778510852514,
            "rating_q025": 1396.0346207533391
        },
        "claude-sonnet-4-20250514-thinking-32k": {
            "rating": 1400.172199569737,
            "rating_q975": 1404.59735287374,
            "rating_q025": 1395.7470462657338
        },
        "qwen3-235b-a22b-no-thinking": {
            "rating": 1399.783196003948,
            "rating_q975": 1404.3242028069726,
            "rating_q025": 1395.2421892009233
        },
        "longcat-flash-chat": {
            "rating": 1399.294970498464,
            "rating_q975": 1405.753895517308,
            "rating_q025": 1392.83604547962
        },
        "qwen3-235b-a22b-thinking-2507": {
            "rating": 1396.5917992799311,
            "rating_q975": 1403.1102394401075,
            "rating_q025": 1390.0733591197547
        },
        "deepseek-r1": {
            "rating": 1396.2250570916506,
            "rating_q975": 1401.0455797616041,
            "rating_q025": 1391.404534421697
        },
        "qwen3-vl-235b-a22b-thinking": {
            "rating": 1393.3006806557805,
            "rating_q975": 1400.161661882991,
            "rating_q025": 1386.43969942857
        },
        "deepseek-v3-0324": {
            "rating": 1392.1350573336824,
            "rating_q975": 1396.0366715761452,
            "rating_q025": 1388.2334430912197
        },
        "o4-mini-2025-04-16": {
            "rating": 1390.95886027335,
            "rating_q975": 1394.9692457355607,
            "rating_q025": 1386.9484748111392
        },
        "gpt-5-mini-high": {
            "rating": 1390.8267928631478,
            "rating_q975": 1395.8479302686133,
            "rating_q025": 1385.8056554576824
        },
        "claude-sonnet-4-20250514": {
            "rating": 1390.7172475037257,
            "rating_q975": 1395.107350598719,
            "rating_q025": 1386.3271444087325
        },
        "mai-1-preview": {
            "rating": 1390.2558900257811,
            "rating_q975": 1395.7589786839665,
            "rating_q025": 1384.7528013675958
        },
        "claude-3-7-sonnet-20250219-thinking-32k": {
            "rating": 1388.1834485802635,
            "rating_q975": 1392.3604357610436,
            "rating_q025": 1384.0064613994834
        },
        "o1-preview": {
            "rating": 1388.0219080585362,
            "rating_q975": 1392.899906002521,
            "rating_q025": 1383.1439101145513
        },
        "qwen3-coder-480b-a35b-instruct": {
            "rating": 1384.541780261375,
            "rating_q975": 1389.5719979538912,
            "rating_q025": 1379.5115625688586
        },
        "hunyuan-t1-20250711": {
            "rating": 1383.8627081217307,
            "rating_q975": 1392.5061591755864,
            "rating_q025": 1375.219257067875
        },
        "mistral-medium-2505": {
            "rating": 1383.4321152545353,
            "rating_q975": 1388.1397360909243,
            "rating_q025": 1378.7244944181464
        },
        "qwen3-30b-a3b-instruct-2507": {
            "rating": 1382.853526017005,
            "rating_q975": 1387.7948639570834,
            "rating_q025": 1377.9121880769264
        },
        "gpt-4.1-mini-2025-04-14": {
            "rating": 1380.350582894761,
            "rating_q975": 1384.681669159788,
            "rating_q025": 1376.0194966297338
        },
        "hunyuan-turbos-20250416": {
            "rating": 1380.2438321132324,
            "rating_q975": 1386.6266347197666,
            "rating_q025": 1373.8610295066983
        },
        "gemini-2.5-flash-lite-preview-09-2025-no-thinking": {
            "rating": 1379.699904155686,
            "rating_q975": 1385.375326874113,
            "rating_q025": 1374.024481437259
        },
        "gemini-2.5-flash-lite-preview-06-17-thinking": {
            "rating": 1375.141676832278,
            "rating_q975": 1379.677766951958,
            "rating_q025": 1370.6055867125983
        },
        "qwen3-235b-a22b": {
            "rating": 1373.724421842575,
            "rating_q975": 1378.4543757191357,
            "rating_q025": 1368.9944679660146
        },
        "claude-3-5-sonnet-20241022": {
            "rating": 1372.731868964258,
            "rating_q975": 1375.800755516923,
            "rating_q025": 1369.662982411593
        },
        "qwen2.5-max": {
            "rating": 1372.0545023131438,
            "rating_q975": 1376.060853330864,
            "rating_q025": 1368.0481512954236
        },
        "glm-4.5-air": {
            "rating": 1370.6684840831333,
            "rating_q975": 1375.2152278443225,
            "rating_q025": 1366.1217403219441
        },
        "minimax-m1": {
            "rating": 1366.7211852521389,
            "rating_q975": 1371.010988208647,
            "rating_q025": 1362.4313822956308
        },
        "qwen3-next-80b-a3b-thinking": {
            "rating": 1366.4364320338727,
            "rating_q975": 1372.3531141910448,
            "rating_q025": 1360.5197498767006
        },
        "gemma-3-27b-it": {
            "rating": 1365.1345707636328,
            "rating_q975": 1368.8152375171455,
            "rating_q025": 1361.4539040101201
        },
        "o3-mini-high": {
            "rating": 1362.9083199327954,
            "rating_q975": 1368.109184106389,
            "rating_q025": 1357.7074557592018
        },
        "grok-3-mini-high": {
            "rating": 1362.2732559465978,
            "rating_q975": 1367.6296635705548,
            "rating_q025": 1356.9168483226408
        },
        "deepseek-v3": {
            "rating": 1357.2288572043474,
            "rating_q975": 1361.8764551249901,
            "rating_q025": 1352.5812592837046
        },
        "grok-3-mini-beta": {
            "rating": 1356.950556050174,
            "rating_q975": 1361.979947750077,
            "rating_q025": 1351.9211643502713
        },
        "mistral-small-2506": {
            "rating": 1354.6078898413334,
            "rating_q975": 1359.8405791424664,
            "rating_q025": 1349.3752005402005
        },
        "gemini-2.0-flash-lite-preview-02-05": {
            "rating": 1351.6837167064527,
            "rating_q975": 1355.916385359984,
            "rating_q025": 1347.4510480529216
        },
        "gemini-1.5-pro-002": {
            "rating": 1351.6016276673693,
            "rating_q975": 1354.8315805402608,
            "rating_q025": 1348.3716747944777
        },
        "glm-4.5v": {
            "rating": 1351.259995640213,
            "rating_q975": 1359.7372139687418,
            "rating_q025": 1342.7827773116842
        },
        "command-a-03-2025": {
            "rating": 1350.9933522544168,
            "rating_q975": 1354.5822774864675,
            "rating_q025": 1347.404427022366
        },
        "gpt-oss-120b": {
            "rating": 1348.9614431456796,
            "rating_q975": 1353.6501546682161,
            "rating_q025": 1344.272731623143
        },
        "o3-mini": {
            "rating": 1347.4793962231474,
            "rating_q975": 1350.957148664911,
            "rating_q025": 1344.0016437813838
        },
        "hunyuan-turbos-20250226": {
            "rating": 1346.7974067397604,
            "rating_q975": 1358.5033575617485,
            "rating_q025": 1335.0914559177722
        },
        "llama-3.1-nemotron-ultra-253b-v1": {
            "rating": 1346.4751535554092,
            "rating_q975": 1358.19650885463,
            "rating_q025": 1334.7537982561882
        },
        "gpt-4o-2024-05-13": {
            "rating": 1345.8701440617897,
            "rating_q975": 1349.1579311589232,
            "rating_q025": 1342.5823569646561
        },
        "step-3": {
            "rating": 1345.6917464136282,
            "rating_q975": 1353.1528945097743,
            "rating_q025": 1338.230598317482
        },
        "qwen3-32b": {
            "rating": 1344.884720262992,
            "rating_q975": 1354.4298509256887,
            "rating_q025": 1335.3395896002953
        },
        "amazon-nova-experimental-chat-10-09": {
            "rating": 1344.7866436201023,
            "rating_q975": 1352.519461414182,
            "rating_q025": 1337.0538258260226
        },
        "qwen-plus-0125": {
            "rating": 1344.6904158896382,
            "rating_q975": 1353.0283813936808,
            "rating_q025": 1336.3524503855956
        },
        "ling-flash-2.0": {
            "rating": 1344.5104431344726,
            "rating_q975": 1351.8174832215288,
            "rating_q025": 1337.2034030474163
        },
        "glm-4-plus-0111": {
            "rating": 1343.5031124858128,
            "rating_q975": 1351.8949437344224,
            "rating_q025": 1335.1112812372032
        },
        "claude-3-5-sonnet-20240620": {
            "rating": 1343.1586349516074,
            "rating_q975": 1346.4781577071194,
            "rating_q025": 1339.8391121960954
        },
        "gemma-3-12b-it": {
            "rating": 1341.0749772222243,
            "rating_q975": 1350.6161154991323,
            "rating_q025": 1331.5338389453163
        },
        "hunyuan-turbo-0110": {
            "rating": 1339.3313335953364,
            "rating_q975": 1350.8572838258378,
            "rating_q025": 1327.805383364835
        },
        "nvidia-llama-3.3-nemotron-super-49b-v1.5": {
            "rating": 1338.881179565458,
            "rating_q975": 1348.736259681954,
            "rating_q025": 1329.0260994489622
        },
        "gpt-5-nano-high": {
            "rating": 1337.4720674600046,
            "rating_q975": 1344.4346516950454,
            "rating_q025": 1330.5094832249638
        },
        "llama-3.1-405b-instruct-bf16": {
            "rating": 1335.4174821180286,
            "rating_q975": 1338.993503704229,
            "rating_q025": 1331.8414605318283
        },
        "gemini-advanced-0514": {
            "rating": 1335.2821790232322,
            "rating_q975": 1340.37040738037,
            "rating_q025": 1330.1939506660945
        },
        "gpt-4o-2024-08-06": {
            "rating": 1335.1434980144613,
            "rating_q975": 1339.2112798161784,
            "rating_q025": 1331.0757162127443
        },
        "o1-mini": {
            "rating": 1335.0276880557346,
            "rating_q975": 1338.5298880134771,
            "rating_q025": 1331.5254880979921
        },
        "grok-2-2024-08-13": {
            "rating": 1334.8294769888812,
            "rating_q975": 1338.3613032198643,
            "rating_q025": 1331.297650757898
        },
        "llama-3.1-405b-instruct-fp8": {
            "rating": 1334.2781168415236,
            "rating_q975": 1337.7102656598734,
            "rating_q025": 1330.8459680231738
        },
        "qwq-32b": {
            "rating": 1333.710058062115,
            "rating_q975": 1338.1275148751038,
            "rating_q025": 1329.2926012491262
        },
        "step-2-16k-exp-202412": {
            "rating": 1331.7904714226322,
            "rating_q975": 1340.336685511295,
            "rating_q025": 1323.2442573339695
        },
        "yi-lightning": {
            "rating": 1328.8821028608113,
            "rating_q975": 1333.6963024594993,
            "rating_q025": 1324.0679032621233
        },
        "llama-4-maverick-17b-128e-instruct": {
            "rating": 1327.7028976979104,
            "rating_q975": 1331.9640884407745,
            "rating_q025": 1323.4417069550464
        },
        "llama-3.3-nemotron-49b-super-v1": {
            "rating": 1327.110182494378,
            "rating_q975": 1339.2553657040348,
            "rating_q025": 1314.9649992847212
        },
        "qwen3-30b-a3b": {
            "rating": 1325.2317441320217,
            "rating_q975": 1329.9742263867931,
            "rating_q025": 1320.4892618772503
        },
        "hunyuan-large-2025-02-10": {
            "rating": 1325.1329338805078,
            "rating_q975": 1334.945989581148,
            "rating_q025": 1315.3198781798676
        },
        "gpt-4-turbo-2024-04-09": {
            "rating": 1324.599019989872,
            "rating_q975": 1328.378957970273,
            "rating_q025": 1320.819082009471
        },
        "claude-3-opus-20240229": {
            "rating": 1323.3745870317339,
            "rating_q975": 1326.2818395864851,
            "rating_q025": 1320.4673344769826
        },
        "claude-3-5-haiku-20241022": {
            "rating": 1323.121449504169,
            "rating_q975": 1326.3051497808544,
            "rating_q025": 1319.9377492274837
        },
        "gemini-1.5-pro-001": {
            "rating": 1322.453178629692,
            "rating_q975": 1326.3008252093045,
            "rating_q025": 1318.6055320500795
        },
        "deepseek-v2.5-1210": {
            "rating": 1322.2556622591612,
            "rating_q975": 1330.4675563264761,
            "rating_q025": 1314.0437681918463
        },
        "llama-4-scout-17b-16e-instruct": {
            "rating": 1321.7151420421574,
            "rating_q975": 1326.4399834138346,
            "rating_q025": 1316.99030067048
        },
        "gpt-4.1-nano-2025-04-14": {
            "rating": 1320.6191987842049,
            "rating_q975": 1328.4145269184585,
            "rating_q025": 1312.8238706499512
        },
        "ring-flash-2.0": {
            "rating": 1319.3904298900661,
            "rating_q975": 1326.6400530817934,
            "rating_q025": 1312.1408066983388
        },
        "step-1o-turbo-202506": {
            "rating": 1319.0902508606796,
            "rating_q975": 1325.794826468072,
            "rating_q025": 1312.3856752532872
        },
        "llama-3.3-70b-instruct": {
            "rating": 1318.9767321080576,
            "rating_q975": 1322.3442715942024,
            "rating_q025": 1315.6091926219128
        },
        "glm-4-plus": {
            "rating": 1318.3310804666924,
            "rating_q975": 1323.1500716955807,
            "rating_q025": 1313.512089237804
        },
        "qwen-max-0919": {
            "rating": 1317.9469491916589,
            "rating_q975": 1323.5602689218456,
            "rating_q025": 1312.3336294614721
        },
        "gemma-3n-e4b-it": {
            "rating": 1317.7369887339119,
            "rating_q975": 1322.887998791401,
            "rating_q025": 1312.5859786764227
        },
        "gpt-oss-20b": {
            "rating": 1316.4422700346634,
            "rating_q975": 1322.8581026977174,
            "rating_q025": 1310.0264373716093
        },
        "gpt-4o-mini-2024-07-18": {
            "rating": 1315.4854371287179,
            "rating_q975": 1318.8432740517385,
            "rating_q025": 1312.1276002056973
        },
        "gpt-4-1106-preview": {
            "rating": 1314.8340811282187,
            "rating_q975": 1318.598905764566,
            "rating_q025": 1311.0692564918713
        },
        "mistral-large-2407": {
            "rating": 1314.081241262119,
            "rating_q975": 1317.8506839996685,
            "rating_q025": 1310.3117985245694
        },
        "gpt-4-0125-preview": {
            "rating": 1313.8411110062607,
            "rating_q975": 1317.8063946072637,
            "rating_q025": 1309.8758274052577
        },
        "qwen2.5-plus-1127": {
            "rating": 1313.2876536292338,
            "rating_q975": 1319.566936057346,
            "rating_q025": 1307.0083712011215
        },
        "athene-v2-chat": {
            "rating": 1312.6132338154023,
            "rating_q975": 1317.0657340624705,
            "rating_q025": 1308.160733568334
        },
        "gemini-1.5-flash-002": {
            "rating": 1310.8067680536133,
            "rating_q975": 1314.8937920449869,
            "rating_q025": 1306.7197440622397
        },
        "hunyuan-standard-2025-02-10": {
            "rating": 1310.142233935277,
            "rating_q975": 1319.9061106965441,
            "rating_q025": 1300.37835717401
        },
        "grok-2-mini-2024-08-13": {
            "rating": 1307.0822861133115,
            "rating_q975": 1310.6480208153519,
            "rating_q025": 1303.5165514112712
        },
        "deepseek-v2.5": {
            "rating": 1306.1693548299309,
            "rating_q975": 1310.7592481757504,
            "rating_q025": 1301.5794614841113
        },
        "magistral-medium-2506": {
            "rating": 1305.4742447285885,
            "rating_q975": 1311.8796448088442,
            "rating_q025": 1299.0688446483327
        },
        "mistral-large-2411": {
            "rating": 1305.1097134405013,
            "rating_q975": 1309.4258390868958,
            "rating_q025": 1300.7935877941068
        },
        "athene-70b-0725": {
            "rating": 1304.869553167923,
            "rating_q975": 1310.4467688985949,
            "rating_q025": 1299.292337437251
        },
        "mistral-small-3.1-24b-instruct-2503": {
            "rating": 1303.2354776269708,
            "rating_q975": 1307.7631937122915,
            "rating_q025": 1298.7077615416501
        },
        "qwen2.5-72b-instruct": {
            "rating": 1301.9797481633386,
            "rating_q975": 1305.9131160085942,
            "rating_q025": 1298.046380318083
        },
        "gemma-3-4b-it": {
            "rating": 1300.6781688103356,
            "rating_q975": 1310.0750868584726,
            "rating_q025": 1291.2812507621986
        },
        "llama-3.1-nemotron-70b-instruct": {
            "rating": 1297.4685427894524,
            "rating_q975": 1305.190285395372,
            "rating_q025": 1289.7468001835327
        },
        "hunyuan-large-vision": {
            "rating": 1294.971174664295,
            "rating_q975": 1304.0333669850868,
            "rating_q025": 1285.908982343503
        },
        "llama-3.1-70b-instruct": {
            "rating": 1293.5266633923025,
            "rating_q975": 1297.0912968657578,
            "rating_q025": 1289.962029918847
        },
        "gpt-4-0314": {
            "rating": 1289.1012642682203,
            "rating_q975": 1293.8331330764952,
            "rating_q025": 1284.3693954599455
        },
        "amazon-nova-pro-v1.0": {
            "rating": 1288.9012887745878,
            "rating_q975": 1293.3507524038505,
            "rating_q025": 1284.451825145325
        },
        "jamba-1.5-large": {
            "rating": 1288.4578860434822,
            "rating_q975": 1295.7391719292375,
            "rating_q025": 1281.1766001577269
        },
        "gemma-2-27b-it": {
            "rating": 1287.535663131992,
            "rating_q975": 1290.7501083175082,
            "rating_q025": 1284.3212179464756
        },
        "llama-3.1-tulu-3-70b": {
            "rating": 1287.0202749442215,
            "rating_q975": 1297.4446159983893,
            "rating_q025": 1276.5959338900536
        },
        "llama-3.1-nemotron-51b-instruct": {
            "rating": 1286.9858751536067,
            "rating_q975": 1296.9157372264556,
            "rating_q025": 1277.0560130807578
        },
        "reka-core-20240904": {
            "rating": 1286.9543520862435,
            "rating_q975": 1294.0628651102925,
            "rating_q025": 1279.8458390621945
        },
        "gemini-1.5-flash-001": {
            "rating": 1284.628133224419,
            "rating_q975": 1288.9988845981263,
            "rating_q025": 1280.2573818507115
        },
        "claude-3-sonnet-20240229": {
            "rating": 1282.514680983018,
            "rating_q975": 1286.4162474697423,
            "rating_q025": 1278.6131144962937
        },
        "gemma-2-9b-it-simpo": {
            "rating": 1278.9525144552695,
            "rating_q975": 1285.7838010092746,
            "rating_q025": 1272.1212279012643
        },
        "nemotron-4-340b-instruct": {
            "rating": 1278.9366148145798,
            "rating_q975": 1284.1771669861635,
            "rating_q025": 1273.6960626429961
        },
        "command-r-plus-08-2024": {
            "rating": 1277.9801919751537,
            "rating_q975": 1284.4864991509971,
            "rating_q025": 1271.4738847993103
        },
        "gpt-4-0613": {
            "rating": 1277.4016225459031,
            "rating_q975": 1281.3840386986478,
            "rating_q025": 1273.4192063931584
        },
        "llama-3-70b-instruct": {
            "rating": 1276.2009391297024,
            "rating_q975": 1279.6582042407526,
            "rating_q025": 1272.7436740186522
        },
        "glm-4-0520": {
            "rating": 1274.1938878993346,
            "rating_q975": 1281.1369376490338,
            "rating_q025": 1267.2508381496355
        },
        "reka-flash-20240904": {
            "rating": 1273.113447747915,
            "rating_q975": 1280.0531230141478,
            "rating_q025": 1266.1737724816821
        },
        "mistral-small-24b-instruct-2501": {
            "rating": 1273.0404678117015,
            "rating_q975": 1278.8928418292041,
            "rating_q025": 1267.188093794199
        },
        "qwen2.5-coder-32b-instruct": {
            "rating": 1269.1215834419093,
            "rating_q975": 1277.2139281110663,
            "rating_q025": 1261.0292387727523
        },
        "c4ai-aya-expanse-32b": {
            "rating": 1267.6595676780303,
            "rating_q975": 1272.43903401223,
            "rating_q025": 1262.8801013438306
        },
        "deepseek-coder-v2": {
            "rating": 1265.1160013241301,
            "rating_q975": 1271.340921474893,
            "rating_q025": 1258.8910811733672
        },
        "gemma-2-9b-it": {
            "rating": 1264.5217421124019,
            "rating_q975": 1268.1949587410343,
            "rating_q025": 1260.8485254837694
        },
        "command-r-plus": {
            "rating": 1264.4726451164602,
            "rating_q975": 1268.6942547704903,
            "rating_q025": 1260.25103546243
        },
        "qwen2-72b-instruct": {
            "rating": 1262.5411291245841,
            "rating_q975": 1267.3888995309267,
            "rating_q025": 1257.6933587182416
        },
        "claude-3-haiku-20240307": {
            "rating": 1261.7854076992871,
            "rating_q975": 1265.4194450307168,
            "rating_q025": 1258.1513703678575
        },
        "amazon-nova-lite-v1.0": {
            "rating": 1259.6638517367808,
            "rating_q975": 1264.717158615744,
            "rating_q025": 1254.6105448578176
        },
        "gemini-1.5-flash-8b-001": {
            "rating": 1259.28217787091,
            "rating_q975": 1263.4258060069765,
            "rating_q025": 1255.1385497348433
        },
        "phi-4": {
            "rating": 1254.8950506893123,
            "rating_q975": 1259.3991606719364,
            "rating_q025": 1250.390940706688
        },
        "olmo-2-0325-32b-instruct": {
            "rating": 1252.1315582826944,
            "rating_q975": 1262.886022652663,
            "rating_q025": 1241.3770939127257
        },
        "command-r-08-2024": {
            "rating": 1251.6740731072744,
            "rating_q975": 1258.2103582839898,
            "rating_q025": 1245.137787930559
        },
        "mistral-large-2402": {
            "rating": 1244.6896223786866,
            "rating_q975": 1249.3252793159465,
            "rating_q025": 1240.0539654414267
        },
        "amazon-nova-micro-v1.0": {
            "rating": 1240.925566133089,
            "rating_q975": 1245.9442547591134,
            "rating_q025": 1235.9068775070646
        },
        "jamba-1.5-mini": {
            "rating": 1238.9211590911552,
            "rating_q975": 1246.1043296786024,
            "rating_q025": 1231.737988503708
        },
        "ministral-8b-2410": {
            "rating": 1236.1349609574577,
            "rating_q975": 1245.1945067844483,
            "rating_q025": 1227.075415130467
        },
        "gemini-pro-dev-api": {
            "rating": 1236.0212651404809,
            "rating_q975": 1243.3496822905172,
            "rating_q025": 1228.6928479904445
        },
        "hunyuan-standard-256k": {
            "rating": 1235.9481036651637,
            "rating_q975": 1247.620218813078,
            "rating_q025": 1224.2759885172493
        },
        "reka-flash-21b-20240226-online": {
            "rating": 1234.9887628353345,
            "rating_q975": 1242.3784686968093,
            "rating_q025": 1227.5990569738597
        },
        "qwen1.5-110b-chat": {
            "rating": 1234.8700152741812,
            "rating_q975": 1240.3534212271757,
            "rating_q025": 1229.3866093211868
        },
        "qwen1.5-72b-chat": {
            "rating": 1234.2226514481529,
            "rating_q975": 1239.4318739437604,
            "rating_q025": 1229.0134289525454
        },
        "mixtral-8x22b-instruct-v0.1": {
            "rating": 1232.0588150572116,
            "rating_q975": 1236.5146224246314,
            "rating_q025": 1227.6030076897919
        },
        "command-r": {
            "rating": 1228.7913429768714,
            "rating_q975": 1233.4872178763378,
            "rating_q025": 1224.095468077405
        },
        "reka-flash-21b-20240226": {
            "rating": 1227.1981011015023,
            "rating_q975": 1233.1043182888127,
            "rating_q025": 1221.2918839141919
        },
        "mistral-medium": {
            "rating": 1225.6766312623604,
            "rating_q975": 1231.1175298249261,
            "rating_q025": 1220.2357326997947
        },
        "gpt-3.5-turbo-0125": {
            "rating": 1224.9516788312212,
            "rating_q975": 1229.573914328184,
            "rating_q025": 1220.3294433342585
        },
        "c4ai-aya-expanse-8b": {
            "rating": 1223.8056730868138,
            "rating_q975": 1230.6918369825019,
            "rating_q025": 1216.9195091911258
        },
        "gemini-pro": {
            "rating": 1223.5659551104225,
            "rating_q975": 1235.388976900608,
            "rating_q025": 1211.742933320237
        },
        "llama-3.1-tulu-3-8b": {
            "rating": 1223.0958401907708,
            "rating_q975": 1233.6884617719384,
            "rating_q025": 1212.5032186096032
        },
        "llama-3-8b-instruct": {
            "rating": 1222.3886977364837,
            "rating_q975": 1226.0056985736892,
            "rating_q025": 1218.7716968992781
        },
        "zephyr-orpo-141b-A35b-v0.1": {
            "rating": 1216.3287379084813,
            "rating_q975": 1227.166721279255,
            "rating_q025": 1205.4907545377077
        },
        "yi-1.5-34b-chat": {
            "rating": 1213.740708027697,
            "rating_q975": 1218.7027960275896,
            "rating_q025": 1208.7786200278047
        },
        "llama-3.1-8b-instruct": {
            "rating": 1211.1470965525061,
            "rating_q975": 1215.1399315788333,
            "rating_q025": 1207.154261526179
        },
        "granite-3.1-8b-instruct": {
            "rating": 1208.955736902486,
            "rating_q975": 1219.9714006688723,
            "rating_q025": 1197.9400731360997
        },
        "qwen1.5-32b-chat": {
            "rating": 1205.534171461501,
            "rating_q975": 1211.6181542596332,
            "rating_q025": 1199.4501886633689
        },
        "gpt-3.5-turbo-1106": {
            "rating": 1202.896542418085,
            "rating_q975": 1211.6754052436188,
            "rating_q025": 1194.117679592551
        },
        "mixtral-8x7b-instruct-v0.1": {
            "rating": 1199.846316299362,
            "rating_q975": 1204.0241933176828,
            "rating_q025": 1195.668439281041
        },
        "phi-3-medium-4k-instruct": {
            "rating": 1198.793872300028,
            "rating_q975": 1203.8607982817416,
            "rating_q025": 1193.7269463183143
        },
        "dbrx-instruct-preview": {
            "rating": 1197.7091423423165,
            "rating_q975": 1203.7705953466095,
            "rating_q025": 1191.6476893380234
        },
        "gemma-2-2b-it": {
            "rating": 1197.3487390118892,
            "rating_q975": 1201.3153292171517,
            "rating_q025": 1193.3821488066267
        },
        "qwen1.5-14b-chat": {
            "rating": 1192.5681157458282,
            "rating_q975": 1199.656176218432,
            "rating_q025": 1185.4800552732245
        },
        "internlm2_5-20b-chat": {
            "rating": 1192.3358991820005,
            "rating_q975": 1199.4651334137159,
            "rating_q025": 1185.2066649502851
        },
        "yi-34b-chat": {
            "rating": 1185.8700387658153,
            "rating_q975": 1192.662872436519,
            "rating_q025": 1179.0772050951116
        },
        "wizardlm-70b": {
            "rating": 1185.285524338635,
            "rating_q975": 1194.7515602583667,
            "rating_q025": 1175.8194884189033
        },
        "granite-3.0-8b-instruct": {
            "rating": 1184.8477301887478,
            "rating_q975": 1193.4811469686551,
            "rating_q025": 1176.2143134088406
        },
        "deepseek-llm-67b-chat": {
            "rating": 1184.5684596349124,
            "rating_q975": 1196.133652761994,
            "rating_q025": 1173.0032665078309
        },
        "openchat-3.5": {
            "rating": 1182.7840618374917,
            "rating_q975": 1192.4893441952318,
            "rating_q025": 1173.0787794797516
        },
        "openchat-3.5-0106": {
            "rating": 1182.7593366471417,
            "rating_q975": 1190.7327301496568,
            "rating_q025": 1174.7859431446266
        },
        "granite-3.1-2b-instruct": {
            "rating": 1181.540640595856,
            "rating_q975": 1192.6484175305004,
            "rating_q025": 1170.4328636612117
        },
        "snowflake-arctic-instruct": {
            "rating": 1180.6235049240013,
            "rating_q975": 1186.5320230232396,
            "rating_q025": 1174.714986824763
        },
        "tulu-2-dpo-70b": {
            "rating": 1180.5068835137226,
            "rating_q975": 1190.3918405406691,
            "rating_q025": 1170.6219264867761
        },
        "gemma-1.1-7b-it": {
            "rating": 1179.294776841658,
            "rating_q975": 1185.3087580382903,
            "rating_q025": 1173.2807956450256
        },
        "openhermes-2.5-mistral-7b": {
            "rating": 1176.9199567093192,
            "rating_q975": 1187.400057503522,
            "rating_q025": 1166.4398559151164
        },
        "vicuna-33b": {
            "rating": 1174.3076168249308,
            "rating_q975": 1180.495458318588,
            "rating_q025": 1168.1197753312738
        },
        "starling-lm-7b-beta": {
            "rating": 1173.7857054147526,
            "rating_q975": 1181.19225988898,
            "rating_q025": 1166.379150940525
        },
        "phi-3-small-8k-instruct": {
            "rating": 1172.982673869898,
            "rating_q975": 1178.834204540155,
            "rating_q025": 1167.131143199641
        },
        "llama-2-70b-chat": {
            "rating": 1172.8513008270252,
            "rating_q975": 1178.3167955545548,
            "rating_q025": 1167.3858060994955
        },
        "starling-lm-7b-alpha": {
            "rating": 1169.4004144548935,
            "rating_q975": 1177.481512589733,
            "rating_q025": 1161.319316320054
        },
        "llama-3.2-3b-instruct": {
            "rating": 1166.413143050518,
            "rating_q975": 1174.0427744869514,
            "rating_q025": 1158.7835116140848
        },
        "nous-hermes-2-mixtral-8x7b-dpo": {
            "rating": 1166.3012538929497,
            "rating_q975": 1178.2382529645583,
            "rating_q025": 1154.364254821341
        },
        "llama2-70b-steerlm-chat": {
            "rating": 1158.4350487067707,
            "rating_q975": 1171.1142633457869,
            "rating_q025": 1145.7558340677544
        },
        "qwq-32b-preview": {
            "rating": 1157.911214989412,
            "rating_q975": 1169.4214650536967,
            "rating_q025": 1146.4009649251273
        },
        "granite-3.0-2b-instruct": {
            "rating": 1156.8247294499495,
            "rating_q975": 1165.1662619104964,
            "rating_q025": 1148.4831969894026
        },
        "solar-10.7b-instruct-v1.0": {
            "rating": 1155.8310720033935,
            "rating_q975": 1169.0999552012088,
            "rating_q025": 1142.5621888055782
        },
        "dolphin-2.2.1-mistral-7b": {
            "rating": 1153.7016895458669,
            "rating_q975": 1169.2025629548161,
            "rating_q025": 1138.2008161369176
        },
        "mpt-30b-chat": {
            "rating": 1152.755173868522,
            "rating_q975": 1165.108181982637,
            "rating_q025": 1140.402165754407
        },
        "wizardlm-13b": {
            "rating": 1151.2505696320102,
            "rating_q975": 1160.563837473719,
            "rating_q025": 1141.9373017903013
        },
        "mistral-7b-instruct-v0.2": {
            "rating": 1151.0356262438218,
            "rating_q975": 1157.679915685713,
            "rating_q025": 1144.3913368019305
        },
        "falcon-180b-chat": {
            "rating": 1150.0984046773356,
            "rating_q975": 1167.4289637821528,
            "rating_q025": 1132.7678455725184
        },
        "phi-3-mini-4k-instruct-june-2024": {
            "rating": 1143.7994276000495,
            "rating_q975": 1150.1752457395141,
            "rating_q025": 1137.4236094605849
        },
        "qwen1.5-7b-chat": {
            "rating": 1143.6996730827877,
            "rating_q975": 1153.5924136805484,
            "rating_q025": 1133.8069324850271
        },
        "llama-2-13b-chat": {
            "rating": 1143.4509549914733,
            "rating_q975": 1150.1428600275476,
            "rating_q025": 1136.759049955399
        },
        "vicuna-13b": {
            "rating": 1142.6355294205669,
            "rating_q975": 1149.3147973438413,
            "rating_q025": 1135.9562614972924
        },
        "qwen-14b-chat": {
            "rating": 1139.602695943651,
            "rating_q975": 1150.6169146108975,
            "rating_q025": 1128.5884772764045
        },
        "palm-2": {
            "rating": 1137.6427528559439,
            "rating_q975": 1147.1110297649236,
            "rating_q025": 1128.174475946964
        },
        "codellama-34b-instruct": {
            "rating": 1136.8699804138041,
            "rating_q975": 1145.7845399312473,
            "rating_q025": 1127.955420896361
        },
        "gemma-7b-it": {
            "rating": 1135.0248699645772,
            "rating_q975": 1144.5438180209828,
            "rating_q025": 1125.5059219081716
        },
        "zephyr-7b-beta": {
            "rating": 1132.2392018735788,
            "rating_q975": 1141.1185540671108,
            "rating_q025": 1123.3598496800469
        },
        "guanaco-33b": {
            "rating": 1130.4070036165904,
            "rating_q975": 1142.5789354657604,
            "rating_q025": 1118.2350717674203
        },
        "phi-3-mini-128k-instruct": {
            "rating": 1130.0381838731278,
            "rating_q975": 1137.4442324744603,
            "rating_q025": 1122.6321352717953
        },
        "zephyr-7b-alpha": {
            "rating": 1129.8763296284787,
            "rating_q975": 1145.7485065506178,
            "rating_q025": 1114.0041527063397
        },
        "phi-3-mini-4k-instruct": {
            "rating": 1129.3776573899322,
            "rating_q975": 1135.6866262964872,
            "rating_q025": 1123.0686884833772
        },
        "stripedhyena-nous-7b": {
            "rating": 1121.4136484041383,
            "rating_q975": 1132.433394122824,
            "rating_q025": 1110.3939026854525
        },
        "codellama-70b-instruct": {
            "rating": 1119.7841966316723,
            "rating_q975": 1138.2159726093134,
            "rating_q025": 1101.3524206540312
        },
        "smollm2-1.7b-instruct": {
            "rating": 1118.8346143181634,
            "rating_q975": 1133.1413524638679,
            "rating_q025": 1104.527876172459
        },
        "vicuna-7b": {
            "rating": 1117.163669224937,
            "rating_q975": 1126.387989298531,
            "rating_q025": 1107.9393491513429
        },
        "gemma-1.1-2b-it": {
            "rating": 1113.0310501906656,
            "rating_q975": 1120.781489249673,
            "rating_q025": 1105.2806111316581
        },
        "llama-3.2-1b-instruct": {
            "rating": 1111.982905713568,
            "rating_q975": 1119.789488988064,
            "rating_q025": 1104.176322439072
        },
        "mistral-7b-instruct": {
            "rating": 1110.9775172556633,
            "rating_q975": 1120.3021571978845,
            "rating_q025": 1101.652877313442
        },
        "llama-2-7b-chat": {
            "rating": 1109.0630053581172,
            "rating_q975": 1116.0957897263931,
            "rating_q025": 1102.0302209898412
        },
        "gemma-2b-it": {
            "rating": 1090.9192331638615,
            "rating_q975": 1102.5873588478553,
            "rating_q025": 1079.2511074798676
        },
        "qwen1.5-4b-chat": {
            "rating": 1090.323953146095,
            "rating_q975": 1099.7252988694454,
            "rating_q025": 1080.9226074227445
        },
        "olmo-7b-instruct": {
            "rating": 1075.1543339359437,
            "rating_q975": 1086.4098713018489,
            "rating_q025": 1063.8987965700385
        },
        "koala-13b": {
            "rating": 1071.400102332143,
            "rating_q975": 1081.4275062090278,
            "rating_q025": 1061.3726984552582
        },
        "gpt4all-13b-snoozy": {
            "rating": 1067.9164268268328,
            "rating_q975": 1083.3202367190343,
            "rating_q025": 1052.5126169346313
        },
        "alpaca-13b": {
            "rating": 1064.841782909909,
            "rating_q975": 1076.3552897311754,
            "rating_q025": 1053.3282760886425
        },
        "mpt-7b-chat": {
            "rating": 1062.2408424339294,
            "rating_q975": 1074.3058224688834,
            "rating_q025": 1050.1758623989754
        },
        "chatglm3-6b": {
            "rating": 1056.501309411749,
            "rating_q975": 1068.2260908003004,
            "rating_q025": 1044.7765280231974
        },
        "RWKV-4-Raven-14B": {
            "rating": 1041.928233106938,
            "rating_q975": 1053.3901884037273,
            "rating_q025": 1030.4662778101488
        },
        "chatglm2-6b": {
            "rating": 1024.1969751654838,
            "rating_q975": 1037.909529500518,
            "rating_q025": 1010.4844208304496
        },
        "oasst-pythia-12b": {
            "rating": 1023.7462615818152,
            "rating_q975": 1034.7095716205865,
            "rating_q025": 1012.7829515430441
        },
        "chatglm-6b": {
            "rating": 994.3714872642427,
            "rating_q975": 1007.1577689050844,
            "rating_q025": 981.585205623401
        },
        "fastchat-t5-3b": {
            "rating": 991.7989068294289,
            "rating_q975": 1004.3616989387452,
            "rating_q025": 979.2361147201126
        },
        "dolly-v2-12b": {
            "rating": 979.3123293692709,
            "rating_q975": 992.971737428899,
            "rating_q025": 965.6529213096427
        },
        "llama-13b": {
            "rating": 973.1030028067539,
            "rating_q975": 989.0425782338435,
            "rating_q025": 957.1634273796643
        },
        "stablelm-tuned-alpha-7b": {
            "rating": 952.2442844151244,
            "rating_q975": 965.1672778039784,
            "rating_q025": 939.3212910262704
        }
    },
    "no_tie": {
        "gemini-2.5-pro": {
            "rating": 1453.5531608708843,
            "rating_q975": 1459.2379778348618,
            "rating_q025": 1447.8683439069068
        },
        "claude-opus-4-1-20250805-thinking-16k": {
            "rating": 1450.1970690117041,
            "rating_q975": 1456.5259168261503,
            "rating_q025": 1443.868221197258
        },
        "claude-sonnet-4-5-20250929-thinking-32k": {
            "rating": 1449.6164950006892,
            "rating_q975": 1457.7432663796276,
            "rating_q025": 1441.4897236217507
        },
        "gpt-4.5-preview-2025-02-27": {
            "rating": 1448.9868001590503,
            "rating_q975": 1457.5201859008873,
            "rating_q025": 1440.4534144172133
        },
        "claude-sonnet-4-5-20250929": {
            "rating": 1440.2792180443637,
            "rating_q975": 1450.637447859555,
            "rating_q025": 1429.9209882291723
        },
        "chatgpt-4o-latest-20250326": {
            "rating": 1439.5160262679703,
            "rating_q975": 1444.9206189598772,
            "rating_q025": 1434.1114335760635
        },
        "claude-opus-4-1-20250805": {
            "rating": 1435.9880478013565,
            "rating_q975": 1441.9280408214327,
            "rating_q025": 1430.0480547812804
        },
        "gpt-5-high": {
            "rating": 1430.5898907838848,
            "rating_q975": 1437.1215323742422,
            "rating_q025": 1424.0582491935274
        },
        "o3-2025-04-16": {
            "rating": 1428.6090724254366,
            "rating_q975": 1433.9019883234375,
            "rating_q025": 1423.3161565274356
        },
        "qwen3-max-preview": {
            "rating": 1428.1682985464697,
            "rating_q975": 1434.9798328894544,
            "rating_q025": 1421.356764203485
        },
        "deepseek-v3.2-exp": {
            "rating": 1423.8426282063178,
            "rating_q975": 1463.0633494060824,
            "rating_q025": 1384.6219070065533
        },
        "glm-4.6": {
            "rating": 1421.1783695160784,
            "rating_q975": 1430.277378464304,
            "rating_q025": 1412.0793605678527
        },
        "gpt-5-chat": {
            "rating": 1417.8300058506989,
            "rating_q975": 1424.1893792885528,
            "rating_q025": 1411.470632412845
        },
        "qwen3-max-2025-09-23": {
            "rating": 1415.4983821267888,
            "rating_q975": 1424.750214505668,
            "rating_q025": 1406.2465497479095
        },
        "claude-opus-4-20250514-thinking-16k": {
            "rating": 1414.6210309005287,
            "rating_q975": 1420.4520090720719,
            "rating_q025": 1408.7900527289855
        },
        "qwen3-235b-a22b-instruct-2507": {
            "rating": 1411.2034301691099,
            "rating_q975": 1417.3466153369895,
            "rating_q025": 1405.0602450012302
        },
        "grok-4-fast": {
            "rating": 1408.8987956079895,
            "rating_q975": 1419.4028006043277,
            "rating_q025": 1398.3947906116514
        },
        "deepseek-v3.2-exp-thinking": {
            "rating": 1408.7966772395557,
            "rating_q975": 1418.013744169427,
            "rating_q025": 1399.5796103096845
        },
        "deepseek-r1-0528": {
            "rating": 1406.2487640708237,
            "rating_q975": 1414.1157104967176,
            "rating_q025": 1398.3818176449297
        },
        "kimi-k2-0905-preview": {
            "rating": 1405.1677212791606,
            "rating_q975": 1414.2538520869055,
            "rating_q025": 1396.0815904714157
        },
        "kimi-k2-0711-preview": {
            "rating": 1404.233456206827,
            "rating_q975": 1410.7275282519786,
            "rating_q025": 1397.7393841616754
        },
        "deepseek-v3.1-thinking": {
            "rating": 1402.1099591002182,
            "rating_q975": 1411.1794448924068,
            "rating_q025": 1393.0404733080297
        },
        "deepseek-v3.1": {
            "rating": 1401.959058497245,
            "rating_q975": 1410.3441686067365,
            "rating_q025": 1393.5739483877535
        },
        "qwen3-vl-235b-a22b-instruct": {
            "rating": 1401.1220034145795,
            "rating_q975": 1410.7069782828073,
            "rating_q025": 1391.5370285463516
        },
        "gpt-4.1-2025-04-14": {
            "rating": 1400.5678167585218,
            "rating_q975": 1405.9524249913604,
            "rating_q025": 1395.183208525683
        },
        "claude-opus-4-20250514": {
            "rating": 1400.3123745635469,
            "rating_q975": 1406.0770760114262,
            "rating_q025": 1394.5476731156675
        },
        "deepseek-v3.1-terminus": {
            "rating": 1399.041486508557,
            "rating_q975": 1412.8843320853803,
            "rating_q025": 1385.1986409317337
        },
        "deepseek-v3.1-terminus-thinking": {
            "rating": 1397.2419044289416,
            "rating_q975": 1411.4828888826225,
            "rating_q025": 1383.0009199752606
        },
        "grok-3-preview-02-24": {
            "rating": 1397.1244649078803,
            "rating_q975": 1403.240841339396,
            "rating_q025": 1391.0080884763647
        },
        "mistral-medium-2508": {
            "rating": 1395.7860527807175,
            "rating_q975": 1402.4008924745845,
            "rating_q025": 1389.1712130868505
        },
        "grok-4-0709": {
            "rating": 1393.9202613934758,
            "rating_q975": 1399.8293324044075,
            "rating_q025": 1388.011190382544
        },
        "glm-4.5": {
            "rating": 1392.2654328373449,
            "rating_q975": 1399.172931921498,
            "rating_q025": 1385.3579337531917
        },
        "gemini-2.5-flash": {
            "rating": 1390.26240923369,
            "rating_q975": 1395.7034805822832,
            "rating_q025": 1384.821337885097
        },
        "claude-haiku-4-5-20251001": {
            "rating": 1388.8748636717835,
            "rating_q975": 1397.7612591950615,
            "rating_q025": 1379.9884681485055
        },
        "gemini-2.5-flash-preview-09-2025": {
            "rating": 1388.5373146573525,
            "rating_q975": 1396.5267530559909,
            "rating_q025": 1380.547876258714
        },
        "o1-2024-12-17": {
            "rating": 1384.2041594286102,
            "rating_q975": 1390.5533709444328,
            "rating_q025": 1377.8549479127876
        },
        "claude-sonnet-4-20250514-thinking-32k": {
            "rating": 1382.9291475657203,
            "rating_q975": 1388.789867767414,
            "rating_q025": 1377.0684273640265
        },
        "qwen3-next-80b-a3b-instruct": {
            "rating": 1382.7999264959153,
            "rating_q975": 1390.0071492121947,
            "rating_q025": 1375.592703779636
        },
        "qwen3-235b-a22b-no-thinking": {
            "rating": 1379.947390800036,
            "rating_q975": 1386.0949731037508,
            "rating_q025": 1373.799808496321
        },
        "deepseek-r1": {
            "rating": 1379.4452351858022,
            "rating_q975": 1386.6723281573334,
            "rating_q025": 1372.218142214271
        },
        "longcat-flash-chat": {
            "rating": 1378.1402584378493,
            "rating_q975": 1387.0203997104447,
            "rating_q025": 1369.2601171652539
        },
        "qwen3-235b-a22b-thinking-2507": {
            "rating": 1376.5508576167508,
            "rating_q975": 1385.8819782411806,
            "rating_q025": 1367.219736992321
        },
        "deepseek-v3-0324": {
            "rating": 1370.9347696339885,
            "rating_q975": 1376.4246878473136,
            "rating_q025": 1365.4448514206633
        },
        "claude-sonnet-4-20250514": {
            "rating": 1369.6547118964388,
            "rating_q975": 1375.4887682397737,
            "rating_q025": 1363.820655553104
        },
        "qwen3-vl-235b-a22b-thinking": {
            "rating": 1369.1819213631368,
            "rating_q975": 1378.9505914658944,
            "rating_q025": 1359.4132512603792
        },
        "gpt-5-mini-high": {
            "rating": 1369.1502815256003,
            "rating_q975": 1375.9379988432156,
            "rating_q025": 1362.362564207985
        },
        "mai-1-preview": {
            "rating": 1368.9257155438022,
            "rating_q975": 1376.5774174430735,
            "rating_q025": 1361.274013644531
        },
        "o4-mini-2025-04-16": {
            "rating": 1368.9089202725534,
            "rating_q975": 1374.4475112322175,
            "rating_q025": 1363.3703293128892
        },
        "claude-3-7-sonnet-20250219-thinking-32k": {
            "rating": 1367.8269790193244,
            "rating_q975": 1373.4134883284821,
            "rating_q025": 1362.2404697101667
        },
        "o1-preview": {
            "rating": 1364.247980529882,
            "rating_q975": 1371.4664085019804,
            "rating_q025": 1357.0295525577835
        },
        "qwen3-coder-480b-a35b-instruct": {
            "rating": 1361.1261620156508,
            "rating_q975": 1367.988262554567,
            "rating_q025": 1354.2640614767347
        },
        "mistral-medium-2505": {
            "rating": 1359.242382648045,
            "rating_q975": 1365.7434361033493,
            "rating_q025": 1352.7413291927405
        },
        "hunyuan-t1-20250711": {
            "rating": 1357.2020447824464,
            "rating_q975": 1369.5547774503402,
            "rating_q025": 1344.8493121145525
        },
        "qwen3-30b-a3b-instruct-2507": {
            "rating": 1357.1981232685184,
            "rating_q975": 1364.0583761391413,
            "rating_q025": 1350.3378703978956
        },
        "gpt-4.1-mini-2025-04-14": {
            "rating": 1356.145027785309,
            "rating_q975": 1362.0753894095046,
            "rating_q025": 1350.2146661611132
        },
        "hunyuan-turbos-20250416": {
            "rating": 1354.9552290262718,
            "rating_q975": 1363.9015107183043,
            "rating_q025": 1346.0089473342393
        },
        "gemini-2.5-flash-lite-preview-09-2025-no-thinking": {
            "rating": 1351.9620733517227,
            "rating_q975": 1359.9998521598648,
            "rating_q025": 1343.9242945435806
        },
        "qwen2.5-max": {
            "rating": 1345.9444084695913,
            "rating_q975": 1351.8644004344465,
            "rating_q025": 1340.024416504736
        },
        "gemini-2.5-flash-lite-preview-06-17-thinking": {
            "rating": 1345.513880323592,
            "rating_q975": 1351.8011153126497,
            "rating_q025": 1339.2266453345344
        },
        "claude-3-5-sonnet-20241022": {
            "rating": 1344.2471607556272,
            "rating_q975": 1348.4382189648927,
            "rating_q025": 1340.0561025463617
        },
        "qwen3-235b-a22b": {
            "rating": 1342.9573172156884,
            "rating_q975": 1349.5566620972636,
            "rating_q025": 1336.3579723341131
        },
        "glm-4.5-air": {
            "rating": 1338.9870784685188,
            "rating_q975": 1345.3668964427343,
            "rating_q025": 1332.6072604943033
        },
        "qwen3-next-80b-a3b-thinking": {
            "rating": 1333.4044814765766,
            "rating_q975": 1341.5310263009826,
            "rating_q025": 1325.2779366521706
        },
        "minimax-m1": {
            "rating": 1333.326959144796,
            "rating_q975": 1339.2940554490665,
            "rating_q025": 1327.3598628405257
        },
        "gemma-3-27b-it": {
            "rating": 1329.4054361441135,
            "rating_q975": 1334.6200189374686,
            "rating_q025": 1324.1908533507585
        },
        "o3-mini-high": {
            "rating": 1327.9656478511724,
            "rating_q975": 1335.6506485732414,
            "rating_q025": 1320.2806471291035
        },
        "grok-3-mini-high": {
            "rating": 1325.7835503411386,
            "rating_q975": 1333.1069080550517,
            "rating_q025": 1318.4601926272255
        },
        "deepseek-v3": {
            "rating": 1325.5974366105247,
            "rating_q975": 1332.8749340295699,
            "rating_q025": 1318.3199391914795
        },
        "grok-3-mini-beta": {
            "rating": 1318.5621226297346,
            "rating_q975": 1325.513169005307,
            "rating_q025": 1311.6110762541623
        },
        "mistral-small-2506": {
            "rating": 1315.400932473713,
            "rating_q975": 1322.769518753234,
            "rating_q025": 1308.032346194192
        },
        "gemini-1.5-pro-002": {
            "rating": 1312.4709141007463,
            "rating_q975": 1317.5498371057704,
            "rating_q025": 1307.3919910957222
        },
        "gemini-2.0-flash-lite-preview-02-05": {
            "rating": 1312.061442367312,
            "rating_q975": 1318.656420124803,
            "rating_q025": 1305.4664646098213
        },
        "glm-4.5v": {
            "rating": 1311.003312638469,
            "rating_q975": 1323.3026667579288,
            "rating_q025": 1298.7039585190091
        },
        "gpt-oss-120b": {
            "rating": 1310.071279028045,
            "rating_q975": 1316.6522872420308,
            "rating_q025": 1303.4902708140592
        },
        "command-a-03-2025": {
            "rating": 1309.9331029514274,
            "rating_q975": 1315.1421592004492,
            "rating_q025": 1304.7240467024055
        },
        "o3-mini": {
            "rating": 1306.749845683776,
            "rating_q975": 1311.612705189367,
            "rating_q025": 1301.8869861781848
        },
        "qwen-plus-0125": {
            "rating": 1305.0548219990294,
            "rating_q975": 1317.909466258735,
            "rating_q025": 1292.2001777393239
        },
        "hunyuan-turbos-20250226": {
            "rating": 1303.522257365575,
            "rating_q975": 1322.671978624483,
            "rating_q025": 1284.3725361066668
        },
        "gpt-4o-2024-05-13": {
            "rating": 1302.7566890615117,
            "rating_q975": 1308.0619449398882,
            "rating_q025": 1297.4514331831351
        },
        "step-3": {
            "rating": 1302.7144075598837,
            "rating_q975": 1313.3242506924719,
            "rating_q025": 1292.1045644272956
        },
        "qwen3-32b": {
            "rating": 1302.2627294347913,
            "rating_q975": 1316.9508936088419,
            "rating_q025": 1287.5745652607407
        },
        "llama-3.1-nemotron-ultra-253b-v1": {
            "rating": 1300.8238743016886,
            "rating_q975": 1318.493283776401,
            "rating_q025": 1283.1544648269762
        },
        "amazon-nova-experimental-chat-10-09": {
            "rating": 1300.519279035373,
            "rating_q975": 1311.6429145688064,
            "rating_q025": 1289.3956435019397
        },
        "ling-flash-2.0": {
            "rating": 1299.618166382918,
            "rating_q975": 1309.946387831551,
            "rating_q025": 1289.289944934285
        },
        "glm-4-plus-0111": {
            "rating": 1299.5556796474052,
            "rating_q975": 1312.2355696083198,
            "rating_q025": 1286.8757896864906
        },
        "claude-3-5-sonnet-20240620": {
            "rating": 1295.6755191984412,
            "rating_q975": 1300.7403807804485,
            "rating_q025": 1290.6106576164339
        },
        "nvidia-llama-3.3-nemotron-super-49b-v1.5": {
            "rating": 1294.5075703903465,
            "rating_q975": 1308.9989277676502,
            "rating_q025": 1280.0162130130427
        },
        "gpt-5-nano-high": {
            "rating": 1294.156245695542,
            "rating_q975": 1303.8404976497993,
            "rating_q025": 1284.471993741285
        },
        "gemma-3-12b-it": {
            "rating": 1293.2282879586703,
            "rating_q975": 1307.686045466031,
            "rating_q025": 1278.7705304513097
        },
        "o1-mini": {
            "rating": 1287.5923257799543,
            "rating_q975": 1292.9729676253037,
            "rating_q025": 1282.211683934605
        },
        "llama-3.1-405b-instruct-bf16": {
            "rating": 1286.7543035351541,
            "rating_q975": 1292.217834379552,
            "rating_q025": 1281.2907726907563
        },
        "step-2-16k-exp-202412": {
            "rating": 1286.5887296669696,
            "rating_q975": 1300.536277940976,
            "rating_q025": 1272.641181392963
        },
        "grok-2-2024-08-13": {
            "rating": 1284.91604517944,
            "rating_q975": 1290.3112754036172,
            "rating_q025": 1279.520814955263
        },
        "gpt-4o-2024-08-06": {
            "rating": 1284.8592731101207,
            "rating_q975": 1291.186277829056,
            "rating_q025": 1278.5322683911854
        },
        "hunyuan-turbo-0110": {
            "rating": 1284.468898396703,
            "rating_q975": 1303.8924199872288,
            "rating_q025": 1265.0453768061773
        },
        "qwq-32b": {
            "rating": 1284.4492977084074,
            "rating_q975": 1290.972466044004,
            "rating_q025": 1277.9261293728107
        },
        "gemini-advanced-0514": {
            "rating": 1282.3819921808008,
            "rating_q975": 1289.6991769112167,
            "rating_q025": 1275.064807450385
        },
        "llama-3.1-405b-instruct-fp8": {
            "rating": 1282.0673505022398,
            "rating_q975": 1287.6608574884922,
            "rating_q025": 1276.4738435159875
        },
        "llama-4-maverick-17b-128e-instruct": {
            "rating": 1279.8945072704237,
            "rating_q975": 1285.929023904083,
            "rating_q025": 1273.8599906367645
        },
        "yi-lightning": {
            "rating": 1279.0514846467872,
            "rating_q975": 1286.591457919004,
            "rating_q025": 1271.5115113745705
        },
        "llama-3.3-nemotron-49b-super-v1": {
            "rating": 1274.724460830701,
            "rating_q975": 1293.904122895797,
            "rating_q025": 1255.544798765605
        },
        "qwen3-30b-a3b": {
            "rating": 1273.141994211905,
            "rating_q975": 1279.8577860730202,
            "rating_q025": 1266.42620235079
        },
        "llama-4-scout-17b-16e-instruct": {
            "rating": 1269.4888586371478,
            "rating_q975": 1276.166879336832,
            "rating_q025": 1262.8108379374637
        },
        "claude-3-5-haiku-20241022": {
            "rating": 1268.4525397258885,
            "rating_q975": 1273.1176689411654,
            "rating_q025": 1263.7874105106116
        },
        "deepseek-v2.5-1210": {
            "rating": 1267.6528027303584,
            "rating_q975": 1280.8023045013633,
            "rating_q025": 1254.5033009593535
        },
        "hunyuan-large-2025-02-10": {
            "rating": 1267.534187934113,
            "rating_q975": 1282.782526001156,
            "rating_q025": 1252.2858498670703
        },
        "gpt-4-turbo-2024-04-09": {
            "rating": 1266.0708519202415,
            "rating_q975": 1271.8257444742385,
            "rating_q025": 1260.3159593662444
        },
        "ring-flash-2.0": {
            "rating": 1265.6281974722551,
            "rating_q975": 1275.9507291247403,
            "rating_q025": 1255.30566581977
        },
        "gemini-1.5-pro-001": {
            "rating": 1264.4646441855982,
            "rating_q975": 1270.5747954923763,
            "rating_q025": 1258.35449287882
        },
        "gpt-4.1-nano-2025-04-14": {
            "rating": 1264.3843241508725,
            "rating_q975": 1276.686611593734,
            "rating_q025": 1252.0820367080112
        },
        "llama-3.3-70b-instruct": {
            "rating": 1263.9765678008112,
            "rating_q975": 1268.8843643353107,
            "rating_q025": 1259.0687712663116
        },
        "step-1o-turbo-202506": {
            "rating": 1263.8801538840435,
            "rating_q975": 1273.2795740246718,
            "rating_q025": 1254.4807337434152
        },
        "gpt-oss-20b": {
            "rating": 1262.7222898267387,
            "rating_q975": 1271.7839645907818,
            "rating_q025": 1253.6606150626956
        },
        "claude-3-opus-20240229": {
            "rating": 1262.3001957506,
            "rating_q975": 1266.8712279941951,
            "rating_q025": 1257.729163507005
        },
        "gemma-3n-e4b-it": {
            "rating": 1261.9806197956223,
            "rating_q975": 1269.1243956408778,
            "rating_q025": 1254.8368439503668
        },
        "glm-4-plus": {
            "rating": 1261.5841140348666,
            "rating_q975": 1269.1809166443388,
            "rating_q025": 1253.9873114253944
        },
        "gpt-4o-mini-2024-07-18": {
            "rating": 1258.137394366382,
            "rating_q975": 1263.2264610420857,
            "rating_q025": 1253.0483276906784
        },
        "qwen2.5-plus-1127": {
            "rating": 1256.631589091186,
            "rating_q975": 1266.7335995763337,
            "rating_q025": 1246.5295786060383
        },
        "qwen-max-0919": {
            "rating": 1255.613253256339,
            "rating_q975": 1264.1526374197158,
            "rating_q025": 1247.0738690929622
        },
        "athene-v2-chat": {
            "rating": 1254.0542187641777,
            "rating_q975": 1261.0321265666394,
            "rating_q025": 1247.076310961716
        },
        "mistral-large-2407": {
            "rating": 1252.7241258331342,
            "rating_q975": 1258.7172846706662,
            "rating_q025": 1246.730966995602
        },
        "hunyuan-standard-2025-02-10": {
            "rating": 1250.890111430881,
            "rating_q975": 1266.2230349665294,
            "rating_q025": 1235.5571878952326
        },
        "magistral-medium-2506": {
            "rating": 1250.058987518215,
            "rating_q975": 1259.1014653000273,
            "rating_q025": 1241.0165097364027
        },
        "gemini-1.5-flash-002": {
            "rating": 1247.3677972555809,
            "rating_q975": 1253.756385327451,
            "rating_q025": 1240.9792091837107
        },
        "gpt-4-1106-preview": {
            "rating": 1245.801897953157,
            "rating_q975": 1251.6286893219483,
            "rating_q025": 1239.975106584366
        },
        "gpt-4-0125-preview": {
            "rating": 1244.8839498737484,
            "rating_q975": 1250.940943022591,
            "rating_q025": 1238.8269567249058
        },
        "grok-2-mini-2024-08-13": {
            "rating": 1244.7465598825138,
            "rating_q975": 1250.3840568307266,
            "rating_q025": 1239.109062934301
        },
        "athene-70b-0725": {
            "rating": 1241.7073005721618,
            "rating_q975": 1250.4306690719632,
            "rating_q025": 1232.9839320723604
        },
        "deepseek-v2.5": {
            "rating": 1241.0175434860207,
            "rating_q975": 1248.4484337734593,
            "rating_q025": 1233.586653198582
        },
        "mistral-small-3.1-24b-instruct-2503": {
            "rating": 1238.960929998133,
            "rating_q975": 1245.4315706934924,
            "rating_q025": 1232.4902893027736
        },
        "mistral-large-2411": {
            "rating": 1235.1629857340126,
            "rating_q975": 1241.8986046978398,
            "rating_q025": 1228.4273667701855
        },
        "qwen2.5-72b-instruct": {
            "rating": 1235.124692818972,
            "rating_q975": 1241.398875227876,
            "rating_q025": 1228.8505104100682
        },
        "gemma-3-4b-it": {
            "rating": 1233.0537834452598,
            "rating_q975": 1247.1214070479652,
            "rating_q025": 1218.9861598425543
        },
        "hunyuan-large-vision": {
            "rating": 1232.8110010501955,
            "rating_q975": 1245.4630974745364,
            "rating_q025": 1220.1589046258546
        },
        "llama-3.1-nemotron-70b-instruct": {
            "rating": 1229.136153177017,
            "rating_q975": 1240.609397683572,
            "rating_q025": 1217.6629086704618
        },
        "llama-3.1-70b-instruct": {
            "rating": 1221.2778315670084,
            "rating_q975": 1227.015475643285,
            "rating_q025": 1215.5401874907318
        },
        "llama-3.1-tulu-3-70b": {
            "rating": 1211.5924150507678,
            "rating_q975": 1229.2012512619979,
            "rating_q025": 1193.9835788395378
        },
        "amazon-nova-pro-v1.0": {
            "rating": 1211.560031490248,
            "rating_q975": 1218.6136916827677,
            "rating_q025": 1204.5063712977285
        },
        "jamba-1.5-large": {
            "rating": 1211.5123711580768,
            "rating_q975": 1222.7979340317615,
            "rating_q025": 1200.226808284392
        },
        "reka-core-20240904": {
            "rating": 1210.6893516827295,
            "rating_q975": 1222.4142802663623,
            "rating_q025": 1198.9644230990966
        },
        "gemma-2-27b-it": {
            "rating": 1208.232731315622,
            "rating_q975": 1213.2500888498098,
            "rating_q025": 1203.2153737814342
        },
        "gemini-1.5-flash-001": {
            "rating": 1205.609224818671,
            "rating_q975": 1212.2649793603193,
            "rating_q025": 1198.9534702770227
        },
        "llama-3.1-nemotron-51b-instruct": {
            "rating": 1204.785616014914,
            "rating_q975": 1220.8433017899406,
            "rating_q025": 1188.7279302398874
        },
        "gpt-4-0314": {
            "rating": 1200.9401186674395,
            "rating_q975": 1207.9649852040238,
            "rating_q025": 1193.9152521308552
        },
        "claude-3-sonnet-20240229": {
            "rating": 1200.0197007171007,
            "rating_q975": 1205.7803640958093,
            "rating_q025": 1194.259037338392
        },
        "nemotron-4-340b-instruct": {
            "rating": 1197.1124356540088,
            "rating_q975": 1205.431317597772,
            "rating_q025": 1188.7935537102455
        },
        "gemma-2-9b-it-simpo": {
            "rating": 1194.1705882221763,
            "rating_q975": 1204.865691589244,
            "rating_q025": 1183.4754848551086
        },
        "llama-3-70b-instruct": {
            "rating": 1192.796015920409,
            "rating_q975": 1198.2183073356052,
            "rating_q025": 1187.3737245052127
        },
        "command-r-plus-08-2024": {
            "rating": 1190.962731538723,
            "rating_q975": 1201.2959564195387,
            "rating_q025": 1180.629506657907
        },
        "glm-4-0520": {
            "rating": 1190.8837641896114,
            "rating_q975": 1201.7897597498356,
            "rating_q025": 1179.9777686293871
        },
        "gpt-4-0613": {
            "rating": 1186.828333198618,
            "rating_q975": 1192.7277149609008,
            "rating_q025": 1180.9289514363354
        },
        "mistral-small-24b-instruct-2501": {
            "rating": 1186.2156407292277,
            "rating_q975": 1195.5128121943637,
            "rating_q025": 1176.9184692640918
        },
        "qwen2.5-coder-32b-instruct": {
            "rating": 1181.9702765917207,
            "rating_q975": 1195.4527341508713,
            "rating_q025": 1168.48781903257
        },
        "reka-flash-20240904": {
            "rating": 1178.9263013376094,
            "rating_q975": 1190.972258901202,
            "rating_q025": 1166.8803437740169
        },
        "c4ai-aya-expanse-32b": {
            "rating": 1175.1703632390918,
            "rating_q975": 1182.9206737257198,
            "rating_q025": 1167.4200527524638
        },
        "deepseek-coder-v2": {
            "rating": 1174.9747694086432,
            "rating_q975": 1184.2819262337362,
            "rating_q025": 1165.6676125835502
        },
        "command-r-plus": {
            "rating": 1172.6805030335438,
            "rating_q975": 1178.9427713907398,
            "rating_q025": 1166.4182346763478
        },
        "qwen2-72b-instruct": {
            "rating": 1171.5441468898948,
            "rating_q975": 1178.845481788997,
            "rating_q025": 1164.2428119907927
        },
        "claude-3-haiku-20240307": {
            "rating": 1171.131600207692,
            "rating_q975": 1176.8547455960756,
            "rating_q025": 1165.4084548193082
        },
        "gemma-2-9b-it": {
            "rating": 1170.3853435211768,
            "rating_q975": 1176.138155669705,
            "rating_q025": 1164.6325313726486
        },
        "gemini-1.5-flash-8b-001": {
            "rating": 1164.6226632601224,
            "rating_q975": 1171.300282207376,
            "rating_q025": 1157.9450443128687
        },
        "amazon-nova-lite-v1.0": {
            "rating": 1163.7432266727565,
            "rating_q975": 1171.902379295183,
            "rating_q025": 1155.58407405033
        },
        "olmo-2-0325-32b-instruct": {
            "rating": 1154.9760563750463,
            "rating_q975": 1172.2244912114847,
            "rating_q025": 1137.7276215386078
        },
        "phi-4": {
            "rating": 1154.9498791674246,
            "rating_q975": 1162.6444181089478,
            "rating_q025": 1147.2553402259014
        },
        "command-r-08-2024": {
            "rating": 1145.4231218897373,
            "rating_q975": 1156.1017505640448,
            "rating_q025": 1134.7444932154299
        },
        "mistral-large-2402": {
            "rating": 1141.487122465035,
            "rating_q975": 1148.3432233344483,
            "rating_q025": 1134.6310215956219
        },
        "reka-flash-21b-20240226-online": {
            "rating": 1130.4394727324893,
            "rating_q975": 1141.4978203920894,
            "rating_q025": 1119.3811250728893
        },
        "amazon-nova-micro-v1.0": {
            "rating": 1130.177883996952,
            "rating_q975": 1138.498658681342,
            "rating_q025": 1121.857109312562
        },
        "qwen1.5-110b-chat": {
            "rating": 1129.590720506858,
            "rating_q975": 1138.1848977376171,
            "rating_q025": 1120.9965432760987
        },
        "jamba-1.5-mini": {
            "rating": 1128.971086949143,
            "rating_q975": 1140.7971157000488,
            "rating_q025": 1117.1450581982372
        },
        "qwen1.5-72b-chat": {
            "rating": 1128.42889099413,
            "rating_q975": 1136.3633326667048,
            "rating_q025": 1120.494449321555
        },
        "gemini-pro-dev-api": {
            "rating": 1126.4915416360993,
            "rating_q975": 1137.2499597788328,
            "rating_q025": 1115.7331234933658
        },
        "ministral-8b-2410": {
            "rating": 1124.2887186805024,
            "rating_q975": 1139.3718591346842,
            "rating_q025": 1109.2055782263205
        },
        "hunyuan-standard-256k": {
            "rating": 1122.590659354457,
            "rating_q975": 1141.306908165138,
            "rating_q025": 1103.874410543776
        },
        "mixtral-8x22b-instruct-v0.1": {
            "rating": 1121.626828391108,
            "rating_q975": 1128.5878161537785,
            "rating_q025": 1114.6658406284373
        },
        "reka-flash-21b-20240226": {
            "rating": 1119.8733206013576,
            "rating_q975": 1129.1421696723494,
            "rating_q025": 1110.6044715303658
        },
        "command-r": {
            "rating": 1118.0482169799063,
            "rating_q975": 1125.1610348524077,
            "rating_q025": 1110.935399107405
        },
        "mistral-medium": {
            "rating": 1113.2813984236354,
            "rating_q975": 1121.3142513214386,
            "rating_q025": 1105.2485455258322
        },
        "gpt-3.5-turbo-0125": {
            "rating": 1111.27016679566,
            "rating_q975": 1118.0959921094084,
            "rating_q025": 1104.4443414819118
        },
        "llama-3-8b-instruct": {
            "rating": 1110.2320205145256,
            "rating_q975": 1116.127689004884,
            "rating_q025": 1104.3363520241674
        },
        "c4ai-aya-expanse-8b": {
            "rating": 1105.7313053387995,
            "rating_q975": 1117.3710846411846,
            "rating_q025": 1094.0915260364145
        },
        "gemini-pro": {
            "rating": 1102.71922408708,
            "rating_q975": 1119.5066951630308,
            "rating_q025": 1085.931753011129
        },
        "llama-3.1-tulu-3-8b": {
            "rating": 1100.9799626696495,
            "rating_q975": 1120.3208368782136,
            "rating_q025": 1081.6390884610853
        },
        "zephyr-orpo-141b-A35b-v0.1": {
            "rating": 1099.5706133200924,
            "rating_q975": 1115.3632156040549,
            "rating_q025": 1083.77801103613
        },
        "yi-1.5-34b-chat": {
            "rating": 1098.034419306457,
            "rating_q975": 1106.2503161894263,
            "rating_q025": 1089.8185224234878
        },
        "llama-3.1-8b-instruct": {
            "rating": 1087.7440911875253,
            "rating_q975": 1094.27008159398,
            "rating_q025": 1081.2181007810707
        },
        "qwen1.5-32b-chat": {
            "rating": 1085.9554699208086,
            "rating_q975": 1095.3821451277395,
            "rating_q025": 1076.5287947138777
        },
        "gpt-3.5-turbo-1106": {
            "rating": 1078.9639581107301,
            "rating_q975": 1091.2967091004182,
            "rating_q025": 1066.631207121042
        },
        "granite-3.1-8b-instruct": {
            "rating": 1076.4472278675853,
            "rating_q975": 1096.3239356623305,
            "rating_q025": 1056.57052007284
        },
        "mixtral-8x7b-instruct-v0.1": {
            "rating": 1071.8155720895797,
            "rating_q975": 1078.2789131554184,
            "rating_q025": 1065.352231023741
        },
        "dbrx-instruct-preview": {
            "rating": 1069.0597068425466,
            "rating_q975": 1078.3605668878895,
            "rating_q025": 1059.7588467972037
        },
        "qwen1.5-14b-chat": {
            "rating": 1068.1001499732538,
            "rating_q975": 1079.0427465812595,
            "rating_q025": 1057.157553365248
        },
        "phi-3-medium-4k-instruct": {
            "rating": 1065.4696430970273,
            "rating_q975": 1074.0013489840003,
            "rating_q025": 1056.9379372100543
        },
        "gemma-2-2b-it": {
            "rating": 1061.1781280665034,
            "rating_q975": 1067.80575237024,
            "rating_q025": 1054.5505037627668
        },
        "wizardlm-70b": {
            "rating": 1058.965209150907,
            "rating_q975": 1072.2301272286707,
            "rating_q025": 1045.7002910731433
        },
        "internlm2_5-20b-chat": {
            "rating": 1055.7831461838691,
            "rating_q975": 1068.0384372784522,
            "rating_q025": 1043.527855089286
        },
        "deepseek-llm-67b-chat": {
            "rating": 1054.7253271802397,
            "rating_q975": 1071.5276168335113,
            "rating_q025": 1037.923037526968
        },
        "yi-34b-chat": {
            "rating": 1052.8085930577654,
            "rating_q975": 1062.8631793052264,
            "rating_q025": 1042.7540068103044
        },
        "openchat-3.5-0106": {
            "rating": 1052.111973255835,
            "rating_q975": 1063.8276475394325,
            "rating_q025": 1040.3962989722374
        },
        "openchat-3.5": {
            "rating": 1048.9532524466117,
            "rating_q975": 1063.024032976553,
            "rating_q025": 1034.8824719166705
        },
        "tulu-2-dpo-70b": {
            "rating": 1045.2245222303332,
            "rating_q975": 1059.330131956667,
            "rating_q025": 1031.1189125039994
        },
        "starling-lm-7b-beta": {
            "rating": 1041.9411321529205,
            "rating_q975": 1052.8884768216606,
            "rating_q025": 1030.9937874841805
        },
        "openhermes-2.5-mistral-7b": {
            "rating": 1040.8679539527143,
            "rating_q975": 1056.1789004529564,
            "rating_q025": 1025.5570074524721
        },
        "snowflake-arctic-instruct": {
            "rating": 1040.2771393097094,
            "rating_q975": 1049.8503498175014,
            "rating_q025": 1030.7039288019173
        },
        "vicuna-33b": {
            "rating": 1040.251953273216,
            "rating_q975": 1049.5180193322167,
            "rating_q025": 1030.9858872142154
        },
        "gemma-1.1-7b-it": {
            "rating": 1037.7163999265345,
            "rating_q975": 1046.782202775014,
            "rating_q025": 1028.650597078055
        },
        "llama-2-70b-chat": {
            "rating": 1033.0909785719866,
            "rating_q975": 1041.203933776069,
            "rating_q025": 1024.9780233679041
        },
        "granite-3.0-8b-instruct": {
            "rating": 1032.9834565277847,
            "rating_q975": 1049.1429878062131,
            "rating_q025": 1016.8239252493562
        },
        "starling-lm-7b-alpha": {
            "rating": 1029.3688468419857,
            "rating_q975": 1041.2490293518883,
            "rating_q025": 1017.4886643320832
        },
        "nous-hermes-2-mixtral-8x7b-dpo": {
            "rating": 1026.0408447991615,
            "rating_q975": 1043.2426237373315,
            "rating_q025": 1008.8390658609914
        },
        "phi-3-small-8k-instruct": {
            "rating": 1022.7835933812194,
            "rating_q975": 1033.2011151785675,
            "rating_q025": 1012.3660715838713
        },
        "granite-3.1-2b-instruct": {
            "rating": 1020.8916497377575,
            "rating_q975": 1042.1488934587817,
            "rating_q025": 999.6344060167334
        },
        "qwq-32b-preview": {
            "rating": 1016.4096155328988,
            "rating_q975": 1034.9948577769228,
            "rating_q025": 997.8243732888748
        },
        "mpt-30b-chat": {
            "rating": 1012.8607241040703,
            "rating_q975": 1031.0123094166934,
            "rating_q025": 994.7091387914472
        },
        "llama2-70b-steerlm-chat": {
            "rating": 1012.0565005456349,
            "rating_q975": 1029.7544706961637,
            "rating_q025": 994.3585303951061
        },
        "llama-3.2-3b-instruct": {
            "rating": 1008.9126082288219,
            "rating_q975": 1022.5676395256983,
            "rating_q025": 995.2575769319456
        },
        "wizardlm-13b": {
            "rating": 1008.0388570599359,
            "rating_q975": 1021.4813387600998,
            "rating_q025": 994.5963753597721
        },
        "solar-10.7b-instruct-v1.0": {
            "rating": 1007.1557402859247,
            "rating_q975": 1026.347692657003,
            "rating_q025": 987.9637879148463
        },
        "dolphin-2.2.1-mistral-7b": {
            "rating": 1005.8077295862139,
            "rating_q975": 1028.3034622260932,
            "rating_q025": 983.3119969463345
        },
        "mistral-7b-instruct-v0.2": {
            "rating": 1000.91763673611,
            "rating_q975": 1011.0717143215727,
            "rating_q025": 990.7635591506473
        },
        "falcon-180b-chat": {
            "rating": 1000.5294760357237,
            "rating_q975": 1024.5901361459623,
            "rating_q025": 976.4688159254853
        },
        "qwen1.5-7b-chat": {
            "rating": 993.3580455731328,
            "rating_q975": 1008.8575122172089,
            "rating_q025": 977.8585789290568
        },
        "qwen-14b-chat": {
            "rating": 989.8914686133644,
            "rating_q975": 1005.7084591662174,
            "rating_q025": 974.0744780605114
        },
        "llama-2-13b-chat": {
            "rating": 989.5320716014621,
            "rating_q975": 999.5420846824329,
            "rating_q025": 979.5220585204913
        },
        "vicuna-13b": {
            "rating": 987.0697148590016,
            "rating_q975": 997.1605076053366,
            "rating_q025": 976.9789221126665
        },
        "palm-2": {
            "rating": 985.3999372546039,
            "rating_q975": 998.5848825996044,
            "rating_q025": 972.2149919096033
        },
        "codellama-34b-instruct": {
            "rating": 982.3369576008529,
            "rating_q975": 995.2778816825424,
            "rating_q025": 969.3960335191633
        },
        "granite-3.0-2b-instruct": {
            "rating": 980.6678769293558,
            "rating_q975": 997.8247381606483,
            "rating_q025": 963.5110156980633
        },
        "guanaco-33b": {
            "rating": 975.725993331585,
            "rating_q975": 993.853569338523,
            "rating_q025": 957.5984173246469
        },
        "zephyr-7b-beta": {
            "rating": 974.6026236617932,
            "rating_q975": 987.2080323300654,
            "rating_q025": 961.9972149935211
        },
        "zephyr-7b-alpha": {
            "rating": 973.6510369059474,
            "rating_q975": 996.1964554633089,
            "rating_q025": 951.105618348586
        },
        "gemma-7b-it": {
            "rating": 972.5465079204852,
            "rating_q975": 986.8513731559102,
            "rating_q025": 958.2416426850601
        },
        "phi-3-mini-4k-instruct-june-2024": {
            "rating": 963.2813631424227,
            "rating_q975": 975.596547729637,
            "rating_q025": 950.9661785552084
        },
        "vicuna-7b": {
            "rating": 959.4766631036166,
            "rating_q975": 972.9029184570518,
            "rating_q025": 946.0504077501814
        },
        "phi-3-mini-128k-instruct": {
            "rating": 958.614957496904,
            "rating_q975": 971.5403274147429,
            "rating_q025": 945.6895875790651
        },
        "codellama-70b-instruct": {
            "rating": 958.3224795069603,
            "rating_q975": 986.4810246459515,
            "rating_q025": 930.1639343679692
        },
        "stripedhyena-nous-7b": {
            "rating": 957.1960327711904,
            "rating_q975": 973.8778595034598,
            "rating_q025": 940.514206038921
        },
        "phi-3-mini-4k-instruct": {
            "rating": 950.0835275487952,
            "rating_q975": 961.5277760545143,
            "rating_q025": 938.6392790430762
        },
        "mistral-7b-instruct": {
            "rating": 941.0586316050897,
            "rating_q975": 954.8385338483675,
            "rating_q025": 927.2787293618118
        },
        "llama-2-7b-chat": {
            "rating": 937.882003764842,
            "rating_q975": 948.3785787328153,
            "rating_q025": 927.3854287968687
        },
        "gemma-1.1-2b-it": {
            "rating": 923.3444537843206,
            "rating_q975": 936.8758976943716,
            "rating_q025": 909.8130098742697
        },
        "smollm2-1.7b-instruct": {
            "rating": 908.7130273038931,
            "rating_q975": 940.3026482101974,
            "rating_q025": 877.1234063975888
        },
        "gemma-2b-it": {
            "rating": 901.5593388619837,
            "rating_q975": 919.7102855261224,
            "rating_q025": 883.408392197845
        },
        "llama-3.2-1b-instruct": {
            "rating": 899.9361894983708,
            "rating_q975": 915.9542905667214,
            "rating_q025": 883.9180884300202
        },
        "qwen1.5-4b-chat": {
            "rating": 897.0343767777448,
            "rating_q975": 912.9841698804538,
            "rating_q025": 881.0845836750358
        },
        "koala-13b": {
            "rating": 895.6050196010533,
            "rating_q975": 911.0900123580974,
            "rating_q025": 880.1200268440092
        },
        "alpaca-13b": {
            "rating": 887.9761755379352,
            "rating_q975": 905.1062990337578,
            "rating_q025": 870.8460520421127
        },
        "olmo-7b-instruct": {
            "rating": 885.6623139145795,
            "rating_q975": 903.3371875140587,
            "rating_q025": 867.9874403151003
        },
        "gpt4all-13b-snoozy": {
            "rating": 884.2437503895578,
            "rating_q975": 908.171761798369,
            "rating_q025": 860.3157389807467
        },
        "mpt-7b-chat": {
            "rating": 877.2007583914973,
            "rating_q975": 895.5790257385991,
            "rating_q025": 858.8224910443955
        },
        "chatglm3-6b": {
            "rating": 862.3598831386595,
            "rating_q975": 880.7262342235595,
            "rating_q025": 843.9935320537595
        },
        "RWKV-4-Raven-14B": {
            "rating": 850.703609012396,
            "rating_q975": 868.1959053191437,
            "rating_q025": 833.2113127056483
        },
        "oasst-pythia-12b": {
            "rating": 821.6932248902904,
            "rating_q975": 838.388351995014,
            "rating_q025": 804.9980977855668
        },
        "chatglm2-6b": {
            "rating": 805.1845431309063,
            "rating_q975": 827.1221027517951,
            "rating_q025": 783.2469835100175
        },
        "fastchat-t5-3b": {
            "rating": 767.317018248822,
            "rating_q975": 786.6550697476991,
            "rating_q025": 747.9789667499449
        },
        "chatglm-6b": {
            "rating": 767.2673000553885,
            "rating_q975": 786.9884449627035,
            "rating_q025": 747.5461551480736
        },
        "dolly-v2-12b": {
            "rating": 748.2429764245428,
            "rating_q975": 770.4042117664196,
            "rating_q025": 726.081741082666
        },
        "llama-13b": {
            "rating": 721.471071863321,
            "rating_q975": 747.5468162235928,
            "rating_q025": 695.3953275030491
        },
        "stablelm-tuned-alpha-7b": {
            "rating": 701.2806897470874,
            "rating_q975": 722.833606766142,
            "rating_q025": 679.7277727280328
        }
    },
    "russian": {
        "gemini-2.5-pro": {
            "rating": 1460.8301623488233,
            "rating_q975": 1471.667653622517,
            "rating_q025": 1449.9926710751295
        },
        "claude-sonnet-4-5-20250929": {
            "rating": 1449.8631939112793,
            "rating_q975": 1480.5233801064048,
            "rating_q025": 1419.2030077161537
        },
        "claude-opus-4-1-20250805": {
            "rating": 1447.172549896801,
            "rating_q975": 1460.0842304445946,
            "rating_q025": 1434.2608693490074
        },
        "gpt-4.5-preview-2025-02-27": {
            "rating": 1441.3851841170317,
            "rating_q975": 1456.5719934123365,
            "rating_q025": 1426.198374821727
        },
        "claude-opus-4-1-20250805-thinking-16k": {
            "rating": 1440.7899651141752,
            "rating_q975": 1456.3616883794775,
            "rating_q025": 1425.2182418488728
        },
        "chatgpt-4o-latest-20250326": {
            "rating": 1435.2426758659465,
            "rating_q975": 1446.0519033717678,
            "rating_q025": 1424.433448360125
        },
        "gpt-5-high": {
            "rating": 1435.225365393712,
            "rating_q975": 1451.1728501041268,
            "rating_q025": 1419.2778806832973
        },
        "qwen3-max-2025-09-23": {
            "rating": 1433.2023177096507,
            "rating_q975": 1457.1167128134,
            "rating_q025": 1409.2879226059015
        },
        "claude-opus-4-20250514-thinking-16k": {
            "rating": 1432.612729242066,
            "rating_q975": 1445.312085968128,
            "rating_q025": 1419.913372516004
        },
        "o3-2025-04-16": {
            "rating": 1431.8697745611244,
            "rating_q975": 1441.9978490788724,
            "rating_q025": 1421.7417000433763
        },
        "gpt-5-chat": {
            "rating": 1428.3715654165565,
            "rating_q975": 1444.1955377130607,
            "rating_q025": 1412.5475931200522
        },
        "deepseek-v3.1-terminus": {
            "rating": 1425.9746199803087,
            "rating_q975": 1459.9012773979039,
            "rating_q025": 1392.0479625627136
        },
        "claude-opus-4-20250514": {
            "rating": 1424.0663890682704,
            "rating_q975": 1435.430045209946,
            "rating_q025": 1412.7027329265948
        },
        "deepseek-v3.1-terminus-thinking": {
            "rating": 1422.259513620204,
            "rating_q975": 1458.1443685574113,
            "rating_q025": 1386.3746586829966
        },
        "grok-4-0709": {
            "rating": 1420.3864178351814,
            "rating_q975": 1434.3286819671482,
            "rating_q025": 1406.4441537032146
        },
        "qwen3-max-preview": {
            "rating": 1414.9214908322342,
            "rating_q975": 1432.1347893029251,
            "rating_q025": 1397.7081923615433
        },
        "claude-sonnet-4-5-20250929-thinking-32k": {
            "rating": 1414.8465520663237,
            "rating_q975": 1436.7872782820468,
            "rating_q025": 1392.9058258506006
        },
        "kimi-k2-0905-preview": {
            "rating": 1414.2596759147527,
            "rating_q975": 1438.3338142055172,
            "rating_q025": 1390.1855376239882
        },
        "gemini-2.5-flash": {
            "rating": 1413.9559602080164,
            "rating_q975": 1424.131118108832,
            "rating_q025": 1403.780802307201
        },
        "qwen3-235b-a22b-instruct-2507": {
            "rating": 1412.0396949352744,
            "rating_q975": 1425.3010854228985,
            "rating_q025": 1398.7783044476503
        },
        "gemini-2.5-flash-preview-09-2025": {
            "rating": 1410.2095490276206,
            "rating_q975": 1431.6324020247446,
            "rating_q025": 1388.7866960304966
        },
        "deepseek-r1-0528": {
            "rating": 1409.4236926384083,
            "rating_q975": 1425.8078913588718,
            "rating_q025": 1393.0394939179448
        },
        "grok-3-preview-02-24": {
            "rating": 1407.946822864771,
            "rating_q975": 1419.5207226072403,
            "rating_q025": 1396.372923122302
        },
        "deepseek-v3.1": {
            "rating": 1406.3154904589528,
            "rating_q975": 1427.2007674491965,
            "rating_q025": 1385.430213468709
        },
        "qwen3-235b-a22b-thinking-2507": {
            "rating": 1405.8022167320676,
            "rating_q975": 1432.800298214195,
            "rating_q025": 1378.8041352499401
        },
        "claude-sonnet-4-20250514-thinking-32k": {
            "rating": 1404.3132181843132,
            "rating_q975": 1417.5979266530323,
            "rating_q025": 1391.028509715594
        },
        "kimi-k2-0711-preview": {
            "rating": 1404.132874260418,
            "rating_q975": 1418.955977854918,
            "rating_q025": 1389.309770665918
        },
        "gpt-4.1-2025-04-14": {
            "rating": 1403.8504274453096,
            "rating_q975": 1414.7281795711203,
            "rating_q025": 1392.9726753194989
        },
        "deepseek-v3.2-exp-thinking": {
            "rating": 1401.4339827770536,
            "rating_q975": 1426.4431142003525,
            "rating_q025": 1376.4248513537548
        },
        "mistral-medium-2508": {
            "rating": 1401.2027360604657,
            "rating_q975": 1416.2694165068312,
            "rating_q025": 1386.1360556141
        },
        "deepseek-v3.1-thinking": {
            "rating": 1401.0478619813798,
            "rating_q975": 1423.7005222726066,
            "rating_q025": 1378.395201690153
        },
        "qwen3-235b-a22b-no-thinking": {
            "rating": 1398.856913039054,
            "rating_q975": 1410.9506737436084,
            "rating_q025": 1386.7631523344996
        },
        "glm-4.6": {
            "rating": 1398.3165864797243,
            "rating_q975": 1423.4680692086831,
            "rating_q025": 1373.1651037507654
        },
        "grok-4-fast": {
            "rating": 1397.2011324552955,
            "rating_q975": 1425.1055762230244,
            "rating_q025": 1369.2966886875665
        },
        "qwen3-vl-235b-a22b-instruct": {
            "rating": 1390.9865066557886,
            "rating_q975": 1415.9119494083247,
            "rating_q025": 1366.0610639032525
        },
        "deepseek-v3-0324": {
            "rating": 1390.6757033386161,
            "rating_q975": 1401.066795914227,
            "rating_q025": 1380.2846107630053
        },
        "glm-4.5": {
            "rating": 1390.6316319801508,
            "rating_q975": 1407.0335809459864,
            "rating_q025": 1374.2296830143152
        },
        "claude-sonnet-4-20250514": {
            "rating": 1388.9566127651776,
            "rating_q975": 1400.6351928029846,
            "rating_q025": 1377.2780327273706
        },
        "qwen3-next-80b-a3b-instruct": {
            "rating": 1388.3881491771308,
            "rating_q975": 1406.6738192094128,
            "rating_q025": 1370.1024791448488
        },
        "claude-haiku-4-5-20251001": {
            "rating": 1387.8002032769919,
            "rating_q975": 1415.9605030479652,
            "rating_q025": 1359.6399035060185
        },
        "o1-2024-12-17": {
            "rating": 1383.5649389718687,
            "rating_q975": 1393.5849595953393,
            "rating_q025": 1373.5449183483981
        },
        "gpt-5-mini-high": {
            "rating": 1382.8499448380348,
            "rating_q975": 1399.5892378988901,
            "rating_q025": 1366.1106517771796
        },
        "mai-1-preview": {
            "rating": 1380.6323976939768,
            "rating_q975": 1399.1760601027077,
            "rating_q025": 1362.088735285246
        },
        "qwen3-coder-480b-a35b-instruct": {
            "rating": 1378.903947136318,
            "rating_q975": 1395.3932675108013,
            "rating_q025": 1362.4146267618348
        },
        "gemini-2.5-flash-lite-preview-06-17-thinking": {
            "rating": 1378.3848535847837,
            "rating_q975": 1391.9266713482964,
            "rating_q025": 1364.843035821271
        },
        "deepseek-r1": {
            "rating": 1375.44706993129,
            "rating_q975": 1387.9976014775102,
            "rating_q025": 1362.8965383850696
        },
        "hunyuan-turbos-20250416": {
            "rating": 1375.3590461003766,
            "rating_q975": 1393.4942716233072,
            "rating_q025": 1357.223820577446
        },
        "mistral-medium-2505": {
            "rating": 1375.2947060232254,
            "rating_q975": 1387.144924881194,
            "rating_q025": 1363.444487165257
        },
        "gemini-2.5-flash-lite-preview-09-2025-no-thinking": {
            "rating": 1373.2965845420329,
            "rating_q975": 1395.6301687215805,
            "rating_q025": 1350.9630003624852
        },
        "hunyuan-t1-20250711": {
            "rating": 1372.6016454880596,
            "rating_q975": 1407.1711016468362,
            "rating_q025": 1338.032189329283
        },
        "o4-mini-2025-04-16": {
            "rating": 1372.1027070607252,
            "rating_q975": 1382.972541513584,
            "rating_q025": 1361.2328726078663
        },
        "claude-3-7-sonnet-20250219-thinking-32k": {
            "rating": 1371.0541891287664,
            "rating_q975": 1381.7616501681518,
            "rating_q025": 1360.346728089381
        },
        "claude-3-5-sonnet-20241022": {
            "rating": 1370.622986446766,
            "rating_q975": 1376.9415029296974,
            "rating_q025": 1364.3044699638344
        },
        "qwen3-vl-235b-a22b-thinking": {
            "rating": 1368.914095462976,
            "rating_q975": 1394.8443034944646,
            "rating_q025": 1342.9838874314876
        },
        "qwen3-30b-a3b-instruct-2507": {
            "rating": 1368.550183949748,
            "rating_q975": 1385.2508903157675,
            "rating_q025": 1351.8494775837287
        },
        "gemma-3-27b-it": {
            "rating": 1367.3973719030544,
            "rating_q975": 1377.8156986774568,
            "rating_q025": 1356.979045128652
        },
        "longcat-flash-chat": {
            "rating": 1363.861919563685,
            "rating_q975": 1385.5624929882263,
            "rating_q025": 1342.1613461391437
        },
        "glm-4.5-air": {
            "rating": 1362.6099186703213,
            "rating_q975": 1378.5587783675496,
            "rating_q025": 1346.661058973093
        },
        "qwen2.5-max": {
            "rating": 1362.2951249938358,
            "rating_q975": 1372.7173006487603,
            "rating_q025": 1351.8729493389112
        },
        "gemma-3-12b-it": {
            "rating": 1357.6345799549633,
            "rating_q975": 1389.4051317496724,
            "rating_q025": 1325.8640281602543
        },
        "gpt-4.1-mini-2025-04-14": {
            "rating": 1357.2485283541428,
            "rating_q975": 1368.7747159488654,
            "rating_q025": 1345.7223407594201
        },
        "o1-preview": {
            "rating": 1356.205866755555,
            "rating_q975": 1365.2577167286722,
            "rating_q025": 1347.1540167824378
        },
        "qwen3-235b-a22b": {
            "rating": 1352.958096691369,
            "rating_q975": 1366.025542464341,
            "rating_q025": 1339.8906509183971
        },
        "qwen3-next-80b-a3b-thinking": {
            "rating": 1351.4963161574358,
            "rating_q975": 1371.9725084951328,
            "rating_q025": 1331.0201238197387
        },
        "deepseek-v3": {
            "rating": 1351.3311310525276,
            "rating_q975": 1362.2889247796663,
            "rating_q025": 1340.3733373253888
        },
        "gemini-2.0-flash-lite-preview-02-05": {
            "rating": 1349.6111041015436,
            "rating_q975": 1360.9156074524735,
            "rating_q025": 1338.3066007506136
        },
        "qwen-plus-0125": {
            "rating": 1349.1550224332284,
            "rating_q975": 1370.9392670708287,
            "rating_q025": 1327.370777795628
        },
        "gemini-1.5-pro-002": {
            "rating": 1348.8618889145773,
            "rating_q975": 1355.8452523373278,
            "rating_q025": 1341.8785254918268
        },
        "grok-3-mini-beta": {
            "rating": 1347.064972057617,
            "rating_q975": 1362.5795680035246,
            "rating_q025": 1331.5503761117095
        },
        "mistral-small-2506": {
            "rating": 1345.894863386297,
            "rating_q975": 1363.7750657760207,
            "rating_q025": 1328.0146609965732
        },
        "grok-3-mini-high": {
            "rating": 1345.340062694018,
            "rating_q975": 1363.6657647874538,
            "rating_q025": 1327.014360600582
        },
        "amazon-nova-experimental-chat-10-09": {
            "rating": 1343.4653769204556,
            "rating_q975": 1383.3888691413651,
            "rating_q025": 1303.541884699546
        },
        "claude-3-5-sonnet-20240620": {
            "rating": 1341.2207038109723,
            "rating_q975": 1348.5955303203812,
            "rating_q025": 1333.8458773015634
        },
        "minimax-m1": {
            "rating": 1340.8592269038184,
            "rating_q975": 1354.144876930314,
            "rating_q025": 1327.5735768773227
        },
        "command-a-03-2025": {
            "rating": 1337.3298610936963,
            "rating_q975": 1347.1849777783368,
            "rating_q025": 1327.4747444090558
        },
        "step-2-16k-exp-202412": {
            "rating": 1337.1248861449994,
            "rating_q975": 1358.7396846488432,
            "rating_q025": 1315.5100876411557
        },
        "hunyuan-turbos-20250226": {
            "rating": 1334.9907355994196,
            "rating_q975": 1370.308897295503,
            "rating_q025": 1299.6725739033363
        },
        "gpt-oss-120b": {
            "rating": 1334.6681829725167,
            "rating_q975": 1350.131630455944,
            "rating_q025": 1319.2047354890892
        },
        "claude-3-opus-20240229": {
            "rating": 1332.1666804758108,
            "rating_q975": 1338.2878402942304,
            "rating_q025": 1326.0455206573913
        },
        "llama-4-maverick-17b-128e-instruct": {
            "rating": 1331.8337268489558,
            "rating_q975": 1343.079911584611,
            "rating_q025": 1320.5875421133007
        },
        "hunyuan-turbo-0110": {
            "rating": 1329.0610152617871,
            "rating_q975": 1361.1127436946529,
            "rating_q025": 1297.0092868289214
        },
        "gpt-4o-2024-05-13": {
            "rating": 1328.1055095112577,
            "rating_q975": 1334.7077000940458,
            "rating_q025": 1321.5033189284695
        },
        "gemini-advanced-0514": {
            "rating": 1328.1006096978626,
            "rating_q975": 1337.9513935194173,
            "rating_q025": 1318.249825876308
        },
        "glm-4-plus-0111": {
            "rating": 1328.0051195478961,
            "rating_q975": 1349.5344626035258,
            "rating_q025": 1306.4757764922665
        },
        "o3-mini-high": {
            "rating": 1326.9814646475247,
            "rating_q975": 1340.0571397294054,
            "rating_q025": 1313.905789565644
        },
        "step-1o-turbo-202506": {
            "rating": 1324.793966449065,
            "rating_q975": 1348.4213031749857,
            "rating_q025": 1301.1666297231443
        },
        "o3-mini": {
            "rating": 1324.3755483413522,
            "rating_q975": 1332.923160514853,
            "rating_q025": 1315.8279361678515
        },
        "qwen3-32b": {
            "rating": 1321.9521075235975,
            "rating_q975": 1347.7786159016155,
            "rating_q025": 1296.1255991455796
        },
        "gemini-1.5-pro-001": {
            "rating": 1321.7967648748727,
            "rating_q975": 1329.8139822674846,
            "rating_q025": 1313.7795474822608
        },
        "grok-2-2024-08-13": {
            "rating": 1321.4565322632338,
            "rating_q975": 1328.3427988198214,
            "rating_q025": 1314.5702657066463
        },
        "gpt-4o-2024-08-06": {
            "rating": 1320.223443054452,
            "rating_q975": 1328.3164222139326,
            "rating_q025": 1312.1304638949714
        },
        "step-3": {
            "rating": 1319.960755906419,
            "rating_q975": 1348.6298843474408,
            "rating_q025": 1291.2916274653974
        },
        "deepseek-v2.5-1210": {
            "rating": 1317.295226560027,
            "rating_q975": 1334.1698418239607,
            "rating_q025": 1300.4206112960933
        },
        "gpt-5-nano-high": {
            "rating": 1315.3805746585126,
            "rating_q975": 1341.8204164808583,
            "rating_q025": 1288.940732836167
        },
        "glm-4.5v": {
            "rating": 1313.91802141767,
            "rating_q975": 1345.05181837568,
            "rating_q025": 1282.7842244596598
        },
        "claude-3-5-haiku-20241022": {
            "rating": 1313.3830903269295,
            "rating_q975": 1320.8137412259296,
            "rating_q025": 1305.9524394279294
        },
        "gemma-3-4b-it": {
            "rating": 1313.1053424023942,
            "rating_q975": 1343.5233433705337,
            "rating_q025": 1282.6873414342547
        },
        "llama-3.1-405b-instruct-fp8": {
            "rating": 1312.7872404955974,
            "rating_q975": 1319.9837095758915,
            "rating_q025": 1305.5907714153034
        },
        "llama-4-scout-17b-16e-instruct": {
            "rating": 1310.4746246713457,
            "rating_q975": 1324.0033717801502,
            "rating_q025": 1296.9458775625412
        },
        "gpt-4-turbo-2024-04-09": {
            "rating": 1309.9141110688433,
            "rating_q975": 1317.5173845842673,
            "rating_q025": 1302.3108375534193
        },
        "llama-3.1-nemotron-ultra-253b-v1": {
            "rating": 1309.6643644965498,
            "rating_q975": 1339.539330272213,
            "rating_q025": 1279.7893987208865
        },
        "gemma-3n-e4b-it": {
            "rating": 1307.1781901571799,
            "rating_q975": 1322.4917658009595,
            "rating_q025": 1291.8646145134003
        },
        "gemini-1.5-flash-002": {
            "rating": 1307.010761367834,
            "rating_q975": 1315.2307961825127,
            "rating_q025": 1298.7907265531553
        },
        "qwen-max-0919": {
            "rating": 1306.890290348261,
            "rating_q975": 1318.1769291433043,
            "rating_q025": 1295.6036515532178
        },
        "o1-mini": {
            "rating": 1305.4367296614867,
            "rating_q975": 1312.6281149879958,
            "rating_q025": 1298.2453443349775
        },
        "qwen3-30b-a3b": {
            "rating": 1305.2831120676647,
            "rating_q975": 1318.4210729115857,
            "rating_q025": 1292.1451512237436
        },
        "llama-3.1-405b-instruct-bf16": {
            "rating": 1304.3882196481925,
            "rating_q975": 1312.4741794615113,
            "rating_q025": 1296.3022598348737
        },
        "gpt-4o-mini-2024-07-18": {
            "rating": 1303.5338064051919,
            "rating_q975": 1310.2352825290168,
            "rating_q025": 1296.832330281367
        },
        "glm-4-plus": {
            "rating": 1303.0997413067603,
            "rating_q975": 1312.6173932448673,
            "rating_q025": 1293.5820893686532
        },
        "qwq-32b": {
            "rating": 1302.4645188982972,
            "rating_q975": 1315.5923641456106,
            "rating_q025": 1289.3366736509838
        },
        "mistral-large-2407": {
            "rating": 1300.3086651093618,
            "rating_q975": 1308.3803107314652,
            "rating_q025": 1292.2370194872583
        },
        "athene-v2-chat": {
            "rating": 1300.118606515909,
            "rating_q975": 1309.600552678523,
            "rating_q025": 1290.6366603532952
        },
        "gpt-oss-20b": {
            "rating": 1299.7662475923867,
            "rating_q975": 1323.5876749927158,
            "rating_q025": 1275.9448201920575
        },
        "hunyuan-large-2025-02-10": {
            "rating": 1298.954752690067,
            "rating_q975": 1327.600266960656,
            "rating_q025": 1270.3092384194779
        },
        "gpt-4-1106-preview": {
            "rating": 1298.197537863316,
            "rating_q975": 1306.7024771268814,
            "rating_q025": 1289.6925985997507
        },
        "gpt-4.1-nano-2025-04-14": {
            "rating": 1297.0593614403817,
            "rating_q975": 1317.9427153435656,
            "rating_q025": 1276.1760075371978
        },
        "mistral-small-3.1-24b-instruct-2503": {
            "rating": 1294.06512726337,
            "rating_q975": 1307.1907453203626,
            "rating_q025": 1280.9395092063774
        },
        "qwen2.5-plus-1127": {
            "rating": 1293.6866027626113,
            "rating_q975": 1308.48391251123,
            "rating_q025": 1278.8892930139925
        },
        "grok-2-mini-2024-08-13": {
            "rating": 1293.2870378647092,
            "rating_q975": 1300.5106737759643,
            "rating_q025": 1286.063401953454
        },
        "gpt-4-0125-preview": {
            "rating": 1292.479582982207,
            "rating_q975": 1300.6456604431542,
            "rating_q025": 1284.3135055212597
        },
        "reka-core-20240904": {
            "rating": 1291.5536472822096,
            "rating_q975": 1309.0785547138782,
            "rating_q025": 1274.028739850541
        },
        "qwen2.5-72b-instruct": {
            "rating": 1291.5026009515186,
            "rating_q975": 1299.2943877892037,
            "rating_q025": 1283.7108141138335
        },
        "mistral-large-2411": {
            "rating": 1291.4874428752214,
            "rating_q975": 1301.0586844588347,
            "rating_q025": 1281.916201291608
        },
        "hunyuan-standard-2025-02-10": {
            "rating": 1290.7626390077467,
            "rating_q975": 1317.8299848345769,
            "rating_q025": 1263.6952931809165
        },
        "llama-3.3-70b-instruct": {
            "rating": 1290.1904465855646,
            "rating_q975": 1297.8137058843706,
            "rating_q025": 1282.5671872867586
        },
        "gemma-2-27b-it": {
            "rating": 1285.1064154961673,
            "rating_q975": 1291.5309162722947,
            "rating_q025": 1278.68191472004
        },
        "deepseek-v2.5": {
            "rating": 1284.9127088226762,
            "rating_q975": 1294.5958561718987,
            "rating_q025": 1275.2295614734537
        },
        "athene-70b-0725": {
            "rating": 1283.884526979159,
            "rating_q975": 1296.5257937634033,
            "rating_q025": 1271.243260194915
        },
        "claude-3-sonnet-20240229": {
            "rating": 1283.3487101448036,
            "rating_q975": 1291.8574854645694,
            "rating_q025": 1274.8399348250377
        },
        "yi-lightning": {
            "rating": 1283.1532526715932,
            "rating_q975": 1292.5480812189203,
            "rating_q025": 1273.7584241242662
        },
        "llama-3.3-nemotron-49b-super-v1": {
            "rating": 1282.6376631530507,
            "rating_q975": 1316.820776587056,
            "rating_q025": 1248.4545497190454
        },
        "ling-flash-2.0": {
            "rating": 1282.3115897418138,
            "rating_q975": 1312.4123039469769,
            "rating_q025": 1252.2108755366507
        },
        "gemini-1.5-flash-001": {
            "rating": 1280.9317430071815,
            "rating_q975": 1289.3514948328334,
            "rating_q025": 1272.5119911815295
        },
        "hunyuan-large-vision": {
            "rating": 1277.362442121552,
            "rating_q975": 1307.9145433503156,
            "rating_q025": 1246.8103408927884
        },
        "llama-3.1-tulu-3-70b": {
            "rating": 1275.523933859188,
            "rating_q975": 1302.33275044334,
            "rating_q025": 1248.715117275036
        },
        "amazon-nova-pro-v1.0": {
            "rating": 1274.0505332514836,
            "rating_q975": 1283.9495797680127,
            "rating_q025": 1264.1514867349545
        },
        "nemotron-4-340b-instruct": {
            "rating": 1270.662978091854,
            "rating_q975": 1282.7715325849983,
            "rating_q025": 1258.5544235987097
        },
        "command-r-plus-08-2024": {
            "rating": 1269.5966030854759,
            "rating_q975": 1284.199394620758,
            "rating_q025": 1254.9938115501936
        },
        "llama-3.1-70b-instruct": {
            "rating": 1267.7151603735433,
            "rating_q975": 1275.0387978987076,
            "rating_q025": 1260.391522848379
        },
        "gemma-2-9b-it-simpo": {
            "rating": 1267.6801216454755,
            "rating_q975": 1284.2249157163833,
            "rating_q025": 1251.1353275745678
        },
        "magistral-medium-2506": {
            "rating": 1266.7772321267082,
            "rating_q975": 1288.1362864104356,
            "rating_q025": 1245.4181778429809
        },
        "qwen2.5-coder-32b-instruct": {
            "rating": 1266.1284547664536,
            "rating_q975": 1284.4433798967202,
            "rating_q025": 1247.813529636187
        },
        "gpt-4-0314": {
            "rating": 1265.396041769894,
            "rating_q975": 1277.0235816205536,
            "rating_q025": 1253.7685019192345
        },
        "claude-3-haiku-20240307": {
            "rating": 1265.144950104279,
            "rating_q975": 1272.6351282861883,
            "rating_q025": 1257.6547719223695
        },
        "reka-flash-20240904": {
            "rating": 1265.1277837493476,
            "rating_q975": 1282.2810359166647,
            "rating_q025": 1247.9745315820305
        },
        "gemini-pro-dev-api": {
            "rating": 1263.471552877847,
            "rating_q975": 1283.2776338777312,
            "rating_q025": 1243.6654718779628
        },
        "gemini-1.5-flash-8b-001": {
            "rating": 1262.7604790675657,
            "rating_q975": 1270.8664171607732,
            "rating_q025": 1254.6545409743583
        },
        "c4ai-aya-expanse-32b": {
            "rating": 1261.9233358330462,
            "rating_q975": 1271.12684636281,
            "rating_q025": 1252.7198253032823
        },
        "mistral-small-24b-instruct-2501": {
            "rating": 1257.3798620893106,
            "rating_q975": 1271.7682487609095,
            "rating_q025": 1242.9914754177116
        },
        "command-r-plus": {
            "rating": 1257.0859304210096,
            "rating_q975": 1265.8456018967572,
            "rating_q025": 1248.326258945262
        },
        "glm-4-0520": {
            "rating": 1256.4070570629501,
            "rating_q975": 1272.225386947791,
            "rating_q025": 1240.5887271781091
        },
        "deepseek-coder-v2": {
            "rating": 1254.4922991470485,
            "rating_q975": 1268.0476134365933,
            "rating_q025": 1240.9369848575036
        },
        "gpt-4-0613": {
            "rating": 1253.5415683265144,
            "rating_q975": 1263.0229656600598,
            "rating_q025": 1244.060170992969
        },
        "gemma-2-9b-it": {
            "rating": 1253.2230306524964,
            "rating_q975": 1260.6303621117156,
            "rating_q025": 1245.8156991932772
        },
        "llama-3.1-nemotron-51b-instruct": {
            "rating": 1246.9974268995225,
            "rating_q975": 1268.9253521900016,
            "rating_q025": 1225.0695016090433
        },
        "amazon-nova-lite-v1.0": {
            "rating": 1246.0956560515942,
            "rating_q975": 1257.1034098639266,
            "rating_q025": 1235.087902239262
        },
        "jamba-1.5-large": {
            "rating": 1245.5400858932728,
            "rating_q975": 1262.9932383086343,
            "rating_q025": 1228.0869334779113
        },
        "phi-4": {
            "rating": 1242.041522428693,
            "rating_q975": 1252.8895453575988,
            "rating_q025": 1231.1934994997873
        },
        "ministral-8b-2410": {
            "rating": 1240.4224050062728,
            "rating_q975": 1259.9626944338586,
            "rating_q025": 1220.882115578687
        },
        "llama-3.1-nemotron-70b-instruct": {
            "rating": 1237.1805513221943,
            "rating_q975": 1254.238767001676,
            "rating_q025": 1220.1223356427126
        },
        "qwen2-72b-instruct": {
            "rating": 1235.839248945545,
            "rating_q975": 1245.6931827925391,
            "rating_q025": 1225.985315098551
        },
        "mistral-large-2402": {
            "rating": 1235.4043328885618,
            "rating_q975": 1245.3353826602831,
            "rating_q025": 1225.4732831168405
        },
        "command-r-08-2024": {
            "rating": 1229.8402426824525,
            "rating_q975": 1245.060586889737,
            "rating_q025": 1214.6198984751682
        },
        "ring-flash-2.0": {
            "rating": 1228.1885004431515,
            "rating_q975": 1258.0944615796711,
            "rating_q025": 1198.2825393066319
        },
        "c4ai-aya-expanse-8b": {
            "rating": 1227.1169877703169,
            "rating_q975": 1241.459799838656,
            "rating_q025": 1212.7741757019778
        },
        "olmo-2-0325-32b-instruct": {
            "rating": 1225.7410576754824,
            "rating_q975": 1259.0966695135119,
            "rating_q025": 1192.3854458374528
        },
        "reka-flash-21b-20240226-online": {
            "rating": 1225.4970381653416,
            "rating_q975": 1241.3650995215573,
            "rating_q025": 1209.6289768091258
        },
        "mixtral-8x22b-instruct-v0.1": {
            "rating": 1222.7350305001382,
            "rating_q975": 1232.324945463318,
            "rating_q025": 1213.1451155369584
        },
        "llama-3.1-tulu-3-8b": {
            "rating": 1222.0555319212663,
            "rating_q975": 1246.4586529471705,
            "rating_q025": 1197.652410895362
        },
        "reka-flash-21b-20240226": {
            "rating": 1222.0213373471101,
            "rating_q975": 1234.7108674817373,
            "rating_q025": 1209.331807212483
        },
        "amazon-nova-micro-v1.0": {
            "rating": 1219.3172563641904,
            "rating_q975": 1230.4858423473545,
            "rating_q025": 1208.1486703810262
        },
        "llama-3-70b-instruct": {
            "rating": 1218.8826469291753,
            "rating_q975": 1226.4490319662577,
            "rating_q025": 1211.3162618920928
        },
        "mistral-medium": {
            "rating": 1217.0215821371335,
            "rating_q975": 1231.5447355675824,
            "rating_q025": 1202.4984287066845
        },
        "gpt-3.5-turbo-0125": {
            "rating": 1215.8803161661253,
            "rating_q975": 1225.5715126271689,
            "rating_q025": 1206.1891197050818
        },
        "jamba-1.5-mini": {
            "rating": 1214.6579643143486,
            "rating_q975": 1232.2953046608327,
            "rating_q025": 1197.0206239678646
        },
        "command-r": {
            "rating": 1214.1467787138438,
            "rating_q975": 1224.124122981403,
            "rating_q025": 1204.1694344462846
        },
        "wizardlm-70b": {
            "rating": 1202.4467947845433,
            "rating_q975": 1246.7213163749082,
            "rating_q025": 1158.1722731941784
        },
        "phi-3-medium-4k-instruct": {
            "rating": 1193.6966909906823,
            "rating_q975": 1204.6571272453812,
            "rating_q025": 1182.7362547359835
        },
        "hunyuan-standard-256k": {
            "rating": 1191.3218316093642,
            "rating_q975": 1217.2442420842196,
            "rating_q025": 1165.3994211345087
        },
        "llama-3.1-8b-instruct": {
            "rating": 1188.068070377074,
            "rating_q975": 1195.7655830704161,
            "rating_q025": 1180.370557683732
        },
        "openchat-3.5": {
            "rating": 1186.977722995823,
            "rating_q975": 1227.9676396538462,
            "rating_q025": 1145.9878063377996
        },
        "zephyr-orpo-141b-A35b-v0.1": {
            "rating": 1181.2364275885739,
            "rating_q975": 1208.053302953755,
            "rating_q025": 1154.4195522233927
        },
        "gpt-3.5-turbo-1106": {
            "rating": 1174.9255379954297,
            "rating_q975": 1203.1956213802994,
            "rating_q025": 1146.6554546105601
        },
        "qwen1.5-110b-chat": {
            "rating": 1174.5223392434898,
            "rating_q975": 1186.2319613280474,
            "rating_q025": 1162.8127171589322
        },
        "llama-3-8b-instruct": {
            "rating": 1170.7522362331013,
            "rating_q975": 1179.0462621256775,
            "rating_q025": 1162.458210340525
        },
        "qwen1.5-72b-chat": {
            "rating": 1169.359631590072,
            "rating_q975": 1181.6478141411872,
            "rating_q025": 1157.0714490389569
        },
        "phi-3-small-8k-instruct": {
            "rating": 1167.771045624877,
            "rating_q975": 1180.539096024331,
            "rating_q025": 1155.0029952254229
        },
        "snowflake-arctic-instruct": {
            "rating": 1167.5016745488654,
            "rating_q975": 1180.317873878701,
            "rating_q025": 1154.6854752190297
        },
        "gemma-2-2b-it": {
            "rating": 1165.1867830825586,
            "rating_q975": 1173.4182200982275,
            "rating_q025": 1156.9553460668897
        },
        "mixtral-8x7b-instruct-v0.1": {
            "rating": 1157.9005056563324,
            "rating_q975": 1167.811811726056,
            "rating_q025": 1147.9891995866087
        },
        "dbrx-instruct-preview": {
            "rating": 1156.9407278623744,
            "rating_q975": 1169.3859484597656,
            "rating_q025": 1144.4955072649832
        },
        "starling-lm-7b-alpha": {
            "rating": 1151.8186756626878,
            "rating_q975": 1179.0369024190954,
            "rating_q025": 1124.6004489062802
        },
        "granite-3.1-8b-instruct": {
            "rating": 1151.3364941885582,
            "rating_q975": 1179.3301547355054,
            "rating_q025": 1123.342833641611
        },
        "openchat-3.5-0106": {
            "rating": 1150.5693707307325,
            "rating_q975": 1170.975524543219,
            "rating_q025": 1130.163216918246
        },
        "codellama-34b-instruct": {
            "rating": 1144.4882837815796,
            "rating_q975": 1188.5032239407074,
            "rating_q025": 1100.473343622452
        },
        "internlm2_5-20b-chat": {
            "rating": 1144.4435495525258,
            "rating_q975": 1159.913301224503,
            "rating_q025": 1128.9737978805488
        },
        "vicuna-33b": {
            "rating": 1141.4951517920626,
            "rating_q975": 1162.7499600335711,
            "rating_q025": 1120.2403435505541
        },
        "qwen1.5-32b-chat": {
            "rating": 1139.9946092908983,
            "rating_q975": 1153.207080129074,
            "rating_q025": 1126.7821384527226
        },
        "starling-lm-7b-beta": {
            "rating": 1139.0038219878588,
            "rating_q975": 1155.0801662870379,
            "rating_q025": 1122.9274776886798
        },
        "yi-1.5-34b-chat": {
            "rating": 1138.5061955850667,
            "rating_q975": 1149.9135249825779,
            "rating_q025": 1127.0988661875556
        },
        "granite-3.0-8b-instruct": {
            "rating": 1136.348419784808,
            "rating_q975": 1155.777993550293,
            "rating_q025": 1116.9188460193227
        },
        "llama-2-70b-chat": {
            "rating": 1136.145398727083,
            "rating_q975": 1150.004791874036,
            "rating_q025": 1122.2860055801298
        },
        "gemma-1.1-7b-it": {
            "rating": 1131.9006282093196,
            "rating_q975": 1144.0775965927432,
            "rating_q025": 1119.723659825896
        },
        "zephyr-7b-beta": {
            "rating": 1129.0187223796283,
            "rating_q975": 1167.1897566402986,
            "rating_q025": 1090.847688118958
        },
        "vicuna-13b": {
            "rating": 1124.0936988185676,
            "rating_q975": 1150.41584795578,
            "rating_q025": 1097.7715496813553
        },
        "qwq-32b-preview": {
            "rating": 1116.0417563871479,
            "rating_q975": 1142.1867518288054,
            "rating_q025": 1089.8967609454903
        },
        "llama-2-13b-chat": {
            "rating": 1111.1421943739497,
            "rating_q975": 1131.6128872576414,
            "rating_q025": 1090.671501490258
        },
        "granite-3.1-2b-instruct": {
            "rating": 1110.791586972736,
            "rating_q975": 1139.0204692641455,
            "rating_q025": 1082.5627046813265
        },
        "granite-3.0-2b-instruct": {
            "rating": 1110.7800753268264,
            "rating_q975": 1129.848158937325,
            "rating_q025": 1091.7119917163277
        },
        "yi-34b-chat": {
            "rating": 1110.1029505603046,
            "rating_q975": 1130.7256982349586,
            "rating_q025": 1089.4802028856507
        },
        "qwen1.5-14b-chat": {
            "rating": 1107.8860255040204,
            "rating_q975": 1123.042583151266,
            "rating_q025": 1092.7294678567748
        },
        "mistral-7b-instruct-v0.2": {
            "rating": 1088.0255057451582,
            "rating_q975": 1104.877950470724,
            "rating_q025": 1071.1730610195923
        },
        "gemma-1.1-2b-it": {
            "rating": 1083.8453242572612,
            "rating_q975": 1101.747518439084,
            "rating_q025": 1065.9431300754384
        },
        "mistral-7b-instruct": {
            "rating": 1082.9349102561278,
            "rating_q975": 1124.3751105447154,
            "rating_q025": 1041.49470996754
        },
        "phi-3-mini-4k-instruct-june-2024": {
            "rating": 1073.914561969434,
            "rating_q975": 1090.1827579337566,
            "rating_q025": 1057.6463660051115
        },
        "gemma-7b-it": {
            "rating": 1072.388056616804,
            "rating_q975": 1095.4295994620386,
            "rating_q025": 1049.3465137715696
        },
        "qwen1.5-7b-chat": {
            "rating": 1071.4932412254507,
            "rating_q975": 1105.52873655736,
            "rating_q025": 1037.4577458935414
        },
        "phi-3-mini-4k-instruct": {
            "rating": 1068.1267488648348,
            "rating_q975": 1080.7506631765161,
            "rating_q025": 1055.5028345531534
        },
        "phi-3-mini-128k-instruct": {
            "rating": 1065.501188186522,
            "rating_q975": 1081.1382454646127,
            "rating_q025": 1049.8641309084314
        },
        "smollm2-1.7b-instruct": {
            "rating": 1059.0171442400074,
            "rating_q975": 1089.8631825427613,
            "rating_q025": 1028.1711059372535
        },
        "llama-2-7b-chat": {
            "rating": 1053.8138151707763,
            "rating_q975": 1076.8304958210858,
            "rating_q025": 1030.7971345204667
        },
        "qwen1.5-4b-chat": {
            "rating": 1040.2148713625033,
            "rating_q975": 1064.906359018346,
            "rating_q025": 1015.5233837066608
        },
        "gemma-2b-it": {
            "rating": 1025.675514114609,
            "rating_q975": 1061.982166394841,
            "rating_q025": 989.3688618343771
        },
        "llama-3.2-3b-instruct": {
            "rating": 1008.4713684795624,
            "rating_q975": 1031.6405730564902,
            "rating_q025": 985.3021639026346
        },
        "llama-3.2-1b-instruct": {
            "rating": 991.2992865082331,
            "rating_q975": 1014.6537849790866,
            "rating_q025": 967.9447880373796
        },
        "olmo-7b-instruct": {
            "rating": 982.5538191149878,
            "rating_q975": 1010.388764345717,
            "rating_q025": 954.7188738842586
        }
    },
    "spanish": {
        "claude-opus-4-1-20250805-thinking-16k": {
            "rating": 1459.3042919287186,
            "rating_q975": 1485.5942691290986,
            "rating_q025": 1433.0143147283386
        },
        "gemini-2.5-pro": {
            "rating": 1456.0298626984059,
            "rating_q975": 1476.8971395970946,
            "rating_q025": 1435.1625857997171
        },
        "claude-sonnet-4-5-20250929": {
            "rating": 1453.554628833098,
            "rating_q975": 1494.2001237867773,
            "rating_q025": 1412.9091338794185
        },
        "qwen3-max-preview": {
            "rating": 1452.0263235398845,
            "rating_q975": 1478.683424703528,
            "rating_q025": 1425.369222376241
        },
        "claude-opus-4-1-20250805": {
            "rating": 1447.355061549725,
            "rating_q975": 1469.2004581758288,
            "rating_q025": 1425.5096649236211
        },
        "claude-sonnet-4-5-20250929-thinking-32k": {
            "rating": 1446.4093212761811,
            "rating_q975": 1477.5124850353068,
            "rating_q025": 1415.3061575170555
        },
        "chatgpt-4o-latest-20250326": {
            "rating": 1437.1604822939623,
            "rating_q975": 1461.0149074993599,
            "rating_q025": 1413.3060570885648
        },
        "grok-4-fast": {
            "rating": 1436.110300110649,
            "rating_q975": 1476.2487020678916,
            "rating_q025": 1395.9718981534063
        },
        "glm-4.5": {
            "rating": 1432.1411777381443,
            "rating_q975": 1459.098802394448,
            "rating_q025": 1405.1835530818405
        },
        "glm-4.6": {
            "rating": 1428.5646725470074,
            "rating_q975": 1464.8882395270227,
            "rating_q025": 1392.241105566992
        },
        "qwen3-235b-a22b-instruct-2507": {
            "rating": 1426.8610636577391,
            "rating_q975": 1450.2070286704368,
            "rating_q025": 1403.5150986450415
        },
        "claude-opus-4-20250514-thinking-16k": {
            "rating": 1420.860440073343,
            "rating_q975": 1444.7060099079815,
            "rating_q025": 1397.0148702387044
        },
        "qwen3-next-80b-a3b-instruct": {
            "rating": 1420.1830697643554,
            "rating_q975": 1448.9082396516328,
            "rating_q025": 1391.457899877078
        },
        "gpt-5-chat": {
            "rating": 1417.1104784463057,
            "rating_q975": 1442.8497323776307,
            "rating_q025": 1391.3712245149807
        },
        "gpt-5-high": {
            "rating": 1417.0709466481082,
            "rating_q975": 1442.7463335823968,
            "rating_q025": 1391.3955597138197
        },
        "kimi-k2-0905-preview": {
            "rating": 1415.7486293528125,
            "rating_q975": 1453.2640101527832,
            "rating_q025": 1378.2332485528418
        },
        "o3-2025-04-16": {
            "rating": 1414.195447442061,
            "rating_q975": 1436.7504710146195,
            "rating_q025": 1391.6404238695027
        },
        "deepseek-v3.1-thinking": {
            "rating": 1411.9549912733585,
            "rating_q975": 1446.22124680767,
            "rating_q025": 1377.688735739047
        },
        "qwen3-235b-a22b-no-thinking": {
            "rating": 1406.6979906131783,
            "rating_q975": 1432.6251528299563,
            "rating_q025": 1380.7708283964002
        },
        "grok-3-preview-02-24": {
            "rating": 1406.5473078710775,
            "rating_q975": 1438.1650714592834,
            "rating_q025": 1374.9295442828716
        },
        "longcat-flash-chat": {
            "rating": 1406.3397538005383,
            "rating_q975": 1440.0155795449682,
            "rating_q025": 1372.6639280561085
        },
        "claude-sonnet-4-20250514": {
            "rating": 1406.0357128726332,
            "rating_q975": 1429.5650218579597,
            "rating_q025": 1382.5064038873068
        },
        "qwen3-max-2025-09-23": {
            "rating": 1405.873662224031,
            "rating_q975": 1438.1049587809223,
            "rating_q025": 1373.6423656671398
        },
        "grok-4-0709": {
            "rating": 1405.5540885717155,
            "rating_q975": 1429.5705526118686,
            "rating_q025": 1381.5376245315624
        },
        "qwen3-vl-235b-a22b-instruct": {
            "rating": 1405.2738213588834,
            "rating_q975": 1439.5303735987807,
            "rating_q025": 1371.0172691189862
        },
        "gemini-2.5-flash": {
            "rating": 1403.7480321472804,
            "rating_q975": 1424.5527819371334,
            "rating_q025": 1382.9432823574273
        },
        "gpt-4.1-2025-04-14": {
            "rating": 1403.7318244311186,
            "rating_q975": 1426.32921986852,
            "rating_q025": 1381.1344289937172
        },
        "mistral-medium-2508": {
            "rating": 1401.8258100941644,
            "rating_q975": 1426.6113989557084,
            "rating_q025": 1377.0402212326203
        },
        "deepseek-v3.1": {
            "rating": 1400.4246084044019,
            "rating_q975": 1435.008114517171,
            "rating_q025": 1365.8411022916328
        },
        "deepseek-v3.2-exp-thinking": {
            "rating": 1397.501749156749,
            "rating_q975": 1434.3560702677196,
            "rating_q025": 1360.6474280457783
        },
        "claude-opus-4-20250514": {
            "rating": 1397.1283548772653,
            "rating_q975": 1419.970416608653,
            "rating_q025": 1374.2862931458776
        },
        "claude-sonnet-4-20250514-thinking-32k": {
            "rating": 1395.8674791961664,
            "rating_q975": 1420.506470997848,
            "rating_q025": 1371.2284873944848
        },
        "gemini-2.5-flash-lite-preview-09-2025-no-thinking": {
            "rating": 1395.4365797914609,
            "rating_q975": 1424.8348487683559,
            "rating_q025": 1366.0383108145659
        },
        "qwen3-vl-235b-a22b-thinking": {
            "rating": 1395.2999835380192,
            "rating_q975": 1430.5052603759755,
            "rating_q025": 1360.094706700063
        },
        "deepseek-r1-0528": {
            "rating": 1393.6805253194386,
            "rating_q975": 1432.5991903457232,
            "rating_q025": 1354.761860293154
        },
        "deepseek-r1": {
            "rating": 1392.1718549059028,
            "rating_q975": 1443.7131793194396,
            "rating_q025": 1340.630530492366
        },
        "gpt-5-nano-high": {
            "rating": 1389.6783670402212,
            "rating_q975": 1434.6427330380013,
            "rating_q025": 1344.7140010424412
        },
        "claude-haiku-4-5-20251001": {
            "rating": 1389.4920831003585,
            "rating_q975": 1427.0034229326202,
            "rating_q025": 1351.9807432680968
        },
        "mai-1-preview": {
            "rating": 1388.9656465492985,
            "rating_q975": 1416.3011329948843,
            "rating_q025": 1361.6301601037128
        },
        "grok-3-mini-beta": {
            "rating": 1387.4732048687886,
            "rating_q975": 1418.3819958109925,
            "rating_q025": 1356.5644139265846
        },
        "o1-2024-12-17": {
            "rating": 1387.4504823015675,
            "rating_q975": 1435.8005042438617,
            "rating_q025": 1339.1004603592733
        },
        "o4-mini-2025-04-16": {
            "rating": 1385.261643824481,
            "rating_q975": 1407.768610725664,
            "rating_q025": 1362.7546769232981
        },
        "qwen3-30b-a3b-instruct-2507": {
            "rating": 1384.178373614912,
            "rating_q975": 1410.5133342817996,
            "rating_q025": 1357.8434129480245
        },
        "gemini-2.5-flash-preview-09-2025": {
            "rating": 1382.9917883380679,
            "rating_q975": 1413.3856466171142,
            "rating_q025": 1352.5979300590216
        },
        "claude-3-7-sonnet-20250219-thinking-32k": {
            "rating": 1381.0004852260963,
            "rating_q975": 1408.3504914292837,
            "rating_q025": 1353.650479022909
        },
        "kimi-k2-0711-preview": {
            "rating": 1380.6818743103165,
            "rating_q975": 1410.2812506966782,
            "rating_q025": 1351.0824979239549
        },
        "qwen3-coder-480b-a35b-instruct": {
            "rating": 1380.5043941790425,
            "rating_q975": 1409.4565667448462,
            "rating_q025": 1351.5522216132388
        },
        "mistral-medium-2505": {
            "rating": 1379.7258424620125,
            "rating_q975": 1408.998702761282,
            "rating_q025": 1350.452982162743
        },
        "deepseek-v3": {
            "rating": 1378.3006602145217,
            "rating_q975": 1427.146240033729,
            "rating_q025": 1329.4550803953143
        },
        "step-3": {
            "rating": 1377.6638305081872,
            "rating_q975": 1423.382756253737,
            "rating_q025": 1331.9449047626374
        },
        "qwen3-235b-a22b": {
            "rating": 1376.6788862800613,
            "rating_q975": 1407.0650436500937,
            "rating_q025": 1346.292728910029
        },
        "ling-flash-2.0": {
            "rating": 1376.295247238006,
            "rating_q975": 1415.634015254831,
            "rating_q025": 1336.9564792211809
        },
        "qwen2.5-max": {
            "rating": 1374.3868908050401,
            "rating_q975": 1410.6819778768545,
            "rating_q025": 1338.0918037332258
        },
        "gpt-oss-120b": {
            "rating": 1371.1113134077802,
            "rating_q975": 1397.5636517503747,
            "rating_q025": 1344.6589750651858
        },
        "amazon-nova-experimental-chat-10-09": {
            "rating": 1370.676032662193,
            "rating_q975": 1424.9382399315602,
            "rating_q025": 1316.4138253928256
        },
        "glm-4.5-air": {
            "rating": 1369.1663128775663,
            "rating_q975": 1395.301807777582,
            "rating_q025": 1343.0308179775504
        },
        "gpt-5-mini-high": {
            "rating": 1368.1514660768498,
            "rating_q975": 1394.6993483796357,
            "rating_q025": 1341.603583774064
        },
        "mistral-small-2506": {
            "rating": 1367.3699991451729,
            "rating_q975": 1400.5388901761876,
            "rating_q025": 1334.2011081141582
        },
        "ring-flash-2.0": {
            "rating": 1366.6344166197107,
            "rating_q975": 1405.6631135229934,
            "rating_q025": 1327.605719716428
        },
        "gemini-2.5-flash-lite-preview-06-17-thinking": {
            "rating": 1366.5157686565133,
            "rating_q975": 1391.7494961757684,
            "rating_q025": 1341.2820411372581
        },
        "claude-3-5-sonnet-20241022": {
            "rating": 1361.111876897209,
            "rating_q975": 1381.1522534326539,
            "rating_q025": 1341.071500361764
        },
        "qwen3-next-80b-a3b-thinking": {
            "rating": 1356.8241561777156,
            "rating_q975": 1388.2244321308333,
            "rating_q025": 1325.423880224598
        },
        "command-a-03-2025": {
            "rating": 1356.1766933690215,
            "rating_q975": 1377.573452228981,
            "rating_q025": 1334.7799345090618
        },
        "grok-3-mini-high": {
            "rating": 1354.621799250066,
            "rating_q975": 1390.9163063906421,
            "rating_q025": 1318.32729210949
        },
        "minimax-m1": {
            "rating": 1353.2301688198284,
            "rating_q975": 1378.3067654123095,
            "rating_q025": 1328.1535722273472
        },
        "deepseek-v3-0324": {
            "rating": 1352.0809681625888,
            "rating_q975": 1375.0236374516992,
            "rating_q025": 1329.1382988734783
        },
        "gpt-4.1-mini-2025-04-14": {
            "rating": 1351.936131446088,
            "rating_q975": 1376.20595034214,
            "rating_q025": 1327.6663125500359
        },
        "o1-preview": {
            "rating": 1351.1434199635275,
            "rating_q975": 1380.9461531367897,
            "rating_q025": 1321.3406867902654
        },
        "gemma-3-27b-it": {
            "rating": 1351.0368713697515,
            "rating_q975": 1374.2106070058533,
            "rating_q025": 1327.8631357336496
        },
        "glm-4.5v": {
            "rating": 1350.2857307767918,
            "rating_q975": 1397.0557350350105,
            "rating_q025": 1303.515726518573
        },
        "claude-3-5-sonnet-20240620": {
            "rating": 1349.93082876673,
            "rating_q975": 1370.2357362947369,
            "rating_q025": 1329.625921238723
        },
        "gemini-1.5-pro-002": {
            "rating": 1349.4864015868604,
            "rating_q975": 1377.5009573503107,
            "rating_q025": 1321.4718458234101
        },
        "qwq-32b": {
            "rating": 1348.3548537492618,
            "rating_q975": 1380.970280477559,
            "rating_q025": 1315.7394270209645
        },
        "o3-mini-high": {
            "rating": 1345.9899769431356,
            "rating_q975": 1395.8365606487828,
            "rating_q025": 1296.1433932374885
        },
        "gpt-4o-2024-05-13": {
            "rating": 1340.5190687087288,
            "rating_q975": 1357.9292768746914,
            "rating_q025": 1323.1088605427663
        },
        "yi-lightning": {
            "rating": 1339.496194949904,
            "rating_q975": 1370.3289500381168,
            "rating_q025": 1308.6634398616914
        },
        "glm-4-plus": {
            "rating": 1338.8471024887453,
            "rating_q975": 1369.4068744686185,
            "rating_q025": 1308.2873305088722
        },
        "gemini-2.0-flash-lite-preview-02-05": {
            "rating": 1333.076748717866,
            "rating_q975": 1377.7655789702433,
            "rating_q025": 1288.3879184654886
        },
        "o1-mini": {
            "rating": 1332.468085460323,
            "rating_q975": 1358.936253570039,
            "rating_q025": 1305.999917350607
        },
        "o3-mini": {
            "rating": 1330.529972391325,
            "rating_q975": 1353.2581397907236,
            "rating_q025": 1307.8018049919262
        },
        "gpt-4o-2024-08-06": {
            "rating": 1327.8239594843158,
            "rating_q975": 1352.907439765064,
            "rating_q025": 1302.7404792035675
        },
        "magistral-medium-2506": {
            "rating": 1327.6634409522158,
            "rating_q975": 1370.002306878999,
            "rating_q025": 1285.3245750254325
        },
        "qwen-max-0919": {
            "rating": 1325.8990303175908,
            "rating_q975": 1363.3315635045876,
            "rating_q025": 1288.466497130594
        },
        "llama-4-maverick-17b-128e-instruct": {
            "rating": 1322.697699229242,
            "rating_q975": 1346.7542083305489,
            "rating_q025": 1298.6411901279353
        },
        "qwen3-30b-a3b": {
            "rating": 1322.4071271766152,
            "rating_q975": 1353.8562664886067,
            "rating_q025": 1290.9579878646236
        },
        "claude-3-5-haiku-20241022": {
            "rating": 1320.9699035890426,
            "rating_q975": 1343.294906319351,
            "rating_q025": 1298.6449008587342
        },
        "gpt-4-1106-preview": {
            "rating": 1316.3409079861688,
            "rating_q975": 1335.8478541399443,
            "rating_q025": 1296.8339618323932
        },
        "gpt-4-turbo-2024-04-09": {
            "rating": 1314.8224820652486,
            "rating_q975": 1333.479447437924,
            "rating_q025": 1296.1655166925732
        },
        "llama-3.1-405b-instruct-bf16": {
            "rating": 1313.4534204426711,
            "rating_q975": 1342.44290094903,
            "rating_q025": 1284.4639399363123
        },
        "llama-3.1-405b-instruct-fp8": {
            "rating": 1310.1366228610382,
            "rating_q975": 1333.4500822585514,
            "rating_q025": 1286.823163463525
        },
        "llama-4-scout-17b-16e-instruct": {
            "rating": 1310.073502340576,
            "rating_q975": 1337.3197655637134,
            "rating_q025": 1282.8272391174385
        },
        "grok-2-2024-08-13": {
            "rating": 1309.4645008465877,
            "rating_q975": 1332.0903488589506,
            "rating_q025": 1286.8386528342248
        },
        "claude-3-opus-20240229": {
            "rating": 1309.2782987423398,
            "rating_q975": 1325.681271117233,
            "rating_q025": 1292.8753263674464
        },
        "gpt-4o-mini-2024-07-18": {
            "rating": 1309.0261694196888,
            "rating_q975": 1330.8332532134941,
            "rating_q025": 1287.2190856258835
        },
        "grok-2-mini-2024-08-13": {
            "rating": 1308.245225277008,
            "rating_q975": 1331.4838748338284,
            "rating_q025": 1285.0065757201878
        },
        "mistral-large-2411": {
            "rating": 1306.4264778333497,
            "rating_q975": 1350.6015308356757,
            "rating_q025": 1262.2514248310238
        },
        "gpt-4-0125-preview": {
            "rating": 1305.8331053177071,
            "rating_q975": 1325.8189457388114,
            "rating_q025": 1285.8472648966028
        },
        "llama-3.3-70b-instruct": {
            "rating": 1303.0909498443912,
            "rating_q975": 1328.414444944767,
            "rating_q025": 1277.7674547440154
        },
        "mistral-small-3.1-24b-instruct-2503": {
            "rating": 1302.6019959545151,
            "rating_q975": 1328.2305668816862,
            "rating_q025": 1276.973425027344
        },
        "gemma-3n-e4b-it": {
            "rating": 1301.5874321611122,
            "rating_q975": 1333.1334506750395,
            "rating_q025": 1270.041413647185
        },
        "gpt-oss-20b": {
            "rating": 1300.5789674567663,
            "rating_q975": 1342.3471353399311,
            "rating_q025": 1258.8107995736016
        },
        "athene-v2-chat": {
            "rating": 1295.7093442123896,
            "rating_q975": 1334.2070639746812,
            "rating_q025": 1257.211624450098
        },
        "gemini-advanced-0514": {
            "rating": 1294.8561726101948,
            "rating_q975": 1317.2039880694697,
            "rating_q025": 1272.50835715092
        },
        "gemini-1.5-pro-001": {
            "rating": 1294.0383895089972,
            "rating_q975": 1313.569256996078,
            "rating_q025": 1274.5075220219164
        },
        "llama-3-70b-instruct": {
            "rating": 1292.5924775214046,
            "rating_q975": 1309.2329001822843,
            "rating_q025": 1275.9520548605249
        },
        "qwen2.5-72b-instruct": {
            "rating": 1290.8525433066932,
            "rating_q975": 1320.5600880221064,
            "rating_q025": 1261.14499859128
        },
        "athene-70b-0725": {
            "rating": 1290.022742165731,
            "rating_q975": 1324.491987165776,
            "rating_q025": 1255.553497165686
        },
        "gemma-2-27b-it": {
            "rating": 1289.3057174285696,
            "rating_q975": 1309.7419284451885,
            "rating_q025": 1268.8695064119506
        },
        "llama-3.1-70b-instruct": {
            "rating": 1289.2061676368785,
            "rating_q975": 1312.6210354455318,
            "rating_q025": 1265.7912998282252
        },
        "mistral-large-2407": {
            "rating": 1285.52621685026,
            "rating_q975": 1309.506270006419,
            "rating_q025": 1261.5461636941009
        },
        "gpt-4-0314": {
            "rating": 1282.7551651010147,
            "rating_q975": 1308.5562788314476,
            "rating_q025": 1256.9540513705817
        },
        "deepseek-v2.5": {
            "rating": 1282.6121968353905,
            "rating_q975": 1315.9359199179726,
            "rating_q025": 1249.2884737528084
        },
        "gemini-1.5-flash-002": {
            "rating": 1274.9509276563585,
            "rating_q975": 1307.6658504895101,
            "rating_q025": 1242.236004823207
        },
        "gemini-1.5-flash-001": {
            "rating": 1274.4859128248659,
            "rating_q975": 1294.494982085417,
            "rating_q025": 1254.4768435643148
        },
        "amazon-nova-lite-v1.0": {
            "rating": 1271.883336790755,
            "rating_q975": 1325.557888171992,
            "rating_q025": 1218.208785409518
        },
        "claude-3-sonnet-20240229": {
            "rating": 1270.4097218723123,
            "rating_q975": 1289.982294448107,
            "rating_q025": 1250.8371492965175
        },
        "phi-4": {
            "rating": 1268.731286493562,
            "rating_q975": 1319.8518929616557,
            "rating_q025": 1217.6106800254684
        },
        "gpt-4-0613": {
            "rating": 1267.8795662952602,
            "rating_q975": 1288.0201610172353,
            "rating_q025": 1247.7389715732852
        },
        "mistral-large-2402": {
            "rating": 1263.2270246230783,
            "rating_q975": 1285.8973532332666,
            "rating_q025": 1240.55669601289
        },
        "gemma-2-9b-it": {
            "rating": 1262.4586122329392,
            "rating_q975": 1286.3929275340772,
            "rating_q025": 1238.5242969318012
        },
        "command-r-plus": {
            "rating": 1254.3165337119497,
            "rating_q975": 1274.7983054718384,
            "rating_q025": 1233.834761952061
        },
        "amazon-nova-micro-v1.0": {
            "rating": 1253.0136674669066,
            "rating_q975": 1298.0300919434007,
            "rating_q025": 1207.9972429904124
        },
        "nemotron-4-340b-instruct": {
            "rating": 1252.798778893492,
            "rating_q975": 1283.20580175932,
            "rating_q025": 1222.391756027664
        },
        "qwen2-72b-instruct": {
            "rating": 1251.2633967804964,
            "rating_q975": 1277.2805325398288,
            "rating_q025": 1225.246261021164
        },
        "gemini-1.5-flash-8b-001": {
            "rating": 1250.9267785318236,
            "rating_q975": 1281.2454645217924,
            "rating_q025": 1220.6080925418548
        },
        "c4ai-aya-expanse-32b": {
            "rating": 1243.2949346543041,
            "rating_q975": 1278.656208372399,
            "rating_q025": 1207.9336609362092
        },
        "claude-3-haiku-20240307": {
            "rating": 1239.7091744617155,
            "rating_q975": 1257.8293080205813,
            "rating_q025": 1221.5890409028498
        },
        "mixtral-8x22b-instruct-v0.1": {
            "rating": 1229.5013134733035,
            "rating_q975": 1252.9071883522613,
            "rating_q025": 1206.0954385943458
        },
        "gpt-3.5-turbo-0125": {
            "rating": 1228.2886997094297,
            "rating_q975": 1251.1628406009474,
            "rating_q025": 1205.414558817912
        },
        "amazon-nova-pro-v1.0": {
            "rating": 1227.4297876210421,
            "rating_q975": 1277.1625946031847,
            "rating_q025": 1177.6969806388995
        },
        "llama-3-8b-instruct": {
            "rating": 1227.1724267609452,
            "rating_q975": 1245.6996812858565,
            "rating_q025": 1208.6451722360339
        },
        "gemini-pro-dev-api": {
            "rating": 1226.0591657170735,
            "rating_q975": 1268.0240192466658,
            "rating_q025": 1184.0943121874811
        },
        "command-r": {
            "rating": 1224.6338105078949,
            "rating_q975": 1249.4207621860699,
            "rating_q025": 1199.8468588297198
        },
        "deepseek-coder-v2": {
            "rating": 1221.9463051074829,
            "rating_q975": 1258.0004038631603,
            "rating_q025": 1185.8922063518055
        },
        "reka-flash-21b-20240226-online": {
            "rating": 1219.1121020404794,
            "rating_q975": 1259.7061499820295,
            "rating_q025": 1178.5180540989293
        },
        "qwen1.5-110b-chat": {
            "rating": 1215.5019374133742,
            "rating_q975": 1243.8061800668288,
            "rating_q025": 1187.1976947599196
        },
        "gpt-3.5-turbo-1106": {
            "rating": 1210.7307230963243,
            "rating_q975": 1249.471603642446,
            "rating_q025": 1171.9898425502024
        },
        "mistral-medium": {
            "rating": 1206.530622541206,
            "rating_q975": 1237.1352698959718,
            "rating_q025": 1175.9259751864402
        },
        "reka-flash-21b-20240226": {
            "rating": 1201.25415908573,
            "rating_q975": 1232.0089012132041,
            "rating_q025": 1170.4994169582558
        },
        "llama-2-70b-chat": {
            "rating": 1197.6215551081511,
            "rating_q975": 1225.1012339912243,
            "rating_q025": 1170.141876225078
        },
        "llama-3.1-8b-instruct": {
            "rating": 1190.1105876460992,
            "rating_q975": 1216.0962847639496,
            "rating_q025": 1164.124890528249
        },
        "gemma-2-2b-it": {
            "rating": 1187.696614028143,
            "rating_q975": 1213.7725445147785,
            "rating_q025": 1161.6206835415073
        },
        "qwen1.5-72b-chat": {
            "rating": 1187.5669843619535,
            "rating_q975": 1215.8478105649306,
            "rating_q025": 1159.2861581589764
        },
        "mixtral-8x7b-instruct-v0.1": {
            "rating": 1181.129181396485,
            "rating_q975": 1202.8912357461265,
            "rating_q025": 1159.3671270468433
        },
        "snowflake-arctic-instruct": {
            "rating": 1178.4916260209352,
            "rating_q975": 1206.7698384792106,
            "rating_q025": 1150.2134135626598
        },
        "phi-3-small-8k-instruct": {
            "rating": 1178.398173843978,
            "rating_q975": 1214.7735126705313,
            "rating_q025": 1142.0228350174245
        },
        "qwen1.5-32b-chat": {
            "rating": 1170.6676874117984,
            "rating_q975": 1200.7105313493055,
            "rating_q025": 1140.6248434742913
        },
        "yi-1.5-34b-chat": {
            "rating": 1168.8618419580748,
            "rating_q975": 1197.8431357867296,
            "rating_q025": 1139.88054812942
        },
        "vicuna-13b": {
            "rating": 1167.5298722430057,
            "rating_q975": 1215.4688975826166,
            "rating_q025": 1119.5908469033948
        },
        "phi-3-medium-4k-instruct": {
            "rating": 1165.9862202709992,
            "rating_q975": 1195.2368379373952,
            "rating_q025": 1136.7356026046032
        },
        "qwen1.5-14b-chat": {
            "rating": 1158.5800471641292,
            "rating_q975": 1192.9438817507662,
            "rating_q025": 1124.2162125774921
        },
        "dbrx-instruct-preview": {
            "rating": 1157.2894397163627,
            "rating_q975": 1188.3131131044704,
            "rating_q025": 1126.265766328255
        },
        "gemma-1.1-7b-it": {
            "rating": 1149.0711447932058,
            "rating_q975": 1180.029258566409,
            "rating_q025": 1118.1130310200026
        },
        "llama-2-13b-chat": {
            "rating": 1148.9919856683896,
            "rating_q975": 1187.3037435083563,
            "rating_q025": 1110.6802278284229
        },
        "phi-3-mini-4k-instruct": {
            "rating": 1148.8397904661883,
            "rating_q975": 1179.8334143462362,
            "rating_q025": 1117.8461665861405
        },
        "vicuna-33b": {
            "rating": 1148.0192972470743,
            "rating_q975": 1184.5355558231424,
            "rating_q025": 1111.5030386710062
        },
        "phi-3-mini-128k-instruct": {
            "rating": 1145.9996629228028,
            "rating_q975": 1179.3097544834907,
            "rating_q025": 1112.689571362115
        },
        "zephyr-7b-beta": {
            "rating": 1145.843072471072,
            "rating_q975": 1200.1829913914073,
            "rating_q025": 1091.5031535507367
        },
        "yi-34b-chat": {
            "rating": 1134.4302790262404,
            "rating_q975": 1174.6657838360786,
            "rating_q025": 1094.1947742164023
        },
        "mistral-7b-instruct-v0.2": {
            "rating": 1101.4720146909492,
            "rating_q975": 1145.6178807819454,
            "rating_q025": 1057.326148599953
        },
        "gemma-1.1-2b-it": {
            "rating": 1090.370261256021,
            "rating_q975": 1139.7507863826024,
            "rating_q025": 1040.9897361294395
        },
        "llama-2-7b-chat": {
            "rating": 1070.2926361202738,
            "rating_q975": 1120.7516268941558,
            "rating_q025": 1019.8336453463917
        }
    }
}