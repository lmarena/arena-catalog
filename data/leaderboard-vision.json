{
    "captioning": {
        "gemini-3-pro": {
            "rating": 1312.0083741127146,
            "rating_q975": 1349.7991063452305,
            "rating_q025": 1274.2176418801987
        },
        "gemini-2.5-pro": {
            "rating": 1298.5982779014275,
            "rating_q975": 1318.8641945331613,
            "rating_q025": 1278.3323612696938
        },
        "gemini-2.5-flash": {
            "rating": 1274.2330603629666,
            "rating_q975": 1297.7562636164594,
            "rating_q025": 1250.709857109474
        },
        "grok-4-0709": {
            "rating": 1235.0068472097437,
            "rating_q975": 1261.4770890819009,
            "rating_q025": 1208.5366053375865
        },
        "gpt-5-chat": {
            "rating": 1217.719480597602,
            "rating_q975": 1242.6493417507693,
            "rating_q025": 1192.7896194444345
        },
        "chatgpt-4o-latest-20250326": {
            "rating": 1212.1194911720954,
            "rating_q975": 1247.0586792053994,
            "rating_q025": 1177.1803031387915
        },
        "gpt-4.1-2025-04-14": {
            "rating": 1210.5808791220247,
            "rating_q975": 1234.438640233644,
            "rating_q025": 1186.7231180104054
        },
        "o3-2025-04-16": {
            "rating": 1210.4416264999513,
            "rating_q975": 1232.758756320078,
            "rating_q025": 1188.1244966798247
        },
        "o4-mini-2025-04-16": {
            "rating": 1210.2401248868173,
            "rating_q975": 1233.9568554728367,
            "rating_q025": 1186.523394300798
        },
        "gpt-5-mini-high": {
            "rating": 1209.534389021163,
            "rating_q975": 1238.1062713928634,
            "rating_q025": 1180.9625066494625
        },
        "gpt-5-high": {
            "rating": 1202.0364813140693,
            "rating_q975": 1227.7254407577066,
            "rating_q025": 1176.347521870432
        },
        "gemini-2.5-flash-lite-preview-06-17-thinking": {
            "rating": 1188.35,
            "rating_q975": 1212.9484743279793,
            "rating_q025": 1163.7515256720205
        },
        "gpt-4.1-mini-2025-04-14": {
            "rating": 1174.3207626120336,
            "rating_q975": 1200.654692327431,
            "rating_q025": 1147.9868328966363
        },
        "mistral-medium-2508": {
            "rating": 1156.3204584044715,
            "rating_q975": 1184.2344921388285,
            "rating_q025": 1128.4064246701146
        },
        "gemma-3-27b-it": {
            "rating": 1155.4090252317594,
            "rating_q975": 1186.1609675235502,
            "rating_q025": 1124.6570829399686
        },
        "mistral-small-3.1-24b-instruct-2503": {
            "rating": 1136.2175466814479,
            "rating_q975": 1166.5317529290112,
            "rating_q025": 1105.9033404338845
        },
        "gemini-2.0-flash-001": {
            "rating": 1110.722349616366,
            "rating_q975": 1167.4431002350818,
            "rating_q025": 1054.0015989976503
        },
        "mistral-medium-2505": {
            "rating": 1100.4193576827888,
            "rating_q975": 1139.75026775089,
            "rating_q025": 1061.0884476146875
        },
        "mistral-small-2506": {
            "rating": 1069.392976267,
            "rating_q975": 1108.521813841574,
            "rating_q025": 1030.264138692426
        }
    },
    "chinese": {
        "gemini-3-pro": {
            "rating": 1405.7312396680159,
            "rating_q975": 1434.0228737143668,
            "rating_q025": 1377.439605621665
        },
        "gemini-2.5-pro": {
            "rating": 1292.7871432412496,
            "rating_q975": 1318.5854339430218,
            "rating_q025": 1266.9888525394774
        },
        "gemini-2.5-flash-preview-09-2025": {
            "rating": 1289.9700799382017,
            "rating_q975": 1324.6867985055828,
            "rating_q025": 1255.2533613708206
        },
        "qwen3-vl-235b-a22b-instruct": {
            "rating": 1277.8219693716894,
            "rating_q975": 1311.8970662012066,
            "rating_q025": 1243.7468725421722
        },
        "gpt-5.1": {
            "rating": 1274.77319993174,
            "rating_q975": 1315.5013498027683,
            "rating_q025": 1234.0450500607117
        },
        "gpt-5-chat": {
            "rating": 1274.5053419935743,
            "rating_q975": 1301.7244570830023,
            "rating_q025": 1247.2862269041464
        },
        "gemini-2.5-flash": {
            "rating": 1270.0256908277215,
            "rating_q975": 1296.4339275174398,
            "rating_q025": 1243.6174541380033
        },
        "grok-4-0709": {
            "rating": 1252.209773774352,
            "rating_q975": 1279.6858478455267,
            "rating_q025": 1224.7336997031773
        },
        "gpt-5.1-high": {
            "rating": 1247.2951427681348,
            "rating_q975": 1293.2150965437397,
            "rating_q025": 1201.37518899253
        },
        "gpt-5-high": {
            "rating": 1237.160998529156,
            "rating_q975": 1264.4552810507241,
            "rating_q025": 1209.8667160075877
        },
        "o3-2025-04-16": {
            "rating": 1232.5368976430161,
            "rating_q975": 1258.4196878292046,
            "rating_q025": 1206.6541074568277
        },
        "chatgpt-4o-latest-20250326": {
            "rating": 1232.3772574620318,
            "rating_q975": 1260.5107124026974,
            "rating_q025": 1204.2438025213662
        },
        "gpt-4.1-2025-04-14": {
            "rating": 1227.0791280350952,
            "rating_q975": 1252.669431203526,
            "rating_q025": 1201.4888248666643
        },
        "gpt-5-mini-high": {
            "rating": 1223.435850036332,
            "rating_q975": 1251.7131648617467,
            "rating_q025": 1195.1585352109175
        },
        "o1-2024-12-17": {
            "rating": 1222.2906447952262,
            "rating_q975": 1280.389712038999,
            "rating_q025": 1164.1915775514533
        },
        "gemini-2.5-flash-lite-preview-09-2025-no-thinking": {
            "rating": 1220.9554903853684,
            "rating_q975": 1254.7354547384487,
            "rating_q025": 1187.1755260322882
        },
        "o4-mini-2025-04-16": {
            "rating": 1206.5194456120842,
            "rating_q975": 1233.4474609195306,
            "rating_q025": 1179.5914303046377
        },
        "gemini-2.5-flash-lite-preview-06-17-thinking": {
            "rating": 1188.35,
            "rating_q975": 1216.5849866677058,
            "rating_q025": 1160.115013332294
        },
        "gpt-4.1-mini-2025-04-14": {
            "rating": 1176.061235296895,
            "rating_q975": 1202.5324632744903,
            "rating_q025": 1149.5900073192995
        },
        "mistral-medium-2508": {
            "rating": 1175.89941627311,
            "rating_q975": 1204.0186239240693,
            "rating_q025": 1147.780208622151
        },
        "gemini-1.5-pro-002": {
            "rating": 1171.62357343408,
            "rating_q975": 1207.708348527649,
            "rating_q025": 1135.5387983405112
        },
        "gpt-4.5-preview-2025-02-27": {
            "rating": 1161.2274132856585,
            "rating_q975": 1224.2204076305748,
            "rating_q025": 1098.2344189407422
        },
        "gemma-3-27b-it": {
            "rating": 1154.5391541262,
            "rating_q975": 1184.5442149365476,
            "rating_q025": 1124.5340933158523
        },
        "mistral-medium-2505": {
            "rating": 1145.2073064877322,
            "rating_q975": 1177.722766567063,
            "rating_q025": 1112.6918464084015
        },
        "claude-3-7-sonnet-20250219": {
            "rating": 1144.1490214749556,
            "rating_q975": 1193.8676464824623,
            "rating_q025": 1094.4303964674489
        },
        "mistral-small-3.1-24b-instruct-2503": {
            "rating": 1141.1667835915532,
            "rating_q975": 1171.4690656113992,
            "rating_q025": 1110.8645015717073
        },
        "mistral-small-2506": {
            "rating": 1137.9978712948916,
            "rating_q975": 1171.120089714524,
            "rating_q025": 1104.8756528752592
        },
        "gemini-2.0-flash-001": {
            "rating": 1135.4492721887573,
            "rating_q975": 1170.0863556470517,
            "rating_q025": 1100.8121887304628
        },
        "gemini-1.5-flash-002": {
            "rating": 1121.9581286119897,
            "rating_q975": 1158.9204167553755,
            "rating_q025": 1084.9958404686038
        },
        "llama-4-maverick-17b-128e-instruct": {
            "rating": 1119.696085979397,
            "rating_q975": 1160.4434457584796,
            "rating_q025": 1078.9487262003142
        },
        "gpt-4o-2024-05-13": {
            "rating": 1117.0325464627101,
            "rating_q975": 1145.7924736680898,
            "rating_q025": 1088.2726192573305
        },
        "claude-3-5-sonnet-20241022": {
            "rating": 1103.970659620531,
            "rating_q975": 1134.68995281187,
            "rating_q025": 1073.251366429192
        },
        "qwen2.5-vl-72b-instruct": {
            "rating": 1092.645249218293,
            "rating_q975": 1145.7658578309638,
            "rating_q025": 1039.5246406056222
        },
        "claude-3-5-sonnet-20240620": {
            "rating": 1090.1018585021784,
            "rating_q975": 1119.9680984136176,
            "rating_q025": 1060.2356185907393
        },
        "llama-4-scout-17b-16e-instruct": {
            "rating": 1083.9042139911962,
            "rating_q975": 1125.1999811803817,
            "rating_q025": 1042.6084468020108
        },
        "pixtral-large-2411": {
            "rating": 1068.515249747204,
            "rating_q975": 1115.387683897726,
            "rating_q025": 1021.6428155966822
        },
        "qwen2-vl-72b": {
            "rating": 1056.591037243029,
            "rating_q975": 1094.792771889035,
            "rating_q025": 1018.3893025970228
        },
        "internvl2-26b": {
            "rating": 1049.7952527004877,
            "rating_q975": 1091.1657443130682,
            "rating_q025": 1008.4247610879072
        },
        "gpt-4-turbo-2024-04-09": {
            "rating": 1029.8853622504407,
            "rating_q975": 1061.7450132899237,
            "rating_q025": 998.0257112109578
        },
        "gpt-4o-mini-2024-07-18": {
            "rating": 1017.8647944562013,
            "rating_q975": 1046.844364684798,
            "rating_q025": 988.8852242276046
        },
        "gemini-1.5-pro-001": {
            "rating": 1015.2092572850438,
            "rating_q975": 1046.5001291558742,
            "rating_q025": 983.9183854142135
        },
        "gemini-2.0-flash-lite-preview-02-05": {
            "rating": 1012.2224937258185,
            "rating_q975": 1070.8249486519567,
            "rating_q025": 953.6200387996804
        },
        "gpt-4o-2024-08-06": {
            "rating": 994.3052837264754,
            "rating_q975": 1040.4900986441412,
            "rating_q025": 948.1204688088096
        },
        "qwen2-vl-7b-instruct": {
            "rating": 984.1734136640796,
            "rating_q975": 1023.0305327085201,
            "rating_q025": 945.316294619639
        },
        "claude-3-opus-20240229": {
            "rating": 979.0010998185132,
            "rating_q975": 1010.6021458830475,
            "rating_q025": 947.400053753979
        },
        "gemini-1.5-flash-8b-001": {
            "rating": 958.556542801314,
            "rating_q975": 995.9443013292458,
            "rating_q025": 921.1687842733821
        },
        "gemini-1.5-flash-001": {
            "rating": 944.6318029657439,
            "rating_q975": 976.784308763655,
            "rating_q025": 912.4792971678328
        },
        "llama-3.2-vision-90b-instruct": {
            "rating": 937.2817138866126,
            "rating_q975": 973.048369792191,
            "rating_q025": 901.5150579810341
        },
        "pixtral-12b-2409": {
            "rating": 935.6035537368645,
            "rating_q975": 973.0170780266119,
            "rating_q025": 898.190029447117
        },
        "internvl2-4b": {
            "rating": 935.2040996500137,
            "rating_q975": 984.2768186824677,
            "rating_q025": 886.1313806175598
        },
        "claude-3-sonnet-20240229": {
            "rating": 927.2169268936125,
            "rating_q975": 959.4765778633338,
            "rating_q025": 894.9572759238912
        },
        "molmo-72b-0924": {
            "rating": 921.3055797518142,
            "rating_q975": 970.5413163265713,
            "rating_q025": 872.0698431770571
        },
        "claude-3-haiku-20240307": {
            "rating": 900.4851300038018,
            "rating_q975": 932.7208199441192,
            "rating_q025": 868.2494400634845
        },
        "llama-3.2-vision-11b-instruct": {
            "rating": 899.717643994103,
            "rating_q975": 941.8352543437779,
            "rating_q025": 857.6000336444281
        },
        "llava-v1.6-34b": {
            "rating": 899.6794072364044,
            "rating_q975": 938.681907104419,
            "rating_q025": 860.6769073683897
        },
        "molmo-7b-d-0924": {
            "rating": 874.9645790381154,
            "rating_q975": 923.1199450010328,
            "rating_q025": 826.809213075198
        }
    },
    "creative_writing_vision": {
        "gemini-3-pro": {
            "rating": 1391.969880063023,
            "rating_q975": 1415.5398678020517,
            "rating_q025": 1368.3998923239944
        },
        "gemini-2.5-flash-preview-09-2025": {
            "rating": 1287.9913047647578,
            "rating_q975": 1312.6928528784608,
            "rating_q025": 1263.2897566510549
        },
        "gpt-5.1-high": {
            "rating": 1284.323384690297,
            "rating_q975": 1319.0961569525668,
            "rating_q025": 1249.550612428027
        },
        "gpt-5.1": {
            "rating": 1279.214100422105,
            "rating_q975": 1314.4761881793268,
            "rating_q025": 1243.9520126648833
        },
        "gemini-2.5-pro": {
            "rating": 1274.564778692045,
            "rating_q975": 1288.5352018225924,
            "rating_q025": 1260.5943555614974
        },
        "grok-4-0709": {
            "rating": 1265.822003109612,
            "rating_q975": 1282.0190055259288,
            "rating_q025": 1249.6250006932953
        },
        "ernie-5.0-preview-1120": {
            "rating": 1263.2949050883951,
            "rating_q975": 1296.1335979955306,
            "rating_q025": 1230.4562121812596
        },
        "claude-opus-4-20250514": {
            "rating": 1252.6382357542004,
            "rating_q975": 1285.1730236736096,
            "rating_q025": 1220.1034478347913
        },
        "gemini-2.5-flash": {
            "rating": 1251.5241979182542,
            "rating_q975": 1266.5346871868544,
            "rating_q025": 1236.513708649654
        },
        "chatgpt-4o-latest-20250326": {
            "rating": 1244.030875930867,
            "rating_q975": 1263.1311970404986,
            "rating_q025": 1224.9305548212355
        },
        "gpt-5-chat": {
            "rating": 1239.9667670724746,
            "rating_q975": 1255.691834786138,
            "rating_q025": 1224.241699358811
        },
        "qwen3-vl-235b-a22b-instruct": {
            "rating": 1231.1653808879314,
            "rating_q975": 1254.9429442691703,
            "rating_q025": 1207.3878175066925
        },
        "qwen3-vl-235b-a22b-thinking": {
            "rating": 1230.0894404634269,
            "rating_q975": 1268.0184286988854,
            "rating_q025": 1192.1604522279683
        },
        "gpt-4.1-2025-04-14": {
            "rating": 1223.5782332470617,
            "rating_q975": 1239.7306014487262,
            "rating_q025": 1207.4258650453971
        },
        "mistral-medium-2508": {
            "rating": 1222.8509789106547,
            "rating_q975": 1239.8485620293948,
            "rating_q025": 1205.8533957919146
        },
        "gemini-2.5-flash-lite-preview-09-2025-no-thinking": {
            "rating": 1219.8760288326894,
            "rating_q975": 1244.122842099843,
            "rating_q025": 1195.6292155655358
        },
        "gemini-2.0-flash-001": {
            "rating": 1203.8437042455585,
            "rating_q975": 1236.9499085010127,
            "rating_q025": 1170.7374999901042
        },
        "o3-2025-04-16": {
            "rating": 1196.7258652808905,
            "rating_q975": 1210.732663966417,
            "rating_q025": 1182.719066595364
        },
        "gpt-5-high": {
            "rating": 1193.3771026552117,
            "rating_q975": 1209.2891270520956,
            "rating_q025": 1177.4650782583278
        },
        "claude-sonnet-4-20250514": {
            "rating": 1190.4280280343191,
            "rating_q975": 1229.8165741328958,
            "rating_q025": 1151.0394819357425
        },
        "gemini-2.5-flash-lite-preview-06-17-thinking": {
            "rating": 1188.35,
            "rating_q975": 1205.4241225033315,
            "rating_q025": 1171.2758774966683
        },
        "mistral-small-2506": {
            "rating": 1185.2568786845807,
            "rating_q975": 1213.1853511201766,
            "rating_q025": 1157.3284062489847
        },
        "qwen-vl-max-2025-08-13": {
            "rating": 1183.5884710231694,
            "rating_q975": 1225.7429932442806,
            "rating_q025": 1141.4339488020582
        },
        "gemma-3-27b-it": {
            "rating": 1182.5462612410768,
            "rating_q975": 1203.9543623002623,
            "rating_q025": 1161.1381601818912
        },
        "gpt-5-mini-high": {
            "rating": 1181.3169863582248,
            "rating_q975": 1199.4272216564354,
            "rating_q025": 1163.206751060014
        },
        "hunyuan-vision-1.5-thinking": {
            "rating": 1176.154334537028,
            "rating_q975": 1211.7799736217073,
            "rating_q025": 1140.5286954523488
        },
        "mistral-medium-2505": {
            "rating": 1168.5498610759837,
            "rating_q975": 1193.0347415616247,
            "rating_q025": 1144.0649805903427
        },
        "gpt-4.1-mini-2025-04-14": {
            "rating": 1164.821437188296,
            "rating_q975": 1182.2122023478605,
            "rating_q025": 1147.4306720287314
        },
        "o4-mini-2025-04-16": {
            "rating": 1160.8425155693353,
            "rating_q975": 1176.8692707143628,
            "rating_q025": 1144.8157604243079
        },
        "mistral-small-3.1-24b-instruct-2503": {
            "rating": 1143.4037814310777,
            "rating_q975": 1164.952781447168,
            "rating_q025": 1121.8547814149874
        },
        "llama-4-scout-17b-16e-instruct": {
            "rating": 1126.6845625450533,
            "rating_q975": 1163.1936066603575,
            "rating_q025": 1090.175518429749
        },
        "gpt-5-nano-high": {
            "rating": 1117.4072113917512,
            "rating_q975": 1157.7193991809058,
            "rating_q025": 1077.0950236025965
        },
        "llama-4-maverick-17b-128e-instruct": {
            "rating": 1112.820742776467,
            "rating_q975": 1150.6821849500068,
            "rating_q025": 1074.959300602927
        }
    },
    "diagram": {
        "gemini-3-pro": {
            "rating": 1314.7770378249766,
            "rating_q975": 1335.9967262517973,
            "rating_q025": 1293.5573493981558
        },
        "gemini-2.5-pro": {
            "rating": 1285.0013047038206,
            "rating_q975": 1295.4066576567943,
            "rating_q025": 1274.5959517508468
        },
        "qwen-vl-max-2025-08-13": {
            "rating": 1277.018562572549,
            "rating_q975": 1307.2166185573342,
            "rating_q025": 1246.8205065877637
        },
        "gpt-5.1": {
            "rating": 1273.9785928964493,
            "rating_q975": 1303.5883168835385,
            "rating_q025": 1244.3688689093601
        },
        "gpt-5.1-high": {
            "rating": 1270.3473475672686,
            "rating_q975": 1298.3955317108491,
            "rating_q025": 1242.299163423688
        },
        "qwen3-vl-235b-a22b-instruct": {
            "rating": 1260.6640703220814,
            "rating_q975": 1278.5669550435775,
            "rating_q025": 1242.7611856005853
        },
        "gpt-5-chat": {
            "rating": 1257.0460421994485,
            "rating_q975": 1269.806758723587,
            "rating_q025": 1244.2853256753099
        },
        "gemini-2.5-flash-preview-09-2025": {
            "rating": 1254.3521154636405,
            "rating_q975": 1272.051810035581,
            "rating_q025": 1236.6524208917
        },
        "chatgpt-4o-latest-20250326": {
            "rating": 1251.5560895927042,
            "rating_q975": 1263.9935295265168,
            "rating_q025": 1239.1186496588916
        },
        "ernie-5.0-preview-1120": {
            "rating": 1240.2679559879916,
            "rating_q975": 1265.1638403063596,
            "rating_q025": 1215.3720716696237
        },
        "gpt-5-high": {
            "rating": 1238.620359737707,
            "rating_q975": 1251.2282567869806,
            "rating_q025": 1226.0124626884335
        },
        "gemini-2.5-flash": {
            "rating": 1238.5219640258324,
            "rating_q975": 1249.3301055946936,
            "rating_q025": 1227.7138224569712
        },
        "hunyuan-vision-1.5-thinking": {
            "rating": 1237.0313756081823,
            "rating_q975": 1261.9097962163694,
            "rating_q025": 1212.1529549999952
        },
        "o3-2025-04-16": {
            "rating": 1226.8835459427648,
            "rating_q975": 1237.8403632586305,
            "rating_q025": 1215.9267286268991
        },
        "gpt-4.1-2025-04-14": {
            "rating": 1223.1011766301467,
            "rating_q975": 1235.0748715278976,
            "rating_q025": 1211.1274817323958
        },
        "qwen3-vl-235b-a22b-thinking": {
            "rating": 1219.0256429133653,
            "rating_q975": 1243.6549029541209,
            "rating_q025": 1194.3963828726098
        },
        "claude-sonnet-4-20250514-thinking-32k": {
            "rating": 1208.227862526727,
            "rating_q975": 1243.9565551354738,
            "rating_q025": 1172.4991699179802
        },
        "gpt-5-mini-high": {
            "rating": 1203.6102857538722,
            "rating_q975": 1217.4773493355287,
            "rating_q025": 1189.7432221722156
        },
        "o4-mini-2025-04-16": {
            "rating": 1199.2511232842307,
            "rating_q975": 1211.008821619836,
            "rating_q025": 1187.4934249486255
        },
        "grok-4-0709": {
            "rating": 1198.308785145057,
            "rating_q975": 1210.7515351563582,
            "rating_q025": 1185.866035133756
        },
        "claude-opus-4-20250514-thinking-16k": {
            "rating": 1195.605023695944,
            "rating_q975": 1229.4489633240419,
            "rating_q025": 1161.7610840678462
        },
        "gemini-2.5-flash-lite-preview-09-2025-no-thinking": {
            "rating": 1195.427371673045,
            "rating_q975": 1212.9058530448629,
            "rating_q025": 1177.948890301227
        },
        "step-1o-turbo-202506": {
            "rating": 1189.8630618449133,
            "rating_q975": 1217.4222123147072,
            "rating_q025": 1162.3039113751195
        },
        "gemini-2.5-flash-lite-preview-06-17-thinking": {
            "rating": 1188.35,
            "rating_q975": 1200.6828629252673,
            "rating_q025": 1176.0171370747325
        },
        "gpt-4.1-mini-2025-04-14": {
            "rating": 1185.304531466592,
            "rating_q975": 1198.0162762958796,
            "rating_q025": 1172.5927866373042
        },
        "claude-opus-4-20250514": {
            "rating": 1183.8625294817728,
            "rating_q975": 1208.1380863018771,
            "rating_q025": 1159.5869726616684
        },
        "claude-sonnet-4-20250514": {
            "rating": 1180.2892916330948,
            "rating_q975": 1207.6766227360308,
            "rating_q025": 1152.9019605301587
        },
        "claude-3-7-sonnet-20250219-thinking-32k": {
            "rating": 1179.0902977307264,
            "rating_q975": 1211.699265607429,
            "rating_q025": 1146.481329854024
        },
        "mistral-medium-2508": {
            "rating": 1172.692803231938,
            "rating_q975": 1186.408671463593,
            "rating_q025": 1158.9769350002828
        },
        "glm-4.5v": {
            "rating": 1164.9366623393075,
            "rating_q975": 1192.8088447266102,
            "rating_q025": 1137.0644799520048
        },
        "gemma-3-27b-it": {
            "rating": 1158.1178231077315,
            "rating_q975": 1171.9387139512833,
            "rating_q025": 1144.2969322641798
        },
        "claude-3-7-sonnet-20250219": {
            "rating": 1154.3679006169973,
            "rating_q975": 1184.8057974327903,
            "rating_q025": 1123.9300038012043
        },
        "gemini-2.0-flash-001": {
            "rating": 1153.1483213289248,
            "rating_q975": 1171.1921468571295,
            "rating_q025": 1135.10449580072
        },
        "mistral-medium-2505": {
            "rating": 1152.7883907689766,
            "rating_q975": 1167.730932506977,
            "rating_q025": 1137.845849030976
        },
        "step-3": {
            "rating": 1150.973426911692,
            "rating_q975": 1179.1880903276658,
            "rating_q025": 1122.7587634957183
        },
        "hunyuan-large-vision": {
            "rating": 1146.0357298223526,
            "rating_q975": 1178.868623640359,
            "rating_q025": 1113.2028360043462
        },
        "gpt-5-nano-high": {
            "rating": 1137.4214741261317,
            "rating_q975": 1163.322378305492,
            "rating_q025": 1111.5205699467713
        },
        "llama-4-maverick-17b-128e-instruct": {
            "rating": 1136.2227458799462,
            "rating_q975": 1154.3992738088727,
            "rating_q025": 1118.0462179510196
        },
        "claude-3-5-sonnet-20241022": {
            "rating": 1132.0795618891939,
            "rating_q975": 1162.5082732728047,
            "rating_q025": 1101.650850505583
        },
        "llama-4-scout-17b-16e-instruct": {
            "rating": 1128.5547848642,
            "rating_q975": 1147.7756315632298,
            "rating_q025": 1109.3339381651701
        },
        "mistral-small-2506": {
            "rating": 1125.7139503697522,
            "rating_q975": 1142.8367670731457,
            "rating_q025": 1108.5911336663587
        },
        "mistral-small-3.1-24b-instruct-2503": {
            "rating": 1124.756088332339,
            "rating_q975": 1139.6718166599685,
            "rating_q025": 1109.8403600047095
        },
        "claude-3-5-haiku-20241022": {
            "rating": 1087.5121781452299,
            "rating_q975": 1118.8001948460394,
            "rating_q025": 1056.2241614444204
        }
    },
    "english": {
        "gemini-3-pro": {
            "rating": 1315.5290837098391,
            "rating_q975": 1333.1510832430351,
            "rating_q025": 1297.9070841766431
        },
        "gemini-2.5-pro": {
            "rating": 1271.0765586366433,
            "rating_q975": 1280.8591663341972,
            "rating_q025": 1261.2939509390894
        },
        "gemini-2.5-flash-preview-09-2025": {
            "rating": 1250.9017247850286,
            "rating_q975": 1265.3265147789923,
            "rating_q025": 1236.4769347910649
        },
        "qwen3-vl-235b-a22b-instruct": {
            "rating": 1249.821237272017,
            "rating_q975": 1263.7924936194063,
            "rating_q025": 1235.8499809246277
        },
        "gpt-5.1-high": {
            "rating": 1242.2650587906862,
            "rating_q975": 1264.2141312825463,
            "rating_q025": 1220.3159862988261
        },
        "chatgpt-4o-latest-20250326": {
            "rating": 1242.1418589655966,
            "rating_q975": 1251.2472638771703,
            "rating_q025": 1233.036454054023
        },
        "gpt-5.1": {
            "rating": 1241.8637842070646,
            "rating_q975": 1263.9364285405723,
            "rating_q025": 1219.7911398735569
        },
        "gemini-2.5-flash": {
            "rating": 1241.3447547324006,
            "rating_q975": 1251.1634828717274,
            "rating_q025": 1231.5260265930738
        },
        "gpt-5-chat": {
            "rating": 1232.2134446779683,
            "rating_q975": 1243.1015638582032,
            "rating_q025": 1221.3253254977333
        },
        "hunyuan-vision-1.5-thinking": {
            "rating": 1231.7182857839762,
            "rating_q975": 1249.0495162405489,
            "rating_q025": 1214.3870553274035
        },
        "qwen-vl-max-2025-08-13": {
            "rating": 1229.5735567101963,
            "rating_q975": 1246.8535657858781,
            "rating_q025": 1212.2935476345144
        },
        "ernie-5.0-preview-1120": {
            "rating": 1223.8307462028233,
            "rating_q975": 1241.6816842361463,
            "rating_q025": 1205.9798081695003
        },
        "o3-2025-04-16": {
            "rating": 1220.2971074465493,
            "rating_q975": 1229.769592152588,
            "rating_q025": 1210.8246227405104
        },
        "grok-4-0709": {
            "rating": 1219.3847416661426,
            "rating_q975": 1230.1048839129148,
            "rating_q025": 1208.6645994193705
        },
        "gpt-5-high": {
            "rating": 1218.823556198133,
            "rating_q975": 1229.743805817404,
            "rating_q025": 1207.903306578862
        },
        "qwen3-vl-235b-a22b-thinking": {
            "rating": 1215.7614920370268,
            "rating_q975": 1233.70457379163,
            "rating_q025": 1197.8184102824234
        },
        "gpt-4.1-2025-04-14": {
            "rating": 1213.8317252286608,
            "rating_q975": 1223.609160684401,
            "rating_q025": 1204.0542897729206
        },
        "gpt-5-mini-high": {
            "rating": 1213.6673263972548,
            "rating_q975": 1224.986415132223,
            "rating_q025": 1202.3482376622865
        },
        "gemini-2.5-flash-lite-preview-09-2025-no-thinking": {
            "rating": 1213.0027034172188,
            "rating_q975": 1227.1687808586305,
            "rating_q025": 1198.836625975807
        },
        "step-1o-turbo-202506": {
            "rating": 1207.0992177013786,
            "rating_q975": 1226.7754319333596,
            "rating_q025": 1187.4230034693976
        },
        "o4-mini-2025-04-16": {
            "rating": 1198.1871355148407,
            "rating_q975": 1208.256852382372,
            "rating_q025": 1188.1174186473095
        },
        "step-3": {
            "rating": 1193.6521971035893,
            "rating_q975": 1210.1207403226858,
            "rating_q025": 1177.1836538844927
        },
        "gpt-4.1-mini-2025-04-14": {
            "rating": 1191.8983651381104,
            "rating_q975": 1202.192394605329,
            "rating_q025": 1181.604335670892
        },
        "hunyuan-large-vision": {
            "rating": 1190.507687241756,
            "rating_q975": 1212.8727523971677,
            "rating_q025": 1168.1426220863443
        },
        "gpt-4.5-preview-2025-02-27": {
            "rating": 1188.408080498234,
            "rating_q975": 1204.1936880796068,
            "rating_q025": 1172.6224729168614
        },
        "gemini-2.5-flash-lite-preview-06-17-thinking": {
            "rating": 1188.35,
            "rating_q975": 1199.0648286688665,
            "rating_q025": 1177.6351713311333
        },
        "glm-4.5v": {
            "rating": 1186.1900186519713,
            "rating_q975": 1202.7908625356586,
            "rating_q025": 1169.589174768284
        },
        "claude-sonnet-4-20250514-thinking-32k": {
            "rating": 1184.3693793987354,
            "rating_q975": 1208.4534173083275,
            "rating_q025": 1160.2853414891433
        },
        "gemma-3-27b-it": {
            "rating": 1183.4696735532252,
            "rating_q975": 1194.5007977670152,
            "rating_q025": 1172.4385493394352
        },
        "claude-opus-4-20250514": {
            "rating": 1179.5453179891076,
            "rating_q975": 1197.429087007206,
            "rating_q025": 1161.6615489710093
        },
        "claude-opus-4-20250514-thinking-16k": {
            "rating": 1177.34977793586,
            "rating_q975": 1201.0865666647894,
            "rating_q025": 1153.6129892069305
        },
        "mistral-medium-2508": {
            "rating": 1177.004044968118,
            "rating_q975": 1188.2388232780538,
            "rating_q025": 1165.7692666581822
        },
        "mistral-medium-2505": {
            "rating": 1173.7590535536938,
            "rating_q975": 1185.1325642223499,
            "rating_q025": 1162.3855428850377
        },
        "gemini-2.0-flash-001": {
            "rating": 1173.2820810766307,
            "rating_q975": 1182.4110288872132,
            "rating_q025": 1164.1531332660481
        },
        "gpt-5-nano-high": {
            "rating": 1166.557101537529,
            "rating_q975": 1182.3803571007843,
            "rating_q025": 1150.7338459742737
        },
        "claude-sonnet-4-20250514": {
            "rating": 1164.3126546963408,
            "rating_q975": 1185.0087452622206,
            "rating_q025": 1143.616564130461
        },
        "claude-3-7-sonnet-20250219-thinking-32k": {
            "rating": 1163.2652268989439,
            "rating_q975": 1185.066150963995,
            "rating_q025": 1141.4643028338928
        },
        "o1-2024-12-17": {
            "rating": 1160.01886519458,
            "rating_q975": 1173.788346832211,
            "rating_q025": 1146.2493835569492
        },
        "mistral-small-2506": {
            "rating": 1157.6300196434827,
            "rating_q975": 1169.8043877992002,
            "rating_q025": 1145.4556514877652
        },
        "gemini-1.5-pro-002": {
            "rating": 1156.4787009878098,
            "rating_q975": 1166.6677775684902,
            "rating_q025": 1146.2896244071294
        },
        "qwen2.5-vl-32b-instruct": {
            "rating": 1156.1024361596615,
            "rating_q975": 1175.208595633466,
            "rating_q025": 1136.9962766858569
        },
        "gemini-1.5-flash-002": {
            "rating": 1154.6424873805968,
            "rating_q975": 1165.8465366847286,
            "rating_q025": 1143.438438076465
        },
        "mistral-small-3.1-24b-instruct-2503": {
            "rating": 1150.9881116379404,
            "rating_q975": 1162.3016615141594,
            "rating_q025": 1139.6745617617214
        },
        "llama-4-maverick-17b-128e-instruct": {
            "rating": 1145.3171187388002,
            "rating_q975": 1157.5832933494974,
            "rating_q025": 1133.050944128103
        },
        "step-1o-vision-32k-highres": {
            "rating": 1144.6619632013744,
            "rating_q975": 1160.0228946543566,
            "rating_q025": 1129.3010317483922
        },
        "gpt-4o-2024-05-13": {
            "rating": 1144.6244155715995,
            "rating_q975": 1154.213600577029,
            "rating_q025": 1135.03523056617
        },
        "claude-3-7-sonnet-20250219": {
            "rating": 1137.2600401515383,
            "rating_q975": 1149.751673711273,
            "rating_q025": 1124.7684065918036
        },
        "llama-4-scout-17b-16e-instruct": {
            "rating": 1135.76517637162,
            "rating_q975": 1148.7358303236251,
            "rating_q025": 1122.794522419615
        },
        "claude-3-5-sonnet-20241022": {
            "rating": 1119.8132863544424,
            "rating_q975": 1128.93834132515,
            "rating_q025": 1110.6882313837348
        },
        "gemini-2.0-flash-lite-preview-02-05": {
            "rating": 1118.6902598565869,
            "rating_q975": 1131.4402192569653,
            "rating_q025": 1105.9403004562084
        },
        "claude-3-5-sonnet-20240620": {
            "rating": 1116.508305916987,
            "rating_q975": 1128.0334076720078,
            "rating_q025": 1104.9832041619661
        },
        "qwen2.5-vl-72b-instruct": {
            "rating": 1112.48888749668,
            "rating_q975": 1125.366243200786,
            "rating_q025": 1099.6115317925742
        },
        "claude-3-5-haiku-20241022": {
            "rating": 1102.393751403348,
            "rating_q975": 1124.9854869820945,
            "rating_q025": 1079.8020158246015
        },
        "gpt-4.1-nano-2025-04-14": {
            "rating": 1098.8011987148707,
            "rating_q975": 1125.3230957961737,
            "rating_q025": 1072.2793016335677
        },
        "pixtral-large-2411": {
            "rating": 1098.0044820213789,
            "rating_q975": 1109.1712863376765,
            "rating_q025": 1086.8376777050812
        },
        "gpt-4-turbo-2024-04-09": {
            "rating": 1094.2205848142544,
            "rating_q975": 1106.7404135888714,
            "rating_q025": 1081.7007560396373
        },
        "gemini-1.5-pro-001": {
            "rating": 1087.1796842810304,
            "rating_q975": 1099.4499598896957,
            "rating_q025": 1074.909408672365
        },
        "gpt-4o-mini-2024-07-18": {
            "rating": 1070.293155925906,
            "rating_q975": 1079.4748773945767,
            "rating_q025": 1061.1114344572352
        },
        "qwen-vl-max-1119": {
            "rating": 1070.2764338646757,
            "rating_q975": 1091.400647415806,
            "rating_q025": 1049.1522203135455
        },
        "gpt-4o-2024-08-06": {
            "rating": 1069.6612171032123,
            "rating_q975": 1085.098309079135,
            "rating_q025": 1054.2241251272894
        },
        "step-1v-32k": {
            "rating": 1067.780542300014,
            "rating_q975": 1089.0216382968708,
            "rating_q025": 1046.5394463031573
        },
        "gemini-1.5-flash-8b-001": {
            "rating": 1067.7095559323166,
            "rating_q975": 1079.7693732429059,
            "rating_q025": 1055.6497386217272
        },
        "qwen2-vl-72b": {
            "rating": 1051.0007360197224,
            "rating_q975": 1062.901370354999,
            "rating_q025": 1039.1001016844457
        },
        "molmo-72b-0924": {
            "rating": 1042.6544902677324,
            "rating_q975": 1058.8200533978472,
            "rating_q025": 1026.4889271376176
        },
        "internvl2-26b": {
            "rating": 1034.8003234683072,
            "rating_q975": 1049.0751268445931,
            "rating_q025": 1020.5255200920212
        },
        "gemini-1.5-flash-001": {
            "rating": 1024.8508007814753,
            "rating_q975": 1037.5249442150894,
            "rating_q025": 1012.1766573478611
        },
        "pixtral-12b-2409": {
            "rating": 1024.2636681150339,
            "rating_q975": 1035.1637022190594,
            "rating_q025": 1013.3636340110082
        },
        "hunyuan-standard-vision-2024-12-31": {
            "rating": 1017.2942835671275,
            "rating_q975": 1044.718431059821,
            "rating_q025": 989.8701360744343
        },
        "claude-3-opus-20240229": {
            "rating": 1016.1077547148026,
            "rating_q975": 1028.046916971173,
            "rating_q025": 1004.1685924584322
        },
        "llama-3.2-vision-90b-instruct": {
            "rating": 1010.4729818980296,
            "rating_q975": 1021.1584028746054,
            "rating_q025": 999.7875609214539
        },
        "molmo-7b-d-0924": {
            "rating": 1009.2639376270054,
            "rating_q975": 1026.3306685903747,
            "rating_q025": 992.197206663636
        },
        "yi-vision": {
            "rating": 1005.0840548271859,
            "rating_q975": 1027.0652169144698,
            "rating_q025": 983.102892739902
        },
        "qwen2-vl-7b-instruct": {
            "rating": 1003.4077589550045,
            "rating_q975": 1015.7271618819535,
            "rating_q025": 991.0883560280555
        },
        "amazon-nova-lite-v1.0": {
            "rating": 996.3433601429638,
            "rating_q975": 1015.2161175448919,
            "rating_q025": 977.4706027410357
        },
        "c4ai-aya-vision-32b": {
            "rating": 995.8947694934992,
            "rating_q975": 1025.7079682829167,
            "rating_q025": 966.0815707040817
        },
        "llama-3.2-vision-11b-instruct": {
            "rating": 994.3075593337779,
            "rating_q975": 1007.7356318351954,
            "rating_q025": 980.8794868323605
        },
        "amazon-nova-pro-v1.0": {
            "rating": 984.9992870819596,
            "rating_q975": 1002.7549585654094,
            "rating_q025": 967.2436155985097
        },
        "internvl2-4b": {
            "rating": 983.3648948868838,
            "rating_q975": 998.3358424502431,
            "rating_q025": 968.3939473235245
        },
        "claude-3-sonnet-20240229": {
            "rating": 978.025808039152,
            "rating_q975": 990.6505202467723,
            "rating_q025": 965.4010958315317
        },
        "llava-v1.6-34b": {
            "rating": 967.971376225399,
            "rating_q975": 982.6415294361592,
            "rating_q025": 953.3012230146388
        },
        "cogvlm2-llama3-chat-19b": {
            "rating": 966.5439611124642,
            "rating_q975": 985.3792187451974,
            "rating_q025": 947.7087034797311
        },
        "llava-onevision-qwen2-72b-ov": {
            "rating": 959.4728060259357,
            "rating_q975": 980.6012658979455,
            "rating_q025": 938.3443461539259
        },
        "nvila-internal-15b-v1": {
            "rating": 956.4226187867752,
            "rating_q975": 981.9292399945821,
            "rating_q025": 930.9159975789682
        },
        "claude-3-haiku-20240307": {
            "rating": 946.4337225658936,
            "rating_q975": 960.0218124332573,
            "rating_q025": 932.8456326985299
        },
        "minicpm-v-2_6": {
            "rating": 946.3249322447049,
            "rating_q975": 964.8887468557459,
            "rating_q025": 927.7611176336638
        },
        "phi-3.5-vision-instruct": {
            "rating": 872.699511972465,
            "rating_q975": 891.0194133731214,
            "rating_q025": 854.3796105718085
        },
        "phi-3-vision-128k-instruct": {
            "rating": 834.7739956113227,
            "rating_q975": 857.0884351644801,
            "rating_q025": 812.4595560581653
        }
    },
    "entity_recognition": {
        "grok-4-0709": {
            "rating": 1296.6045949194872,
            "rating_q975": 1326.3088522249345,
            "rating_q025": 1266.90033761404
        },
        "gemini-2.5-pro": {
            "rating": 1280.6192371156303,
            "rating_q975": 1301.1654455041535,
            "rating_q025": 1260.0730287271072
        },
        "gpt-5-high": {
            "rating": 1256.8595868799675,
            "rating_q975": 1283.7954686626144,
            "rating_q025": 1229.9237050973206
        },
        "gemini-2.5-flash": {
            "rating": 1246.5086082586176,
            "rating_q975": 1272.0758727421276,
            "rating_q025": 1220.9413437751077
        },
        "chatgpt-4o-latest-20250326": {
            "rating": 1240.8569411648841,
            "rating_q975": 1275.0782231452656,
            "rating_q025": 1206.6356591845026
        },
        "o3-2025-04-16": {
            "rating": 1236.2830229281994,
            "rating_q975": 1260.1904020692816,
            "rating_q025": 1212.3756437871173
        },
        "gpt-5-chat": {
            "rating": 1220.4875142036617,
            "rating_q975": 1248.1604708566529,
            "rating_q025": 1192.8145575506705
        },
        "gpt-5-mini-high": {
            "rating": 1219.8491077903382,
            "rating_q975": 1249.7914916480015,
            "rating_q025": 1189.9067239326748
        },
        "o4-mini-2025-04-16": {
            "rating": 1213.4753599301473,
            "rating_q975": 1238.7363087601261,
            "rating_q025": 1188.2144111001685
        },
        "gpt-4.1-2025-04-14": {
            "rating": 1205.166166626802,
            "rating_q975": 1231.852969687199,
            "rating_q025": 1178.4793635664048
        },
        "gemma-3-27b-it": {
            "rating": 1193.4641976146777,
            "rating_q975": 1221.6040889961248,
            "rating_q025": 1165.3243062332306
        },
        "gemini-2.5-flash-lite-preview-06-17-thinking": {
            "rating": 1188.35,
            "rating_q975": 1213.9247766438937,
            "rating_q025": 1162.7752233561062
        },
        "gpt-4.1-mini-2025-04-14": {
            "rating": 1180.40099073885,
            "rating_q975": 1207.1539235526914,
            "rating_q025": 1153.6480579250085
        },
        "mistral-medium-2508": {
            "rating": 1164.172675247923,
            "rating_q975": 1194.0903927421916,
            "rating_q025": 1134.2549577536545
        },
        "mistral-small-3.1-24b-instruct-2503": {
            "rating": 1143.8747895623615,
            "rating_q975": 1179.166702671616,
            "rating_q025": 1108.582876453107
        },
        "mistral-medium-2505": {
            "rating": 1143.0177893230127,
            "rating_q975": 1177.797637828418,
            "rating_q025": 1108.2379408176075
        },
        "mistral-small-2506": {
            "rating": 1132.207596024211,
            "rating_q975": 1169.4950883542185,
            "rating_q025": 1094.9201036942034
        }
    },
    "full": {
        "gemini-3-pro": {
            "rating": 1330.1328842114663,
            "rating_q975": 1342.0801716878977,
            "rating_q025": 1318.1855967350348
        },
        "gemini-2.5-pro": {
            "rating": 1262.8186225639502,
            "rating_q975": 1269.94632843829,
            "rating_q025": 1255.6909166896103
        },
        "gemini-2.5-flash-preview-09-2025": {
            "rating": 1248.3894383636764,
            "rating_q975": 1258.6313423270212,
            "rating_q025": 1238.1475344003316
        },
        "gpt-5.1-high": {
            "rating": 1247.7271613979901,
            "rating_q975": 1262.4772033378038,
            "rating_q025": 1232.9771194581765
        },
        "qwen3-vl-235b-a22b-instruct": {
            "rating": 1241.4151699068661,
            "rating_q975": 1251.5493813522853,
            "rating_q025": 1231.280958461447
        },
        "chatgpt-4o-latest-20250326": {
            "rating": 1240.6444762166109,
            "rating_q975": 1247.41549806579,
            "rating_q025": 1233.8734543674318
        },
        "gemini-2.5-flash": {
            "rating": 1234.1492750628493,
            "rating_q975": 1241.3236152356476,
            "rating_q025": 1226.974934890051
        },
        "gpt-5.1": {
            "rating": 1233.442090079419,
            "rating_q975": 1247.7353555725954,
            "rating_q025": 1219.1488245862424
        },
        "gpt-5-chat": {
            "rating": 1229.7778497032386,
            "rating_q975": 1237.637743490408,
            "rating_q025": 1221.9179559160693
        },
        "ernie-5.0-preview-1120": {
            "rating": 1223.6129079188886,
            "rating_q975": 1236.3314434287684,
            "rating_q025": 1210.8943724090088
        },
        "hunyuan-vision-1.5-thinking": {
            "rating": 1217.301234157582,
            "rating_q975": 1229.3624070068101,
            "rating_q025": 1205.240061308354
        },
        "o3-2025-04-16": {
            "rating": 1212.4695266888587,
            "rating_q975": 1219.6300696745386,
            "rating_q025": 1205.3089837031787
        },
        "gpt-4.1-2025-04-14": {
            "rating": 1211.5492700222292,
            "rating_q975": 1218.7192776926745,
            "rating_q025": 1204.3792623517838
        },
        "qwen-vl-max-2025-08-13": {
            "rating": 1211.5359172122487,
            "rating_q975": 1223.6893485030848,
            "rating_q025": 1199.3824859214126
        },
        "gpt-5-high": {
            "rating": 1208.4701215868192,
            "rating_q975": 1216.4270962568144,
            "rating_q025": 1200.513146916824
        },
        "qwen3-vl-235b-a22b-thinking": {
            "rating": 1208.0283982338208,
            "rating_q975": 1220.387040918016,
            "rating_q025": 1195.6697555496255
        },
        "grok-4-0709": {
            "rating": 1206.4116850915977,
            "rating_q975": 1214.3109005958627,
            "rating_q025": 1198.5124695873328
        },
        "gemini-2.5-flash-lite-preview-09-2025-no-thinking": {
            "rating": 1204.6692995555225,
            "rating_q975": 1214.7186748975528,
            "rating_q025": 1194.6199242134921
        },
        "gpt-5-mini-high": {
            "rating": 1200.7514029174129,
            "rating_q975": 1209.119648517069,
            "rating_q025": 1192.3831573177567
        },
        "claude-opus-4-20250514-thinking-16k": {
            "rating": 1194.256856379378,
            "rating_q975": 1209.5477564722814,
            "rating_q025": 1178.9659562864745
        },
        "gpt-4.5-preview-2025-02-27": {
            "rating": 1193.7234438264124,
            "rating_q975": 1205.0696857625187,
            "rating_q025": 1182.3772018903062
        },
        "o4-mini-2025-04-16": {
            "rating": 1193.0435493925788,
            "rating_q975": 1200.6235107895764,
            "rating_q025": 1185.4635879955813
        },
        "claude-sonnet-4-20250514-thinking-32k": {
            "rating": 1190.919294449183,
            "rating_q975": 1206.7332597657532,
            "rating_q025": 1175.105329132613
        },
        "gemini-2.5-flash-lite-preview-06-17-thinking": {
            "rating": 1188.35,
            "rating_q975": 1196.3212861906923,
            "rating_q025": 1180.3787138093076
        },
        "step-1o-turbo-202506": {
            "rating": 1184.6202503057946,
            "rating_q975": 1198.7181035718208,
            "rating_q025": 1170.5223970397683
        },
        "hunyuan-large-vision": {
            "rating": 1182.4076656231662,
            "rating_q975": 1198.1502886678966,
            "rating_q025": 1166.6650425784358
        },
        "gpt-4.1-mini-2025-04-14": {
            "rating": 1181.4319689503557,
            "rating_q975": 1189.3276330587826,
            "rating_q025": 1173.5363048419288
        },
        "claude-opus-4-20250514": {
            "rating": 1175.8158891680298,
            "rating_q975": 1188.2380739557866,
            "rating_q025": 1163.393704380273
        },
        "step-3": {
            "rating": 1174.851865327111,
            "rating_q975": 1186.5801395367278,
            "rating_q025": 1163.1235911174942
        },
        "claude-sonnet-4-20250514": {
            "rating": 1173.7336537228095,
            "rating_q975": 1187.1258774403384,
            "rating_q025": 1160.3414300052807
        },
        "claude-3-7-sonnet-20250219-thinking-32k": {
            "rating": 1169.0861733399486,
            "rating_q975": 1183.8550765016814,
            "rating_q025": 1154.3172701782157
        },
        "mistral-medium-2508": {
            "rating": 1168.6141013725703,
            "rating_q975": 1176.7581774078499,
            "rating_q025": 1160.4700253372907
        },
        "o1-2024-12-17": {
            "rating": 1167.238244248386,
            "rating_q975": 1177.5815889859384,
            "rating_q025": 1156.8948995108337
        },
        "gemma-3-27b-it": {
            "rating": 1163.8913151185159,
            "rating_q975": 1172.3000710516087,
            "rating_q025": 1155.482559185423
        },
        "gemini-1.5-pro-002": {
            "rating": 1160.260558847968,
            "rating_q975": 1168.386098621056,
            "rating_q025": 1152.1350190748801
        },
        "gpt-5-nano-high": {
            "rating": 1159.0094503408163,
            "rating_q975": 1170.2959205699258,
            "rating_q025": 1147.7229801117069
        },
        "mistral-medium-2505": {
            "rating": 1157.7197134566054,
            "rating_q975": 1166.3149184429442,
            "rating_q025": 1149.1245084702666
        },
        "glm-4.5v": {
            "rating": 1156.9949041387167,
            "rating_q975": 1168.7432437883688,
            "rating_q025": 1145.2465644890647
        },
        "gemini-2.0-flash-001": {
            "rating": 1156.9722594324717,
            "rating_q975": 1164.0329358810352,
            "rating_q025": 1149.9115829839081
        },
        "qwen2.5-vl-32b-instruct": {
            "rating": 1151.1614005656902,
            "rating_q975": 1166.4437486471074,
            "rating_q025": 1135.879052484273
        },
        "claude-3-7-sonnet-20250219": {
            "rating": 1149.7150944542946,
            "rating_q975": 1158.8170033065014,
            "rating_q025": 1140.6131856020877
        },
        "llama-4-maverick-17b-128e-instruct": {
            "rating": 1142.5324221005458,
            "rating_q975": 1151.9039174539596,
            "rating_q025": 1133.160926747132
        },
        "mistral-small-2506": {
            "rating": 1141.5108050121435,
            "rating_q975": 1151.034844985483,
            "rating_q025": 1131.986765038804
        },
        "gemini-1.5-flash-002": {
            "rating": 1139.2953564753104,
            "rating_q975": 1148.347384123699,
            "rating_q025": 1130.243328826922
        },
        "gpt-4o-2024-05-13": {
            "rating": 1135.6006227688515,
            "rating_q975": 1143.3331212450678,
            "rating_q025": 1127.8681242926352
        },
        "mistral-small-3.1-24b-instruct-2503": {
            "rating": 1134.549203041667,
            "rating_q975": 1143.4169482794766,
            "rating_q025": 1125.6814578038573
        },
        "claude-3-5-sonnet-20241022": {
            "rating": 1124.291206264697,
            "rating_q975": 1131.32003635363,
            "rating_q025": 1117.2623761757638
        },
        "step-1o-vision-32k-highres": {
            "rating": 1120.8092624863841,
            "rating_q975": 1132.8765803639642,
            "rating_q025": 1108.741944608804
        },
        "claude-3-5-sonnet-20240620": {
            "rating": 1119.4621118737705,
            "rating_q975": 1128.6409599200579,
            "rating_q025": 1110.283263827483
        },
        "llama-4-scout-17b-16e-instruct": {
            "rating": 1117.061562158595,
            "rating_q975": 1126.783412579851,
            "rating_q025": 1107.339711737339
        },
        "qwen2.5-vl-72b-instruct": {
            "rating": 1106.4759219226642,
            "rating_q975": 1116.8255585382158,
            "rating_q025": 1096.1262853071125
        },
        "gemini-2.0-flash-lite-preview-02-05": {
            "rating": 1099.3541048134716,
            "rating_q975": 1109.289286116363,
            "rating_q025": 1089.4189235105803
        },
        "claude-3-5-haiku-20241022": {
            "rating": 1099.0371386453792,
            "rating_q975": 1114.383187456064,
            "rating_q025": 1083.6910898346944
        },
        "gpt-4-turbo-2024-04-09": {
            "rating": 1088.9393789892097,
            "rating_q975": 1099.803051437398,
            "rating_q025": 1078.0757065410214
        },
        "pixtral-large-2411": {
            "rating": 1088.5109208525505,
            "rating_q975": 1097.029957237667,
            "rating_q025": 1079.991884467434
        },
        "gemini-1.5-pro-001": {
            "rating": 1087.4764194002018,
            "rating_q975": 1098.40236218383,
            "rating_q025": 1076.5504766165736
        },
        "gpt-4o-mini-2024-07-18": {
            "rating": 1064.998937961893,
            "rating_q975": 1072.2941933187865,
            "rating_q025": 1057.7036826049996
        },
        "gpt-4o-2024-08-06": {
            "rating": 1063.7135671665126,
            "rating_q975": 1075.5309015318057,
            "rating_q025": 1051.8962328012194
        },
        "gpt-4.1-nano-2025-04-14": {
            "rating": 1062.1739310120934,
            "rating_q975": 1080.45983915103,
            "rating_q025": 1043.8880228731566
        },
        "qwen-vl-max-1119": {
            "rating": 1056.94978444333,
            "rating_q975": 1072.6513134832587,
            "rating_q025": 1041.2482554034011
        },
        "qwen2-vl-72b": {
            "rating": 1045.7676846199827,
            "rating_q975": 1055.1308788430554,
            "rating_q025": 1036.40449039691
        },
        "step-1v-32k": {
            "rating": 1043.5991622359895,
            "rating_q975": 1059.8035412956199,
            "rating_q025": 1027.3947831763592
        },
        "gemini-1.5-flash-8b-001": {
            "rating": 1043.1144557313748,
            "rating_q975": 1052.9193013609536,
            "rating_q025": 1033.3096101017961
        },
        "claude-3-opus-20240229": {
            "rating": 1021.9289950728814,
            "rating_q975": 1031.4308915021868,
            "rating_q025": 1012.4270986435761
        },
        "molmo-72b-0924": {
            "rating": 1011.4625553582348,
            "rating_q975": 1023.9133012618017,
            "rating_q025": 999.0118094546679
        },
        "pixtral-12b-2409": {
            "rating": 1007.5663991104768,
            "rating_q975": 1016.2184911763921,
            "rating_q025": 998.9143070445615
        },
        "gemini-1.5-flash-001": {
            "rating": 1007.1834945073703,
            "rating_q975": 1018.3323656272084,
            "rating_q025": 996.0346233875321
        },
        "internvl2-26b": {
            "rating": 1003.6061098143425,
            "rating_q975": 1015.7754619753209,
            "rating_q025": 991.4367576533641
        },
        "llama-3.2-vision-90b-instruct": {
            "rating": 998.6721485599091,
            "rating_q975": 1006.9760240687383,
            "rating_q025": 990.36827305108
        },
        "hunyuan-standard-vision-2024-12-31": {
            "rating": 998.0307727004769,
            "rating_q975": 1019.2558680857285,
            "rating_q025": 976.8056773152252
        },
        "c4ai-aya-vision-32b": {
            "rating": 994.3747633688035,
            "rating_q975": 1016.25807702347,
            "rating_q025": 972.491449714137
        },
        "amazon-nova-lite-v1.0": {
            "rating": 989.4277548054915,
            "rating_q975": 1003.8929697702566,
            "rating_q025": 974.9625398407264
        },
        "qwen2-vl-7b-instruct": {
            "rating": 988.9527626905622,
            "rating_q975": 998.669965638675,
            "rating_q025": 979.2355597424494
        },
        "claude-3-sonnet-20240229": {
            "rating": 983.0569682389252,
            "rating_q975": 993.7502154732899,
            "rating_q025": 972.3637210045604
        },
        "amazon-nova-pro-v1.0": {
            "rating": 979.7434153086626,
            "rating_q975": 993.0329286453693,
            "rating_q025": 966.4539019719559
        },
        "yi-vision": {
            "rating": 977.4615042193446,
            "rating_q975": 995.1837059704898,
            "rating_q025": 959.7393024681995
        },
        "llama-3.2-vision-11b-instruct": {
            "rating": 965.3607102554761,
            "rating_q975": 975.9430619328953,
            "rating_q025": 954.7783585780569
        },
        "molmo-7b-d-0924": {
            "rating": 957.5881094166344,
            "rating_q975": 970.7857508903794,
            "rating_q025": 944.3904679428895
        },
        "claude-3-haiku-20240307": {
            "rating": 949.2086011460274,
            "rating_q975": 961.0566644772509,
            "rating_q025": 937.3605378148038
        },
        "internvl2-4b": {
            "rating": 940.5282979959914,
            "rating_q975": 952.3771225958247,
            "rating_q025": 928.679473396158
        },
        "nvila-internal-15b-v1": {
            "rating": 939.0251226157784,
            "rating_q975": 958.5756660329874,
            "rating_q025": 919.4745791985694
        },
        "llava-v1.6-34b": {
            "rating": 935.567484033679,
            "rating_q975": 947.2059247291427,
            "rating_q025": 923.9290433382153
        },
        "cogvlm2-llama3-chat-19b": {
            "rating": 926.6595253731056,
            "rating_q975": 941.4411573935215,
            "rating_q025": 911.8778933526896
        },
        "llava-onevision-qwen2-72b-ov": {
            "rating": 922.0336354762012,
            "rating_q975": 939.6335570257497,
            "rating_q025": 904.4337139266527
        },
        "minicpm-v-2_6": {
            "rating": 910.7432567637992,
            "rating_q975": 926.2667553447782,
            "rating_q025": 895.2197581828202
        },
        "phi-3.5-vision-instruct": {
            "rating": 850.698748897664,
            "rating_q975": 865.9955483800716,
            "rating_q025": 835.4019494152565
        },
        "phi-3-vision-128k-instruct": {
            "rating": 810.8594761758181,
            "rating_q975": 829.2725966209603,
            "rating_q025": 792.446355730676
        }
    },
    "homework": {
        "gemini-3-pro": {
            "rating": 1341.3678745946,
            "rating_q975": 1365.3993351382426,
            "rating_q025": 1317.3364140509573
        },
        "hunyuan-vision-1.5-thinking": {
            "rating": 1304.8012361588653,
            "rating_q975": 1333.2930580227353,
            "rating_q025": 1276.3094142949953
        },
        "gpt-5-chat": {
            "rating": 1282.6096039670656,
            "rating_q975": 1297.746886315218,
            "rating_q025": 1267.4723216189132
        },
        "gemini-2.5-pro": {
            "rating": 1279.4499751001185,
            "rating_q975": 1291.504304242196,
            "rating_q025": 1267.395645958041
        },
        "qwen-vl-max-2025-08-13": {
            "rating": 1276.3160706371445,
            "rating_q975": 1313.7376835791297,
            "rating_q025": 1238.8944576951594
        },
        "gemini-2.5-flash-preview-09-2025": {
            "rating": 1272.9726885224968,
            "rating_q975": 1293.9432558170015,
            "rating_q025": 1252.0021212279921
        },
        "gpt-5.1-high": {
            "rating": 1260.59752196621,
            "rating_q975": 1295.9827309894197,
            "rating_q025": 1225.2123129430004
        },
        "qwen3-vl-235b-a22b-instruct": {
            "rating": 1258.8509422296809,
            "rating_q975": 1279.7626850409351,
            "rating_q025": 1237.9391994184266
        },
        "ernie-5.0-preview-1120": {
            "rating": 1252.7508769006672,
            "rating_q975": 1284.4677946197698,
            "rating_q025": 1221.0339591815646
        },
        "gpt-5.1": {
            "rating": 1248.7687438782787,
            "rating_q975": 1283.0039022424185,
            "rating_q025": 1214.5335855141388
        },
        "chatgpt-4o-latest-20250326": {
            "rating": 1246.5948124099582,
            "rating_q975": 1261.2486798363639,
            "rating_q025": 1231.9409449835525
        },
        "gemini-2.5-flash": {
            "rating": 1239.9162198538916,
            "rating_q975": 1252.5887237392992,
            "rating_q025": 1227.243715968484
        },
        "gpt-4.1-2025-04-14": {
            "rating": 1239.2344040039484,
            "rating_q975": 1253.2014571605903,
            "rating_q025": 1225.2673508473065
        },
        "qwen3-vl-235b-a22b-thinking": {
            "rating": 1236.1932795333687,
            "rating_q975": 1263.832114463609,
            "rating_q025": 1208.5544446031283
        },
        "claude-opus-4-20250514-thinking-16k": {
            "rating": 1234.6908219897105,
            "rating_q975": 1274.1757892685605,
            "rating_q025": 1195.2058547108604
        },
        "o4-mini-2025-04-16": {
            "rating": 1233.4052193785556,
            "rating_q975": 1247.123392522256,
            "rating_q025": 1219.6870462348552
        },
        "o3-2025-04-16": {
            "rating": 1232.3058135408523,
            "rating_q975": 1245.0730377142693,
            "rating_q025": 1219.5385893674354
        },
        "gpt-5-high": {
            "rating": 1224.7230081842813,
            "rating_q975": 1239.992554504596,
            "rating_q025": 1209.4534618639666
        },
        "claude-sonnet-4-20250514": {
            "rating": 1219.3762130767227,
            "rating_q975": 1250.8718418175158,
            "rating_q025": 1187.8805843359296
        },
        "gpt-4.1-mini-2025-04-14": {
            "rating": 1216.0830091129096,
            "rating_q975": 1230.8467907659908,
            "rating_q025": 1201.3192274598284
        },
        "claude-opus-4-20250514": {
            "rating": 1216.0801962167943,
            "rating_q975": 1245.3795010228664,
            "rating_q025": 1186.7808914107222
        },
        "gpt-5-mini-high": {
            "rating": 1211.3779889748332,
            "rating_q975": 1228.5874585846793,
            "rating_q025": 1194.168519364987
        },
        "gemini-2.5-flash-lite-preview-09-2025-no-thinking": {
            "rating": 1210.0516816973618,
            "rating_q975": 1230.1728556389298,
            "rating_q025": 1189.9305077557938
        },
        "claude-3-7-sonnet-20250219": {
            "rating": 1199.7160162376254,
            "rating_q975": 1231.514087315538,
            "rating_q025": 1167.9179451597126
        },
        "claude-3-7-sonnet-20250219-thinking-32k": {
            "rating": 1193.7160725783733,
            "rating_q975": 1230.8223956030422,
            "rating_q025": 1156.6097495537044
        },
        "gemini-2.5-flash-lite-preview-06-17-thinking": {
            "rating": 1188.35,
            "rating_q975": 1202.7245545855374,
            "rating_q025": 1173.9754454144625
        },
        "step-3": {
            "rating": 1187.651398410112,
            "rating_q975": 1221.5328627810595,
            "rating_q025": 1153.7699340391646
        },
        "gemini-2.0-flash-001": {
            "rating": 1180.589299823749,
            "rating_q975": 1200.2592541715517,
            "rating_q025": 1160.919345475946
        },
        "mistral-medium-2508": {
            "rating": 1175.2408876857803,
            "rating_q975": 1191.6029975692707,
            "rating_q025": 1158.87877780229
        },
        "mistral-small-2506": {
            "rating": 1169.1278762086858,
            "rating_q975": 1189.6514104746825,
            "rating_q025": 1148.6043419426892
        },
        "gemma-3-27b-it": {
            "rating": 1167.048627209339,
            "rating_q975": 1183.3738841605834,
            "rating_q025": 1150.7233702580945
        },
        "llama-4-maverick-17b-128e-instruct": {
            "rating": 1166.5230888006026,
            "rating_q975": 1188.0518166212469,
            "rating_q025": 1144.9943609799584
        },
        "glm-4.5v": {
            "rating": 1166.0976853964025,
            "rating_q975": 1200.6994360834228,
            "rating_q025": 1131.4959347093823
        },
        "grok-4-0709": {
            "rating": 1162.3656866942279,
            "rating_q975": 1178.7115675013217,
            "rating_q025": 1146.019805887134
        },
        "mistral-medium-2505": {
            "rating": 1161.2623079631198,
            "rating_q975": 1179.2153781281359,
            "rating_q025": 1143.3092377981038
        },
        "step-1o-turbo-202506": {
            "rating": 1161.2026493398125,
            "rating_q975": 1192.911326284982,
            "rating_q025": 1129.4939723946432
        },
        "mistral-small-3.1-24b-instruct-2503": {
            "rating": 1155.4706143421772,
            "rating_q975": 1173.6925016060366,
            "rating_q025": 1137.2487270783179
        },
        "llama-4-scout-17b-16e-instruct": {
            "rating": 1152.0888236257929,
            "rating_q975": 1175.107311456441,
            "rating_q025": 1129.0703357951447
        },
        "gpt-5-nano-high": {
            "rating": 1148.1792671990618,
            "rating_q975": 1179.1916162095963,
            "rating_q025": 1117.1669181885272
        },
        "hunyuan-large-vision": {
            "rating": 1146.2451894065591,
            "rating_q975": 1185.9388800015347,
            "rating_q025": 1106.5514988115835
        },
        "claude-3-5-sonnet-20241022": {
            "rating": 1144.2140414601984,
            "rating_q975": 1178.0911498236628,
            "rating_q025": 1110.336933096734
        },
        "claude-3-5-haiku-20241022": {
            "rating": 1125.5536751473956,
            "rating_q975": 1158.955604797155,
            "rating_q025": 1092.151745497636
        }
    },
    "humor": {
        "gemini-3-pro": {
            "rating": 1394.1319695196414,
            "rating_q975": 1430.3418277742726,
            "rating_q025": 1357.9221112650102
        },
        "gemini-2.5-flash-preview-09-2025": {
            "rating": 1272.4599036599802,
            "rating_q975": 1306.22455160304,
            "rating_q025": 1238.6952557169204
        },
        "gemini-2.5-pro": {
            "rating": 1249.4336726937593,
            "rating_q975": 1263.6656845473706,
            "rating_q025": 1235.201660840148
        },
        "chatgpt-4o-latest-20250326": {
            "rating": 1243.2575046271807,
            "rating_q975": 1266.9193981072137,
            "rating_q025": 1219.5956111471476
        },
        "gpt-5-chat": {
            "rating": 1226.0572396095383,
            "rating_q975": 1242.8993031641055,
            "rating_q025": 1209.2151760549712
        },
        "o3-2025-04-16": {
            "rating": 1223.3191983144568,
            "rating_q975": 1238.5122458739024,
            "rating_q025": 1208.1261507550112
        },
        "gemini-2.5-flash": {
            "rating": 1221.417534910514,
            "rating_q975": 1237.721151245331,
            "rating_q025": 1205.113918575697
        },
        "grok-4-0709": {
            "rating": 1211.8995186488635,
            "rating_q975": 1229.3061113234528,
            "rating_q025": 1194.4929259742742
        },
        "gpt-5-high": {
            "rating": 1206.5514529904326,
            "rating_q975": 1223.9398196182756,
            "rating_q025": 1189.1630863625896
        },
        "qwen3-vl-235b-a22b-instruct": {
            "rating": 1206.4297976586367,
            "rating_q975": 1242.1667556222358,
            "rating_q025": 1170.6928396950377
        },
        "gpt-4.1-2025-04-14": {
            "rating": 1203.0527488907633,
            "rating_q975": 1219.8514468193969,
            "rating_q025": 1186.2540509621297
        },
        "o4-mini-2025-04-16": {
            "rating": 1192.8922391046813,
            "rating_q975": 1209.4995433784084,
            "rating_q025": 1176.2849348309542
        },
        "gemini-2.5-flash-lite-preview-06-17-thinking": {
            "rating": 1188.35,
            "rating_q975": 1205.03397756206,
            "rating_q025": 1171.6660224379398
        },
        "gpt-5-mini-high": {
            "rating": 1185.1963997292214,
            "rating_q975": 1204.5322130827553,
            "rating_q025": 1165.8605863756875
        },
        "gpt-4.1-mini-2025-04-14": {
            "rating": 1177.5199993300157,
            "rating_q975": 1194.2683237979818,
            "rating_q025": 1160.7716748620496
        },
        "gemini-2.5-flash-lite-preview-09-2025-no-thinking": {
            "rating": 1175.280393685815,
            "rating_q975": 1209.6576208331144,
            "rating_q025": 1140.9031665385155
        },
        "mistral-medium-2508": {
            "rating": 1171.494359453552,
            "rating_q975": 1189.4679670876317,
            "rating_q025": 1153.5207518194725
        },
        "gemini-2.0-flash-001": {
            "rating": 1165.6434768823449,
            "rating_q975": 1203.4398049014942,
            "rating_q025": 1127.8471488631956
        },
        "gemma-3-27b-it": {
            "rating": 1159.415185338913,
            "rating_q975": 1180.3309693733431,
            "rating_q025": 1138.499401304483
        },
        "mistral-medium-2505": {
            "rating": 1145.9555098968008,
            "rating_q975": 1173.103152373051,
            "rating_q025": 1118.8078674205506
        },
        "mistral-small-3.1-24b-instruct-2503": {
            "rating": 1128.6800362903737,
            "rating_q975": 1149.499035285495,
            "rating_q025": 1107.8610372952523
        },
        "mistral-small-2506": {
            "rating": 1104.6032030304493,
            "rating_q975": 1133.5731689131526,
            "rating_q025": 1075.633237147746
        },
        "llama-4-maverick-17b-128e-instruct": {
            "rating": 1096.029126143973,
            "rating_q975": 1132.6890681254174,
            "rating_q025": 1059.3691841625284
        },
        "llama-4-scout-17b-16e-instruct": {
            "rating": 1082.4851161996728,
            "rating_q975": 1122.380822983494,
            "rating_q025": 1042.5894094158516
        }
    },
    "ocr": {
        "gemini-3-pro": {
            "rating": 1330.5455736567285,
            "rating_q975": 1344.1171302316961,
            "rating_q025": 1316.9740170817608
        },
        "gemini-2.5-pro": {
            "rating": 1273.7033723022214,
            "rating_q975": 1280.7234284685574,
            "rating_q025": 1266.6833161358854
        },
        "gemini-2.5-flash-preview-09-2025": {
            "rating": 1255.9636056429513,
            "rating_q975": 1267.0704507092883,
            "rating_q025": 1244.8567605766143
        },
        "gpt-5.1": {
            "rating": 1251.7795621910059,
            "rating_q975": 1268.964812367381,
            "rating_q025": 1234.5943120146308
        },
        "gpt-5.1-high": {
            "rating": 1250.1437304129083,
            "rating_q975": 1267.4341956478756,
            "rating_q025": 1232.853265177941
        },
        "qwen3-vl-235b-a22b-instruct": {
            "rating": 1249.104179326194,
            "rating_q975": 1260.2497604294379,
            "rating_q025": 1237.9585982229503
        },
        "chatgpt-4o-latest-20250326": {
            "rating": 1246.1206606087717,
            "rating_q975": 1254.1084929102265,
            "rating_q025": 1238.132828307317
        },
        "gpt-5-chat": {
            "rating": 1242.355752287089,
            "rating_q975": 1250.8958240596464,
            "rating_q025": 1233.8156805145316
        },
        "gemini-2.5-flash": {
            "rating": 1237.528506416146,
            "rating_q975": 1244.8462027578719,
            "rating_q025": 1230.2108100744201
        },
        "ernie-5.0-preview-1120": {
            "rating": 1234.1194836976724,
            "rating_q975": 1248.867685746374,
            "rating_q025": 1219.3712816489708
        },
        "qwen-vl-max-2025-08-13": {
            "rating": 1230.7590495537067,
            "rating_q975": 1247.6173662883973,
            "rating_q025": 1213.9007328190162
        },
        "gpt-4.1-2025-04-14": {
            "rating": 1218.7871217884122,
            "rating_q975": 1226.7462753246514,
            "rating_q025": 1210.827968252173
        },
        "o3-2025-04-16": {
            "rating": 1217.226166360671,
            "rating_q975": 1224.5313704063476,
            "rating_q025": 1209.9209623149943
        },
        "gpt-5-high": {
            "rating": 1215.4230050885908,
            "rating_q975": 1224.113949862546,
            "rating_q025": 1206.7320603146356
        },
        "qwen3-vl-235b-a22b-thinking": {
            "rating": 1214.8074759129886,
            "rating_q975": 1229.5428999240235,
            "rating_q025": 1200.0720519019537
        },
        "hunyuan-vision-1.5-thinking": {
            "rating": 1208.0091007653755,
            "rating_q975": 1222.6446903615492,
            "rating_q025": 1193.3735111692017
        },
        "claude-opus-4-20250514-thinking-16k": {
            "rating": 1206.0977243560424,
            "rating_q975": 1224.9533185078371,
            "rating_q025": 1187.2421302042476
        },
        "gemini-2.5-flash-lite-preview-09-2025-no-thinking": {
            "rating": 1205.8881302769264,
            "rating_q975": 1216.7943831511427,
            "rating_q025": 1194.98187740271
        },
        "gpt-5-mini-high": {
            "rating": 1201.1552285250507,
            "rating_q975": 1210.6303294422219,
            "rating_q025": 1191.6801276078795
        },
        "claude-sonnet-4-20250514-thinking-32k": {
            "rating": 1199.3838222910179,
            "rating_q975": 1219.1235806158563,
            "rating_q025": 1179.6440639661794
        },
        "o4-mini-2025-04-16": {
            "rating": 1195.8372077838137,
            "rating_q975": 1203.7656185656915,
            "rating_q025": 1187.908797001936
        },
        "grok-4-0709": {
            "rating": 1190.6724104047066,
            "rating_q975": 1198.9631596351594,
            "rating_q025": 1182.3816611742538
        },
        "gpt-4.1-mini-2025-04-14": {
            "rating": 1188.7057274724277,
            "rating_q975": 1197.247756085205,
            "rating_q025": 1180.1636988596504
        },
        "gemini-2.5-flash-lite-preview-06-17-thinking": {
            "rating": 1188.35,
            "rating_q975": 1196.6123121582987,
            "rating_q025": 1180.0876878417012
        },
        "claude-3-7-sonnet-20250219-thinking-32k": {
            "rating": 1184.6651948604786,
            "rating_q975": 1202.8914950489677,
            "rating_q025": 1166.4388946719894
        },
        "step-1o-turbo-202506": {
            "rating": 1178.560638761429,
            "rating_q975": 1194.270901212986,
            "rating_q025": 1162.8503763098718
        },
        "claude-opus-4-20250514": {
            "rating": 1178.4577379211823,
            "rating_q975": 1193.5266835341772,
            "rating_q025": 1163.3887923081875
        },
        "claude-sonnet-4-20250514": {
            "rating": 1172.7748800746185,
            "rating_q975": 1188.9723625467448,
            "rating_q025": 1156.5773976024923
        },
        "mistral-medium-2508": {
            "rating": 1170.3611898838913,
            "rating_q975": 1179.496957419789,
            "rating_q025": 1161.2254223479936
        },
        "hunyuan-large-vision": {
            "rating": 1168.3876223427656,
            "rating_q975": 1187.1485102987442,
            "rating_q025": 1149.626734386787
        },
        "step-3": {
            "rating": 1165.2409493808195,
            "rating_q975": 1181.2048110939677,
            "rating_q025": 1149.2770876676714
        },
        "claude-3-7-sonnet-20250219": {
            "rating": 1157.8159685000883,
            "rating_q975": 1175.7868892210467,
            "rating_q025": 1139.8450477791298
        },
        "gemma-3-27b-it": {
            "rating": 1156.765268090549,
            "rating_q975": 1165.7441537222435,
            "rating_q025": 1147.7863824588544
        },
        "mistral-medium-2505": {
            "rating": 1153.9489420964771,
            "rating_q975": 1163.5196872656109,
            "rating_q025": 1144.3781969273434
        },
        "glm-4.5v": {
            "rating": 1150.4119411278175,
            "rating_q975": 1166.2869606393542,
            "rating_q025": 1134.5369216162808
        },
        "gemini-2.0-flash-001": {
            "rating": 1148.4488562250103,
            "rating_q975": 1159.1488016255166,
            "rating_q025": 1137.748910824504
        },
        "gpt-5-nano-high": {
            "rating": 1146.0921742102632,
            "rating_q975": 1160.2937123184367,
            "rating_q025": 1131.8906361020897
        },
        "llama-4-maverick-17b-128e-instruct": {
            "rating": 1145.189325762584,
            "rating_q975": 1156.058181955812,
            "rating_q025": 1134.3204695693562
        },
        "claude-3-5-sonnet-20241022": {
            "rating": 1141.5012318521863,
            "rating_q975": 1159.3385783183885,
            "rating_q025": 1123.663885385984
        },
        "mistral-small-3.1-24b-instruct-2503": {
            "rating": 1134.1078571818316,
            "rating_q975": 1143.770375948474,
            "rating_q025": 1124.445338415189
        },
        "mistral-small-2506": {
            "rating": 1133.7284030218636,
            "rating_q975": 1144.1661541923493,
            "rating_q025": 1123.290651851378
        },
        "llama-4-scout-17b-16e-instruct": {
            "rating": 1118.412295903408,
            "rating_q975": 1129.9851811236797,
            "rating_q025": 1106.8394106831363
        },
        "claude-3-5-haiku-20241022": {
            "rating": 1100.1120807137559,
            "rating_q975": 1118.522324905623,
            "rating_q025": 1081.7018365218887
        }
    }
}