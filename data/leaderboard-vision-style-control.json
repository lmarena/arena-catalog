{
    "chinese": {
        "gemini-2.5-pro": {
            "rating": 1311.3910764505956,
            "rating_q975": 1345.6928662037287,
            "rating_q025": 1277.0892866974625
        },
        "gpt-5-chat": {
            "rating": 1302.951652961434,
            "rating_q975": 1344.9406455619617,
            "rating_q025": 1260.9626603609063
        },
        "o1-2024-12-17": {
            "rating": 1286.9648293944272,
            "rating_q975": 1344.272904423158,
            "rating_q025": 1229.6567543656963
        },
        "o3-2025-04-16": {
            "rating": 1274.655206105105,
            "rating_q975": 1307.9753156192028,
            "rating_q025": 1241.3350965910072
        },
        "chatgpt-4o-latest-20250326": {
            "rating": 1273.6931714010443,
            "rating_q975": 1309.158780920573,
            "rating_q025": 1238.2275618815156
        },
        "gpt-4.1-2025-04-14": {
            "rating": 1264.771965495645,
            "rating_q975": 1296.899835625427,
            "rating_q025": 1232.644095365863
        },
        "gpt-4.1-mini-2025-04-14": {
            "rating": 1262.008196193399,
            "rating_q975": 1294.8206706922665,
            "rating_q025": 1229.1957216945316
        },
        "o4-mini-2025-04-16": {
            "rating": 1261.685525732719,
            "rating_q975": 1298.639674154631,
            "rating_q025": 1224.7313773108071
        },
        "gemini-2.5-flash": {
            "rating": 1261.3575333935298,
            "rating_q975": 1296.073307858377,
            "rating_q025": 1226.6417589286827
        },
        "gpt-5-high": {
            "rating": 1246.171837623785,
            "rating_q975": 1288.2602350212787,
            "rating_q025": 1204.0834402262913
        },
        "grok-4-0709": {
            "rating": 1235.0386968893497,
            "rating_q975": 1273.9766961569003,
            "rating_q025": 1196.1006976217989
        },
        "gpt-4.5-preview-2025-02-27": {
            "rating": 1227.1112997793905,
            "rating_q975": 1288.4167972491236,
            "rating_q025": 1165.8058023096573
        },
        "gpt-5-mini-high": {
            "rating": 1226.9366162686256,
            "rating_q975": 1274.1312827642782,
            "rating_q025": 1179.741949772973
        },
        "gemini-1.5-pro-002": {
            "rating": 1220.4564938236877,
            "rating_q975": 1254.9417996600037,
            "rating_q025": 1185.9711879873716
        },
        "claude-3-7-sonnet-20250219": {
            "rating": 1204.0752597125452,
            "rating_q975": 1254.008379718911,
            "rating_q025": 1154.1421397061793
        },
        "mistral-medium-2508": {
            "rating": 1192.186171262935,
            "rating_q975": 1241.0578157198495,
            "rating_q025": 1143.3145268060207
        },
        "mistral-medium-2505": {
            "rating": 1188.4077252669833,
            "rating_q975": 1224.1736350804574,
            "rating_q025": 1152.6418154535095
        },
        "gemma-3-27b-it": {
            "rating": 1187.063761301678,
            "rating_q975": 1226.8900899475586,
            "rating_q025": 1147.2374326557972
        },
        "claude-3-5-sonnet-20241022": {
            "rating": 1185.089623372306,
            "rating_q975": 1214.649340583519,
            "rating_q025": 1155.5299061610929
        },
        "mistral-small-3.1-24b-instruct-2503": {
            "rating": 1181.4163252725132,
            "rating_q975": 1218.4329991619102,
            "rating_q025": 1144.399651383116
        },
        "gemini-2.0-flash-001": {
            "rating": 1178.3999874226793,
            "rating_q975": 1217.7329532232031,
            "rating_q025": 1139.0670216221552
        },
        "gpt-4o-2024-05-13": {
            "rating": 1177.1258180935629,
            "rating_q975": 1203.4947145845767,
            "rating_q025": 1150.7569216025488
        },
        "llama-4-maverick-17b-128e-instruct": {
            "rating": 1163.4439664808128,
            "rating_q975": 1207.0352835784854,
            "rating_q025": 1119.85264938314
        },
        "qwen2.5-vl-72b-instruct": {
            "rating": 1148.8420358499861,
            "rating_q975": 1199.8894037231405,
            "rating_q025": 1097.7946679768318
        },
        "mistral-small-2506": {
            "rating": 1147.615727695575,
            "rating_q975": 1188.0955239466825,
            "rating_q025": 1107.1359314444674
        },
        "gemini-1.5-flash-002": {
            "rating": 1147.0187895545732,
            "rating_q975": 1181.999723952273,
            "rating_q025": 1112.0378551568735
        },
        "claude-3-5-sonnet-20240620": {
            "rating": 1144.824304534009,
            "rating_q975": 1172.6404153833355,
            "rating_q025": 1117.0081936846823
        },
        "llama-4-scout-17b-16e-instruct": {
            "rating": 1142.2741778659965,
            "rating_q975": 1190.48131028237,
            "rating_q025": 1094.0670454496233
        },
        "qwen2-vl-72b": {
            "rating": 1131.4759195837669,
            "rating_q975": 1167.8918253869276,
            "rating_q025": 1095.0600137806064
        },
        "pixtral-large-2411": {
            "rating": 1118.6471799829276,
            "rating_q975": 1165.308686176465,
            "rating_q025": 1071.9856737893901
        },
        "internvl2-26b": {
            "rating": 1102.3393084732688,
            "rating_q975": 1141.5829025690894,
            "rating_q025": 1063.0957143774478
        },
        "gpt-4o-mini-2024-07-18": {
            "rating": 1102.085329978232,
            "rating_q975": 1129.0900893554394,
            "rating_q025": 1075.0805706010246
        },
        "gpt-4o-2024-08-06": {
            "rating": 1098.2252012922,
            "rating_q975": 1141.8818883648655,
            "rating_q025": 1054.568514219534
        },
        "gemini-2.0-flash-lite-preview-02-05": {
            "rating": 1096.3565565526724,
            "rating_q975": 1152.9053906057597,
            "rating_q025": 1039.807722499585
        },
        "gemini-1.5-pro-001": {
            "rating": 1090.4697863676818,
            "rating_q975": 1119.488961349255,
            "rating_q025": 1061.4506113861084
        },
        "gpt-4-turbo-2024-04-09": {
            "rating": 1085.5831779639564,
            "rating_q975": 1115.1144242013033,
            "rating_q025": 1056.0519317266094
        },
        "qwen2-vl-7b-instruct": {
            "rating": 1059.4870862245093,
            "rating_q975": 1097.1074092589465,
            "rating_q025": 1021.8667631900721
        },
        "claude-3-opus-20240229": {
            "rating": 1049.4544786807846,
            "rating_q975": 1079.1401026354868,
            "rating_q025": 1019.7688547260822
        },
        "gemini-1.5-flash-001": {
            "rating": 1048.2624064700985,
            "rating_q975": 1078.4167963671662,
            "rating_q025": 1018.1080165730309
        },
        "gemini-1.5-flash-8b-001": {
            "rating": 1035.1682150761642,
            "rating_q975": 1071.3393688669244,
            "rating_q025": 998.997061285404
        },
        "llama-3.2-vision-90b-instruct": {
            "rating": 1026.402599471101,
            "rating_q975": 1060.652403543645,
            "rating_q025": 992.1527953985569
        },
        "molmo-72b-0924": {
            "rating": 1009.1434488733784,
            "rating_q975": 1056.5921400102773,
            "rating_q025": 961.6947577364796
        },
        "claude-3-sonnet-20240229": {
            "rating": 1005.8939961162829,
            "rating_q975": 1036.0964574663471,
            "rating_q025": 975.6915347662186
        },
        "claude-3-haiku-20240307": {
            "rating": 1000.0,
            "rating_q975": 1030.2132188625758,
            "rating_q025": 969.7867811374241
        },
        "internvl2-4b": {
            "rating": 992.2150436548777,
            "rating_q975": 1040.4886293647971,
            "rating_q025": 943.9414579449582
        },
        "pixtral-12b-2409": {
            "rating": 988.6754103851366,
            "rating_q975": 1024.865722200417,
            "rating_q025": 952.4850985698563
        },
        "molmo-7b-d-0924": {
            "rating": 978.7147919243615,
            "rating_q975": 1027.6714531132839,
            "rating_q025": 929.7581307354391
        },
        "llava-v1.6-34b": {
            "rating": 976.6473617546942,
            "rating_q975": 1014.0619076994592,
            "rating_q025": 939.2328158099292
        },
        "llama-3.2-vision-11b-instruct": {
            "rating": 968.8306655551931,
            "rating_q975": 1010.9508529960201,
            "rating_q025": 926.7104781143662
        }
    },
    "english": {
        "gemini-2.5-pro": {
            "rating": 1255.8273072460886,
            "rating_q975": 1269.368395517642,
            "rating_q025": 1242.2862189745351
        },
        "gpt-5-old": {
            "rating": 1245.5072951579443,
            "rating_q975": 1287.1211774216658,
            "rating_q025": 1203.893412894223
        },
        "chatgpt-4o-latest-20250326": {
            "rating": 1240.6203050516694,
            "rating_q975": 1253.1914180843894,
            "rating_q025": 1228.0491920189497
        },
        "gpt-5-chat": {
            "rating": 1239.4205294329945,
            "rating_q975": 1255.7689074168752,
            "rating_q025": 1223.0721514491138
        },
        "o3-2025-04-16": {
            "rating": 1236.1591042817415,
            "rating_q975": 1249.308877756558,
            "rating_q025": 1223.0093308069247
        },
        "gpt-5-high": {
            "rating": 1224.8674203611029,
            "rating_q975": 1241.0443571388441,
            "rating_q025": 1208.6904835833616
        },
        "gpt-4.5-preview-2025-02-27": {
            "rating": 1220.3246987268753,
            "rating_q975": 1237.4924801909065,
            "rating_q025": 1203.156917262844
        },
        "gemini-2.5-flash": {
            "rating": 1216.9776229170322,
            "rating_q975": 1230.692817617032,
            "rating_q025": 1203.2624282170327
        },
        "gpt-4.1-2025-04-14": {
            "rating": 1214.372551225347,
            "rating_q975": 1227.8334345505336,
            "rating_q025": 1200.9116679001604
        },
        "gpt-4.1-mini-2025-04-14": {
            "rating": 1209.6080458574422,
            "rating_q975": 1223.2981126619075,
            "rating_q025": 1195.9179790529772
        },
        "gpt-5-mini-high": {
            "rating": 1206.3477700629105,
            "rating_q975": 1223.597006680571,
            "rating_q025": 1189.0985334452498
        },
        "claude-sonnet-4-20250514-thinking-32k": {
            "rating": 1203.004117672937,
            "rating_q975": 1227.9647706789492,
            "rating_q025": 1178.0434646669244
        },
        "o4-mini-2025-04-16": {
            "rating": 1201.0533888049602,
            "rating_q975": 1214.814726075001,
            "rating_q025": 1187.2920515349192
        },
        "grok-4-0709": {
            "rating": 1200.8022929554575,
            "rating_q975": 1216.3481311242779,
            "rating_q025": 1185.2564547866373
        },
        "qwen-vl-max-2025-08-13": {
            "rating": 1194.5647866949357,
            "rating_q975": 1221.4979773359548,
            "rating_q025": 1167.6315960539166
        },
        "claude-3-7-sonnet-20250219-thinking-32k": {
            "rating": 1193.9113696762863,
            "rating_q975": 1217.1463656630403,
            "rating_q025": 1170.676373689532
        },
        "claude-opus-4-20250514": {
            "rating": 1192.9060428490936,
            "rating_q975": 1212.260150014158,
            "rating_q025": 1173.5519356840293
        },
        "claude-opus-4-20250514-thinking-16k": {
            "rating": 1189.2613174778628,
            "rating_q975": 1214.265654389718,
            "rating_q025": 1164.2569805660078
        },
        "o1-2024-12-17": {
            "rating": 1189.0337068382712,
            "rating_q975": 1204.4050150867704,
            "rating_q025": 1173.6623985897722
        },
        "glm-4.5v": {
            "rating": 1186.2637344989826,
            "rating_q975": 1209.9352542528497,
            "rating_q025": 1162.5922147451154
        },
        "claude-sonnet-4-20250514": {
            "rating": 1178.287953895171,
            "rating_q975": 1200.0547479682084,
            "rating_q025": 1156.5211598221335
        },
        "step-3": {
            "rating": 1175.695789408762,
            "rating_q975": 1200.132044071853,
            "rating_q025": 1151.2595347456713
        },
        "gemini-2.0-flash-001": {
            "rating": 1174.908025428471,
            "rating_q975": 1186.98482248499,
            "rating_q025": 1162.8312283719522
        },
        "step-1o-turbo-202506": {
            "rating": 1173.6814751245129,
            "rating_q975": 1194.8832923484053,
            "rating_q025": 1152.4796579006204
        },
        "gemini-1.5-pro-002": {
            "rating": 1172.026188313974,
            "rating_q975": 1184.0384791268789,
            "rating_q025": 1160.0138975010693
        },
        "gpt-4o-2024-05-13": {
            "rating": 1168.3909756880457,
            "rating_q975": 1179.7754817500177,
            "rating_q025": 1157.0064696260738
        },
        "gemma-3-27b-it": {
            "rating": 1165.0864064700272,
            "rating_q975": 1180.221781163186,
            "rating_q025": 1149.9510317768686
        },
        "claude-3-7-sonnet-20250219": {
            "rating": 1164.5862560677383,
            "rating_q975": 1179.0037283871748,
            "rating_q025": 1150.168783748302
        },
        "mistral-medium-2505": {
            "rating": 1163.2291109040907,
            "rating_q975": 1177.4445037159132,
            "rating_q025": 1149.0137180922682
        },
        "gpt-5-nano-high": {
            "rating": 1162.2508857659361,
            "rating_q975": 1183.6811525812977,
            "rating_q025": 1140.8206189505743
        },
        "claude-3-5-sonnet-20241022": {
            "rating": 1154.9643895667791,
            "rating_q975": 1166.4105796966167,
            "rating_q025": 1143.5181994369414
        },
        "hunyuan-large-vision": {
            "rating": 1154.1086188976647,
            "rating_q975": 1177.6838802835168,
            "rating_q025": 1130.5333575118127
        },
        "mistral-small-2506": {
            "rating": 1151.869667588297,
            "rating_q975": 1167.230115473443,
            "rating_q025": 1136.509219703151
        },
        "gemini-1.5-flash-002": {
            "rating": 1150.3895410686523,
            "rating_q975": 1163.2805464191063,
            "rating_q025": 1137.4985357181981
        },
        "gemini-2.0-flash-lite-preview-02-05": {
            "rating": 1148.2237096221102,
            "rating_q975": 1162.551167223042,
            "rating_q025": 1133.8962520211785
        },
        "llama-4-scout-17b-16e-instruct": {
            "rating": 1143.5882556184642,
            "rating_q975": 1159.7785391685134,
            "rating_q025": 1127.3979720684156
        },
        "step-1o-vision-32k-highres": {
            "rating": 1141.8552280221766,
            "rating_q975": 1158.4103516773578,
            "rating_q025": 1125.3001043669951
        },
        "llama-4-maverick-17b-128e-instruct": {
            "rating": 1141.0737943391778,
            "rating_q975": 1156.542125758798,
            "rating_q025": 1125.6054629195573
        },
        "claude-3-5-sonnet-20240620": {
            "rating": 1139.0091467629645,
            "rating_q975": 1152.0680050767353,
            "rating_q025": 1125.9502884491937
        },
        "mistral-medium-2508": {
            "rating": 1135.5369510476785,
            "rating_q975": 1153.442334619925,
            "rating_q025": 1117.6315674754321
        },
        "claude-3-5-haiku-20241022": {
            "rating": 1135.5336429747126,
            "rating_q975": 1158.959762319334,
            "rating_q025": 1112.107523630091
        },
        "gpt-4.1-nano-2025-04-14": {
            "rating": 1126.725270652948,
            "rating_q975": 1154.2535031828563,
            "rating_q025": 1099.1970381230394
        },
        "qwen2.5-vl-72b-instruct": {
            "rating": 1125.0221557249665,
            "rating_q975": 1139.4106672428657,
            "rating_q025": 1110.6336442070672
        },
        "gpt-4o-2024-08-06": {
            "rating": 1123.8573790138594,
            "rating_q975": 1140.3488315001164,
            "rating_q025": 1107.3659265276026
        },
        "mistral-small-3.1-24b-instruct-2503": {
            "rating": 1122.142447480258,
            "rating_q975": 1136.9674025345298,
            "rating_q025": 1107.317492425986
        },
        "qwen2.5-vl-32b-instruct": {
            "rating": 1120.219196802137,
            "rating_q975": 1140.826584319705,
            "rating_q025": 1099.6118092845695
        },
        "gpt-4-turbo-2024-04-09": {
            "rating": 1115.207081599018,
            "rating_q975": 1129.0666931704925,
            "rating_q025": 1101.3474700275435
        },
        "gemini-1.5-pro-001": {
            "rating": 1112.1310730957468,
            "rating_q975": 1125.785852691952,
            "rating_q025": 1098.4762934995417
        },
        "gpt-4o-mini-2024-07-18": {
            "rating": 1099.540961377213,
            "rating_q975": 1110.7042765467638,
            "rating_q025": 1088.377646207662
        },
        "pixtral-large-2411": {
            "rating": 1098.8496455422805,
            "rating_q975": 1111.7893939019953,
            "rating_q025": 1085.909897182566
        },
        "qwen-vl-max-1119": {
            "rating": 1096.8031037457888,
            "rating_q975": 1118.424565485933,
            "rating_q025": 1075.1816420056446
        },
        "gemini-1.5-flash-8b-001": {
            "rating": 1088.5618668245247,
            "rating_q975": 1102.154574130156,
            "rating_q025": 1074.9691595188935
        },
        "qwen2-vl-72b": {
            "rating": 1086.8049995022525,
            "rating_q975": 1100.1546562886938,
            "rating_q025": 1073.4553427158112
        },
        "step-1v-32k": {
            "rating": 1080.2227590893458,
            "rating_q975": 1102.4641701220532,
            "rating_q025": 1057.9813480566384
        },
        "gemini-1.5-flash-001": {
            "rating": 1074.314332031315,
            "rating_q975": 1088.3827109060617,
            "rating_q025": 1060.2459531565682
        },
        "molmo-72b-0924": {
            "rating": 1072.6267800991714,
            "rating_q975": 1089.8236829457303,
            "rating_q025": 1055.4298772526124
        },
        "hunyuan-standard-vision-2024-12-31": {
            "rating": 1058.5616359314972,
            "rating_q975": 1086.2489247582794,
            "rating_q025": 1030.8743471047148
        },
        "claude-3-opus-20240229": {
            "rating": 1058.2333836374912,
            "rating_q975": 1071.7552807297757,
            "rating_q025": 1044.7114865452068
        },
        "internvl2-26b": {
            "rating": 1051.431221658631,
            "rating_q975": 1066.8483600339516,
            "rating_q025": 1036.0140832833106
        },
        "pixtral-12b-2409": {
            "rating": 1043.582100542687,
            "rating_q975": 1056.158797159351,
            "rating_q025": 1031.0054039260228
        },
        "qwen2-vl-7b-instruct": {
            "rating": 1043.2846547990446,
            "rating_q975": 1057.0713658424136,
            "rating_q025": 1029.4979437556758
        },
        "molmo-7b-d-0924": {
            "rating": 1041.7377055837271,
            "rating_q975": 1059.6162190246341,
            "rating_q025": 1023.8591921428201
        },
        "llama-3.2-vision-90b-instruct": {
            "rating": 1041.2662192598914,
            "rating_q975": 1053.5880714355878,
            "rating_q025": 1028.944367084195
        },
        "amazon-nova-lite-v1.0": {
            "rating": 1032.6536622916085,
            "rating_q975": 1052.375191530931,
            "rating_q025": 1012.932133052286
        },
        "amazon-nova-pro-v1.0": {
            "rating": 1029.0074995451278,
            "rating_q975": 1047.4784874429245,
            "rating_q025": 1010.5365116473312
        },
        "yi-vision": {
            "rating": 1027.5202014269662,
            "rating_q975": 1050.2358590351996,
            "rating_q025": 1004.8045438187327
        },
        "llama-3.2-vision-11b-instruct": {
            "rating": 1017.6330453483845,
            "rating_q975": 1032.3188228276358,
            "rating_q025": 1002.9472678691333
        },
        "llava-onevision-qwen2-72b-ov": {
            "rating": 1015.3951619431907,
            "rating_q975": 1037.3787729627536,
            "rating_q025": 993.4115509236277
        },
        "claude-3-sonnet-20240229": {
            "rating": 1015.130553164967,
            "rating_q975": 1029.0529655537428,
            "rating_q025": 1001.2081407761909
        },
        "internvl2-4b": {
            "rating": 1001.2247738388141,
            "rating_q975": 1017.3441977408074,
            "rating_q025": 985.1053499368207
        },
        "claude-3-haiku-20240307": {
            "rating": 1000.0,
            "rating_q975": 1014.7913050527291,
            "rating_q025": 985.2086949472709
        },
        "c4ai-aya-vision-32b": {
            "rating": 998.9538181139494,
            "rating_q975": 1029.3933049355173,
            "rating_q025": 968.5143312923816
        },
        "nvila-internal-15b-v1": {
            "rating": 997.1446168199521,
            "rating_q975": 1023.2835833225796,
            "rating_q025": 971.0056503173247
        },
        "llava-v1.6-34b": {
            "rating": 996.7101907868471,
            "rating_q975": 1012.2410912997742,
            "rating_q025": 981.1792902739198
        },
        "minicpm-v-2_6": {
            "rating": 996.1863592021931,
            "rating_q975": 1015.3689232113607,
            "rating_q025": 977.0037951930256
        },
        "cogvlm2-llama3-chat-19b": {
            "rating": 994.2757944774526,
            "rating_q975": 1013.8769072134679,
            "rating_q025": 974.6746817414372
        },
        "phi-3.5-vision-instruct": {
            "rating": 942.9380982474889,
            "rating_q975": 962.1629511990575,
            "rating_q025": 923.7132452959204
        },
        "phi-3-vision-128k-instruct": {
            "rating": 909.3427902858647,
            "rating_q975": 931.8850564212494,
            "rating_q025": 886.8005241504799
        }
    },
    "full": {
        "gemini-2.5-pro": {
            "rating": 1251.2319816182548,
            "rating_q975": 1261.718006831733,
            "rating_q025": 1240.7459564047765
        },
        "chatgpt-4o-latest-20250326": {
            "rating": 1234.0824741539832,
            "rating_q975": 1243.9811283553695,
            "rating_q025": 1224.1838199525969
        },
        "gpt-5-chat": {
            "rating": 1227.396762939296,
            "rating_q975": 1239.9285595611082,
            "rating_q025": 1214.8649663174838
        },
        "gpt-5-old": {
            "rating": 1220.666085502677,
            "rating_q975": 1249.3374020585463,
            "rating_q025": 1191.9947689468083
        },
        "o3-2025-04-16": {
            "rating": 1220.1952865696135,
            "rating_q975": 1230.7165379331636,
            "rating_q025": 1209.6740352060633
        },
        "gpt-4.5-preview-2025-02-27": {
            "rating": 1219.5259556817223,
            "rating_q975": 1232.284561985791,
            "rating_q025": 1206.767349377654
        },
        "gpt-5-high": {
            "rating": 1210.0023113235675,
            "rating_q975": 1222.3292306235048,
            "rating_q025": 1197.6753920236304
        },
        "gpt-4.1-2025-04-14": {
            "rating": 1207.1647787144343,
            "rating_q975": 1217.6250319705123,
            "rating_q025": 1196.7045254583566
        },
        "gemini-2.5-flash": {
            "rating": 1206.6361010904088,
            "rating_q975": 1217.3054466396131,
            "rating_q025": 1195.9667555412052
        },
        "claude-opus-4-20250514-thinking-16k": {
            "rating": 1198.9440573850152,
            "rating_q975": 1215.5123422486504,
            "rating_q025": 1182.3757725213804
        },
        "claude-sonnet-4-20250514-thinking-32k": {
            "rating": 1197.5496820031212,
            "rating_q975": 1214.4009003654073,
            "rating_q025": 1180.6984636408351
        },
        "o4-mini-2025-04-16": {
            "rating": 1195.8535594090295,
            "rating_q975": 1206.9301359358956,
            "rating_q025": 1184.7769828821638
        },
        "gpt-5-mini-high": {
            "rating": 1193.2093970764554,
            "rating_q975": 1206.599249374334,
            "rating_q025": 1179.819544778577
        },
        "gpt-4.1-mini-2025-04-14": {
            "rating": 1191.8716236321065,
            "rating_q975": 1202.6033274504673,
            "rating_q025": 1181.1399198137456
        },
        "claude-3-7-sonnet-20250219-thinking-32k": {
            "rating": 1189.2147376861553,
            "rating_q975": 1205.257857967368,
            "rating_q025": 1173.1716174049434
        },
        "o1-2024-12-17": {
            "rating": 1186.5697864431381,
            "rating_q975": 1198.4331895206851,
            "rating_q025": 1174.7063833655914
        },
        "claude-opus-4-20250514": {
            "rating": 1180.3527676559656,
            "rating_q975": 1194.1726326978865,
            "rating_q025": 1166.5329026140453
        },
        "claude-sonnet-4-20250514": {
            "rating": 1178.537755405237,
            "rating_q975": 1193.3107460079088,
            "rating_q025": 1163.764764802565
        },
        "grok-4-0709": {
            "rating": 1177.152185251849,
            "rating_q975": 1189.4516923946458,
            "rating_q025": 1164.852678109052
        },
        "qwen-vl-max-2025-08-13": {
            "rating": 1174.7193096185747,
            "rating_q975": 1193.3410193240722,
            "rating_q025": 1156.0975999130776
        },
        "claude-3-7-sonnet-20250219": {
            "rating": 1170.981570670238,
            "rating_q975": 1181.963131591524,
            "rating_q025": 1160.0000097489526
        },
        "gemini-1.5-pro-002": {
            "rating": 1170.688000660417,
            "rating_q975": 1180.5706750445645,
            "rating_q025": 1160.8053262762694
        },
        "gemini-2.0-flash-001": {
            "rating": 1157.487244946291,
            "rating_q975": 1167.1580695695552,
            "rating_q025": 1147.8164203230265
        },
        "gpt-4o-2024-05-13": {
            "rating": 1155.5265891950971,
            "rating_q975": 1164.9813764360174,
            "rating_q025": 1146.0718019541769
        },
        "claude-3-5-sonnet-20241022": {
            "rating": 1154.7746293812156,
            "rating_q975": 1164.0141418930143,
            "rating_q025": 1145.5351168694172
        },
        "step-3": {
            "rating": 1153.7302791198313,
            "rating_q975": 1171.1585988080876,
            "rating_q025": 1136.3019594315751
        },
        "glm-4.5v": {
            "rating": 1151.5034088929604,
            "rating_q975": 1168.37754641172,
            "rating_q025": 1134.629271374201
        },
        "gemma-3-27b-it": {
            "rating": 1148.142329932437,
            "rating_q975": 1160.1937960097753,
            "rating_q025": 1136.0908638550986
        },
        "step-1o-turbo-202506": {
            "rating": 1145.6388455451179,
            "rating_q975": 1161.306305577299,
            "rating_q025": 1129.9713855129366
        },
        "gpt-5-nano-high": {
            "rating": 1145.0620744522816,
            "rating_q975": 1160.7580789604115,
            "rating_q025": 1129.3660699441518
        },
        "mistral-medium-2505": {
            "rating": 1141.1916218994766,
            "rating_q975": 1152.1585125314775,
            "rating_q025": 1130.2247312674756
        },
        "claude-3-5-sonnet-20240620": {
            "rating": 1139.7868897578123,
            "rating_q975": 1150.4774238831585,
            "rating_q025": 1129.0963556324662
        },
        "hunyuan-large-vision": {
            "rating": 1139.5115141797678,
            "rating_q975": 1156.6361793417982,
            "rating_q025": 1122.3868490177376
        },
        "gemini-1.5-flash-002": {
            "rating": 1130.6075439492433,
            "rating_q975": 1141.2218832322649,
            "rating_q025": 1119.993204666222
        },
        "llama-4-maverick-17b-128e-instruct": {
            "rating": 1130.4365063422279,
            "rating_q975": 1142.5338340727858,
            "rating_q025": 1118.33917861167
        },
        "claude-3-5-haiku-20241022": {
            "rating": 1128.9471351543853,
            "rating_q975": 1145.3762812982345,
            "rating_q025": 1112.5179890105362
        },
        "gemini-2.0-flash-lite-preview-02-05": {
            "rating": 1126.615825263644,
            "rating_q975": 1138.07107288942,
            "rating_q025": 1115.160577637868
        },
        "mistral-small-2506": {
            "rating": 1125.5371440399758,
            "rating_q975": 1137.5940991255309,
            "rating_q025": 1113.4801889544208
        },
        "mistral-medium-2508": {
            "rating": 1122.2278216901495,
            "rating_q975": 1136.0194128532196,
            "rating_q025": 1108.4362305270797
        },
        "llama-4-scout-17b-16e-instruct": {
            "rating": 1121.7606169217242,
            "rating_q975": 1134.408141793164,
            "rating_q025": 1109.1130920502846
        },
        "step-1o-vision-32k-highres": {
            "rating": 1116.7143884114446,
            "rating_q975": 1130.0011247995599,
            "rating_q025": 1103.4276520233295
        },
        "qwen2.5-vl-72b-instruct": {
            "rating": 1114.9596495467922,
            "rating_q975": 1126.7551296373329,
            "rating_q025": 1103.1641694562518
        },
        "gpt-4o-2024-08-06": {
            "rating": 1113.283770252374,
            "rating_q975": 1126.149223573364,
            "rating_q025": 1100.4183169313844
        },
        "gemini-1.5-pro-001": {
            "rating": 1110.9824013250263,
            "rating_q975": 1123.085809931897,
            "rating_q025": 1098.8789927181556
        },
        "qwen2.5-vl-32b-instruct": {
            "rating": 1107.0022409159965,
            "rating_q975": 1123.6488720172492,
            "rating_q025": 1090.355609814744
        },
        "gpt-4-turbo-2024-04-09": {
            "rating": 1106.155494633315,
            "rating_q975": 1118.2338068900128,
            "rating_q025": 1094.0771823766172
        },
        "mistral-small-3.1-24b-instruct-2503": {
            "rating": 1098.9485124814648,
            "rating_q975": 1110.6011251174793,
            "rating_q025": 1087.2958998454505
        },
        "gpt-4o-mini-2024-07-18": {
            "rating": 1091.6860614669104,
            "rating_q975": 1100.8812491889178,
            "rating_q025": 1082.4908737449027
        },
        "pixtral-large-2411": {
            "rating": 1086.6225569269368,
            "rating_q975": 1096.8894540736799,
            "rating_q025": 1076.355659780194
        },
        "gpt-4.1-nano-2025-04-14": {
            "rating": 1082.3623529208062,
            "rating_q975": 1101.6079680459134,
            "rating_q025": 1063.1167377956995
        },
        "qwen-vl-max-1119": {
            "rating": 1079.9009929698695,
            "rating_q975": 1096.2563883256873,
            "rating_q025": 1063.545597614052
        },
        "qwen2-vl-72b": {
            "rating": 1079.5883633082672,
            "rating_q975": 1090.3899785518158,
            "rating_q025": 1068.7867480647187
        },
        "gemini-1.5-flash-8b-001": {
            "rating": 1064.4073227709719,
            "rating_q975": 1075.6199175840395,
            "rating_q025": 1053.1947279579042
        },
        "claude-3-opus-20240229": {
            "rating": 1059.1089954651682,
            "rating_q975": 1070.1080574216978,
            "rating_q025": 1048.1099335086387
        },
        "gemini-1.5-flash-001": {
            "rating": 1056.3159312475195,
            "rating_q975": 1068.6973664357943,
            "rating_q025": 1043.9344960592452
        },
        "step-1v-32k": {
            "rating": 1055.6634535641492,
            "rating_q975": 1072.8636769556992,
            "rating_q025": 1038.4632301725994
        },
        "molmo-72b-0924": {
            "rating": 1042.0342281164303,
            "rating_q975": 1055.677071701084,
            "rating_q025": 1028.3913845317766
        },
        "hunyuan-standard-vision-2024-12-31": {
            "rating": 1038.0964210002608,
            "rating_q975": 1059.6588597534196,
            "rating_q025": 1016.5339822471021
        },
        "qwen2-vl-7b-instruct": {
            "rating": 1026.9402968716563,
            "rating_q975": 1038.1435301003296,
            "rating_q025": 1015.7370636429829
        },
        "llama-3.2-vision-90b-instruct": {
            "rating": 1026.8266802684655,
            "rating_q975": 1036.8043449148947,
            "rating_q025": 1016.8490156220364
        },
        "pixtral-12b-2409": {
            "rating": 1018.8165069172027,
            "rating_q975": 1029.0893683404759,
            "rating_q025": 1008.5436454939298
        },
        "internvl2-26b": {
            "rating": 1018.6605673195329,
            "rating_q975": 1031.9082171415446,
            "rating_q025": 1005.4129174975214
        },
        "amazon-nova-lite-v1.0": {
            "rating": 1017.1730505937137,
            "rating_q975": 1032.6049104985232,
            "rating_q025": 1001.7411906889043
        },
        "claude-3-sonnet-20240229": {
            "rating": 1016.3761785929099,
            "rating_q975": 1028.299979045281,
            "rating_q025": 1004.4523781405393
        },
        "amazon-nova-pro-v1.0": {
            "rating": 1016.3178861389879,
            "rating_q975": 1030.5753597418966,
            "rating_q025": 1002.0604125360796
        },
        "yi-vision": {
            "rating": 1000.572086024876,
            "rating_q975": 1018.9245780836187,
            "rating_q025": 982.2195939661333
        },
        "claude-3-haiku-20240307": {
            "rating": 1000.0,
            "rating_q975": 1012.899866486281,
            "rating_q025": 987.1001335137194
        },
        "c4ai-aya-vision-32b": {
            "rating": 992.3881390985817,
            "rating_q975": 1015.0725725030435,
            "rating_q025": 969.7037056941202
        },
        "molmo-7b-d-0924": {
            "rating": 992.1342449936795,
            "rating_q975": 1006.3653933931847,
            "rating_q025": 977.9030965941745
        },
        "llama-3.2-vision-11b-instruct": {
            "rating": 985.5589571596693,
            "rating_q975": 997.4281166008548,
            "rating_q025": 973.689797718484
        },
        "nvila-internal-15b-v1": {
            "rating": 985.0944428087267,
            "rating_q975": 1005.5129792364625,
            "rating_q025": 964.6759063809911
        },
        "llava-onevision-qwen2-72b-ov": {
            "rating": 977.5130612966137,
            "rating_q975": 996.0315709305431,
            "rating_q025": 958.9945516626847
        },
        "llava-v1.6-34b": {
            "rating": 964.6253991000713,
            "rating_q975": 977.2423748910894,
            "rating_q025": 952.0084233090535
        },
        "minicpm-v-2_6": {
            "rating": 962.5299871351673,
            "rating_q975": 978.6160424607308,
            "rating_q025": 946.4439318096041
        },
        "cogvlm2-llama3-chat-19b": {
            "rating": 960.0410342678638,
            "rating_q975": 975.560544961354,
            "rating_q025": 944.5215235743738
        },
        "internvl2-4b": {
            "rating": 952.0896264331446,
            "rating_q975": 965.1383549201162,
            "rating_q025": 939.0408979461733
        },
        "phi-3.5-vision-instruct": {
            "rating": 919.6278216473225,
            "rating_q975": 935.8703500214312,
            "rating_q025": 903.385293273214
        },
        "phi-3-vision-128k-instruct": {
            "rating": 885.3746295387649,
            "rating_q975": 904.0334543664308,
            "rating_q025": 866.7158047110993
        }
    }
}