{
    "captioning": {
        "gemini-3-pro": {
            "rating": 1261.8853215627332,
            "rating_q975": 1302.966745024135,
            "rating_q025": 1220.8038981013315
        },
        "gemini-2.5-pro": {
            "rating": 1251.9188484283252,
            "rating_q975": 1274.045918724769,
            "rating_q025": 1229.7917781318813
        },
        "gemini-2.5-flash": {
            "rating": 1217.7577265630491,
            "rating_q975": 1243.3889567587705,
            "rating_q025": 1192.1264963673277
        },
        "gpt-4.1-2025-04-14": {
            "rating": 1212.3225758175793,
            "rating_q975": 1237.0443213958827,
            "rating_q025": 1187.6008302392759
        },
        "gpt-5-chat": {
            "rating": 1202.0333197826658,
            "rating_q975": 1227.425330512747,
            "rating_q025": 1176.6413090525846
        },
        "chatgpt-4o-latest-20250326": {
            "rating": 1201.018425086408,
            "rating_q975": 1236.404282910748,
            "rating_q025": 1165.6325672620678
        },
        "gpt-5-high": {
            "rating": 1192.4006643508721,
            "rating_q975": 1222.2373070103445,
            "rating_q025": 1162.5640216913998
        },
        "o4-mini-2025-04-16": {
            "rating": 1190.7788448193696,
            "rating_q975": 1215.9303253045139,
            "rating_q025": 1165.6273643342254
        },
        "gpt-4.1-mini-2025-04-14": {
            "rating": 1190.6788586968373,
            "rating_q975": 1218.2197142782647,
            "rating_q025": 1163.13800311541
        },
        "gemini-2.5-flash-lite-preview-06-17-thinking": {
            "rating": 1188.35,
            "rating_q975": 1213.8010157445754,
            "rating_q025": 1162.8989842554245
        },
        "o3-2025-04-16": {
            "rating": 1183.8129218645572,
            "rating_q975": 1207.7554061137319,
            "rating_q025": 1159.8704376153826
        },
        "gpt-5-mini-high": {
            "rating": 1169.5688370260984,
            "rating_q975": 1204.2266188398748,
            "rating_q025": 1134.911055212322
        },
        "grok-4-0709": {
            "rating": 1163.840637186078,
            "rating_q975": 1194.771814238191,
            "rating_q025": 1132.9094601339652
        },
        "mistral-medium-2508": {
            "rating": 1143.1281717886939,
            "rating_q975": 1171.2294122864537,
            "rating_q025": 1115.026931290934
        },
        "gemma-3-27b-it": {
            "rating": 1125.12725609593,
            "rating_q975": 1156.872645862727,
            "rating_q025": 1093.3818663291331
        },
        "gemini-2.0-flash-001": {
            "rating": 1124.7345993971962,
            "rating_q975": 1180.1667981210112,
            "rating_q025": 1069.3024006733813
        },
        "mistral-small-3.1-24b-instruct-2503": {
            "rating": 1121.011570798903,
            "rating_q975": 1151.4928473993416,
            "rating_q025": 1090.5302941984644
        },
        "mistral-medium-2505": {
            "rating": 1092.1918991132627,
            "rating_q975": 1131.927590413905,
            "rating_q025": 1052.4562078126205
        },
        "mistral-small-2506": {
            "rating": 1062.6184755269712,
            "rating_q975": 1102.2540774665058,
            "rating_q025": 1022.9828735874366
        }
    },
    "chinese": {
        "gemini-3-pro": {
            "rating": 1379.8613662135374,
            "rating_q975": 1408.4407617492898,
            "rating_q025": 1351.281970677785
        },
        "gpt-5-chat": {
            "rating": 1272.9777894005276,
            "rating_q975": 1300.2029364159841,
            "rating_q025": 1245.752642385071
        },
        "gemini-2.5-pro": {
            "rating": 1270.9322633529466,
            "rating_q975": 1296.7972059031977,
            "rating_q025": 1245.0673208026956
        },
        "gpt-5.1": {
            "rating": 1265.6595115901328,
            "rating_q975": 1305.8003946384167,
            "rating_q025": 1225.5186285418488
        },
        "gemini-2.5-flash-preview-09-2025": {
            "rating": 1257.8746353257454,
            "rating_q975": 1292.7589230446742,
            "rating_q025": 1222.9903476068166
        },
        "o1-2024-12-17": {
            "rating": 1251.2549742314832,
            "rating_q975": 1307.963066736749,
            "rating_q025": 1194.5468817262174
        },
        "gemini-2.5-flash": {
            "rating": 1245.1456425939234,
            "rating_q975": 1271.697382468386,
            "rating_q025": 1218.5939027194609
        },
        "gpt-4.1-2025-04-14": {
            "rating": 1237.3351836820088,
            "rating_q975": 1262.9230227423398,
            "rating_q025": 1211.747344621678
        },
        "gpt-5.1-high": {
            "rating": 1236.4258235405903,
            "rating_q975": 1282.4775997612933,
            "rating_q025": 1190.3740473198873
        },
        "qwen3-vl-235b-a22b-instruct": {
            "rating": 1235.543299393379,
            "rating_q975": 1269.7578922757602,
            "rating_q025": 1201.3287065109976
        },
        "chatgpt-4o-latest-20250326": {
            "rating": 1230.2323624024887,
            "rating_q975": 1258.35376890395,
            "rating_q025": 1202.1109559010274
        },
        "o3-2025-04-16": {
            "rating": 1227.9829971798858,
            "rating_q975": 1254.164387900614,
            "rating_q025": 1201.8016064591577
        },
        "gpt-5-high": {
            "rating": 1226.3660679761183,
            "rating_q975": 1255.0322239330187,
            "rating_q025": 1197.699912019218
        },
        "grok-4-0709": {
            "rating": 1215.5183490846414,
            "rating_q975": 1243.2983838522878,
            "rating_q025": 1187.738314316995
        },
        "o4-mini-2025-04-16": {
            "rating": 1210.1395402991816,
            "rating_q975": 1237.379644193956,
            "rating_q025": 1182.8994364044072
        },
        "gpt-4.1-mini-2025-04-14": {
            "rating": 1207.8081025694269,
            "rating_q975": 1234.2028695850925,
            "rating_q025": 1181.4133355537613
        },
        "gemini-2.5-flash-lite-preview-09-2025-no-thinking": {
            "rating": 1191.7576065110186,
            "rating_q975": 1226.3152534303,
            "rating_q025": 1157.1999595917373
        },
        "gpt-5-mini-high": {
            "rating": 1189.4822377114858,
            "rating_q975": 1219.4804255324361,
            "rating_q025": 1159.4840498905355
        },
        "gpt-4.5-preview-2025-02-27": {
            "rating": 1189.2999753428164,
            "rating_q975": 1249.8774401859919,
            "rating_q025": 1128.722510499641
        },
        "gemini-1.5-pro-002": {
            "rating": 1188.6717581344412,
            "rating_q975": 1224.7021800006098,
            "rating_q025": 1152.6413362682727
        },
        "gemini-2.5-flash-lite-preview-06-17-thinking": {
            "rating": 1188.35,
            "rating_q975": 1216.7130122963051,
            "rating_q025": 1159.9869877036947
        },
        "mistral-medium-2508": {
            "rating": 1169.1994619449438,
            "rating_q975": 1197.301756979026,
            "rating_q025": 1141.0971669108615
        },
        "claude-3-7-sonnet-20250219": {
            "rating": 1167.4543285613895,
            "rating_q975": 1216.6125084244247,
            "rating_q025": 1118.2961486983543
        },
        "gemma-3-27b-it": {
            "rating": 1165.58513681436,
            "rating_q975": 1195.7748863015613,
            "rating_q025": 1135.395387327159
        },
        "gemini-2.0-flash-001": {
            "rating": 1160.2959385710562,
            "rating_q975": 1195.2858588371575,
            "rating_q025": 1125.306018304955
        },
        "mistral-medium-2505": {
            "rating": 1152.3034065720092,
            "rating_q975": 1184.7725290581045,
            "rating_q025": 1119.8342840859139
        },
        "claude-3-5-sonnet-20241022": {
            "rating": 1147.5197691691797,
            "rating_q975": 1178.2132512909845,
            "rating_q025": 1116.8262870473748
        },
        "gpt-4o-2024-05-13": {
            "rating": 1143.3719052673127,
            "rating_q975": 1172.003098019173,
            "rating_q025": 1114.7407125154525
        },
        "mistral-small-2506": {
            "rating": 1140.751801583394,
            "rating_q975": 1174.1079127332255,
            "rating_q025": 1107.3956904335623
        },
        "mistral-small-3.1-24b-instruct-2503": {
            "rating": 1139.1141703957378,
            "rating_q975": 1169.4498692673117,
            "rating_q025": 1108.778471524164
        },
        "llama-4-maverick-17b-128e-instruct": {
            "rating": 1124.768180531671,
            "rating_q975": 1165.5667417764928,
            "rating_q025": 1083.9696192868494
        },
        "gemini-1.5-flash-002": {
            "rating": 1118.6054952744323,
            "rating_q975": 1155.2772808331229,
            "rating_q025": 1081.9337097157418
        },
        "qwen2.5-vl-72b-instruct": {
            "rating": 1112.2603760649222,
            "rating_q975": 1164.839624197899,
            "rating_q025": 1059.6811279319454
        },
        "claude-3-5-sonnet-20240620": {
            "rating": 1109.2715367246824,
            "rating_q975": 1139.0750577076305,
            "rating_q025": 1079.4680157417342
        },
        "llama-4-scout-17b-16e-instruct": {
            "rating": 1108.6630839810568,
            "rating_q975": 1150.2696400737618,
            "rating_q025": 1067.0565278883519
        },
        "qwen2-vl-72b": {
            "rating": 1095.81600664582,
            "rating_q975": 1133.6750375788406,
            "rating_q025": 1057.9569757127992
        },
        "pixtral-large-2411": {
            "rating": 1085.3048141179192,
            "rating_q975": 1132.6417464977606,
            "rating_q025": 1037.967881738078
        },
        "internvl2-26b": {
            "rating": 1067.4253221410804,
            "rating_q975": 1108.221750635274,
            "rating_q025": 1026.6288936468868
        },
        "gpt-4o-mini-2024-07-18": {
            "rating": 1065.9398476674642,
            "rating_q975": 1094.9057603459514,
            "rating_q025": 1036.973934988977
        },
        "gemini-2.0-flash-lite-preview-02-05": {
            "rating": 1062.0594845074388,
            "rating_q975": 1119.3006312026428,
            "rating_q025": 1004.8183378122349
        },
        "gemini-1.5-pro-001": {
            "rating": 1058.0254419065413,
            "rating_q975": 1089.1062456044463,
            "rating_q025": 1026.9446382086364
        },
        "gpt-4o-2024-08-06": {
            "rating": 1057.9109627877278,
            "rating_q975": 1103.2151848111876,
            "rating_q025": 1012.6067407642681
        },
        "gpt-4-turbo-2024-04-09": {
            "rating": 1051.3281567702506,
            "rating_q975": 1082.9138054215684,
            "rating_q025": 1019.7425081189328
        },
        "qwen2-vl-7b-instruct": {
            "rating": 1024.0810953461682,
            "rating_q975": 1063.0867800630328,
            "rating_q025": 985.0754106293036
        },
        "claude-3-opus-20240229": {
            "rating": 1014.2400027343558,
            "rating_q975": 1045.9061784713344,
            "rating_q025": 982.5738269973771
        },
        "gemini-1.5-flash-001": {
            "rating": 1012.985563884704,
            "rating_q975": 1045.0845256389023,
            "rating_q025": 980.8866021305058
        },
        "gemini-1.5-flash-8b-001": {
            "rating": 1004.2336028959066,
            "rating_q975": 1041.805250761991,
            "rating_q025": 966.6619550298223
        },
        "llama-3.2-vision-90b-instruct": {
            "rating": 990.2396038315355,
            "rating_q975": 1026.1254393217312,
            "rating_q025": 954.3537683413399
        },
        "molmo-72b-0924": {
            "rating": 971.392714773529,
            "rating_q975": 1020.2022332362511,
            "rating_q025": 922.5831963108068
        },
        "claude-3-sonnet-20240229": {
            "rating": 969.0326774416916,
            "rating_q975": 1001.1994415781153,
            "rating_q025": 936.8659133052679
        },
        "claude-3-haiku-20240307": {
            "rating": 962.1762956237911,
            "rating_q975": 994.3728340300809,
            "rating_q025": 929.9797572175014
        },
        "internvl2-4b": {
            "rating": 958.7524946827264,
            "rating_q975": 1008.1859821545278,
            "rating_q025": 909.319007210925
        },
        "pixtral-12b-2409": {
            "rating": 954.4107968639173,
            "rating_q975": 991.9750865064668,
            "rating_q025": 916.8465072213678
        },
        "molmo-7b-d-0924": {
            "rating": 940.7373311258511,
            "rating_q975": 990.5106404001642,
            "rating_q025": 890.9640218515381
        },
        "llava-v1.6-34b": {
            "rating": 940.4936009939844,
            "rating_q975": 979.477355374956,
            "rating_q025": 901.5098466130128
        },
        "llama-3.2-vision-11b-instruct": {
            "rating": 937.734151068629,
            "rating_q975": 980.980173340989,
            "rating_q025": 894.4881287962689
        }
    },
    "creative_writing_vision": {
        "gemini-3-pro": {
            "rating": 1373.7744372815348,
            "rating_q975": 1397.7242466001203,
            "rating_q025": 1349.8246279629493
        },
        "gpt-5.1": {
            "rating": 1275.2399358522787,
            "rating_q975": 1309.9558778077435,
            "rating_q025": 1240.5239938968139
        },
        "gpt-5.1-high": {
            "rating": 1272.6325848074264,
            "rating_q975": 1307.342892729653,
            "rating_q025": 1237.9222768851998
        },
        "gemini-2.5-flash-preview-09-2025": {
            "rating": 1262.1090973943453,
            "rating_q975": 1287.309579049272,
            "rating_q025": 1236.9086157394186
        },
        "gemini-2.5-pro": {
            "rating": 1260.1367278690118,
            "rating_q975": 1274.1930597535852,
            "rating_q025": 1246.0803959844384
        },
        "claude-opus-4-20250514": {
            "rating": 1257.7508315804357,
            "rating_q975": 1288.8965532099285,
            "rating_q025": 1226.605109950943
        },
        "chatgpt-4o-latest-20250326": {
            "rating": 1246.0013891714134,
            "rating_q975": 1265.208734977617,
            "rating_q025": 1226.7940433652097
        },
        "ernie-5.0-preview-1120": {
            "rating": 1239.0106905510647,
            "rating_q975": 1271.7428533346183,
            "rating_q025": 1206.2785277675112
        },
        "grok-4-0709": {
            "rating": 1237.1274172418746,
            "rating_q975": 1253.7111316033406,
            "rating_q025": 1220.5437028804085
        },
        "gpt-4.1-2025-04-14": {
            "rating": 1234.3577210375445,
            "rating_q975": 1250.7299756400578,
            "rating_q025": 1217.9854664350312
        },
        "gpt-5-chat": {
            "rating": 1232.1513759339036,
            "rating_q975": 1248.0458904443894,
            "rating_q025": 1216.2568614234178
        },
        "gemini-2.5-flash": {
            "rating": 1229.1514536959523,
            "rating_q975": 1244.3899160066283,
            "rating_q025": 1213.9129913852764
        },
        "qwen3-vl-235b-a22b-thinking": {
            "rating": 1217.4932525569518,
            "rating_q975": 1255.5467863521997,
            "rating_q025": 1179.439718761704
        },
        "gemini-2.0-flash-001": {
            "rating": 1208.1303652952627,
            "rating_q975": 1241.4391622146074,
            "rating_q025": 1174.8215683759179
        },
        "mistral-medium-2508": {
            "rating": 1203.1521174665456,
            "rating_q975": 1220.5288357284107,
            "rating_q025": 1185.7753992046805
        },
        "gemini-2.5-flash-lite-preview-09-2025-no-thinking": {
            "rating": 1200.8757789228525,
            "rating_q975": 1225.6395998824055,
            "rating_q025": 1176.1119579632996
        },
        "qwen3-vl-235b-a22b-instruct": {
            "rating": 1199.1704385751523,
            "rating_q975": 1223.6418600196107,
            "rating_q025": 1174.6990171306938
        },
        "claude-sonnet-4-20250514": {
            "rating": 1193.2536091719471,
            "rating_q975": 1232.1663495734047,
            "rating_q025": 1154.3408687704896
        },
        "o3-2025-04-16": {
            "rating": 1191.9722792327905,
            "rating_q975": 1206.5279534843937,
            "rating_q025": 1177.4166049811872
        },
        "gemini-2.5-flash-lite-preview-06-17-thinking": {
            "rating": 1188.35,
            "rating_q975": 1205.8271989954987,
            "rating_q025": 1170.872801004501
        },
        "gpt-4.1-mini-2025-04-14": {
            "rating": 1187.4563366097755,
            "rating_q975": 1205.3818217150742,
            "rating_q025": 1169.5308515044767
        },
        "mistral-small-2506": {
            "rating": 1186.9493708323114,
            "rating_q975": 1215.0475828087528,
            "rating_q025": 1158.85115885587
        },
        "gpt-5-high": {
            "rating": 1181.5751139630534,
            "rating_q975": 1199.8798085346,
            "rating_q025": 1163.2704193915067
        },
        "gemma-3-27b-it": {
            "rating": 1175.1526305794168,
            "rating_q975": 1197.0813351749216,
            "rating_q025": 1153.223925983912
        },
        "mistral-medium-2505": {
            "rating": 1165.5955778587272,
            "rating_q975": 1190.3414956952256,
            "rating_q025": 1140.8496600222288
        },
        "o4-mini-2025-04-16": {
            "rating": 1164.2900331119536,
            "rating_q975": 1180.9141026680259,
            "rating_q025": 1147.6659635558813
        },
        "qwen-vl-max-2025-08-13": {
            "rating": 1159.4203191304482,
            "rating_q975": 1202.4144335328763,
            "rating_q025": 1116.4262047280201
        },
        "gpt-5-mini-high": {
            "rating": 1154.1027625670947,
            "rating_q975": 1174.895687817358,
            "rating_q025": 1133.3098373168314
        },
        "hunyuan-vision-1.5-thinking": {
            "rating": 1145.7324325316058,
            "rating_q975": 1182.0521558940832,
            "rating_q025": 1109.4127091691284
        },
        "llama-4-scout-17b-16e-instruct": {
            "rating": 1138.2654438821078,
            "rating_q975": 1174.9529032179623,
            "rating_q025": 1101.5779845462532
        },
        "mistral-small-3.1-24b-instruct-2503": {
            "rating": 1131.95731430257,
            "rating_q975": 1153.7429562941077,
            "rating_q025": 1110.1716723110324
        },
        "llama-4-maverick-17b-128e-instruct": {
            "rating": 1128.2103679586721,
            "rating_q975": 1165.8681357901876,
            "rating_q025": 1090.5526001271567
        },
        "gpt-5-nano-high": {
            "rating": 1093.7645370595415,
            "rating_q975": 1135.5526100132497,
            "rating_q025": 1051.9764641058332
        }
    },
    "diagram": {
        "gemini-3-pro": {
            "rating": 1307.0266793448043,
            "rating_q975": 1328.4801492659392,
            "rating_q025": 1285.5732094236694
        },
        "gpt-5.1": {
            "rating": 1287.1557547636578,
            "rating_q975": 1316.7628794856864,
            "rating_q025": 1257.5486300416292
        },
        "gpt-5.1-high": {
            "rating": 1278.7414331227722,
            "rating_q975": 1306.8562650625388,
            "rating_q025": 1250.6266011830055
        },
        "gemini-2.5-pro": {
            "rating": 1276.3221626063423,
            "rating_q975": 1286.9828161187181,
            "rating_q025": 1265.6615090939665
        },
        "gpt-5-high": {
            "rating": 1268.9285921584653,
            "rating_q975": 1283.4483861711233,
            "rating_q025": 1254.4087981458074
        },
        "gpt-5-chat": {
            "rating": 1259.8765664547268,
            "rating_q975": 1272.8259002888656,
            "rating_q025": 1246.927232620588
        },
        "qwen-vl-max-2025-08-13": {
            "rating": 1254.5112523974628,
            "rating_q975": 1285.1444118611041,
            "rating_q025": 1223.8780929338216
        },
        "chatgpt-4o-latest-20250326": {
            "rating": 1251.5105715537102,
            "rating_q975": 1264.4490384641572,
            "rating_q025": 1238.5721046432632
        },
        "gemini-2.5-flash-preview-09-2025": {
            "rating": 1242.631856583698,
            "rating_q975": 1260.6573004714376,
            "rating_q025": 1224.6064126959584
        },
        "o3-2025-04-16": {
            "rating": 1241.3392388995494,
            "rating_q975": 1252.9736782101902,
            "rating_q025": 1229.7047995889086
        },
        "qwen3-vl-235b-a22b-instruct": {
            "rating": 1241.2161441150395,
            "rating_q975": 1259.5648602074675,
            "rating_q025": 1222.8674280226114
        },
        "gpt-4.1-2025-04-14": {
            "rating": 1233.4597926379092,
            "rating_q975": 1245.7268287599582,
            "rating_q025": 1221.1927565158603
        },
        "ernie-5.0-preview-1120": {
            "rating": 1230.8022258042822,
            "rating_q975": 1255.8449581705772,
            "rating_q025": 1205.7594934379872
        },
        "claude-sonnet-4-20250514-thinking-32k": {
            "rating": 1230.5656052783206,
            "rating_q975": 1266.5946281138918,
            "rating_q025": 1194.5365824427495
        },
        "hunyuan-vision-1.5-thinking": {
            "rating": 1228.1699389391076,
            "rating_q975": 1253.3725037225065,
            "rating_q025": 1202.9673741557087
        },
        "gemini-2.5-flash": {
            "rating": 1226.268714345694,
            "rating_q975": 1237.607043819191,
            "rating_q025": 1214.930384872197
        },
        "gpt-5-mini-high": {
            "rating": 1222.5194985313772,
            "rating_q975": 1238.3362334470253,
            "rating_q025": 1206.702763615729
        },
        "o4-mini-2025-04-16": {
            "rating": 1221.0630466948683,
            "rating_q975": 1233.2816205005593,
            "rating_q025": 1208.8444728891773
        },
        "claude-opus-4-20250514-thinking-16k": {
            "rating": 1219.3192560799278,
            "rating_q975": 1253.1803026761163,
            "rating_q025": 1185.4582094837392
        },
        "claude-3-7-sonnet-20250219-thinking-32k": {
            "rating": 1214.7565351547448,
            "rating_q975": 1247.3781948108497,
            "rating_q025": 1182.13487549864
        },
        "qwen3-vl-235b-a22b-thinking": {
            "rating": 1212.2854843019609,
            "rating_q975": 1237.2098203004696,
            "rating_q025": 1187.3611483034522
        },
        "claude-opus-4-20250514": {
            "rating": 1208.6411953059421,
            "rating_q975": 1232.9331769851785,
            "rating_q025": 1184.3492136267057
        },
        "gpt-4.1-mini-2025-04-14": {
            "rating": 1205.8911785642085,
            "rating_q975": 1218.8628194494693,
            "rating_q025": 1192.9195376789478
        },
        "claude-sonnet-4-20250514": {
            "rating": 1201.5636698210988,
            "rating_q975": 1229.1468929247626,
            "rating_q025": 1173.980446717435
        },
        "claude-3-7-sonnet-20250219": {
            "rating": 1192.3212698799853,
            "rating_q975": 1222.8500255643478,
            "rating_q025": 1161.7925141956227
        },
        "gemini-2.5-flash-lite-preview-06-17-thinking": {
            "rating": 1188.35,
            "rating_q975": 1201.0340643271063,
            "rating_q025": 1175.6659356728935
        },
        "grok-4-0709": {
            "rating": 1187.7106700451784,
            "rating_q975": 1200.3763571318636,
            "rating_q025": 1175.0449829584932
        },
        "claude-3-5-sonnet-20241022": {
            "rating": 1180.0102415468832,
            "rating_q975": 1211.3872077998087,
            "rating_q025": 1148.6332752939577
        },
        "gemini-2.5-flash-lite-preview-09-2025-no-thinking": {
            "rating": 1178.8573335677083,
            "rating_q975": 1196.7947196466207,
            "rating_q025": 1160.919947488796
        },
        "glm-4.5v": {
            "rating": 1176.3889261170893,
            "rating_q975": 1204.3880531136347,
            "rating_q025": 1148.389799120544
        },
        "mistral-medium-2508": {
            "rating": 1175.5072358097805,
            "rating_q975": 1189.2706540071779,
            "rating_q025": 1161.743817612383
        },
        "gemini-2.0-flash-001": {
            "rating": 1175.074418751593,
            "rating_q975": 1193.3617693636268,
            "rating_q025": 1156.787068139559
        },
        "step-1o-turbo-202506": {
            "rating": 1165.8159880654425,
            "rating_q975": 1193.866458909858,
            "rating_q025": 1137.765517221027
        },
        "gemma-3-27b-it": {
            "rating": 1163.739755298373,
            "rating_q975": 1178.0669744998427,
            "rating_q025": 1149.4125360969033
        },
        "mistral-medium-2505": {
            "rating": 1161.8666443396583,
            "rating_q975": 1176.8558062602378,
            "rating_q025": 1146.8774824190787
        },
        "gpt-5-nano-high": {
            "rating": 1158.4548795161684,
            "rating_q975": 1185.6498727746666,
            "rating_q025": 1131.2598862576701
        },
        "llama-4-maverick-17b-128e-instruct": {
            "rating": 1150.2666532086023,
            "rating_q975": 1168.5125746603628,
            "rating_q025": 1132.0207317568418
        },
        "llama-4-scout-17b-16e-instruct": {
            "rating": 1147.643650944624,
            "rating_q975": 1166.8386018954827,
            "rating_q025": 1128.448699993765
        },
        "step-3": {
            "rating": 1140.958693925874,
            "rating_q975": 1169.3344483586827,
            "rating_q025": 1112.5829394930654
        },
        "claude-3-5-haiku-20241022": {
            "rating": 1137.9005858153469,
            "rating_q975": 1169.8908074090652,
            "rating_q025": 1105.9103642216285
        },
        "mistral-small-2506": {
            "rating": 1136.5064127137402,
            "rating_q975": 1153.700545123714,
            "rating_q025": 1119.3122803037666
        },
        "mistral-small-3.1-24b-instruct-2503": {
            "rating": 1133.0099509850377,
            "rating_q975": 1147.916670764175,
            "rating_q025": 1118.1032312059003
        },
        "hunyuan-large-vision": {
            "rating": 1128.8416077636325,
            "rating_q975": 1162.2352461232842,
            "rating_q025": 1095.4479694039808
        }
    },
    "english": {
        "gemini-3-pro": {
            "rating": 1294.9014558155095,
            "rating_q975": 1312.6052221958576,
            "rating_q025": 1277.1976894351615
        },
        "gemini-2.5-pro": {
            "rating": 1256.4327421923128,
            "rating_q975": 1266.2396428133518,
            "rating_q025": 1246.625841571274
        },
        "gpt-5.1": {
            "rating": 1248.5476797839885,
            "rating_q975": 1270.625058597657,
            "rating_q025": 1226.47030097032
        },
        "gpt-5.1-high": {
            "rating": 1243.3385039945417,
            "rating_q975": 1265.342937403177,
            "rating_q025": 1221.3340705859064
        },
        "chatgpt-4o-latest-20250326": {
            "rating": 1235.625594821901,
            "rating_q975": 1244.8472775843168,
            "rating_q025": 1226.403912059485
        },
        "gemini-2.5-flash-preview-09-2025": {
            "rating": 1228.8548571786953,
            "rating_q975": 1243.422705194482,
            "rating_q025": 1214.2870091629086
        },
        "gpt-5-chat": {
            "rating": 1224.1046862917747,
            "rating_q975": 1235.0467545835406,
            "rating_q025": 1213.1626180000087
        },
        "o3-2025-04-16": {
            "rating": 1223.470348059068,
            "rating_q975": 1232.9734779021771,
            "rating_q025": 1213.967218215959
        },
        "gpt-4.5-preview-2025-02-27": {
            "rating": 1219.3877308559927,
            "rating_q975": 1235.1138527442577,
            "rating_q025": 1203.6616089677277
        },
        "gemini-2.5-flash": {
            "rating": 1218.541784258683,
            "rating_q975": 1228.4371948005514,
            "rating_q025": 1208.6463737168147
        },
        "gpt-5-high": {
            "rating": 1218.2327122896545,
            "rating_q975": 1229.668715971241,
            "rating_q025": 1206.796708608068
        },
        "qwen3-vl-235b-a22b-instruct": {
            "rating": 1216.3376844305014,
            "rating_q975": 1230.4695092601064,
            "rating_q025": 1202.2058596008965
        },
        "gpt-4.1-2025-04-14": {
            "rating": 1214.5664863233178,
            "rating_q975": 1224.3838106913245,
            "rating_q025": 1204.7491619553111
        },
        "gpt-4.1-mini-2025-04-14": {
            "rating": 1210.7115335383864,
            "rating_q975": 1221.0230104289826,
            "rating_q025": 1200.4000566477903
        },
        "hunyuan-vision-1.5-thinking": {
            "rating": 1208.3375150176316,
            "rating_q975": 1225.8942147701753,
            "rating_q025": 1190.780815265088
        },
        "o4-mini-2025-04-16": {
            "rating": 1203.9554535002974,
            "rating_q975": 1214.0805523345405,
            "rating_q025": 1193.8303546660543
        },
        "ernie-5.0-preview-1120": {
            "rating": 1201.7193923146835,
            "rating_q975": 1219.6297846553368,
            "rating_q025": 1183.8089999740303
        },
        "qwen-vl-max-2025-08-13": {
            "rating": 1200.7436002687875,
            "rating_q975": 1218.2230606825851,
            "rating_q025": 1183.26413985499
        },
        "claude-sonnet-4-20250514-thinking-32k": {
            "rating": 1198.2408867578843,
            "rating_q975": 1222.1003220579623,
            "rating_q025": 1174.3814514578062
        },
        "gpt-5-mini-high": {
            "rating": 1195.944401038891,
            "rating_q975": 1207.9709823134858,
            "rating_q025": 1183.9178197642964
        },
        "qwen3-vl-235b-a22b-thinking": {
            "rating": 1195.3620373958674,
            "rating_q975": 1213.5289146797752,
            "rating_q025": 1177.1951601119597
        },
        "grok-4-0709": {
            "rating": 1192.6766691438354,
            "rating_q975": 1203.5438725015517,
            "rating_q025": 1181.809465786119
        },
        "claude-opus-4-20250514": {
            "rating": 1191.955939218561,
            "rating_q975": 1209.864563445417,
            "rating_q025": 1174.0473149917052
        },
        "claude-opus-4-20250514-thinking-16k": {
            "rating": 1189.949253571268,
            "rating_q975": 1213.8863769908755,
            "rating_q025": 1166.0121301516604
        },
        "claude-3-7-sonnet-20250219-thinking-32k": {
            "rating": 1188.981164251831,
            "rating_q975": 1210.837827740754,
            "rating_q025": 1167.124500762908
        },
        "gemini-2.5-flash-lite-preview-06-17-thinking": {
            "rating": 1188.35,
            "rating_q975": 1199.121640262268,
            "rating_q025": 1177.5783597377317
        },
        "gemini-2.5-flash-lite-preview-09-2025-no-thinking": {
            "rating": 1186.7834830767517,
            "rating_q975": 1201.0974027642878,
            "rating_q025": 1172.4695633892156
        },
        "o1-2024-12-17": {
            "rating": 1186.4388949181628,
            "rating_q975": 1200.2692535727056,
            "rating_q025": 1172.60853626362
        },
        "glm-4.5v": {
            "rating": 1182.9475489489434,
            "rating_q975": 1199.7435918503982,
            "rating_q025": 1166.1515060474887
        },
        "gemini-2.0-flash-001": {
            "rating": 1176.90342217392,
            "rating_q975": 1186.1241040439481,
            "rating_q025": 1167.682740303892
        },
        "claude-sonnet-4-20250514": {
            "rating": 1176.0832390522444,
            "rating_q975": 1196.6080510353827,
            "rating_q025": 1155.558427069106
        },
        "step-1o-turbo-202506": {
            "rating": 1174.1869927410726,
            "rating_q975": 1194.1874003848507,
            "rating_q025": 1154.1865850972945
        },
        "gemini-1.5-pro-002": {
            "rating": 1170.111314792427,
            "rating_q975": 1180.310636329878,
            "rating_q025": 1159.911993254976
        },
        "mistral-medium-2505": {
            "rating": 1168.791744233647,
            "rating_q975": 1180.1894665332718,
            "rating_q025": 1157.3940219340222
        },
        "gpt-4o-2024-05-13": {
            "rating": 1166.2761556567502,
            "rating_q975": 1175.8163663920384,
            "rating_q025": 1156.735944921462
        },
        "claude-3-7-sonnet-20250219": {
            "rating": 1162.8585594004348,
            "rating_q975": 1175.392763951409,
            "rating_q025": 1150.3243548494606
        },
        "gemma-3-27b-it": {
            "rating": 1162.613697585597,
            "rating_q975": 1173.803079343558,
            "rating_q025": 1151.424315827636
        },
        "step-3": {
            "rating": 1158.5801688387978,
            "rating_q975": 1175.3615949081022,
            "rating_q025": 1141.7987427694934
        },
        "gpt-5-nano-high": {
            "rating": 1156.193598910696,
            "rating_q975": 1172.557545210139,
            "rating_q025": 1139.8296526112529
        },
        "claude-3-5-sonnet-20241022": {
            "rating": 1153.30254445621,
            "rating_q975": 1162.5927338536508,
            "rating_q025": 1144.0123550587691
        },
        "mistral-medium-2508": {
            "rating": 1153.0723724405186,
            "rating_q975": 1164.4465542023918,
            "rating_q025": 1141.6981906786455
        },
        "mistral-small-2506": {
            "rating": 1151.575661810068,
            "rating_q975": 1163.7991013084966,
            "rating_q025": 1139.3522223116393
        },
        "hunyuan-large-vision": {
            "rating": 1149.6494025940226,
            "rating_q975": 1172.2802764366738,
            "rating_q025": 1127.0185287513714
        },
        "gemini-1.5-flash-002": {
            "rating": 1149.5894438240446,
            "rating_q975": 1160.8481330822383,
            "rating_q025": 1138.3307545658508
        },
        "llama-4-maverick-17b-128e-instruct": {
            "rating": 1148.5313235492272,
            "rating_q975": 1160.890987008191,
            "rating_q025": 1136.1716600902635
        },
        "gemini-2.0-flash-lite-preview-02-05": {
            "rating": 1146.0485521189685,
            "rating_q975": 1158.7893408062278,
            "rating_q025": 1133.3077634317092
        },
        "step-1o-vision-32k-highres": {
            "rating": 1141.1556315413463,
            "rating_q975": 1156.5083661233584,
            "rating_q025": 1125.8028969593342
        },
        "llama-4-scout-17b-16e-instruct": {
            "rating": 1140.6652910829216,
            "rating_q975": 1153.6539357386464,
            "rating_q025": 1127.6766464271968
        },
        "claude-3-5-sonnet-20240620": {
            "rating": 1138.0925506645058,
            "rating_q975": 1149.6528796352482,
            "rating_q025": 1126.5322216937634
        },
        "mistral-small-3.1-24b-instruct-2503": {
            "rating": 1136.47962978938,
            "rating_q975": 1147.888363617331,
            "rating_q025": 1125.070895961429
        },
        "claude-3-5-haiku-20241022": {
            "rating": 1134.3608537136593,
            "rating_q975": 1156.9048694409619,
            "rating_q025": 1111.8168379863566
        },
        "gpt-4.1-nano-2025-04-14": {
            "rating": 1124.7002929935343,
            "rating_q975": 1151.2320172696934,
            "rating_q025": 1098.1685687173751
        },
        "qwen2.5-vl-72b-instruct": {
            "rating": 1124.2835831077,
            "rating_q975": 1137.087879316878,
            "rating_q025": 1111.479286898522
        },
        "qwen2.5-vl-32b-instruct": {
            "rating": 1121.807078813778,
            "rating_q975": 1141.1511933074273,
            "rating_q025": 1102.4629643201285
        },
        "gpt-4o-2024-08-06": {
            "rating": 1120.4386495353424,
            "rating_q975": 1135.7054050886777,
            "rating_q025": 1105.171893982007
        },
        "gpt-4-turbo-2024-04-09": {
            "rating": 1112.7902227446282,
            "rating_q975": 1125.2698530263463,
            "rating_q025": 1100.31059246291
        },
        "gemini-1.5-pro-001": {
            "rating": 1109.3453452022522,
            "rating_q975": 1121.6034937342213,
            "rating_q025": 1097.0871966702832
        },
        "pixtral-large-2411": {
            "rating": 1097.7452078664312,
            "rating_q975": 1108.9506541680332,
            "rating_q025": 1086.5397615648292
        },
        "gpt-4o-mini-2024-07-18": {
            "rating": 1097.1078204545292,
            "rating_q975": 1106.284055427426,
            "rating_q025": 1087.9315854816325
        },
        "qwen-vl-max-1119": {
            "rating": 1093.7096718096373,
            "rating_q975": 1114.5550276066567,
            "rating_q025": 1072.8643160126178
        },
        "gemini-1.5-flash-8b-001": {
            "rating": 1085.3571057125396,
            "rating_q975": 1097.45003640844,
            "rating_q025": 1073.2641750166392
        },
        "qwen2-vl-72b": {
            "rating": 1084.1301402650363,
            "rating_q975": 1095.9911629102276,
            "rating_q025": 1072.269117619845
        },
        "step-1v-32k": {
            "rating": 1078.353433652272,
            "rating_q975": 1099.6767987274823,
            "rating_q025": 1057.030068577062
        },
        "molmo-72b-0924": {
            "rating": 1070.536936718488,
            "rating_q975": 1086.571985677478,
            "rating_q025": 1054.501887759498
        },
        "gemini-1.5-flash-001": {
            "rating": 1069.2578451579338,
            "rating_q975": 1081.9463063504074,
            "rating_q025": 1056.5693839654602
        },
        "hunyuan-standard-vision-2024-12-31": {
            "rating": 1056.1445526274072,
            "rating_q975": 1082.9930089673194,
            "rating_q025": 1029.296096287495
        },
        "claude-3-opus-20240229": {
            "rating": 1053.8555137100714,
            "rating_q975": 1065.9213796434062,
            "rating_q025": 1041.7896477767365
        },
        "internvl2-26b": {
            "rating": 1048.8547823335648,
            "rating_q975": 1063.0658140276034,
            "rating_q025": 1034.6437506395262
        },
        "pixtral-12b-2409": {
            "rating": 1040.727027102606,
            "rating_q975": 1051.6161574864636,
            "rating_q025": 1029.8378967187482
        },
        "qwen2-vl-7b-instruct": {
            "rating": 1039.6718887437532,
            "rating_q975": 1051.9976842707774,
            "rating_q025": 1027.346093216729
        },
        "llama-3.2-vision-90b-instruct": {
            "rating": 1037.8683179295188,
            "rating_q975": 1048.472556551642,
            "rating_q025": 1027.2640793073956
        },
        "molmo-7b-d-0924": {
            "rating": 1037.5288185175805,
            "rating_q975": 1054.4881296637077,
            "rating_q025": 1020.5695073714534
        },
        "amazon-nova-lite-v1.0": {
            "rating": 1027.2072455104878,
            "rating_q975": 1046.1515103168745,
            "rating_q025": 1008.2629807041012
        },
        "yi-vision": {
            "rating": 1023.3372491457415,
            "rating_q975": 1045.4178209345228,
            "rating_q025": 1001.2566773569603
        },
        "amazon-nova-pro-v1.0": {
            "rating": 1022.9366832700752,
            "rating_q975": 1040.5562698380227,
            "rating_q025": 1005.3170967021277
        },
        "llama-3.2-vision-11b-instruct": {
            "rating": 1013.5898093783244,
            "rating_q975": 1026.9544443725395,
            "rating_q025": 1000.2251743841093
        },
        "llava-onevision-qwen2-72b-ov": {
            "rating": 1009.4730895883756,
            "rating_q975": 1030.7694059540372,
            "rating_q025": 988.1767732227141
        },
        "claude-3-sonnet-20240229": {
            "rating": 1008.8041803793025,
            "rating_q975": 1021.3795071971921,
            "rating_q025": 996.2288535614128
        },
        "c4ai-aya-vision-32b": {
            "rating": 998.4594096068224,
            "rating_q975": 1028.104238963951,
            "rating_q025": 968.8145802496938
        },
        "internvl2-4b": {
            "rating": 998.2059867048613,
            "rating_q975": 1013.2243946535958,
            "rating_q025": 983.1875787561268
        },
        "claude-3-haiku-20240307": {
            "rating": 992.9282672760044,
            "rating_q975": 1006.5022744920739,
            "rating_q025": 979.3542600599349
        },
        "nvila-internal-15b-v1": {
            "rating": 992.3564505287771,
            "rating_q975": 1017.9479304248567,
            "rating_q025": 966.7649706326976
        },
        "minicpm-v-2_6": {
            "rating": 990.4379912754813,
            "rating_q975": 1008.8278026983534,
            "rating_q025": 972.0481798526092
        },
        "cogvlm2-llama3-chat-19b": {
            "rating": 990.1461327102809,
            "rating_q975": 1008.9498953428343,
            "rating_q025": 971.3423700777274
        },
        "llava-v1.6-34b": {
            "rating": 989.6510686883746,
            "rating_q975": 1004.2698229307338,
            "rating_q025": 975.0323144460154
        },
        "phi-3.5-vision-instruct": {
            "rating": 936.4732503619928,
            "rating_q975": 954.7747405999963,
            "rating_q025": 918.1717601239892
        },
        "phi-3-vision-128k-instruct": {
            "rating": 899.852861605209,
            "rating_q975": 922.0183582643757,
            "rating_q025": 877.6873649460423
        }
    },
    "entity_recognition": {
        "gpt-5-high": {
            "rating": 1258.3289251256465,
            "rating_q975": 1289.4537986316373,
            "rating_q025": 1227.2040516196557
        },
        "gemini-2.5-pro": {
            "rating": 1240.826269930918,
            "rating_q975": 1262.8361150876353,
            "rating_q025": 1218.8164247742006
        },
        "o3-2025-04-16": {
            "rating": 1233.2640028320661,
            "rating_q975": 1258.2784357723222,
            "rating_q025": 1208.24956989181
        },
        "grok-4-0709": {
            "rating": 1230.4631072763036,
            "rating_q975": 1263.6024090387607,
            "rating_q025": 1197.3238055138465
        },
        "o4-mini-2025-04-16": {
            "rating": 1213.943348075829,
            "rating_q975": 1240.4634142756152,
            "rating_q025": 1187.4232818760427
        },
        "gemini-2.5-flash": {
            "rating": 1212.0024104032373,
            "rating_q975": 1239.6555878508777,
            "rating_q025": 1184.3492329555968
        },
        "chatgpt-4o-latest-20250326": {
            "rating": 1202.7716001865497,
            "rating_q975": 1237.6778281339048,
            "rating_q025": 1167.8653722391946
        },
        "gpt-5-mini-high": {
            "rating": 1199.559588656156,
            "rating_q975": 1236.317534884496,
            "rating_q025": 1162.801642427816
        },
        "gpt-4.1-mini-2025-04-14": {
            "rating": 1190.5221911111994,
            "rating_q975": 1217.9058752018946,
            "rating_q025": 1163.1385070205042
        },
        "gemini-2.5-flash-lite-preview-06-17-thinking": {
            "rating": 1188.35,
            "rating_q975": 1215.9349366041968,
            "rating_q025": 1160.765063395803
        },
        "gpt-5-chat": {
            "rating": 1185.3906326988108,
            "rating_q975": 1213.9464903760993,
            "rating_q025": 1156.8347750215223
        },
        "gpt-4.1-2025-04-14": {
            "rating": 1178.4429409054314,
            "rating_q975": 1205.4622926025118,
            "rating_q025": 1151.4235892083511
        },
        "gemma-3-27b-it": {
            "rating": 1162.1087147731073,
            "rating_q975": 1191.0943811027962,
            "rating_q025": 1133.1230484434184
        },
        "mistral-medium-2508": {
            "rating": 1148.5510941499738,
            "rating_q975": 1179.3211529980956,
            "rating_q025": 1117.781035301852
        },
        "mistral-medium-2505": {
            "rating": 1124.128284917068,
            "rating_q975": 1159.3876692385084,
            "rating_q025": 1088.8689005956276
        },
        "mistral-small-3.1-24b-instruct-2503": {
            "rating": 1118.5572375828074,
            "rating_q975": 1153.8788782101985,
            "rating_q025": 1083.2355969554162
        },
        "mistral-small-2506": {
            "rating": 1112.4489322764248,
            "rating_q975": 1148.9694800630289,
            "rating_q025": 1075.9283844898207
        }
    },
    "full": {
        "gemini-3-pro": {
            "rating": 1308.7270277785597,
            "rating_q975": 1320.7595538785179,
            "rating_q025": 1296.6945016786015
        },
        "gpt-5.1-high": {
            "rating": 1248.959291635541,
            "rating_q975": 1263.7415838107368,
            "rating_q025": 1234.176999460345
        },
        "gemini-2.5-pro": {
            "rating": 1248.4243551545035,
            "rating_q975": 1255.5536183716317,
            "rating_q025": 1241.2950919373752
        },
        "gpt-5.1": {
            "rating": 1237.9260262921543,
            "rating_q975": 1252.2963012106754,
            "rating_q025": 1223.5557513736333
        },
        "chatgpt-4o-latest-20250326": {
            "rating": 1235.997713741261,
            "rating_q975": 1242.8470375554984,
            "rating_q025": 1229.1483899270233
        },
        "gpt-4.5-preview-2025-02-27": {
            "rating": 1226.1031849255046,
            "rating_q975": 1237.438649020029,
            "rating_q025": 1214.7677208309801
        },
        "gemini-2.5-flash-preview-09-2025": {
            "rating": 1224.124771713133,
            "rating_q975": 1234.5250700338431,
            "rating_q025": 1213.7244733924229
        },
        "gpt-5-chat": {
            "rating": 1222.7146608831645,
            "rating_q975": 1230.603248615529,
            "rating_q025": 1214.8260731507999
        },
        "o3-2025-04-16": {
            "rating": 1217.3962641494513,
            "rating_q975": 1224.603755747226,
            "rating_q025": 1210.1887725516767
        },
        "gpt-4.1-2025-04-14": {
            "rating": 1215.4339767552838,
            "rating_q975": 1222.6158735256915,
            "rating_q025": 1208.252079984876
        },
        "gemini-2.5-flash": {
            "rating": 1214.6771036042135,
            "rating_q975": 1221.902577099973,
            "rating_q025": 1207.4516301084539
        },
        "gpt-5-high": {
            "rating": 1209.6509807971463,
            "rating_q975": 1218.0370856327008,
            "rating_q025": 1201.2648759615918
        },
        "claude-opus-4-20250514-thinking-16k": {
            "rating": 1209.381058258179,
            "rating_q975": 1224.7239146455033,
            "rating_q025": 1194.038201870855
        },
        "qwen3-vl-235b-a22b-instruct": {
            "rating": 1207.3763856002615,
            "rating_q975": 1217.6441840185603,
            "rating_q025": 1197.1085871819628
        },
        "claude-sonnet-4-20250514-thinking-32k": {
            "rating": 1204.6899533540438,
            "rating_q975": 1220.4723039876922,
            "rating_q025": 1188.9076027203955
        },
        "ernie-5.0-preview-1120": {
            "rating": 1202.1621620433668,
            "rating_q975": 1214.9403702264856,
            "rating_q025": 1189.383953860248
        },
        "gpt-4.1-mini-2025-04-14": {
            "rating": 1201.9483069005173,
            "rating_q975": 1209.8691242575387,
            "rating_q025": 1194.027489543496
        },
        "o4-mini-2025-04-16": {
            "rating": 1201.9418730680554,
            "rating_q975": 1209.5991166246156,
            "rating_q025": 1194.2846295114953
        },
        "claude-3-7-sonnet-20250219-thinking-32k": {
            "rating": 1195.1313717026853,
            "rating_q975": 1209.8851870593921,
            "rating_q025": 1180.3775563459785
        },
        "hunyuan-vision-1.5-thinking": {
            "rating": 1193.6599789612712,
            "rating_q975": 1205.9030979037043,
            "rating_q025": 1181.4168600188382
        },
        "o1-2024-12-17": {
            "rating": 1192.7972007795042,
            "rating_q975": 1203.1331690126572,
            "rating_q025": 1182.4612325463513
        },
        "qwen3-vl-235b-a22b-thinking": {
            "rating": 1190.0852580475316,
            "rating_q975": 1202.5740027191198,
            "rating_q025": 1177.5965133759435
        },
        "claude-opus-4-20250514": {
            "rating": 1188.9194534321875,
            "rating_q975": 1201.303821077433,
            "rating_q025": 1176.535085786942
        },
        "gemini-2.5-flash-lite-preview-06-17-thinking": {
            "rating": 1188.35,
            "rating_q975": 1196.364162530105,
            "rating_q025": 1180.3358374698948
        },
        "claude-sonnet-4-20250514": {
            "rating": 1186.7312960012794,
            "rating_q975": 1200.1625548934323,
            "rating_q025": 1173.3000371091264
        },
        "qwen-vl-max-2025-08-13": {
            "rating": 1184.0460738339268,
            "rating_q975": 1196.3490377899416,
            "rating_q025": 1171.743109877912
        },
        "gpt-5-mini-high": {
            "rating": 1183.4688327981469,
            "rating_q975": 1192.3672984648904,
            "rating_q025": 1174.5703671314034
        },
        "grok-4-0709": {
            "rating": 1180.918417147568,
            "rating_q975": 1188.91387831823,
            "rating_q025": 1172.9229559769062
        },
        "gemini-2.5-flash-lite-preview-09-2025-no-thinking": {
            "rating": 1178.250591942898,
            "rating_q975": 1188.4596587578785,
            "rating_q025": 1168.0415251279173
        },
        "gemini-1.5-pro-002": {
            "rating": 1177.883092143532,
            "rating_q975": 1186.0365346905016,
            "rating_q025": 1169.7296495965622
        },
        "claude-3-7-sonnet-20250219": {
            "rating": 1177.1329086202345,
            "rating_q975": 1186.2880609924591,
            "rating_q025": 1167.9777562480099
        },
        "gemini-2.0-flash-001": {
            "rating": 1168.615794791615,
            "rating_q975": 1175.7223897375084,
            "rating_q025": 1161.5091998457215
        },
        "gpt-4o-2024-05-13": {
            "rating": 1162.0183437606468,
            "rating_q975": 1169.7267691807237,
            "rating_q025": 1154.3099183405698
        },
        "claude-3-5-sonnet-20241022": {
            "rating": 1161.3964180262578,
            "rating_q975": 1168.561047373175,
            "rating_q025": 1154.2317886793408
        },
        "glm-4.5v": {
            "rating": 1156.946392723596,
            "rating_q975": 1168.7995837083377,
            "rating_q025": 1145.0932017388545
        },
        "mistral-medium-2505": {
            "rating": 1155.8847253131644,
            "rating_q975": 1164.4924457341867,
            "rating_q025": 1147.277004892142
        },
        "step-1o-turbo-202506": {
            "rating": 1154.4324452035612,
            "rating_q975": 1168.760528755185,
            "rating_q025": 1140.1043616519373
        },
        "gemma-3-27b-it": {
            "rating": 1154.3988705714082,
            "rating_q975": 1162.9033454376952,
            "rating_q025": 1145.8943957051213
        },
        "mistral-medium-2508": {
            "rating": 1148.882196354525,
            "rating_q975": 1157.1128172479025,
            "rating_q025": 1140.6515754611473
        },
        "claude-3-5-sonnet-20240620": {
            "rating": 1147.1222672177082,
            "rating_q975": 1156.3504028899122,
            "rating_q025": 1137.8941315455043
        },
        "hunyuan-large-vision": {
            "rating": 1147.1118042843414,
            "rating_q975": 1163.065386861346,
            "rating_q025": 1131.1582217073367
        },
        "gpt-5-nano-high": {
            "rating": 1146.4991948710979,
            "rating_q975": 1158.2887704201999,
            "rating_q025": 1134.709619321996
        },
        "llama-4-maverick-17b-128e-instruct": {
            "rating": 1146.0560377680754,
            "rating_q975": 1155.4778122922048,
            "rating_q025": 1136.634263243946
        },
        "step-3": {
            "rating": 1140.8922451297617,
            "rating_q975": 1152.8930797907312,
            "rating_q025": 1128.8914104687922
        },
        "mistral-small-2506": {
            "rating": 1139.322167114507,
            "rating_q975": 1148.8786664081163,
            "rating_q025": 1129.7656678208978
        },
        "gemini-1.5-flash-002": {
            "rating": 1138.2308321096789,
            "rating_q975": 1147.2864582805407,
            "rating_q025": 1129.175205938817
        },
        "claude-3-5-haiku-20241022": {
            "rating": 1135.0925238384407,
            "rating_q975": 1150.4436894014916,
            "rating_q025": 1119.7413582753898
        },
        "gemini-2.0-flash-lite-preview-02-05": {
            "rating": 1133.1462270914635,
            "rating_q975": 1143.0506533325745,
            "rating_q025": 1123.2418008503525
        },
        "mistral-small-3.1-24b-instruct-2503": {
            "rating": 1125.5585729998172,
            "rating_q975": 1134.446274053806,
            "rating_q025": 1116.6708719458284
        },
        "llama-4-scout-17b-16e-instruct": {
            "rating": 1125.4816523766922,
            "rating_q975": 1135.2553069148632,
            "rating_q025": 1115.7079978385211
        },
        "step-1o-vision-32k-highres": {
            "rating": 1123.8863218305423,
            "rating_q975": 1135.9681536916657,
            "rating_q025": 1111.804489969419
        },
        "qwen2.5-vl-72b-instruct": {
            "rating": 1121.874426377176,
            "rating_q975": 1132.186615085216,
            "rating_q025": 1111.5622376691358
        },
        "gpt-4o-2024-08-06": {
            "rating": 1118.6800935045662,
            "rating_q975": 1130.3027522501463,
            "rating_q025": 1107.0574347589861
        },
        "gemini-1.5-pro-001": {
            "rating": 1117.4566103546988,
            "rating_q975": 1128.3259278205146,
            "rating_q025": 1106.587292888883
        },
        "qwen2.5-vl-32b-instruct": {
            "rating": 1116.8923873108906,
            "rating_q975": 1132.3795640318865,
            "rating_q025": 1101.4052105898948
        },
        "gpt-4-turbo-2024-04-09": {
            "rating": 1112.8220856032312,
            "rating_q975": 1123.6645129305668,
            "rating_q025": 1101.9796582758956
        },
        "gpt-4o-mini-2024-07-18": {
            "rating": 1097.606822690249,
            "rating_q975": 1104.8976060613759,
            "rating_q025": 1090.316039319122
        },
        "pixtral-large-2411": {
            "rating": 1093.8783261898734,
            "rating_q975": 1102.4323819737601,
            "rating_q025": 1085.3242704059867
        },
        "gpt-4.1-nano-2025-04-14": {
            "rating": 1088.8836691035128,
            "rating_q975": 1107.1723926760658,
            "rating_q025": 1070.5949455309599
        },
        "qwen2-vl-72b": {
            "rating": 1085.3019181627023,
            "rating_q975": 1094.6265328312202,
            "rating_q025": 1075.9773034941845
        },
        "qwen-vl-max-1119": {
            "rating": 1085.1331921757771,
            "rating_q975": 1100.6395913286894,
            "rating_q025": 1069.6267930228648
        },
        "gemini-1.5-flash-8b-001": {
            "rating": 1069.8947700869473,
            "rating_q975": 1079.6845056389432,
            "rating_q025": 1060.1050345349515
        },
        "claude-3-opus-20240229": {
            "rating": 1064.2818628556245,
            "rating_q975": 1073.8613926711353,
            "rating_q025": 1054.7023330401137
        },
        "step-1v-32k": {
            "rating": 1061.8491392285641,
            "rating_q975": 1078.1092577288387,
            "rating_q025": 1045.5890207282896
        },
        "gemini-1.5-flash-001": {
            "rating": 1059.9442323905,
            "rating_q975": 1071.1092774304707,
            "rating_q025": 1048.7791873505294
        },
        "molmo-72b-0924": {
            "rating": 1047.6946447969376,
            "rating_q975": 1060.160981149436,
            "rating_q025": 1035.228308444439
        },
        "hunyuan-standard-vision-2024-12-31": {
            "rating": 1043.424759709871,
            "rating_q975": 1064.22435203944,
            "rating_q025": 1022.6251673803021
        },
        "llama-3.2-vision-90b-instruct": {
            "rating": 1032.3906317453007,
            "rating_q975": 1040.691863026516,
            "rating_q025": 1024.0894004640852
        },
        "qwen2-vl-7b-instruct": {
            "rating": 1031.744536779823,
            "rating_q975": 1041.5199755982921,
            "rating_q025": 1021.9690979613537
        },
        "pixtral-12b-2409": {
            "rating": 1025.0850892499197,
            "rating_q975": 1033.73726572198,
            "rating_q025": 1016.4329127778593
        },
        "internvl2-26b": {
            "rating": 1024.6063079423766,
            "rating_q975": 1036.8069891451592,
            "rating_q025": 1012.405626739594
        },
        "amazon-nova-lite-v1.0": {
            "rating": 1020.554117867938,
            "rating_q975": 1035.082187302939,
            "rating_q025": 1006.0260484329369
        },
        "amazon-nova-pro-v1.0": {
            "rating": 1020.1084296102874,
            "rating_q975": 1033.352943748643,
            "rating_q025": 1006.863915471932
        },
        "claude-3-sonnet-20240229": {
            "rating": 1019.4076275977155,
            "rating_q975": 1030.0848137326764,
            "rating_q025": 1008.7304414627547
        },
        "yi-vision": {
            "rating": 1004.5282118895074,
            "rating_q975": 1022.2102072018777,
            "rating_q025": 986.846216577137
        },
        "claude-3-haiku-20240307": {
            "rating": 1002.4645945579282,
            "rating_q975": 1014.2493918994093,
            "rating_q025": 990.6797972164471
        },
        "c4ai-aya-vision-32b": {
            "rating": 1000.2797188494212,
            "rating_q975": 1022.1537399793605,
            "rating_q025": 978.405697719482
        },
        "molmo-7b-d-0924": {
            "rating": 996.2414905444552,
            "rating_q975": 1009.4349028610982,
            "rating_q025": 983.0480782278123
        },
        "llama-3.2-vision-11b-instruct": {
            "rating": 991.0638568423949,
            "rating_q975": 1001.6241715499355,
            "rating_q025": 980.5035421348543
        },
        "nvila-internal-15b-v1": {
            "rating": 987.7457873026038,
            "rating_q975": 1007.5533487482895,
            "rating_q025": 967.9382258569182
        },
        "llava-onevision-qwen2-72b-ov": {
            "rating": 980.8214052415019,
            "rating_q975": 998.6382436647446,
            "rating_q025": 963.0045668182593
        },
        "llava-v1.6-34b": {
            "rating": 966.548694108422,
            "rating_q975": 978.1547925751678,
            "rating_q025": 954.9425956416761
        },
        "minicpm-v-2_6": {
            "rating": 965.0104486555879,
            "rating_q975": 980.3639016526112,
            "rating_q025": 949.6569956585646
        },
        "cogvlm2-llama3-chat-19b": {
            "rating": 964.3173415381303,
            "rating_q975": 979.0468174661329,
            "rating_q025": 949.5878656101278
        },
        "internvl2-4b": {
            "rating": 957.8529783307588,
            "rating_q975": 969.8024802352845,
            "rating_q025": 945.903476426233
        },
        "phi-3.5-vision-instruct": {
            "rating": 922.0518836454595,
            "rating_q975": 937.398694696086,
            "rating_q025": 906.705072594833
        },
        "phi-3-vision-128k-instruct": {
            "rating": 884.0391563909827,
            "rating_q975": 902.3462481534392,
            "rating_q025": 865.7320646285262
        }
    },
    "homework": {
        "gemini-3-pro": {
            "rating": 1332.4477064275163,
            "rating_q975": 1356.6406661091185,
            "rating_q025": 1308.2547467459142
        },
        "hunyuan-vision-1.5-thinking": {
            "rating": 1292.7693492097537,
            "rating_q975": 1321.708389179801,
            "rating_q025": 1263.8303092397064
        },
        "gpt-5-chat": {
            "rating": 1278.3733626577607,
            "rating_q975": 1293.782272629705,
            "rating_q025": 1262.9644526858165
        },
        "gpt-5.1-high": {
            "rating": 1273.1878790734688,
            "rating_q975": 1308.521687229365,
            "rating_q025": 1237.8540709175727
        },
        "gemini-2.5-pro": {
            "rating": 1268.8807016765845,
            "rating_q975": 1281.2960878668214,
            "rating_q025": 1256.4653154863477
        },
        "gpt-5.1": {
            "rating": 1263.5364835628793,
            "rating_q975": 1298.0062129731432,
            "rating_q025": 1229.0667541526154
        },
        "gpt-5-high": {
            "rating": 1259.8420476981794,
            "rating_q975": 1276.6176082798868,
            "rating_q025": 1243.066487116472
        },
        "gemini-2.5-flash-preview-09-2025": {
            "rating": 1257.9809045131535,
            "rating_q975": 1279.2425088151658,
            "rating_q025": 1236.7193002111412
        },
        "qwen-vl-max-2025-08-13": {
            "rating": 1255.0194879797607,
            "rating_q975": 1292.9789723768142,
            "rating_q025": 1217.0600035827072
        },
        "o4-mini-2025-04-16": {
            "rating": 1253.8723611158223,
            "rating_q975": 1268.0708521960426,
            "rating_q025": 1239.673870035602
        },
        "o3-2025-04-16": {
            "rating": 1249.7629275349273,
            "rating_q975": 1263.129941099259,
            "rating_q025": 1236.3959139705955
        },
        "claude-opus-4-20250514-thinking-16k": {
            "rating": 1248.912478084643,
            "rating_q975": 1288.622445396329,
            "rating_q025": 1209.2025107729569
        },
        "ernie-5.0-preview-1120": {
            "rating": 1242.6344551198695,
            "rating_q975": 1274.5725471472915,
            "rating_q025": 1210.6963630924474
        },
        "gpt-4.1-2025-04-14": {
            "rating": 1241.806925056003,
            "rating_q975": 1256.158091959075,
            "rating_q025": 1227.455758152931
        },
        "gpt-5-mini-high": {
            "rating": 1240.3870540902374,
            "rating_q975": 1258.8407196778046,
            "rating_q025": 1221.9333885026701
        },
        "chatgpt-4o-latest-20250326": {
            "rating": 1238.2026870254726,
            "rating_q975": 1253.5615842752752,
            "rating_q025": 1222.84378977567
        },
        "qwen3-vl-235b-a22b-instruct": {
            "rating": 1237.1524093355615,
            "rating_q975": 1258.6053439145912,
            "rating_q025": 1215.6994747565318
        },
        "gemini-2.5-flash": {
            "rating": 1230.7966703302186,
            "rating_q975": 1244.1217933693194,
            "rating_q025": 1217.4715472911178
        },
        "claude-opus-4-20250514": {
            "rating": 1229.5786757956657,
            "rating_q975": 1258.917270965064,
            "rating_q025": 1200.2400806262674
        },
        "claude-sonnet-4-20250514": {
            "rating": 1229.1242891272211,
            "rating_q975": 1260.79638322797,
            "rating_q025": 1197.4521950264723
        },
        "qwen3-vl-235b-a22b-thinking": {
            "rating": 1227.7614005798582,
            "rating_q975": 1255.672570639504,
            "rating_q025": 1199.8502305202123
        },
        "claude-3-7-sonnet-20250219": {
            "rating": 1225.9158532637907,
            "rating_q975": 1258.3907199429964,
            "rating_q025": 1193.440986584585
        },
        "gpt-4.1-mini-2025-04-14": {
            "rating": 1224.7148635607252,
            "rating_q975": 1239.6158589803103,
            "rating_q025": 1209.8138681411401
        },
        "claude-3-7-sonnet-20250219-thinking-32k": {
            "rating": 1219.031435409617,
            "rating_q975": 1255.9423161212944,
            "rating_q025": 1182.1205546979395
        },
        "gemini-2.0-flash-001": {
            "rating": 1195.4292593302043,
            "rating_q975": 1215.2457644522424,
            "rating_q025": 1175.6127542081663
        },
        "gemini-2.5-flash-lite-preview-09-2025-no-thinking": {
            "rating": 1189.0502620415484,
            "rating_q975": 1209.8192184996246,
            "rating_q025": 1168.2813055834722
        },
        "gemini-2.5-flash-lite-preview-06-17-thinking": {
            "rating": 1188.35,
            "rating_q975": 1203.1123138107762,
            "rating_q025": 1173.5876861892236
        },
        "mistral-medium-2508": {
            "rating": 1181.187183910312,
            "rating_q975": 1197.6112157511748,
            "rating_q025": 1164.763152069449
        },
        "claude-3-5-sonnet-20241022": {
            "rating": 1179.7313604371338,
            "rating_q975": 1214.155619242385,
            "rating_q025": 1145.3071016318827
        },
        "step-3": {
            "rating": 1179.1627805398298,
            "rating_q975": 1213.488322076174,
            "rating_q025": 1144.8372390034856
        },
        "gpt-5-nano-high": {
            "rating": 1178.1464539654048,
            "rating_q975": 1210.228098326634,
            "rating_q025": 1146.0648096041757
        },
        "mistral-small-2506": {
            "rating": 1173.845444963939,
            "rating_q975": 1194.3028861599093,
            "rating_q025": 1153.3880037679685
        },
        "gemma-3-27b-it": {
            "rating": 1171.1127851240794,
            "rating_q975": 1187.9149501231673,
            "rating_q025": 1154.3106201249916
        },
        "llama-4-maverick-17b-128e-instruct": {
            "rating": 1168.0502961140032,
            "rating_q975": 1189.605932892524,
            "rating_q025": 1146.4946593354825
        },
        "glm-4.5v": {
            "rating": 1168.0495149419685,
            "rating_q975": 1202.8184178235679,
            "rating_q025": 1133.280612060369
        },
        "grok-4-0709": {
            "rating": 1165.2512064298517,
            "rating_q975": 1181.7845146458126,
            "rating_q025": 1148.7178982138907
        },
        "mistral-medium-2505": {
            "rating": 1164.211900039792,
            "rating_q975": 1182.1795593497257,
            "rating_q025": 1146.2442407298583
        },
        "mistral-small-3.1-24b-instruct-2503": {
            "rating": 1158.9961075143922,
            "rating_q975": 1177.281983960055,
            "rating_q025": 1140.7102310687294
        },
        "claude-3-5-haiku-20241022": {
            "rating": 1157.4056759772461,
            "rating_q975": 1191.21462519047,
            "rating_q025": 1123.5967267640222
        },
        "llama-4-scout-17b-16e-instruct": {
            "rating": 1153.092021190589,
            "rating_q975": 1176.4897577549677,
            "rating_q025": 1129.6942846262104
        },
        "step-1o-turbo-202506": {
            "rating": 1138.0730455287076,
            "rating_q975": 1170.5390869031917,
            "rating_q025": 1105.6070041542234
        },
        "hunyuan-large-vision": {
            "rating": 1132.3207484400568,
            "rating_q975": 1172.6501845829257,
            "rating_q025": 1091.991312297188
        }
    },
    "humor": {
        "gemini-3-pro": {
            "rating": 1366.6653122310358,
            "rating_q975": 1403.242826779321,
            "rating_q025": 1330.0877976827508
        },
        "gemini-2.5-flash-preview-09-2025": {
            "rating": 1240.2839763918387,
            "rating_q975": 1274.6391709452837,
            "rating_q025": 1205.9287818383937
        },
        "gemini-2.5-pro": {
            "rating": 1233.8752122648862,
            "rating_q975": 1248.3298453640562,
            "rating_q025": 1219.4205791657162
        },
        "chatgpt-4o-latest-20250326": {
            "rating": 1220.245138970271,
            "rating_q975": 1244.1588333100763,
            "rating_q025": 1196.3314446304657
        },
        "o3-2025-04-16": {
            "rating": 1218.0225087316392,
            "rating_q975": 1234.514988875583,
            "rating_q025": 1201.5300285876954
        },
        "gpt-5-chat": {
            "rating": 1211.2785319036584,
            "rating_q975": 1228.3687681097415,
            "rating_q025": 1194.1882956975753
        },
        "gpt-5-high": {
            "rating": 1206.0424830991362,
            "rating_q975": 1227.4237681876964,
            "rating_q025": 1184.661198010576
        },
        "gemini-2.5-flash": {
            "rating": 1204.0663544056954,
            "rating_q975": 1220.9114952231218,
            "rating_q025": 1187.221213588269
        },
        "gpt-4.1-2025-04-14": {
            "rating": 1194.4908344698724,
            "rating_q975": 1211.5268926240876,
            "rating_q025": 1177.4547763156572
        },
        "o4-mini-2025-04-16": {
            "rating": 1190.294827956533,
            "rating_q975": 1208.0476195115355,
            "rating_q025": 1172.5420364015306
        },
        "gemini-2.5-flash-lite-preview-06-17-thinking": {
            "rating": 1188.35,
            "rating_q975": 1205.4183781044012,
            "rating_q025": 1171.2816218955986
        },
        "gpt-4.1-mini-2025-04-14": {
            "rating": 1187.5887235451705,
            "rating_q975": 1204.9458042711387,
            "rating_q025": 1170.2316428192023
        },
        "grok-4-0709": {
            "rating": 1183.7243338928993,
            "rating_q975": 1201.7184678720964,
            "rating_q025": 1165.730199913702
        },
        "gemini-2.0-flash-001": {
            "rating": 1172.9496116666191,
            "rating_q975": 1210.9915198192257,
            "rating_q025": 1134.9077035140126
        },
        "gpt-5-mini-high": {
            "rating": 1168.6705347704647,
            "rating_q975": 1192.3600360722714,
            "rating_q025": 1144.9810334686579
        },
        "qwen3-vl-235b-a22b-instruct": {
            "rating": 1161.4327412599496,
            "rating_q975": 1197.9219644591296,
            "rating_q025": 1124.9435180607695
        },
        "mistral-medium-2508": {
            "rating": 1150.2748971224237,
            "rating_q975": 1168.4727160702676,
            "rating_q025": 1132.0770781745798
        },
        "gemma-3-27b-it": {
            "rating": 1148.1084563219852,
            "rating_q975": 1169.6056475127184,
            "rating_q025": 1126.611265131252
        },
        "gemini-2.5-flash-lite-preview-09-2025-no-thinking": {
            "rating": 1145.4982480102274,
            "rating_q975": 1180.90888194872,
            "rating_q025": 1110.0876140717348
        },
        "mistral-medium-2505": {
            "rating": 1134.7818983993673,
            "rating_q975": 1161.7509281469042,
            "rating_q025": 1107.8128686518303
        },
        "mistral-small-3.1-24b-instruct-2503": {
            "rating": 1114.923680561758,
            "rating_q975": 1135.7737331455248,
            "rating_q025": 1094.073627977991
        },
        "mistral-small-2506": {
            "rating": 1097.1523279287192,
            "rating_q975": 1125.8403107023382,
            "rating_q025": 1068.4643451551
        },
        "llama-4-maverick-17b-128e-instruct": {
            "rating": 1093.3845798411612,
            "rating_q975": 1129.6736526997947,
            "rating_q025": 1057.0955069825277
        },
        "llama-4-scout-17b-16e-instruct": {
            "rating": 1081.804979497797,
            "rating_q975": 1121.1790336414006,
            "rating_q025": 1042.4309253541933
        }
    },
    "ocr": {
        "gemini-3-pro": {
            "rating": 1317.7085270626503,
            "rating_q975": 1331.4094561168815,
            "rating_q025": 1304.007598008419
        },
        "gemini-2.5-pro": {
            "rating": 1261.5900007336732,
            "rating_q975": 1268.7272596069656,
            "rating_q025": 1254.4527418603807
        },
        "gpt-5.1": {
            "rating": 1261.3158016554376,
            "rating_q975": 1278.560606373532,
            "rating_q025": 1244.0709969373431
        },
        "gpt-5.1-high": {
            "rating": 1256.0622092635963,
            "rating_q975": 1273.3906070873418,
            "rating_q025": 1238.7338114398508
        },
        "gpt-5-chat": {
            "rating": 1239.3463424601118,
            "rating_q975": 1247.936949262041,
            "rating_q025": 1230.7557356581826
        },
        "chatgpt-4o-latest-20250326": {
            "rating": 1239.1715506774372,
            "rating_q975": 1247.408200554,
            "rating_q025": 1230.9349008008744
        },
        "gemini-2.5-flash-preview-09-2025": {
            "rating": 1237.2771601116983,
            "rating_q975": 1248.6055201125323,
            "rating_q025": 1225.9488001108643
        },
        "gpt-5-high": {
            "rating": 1235.6681204380925,
            "rating_q975": 1245.3595614699918,
            "rating_q025": 1225.9766794061932
        },
        "o3-2025-04-16": {
            "rating": 1225.615071788382,
            "rating_q975": 1233.2226073998825,
            "rating_q025": 1218.0075361768816
        },
        "qwen3-vl-235b-a22b-instruct": {
            "rating": 1224.2041558960502,
            "rating_q975": 1235.5698737697317,
            "rating_q025": 1212.8384380223688
        },
        "gemini-2.5-flash": {
            "rating": 1224.1463853421642,
            "rating_q975": 1231.6929739887487,
            "rating_q025": 1216.5997966955797
        },
        "claude-opus-4-20250514-thinking-16k": {
            "rating": 1223.775079190782,
            "rating_q975": 1242.6694137889217,
            "rating_q025": 1204.8807445926423
        },
        "gpt-4.1-2025-04-14": {
            "rating": 1223.5152486229995,
            "rating_q975": 1231.6014475584266,
            "rating_q025": 1215.4290496875724
        },
        "ernie-5.0-preview-1120": {
            "rating": 1220.5802822250805,
            "rating_q975": 1235.4068020592288,
            "rating_q025": 1205.7537623909323
        },
        "claude-sonnet-4-20250514-thinking-32k": {
            "rating": 1213.6738234697236,
            "rating_q975": 1233.426714674934,
            "rating_q025": 1193.9209322645133
        },
        "claude-3-7-sonnet-20250219-thinking-32k": {
            "rating": 1211.63638778593,
            "rating_q975": 1229.8866046323299,
            "rating_q025": 1193.3861709395303
        },
        "o4-mini-2025-04-16": {
            "rating": 1210.0599516126517,
            "rating_q975": 1218.2595155684264,
            "rating_q025": 1201.860387656877
        },
        "qwen-vl-max-2025-08-13": {
            "rating": 1208.8910105598325,
            "rating_q975": 1225.9298529972255,
            "rating_q025": 1191.8521681224395
        },
        "gpt-5-mini-high": {
            "rating": 1208.569169308976,
            "rating_q975": 1219.0877254620539,
            "rating_q025": 1198.050613155898
        },
        "gpt-4.1-mini-2025-04-14": {
            "rating": 1204.2890165345175,
            "rating_q975": 1212.970197250023,
            "rating_q025": 1195.607835819012
        },
        "qwen3-vl-235b-a22b-thinking": {
            "rating": 1202.2329966005705,
            "rating_q975": 1217.1617527347478,
            "rating_q025": 1187.3042404663931
        },
        "claude-opus-4-20250514": {
            "rating": 1194.6206503326116,
            "rating_q975": 1209.6786456236168,
            "rating_q025": 1179.5626550416064
        },
        "hunyuan-vision-1.5-thinking": {
            "rating": 1191.148016157188,
            "rating_q975": 1205.9872514015685,
            "rating_q025": 1176.3087809128076
        },
        "gemini-2.5-flash-lite-preview-06-17-thinking": {
            "rating": 1188.35,
            "rating_q975": 1196.75965125532,
            "rating_q025": 1179.9403487446798
        },
        "claude-sonnet-4-20250514": {
            "rating": 1186.4834672740205,
            "rating_q975": 1202.7300877592163,
            "rating_q025": 1170.2368467888248
        },
        "gemini-2.5-flash-lite-preview-09-2025-no-thinking": {
            "rating": 1186.019916110068,
            "rating_q975": 1197.1748736508164,
            "rating_q025": 1174.8649585693195
        },
        "claude-3-7-sonnet-20250219": {
            "rating": 1185.6035526806331,
            "rating_q975": 1203.7422883299043,
            "rating_q025": 1167.464817031362
        },
        "claude-3-5-sonnet-20241022": {
            "rating": 1179.405218216109,
            "rating_q975": 1197.5359830235307,
            "rating_q025": 1161.2744534086874
        },
        "grok-4-0709": {
            "rating": 1173.7793844280009,
            "rating_q975": 1182.1978050059172,
            "rating_q025": 1165.3609638500845
        },
        "mistral-medium-2508": {
            "rating": 1164.850769848982,
            "rating_q975": 1174.039236895178,
            "rating_q025": 1155.6623028027861
        },
        "gemini-2.0-flash-001": {
            "rating": 1163.1070231082522,
            "rating_q975": 1173.888992967069,
            "rating_q025": 1152.3250532494353
        },
        "gpt-5-nano-high": {
            "rating": 1158.4385034234774,
            "rating_q975": 1173.5166027424216,
            "rating_q025": 1143.3604041045332
        },
        "gemma-3-27b-it": {
            "rating": 1157.8716726105317,
            "rating_q975": 1167.1335275240688,
            "rating_q025": 1148.6098176969947
        },
        "mistral-medium-2505": {
            "rating": 1157.3293723685288,
            "rating_q975": 1166.9371217666217,
            "rating_q025": 1147.7216229704359
        },
        "glm-4.5v": {
            "rating": 1154.8816983809616,
            "rating_q975": 1170.9418862927687,
            "rating_q025": 1138.8215104691544
        },
        "step-1o-turbo-202506": {
            "rating": 1152.4074351210147,
            "rating_q975": 1168.4152796179128,
            "rating_q025": 1136.3995906241166
        },
        "llama-4-maverick-17b-128e-instruct": {
            "rating": 1152.1498350870597,
            "rating_q975": 1163.0555097471884,
            "rating_q025": 1141.244160426931
        },
        "hunyuan-large-vision": {
            "rating": 1148.2221252525474,
            "rating_q975": 1167.275097541792,
            "rating_q025": 1129.1691529633026
        },
        "step-3": {
            "rating": 1147.4723058694071,
            "rating_q975": 1163.620656377826,
            "rating_q025": 1131.3239553609883
        },
        "claude-3-5-haiku-20241022": {
            "rating": 1138.7227779855098,
            "rating_q975": 1157.3263202451487,
            "rating_q025": 1120.1192357258708
        },
        "mistral-small-2506": {
            "rating": 1138.3406176117062,
            "rating_q975": 1148.8012636413978,
            "rating_q025": 1127.8799715820146
        },
        "mistral-small-3.1-24b-instruct-2503": {
            "rating": 1135.1393282950717,
            "rating_q975": 1144.8063363883819,
            "rating_q025": 1125.4723202017615
        },
        "llama-4-scout-17b-16e-instruct": {
            "rating": 1128.333761954897,
            "rating_q975": 1139.9575409618728,
            "rating_q025": 1116.7099829479212
        }
    }
}