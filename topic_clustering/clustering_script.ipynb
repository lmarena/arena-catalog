{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%capture\n",
    "# %pip install datasets\n",
    "# %pip install bertopic\n",
    "# %pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json, math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to huggingface\n",
    "# %pip install huggingface_hub\n",
    "# from huggingface_hub import login\n",
    "# login('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', add_to_git_credential=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_json(\"/mnt/disk0/weilin/tmp/battles_latest_20240819_freshness_20240619_md.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question_id</th>\n",
       "      <th>model_a</th>\n",
       "      <th>model_b</th>\n",
       "      <th>winner</th>\n",
       "      <th>conversation_a</th>\n",
       "      <th>conversation_b</th>\n",
       "      <th>turn</th>\n",
       "      <th>anony</th>\n",
       "      <th>language</th>\n",
       "      <th>tstamp</th>\n",
       "      <th>conv_metadata</th>\n",
       "      <th>is_code</th>\n",
       "      <th>is_refusal</th>\n",
       "      <th>dedup_tag</th>\n",
       "      <th>category_tag</th>\n",
       "      <th>judge_hash</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4c6978dfa56b4ffea9d3a47e3c84181a</td>\n",
       "      <td>claude-3-5-sonnet-20240620</td>\n",
       "      <td>gpt-3.5-turbo-0125</td>\n",
       "      <td>tie (bothbad)</td>\n",
       "      <td>[{'role': 'user', 'content': 'В моем портфеле ...</td>\n",
       "      <td>[{'role': 'user', 'content': 'В моем портфеле ...</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>Russian</td>\n",
       "      <td>1.719064e+09</td>\n",
       "      <td>{'sum_user_tokens': 290, 'sum_assistant_a_toke...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>{'high_freq': False, 'sampled': True}</td>\n",
       "      <td>{'if_v0.1': {'if': True, 'score': 4}, 'math_v0...</td>\n",
       "      <td>a75630e1759a83f9d476889eee3a4063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>76ce56f8ba474768bc66128c7993ccb8</td>\n",
       "      <td>mistral-large-2407</td>\n",
       "      <td>athene-70b-0725</td>\n",
       "      <td>model_b</td>\n",
       "      <td>[{'role': 'user', 'content': 'php, handle tab ...</td>\n",
       "      <td>[{'role': 'user', 'content': 'php, handle tab ...</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>English</td>\n",
       "      <td>1.722726e+09</td>\n",
       "      <td>{'sum_user_tokens': 23, 'sum_assistant_a_token...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>{'high_freq': False, 'sampled': True}</td>\n",
       "      <td>{'if_v0.1': {'if': False, 'score': 1}, 'math_v...</td>\n",
       "      <td>093c8631190fc9fed2ad75a365861d23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>385420904ba646e7a4df90c6ffae1afa</td>\n",
       "      <td>claude-3-opus-20240229</td>\n",
       "      <td>gemini-1.5-flash-api-0514</td>\n",
       "      <td>tie (bothbad)</td>\n",
       "      <td>[{'role': 'user', 'content': '普通人在愿意付出一定资源的情况下...</td>\n",
       "      <td>[{'role': 'user', 'content': '普通人在愿意付出一定资源的情况下...</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>Chinese</td>\n",
       "      <td>1.723119e+09</td>\n",
       "      <td>{'sum_user_tokens': 44, 'sum_assistant_a_token...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>{'high_freq': False, 'sampled': True}</td>\n",
       "      <td>{'if_v0.1': {'if': False, 'score': 3}, 'math_v...</td>\n",
       "      <td>a92c23ff97936574bee79f89e350ea80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>e8fe7c9f75ab4e528367cc7de625c475</td>\n",
       "      <td>gemma-2-9b-it</td>\n",
       "      <td>qwen2-72b-instruct</td>\n",
       "      <td>model_b</td>\n",
       "      <td>[{'role': 'user', 'content': 'Is there any Art...</td>\n",
       "      <td>[{'role': 'user', 'content': 'Is there any Art...</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>English</td>\n",
       "      <td>1.721643e+09</td>\n",
       "      <td>{'sum_user_tokens': 14, 'sum_assistant_a_token...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>{'high_freq': False, 'sampled': True}</td>\n",
       "      <td>{'if_v0.1': {'if': False, 'score': 1}, 'math_v...</td>\n",
       "      <td>26ac88d9f790142cd34c237fe369738c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>772d53e5c51c487e8a293eadcd9d4855</td>\n",
       "      <td>mixtral-8x22b-instruct-v0.1</td>\n",
       "      <td>llama-3.1-70b-instruct</td>\n",
       "      <td>tie (bothbad)</td>\n",
       "      <td>[{'role': 'user', 'content': 'Which number id ...</td>\n",
       "      <td>[{'role': 'user', 'content': 'Which number id ...</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>English</td>\n",
       "      <td>1.721899e+09</td>\n",
       "      <td>{'sum_user_tokens': 14, 'sum_assistant_a_token...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>{'high_freq': False, 'sampled': True}</td>\n",
       "      <td>{'if_v0.1': {'if': False, 'score': 1}, 'math_v...</td>\n",
       "      <td>7d4cec8fb7b286fb2143cfa7b42b8eda</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        question_id                      model_a  \\\n",
       "0  4c6978dfa56b4ffea9d3a47e3c84181a   claude-3-5-sonnet-20240620   \n",
       "1  76ce56f8ba474768bc66128c7993ccb8           mistral-large-2407   \n",
       "2  385420904ba646e7a4df90c6ffae1afa       claude-3-opus-20240229   \n",
       "3  e8fe7c9f75ab4e528367cc7de625c475                gemma-2-9b-it   \n",
       "4  772d53e5c51c487e8a293eadcd9d4855  mixtral-8x22b-instruct-v0.1   \n",
       "\n",
       "                     model_b         winner  \\\n",
       "0         gpt-3.5-turbo-0125  tie (bothbad)   \n",
       "1            athene-70b-0725        model_b   \n",
       "2  gemini-1.5-flash-api-0514  tie (bothbad)   \n",
       "3         qwen2-72b-instruct        model_b   \n",
       "4     llama-3.1-70b-instruct  tie (bothbad)   \n",
       "\n",
       "                                      conversation_a  \\\n",
       "0  [{'role': 'user', 'content': 'В моем портфеле ...   \n",
       "1  [{'role': 'user', 'content': 'php, handle tab ...   \n",
       "2  [{'role': 'user', 'content': '普通人在愿意付出一定资源的情况下...   \n",
       "3  [{'role': 'user', 'content': 'Is there any Art...   \n",
       "4  [{'role': 'user', 'content': 'Which number id ...   \n",
       "\n",
       "                                      conversation_b  turn  anony language  \\\n",
       "0  [{'role': 'user', 'content': 'В моем портфеле ...     1   True  Russian   \n",
       "1  [{'role': 'user', 'content': 'php, handle tab ...     2   True  English   \n",
       "2  [{'role': 'user', 'content': '普通人在愿意付出一定资源的情况下...     1   True  Chinese   \n",
       "3  [{'role': 'user', 'content': 'Is there any Art...     2   True  English   \n",
       "4  [{'role': 'user', 'content': 'Which number id ...     1   True  English   \n",
       "\n",
       "         tstamp                                      conv_metadata  is_code  \\\n",
       "0  1.719064e+09  {'sum_user_tokens': 290, 'sum_assistant_a_toke...    False   \n",
       "1  1.722726e+09  {'sum_user_tokens': 23, 'sum_assistant_a_token...     True   \n",
       "2  1.723119e+09  {'sum_user_tokens': 44, 'sum_assistant_a_token...    False   \n",
       "3  1.721643e+09  {'sum_user_tokens': 14, 'sum_assistant_a_token...    False   \n",
       "4  1.721899e+09  {'sum_user_tokens': 14, 'sum_assistant_a_token...    False   \n",
       "\n",
       "   is_refusal                              dedup_tag  \\\n",
       "0        True  {'high_freq': False, 'sampled': True}   \n",
       "1       False  {'high_freq': False, 'sampled': True}   \n",
       "2        True  {'high_freq': False, 'sampled': True}   \n",
       "3       False  {'high_freq': False, 'sampled': True}   \n",
       "4       False  {'high_freq': False, 'sampled': True}   \n",
       "\n",
       "                                        category_tag  \\\n",
       "0  {'if_v0.1': {'if': True, 'score': 4}, 'math_v0...   \n",
       "1  {'if_v0.1': {'if': False, 'score': 1}, 'math_v...   \n",
       "2  {'if_v0.1': {'if': False, 'score': 3}, 'math_v...   \n",
       "3  {'if_v0.1': {'if': False, 'score': 1}, 'math_v...   \n",
       "4  {'if_v0.1': {'if': False, 'score': 1}, 'math_v...   \n",
       "\n",
       "                         judge_hash  \n",
       "0  a75630e1759a83f9d476889eee3a4063  \n",
       "1  093c8631190fc9fed2ad75a365861d23  \n",
       "2  a92c23ff97936574bee79f89e350ea80  \n",
       "3  26ac88d9f790142cd34c237fe369738c  \n",
       "4  7d4cec8fb7b286fb2143cfa7b42b8eda  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60793"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "english_df = df[df['language'] == 'English']\n",
    "len(english_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "english_df['Prompt'] = english_df.apply(lambda x: ' '.join([i['content'] for i in x['conversation_a'] if i['role'] == 'user']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question_id</th>\n",
       "      <th>model_a</th>\n",
       "      <th>model_b</th>\n",
       "      <th>winner</th>\n",
       "      <th>conversation_a</th>\n",
       "      <th>conversation_b</th>\n",
       "      <th>turn</th>\n",
       "      <th>anony</th>\n",
       "      <th>language</th>\n",
       "      <th>tstamp</th>\n",
       "      <th>conv_metadata</th>\n",
       "      <th>is_code</th>\n",
       "      <th>is_refusal</th>\n",
       "      <th>dedup_tag</th>\n",
       "      <th>category_tag</th>\n",
       "      <th>judge_hash</th>\n",
       "      <th>Prompt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>76ce56f8ba474768bc66128c7993ccb8</td>\n",
       "      <td>mistral-large-2407</td>\n",
       "      <td>athene-70b-0725</td>\n",
       "      <td>model_b</td>\n",
       "      <td>[{'role': 'user', 'content': 'php, handle tab ...</td>\n",
       "      <td>[{'role': 'user', 'content': 'php, handle tab ...</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>English</td>\n",
       "      <td>1.722726e+09</td>\n",
       "      <td>{'sum_user_tokens': 23, 'sum_assistant_a_token...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>{'high_freq': False, 'sampled': True}</td>\n",
       "      <td>{'if_v0.1': {'if': False, 'score': 1}, 'math_v...</td>\n",
       "      <td>093c8631190fc9fed2ad75a365861d23</td>\n",
       "      <td>php, handle tab in text as html, keeping them ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>e8fe7c9f75ab4e528367cc7de625c475</td>\n",
       "      <td>gemma-2-9b-it</td>\n",
       "      <td>qwen2-72b-instruct</td>\n",
       "      <td>model_b</td>\n",
       "      <td>[{'role': 'user', 'content': 'Is there any Art...</td>\n",
       "      <td>[{'role': 'user', 'content': 'Is there any Art...</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>English</td>\n",
       "      <td>1.721643e+09</td>\n",
       "      <td>{'sum_user_tokens': 14, 'sum_assistant_a_token...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>{'high_freq': False, 'sampled': True}</td>\n",
       "      <td>{'if_v0.1': {'if': False, 'score': 1}, 'math_v...</td>\n",
       "      <td>26ac88d9f790142cd34c237fe369738c</td>\n",
       "      <td>Is there any Artificial Superintelligence? Wha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>772d53e5c51c487e8a293eadcd9d4855</td>\n",
       "      <td>mixtral-8x22b-instruct-v0.1</td>\n",
       "      <td>llama-3.1-70b-instruct</td>\n",
       "      <td>tie (bothbad)</td>\n",
       "      <td>[{'role': 'user', 'content': 'Which number id ...</td>\n",
       "      <td>[{'role': 'user', 'content': 'Which number id ...</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>English</td>\n",
       "      <td>1.721899e+09</td>\n",
       "      <td>{'sum_user_tokens': 14, 'sum_assistant_a_token...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>{'high_freq': False, 'sampled': True}</td>\n",
       "      <td>{'if_v0.1': {'if': False, 'score': 1}, 'math_v...</td>\n",
       "      <td>7d4cec8fb7b286fb2143cfa7b42b8eda</td>\n",
       "      <td>Which number id bigger 9.11 or 9.9 ?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>6ccd7a51825249d5881ee501e06bb9ab</td>\n",
       "      <td>mixtral-8x22b-instruct-v0.1</td>\n",
       "      <td>gemma-2-2b-it</td>\n",
       "      <td>model_a</td>\n",
       "      <td>[{'role': 'user', 'content': 'solve this sudok...</td>\n",
       "      <td>[{'role': 'user', 'content': 'solve this sudok...</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>English</td>\n",
       "      <td>1.721922e+09</td>\n",
       "      <td>{'sum_user_tokens': 133, 'sum_assistant_a_toke...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>{'high_freq': False, 'sampled': True}</td>\n",
       "      <td>{'if_v0.1': {'if': True, 'score': 4}, 'math_v0...</td>\n",
       "      <td>1f71d1675fcea18e498cec67006eddeb</td>\n",
       "      <td>solve this sudoku:\\n. 2 . | 6 . . | . . .\\n. ....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>463aa4efacf34f27b6a5c3f1f7417e86</td>\n",
       "      <td>gemini-1.5-pro-api-0514</td>\n",
       "      <td>reka-flash-preview-20240611</td>\n",
       "      <td>model_a</td>\n",
       "      <td>[{'role': 'user', 'content': 'paraphrase and s...</td>\n",
       "      <td>[{'role': 'user', 'content': 'paraphrase and s...</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>English</td>\n",
       "      <td>1.719425e+09</td>\n",
       "      <td>{'sum_user_tokens': 47, 'sum_assistant_a_token...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>{'high_freq': False, 'sampled': True}</td>\n",
       "      <td>{'if_v0.1': {'if': False, 'score': 1}, 'math_v...</td>\n",
       "      <td>4e4b464f98fcea52723ebba66953fbdf</td>\n",
       "      <td>paraphrase and simplify as best you can: The s...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         question_id                      model_a  \\\n",
       "1   76ce56f8ba474768bc66128c7993ccb8           mistral-large-2407   \n",
       "3   e8fe7c9f75ab4e528367cc7de625c475                gemma-2-9b-it   \n",
       "4   772d53e5c51c487e8a293eadcd9d4855  mixtral-8x22b-instruct-v0.1   \n",
       "8   6ccd7a51825249d5881ee501e06bb9ab  mixtral-8x22b-instruct-v0.1   \n",
       "11  463aa4efacf34f27b6a5c3f1f7417e86      gemini-1.5-pro-api-0514   \n",
       "\n",
       "                        model_b         winner  \\\n",
       "1               athene-70b-0725        model_b   \n",
       "3            qwen2-72b-instruct        model_b   \n",
       "4        llama-3.1-70b-instruct  tie (bothbad)   \n",
       "8                 gemma-2-2b-it        model_a   \n",
       "11  reka-flash-preview-20240611        model_a   \n",
       "\n",
       "                                       conversation_a  \\\n",
       "1   [{'role': 'user', 'content': 'php, handle tab ...   \n",
       "3   [{'role': 'user', 'content': 'Is there any Art...   \n",
       "4   [{'role': 'user', 'content': 'Which number id ...   \n",
       "8   [{'role': 'user', 'content': 'solve this sudok...   \n",
       "11  [{'role': 'user', 'content': 'paraphrase and s...   \n",
       "\n",
       "                                       conversation_b  turn  anony language  \\\n",
       "1   [{'role': 'user', 'content': 'php, handle tab ...     2   True  English   \n",
       "3   [{'role': 'user', 'content': 'Is there any Art...     2   True  English   \n",
       "4   [{'role': 'user', 'content': 'Which number id ...     1   True  English   \n",
       "8   [{'role': 'user', 'content': 'solve this sudok...     1   True  English   \n",
       "11  [{'role': 'user', 'content': 'paraphrase and s...     1   True  English   \n",
       "\n",
       "          tstamp                                      conv_metadata  is_code  \\\n",
       "1   1.722726e+09  {'sum_user_tokens': 23, 'sum_assistant_a_token...     True   \n",
       "3   1.721643e+09  {'sum_user_tokens': 14, 'sum_assistant_a_token...    False   \n",
       "4   1.721899e+09  {'sum_user_tokens': 14, 'sum_assistant_a_token...    False   \n",
       "8   1.721922e+09  {'sum_user_tokens': 133, 'sum_assistant_a_toke...     True   \n",
       "11  1.719425e+09  {'sum_user_tokens': 47, 'sum_assistant_a_token...    False   \n",
       "\n",
       "    is_refusal                              dedup_tag  \\\n",
       "1        False  {'high_freq': False, 'sampled': True}   \n",
       "3        False  {'high_freq': False, 'sampled': True}   \n",
       "4        False  {'high_freq': False, 'sampled': True}   \n",
       "8        False  {'high_freq': False, 'sampled': True}   \n",
       "11       False  {'high_freq': False, 'sampled': True}   \n",
       "\n",
       "                                         category_tag  \\\n",
       "1   {'if_v0.1': {'if': False, 'score': 1}, 'math_v...   \n",
       "3   {'if_v0.1': {'if': False, 'score': 1}, 'math_v...   \n",
       "4   {'if_v0.1': {'if': False, 'score': 1}, 'math_v...   \n",
       "8   {'if_v0.1': {'if': True, 'score': 4}, 'math_v0...   \n",
       "11  {'if_v0.1': {'if': False, 'score': 1}, 'math_v...   \n",
       "\n",
       "                          judge_hash  \\\n",
       "1   093c8631190fc9fed2ad75a365861d23   \n",
       "3   26ac88d9f790142cd34c237fe369738c   \n",
       "4   7d4cec8fb7b286fb2143cfa7b42b8eda   \n",
       "8   1f71d1675fcea18e498cec67006eddeb   \n",
       "11  4e4b464f98fcea52723ebba66953fbdf   \n",
       "\n",
       "                                               Prompt  \n",
       "1   php, handle tab in text as html, keeping them ...  \n",
       "3   Is there any Artificial Superintelligence? Wha...  \n",
       "4                Which number id bigger 9.11 or 9.9 ?  \n",
       "8   solve this sudoku:\\n. 2 . | 6 . . | . . .\\n. ....  \n",
       "11  paraphrase and simplify as best you can: The s...  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "english_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json, math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"/home/ygtang/topic_clustering/data/recent_english_dataset.parquet\"\n",
    "# english_df.to_parquet(file_path, index=False)\n",
    "\n",
    "english_df = load_dataset(\"parquet\", data_files=file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60793"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc = english_df['train']['Prompt']\n",
    "len(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec3a77e8797443a99789fbcac6173b8c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1900 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create embeddings\n",
    "model = SentenceTransformer('sentence-transformers/all-mpnet-base-v2')\n",
    "embeddings = model.encode(doc, show_progress_bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60793"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path = \"/home/ygtang/topic_clustering/data/recent_english_embeddings.npy\"\n",
    "# np.save(file_path, embeddings)\n",
    "\n",
    "embeddings = np.load(file_path)\n",
    "len(embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train BERTopic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from umap import UMAP\n",
    "from hdbscan import HDBSCAN\n",
    "from bertopic import BERTopic\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import openai\n",
    "from bertopic.representation import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-28 02:34:37,670 - BERTopic - Dimensionality - Fitting the dimensionality reduction algorithm\n",
      "2024-10-28 02:35:58,258 - BERTopic - Dimensionality - Completed ✓\n",
      "2024-10-28 02:35:58,262 - BERTopic - Cluster - Start clustering the reduced embeddings\n",
      "2024-10-28 02:36:04,113 - BERTopic - Cluster - Completed ✓\n",
      "2024-10-28 02:36:04,128 - BERTopic - Representation - Extracting topics from clusters using representation models.\n",
      "2024-10-28 02:36:18,305 - BERTopic - Representation - Completed ✓\n"
     ]
    }
   ],
   "source": [
    "# Prepare sub-models\n",
    "embedding_model = SentenceTransformer('all-mpnet-base-v2')\n",
    "umap_model = UMAP(n_neighbors=15, n_components=5, min_dist=0.0, metric='cosine', random_state=42)\n",
    "hdbscan_model = HDBSCAN(min_cluster_size=30, metric='euclidean', cluster_selection_method='eom', prediction_data=True)\n",
    "vectorizer_model = CountVectorizer(stop_words=\"english\", min_df=2, ngram_range=(1, 2))\n",
    "\n",
    "# Fit BERTopic without actually performing any clustering\n",
    "topic_model= BERTopic(\n",
    "        embedding_model=embedding_model,\n",
    "        umap_model=umap_model,\n",
    "        hdbscan_model=hdbscan_model,\n",
    "        vectorizer_model=vectorizer_model,\n",
    "        \n",
    "        top_n_words=10,\n",
    "        verbose=True\n",
    ").fit(doc, embeddings=embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"/home/ygtang/topic_clustering/recent_model\"\n",
    "\n",
    "# topic_model.save(\n",
    "#     path=file_path,\n",
    "#     serialization=\"safetensors\",\n",
    "#     save_ctfidf=True,\n",
    "#     save_embedding_model=\"sentence-transformers/all-mpnet-base-v2\"\n",
    "# )\n",
    "\n",
    "topic_model = BERTopic.load(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summarize Categories\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from collections import defaultdict\n",
    "from openai import OpenAI\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_info = topic_model.get_topic_info()\n",
    "doc_info = topic_model.get_document_info(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "contents = doc_info['Document']\n",
    "topics = doc_info['Topic']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Document</th>\n",
       "      <th>Topic</th>\n",
       "      <th>Name</th>\n",
       "      <th>Representation</th>\n",
       "      <th>Representative_Docs</th>\n",
       "      <th>Top_n_words</th>\n",
       "      <th>Representative_document</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>php, handle tab in text as html, keeping them ...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1_self_data_return_new</td>\n",
       "      <td>[self, data, return, new, time, use, like, tex...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>self - data - return - new - time - use - like...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Is there any Artificial Superintelligence? Wha...</td>\n",
       "      <td>0</td>\n",
       "      <td>0_ai_llm_machine_prompt</td>\n",
       "      <td>[ai, llm, machine, prompt, user, human, ethica...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ai - llm - machine - prompt - user - human - e...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Which number id bigger 9.11 or 9.9 ?</td>\n",
       "      <td>3</td>\n",
       "      <td>3_bigger_bigger 11_11 bigger_11</td>\n",
       "      <td>[bigger, bigger 11, 11 bigger, 11, larger, lar...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>bigger - bigger 11 - 11 bigger - 11 - larger -...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>solve this sudoku:\\n. 2 . | 6 . . | . . .\\n. ....</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1_self_data_return_new</td>\n",
       "      <td>[self, data, return, new, time, use, like, tex...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>self - data - return - new - time - use - like...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>paraphrase and simplify as best you can: The s...</td>\n",
       "      <td>149</td>\n",
       "      <td>149_decathlon_plato_throttling_amazon</td>\n",
       "      <td>[decathlon, plato, throttling, amazon, shareho...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>decathlon - plato - throttling - amazon - shar...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Document  Topic  \\\n",
       "0  php, handle tab in text as html, keeping them ...     -1   \n",
       "1  Is there any Artificial Superintelligence? Wha...      0   \n",
       "2               Which number id bigger 9.11 or 9.9 ?      3   \n",
       "3  solve this sudoku:\\n. 2 . | 6 . . | . . .\\n. ....     -1   \n",
       "4  paraphrase and simplify as best you can: The s...    149   \n",
       "\n",
       "                                    Name  \\\n",
       "0                -1_self_data_return_new   \n",
       "1                0_ai_llm_machine_prompt   \n",
       "2        3_bigger_bigger 11_11 bigger_11   \n",
       "3                -1_self_data_return_new   \n",
       "4  149_decathlon_plato_throttling_amazon   \n",
       "\n",
       "                                      Representation  Representative_Docs  \\\n",
       "0  [self, data, return, new, time, use, like, tex...                  NaN   \n",
       "1  [ai, llm, machine, prompt, user, human, ethica...                  NaN   \n",
       "2  [bigger, bigger 11, 11 bigger, 11, larger, lar...                  NaN   \n",
       "3  [self, data, return, new, time, use, like, tex...                  NaN   \n",
       "4  [decathlon, plato, throttling, amazon, shareho...                  NaN   \n",
       "\n",
       "                                         Top_n_words  Representative_document  \n",
       "0  self - data - return - new - time - use - like...                    False  \n",
       "1  ai - llm - machine - prompt - user - human - e...                    False  \n",
       "2  bigger - bigger 11 - 11 bigger - 11 - larger -...                    False  \n",
       "3  self - data - return - new - time - use - like...                    False  \n",
       "4  decathlon - plato - throttling - amazon - shar...                    False  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_info.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "280"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(topic_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic</th>\n",
       "      <th>Count</th>\n",
       "      <th>Name</th>\n",
       "      <th>Representation</th>\n",
       "      <th>Representative_Docs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1</td>\n",
       "      <td>30701</td>\n",
       "      <td>-1_self_data_return_new</td>\n",
       "      <td>[self, data, return, new, time, use, like, tex...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1087</td>\n",
       "      <td>0_ai_llm_machine_prompt</td>\n",
       "      <td>[ai, llm, machine, prompt, user, human, ethica...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1045</td>\n",
       "      <td>1_song_lyrics_chorus_verse</td>\n",
       "      <td>[song, lyrics, chorus, verse, dub, bridge, oh,...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>854</td>\n",
       "      <td>2_story_mark_write story_write</td>\n",
       "      <td>[story, mark, write story, write, girl, horror...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>497</td>\n",
       "      <td>3_bigger_bigger 11_11 bigger_11</td>\n",
       "      <td>[bigger, bigger 11, 11 bigger, 11, larger, lar...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Topic  Count                             Name  \\\n",
       "0     -1  30701          -1_self_data_return_new   \n",
       "1      0   1087          0_ai_llm_machine_prompt   \n",
       "2      1   1045       1_song_lyrics_chorus_verse   \n",
       "3      2    854   2_story_mark_write story_write   \n",
       "4      3    497  3_bigger_bigger 11_11 bigger_11   \n",
       "\n",
       "                                      Representation  Representative_Docs  \n",
       "0  [self, data, return, new, time, use, like, tex...                  NaN  \n",
       "1  [ai, llm, machine, prompt, user, human, ethica...                  NaN  \n",
       "2  [song, lyrics, chorus, verse, dub, bridge, oh,...                  NaN  \n",
       "3  [story, mark, write story, write, girl, horror...                  NaN  \n",
       "4  [bigger, bigger 11, 11 bigger, 11, larger, lar...                  NaN  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_info.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store sampled prompts per topic\n",
    "sampled_prompts = defaultdict(list)\n",
    "\n",
    "for topic_id in topic_info['Topic']:\n",
    "    # Get all prompts for the current topic\n",
    "    topic_prompts = [contents[i] for i in range(len(doc_info)) if topics[i] == topic_id]\n",
    "\n",
    "    s = random.sample(topic_prompts, min(10, len(topic_prompts)))\n",
    "\n",
    "    sampled_prompts[topic_id] = s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 :  The topic of doc is 'Machine Learning Market & Applications'.\n",
      "50 :  The topic of doc is 'Flask and Discord Bot Programming'.\n",
      "100 :  The topic of doc is 'Mathematical Puzzles and Brain Teasers'.\n",
      "150 :  The topic of doc is 'Spring Boot MyBatis Project Setup'.\n",
      "200 :  The topic of doc is 'Unethical AI Behavior Simulation'.\n",
      "250 :  The topic of doc is 'Cave Exploration Adventure Story'.\n"
     ]
    }
   ],
   "source": [
    "key = \"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\"\n",
    "\n",
    "def summarize_topic(prompts):\n",
    "    input_text = \"Based on the information above, extract a short but highly descriptive topic label of at most 5 words:\\n\\n\" + \"\\n\\n\".join(prompts)\n",
    "    client = openai.OpenAI(api_key=key)\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You help summarize the category of the given prompts. Make sure it is in the following format: The topic of doc is '...'.\"},\n",
    "            {\"role\": \"user\", \"content\": input_text}\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "# Summarize the prompts\n",
    "summaries = {}\n",
    "for topic_id, prompts in sampled_prompts.items():\n",
    "    summary = summarize_topic(prompts)\n",
    "    summaries[topic_id] = summary\n",
    "\n",
    "    if topic_id % 50 == 0:\n",
    "        print(topic_id, ': ', summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "summaries[-1] = \"'Miscellaneous'\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "summaries_df = pd.DataFrame(list(summaries.items()), columns=['Topic', 'Summary'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic</th>\n",
       "      <th>Summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1</td>\n",
       "      <td>'Miscellaneous'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>The topic of doc is 'Machine Learning Market &amp;...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>The topic of doc is 'Creative Songwriting and ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>The topic of doc is 'Creative Writing Prompts ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>The topic of doc is 'Number Comparison Questio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>275</th>\n",
       "      <td>274</td>\n",
       "      <td>The topic of doc is 'Acne Treatment Advice'.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>276</th>\n",
       "      <td>275</td>\n",
       "      <td>The topic of doc is 'Apartment Living and Luxu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>277</th>\n",
       "      <td>276</td>\n",
       "      <td>The topic of doc is 'Water Quality and Contami...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278</th>\n",
       "      <td>277</td>\n",
       "      <td>The topic of doc is 'Fantasy RPG Character Abi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279</th>\n",
       "      <td>278</td>\n",
       "      <td>The topic of doc is 'AI Roleplaying Bot Design...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>280 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Topic                                            Summary\n",
       "0       -1                                    'Miscellaneous'\n",
       "1        0  The topic of doc is 'Machine Learning Market &...\n",
       "2        1  The topic of doc is 'Creative Songwriting and ...\n",
       "3        2  The topic of doc is 'Creative Writing Prompts ...\n",
       "4        3  The topic of doc is 'Number Comparison Questio...\n",
       "..     ...                                                ...\n",
       "275    274       The topic of doc is 'Acne Treatment Advice'.\n",
       "276    275  The topic of doc is 'Apartment Living and Luxu...\n",
       "277    276  The topic of doc is 'Water Quality and Contami...\n",
       "278    277  The topic of doc is 'Fantasy RPG Character Abi...\n",
       "279    278  The topic of doc is 'AI Roleplaying Bot Design...\n",
       "\n",
       "[280 rows x 2 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summaries_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "summaries_df['Category'] = summaries_df['Summary'].apply(lambda x: re.search(r\"'(.*?)'\", x).group(1))\n",
    "topic_info_modified = topic_info[['Topic', 'Count']]\n",
    "summaries_df = summaries_df.merge(topic_info_modified, on='Topic')[['Topic', 'Category', 'Count']]\n",
    "summaries_df['Percentage'] = summaries_df['Count'] / summaries_df['Count'].sum()\n",
    "summaries_df['Example Prompt'] = summaries_df.apply(lambda x: sampled_prompts[x.Topic], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"/home/ygtang/arena-leaderboard-v2/topic_clustering/data/recent_english_categories.csv\"\n",
    "summaries_df.to_csv(file_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "topic_clustering",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
