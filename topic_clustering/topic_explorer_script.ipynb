{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topic Explorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datasets import load_dataset\n",
    "\n",
    "file_path = \"/out\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Specific Category\n",
    "\n",
    "We began by summarizing the English prompts from the 06/2024 - 08/2024 leaderboard dataset into specific categories."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Processing\n",
    "\n",
    "From the dataset of 60,000 conversations, we selected those tagged as English and removed any repetitive entries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "52483"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_json(\"/mnt/disk0/weilin/tmp/battles_latest_20240819_freshness_20240619_md.json\")\n",
    "\n",
    "english_df = df[df['language'] == 'English'].copy()\n",
    "english_df['Prompt'] = english_df.apply(\n",
    "    lambda x: ' '.join([i['content'] for i in x['conversation_a'] if i['role'] == 'user']),\n",
    "    axis=1\n",
    ")\n",
    "english_df = english_df.drop_duplicates(subset='Prompt')\n",
    "doc = english_df['Prompt']\n",
    "\n",
    "len(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "model = SentenceTransformer('sentence-transformers/all-mpnet-base-v2')\n",
    "embeddings = model.encode(doc, show_progress_bar=True)\n",
    "\n",
    "np.save(f\"{file_path}/recent_english_embeddings.npy\", embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BERTopic Topic Clustering\n",
    "\n",
    "We performed topic clustering on the english conversation dataset using BERTopic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from umap import UMAP\n",
    "from hdbscan import HDBSCAN\n",
    "from bertopic import BERTopic\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import openai\n",
    "from bertopic.representation import OpenAI\n",
    "\n",
    "embedding_model = SentenceTransformer('all-mpnet-base-v2')\n",
    "umap_model = UMAP(n_neighbors=20, n_components=5, min_dist=0.0, metric='cosine', random_state=42)\n",
    "hdbscan_model = HDBSCAN(min_cluster_size=30, metric='euclidean', cluster_selection_method='eom', prediction_data=True)\n",
    "vectorizer_model = CountVectorizer(stop_words=\"english\", min_df=2, ngram_range=(1, 2))\n",
    "\n",
    "topic_model = BERTopic(\n",
    "        embedding_model=embedding_model,\n",
    "        umap_model=umap_model,\n",
    "        hdbscan_model=hdbscan_model,\n",
    "        vectorizer_model=vectorizer_model,\n",
    "        \n",
    "        top_n_words=10,\n",
    "        verbose=True,\n",
    "        calculate_probabilities=True\n",
    ")\n",
    "\n",
    "topics, probs = topic_model.fit_transform(doc, embeddings=embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before reducing outliers, we selected 20 example prompts from each identified cluster. These prompts were chosen from those in the first 20th percentile of probability calculated by HDBSCAN clustering, representing the likelihood that they belong to the cluster. We excluded extra-long (>100 words) and extra-short (<5 words) prompts for better readability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from collections import defaultdict\n",
    "\n",
    "sampled_prompts = defaultdict(list)\n",
    "topic_info = topic_model.get_topic_info()\n",
    "doc_info = topic_model.get_document_info(doc)\n",
    "\n",
    "for topic_id in topic_info['Topic'][1:]:\n",
    "    filtered_docs = doc_info[(doc_info['Topic'] == topic_id) & \n",
    "                             (doc_info['Probability'] >= doc_info['Probability'].quantile(0.8)) &\n",
    "                             (doc_info['Document'].str.split().str.len() >= 5)]\n",
    "\n",
    "    res = filtered_docs\n",
    "    cap = 100\n",
    "    if len(filtered_docs) >= 20:\n",
    "        while len(res) < 20:\n",
    "            res = filtered_docs[\n",
    "                filtered_docs['Document'].str.split().str.len() <= cap\n",
    "            ]\n",
    "            cap += 50\n",
    "    if topic_id % 10 == 0:\n",
    "        print(topic_id)\n",
    "    \n",
    "    sampled_docs = res.sample(n=min(20, \n",
    "                            len(res)),\n",
    "                            random_state=42,\n",
    "                            replace=False)\n",
    "    \n",
    "    sampled_prompts[topic_id] = sampled_docs['Document'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle \n",
    "\n",
    "with open(f\"{file_path}/example_prompts.pkl\", 'wb') as f:\n",
    "    pickle.dump(sampled_prompts, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reduce all outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_topics = topic_model.reduce_outliers(doc, topics, probabilities=probs, strategy=\"probabilities\")\n",
    "topic_model.update_topics(doc, topics=new_topics)\n",
    "\n",
    "topic_model.save(\n",
    "    path=f\"{file_path}/model\",\n",
    "    serialization=\"safetensors\",\n",
    "    save_ctfidf=True,\n",
    "    save_embedding_model=\"sentence-transformers/all-mpnet-base-v2\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summarize Category Names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each cluster, we used ChatGPT-4o to assign a category name based on the selected example prompts. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_topic(prompts):\n",
    "    input_text = \"Based on the sampled prompts below, extract a short but highly descriptive topic label of at most 5 words:\\n\\n\" + \"\\n\\n\".join(prompts)\n",
    "    client = openai.OpenAI()\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You help summarize the category of the given prompts. Make sure it is in the following format: The topic of doc is '...'.\"},\n",
    "            {\"role\": \"user\", \"content\": input_text}\n",
    "        ],\n",
    "        temperature=0\n",
    "    )\n",
    "\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "summaries = {}\n",
    "for topic_id, prompts in sampled_prompts.items():\n",
    "    summary = summarize_topic(prompts)\n",
    "    summaries[topic_id] = summary\n",
    "\n",
    "    if topic_id % 50 == 0:\n",
    "        print(topic_id, ': ', summary)\n",
    "\n",
    "summaries_df = pd.DataFrame(list(summaries.items()), columns=['Topic', 'Summary'])\n",
    "summaries_df['Category'] = summaries_df['Summary'].apply(lambda x: re.search(r\"'(.*?)'\", x).group(1))\n",
    "topic_info_modified = topic_info[['Topic', 'Count']]\n",
    "summaries_df = summaries_df.merge(topic_info_modified, on='Topic')[['Topic', 'Category', 'Count']]\n",
    "summaries_df['Percentage'] = summaries_df['Count'] / summaries_df['Count'].sum()\n",
    "summaries_df['Example Prompt'] = summaries_df.apply(lambda x: sampled_prompts[x.Topic], axis=1)\n",
    "summaries_df['Example Prompt'] = summaries_df['Example Prompt'].str.join('|||')\n",
    "\n",
    "summaries_df.to_csv(f\"{file_path}/recent_english_narrow_categories.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Broad Category\n",
    "\n",
    "We performed topic clustering again on the category names of these 279 specific categories, summarizing them into 12 broad categories. The summarization process followed an almost identical approach as before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "broad_doc = summaries_df['Category']\n",
    "\n",
    "# Create embeddings\n",
    "model = SentenceTransformer('sentence-transformers/all-mpnet-base-v2')\n",
    "embeddings = model.encode(broad_doc, show_progress_bar=True)\n",
    "\n",
    "# BERTopic\n",
    "embedding_model = SentenceTransformer('all-mpnet-base-v2')\n",
    "umap_model = UMAP(n_neighbors=15, n_components=5, min_dist=0.0, metric='cosine', random_state=42)\n",
    "hdbscan_model = HDBSCAN(min_cluster_size=4, metric='euclidean', cluster_selection_method='eom', prediction_data=True)\n",
    "vectorizer_model = CountVectorizer(stop_words=\"english\", min_df=2, ngram_range=(1, 2))\n",
    "topic_model= BERTopic(\n",
    "        embedding_model=embedding_model,\n",
    "        umap_model=umap_model,\n",
    "        hdbscan_model=hdbscan_model,\n",
    "        vectorizer_model=vectorizer_model,\n",
    "        # representation_model=openai_model,\n",
    "\n",
    "        top_n_words=3,\n",
    "        verbose=True\n",
    ")\n",
    "\n",
    "topics, probs = topic_model.fit_transform(broad_doc, embeddings=embeddings)\n",
    "\n",
    "# Reduce all outliers\n",
    "new_topics = topic_model.reduce_outliers(broad_doc, topics, strategy=\"embeddings\")\n",
    "topic_model.update_topics(broad_doc, topics=new_topics)\n",
    "\n",
    "# Summarize category names\n",
    "broad_topic_info = topic_model.get_topic_info()\n",
    "broad_doc_info = topic_model.get_document_info(broad_doc)\n",
    "summaries = {}\n",
    "\n",
    "for topic_id in range(len(broad_topic_info)):\n",
    "    cat = ', '.join(list(broad_doc_info[broad_doc_info['Topic'] == topic_id]['Document']))\n",
    "    summary = summarize_topic(cat)\n",
    "    summaries[topic_id] = summary\n",
    "\n",
    "\n",
    "# Combine results \n",
    "broad_summaries_df = pd.DataFrame(list(summaries.items()), columns=['Topic', 'Summary'])\n",
    "broad_summaries_df['Category'] = broad_summaries_df['Summary'].apply(lambda x: re.search(r\"'(.*?)'\", x).group(1))\n",
    "topic_info_modified = broad_topic_info[['Topic', 'Count']]\n",
    "broad_summaries_df = broad_summaries_df.merge(topic_info_modified, on='Topic')[['Topic', 'Category', 'Count']]\n",
    "broad_summaries_df['Percentage'] = broad_summaries_df['Count'] / broad_summaries_df['Count'].sum()\n",
    "broad_summaries_df = broad_summaries_df.fillna('Other')\n",
    "\n",
    "broad_summaries_df.to_csv(f\"{file_path}/recent_english_broad_categories.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Processing: combine broad and narrow topics\n",
    "\n",
    "The clustering results were stored in JSON format to facilitate future visualizations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge categories\n",
    "merged = broad_doc_info[['Topic']].merge(summaries_df, left_index=True, right_index=True)\n",
    "merged = merged.merge(broad_summaries_df, left_on='Topic_x', right_on='Topic')\n",
    "merged = merged[['Topic_x', 'Category_y', 'Topic_y', 'Category_x', 'Count_x', 'Percentage_x', 'Example Prompt']]\n",
    "merged = merged.rename(columns={\n",
    "    'Topic_x': 'broad_category_id', \n",
    "    'Category_y': 'broad_category', \n",
    "    'Topic_y': 'narrower_category_id',\n",
    "    'Category_x': 'narrower_category',\n",
    "    'Count_x': 'prompt_count',\n",
    "    'Percentage_x': 'prompt_percentage',\n",
    "    'Example Prompt': 'example_prompt'})\n",
    "\n",
    "# Export results in JSON format\n",
    "root = {\n",
    "    \"name\": \"categories\",\n",
    "    \"children\": []\n",
    "}\n",
    "for broad_category, group in merged.groupby([\"broad_category_id\", \"broad_category\"]):\n",
    "    parent = {\n",
    "        \"id\": int(broad_category[0]),\n",
    "        \"name\": broad_category[1],\n",
    "        \"children\": []\n",
    "    }\n",
    "    \n",
    "    for _, row in group.iterrows():\n",
    "        child = {\n",
    "            \"id\": row[\"narrower_category_id\"],\n",
    "            \"name\": row[\"narrower_category\"],\n",
    "            \"count\": row[\"prompt_count\"],\n",
    "            \"percent\": row['prompt_percentage'],\n",
    "        }\n",
    "\n",
    "        parent[\"children\"].append(child)\n",
    "    \n",
    "    root[\"children\"].append(parent)\n",
    "\n",
    "json_output = json.dumps(root, indent=4)\n",
    "\n",
    "with open(f\"{file_path}/recent_english_piechart.json\", \"w\") as f:\n",
    "    f.write(json_output)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "topic_clustering",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
